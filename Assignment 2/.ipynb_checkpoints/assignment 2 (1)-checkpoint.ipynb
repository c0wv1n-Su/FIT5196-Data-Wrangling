{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP3233.pdf\n",
      "https://drive.google.com/uc?export=download&id=1u2TPAS9i-gRoQAYRVbIaDdY_2ktejzRL\n",
      "Begin download PP3233.pdf\n",
      "Finish downloadPP3233.pdf\n",
      "PP3289.pdf\n",
      "https://drive.google.com/uc?export=download&id=1kjJuKki3zR1k2nBZiaMeQJqUIpjC3sLJ\n",
      "Begin download PP3289.pdf\n",
      "Finish downloadPP3289.pdf\n",
      "PP3367.pdf\n",
      "https://drive.google.com/uc?export=download&id=1K-cvY8IpG-lgfIcrr2iZP4STLYxk5H-S\n",
      "Begin download PP3367.pdf\n",
      "Finish downloadPP3367.pdf\n",
      "PP3475.pdf\n",
      "https://drive.google.com/uc?export=download&id=1ak84ZhvmKcbSc_yCIeecT_Mr9CrsJhlo\n",
      "Begin download PP3475.pdf\n",
      "Finish downloadPP3475.pdf\n",
      "PP3529.pdf\n",
      "https://drive.google.com/uc?export=download&id=1CBV6LpQlZDsKE6iriYaSfVkKnFBTPwtD\n",
      "Begin download PP3529.pdf\n",
      "Finish downloadPP3529.pdf\n",
      "PP3596.pdf\n",
      "https://drive.google.com/uc?export=download&id=1QU07TBE9PJpYYFhlBVT80eBAqXtbowWa\n",
      "Begin download PP3596.pdf\n",
      "Finish downloadPP3596.pdf\n",
      "PP3664.pdf\n",
      "https://drive.google.com/uc?export=download&id=1HcFZiDGa13yt4zKpU47qUyMn-yYgOWfO\n",
      "Begin download PP3664.pdf\n",
      "Finish downloadPP3664.pdf\n",
      "PP3698.pdf\n",
      "https://drive.google.com/uc?export=download&id=1h46RZUMyNOr4qWG_KEEjg2wgzfikmJPc\n",
      "Begin download PP3698.pdf\n",
      "Finish downloadPP3698.pdf\n",
      "PP3729.pdf\n",
      "https://drive.google.com/uc?export=download&id=1lQjPF-ETYDDCYrDi7EeF6hvltmqaxgvd\n",
      "Begin download PP3729.pdf\n",
      "Finish downloadPP3729.pdf\n",
      "PP3794.pdf\n",
      "https://drive.google.com/uc?export=download&id=1hrKtRFG8T3FH5p5I3lJsUtAElhbd48KD\n",
      "Begin download PP3794.pdf\n",
      "Finish downloadPP3794.pdf\n",
      "PP3807.pdf\n",
      "https://drive.google.com/uc?export=download&id=1bQwb0shRaIptnyYFp05Nh53QU4V_iIcx\n",
      "Begin download PP3807.pdf\n",
      "Finish downloadPP3807.pdf\n",
      "PP3822.pdf\n",
      "https://drive.google.com/uc?export=download&id=1vj7yT-qs-QLH1cr8oNWO9SbyUCNQHP3d\n",
      "Begin download PP3822.pdf\n",
      "Finish downloadPP3822.pdf\n",
      "PP3851.pdf\n",
      "https://drive.google.com/uc?export=download&id=11nzFdBEdG3lB3NG2khlMisWuXl2pJyRg\n",
      "Begin download PP3851.pdf\n",
      "Finish downloadPP3851.pdf\n",
      "PP3872.pdf\n",
      "https://drive.google.com/uc?export=download&id=1Usce84HNceHxQ7VnYy5r_t-8sSTNCDeV\n",
      "Begin download PP3872.pdf\n",
      "Finish downloadPP3872.pdf\n",
      "PP3887.pdf\n",
      "https://drive.google.com/uc?export=download&id=1wpGUdsve9vVAIyGEr4YPOfWfqbSsMcAF\n",
      "Begin download PP3887.pdf\n",
      "Finish downloadPP3887.pdf\n",
      "PP3920.pdf\n",
      "https://drive.google.com/uc?export=download&id=1PFkryZueTzDZgK1-SnRDbi8h40TnFYM3\n",
      "Begin download PP3920.pdf\n",
      "Finish downloadPP3920.pdf\n",
      "PP3928.pdf\n",
      "https://drive.google.com/uc?export=download&id=1XV8uAOPzFs0nQyR7-PkT12yx_7OCak98\n",
      "Begin download PP3928.pdf\n",
      "Finish downloadPP3928.pdf\n",
      "PP3965.pdf\n",
      "https://drive.google.com/uc?export=download&id=1iTeS_p5q65qvAnxdRB9Q3Ch7I1zz_nhu\n",
      "Begin download PP3965.pdf\n",
      "Finish downloadPP3965.pdf\n",
      "PP3988.pdf\n",
      "https://drive.google.com/uc?export=download&id=16ADSR0oPz36ZI9292ZJls8V8_0-tNNY1\n",
      "Begin download PP3988.pdf\n",
      "Finish downloadPP3988.pdf\n",
      "PP4034.pdf\n",
      "https://drive.google.com/uc?export=download&id=17zI_Pak9PiOIuzVe-yoD3s_qi1DRezj1\n",
      "Begin download PP4034.pdf\n",
      "Finish downloadPP4034.pdf\n",
      "PP4083.pdf\n",
      "https://drive.google.com/uc?export=download&id=1858m-bd_CKg31Y3L9DoJXjD144PyMKsj\n",
      "Begin download PP4083.pdf\n",
      "Finish downloadPP4083.pdf\n",
      "PP4098.pdf\n",
      "https://drive.google.com/uc?export=download&id=1bYQOXTx2tjq0n_PfTETwjlauCtEbqb5z\n",
      "Begin download PP4098.pdf\n",
      "Finish downloadPP4098.pdf\n",
      "PP4177.pdf\n",
      "https://drive.google.com/uc?export=download&id=17GdZa3ALF7bHPYTWfTVx1a-o4wgaOsbN\n",
      "Begin download PP4177.pdf\n",
      "Finish downloadPP4177.pdf\n",
      "PP4213.pdf\n",
      "https://drive.google.com/uc?export=download&id=1XiDBJ0Rysg56qA2yQlVtUGUytoT97cxR\n",
      "Begin download PP4213.pdf\n",
      "Finish downloadPP4213.pdf\n",
      "PP4300.pdf\n",
      "https://drive.google.com/uc?export=download&id=1jjtoH1xAs24S35YlfufB_MZqNQxP4585\n",
      "Begin download PP4300.pdf\n",
      "Finish downloadPP4300.pdf\n",
      "PP4318.pdf\n",
      "https://drive.google.com/uc?export=download&id=1HwjbEc_jyAvkx_ovC7SjQ9bCskO1sgvv\n",
      "Begin download PP4318.pdf\n",
      "Finish downloadPP4318.pdf\n",
      "PP4401.pdf\n",
      "https://drive.google.com/uc?export=download&id=188J3WOAmFngw4H7XLv8HKPPnN5zeRTd2\n",
      "Begin download PP4401.pdf\n",
      "Finish downloadPP4401.pdf\n",
      "PP4427.pdf\n",
      "https://drive.google.com/uc?export=download&id=11pPdlM8ejoA4kBfSad2Iv1pFOkb3JPeg\n",
      "Begin download PP4427.pdf\n",
      "Finish downloadPP4427.pdf\n",
      "PP4448.pdf\n",
      "https://drive.google.com/uc?export=download&id=1VresXJDM_xrT2wvr3ffM2_A930tG--Q9\n",
      "Begin download PP4448.pdf\n",
      "Finish downloadPP4448.pdf\n",
      "PP4528.pdf\n",
      "https://drive.google.com/uc?export=download&id=18ZHF-I3pk_Kjksmh2qxVklF7sgVkJJiG\n",
      "Begin download PP4528.pdf\n",
      "Finish downloadPP4528.pdf\n",
      "PP4544.pdf\n",
      "https://drive.google.com/uc?export=download&id=1lbqUkuu07SZOGJEc9195weadcKdb4vLB\n",
      "Begin download PP4544.pdf\n",
      "Finish downloadPP4544.pdf\n",
      "PP4580.pdf\n",
      "https://drive.google.com/uc?export=download&id=1hCSNkv3MrbS4HlHAXC2HRGkV69w3eO3s\n",
      "Begin download PP4580.pdf\n",
      "Finish downloadPP4580.pdf\n",
      "PP4659.pdf\n",
      "https://drive.google.com/uc?export=download&id=1O2-CdI6Ae4VaeQ86po2xdSfoT4E5fjLL\n",
      "Begin download PP4659.pdf\n",
      "Finish downloadPP4659.pdf\n",
      "PP4687.pdf\n",
      "https://drive.google.com/uc?export=download&id=1G1H3uL65kclBib55Z7p42NhcCs9E1k_3\n",
      "Begin download PP4687.pdf\n",
      "Finish downloadPP4687.pdf\n",
      "PP4707.pdf\n",
      "https://drive.google.com/uc?export=download&id=1Iyg8wFbw2q1yfL_GQyzpRCNGzfmGzLyA\n",
      "Begin download PP4707.pdf\n",
      "Finish downloadPP4707.pdf\n",
      "PP4734.pdf\n",
      "https://drive.google.com/uc?export=download&id=1pvpk7mTGpmM5l80Vq79MzGPrfadIdaCj\n",
      "Begin download PP4734.pdf\n",
      "Finish downloadPP4734.pdf\n",
      "PP4756.pdf\n",
      "https://drive.google.com/uc?export=download&id=1I4QBiMzav14a4MfA_VWuoxj7Id0WhHX4\n",
      "Begin download PP4756.pdf\n",
      "Finish downloadPP4756.pdf\n",
      "PP4798.pdf\n",
      "https://drive.google.com/uc?export=download&id=1hpWpDjqexVMGu4d20M-r5u18aYLBMH2f\n",
      "Begin download PP4798.pdf\n",
      "Finish downloadPP4798.pdf\n",
      "PP4877.pdf\n",
      "https://drive.google.com/uc?export=download&id=1215bXCnIXciclBqPLb2pHBiMAY6gC4RO\n",
      "Begin download PP4877.pdf\n",
      "Finish downloadPP4877.pdf\n",
      "PP4921.pdf\n",
      "https://drive.google.com/uc?export=download&id=1uKIjpR82JWiGYPo6HLJ3StKNtSq8ovEU\n",
      "Begin download PP4921.pdf\n",
      "Finish downloadPP4921.pdf\n",
      "PP4946.pdf\n",
      "https://drive.google.com/uc?export=download&id=1CXZnWGUieZjIU3Mg2voGk_kblhYeQa3b\n",
      "Begin download PP4946.pdf\n",
      "Finish downloadPP4946.pdf\n",
      "PP4968.pdf\n",
      "https://drive.google.com/uc?export=download&id=1gGOlsvCUYbzvsGR4MexQ2Rmsrh2mV9Zf\n",
      "Begin download PP4968.pdf\n",
      "Finish downloadPP4968.pdf\n",
      "PP5016.pdf\n",
      "https://drive.google.com/uc?export=download&id=13FKtvWyEurThrbRoWsDWCljTgoBdnHpT\n",
      "Begin download PP5016.pdf\n",
      "Finish downloadPP5016.pdf\n",
      "PP5043.pdf\n",
      "https://drive.google.com/uc?export=download&id=15S6KLnV2pzJjIvUhq6RRWAGFV0pyoCN-\n",
      "Begin download PP5043.pdf\n",
      "Finish downloadPP5043.pdf\n",
      "PP5074.pdf\n",
      "https://drive.google.com/uc?export=download&id=1TLsXlBicFuJBcj5oLW2Fp68P9yrLCVgo\n",
      "Begin download PP5074.pdf\n",
      "Finish downloadPP5074.pdf\n",
      "PP5087.pdf\n",
      "https://drive.google.com/uc?export=download&id=1KH8O4RfeUbkzFHOrtT-1gytqRhBkI0Tt\n",
      "Begin download PP5087.pdf\n",
      "Finish downloadPP5087.pdf\n",
      "PP5107.pdf\n",
      "https://drive.google.com/uc?export=download&id=1gg60U2y_0yWBeWKP-G7kgZ_Mo4T_tTu8\n",
      "Begin download PP5107.pdf\n",
      "Finish downloadPP5107.pdf\n",
      "PP5122.pdf\n",
      "https://drive.google.com/uc?export=download&id=1UsROYqQB2NEe_zB9P8fZQ_Yeev2iO4rX\n",
      "Begin download PP5122.pdf\n",
      "Finish downloadPP5122.pdf\n",
      "PP5172.pdf\n",
      "https://drive.google.com/uc?export=download&id=1z_vPp9qflt3Km55cw5Cw2OBFUTD_SErM\n",
      "Begin download PP5172.pdf\n",
      "Finish downloadPP5172.pdf\n",
      "PP5235.pdf\n",
      "https://drive.google.com/uc?export=download&id=1NLMKQTY_m_nVTYyjblW4karzzWpBjgPM\n",
      "Begin download PP5235.pdf\n",
      "Finish downloadPP5235.pdf\n",
      "PP5283.pdf\n",
      "https://drive.google.com/uc?export=download&id=1VMmt0M5ER3B_oIagQay4qtW9gfMuEaah\n",
      "Begin download PP5283.pdf\n",
      "Finish downloadPP5283.pdf\n",
      "PP5319.pdf\n",
      "https://drive.google.com/uc?export=download&id=1hzwIicU5pZdGtQ8JFX9nsFLA4acqEClL\n",
      "Begin download PP5319.pdf\n",
      "Finish downloadPP5319.pdf\n",
      "PP5357.pdf\n",
      "https://drive.google.com/uc?export=download&id=1vB7CEWEln9PgJuYCyLIgM8AoIHltz7d6\n",
      "Begin download PP5357.pdf\n",
      "Finish downloadPP5357.pdf\n",
      "PP5416.pdf\n",
      "https://drive.google.com/uc?export=download&id=10Yp5D3fVpnn51BSq8WRz8dIs39y__Exe\n",
      "Begin download PP5416.pdf\n",
      "Finish downloadPP5416.pdf\n",
      "PP5444.pdf\n",
      "https://drive.google.com/uc?export=download&id=1_cHi_oCk4-2e0TWuhU2bAIjg_sQKOByR\n",
      "Begin download PP5444.pdf\n",
      "Finish downloadPP5444.pdf\n",
      "PP5447.pdf\n",
      "https://drive.google.com/uc?export=download&id=1MlInPPCetoe-7fITnlfUNX7u3eXF-EOe\n",
      "Begin download PP5447.pdf\n",
      "Finish downloadPP5447.pdf\n",
      "PP5492.pdf\n",
      "https://drive.google.com/uc?export=download&id=1J_k3Q2yXKQSMGHek9QxZmyekggiYG_QP\n",
      "Begin download PP5492.pdf\n",
      "Finish downloadPP5492.pdf\n",
      "PP5504.pdf\n",
      "https://drive.google.com/uc?export=download&id=1eymSgp3jV_p-BtLkNlbMhD9eGOnjzqP6\n",
      "Begin download PP5504.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish downloadPP5504.pdf\n",
      "PP5563.pdf\n",
      "https://drive.google.com/uc?export=download&id=1jcNvYbZBDLfVvbT-XjBMtZPhvmhsr9UK\n",
      "Begin download PP5563.pdf\n",
      "Finish downloadPP5563.pdf\n",
      "PP5582.pdf\n",
      "https://drive.google.com/uc?export=download&id=1NZgUnjnR-fqlBUrWWhV6vhe0Dth4FuM2\n",
      "Begin download PP5582.pdf\n",
      "Finish downloadPP5582.pdf\n",
      "PP5614.pdf\n",
      "https://drive.google.com/uc?export=download&id=16LdEiPNYdFBgWvmlw4MBhiYcyPttfuKl\n",
      "Begin download PP5614.pdf\n",
      "Finish downloadPP5614.pdf\n",
      "PP5630.pdf\n",
      "https://drive.google.com/uc?export=download&id=1lLvNLIhrLraB4jKE9B3ROpkqhr1IBr3J\n",
      "Begin download PP5630.pdf\n",
      "Finish downloadPP5630.pdf\n",
      "PP5721.pdf\n",
      "https://drive.google.com/uc?export=download&id=124WQ1V-P8WRTOyi0f-RFqjFouPmWeFJg\n",
      "Begin download PP5721.pdf\n",
      "Finish downloadPP5721.pdf\n",
      "PP5772.pdf\n",
      "https://drive.google.com/uc?export=download&id=11VIZHC8IsO9pyUX7px6mn2NFLzTLfX7k\n",
      "Begin download PP5772.pdf\n",
      "Finish downloadPP5772.pdf\n",
      "PP5807.pdf\n",
      "https://drive.google.com/uc?export=download&id=1C6yaM5QvILHo_6OyT01snshwmW5q107o\n",
      "Begin download PP5807.pdf\n",
      "Finish downloadPP5807.pdf\n",
      "PP5855.pdf\n",
      "https://drive.google.com/uc?export=download&id=1YpmWT1WZOcN8d4WdggHLLJjjETyxH5_4\n",
      "Begin download PP5855.pdf\n",
      "Finish downloadPP5855.pdf\n",
      "PP5882.pdf\n",
      "https://drive.google.com/uc?export=download&id=1sD7PXFbqFYiPlWB0-6jrHyaCsCBTonwk\n",
      "Begin download PP5882.pdf\n",
      "Finish downloadPP5882.pdf\n",
      "PP5927.pdf\n",
      "https://drive.google.com/uc?export=download&id=191_589q5dFSEaYW__QS6zd6ntFkcls35\n",
      "Begin download PP5927.pdf\n",
      "Finish downloadPP5927.pdf\n",
      "PP5932.pdf\n",
      "https://drive.google.com/uc?export=download&id=1cfx__7PirftJDkOTWo-lMlJg9amqWnOB\n",
      "Begin download PP5932.pdf\n",
      "Finish downloadPP5932.pdf\n",
      "PP5941.pdf\n",
      "https://drive.google.com/uc?export=download&id=19NFYLF04gB80iXPNzwquIdyU8nkaMhmJ\n",
      "Begin download PP5941.pdf\n",
      "Finish downloadPP5941.pdf\n",
      "PP5981.pdf\n",
      "https://drive.google.com/uc?export=download&id=1OwxAxqihYCCshdR7nvBY2Vj0lxopJacZ\n",
      "Begin download PP5981.pdf\n",
      "Finish downloadPP5981.pdf\n",
      "PP6017.pdf\n",
      "https://drive.google.com/uc?export=download&id=1xFqkmFhDMsPNoZ201tPX0iySi7YdTe_X\n",
      "Begin download PP6017.pdf\n",
      "Finish downloadPP6017.pdf\n",
      "PP6034.pdf\n",
      "https://drive.google.com/uc?export=download&id=10MreOJxWyG2LO49O9hcxAAmDohg2RTHa\n",
      "Begin download PP6034.pdf\n",
      "Finish downloadPP6034.pdf\n",
      "PP6045.pdf\n",
      "https://drive.google.com/uc?export=download&id=1tNRVm96XK7cB4Nt_4uZP0gpl54CqJbL6\n",
      "Begin download PP6045.pdf\n",
      "Finish downloadPP6045.pdf\n",
      "PP6110.pdf\n",
      "https://drive.google.com/uc?export=download&id=130U7GJiG1HY0Xeq2MMxSk_u3OPma1Ro5\n",
      "Begin download PP6110.pdf\n",
      "Finish downloadPP6110.pdf\n",
      "PP6171.pdf\n",
      "https://drive.google.com/uc?export=download&id=1T5LEIPgI_rQjhg9mQPwXJsu5GEyhNgQq\n",
      "Begin download PP6171.pdf\n",
      "Finish downloadPP6171.pdf\n",
      "PP6233.pdf\n",
      "https://drive.google.com/uc?export=download&id=1_k7gSCR1kDQOCb78kU828Hk1BCUC0Voc\n",
      "Begin download PP6233.pdf\n",
      "Finish downloadPP6233.pdf\n",
      "PP6334.pdf\n",
      "https://drive.google.com/uc?export=download&id=1Q2PQQ11US9IXFIFwFlsWTBgPkZAP4fMg\n",
      "Begin download PP6334.pdf\n",
      "Finish downloadPP6334.pdf\n",
      "PP6426.pdf\n",
      "https://drive.google.com/uc?export=download&id=16DKxpdA6hOGrF9Gx6HwoyQgujguvbrFQ\n",
      "Begin download PP6426.pdf\n",
      "Finish downloadPP6426.pdf\n",
      "PP6435.pdf\n",
      "https://drive.google.com/uc?export=download&id=18lDHDs-dxIkvueGF4DGJqP-W7Mg5Pnvf\n",
      "Begin download PP6435.pdf\n",
      "Finish downloadPP6435.pdf\n",
      "PP6462.pdf\n",
      "https://drive.google.com/uc?export=download&id=1EAVqP91OXbdH_sCcImOhfirRn1OEuTRs\n",
      "Begin download PP6462.pdf\n",
      "Finish downloadPP6462.pdf\n",
      "PP6495.pdf\n",
      "https://drive.google.com/uc?export=download&id=1N1mIKBDLnmytd7O8iQyY0gsXWTGmdlJN\n",
      "Begin download PP6495.pdf\n",
      "Finish downloadPP6495.pdf\n",
      "PP6518.pdf\n",
      "https://drive.google.com/uc?export=download&id=1mP1oIgYmVp0KLkU8anZY-Ez-jOnEDxpL\n",
      "Begin download PP6518.pdf\n",
      "Finish downloadPP6518.pdf\n",
      "PP6539.pdf\n",
      "https://drive.google.com/uc?export=download&id=1dXz46hizkqGTNbryXa3QQKeucjpSpuMx\n",
      "Begin download PP6539.pdf\n",
      "Finish downloadPP6539.pdf\n",
      "PP6618.pdf\n",
      "https://drive.google.com/uc?export=download&id=1jDcKQynDiiNZBotWaNKF_qI7XID-v6xb\n",
      "Begin download PP6618.pdf\n",
      "Finish downloadPP6618.pdf\n",
      "PP6641.pdf\n",
      "https://drive.google.com/uc?export=download&id=1jIOXwGpTFgEZl-EFkC5hXwaTkLvcDE5P\n",
      "Begin download PP6641.pdf\n",
      "Finish downloadPP6641.pdf\n",
      "PP6686.pdf\n",
      "https://drive.google.com/uc?export=download&id=1r8P9V6aIy7WtGzjLgBZngsgqlx8YHwaE\n",
      "Begin download PP6686.pdf\n",
      "Finish downloadPP6686.pdf\n",
      "PP6715.pdf\n",
      "https://drive.google.com/uc?export=download&id=1lGDnV2M-Lgd8zgAivPsxpLZpsvMummG1\n",
      "Begin download PP6715.pdf\n",
      "Finish downloadPP6715.pdf\n",
      "PP6791.pdf\n",
      "https://drive.google.com/uc?export=download&id=1HPz3RXXpy4T7H81XeWh6y-v-chEflKst\n",
      "Begin download PP6791.pdf\n",
      "Finish downloadPP6791.pdf\n",
      "PP6825.pdf\n",
      "https://drive.google.com/uc?export=download&id=1fixfFYl-252tmenxloAi4hEhsGY6s1_9\n",
      "Begin download PP6825.pdf\n",
      "Finish downloadPP6825.pdf\n",
      "PP6899.pdf\n",
      "https://drive.google.com/uc?export=download&id=14rdmrrvVGUw-KmzGlJSSS7AgV9wTlX0u\n",
      "Begin download PP6899.pdf\n",
      "Finish downloadPP6899.pdf\n",
      "PP6945.pdf\n",
      "https://drive.google.com/uc?export=download&id=1GSfkL_oVbEp5Quxubxy0BAnE7BcveCN7\n",
      "Begin download PP6945.pdf\n",
      "Finish downloadPP6945.pdf\n",
      "PP6964.pdf\n",
      "https://drive.google.com/uc?export=download&id=11BCmBjqQeAu7xT7wrOAzOJcept50pX2n\n",
      "Begin download PP6964.pdf\n",
      "Finish downloadPP6964.pdf\n",
      "PP7054.pdf\n",
      "https://drive.google.com/uc?export=download&id=1QBs4CCX_SDNouqyYTCnyExxqPKQ4K1qy\n",
      "Begin download PP7054.pdf\n",
      "Finish downloadPP7054.pdf\n",
      "PP7078.pdf\n",
      "https://drive.google.com/uc?export=download&id=1Jy7UZvJWB0557fm5U3fKDnKk9wppLj1R\n",
      "Begin download PP7078.pdf\n",
      "Finish downloadPP7078.pdf\n",
      "PP7122.pdf\n",
      "https://drive.google.com/uc?export=download&id=17seFdOEt-wQeXignst6x2EHmSYp0W6ah\n",
      "Begin download PP7122.pdf\n",
      "Finish downloadPP7122.pdf\n",
      "PP7221.pdf\n",
      "https://drive.google.com/uc?export=download&id=14c-CWeabYIttJy1VwA0-o4QglMUoltQu\n",
      "Begin download PP7221.pdf\n",
      "Finish downloadPP7221.pdf\n",
      "PP7262.pdf\n",
      "https://drive.google.com/uc?export=download&id=1GKkY4ntyUuqPmv8ifbYXBJrDzZODQ1Mp\n",
      "Begin download PP7262.pdf\n",
      "Finish downloadPP7262.pdf\n",
      "PP7275.pdf\n",
      "https://drive.google.com/uc?export=download&id=1tbBvsq4RXcwCy0lMayZQCKR-puUwwAH5\n",
      "Begin download PP7275.pdf\n",
      "Finish downloadPP7275.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf = './Group067.txt'\n",
    "pdf_txt = open(pdf, 'r')\n",
    "for line in pdf_txt:\n",
    "    data = pdf_txt.readline()\n",
    "    patten = re.compile(\"(PP\\d{4}.pdf)\\s(https.*)\")\n",
    "    result = []\n",
    "    if patten.match(str(data)) is not None:\n",
    "        target = patten.findall(str(data))\n",
    "        result.append(target)\n",
    "    #print(result)\n",
    "    for lines in result:\n",
    "        if lines is not None:\n",
    "            lines = str(target).split(',')\n",
    "            url_name = lines[0].replace('[(', '').strip(\"''\")\n",
    "            print(url_name)\n",
    "            url = lines[1].rstrip(')]').strip(\"''\")[2:]\n",
    "            print(url)\n",
    "            print(\"Begin download \" + url_name)\n",
    "            r = requests.get(url)\n",
    "            with open(url_name, \"wb\") as pdf:\n",
    "                pdf.write(r.content)\n",
    "            print(\"Finish download\" + url_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP4300.pdf\n",
      "PP4300.pdf 12\n",
      "BudgetedOptimizationwithConcurrent\n",
      "Stochastic-DurationExperiments\n",
      "Authoredby:\n",
      "AlanFern\n",
      "JavadAzimi\n",
      "XiaoliZ.Fern\n",
      "Abstract\n",
      "Budgetedoptimizationinvolvesoptimizinganunknownfunctionthat\n",
      "iscostlytoevaluatebyrequestingalimitednumberoffunctionevaluations\n",
      "atintelligentlyselectedinputs.Typicalproblemformulationsassumethat\n",
      "experimentsareselectedoneatatimewithalimitedtotalnumberofex-\n",
      "periments,whichfailtocaptureimportantaspectsofmanyreal-world\n",
      "problems.Thispaperanovelproblemformulationwiththefol-\n",
      "lowingimportantextensions:1)allowingforconcurrentexperiments;2)\n",
      "allowingforstochasticexperimentdurations;and3)placingconstraints\n",
      "onboththetotalnumberofexperimentsandthetotalexperimentaltime.\n",
      "Wedevelopbothandonlinealgorithmsforselectingconcurrentex-\n",
      "perimentsinthisnewsettingandprovideexperimentalresultsonanum-\n",
      "berofoptimizationbenchmarks.Theresultsshowthatouralgorithms\n",
      "producehighlyeschedulescomparedtonaturalbaselines.\n",
      "1PaperBody\n",
      "Westudytheoptimizationofanunknownfunctionfbyrequestingnexperi-\n",
      "ments,eachspecifyinganinputxandproducinganoisyobservationoff(x).In\n",
      "practice,thefunctionfmightbetheperformanceofadeviceparameterizedby\n",
      "x.Weconsiderthesettingwhererunningexperimentsiscostly(e.g.interms\n",
      "oftime),whichrendersmethodsthatrelyonmanyfunctionevaluations,such\n",
      "asstochasticsearchorempiricalgradientmethods,impractical.Bayesianop-\n",
      "timization(BO)[8,4]addressesthisissuebyleveragingBayesianmodelingto\n",
      "maintainaposteriorovertheunknownfunctionbasedonpreviousexperiments.\n",
      "Theposterioristhenusedtointelligentlyselectnewexperimentsto\n",
      "exploringnewpartsoftheexperimentalspaceandexploitingpromisingparts.\n",
      "TraditionalBOfollowsasequentialapproachwhereonlyoneexperimentisse-\n",
      "lectedandrunatatime.However,itisoftendesirabletoselectmorethanone\n",
      "experimentatatimesothatmultipleexperimentscanberunsimultaneously\n",
      "1\n",
      "\n",
      "toleverageparallelfacilities.Recently,Azimietal.(2010)proposedabatch\n",
      "BOalgorithmthatselectsabatchofk?1experimentsatatime.Whilethis\n",
      "broadenstheapplicabilityofBO,itisstilllimitedtoselectinganumberof\n",
      "experimentsateachstep.Assuch,priorworkonBO,bothbatchandsequen-\n",
      "tial,completelyignorestheproblemofhowtoscheduleexperimentsunder\n",
      "experimentalbudgetandtimeconstraints.Furthermore,existingworkassumes\n",
      "thatthedurationsofexperimentsareidenticalanddeterministic,whereasin\n",
      "practicetheyareoftenstochastic.Consideroneofourmotivatingapplications\n",
      "ofoptimizingthepoweroutputofnano-enhancedMicrobialFuelCells(MFCs).\n",
      "MFCs[3]usemicro-organismstogenerateelectricity.Theirperformancede-\n",
      "pends1\n",
      "stronglyonthesurfacepropertiesoftheanode[10].Ourprobleminvolves\n",
      "optimizingnano-enhancedanodes,wherevarioustypesofnano-structures,e.g.\n",
      "carbonnano-wire,aregrowndirectlyontheanodesurface.Becausethereis\n",
      "littleunderstandingofhowtnano-enhancementsimpactpoweroutput,\n",
      "optimizinganodedesignislargelyguesswork.Ouroriginalgoalwastode-\n",
      "velopBOalgorithmsforaidingthisprocess.However,manyaspectsofthis\n",
      "domaincomplicatetheapplicationofBO.First,thereisabudgetonthe\n",
      "numberofexperimentsthatcanberunduetolimitedfundsandatime\n",
      "periodfortheproject.Second,wecanrunmultipleconcurrentexperiments,\n",
      "limitedbythenumberofexperimentalapparatus.Third,thetimerequiredto\n",
      "runeachexperimentisvariablebecauseeachexperimentrequirestheconstruc-\n",
      "tionofanano-structurewithspproperties.Nano-fabricationishighly\n",
      "unpredictableandtheamountoftimetosuccessfullyproduceastructureis\n",
      "quitevariable.ClearlypriorBOmodelsfailtocapturecriticalaspectsofthe\n",
      "experimentalprocessinthisdomain.Inthispaper,weconsiderthefollowing\n",
      "extensions.First,wehavelavailablelabs(whichmaycorrespondtoexperi-\n",
      "mentalstationsatonelocationortophysicallydistinctlaboratories),allowing\n",
      "uptolconcurrentexperiments.Second,experimentshavestochasticdurations,\n",
      "independentlyandidenticallydistributedaccordingtoaknowndensityfunction\n",
      "pd.Finally,weareconstrainedbyabudgetofntotalexperimentsandatime\n",
      "horizonhbywhichpointwemustThegoalistomaximizetheunknown\n",
      "functionfbyselectingexperimentsandwhentostartthemwhilesatisfyingthe\n",
      "constraints.Wepropose(Section4)andonline(Section5)scheduling\n",
      "approachesforthisproblem,whichaimtobalancetwocompetingfactors.First,\n",
      "aschedulershouldensurethatallnexperimentscompletewithinthehorizon\n",
      "h,whichencourageshighconcurrency.Second,wewishtoselectnewexper-\n",
      "imentsgivenasmanypreviouslycompletedexperimentsaspossibletomake\n",
      "moreintelligentexperimentselections,whichencourageslowconcurrency.We\n",
      "introduceanovelmeasureofthesecondfactor,cumulativepriorexperiments\n",
      "(CPE)(Section3),whichourapproachesaimtooptimize.Ourexperimental\n",
      "resultsindicatethattheseapproachestlyoutperformasetofbaselines\n",
      "acrossarangeofbenchmarkoptimizationproblems.\n",
      "2\n",
      "ProblemSetup\n",
      "LetX?<dbead-dimensionalcompactinputspace,whereeachdimensioni\n",
      "2\n",
      "\n",
      "isboundedin[ai,bi].AnelementofXiscalledanexperiment.Anunknown\n",
      "real-valuedfunctionf:X?<representstheexpectedvalueofthedependent\n",
      "variableafterrunninganexperiment.Forexample,f(x)mightbetheresultofa\n",
      "wetlabexperimentdescribedbyx.Conductinganexperimentxproducesanoisy\n",
      "outcomey=f(x)+,whereisarandomnoiseterm.BayesianOptimization\n",
      "(BO)aimstoanexperimentx?Xthatapproximatelymaximizesfby\n",
      "requestingalimitednumberofexperimentsandobservingtheiroutcomes.We\n",
      "extendtraditionalBOalgorithmsandstudytheexperimentschedulingproblem.\n",
      "Assumingaknowndensityfunctionpdfortheexperimentdurations,theinputs\n",
      "toourproblemincludethetotalnumberofavailablelabsl,thetotalnumberof\n",
      "experimentsn,andthetimehorizonhbywhichwemustish.Thegoalisto\n",
      "designapolicy?forselectingwhentostartexperimentsandwhichonestostart\n",
      "tooptimizef.Sp,theinputsto?arethesetofcompletedexperiments\n",
      "andtheiroutcomes,thesetofcurrentlyrunningexperimentswiththeirelapsed\n",
      "runningtime,thenumberoffreelabs,andtheremainingtimetillthehorizon.\n",
      "Giventhisinformation,?mustselectasetofexperiments(possiblyempty)\n",
      "tostartthatisnolargerthanthenumberoffreelabs.Anyrunofthepolicy\n",
      "endswheneithernexperimentsarecompletedorthetimehorizonisreached,\n",
      "resultinginasetXofnorfewercompletedexperiments.Theobjectiveisto\n",
      "obtainapolicywithsmallregret,whichistheexpectedrencebetweenthe\n",
      "optimalvalueoffandthevalueoffforthepredictedbestexperimentinX.In\n",
      "theory,theoptimalpolicycanbefoundbysolvingaPOMDPwithhiddenstate\n",
      "correspondingtotheunknownfunctionf.However,thisPOMDPisbeyond\n",
      "thereachofanyexistingsolvers.Thus,wefocusoningandcomparing\n",
      "severalprincipledpoliciesthatworkwellinpractice,butwithoutoptimality\n",
      "guarantees.Notethatthisproblemhasnotbeenstudiedintheliteraturetothe\n",
      "bestofourknowledge.2\n",
      "3\n",
      "OverviewofGeneralApproach\n",
      "Apolicyforourproblemmustmaketwotypesofdecisions:1)scheduling\n",
      "whentostartnewexperiments,and2)selectingthespexperimentsto\n",
      "start.Inthiswork,wefactortheproblembasedonthesedecisionsandfocus\n",
      "onapproachesforschedulingexperiments.Weassumeablackboxfunction\n",
      "SelectBatchforintelligentlyselectingthek?1experimentsbasedonbothcom-\n",
      "pletedandcurrentlyrunningexperiments.TheimplementationofSelectBatch\n",
      "isdescribedinSection6.Optimalschedulingtominimizeregretappearsto\n",
      "becomputationallyhardfornon-trivialinstancesofSelectBatch.Further,we\n",
      "desireschedulingapproachesthatdonotdependonthedetailsofSelectBatch,\n",
      "butworkwellforanyreasonableimplementation.Thus,ratherthandirectly\n",
      "optimizingregretforaspSelectBatch,weconsiderthefollowingsurrogate\n",
      "criteria.First,wewanttoallnexperimentswithinthehorizonhwith\n",
      "highprobability.Second,wewouldliketoselecteachexperimentbasedonas\n",
      "muchinformationaspossible,measuredbythenumberofpreviouslycompleted\n",
      "experiments.Thesetwogoalsareatodds,sincemaximizingthecompletion\n",
      "probabilityrequiresmaximizingconcurrencyoftheexperiments,whichmini-\n",
      "mizesthesecondcriterion.Ourandonlineschedulingapproachesprovide\n",
      "3\n",
      "\n",
      "twaysformanagingthisCosines\n",
      "0.32\n",
      "0.28\n",
      "0.08\n",
      "Regret\n",
      "0.09\n",
      "0.07\n",
      "0.26\n",
      "0.06\n",
      "0.24\n",
      "0.05\n",
      "0.22\n",
      "0.04\n",
      "0.2\n",
      "0.18\n",
      "Hydrogen\n",
      "0.1\n",
      "0.3\n",
      "Regret\n",
      "Toquantifythesecondcriterion,consideracompleteexecutionEofasched-\n",
      "uler.ForanyexperimenteinE,letpriorE(e)denotethenumberofexperi-\n",
      "mentsinEthatcompletedbeforestartinge.PWethecumulativeprior\n",
      "experiments(CPE)ofEas:e?EpriorE(e).Intuitively,aschedulerwithahigh\n",
      "expectedCPEisdesirable,sinceCPEmeasuresthetotalamountofinformation\n",
      "SelectBatchusestomakeitsdecisions.\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "CPE\n",
      "80\n",
      "100\n",
      "120\n",
      "0.03\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "CPE\n",
      "Figure1:ThecorrelationbetweenCPEandCPEagreeswithintuitionwhen\n",
      "consideringextremepolicies.regretfor30tschedulersontwoBOA\n",
      "poorschedulerthatstartsallnexperimentsatthesametimebenchmarks.\n",
      "(assumingenoughlabs)willhaveaminimumCPEofzero.Further,CPEis\n",
      "4\n",
      "\n",
      "maximizedbyaschedulerthatsequentiallyexecutesallexperiments(assuming\n",
      "enoughtime).However,inbetweentheseextremes,CPEfailstocapturecertain\n",
      "intuitiveproperties.Forexample,CPEincreaseslinearlyinthenumberof\n",
      "priorexperiments,whileonemightexpectdiminishingreturnsasthenumber\n",
      "ofpriorexperimentsbecomeslarge.Similarly,asthenumberofexperiments\n",
      "startedtogether(thebatchsize)increases,wemightalsoexpectdiminishing\n",
      "returnssinceSelectBatchmustchoosetheexperimentsbasedonthesameprior\n",
      "experiments.Unfortunately,quantifyingtheseintuitionsinageneralwayisstill\n",
      "anopenproblem.Despiteitspotentialshortcomings,wehavefoundCPEto\n",
      "bearobustmeasureinpractice.ToempiricallyexaminetheutilityofCPE,we\n",
      "conductedexperimentsonanumberofBObenchmarks.Foreachdomain,we\n",
      "used30manuallydesigneddiverseschedulers,somestartedmoreexperiments\n",
      "earlyonthanlater,andvice-versa,whileothersincludedrandomanduniform\n",
      "schedules.Wemeasuredtheaverageregretachievedforeachschedulergiven\n",
      "thesameinputsandtheexpectedCPEoftheexecutions.Figure1showsthe\n",
      "resultsfortwoofthedomains(otherresultsarehighlysimilar),whereeach\n",
      "pointcorrespondstotheaverageregretandCPEofaparticularscheduler.\n",
      "Weobserveaclearandnon-trivialcorrelationbetweenregretandCPE,which\n",
      "providesempiricalevidencethatCPEisausefulmeasuretooptimize.Further,\n",
      "aswewillseeinourexperiments,theperformanceofourmethodsisalsohighly\n",
      "correlatedwithCPE.\n",
      "4\n",
      "Scheduling\n",
      "Wenowconsiderschedules,whichassignstarttimestoallnexperi-\n",
      "mentsbeforetheexperimentalprocessbegins.Notethatwhiletheschedulesare\n",
      "theoverallBOpolicyhasonlinecharacteristics,sincetheexactexper-\n",
      "imentstorunareonlyspwhentheyneedtobestartedbySelectBatch,\n",
      "based3\n",
      "onthemostrecentinformation.Thisschedulingapproachisoften\n",
      "convenientinrealexperimentaldomainswhereitisusefultoplanoutastatic\n",
      "equipment/personnelscheduleforthedurationofaproject.Belowwe\n",
      "considerarestrictedclassofschedules,calledstagedschedules,forwhichwe\n",
      "presentasolutionthatoptimizesCPE.Next,wedescribeanapproachfora\n",
      "moregeneralclassofschedules.4.1\n",
      "StagedSchedules\n",
      "AstagedscheduleaconsecutivePsequenceofNPexperimentalstages,\n",
      "denotedbyasequenceoftuplesh(ni,di)iNi=1,where0<ni?l,idi?h,andi\n",
      "ni?n.StageibeginsbystartingupninewexperimentsselectedbySelectBatch\n",
      "usingthemostrecentinformation,andendsafteradurationofdi,uponwhich\n",
      "stagei+1starts.Insomeapplications,stagedschedulesarepreferableasthey\n",
      "allowprojectplanningtofocusonarelativelysmallnumberoftimepoints(the\n",
      "beginningofeachstage).Whileourapproachtriestoensurethatexperiments\n",
      "withintheirstage,experimentsareneverterminatedandhencemight\n",
      "runlongerthantheirspduration.If,becauseofthis,atthebeginning\n",
      "ofstageitherearenotnifreelabs,theexperimentswillwaittilllabsfreeup.\n",
      "WesaythatanexecutionEofastagedscheduleSissafeifeachexperimentis\n",
      "5\n",
      "\n",
      "completedwithinitsspdurationinS.WesaythatastagedscheduleS\n",
      "isp-safeifwithprobabilityatleastpanexecutionofSissafewhichprovides\n",
      "aprobabilisticguaranteethatallnexperimentscompletewithinthehorizonh.\n",
      "Further,itensureswithprobabilitypthatthemaximumnumberofconcurrent\n",
      "experimentswhenexecutingSismaxini(sinceexperimentsfromtwostageswill\n",
      "notoverlapwithprobabilityp).Assuch,weareinterestedinstaged\n",
      "schedulesthatarep-safeforauserspp,e.g.95%.Meanwhile,wewantto\n",
      "maximizeCPE.PNPi?1TheCPEofanysafeexecutionofS(slightlyabusing\n",
      "notation)is:CPE(S)=i=2nij=1nj.Typicalapplicationswilluserelative\n",
      "highvaluesofp,sinceotherwiseexperimentalresourceswouldbewasted,and\n",
      "thuswithhighprobabilityweexpecttheCPEofanexecutionofStoequal\n",
      "CPE(S).OurgoalisthustomaximizeCPE(S)whileensuringp-safeness.It\n",
      "turnsoutthatforanynumberofstagesN,theschedulesthatmaximize\n",
      "CPE(S)mustbeuniform.Astagedscheduleistobeuniformif?i,j,\n",
      "|ni?nj|?1,i.e.,thebatchsizesacrossstagesmaybyatmostasingle\n",
      "experiment.Proposition1.Foranynumberofexperimentsnandlabsl,letSN\n",
      "bethesetofcorrespondingNstageschedules,whereN?dn/le.ForanyS?SN\n",
      ",CPE(S)=maxS0?SNCPE(S0)ifandonlyifSisuniform.Itiseasyto\n",
      "verifythatforagivennandl,anNstageuniformscheduleachievesastrictly\n",
      "higherCPEthananyN?1stageschedule.Thisimpliesthatweshouldprefer\n",
      "uniformscheduleswithmaximumnumberofstagesallowedbythep-safeness\n",
      "restriction.Thismotivatesustosolvethefollowingproblem:Findap-safe\n",
      "uniformschedulewithmaximumnumberofstages.\n",
      "Algorithm1Algorithmforcomputingap-safeuniformschedulewithmax-\n",
      "imumnumberofstages.Input:numberofexperiments(n),numberoflabs(l),\n",
      "horizon(h),safetyprobability(p)Output:Ap-safeuniformschedulewithmax-\n",
      "imumnumberofstagesN=dn/le,S?nullloopS0?MaxProbUniform(N,n,\n",
      "l,h)ifS0isnotp-safethenreturnSendifS?S0,N?N+1endloop\n",
      "Ourapproach,outlinedinAlgorithm1,considersNstageschedulesinorder\n",
      "ofincreasingN,startingattheminimumpossiblenumberofstagesN=dn/le\n",
      "forrunningallexperiments.ForeachvalueofN,thecalltoMaxProbUniform\n",
      "computesauniformscheduleSwiththehighestprobabilityofasafeexecution,\n",
      "amongallNstageuniformschedules.Iftheresultingscheduleisp-safethenwe\n",
      "considerN+1stages.Otherwise,thereisnouniformNstageschedulethatis\n",
      "p-safeandwereturnauniformN?1stageschedule,whichwascomputedin\n",
      "thepreviousiteration.4\n",
      "ItremainstodescribetheMaxProbUniformfunction,whichcomputesa\n",
      "uniformNstagescheduleS=h(ni,di)iNi=1thatmaximizestheprobability\n",
      "ofasafeexecution.First,anyNstageuniformschedulemusthaveN0=(n\n",
      "modN)stageswithn0=bn/Nc+1experimentsandN?N0stageswithn0\n",
      "?1experiments.Furthermore,theprobabilityofasafeexecutionisinvariantto\n",
      "theorderingofthestages,sinceweassumei.i.d.distributionontheexperiment\n",
      "durations.TheMaxProbUniformproblemisnowreducedtocomputingthe\n",
      "durationsdiofSthatmaximizetheprobabilityofsafenessforeachgivenni\n",
      ".Forthiswewillassumethatthedistributionoftheexperimentdurationpd\n",
      "islog-concave,whichallowsustocharacterizethesolutionusingthefollowing\n",
      "6\n",
      "\n",
      "lemma.Lemma1.Foranydurationdistributionpdthatislog-concave,ifanN\n",
      "stagescheduleS=h(ni,di)iNi=100isp-safe,thenthereisap-safeNstage\n",
      "scheduleS0=h(ni,d0i)iNi=1suchthatifni=njthendi=dj.Thislemma\n",
      "suggeststhatanystageswithequalni?sshouldhaveequaldi?stomaximize\n",
      "theprobabilityofsafeexecution.Forauniformschedule,niiseithern0orn0\n",
      "?1.Thusweonlyneedtoconsiderscheduleswithtwodurations,d0forstages\n",
      "withni=n0andd00forstageswithni=n0?1.Sincealldurationsmust0?N\n",
      "00sumtoh,d0andd00aredeterministicallyrelatedby:d00=h?dN?N0.\n",
      "Basedonthis,foranyvalueofdtheprobabilityoftheuniformscheduleusing\n",
      "durationsd0andd00isasfollows,wherePdistheCDFofpd.\n",
      "Pd(d0)\n",
      "N0?n0\n",
      "Pd\n",
      "h?d0?N0N?N0\n",
      "(N?N0)?(n0?1)(1)\n",
      "WecomputeMaxProbUniformbymaximizingEquation1withrespectto\n",
      "d0andusingthecorrespondingdurationford00.Puttingeverythingtogether\n",
      "wegetthefollowingresult.Theorem1.Foranylog-concavepd,comput-\n",
      "ingMaxProbUniformbymaximizingEquation1overd0,ifap-safeuniform\n",
      "scheduleexists,Algorithm1returnsamaximum-stagep-safeuniformschedule.\n",
      "4.2IndependentLabSchedulesWenowconsideramoregeneralclassof\n",
      "schedulesandaheuristicalgorithmforcomputingthem.Thisclassallowsthe\n",
      "starttimesofderentlabstobedecoupled,desirableinsettingswherelabsare\n",
      "runbyindependentexperimenters.Further,ouronlineschedulingapproachis\n",
      "basedonrepeatedlycallinganscheduler,whichrequiresthey\n",
      "tomakeschedulesforlabsindrentstagesofexecution.Anindependentlab\n",
      "(IL)PscheduleSspanumberoflabsk<landforeachlabi,anumber\n",
      "ofiexperimentsmisuchthatimi=n.Further,foreachlabiasequenceof\n",
      "midurationsDi=hd1i,...,dmiiisgiven.TheexecutionofSruns\n",
      "eachlabindependently,byhavingeachlabstartupexperimentswheneverthey\n",
      "movetothenextstage.Stagejoflabiendsafteradurationofdji,orafter\n",
      "theexperimentwhenitrunslongerthandji(i.e.wedonotterminate\n",
      "experiments).EachexperimentisselectedaccordingtoSelectBatch,givenin-\n",
      "formationaboutallcompletedandrunningexperimentsacrossalllabs.We\n",
      "saythatanexecutionofanILscheduleissafeifallexperimentsishwithin\n",
      "theirspdurations,whichalsoyieldsanotionofp-safeness.Weareagain\n",
      "interestedincomputingp-safeschedulesthatmaximizestheCPE.Intuitively,\n",
      "CPEwillbemaximizediftheamountofconcurrencyduringanexecutionis\n",
      "minimized,suggestingtheuseofasfewlabsaspossible.Thismotivatesthe\n",
      "problemofap-safeILschedulethatusetheminimumnumberoflabs.\n",
      "Belowwedescribeourheuristicapproachtothisproblem.AlgorithmDescrip-\n",
      "tion.Startingwithk=1,wecomputeaklabsILschedulewiththegoalof\n",
      "maximizingtheprobabilityofsafeexecution.Ifthisprobabilityislessthan\n",
      "p,weincrementk,andotherwiseoutputthescheduleforklabs.Tocompute\n",
      "ascheduleforeachvalueofk,weallocatethenumberofexperimentsmi\n",
      "acrossklabsasuniformlyaspossible.Inparticular,(nmodk)labswillhave\n",
      "7\n",
      "\n",
      "bn/kc+1experimentsandk?(nmodk)labswillhavebn/kcexperiments.\n",
      "Thischoiceismotivatedbytheintuitionthatthebestwaytomaximizethe\n",
      "probabilityofasafeexecutionistodistributetheworkacrosslabsasuniformly\n",
      "aspossible.Givenmiforeachlab,weassignalldurationsoflabitobeh/mi\n",
      ",whichcanbeshowntobeoptimalforlog-concavepd.Inthisway,foreach\n",
      "valueofktheschedulewecomputehasjusttwopossiblevaluesofmiandlabs\n",
      "withthesamemihavethesamestagedurations.5\n",
      "5\n",
      "OnlineSchedulingApproaches\n",
      "Wenowconsideronlinescheduling,whichselectsthestarttimeofexper-\n",
      "imentsonline.Theyoftheonlineapproachesthepotentialto\n",
      "outperformschedulesbyadaptingtospstochasticoutcomesob-\n",
      "servedduringexperimentalruns.Belowwedescribetwobaselineonline\n",
      "approaches,followedbyourmainapproach,policyswitching,whichaimsto\n",
      "directlyoptimizeCPE.OnlineFastestCompletionPolicy(OnFCP).Thisbase-\n",
      "linepolicysimplytriestoallofthenexperimentsasquicklyaspossible.\n",
      "Assuch,itkeepsallllabsbusyaslongasthereareexperimentslefttorun.\n",
      "Spwheneveralab(orlabs)becomesfreethepolicyimmediatelyuses\n",
      "SelectBatchwiththelatestinformationtoselectnewexperimentstostartright\n",
      "away.ThispolicywillachievealowvalueofexpectedCPEsinceitmaximizes\n",
      "concurrency.OnlineMinimumEagerLabPolicy(OnMEL).Oneproblemwith\n",
      "OnFCPisthatitdoesnotattempttousethefulltimehorizon.TheOnMEL\n",
      "policysimplyrestrictsOnFCPtouseonlyklabs,wherekistheminimum\n",
      "numberoflabsrequiredtoguaranteewithprobabilityatleastpthatalln\n",
      "experimentscompletewithinthehorizon.Monte-Carlosimulationisusedto\n",
      "estimatepforeachk.PolicySwitching(PS).Ourpolicyswitchingapproach\n",
      "decidesthenumberofnewexperimentstostartateachdecisionepoch.Decision\n",
      "epochsareassumedtooccurevery?unitsoftime,where?isasmallconstant\n",
      "relativetotheexpectedexperimentdurations.Themotivationbehindpolicy\n",
      "switchingistoexploittheavailabilityofapolicygeneratorthatcanproduce\n",
      "multiplepoliciesatanydecisionepoch,whereatleastoneofthemisexpected\n",
      "tobegood.Givensuchagenerator,thegoalistoanew(switching)\n",
      "policythatperformsaswellorbetterthanthebestofthegeneratedpoliciesin\n",
      "anystate.Inourcase,theobjectiveistoimproveCPE,thoughotherobjectives\n",
      "canalsobeused.Thisismotivatedbypriorworkonpolicyswitching[6]overa\n",
      "policylibrary,andgeneralizethatworktohandlearbitrarypolicygener-\n",
      "atorsinsteadofstaticpolicylibraries.Belowwedescribethegeneralapproach\n",
      "andthenthesppolicygeneratorthatweuse.Lettdenotethenumberof\n",
      "remainingdecisionepochs(stages-to-go),whichisoriginallyequaltobh/?cand\n",
      "decrementedbyoneeachepoch.Weusestodenotetheexperimentalstateof\n",
      "theschedulingproblem,whichencodesthenumberofcompletedexperiments\n",
      "andongoingexperimentswiththeirelapsedrunningtime.Weassumeaccessto\n",
      "apolicygenerator?(s,t)whichreturnsasetofbaseschedulingpolicies(pos-\n",
      "siblynonstationary)giveninputssandt.Priorworkonpolicyswitching[6]\n",
      "correspondstothecasewhere?(s,t)returnsasetofpoliciesregardlessofs\n",
      "andt.Given?(s,t),??(s,t,?)denotestheresultingswitchingpolicybasedon\n",
      "8\n",
      "\n",
      "s,t,andthebasepolicy?selectedinthepreviousepoch.Thedecisionreturned\n",
      "by??iscomputedbyconductingNsimulationsofeachpolicyreturnedby\n",
      "?(s,t)alongwith?toestimatetheirCPEs.Thebasepolicywiththehighest\n",
      "estimatedCPEisthenselectedanditsdecisionisreturnedby??.Theneed\n",
      "tocomparetothepreviouspolicy?isduetotheuseofadynamicpolicygen-\n",
      "erator,ratherthanalibrary.Thebasepolicypassedintopolicyswitching\n",
      "forthedecisionepochcanbearbitrary.Despiteitssimplicity,wecanmake\n",
      "guaranteesaboutthequalityof??assumingaboundontheCPEestimation\n",
      "error.Inparticular,theCPEoftheswitchingpolicywillnotbemuchworse\n",
      "thanthebestofthepoliciesproducedbyourgeneratorgivenaccuratesimula-\n",
      "tions.WesaythataCPEestimatoris-accurateifitcanestimatetheCPECt?\n",
      "(s)ofanybasepolicy?foranysandtwithinanaccuracyboundof.Belowwe\n",
      "denotetheexpectedCPEof??fors,t,and?tobeCt??(s,?).Theorem2.\n",
      "Let?(s,t)beapolicygeneratorand??betheswitchingpolicycomputedwith\n",
      "-accurate0estimates.Foranystates,stages-to-got,andbasepolicy?,Ct??\n",
      "(s,?)?max?0??(s,t)?\n",
      "f\n",
      "?\n",
      "g\n",
      "Ct?(s)?2t.Weuseasimplepolicygenerator?(s,\n",
      "t)thatmakesmultiplecallstotheILschedulerdescribedearlier.The\n",
      "intuitionistonoticethattheproducedp-safeschedulesarefairlypessimisticin\n",
      "termsoftheexperimentruntimes.Inrealitymanyexperimentswillearly\n",
      "andwecanadaptivelyexploitsuchsituations.Sp,ratherthanfollow\n",
      "theschedulewemaychoosetousefewerlabsandhenceimprove\n",
      "CPE.Similarlyifexperimentsruntoolong,wewillincreasethenumberoflabs.\n",
      "6\n",
      "Table1:BenchmarkFunctions\n",
      "1?(u2+v2?0.3cos(3?u)?0.3cos(3?v))Rosenbrock(2)[1]10?100(y?\n",
      "x2)2?(1?x)2u=1.6x?0.5,dv=1.6y?0.52220P?i=14?iexp??j=1Aij\n",
      "(xj?Pij)iHartman(3,6)[7]Michalewicz(5)[9]?5i=1sin(xi).sini.x??1?4,\n",
      "A4?d,P4?dareconstants1Shekel(4)[7]?10?1?10,A4?10areconstantsi=1?\n",
      "+?4(x?A)2Cosines(2)[1]\n",
      "i\n",
      "j=1\n",
      "j\n",
      "ji\n",
      "We?(s,t)toreturnk+1policies,\n",
      "f\n",
      "?(s,t,0),...,?(s,t,k)\n",
      "g\n",
      ",where\n",
      "kisthenumberofexperimentsrunningins.Policy?(s,t,i)issothatit\n",
      "waitsforicurrentexperimentstoandthenusestheILscheduler\n",
      "toreturnaschedule.ThisamountstoaddingasmalllookaheadtotheIL\n",
      "schedulerwheretamountsofwaitingtimeareconsidered1.Notethat\n",
      "theofthesepoliciesdependsonsandtandhencecannotbeviewed\n",
      "asasetofstaticpoliciesasusedbytraditionalpolicyswitching.Inthe\n",
      "initialstates0,?(s0,h,0)correspondstotheILscheduleandhencethe\n",
      "abovetheoremguaranteesthatwewillnotperformmuchworsethanthe\n",
      "IL,withtheexpectationofperformingmuchbetter.Wheneverpolicyswitching\n",
      "selectsa?iwithi>0thennonewexperimentswillbestartedandwewait\n",
      "forthenextdecisionepoch.Fori=0,itwillapplytheILschedulerto\n",
      "returnap-safescheduletostartimmediately,whichmayrequirestartingnew\n",
      "9\n",
      "\n",
      "labstoensurehighprobabilityofcompletingnexperiments.\n",
      "6\n",
      "Experiments\n",
      "ImplementationofSelectBatch.Giventhesetofcompletedexperiments\n",
      "Oandon-goingexperimentsA,SelectBatchselectsknewexperiments.We\n",
      "implementSelectBatchbasedonarecentbatchBOalgorithm[2],whichgreedily\n",
      "selectskexperimentsconsideringonlyO.Wemodifythisgreedyalgorithmto\n",
      "alsoconsiderAbyforcingtheselectedbatchtoincludetheongoingexperiments\n",
      "pluskadditionalexperiments.SelectBatchmakesselectionsbasedonaposterior\n",
      "overtheunknownfunctionf.WeuseGaussianProcessPdwiththeRBF\n",
      "kernelandthekernelwidth=0.01i=1li,whereliistheinputspacelengthin\n",
      "dimensioni.BenchmarkFunctions.Weevaluateourschedulingpoliciesusing\n",
      "6well-knownsyntheticbenchmarkfunctions(showninTab.1withdimension\n",
      "insidetheparenthesis)andtworeal-worldbenchmarkfunctionsHydrogenand\n",
      "FuelCellover[0,1]2[2].TheHydrogendataisproducedbyastudyonbiosolar\n",
      "hydrogenproduction[5],wherethegoalwastomaximizehydrogenproduction\n",
      "ofaparticularbacteriabyoptimizingPHandNitrogenlevels.TheFuelCell\n",
      "datawascollectedinourmotivatingapplicationmentionedinSect.1.Inboth\n",
      "cases,thebenchmarkfunctionwascreatedbyregressionmodelstothe\n",
      "availabledata.Evaluation.Weconsiderap-safenessguaranteeofp=0.95and\n",
      "thenumberofavailablelabslis10.Forpd(x),weuseonesidedtruncated\n",
      "normaldistributionsuchthatx?(0,inf)with?=1,?2=0.1,andweset\n",
      "thetotalnumberofexperimentsn=20.Weconsiderthreetimehorizonsh\n",
      "of6,5,and4.Givenl,nandh,toevaluatepolicy?usingfunctionf(with\n",
      "asetofinitialobservedexperiments),weexecute?andgetasetXofnor\n",
      "fewercompletedexperiments.Wemeasuretheregretof?asthedierence\n",
      "betweentheoptimalvalueoff(knownforalleightfunctions)andthefvalueof\n",
      "thepredictedbestexperimentinX.Results.Table2showstheresultsofour\n",
      "proposedandonlineschedulers.Wealsoinclude,asareferencepoint,\n",
      "theresultoftheun-constrainedsequentialpolicy(i.e.,selectingoneexperiment\n",
      "atatime)usingSelectBatch,whichcanbeviewedasaneupperbound\n",
      "ontheoptimalperformanceofanyconstrainedschedulerbecauseitignoresthe\n",
      "timehorizon(h=?).Thevaluesinthetablecorrespondtotheregrets(smaller\n",
      "valuesarebetter)achievedbyeachpolicy,averagedacross100independentruns\n",
      "withthesameinitialexperiments(5for2-dand3-dfunctionsand20forthe\n",
      "rest)forallpoliciesineachrun.1Forsimplicityourpreviousdiscussionofthe\n",
      "ILschedulerdidnotconsiderstateswithongoingexperiments,whichwilloccur\n",
      "here.Tohandlethistheschedulerconsidersusingalreadyexecutinglabs\n",
      "takingintoaccounthowlongtheyhavebeenrunning.Ifmorelabsarerequired\n",
      "toensurep-safenessnewonesareadded.\n",
      "7\n",
      "Table2:Theproposedpoliciesresultsforthorizons.h=4Functionh\n",
      "=?OnFCPOfStagedOfILOnMELCosines.142.339.181.195.275.182.191\n",
      ".258FuelCell.160.240Hydro.025.115.069.070.123.008.013.010.009.013\n",
      "RosenHart(3).037.095.070.069.096.509.508.525Michal.465.545Shekel\n",
      ".427.660.630.648.688Hart(6).265.348.338.340.354CPE1905510010066\n",
      "10\n",
      "\n",
      "h=5PSOfStagedOfILOnMEL.205.181.194.274.206.167.190.239.059\n",
      ".071.069.086.008.009.008.011.067.055.064.081.502.500.510.521.623\n",
      ".635.645.682.347.334.330.33310010010091\n",
      "h=6PSOfStagedOfILOnMEL.150.167.147.270.185.154.163.230.042\n",
      ".036.035.064.008.007.009.010.045.045.050.070.494.477.460.502.540\n",
      ".530.564.576.297.304.266.301118133137120\n",
      "PS.156.153.025.009.038.480.510.262138\n",
      "Wenotethatthetwoalgorithms(OfStagesandOfIL)perform\n",
      "similarlyacrossallthreehorizonsettings.Thissuggeststhatthereislimited\n",
      "binthesescenariostousingthemoreILschedules,whichwere\n",
      "primarilyintroducedforuseintheonlineschedulingcontext.Comparingwith\n",
      "thetwoonlinebaselines(OnFCPandOnMEL),thealgorithmsperform\n",
      "tlybetter.Thismayseemsurprisingatbecauseonlinepolicies\n",
      "shouldmoreythanschedules.However,the\n",
      "schedulespurposefullywaitforexperimentstocompletebeforestartingupnew\n",
      "experiments,whichtendstoimprovetheCPEvalues.Toseethis,thelast\n",
      "rowofTable2givestheaverageCPEsofeachpolicy.BothOnFCPandOn-\n",
      "MELyieldtlylowerCPEscomparedtothealgorithms,which\n",
      "correlateswiththeircantlylargerregrets.Finally,policyswitchingcon-\n",
      "sistentlyoutperformsotherpolicies(excludingh=?)onthemediumhorizon\n",
      "settingandperformssimilarlyintheothersettings.Thismakessensesincethe\n",
      "addedyofPSisnotascriticalforlongandshorthorizons.Forshort\n",
      "horizons,thereislessopportunityforschedulingchoicesandforlongerhorizons\n",
      "theschedulingproblemiseasierandhencetheapproachesaremorecom-\n",
      "petitive.Inaddition,lookingatTable2,weseethatPSachievesatly\n",
      "higherCPEthanapproachesinthemediumhorizon,andissimilarto\n",
      "themintheotherhorizons,againcorrelatingwiththeregret.Furtherexamina-\n",
      "tionoftheschedulesproducedbyPSindicatesthatalthoughitbeginswiththe\n",
      "samenumberoflabsasOfIL,PSoftenselectsfewerlabsinlaterstepsifearly\n",
      "experimentsarecompletedsoonerthanexpected,whichleadstohigherCPE\n",
      "andconsequentlybetterperformance.Notethatthevariancesoftheproposed\n",
      "policiesareverysmallwhichareshowninthesupplementarymaterials.\n",
      "7\n",
      "SummaryandFutureWork\n",
      "Motivatedbyreal-worldapplicationsweintroducedanovelsettingforBayesian\n",
      "optimizationthatincorporatesabudgetonthetotaltimeandnumberofex-\n",
      "perimentsandallowsforconcurrent,stochastic-durationexperiments.Wecon-\n",
      "sideredandonlineapproachesforschedulingexperimentsinthissetting,\n",
      "relyingonablackboxfunctiontointelligentlyselectspeexperimentsat\n",
      "theirscheduledstarttimes.Theseapproachesaimedtooptimizeanovelob-\n",
      "jectivefunction,CumulativePriorExperiments(CPE),whichweempirically\n",
      "demonstratetostronglycorrelatewithperformanceontheoriginaloptimiza-\n",
      "tionproblem.Ourschedulingapproachestlyoutperformedsome\n",
      "naturalbaselinesandouronlineapproachofpolicyswitchingwasthebestover-\n",
      "allperformer.ForfurtherworkweplantoconsideralternativestoCPE,which,\n",
      "forexample,incorporatefactorssuchasdiminishingreturns.Wealsoplanto\n",
      "11\n",
      "\n",
      "studyfurtherextensionstotheexperimentalmodelforBOandalsoforactive\n",
      "learning.Forexample,takingintoaccountvaryingcostsanddurationdistri-\n",
      "butionsacrosslabsandexperiments.Ingeneral,webelievethatthereismuch\n",
      "opportunityformoretightlyintegratingschedulingandplanningalgorithms\n",
      "intoBOandactivelearningtomoreaccuratelymodelreal-worldconditions.\n",
      "AcknowledgmentsTheauthorsacknowledgethesupportoftheNSFunder\n",
      "grantsIIS-0905678.8\n",
      "2References\n",
      "[1]B.S.Anderson,A.Moore,andD.Cohn.Anonparametricapproachto\n",
      "noisyandcostlyoptimization.InICML,2000.[2]J.Azimi,A.Fern,and\n",
      "X.Fern.Batchbayesianoptimizationviasimulationmatching.InNIPS,\n",
      "2010.[3]D.BondandD.Lovley.Electricityproductionbygeobactersulfurre-\n",
      "ducensattachedtoelectrodes.ApplicationsofEnvironmentalMicrobiology,\n",
      "69:1548?1555,2003.[4]E.Brochu,M.Cora,andN.deFreitas.Atutorial\n",
      "onBayesianoptimizationofexpensivecostfunctions,withapplicationtoac-\n",
      "tiveusermodelingandhierarchicalreinforcementlearning.TechnicalReport\n",
      "TR-2009-23,DepartmentofComputerScience,UniversityofBritishColumbia,\n",
      "2009.[5]E.H.Burrows,W.-K.Wong,X.Fern,F.W.Chaplen,andR.L.Ely.\n",
      "Optimizationofphandnitrogenforenhancedhydrogenproductionbysyne-\n",
      "chocystissp.pcc6803viastatisticalandmachinelearningmethods.Biotech-\n",
      "nologyProgress,25:1009?1017,2009.[6]H.Chang,R.Givan,andE.Chong.\n",
      "Parallelrolloutforonlinesolutionofpartiallyobservablemarkovdecisionpro-\n",
      "cesses.DiscreteEventDynamicSystems,14:309?341,2004.[7]L.Dixonand\n",
      "G.Szeg.TheGlobalOptimizationProblem:AnIntroductionTowardGlobal\n",
      "Optimization.NorthHolland,Amsterdam,1978.[8]D.Jones.Ataxonomy\n",
      "ofglobaloptimizationmethodsbasedonresponsesurfaces.JournalofGlobal\n",
      "Optimization,pages345?383,2001.[9]Z.Michalewicz.Geneticalgorithms\n",
      "+datastructures=evolutionprograms(2nd,extendeded.).Springer-Verlag\n",
      "NewYork,Inc.,NewYork,NY,USA,1994.[10]D.ParkandJ.Zeikus.Im-\n",
      "provedfuelcellandelectrodedesignsforproducingelectricityfrommicrobial\n",
      "degradation.Biotechnol.Bioeng.,81(3):348?355,2003.\n",
      "9\n",
      "12\n",
      "\n",
      "PP6715.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP6715.pdf 14\n",
      "Learningspatiotemporalpiecewise-geodesic\n",
      "trajectoriesfromlongitudinalmanifold-valued\n",
      "data\n",
      "Authoredby:\n",
      "St?phanieALLASSONNIERE\n",
      "JulietteChevallier\n",
      "StephaneOudard\n",
      "Abstract\n",
      "Weintroduceahierarchicalmodelwhichallowstoestimateagroup-\n",
      "averagepiecewise-geodesictrajectoryintheRiemannianspaceofmea-\n",
      "surementsandindividualvariability.Thismodelfallsintothewell\n",
      "models.Thesubject-sptrajectoriesarethrough\n",
      "spatialandtemporaltransformationsofthegroup-averagepiecewise-geodesic\n",
      "path,componentbycomponent.Thuswecanapplyourmodeltoa\n",
      "widevarietyofsituations.Duetothenon-linearityofthemodel,we\n",
      "usetheStochasticApproximationExpectation-Maximizationalgorithm\n",
      "toestimatethemodelparameters.Experimentsonsyntheticdatavali-\n",
      "datethischoice.Themodelisthenappliedtothemetastaticrenalcan-\n",
      "cerchemotherapymonitoring:werunestimationsonRECISTscoresof\n",
      "treatedpatientsandestimatethetimetheyescapefromthetreatment.\n",
      "Experimentshighlighttheroleofthetparametersontheresponse\n",
      "totreatment.\n",
      "1PaperBody\n",
      "Duringthepastfewyears,thewaywetreatrenalmetastaticcancerwaspro-\n",
      "foundlychanged:anewclassofanti-angiogenictherapiestargetingthetumor\n",
      "vesselsinsteadofthetumorcellshasemergedanddrasticallyimprovedsurvival\n",
      "byafactorofthree(Escudieretal.,2016).Thesenewdrugs,however,donot\n",
      "curethecancer,andonlysucceedindelayingthetumorgrowth,requiringthe\n",
      "useofsuccessivetherapieswhichmustbecontinuedorinterruptedattheappro-\n",
      "priatemomentaccordingtothepatient?sresponse.Thenewmedicineprocess\n",
      "hasalsocreatedanewsciencchallenge:howtochoosethemoretdrug\n",
      "therapy.Thismeansthatonehastoproperlyunderstandhowthepatientreacts\n",
      "tothepossibletreatments.Actually,thereareseveralstrategiesandtakingthe\n",
      "rightdecisionisacontestedissue(Rothermundtetal.,2015,2017).Toachieve\n",
      "1\n",
      "\n",
      "thatgoal,physicianstookaninterestinmathematicalmodeling.Mathematics\n",
      "hasalreadydemonstrateditsandplayedaroleinthechangeofstop-\n",
      "criteriaforagiventreatment(Burottoetal.,2014).However,tothebestofour\n",
      "knowledge,thereonlyexistsonemodelwhichwasdesignedbymedicalpracti-\n",
      "tioners.Although,verybasicmathematically,itseemstoshowthatthispoint\n",
      "ofviewmayproduceinterestingresults.IntroducedbySteinetal.in2008,\n",
      "themodelperformsanon-linearregressionusingtheleastsquaresmethodto\n",
      "anincreasingor/anddecreasingexponentialcurve.Thismodelisstillused\n",
      "butlimitations.First,astheareindividual-by-individual\n",
      "independently,themodelcannotexplainaglobaldynamic.Then,thechoice\n",
      "ofexponentialgrowthavoidstheemergenceofplateauwhichareoften\n",
      "observedinpractice.Thisopensthewaytonewmodelswhichwouldexplain\n",
      "bothapopulationandeachindividualwithotherconstraintsontheshapeof\n",
      "theresponse.31stConferenceonNeuralInformationProcessingSystems(NIPS\n",
      "2017),LongBeach,CA,USA.\n",
      "Learningmodelsofdiseaseprogressionfromsuchdatabasesraisesgreat\n",
      "methodologicalchallenges.Weproposehereaverygenericmodelwhichcan\n",
      "beadaptedtoalargenumberofsituations.Foragivenpopulation,ourmodel\n",
      "amountstoestimatinganaveragetrajectoryinthesetofmeasurementsand\n",
      "individualvariability.Thenwecancontinuoussubject-sptrajecto-\n",
      "riesinviewofthepopulationprogression.Trajectoriesneedtoberegistered\n",
      "inspaceandtime,toallowanatomicalvariability(asttumorsizes),\n",
      "tpacesofprogressionandsensitivitytotreatments.Theframework\n",
      "ofmodelsiswellsuitedtodealwiththishierarchicalproblem.\n",
      "modelsforlongitudinalmeasurementswereintroducedinthesem-\n",
      "inalpaperofLairdandWare(1982)andhavebeenwidelydevelopedsince\n",
      "then.TherecentgenericapproachofSchirattietal.(2015)toalignpatients\n",
      "isevenmoresuitable.First,anatomicaldataarenaturallymodeledaspoints\n",
      "onRiemannianmanifoldswhiletheusualmodelsarefor\n",
      "Euclideandata.Secondly,themodelwasbuiltwiththeaimofgrantingindivid-\n",
      "ualtemporalandspatialvariabilitythroughindividualvariationsofacommon\n",
      "time-linegrantandparallelshiftingoftheaveragetrajectory.However,Schi-\n",
      "rattietal.(2015)havemadeastronghypothesistobuildtheirmodelasthey\n",
      "considerthatthemeanevolutionisageodesic.Thiswouldmeaninourtargeted\n",
      "situationthatthecancerwouldeithergoonevolvingorisalwayssensitiveto\n",
      "thetreatment.Unfortunately,theanti-angiogenictreatmentsmaybet,\n",
      "tortemporarilyt,leadingtoare-progressionofthemetastasis.\n",
      "Therefore,wewanttorelaxthisassumptiononthemodel.Inthispaper,we\n",
      "proposeagenericstatisticalframeworkfortheandestimationofspa-\n",
      "tiotemporalpiecewise-geodesictrajectoriesfromlongitudinalmanifold-valued\n",
      "data.Riemanniangeometryallowsustoderiveamethodthatmakesfewas-\n",
      "sumptionsaboutthedataandapplicationsdealtwith.Weintroduceour\n",
      "modelinitsmostgenericformulationandthenmakeitexplicitforRECIST\n",
      "(Therasseetal.,2000)scoremonitoring,i.e.forone-dimensionmanifolds.Ex-\n",
      "perimentalresultsonthosescoresaregiveninsection4.2.Theintroductionof\n",
      "amoregeneralmodelisadeliberatechoiceasweareexpectingtoapplyour\n",
      "2\n",
      "\n",
      "modeltothecorrespondingmedicalimages.Becauseofthenon-linearityofthe\n",
      "model,wehavetouseastochasticversionoftheExpectation-Maximization\n",
      "algorithm(Dempsteretal.,1977),namelytheMCMC-SAEMalgorithm,for\n",
      "whichtheoreticalresultsregardingtheconvergencehavebeenprovedinDelyon\n",
      "etal.(1999)andAllassonni?reetal.(2010)andnumericalhasbeen\n",
      "demonstratedforthesetypesofmodels(Schirattietal.(2015),MONOLIX?\n",
      "MOd?lesNOnLIn?aires?emiXtes).\n",
      "2\n",
      "modelforpiecewise-geodesicallydistributeddata\n",
      "Weconsideralongitudinaldatasetobtainedbyrepeatingmeasurementsof\n",
      "n?N?individuals,whereeachindividuali?J1,nKisobservedki?N?times,\n",
      "atthetimepointsti=(ti,j)16j6kiandwhereyiP=(yi,j)16j6kidenotesthe\n",
      "sequenceofobservationsforthisindividual.Wealsondenotek=i=1kithe\n",
      "totalnumbersofobservations.Weassumethateachobservationyi,jisapoint\n",
      "onad-dimensionalgeodesicallycompleteRiemannianmanifold(M,g),sothat\n",
      "y=(yi,j)16i6n,16j6ki?Mk.WegeneralizetheideaofSchirattietal.(2015)\n",
      "andbuildourmodelinahierarchicalway.Weseeourdatapointsassamples\n",
      "alongtrajectoriesandsupposethateachindividualtrajectoryderivesfroma\n",
      "group-averagescenariothroughspatiotemporaltransformations.Keytoour\n",
      "modelisthatthegroup-averagetrajectoryinnolongerassumedtobegeodesic\n",
      "butpiecewise-geodesic.2.1\n",
      "Genericpiecewise-geodesiccurvesmodel\n",
      "Letm?N?andtR=??<t1R<...<tm?1<+?asubdivisionofR,called\n",
      "thebreakingRuptimessequence.LetM0ad-dimensionalgeodesicallycomplete\n",
      "manifoldand??0`16`6mafamilyofgeodesicsonM0.Tocompletely\n",
      "ouraveragetrajectory,weintroducemisometries>0:M0?M0`:=>0(M0).\n",
      "Thismnewgeodesics?onthecorrespondingspaceM0`?bysetting\n",
      "down?0`=>0???0`.Theisometricnatureofthemapping>0ensuresthat\n",
      "themanifoldsM0`remainRiemannianandthatthecurves?0`remaingeodesic.\n",
      "Inparticular,each?0`remainsparametrizable(Gallotetal.,2004).We\n",
      "theaveragetrajectoryby?t?R,\n",
      "?0(t)=\n",
      "?01(t)1]??,t1R](t)\n",
      "+\n",
      "m?1X\n",
      "?0`(t)1]t`?1,t`](t)+?0m(t)1]tm?1,+?[(t).R\n",
      "`=2\n",
      "2\n",
      "R\n",
      "R\n",
      "Inthisframework,M0maybeunderstoodasamanifold-templateofthe\n",
      "geodesiccomponentsofthecurve?0.Becauseofthepiecewisenatureofour\n",
      "average-trajectory?0,constraintshavetobeformulatedoneachintervalofthe\n",
      "subdivisiontR.Followingtheformulationofthelocalexistenceanduniqueness\n",
      "theorem(Gallotetal.,2004),constraintsongeodesicsaregenerallyformulated\n",
      "byforcingavalueandatangentvectoratagiventime-point.However,suchan\n",
      "3\n",
      "\n",
      "approachcannotensurethecurve?0tobeatleastcontinuous.Thatiswhywe\n",
      "re-formulatetheseconstraintsinourmodelasboundarym+1conditions.Leta\n",
      "sequenceA?=(A?0,...,A?m)?(M0),aninitialtimet0?Randa\n",
      "time11t1?R.Weimposethatforall`?J1,m?1K,??0(t0)=A?0,??0`(t`R\n",
      ")=A>,??0`+1(t`R)=A>and??0m(t1)=A?m.Notably,the2mconstraints\n",
      "arestepbystep.Inonedimension(cfsection2.2),thegeodesicscould\n",
      "bewrittenexplicitlyandsuchconstraintsdonotcomplicatethemodelsomuch.\n",
      "Inhigherdimension,wehavetouseshootingormatchingmethodstoenforce\n",
      "thisconstraint.Inpractice,thechoiceoftheisometries>0andthegeodesics??0`\n",
      "havetobedonewiththeaimtobe\"asregularaspossible\"(atleastcontinuous\n",
      "assaidabove)attherupturepointst`R.Inonedimensionforinstance,we\n",
      "buildtrajectoriesthatarecontinuous,nottiablebutwithaverysimilar\n",
      "slopeoneachsideofthebreaking-points.Wewanttheindividualtrajectoriesto\n",
      "representawidevarietyofbehaviorsandtoderivefromthegroupaveragepath\n",
      "byspatiotemporaltransformations.Todothat,weforeachcomponent`\n",
      "ofthepiecewise-geodesiccurve?0acoupleoftransformations(>i,?i`).These\n",
      "transformations,namelytheorphiccomponentdeformationsandthe\n",
      "timecomponentreparametrizations,characterizerespectivelythespatialand\n",
      "thetemporalvariabilityofpropagationamongthepopulation.Thus,individual\n",
      "trajectoriesmaywriteintheformof?t?R,\n",
      "?i(t)=?i1(t)1]??,t1R,i](t)+\n",
      "m?1X\n",
      "?i`(t)1]t`?1,t`R,i\n",
      "R,i]\n",
      "(t)+?im(t)1]tm?1,+?[(t)(?)R,i\n",
      "`=2\n",
      "wherethefunctions?i`areobtainedfrom?0`throughtheapplicationsofthe\n",
      "twotransformations>iand?i`describedbelow.Notethat,inparticular,each\n",
      "individualpossesseshisownsequence\n",
      "ofrupturetimestR,i=t`R,i16`<m.Moreover,werequirethefewestcon-\n",
      "straintspossibleintheconstruction:atleastcontinuityandcontroloftheslopes\n",
      "atthesebreaking-uppoints.Forcompactness,wewillnowabusivelydenotet0R\n",
      "fort0andtmRfort1.Toallowtpacesintheprogressionandt\n",
      "breaking-uptimesforeachindividual,weintroducesometemporaltransforma-\n",
      "tions?i`,calledtime-warp,thatareforthesubject`?1`i?J1,nKand\n",
      "forthegeodesiccomponent`?J1,mKby?i`(t)=?i`(t?t`?1R??i)+tR.\n",
      "The`parameters?icorrespondtothetime-shiftbetweenthemeanandthein-\n",
      "dividualprogressiononsetandthe?i`aretheaccelerationfactorsthatdescribe\n",
      "thepaceofindividuals,beingfasterorslowerthantheaverage.Toensuregood\n",
      "adjunctionattherupturepoints,wedemandtheindividualbreaking-up`?1\n",
      "timest`R,iandthetime-warpstosatisfy?i`(t`R,i)=t`Rand?i`(t`?1R,i)=\n",
      "tR.HencethesubdivisiontR,iisconstrainedbythetimereparametrizations,\n",
      "whicharealsoconstrained.Onlytheaccelerationfactors?i`andthetime\n",
      "shift?i1arefree:forall`?J1,mK,theconstraintsrewritestepbystepas`\n",
      "t`R,i=t`?1R+?i+\n",
      "t`R?t`?1R>i\n",
      "4\n",
      "\n",
      "`?1`?1and?i`=tR,i?tR.\n",
      "Concerningthespacevariability,weintroducemdeformations\n",
      ">iwhichenablethetcomponentsoftheindividualtrajectoriestovary\n",
      "moreirrespectivelyofeachother.Wejustenforcetheadjunctiontobeatleast\n",
      "continuousandthereforethe>ihavetosatisfy>i??0`(t`R)\n",
      "=>+1??0`+1(t`R).Notethatthemappings>idonotneedtobeisometric\n",
      "anymore,asitheindividualtrajectoriesarenolongerrequiredtobegeodesic.\n",
      "Finally,foralli?J1,nKand`?J1,mK,weset?i`=>i??0`??i`and\n",
      "?iasin(?).Theobservationsyi=(yi,j)areassumedtobedistributedalong\n",
      "thecurve?iandperturbedbyanadditiveGaussiannoise?i?N(0,?2Iki):\n",
      "?(i,j)?J1,nK?J1,kiK,1\n",
      "yi,j=?i(ti,j)+?i,j\n",
      "where?i,j?N(0,?2).\n",
      "ByA`=>0(A>)foreach`wecanapplytheconstraintson?0`\n",
      "insteadof??0`.\n",
      "3\n",
      "Thechoiceoftheisometries>0andthe>iwillinducea\n",
      "largepanelofpiecewisegeodesicmodels.Forexample,ifm=1,?0=Idandif\n",
      "?1idenotestheapplicationthatmapsthecurve?0ontoitsparallelcurvefora\n",
      "givennon-zerotangentvectorwi,wefeaturethemodelproposedbySchiratti\n",
      "etal.(2015).Inthefollowingparagraphweproposeanotherspmodel\n",
      "whichcanbeusedforchemotherapymonitoringforinstance(seesection4.2).\n",
      "2.2\n",
      "Piecewise-logisticcurvemodel\n",
      "Wefocusinthefollowingonthecaseofpiecewise-logisticmodel,which\n",
      "presentsarealinterestregardingtoourtargetapplication(cfsection4.2).We\n",
      "assumethatm=2andd=1andwesetM0=]0,1[equippedwiththe\n",
      "logisticmetric.Giventhreerealnumbers?0init,?0escapandwesetescap\n",
      "escapescap1init2down?0:x7??0??0x+?0and?0:x7??0\n",
      "??0x+?0escap.Thus,wecanmapescapescapM0ontotheintervals]?0\n",
      ",?0init[and]?0,[respectively:if??0referstothesigmoidfunction,\n",
      "?10???0willbealogisticcurve,growingfrom?0escapto?0init.Inthis\n",
      "way,thereisessentiallyasinglebreaking-uptimeandwewilldenoteittR\n",
      "atthepopulationlevelandtiRattheindividualone.Moreover,duetoour\n",
      "targetapplications,weforcethelogistictobedecreasingandthesecond\n",
      "oneincreasing(thisconditionmayberelaxed).Logisticsareonopen\n",
      "intervals,withasymptoticconstraints.Wewanttoformulateourconstraints\n",
      "onsometime-points,asexplainedinthepreviousparagraph,weset\n",
      "apositivethreshold?closetozeroanddemandthelogistics?01and?02to\n",
      "be?-nearfromtheircorrespondingasymptotes.Moreprecisely,weimposethe\n",
      "averagetrajectory?0tobeoftheform?0=?011]??,tR]+?021]tR,+?[where\n",
      "(escap?01:R?]?0escap,?0init[?02:R?]?0escap,[?0+2?6?0init\n",
      "?0init+?0escape(at+b)?n+?0escape?(ct+d)?0escap+2?6t?7\n",
      "(at+b)?(ct+d)1+e1+eanda,b,canddaresomepositivenumbersgivenby\n",
      "thefollowingconstraintst7?\n",
      "?01(t0)=?0init??,\n",
      "5\n",
      "\n",
      "?01(tR)=?02(tR)=?0escap+?\n",
      "and\n",
      "?02(t1)=??.\n",
      "Inourcontext,theinitialtimeoftheprocessisknown:itisthebeginningof\n",
      "thetreatment.So,weassumethattheaverageinitialtimet0isequaltozero.\n",
      "Especiallyt0isnolongeravariable.111Moreover,foreachindividuali?J1,\n",
      "nK,thetime-warps\n",
      "write?i(t)=?i(t?t0??i)+t0and1??1i?1i\n",
      "?i2(t)=?i2(t?tR??i2)+tRwhere?i2=?i1+\n",
      "(tR?t0).Fromnowon,wenote?ifor?i1.\n",
      "RECISTscore(dimentionless)\n",
      "Inthesamewayasthetime-warp,theorphisms?1iand?2iare\n",
      "chosentoallowtamplitudesandrupturevalues:foreachsubjecti?\n",
      "J1,nK,giventhetwoscalingfactorsri1andri2andthespace-shift?i,we\n",
      ">i(x)=ri`(x??0(tR))+?0(tR)+?i,`?\n",
      "f\n",
      "1,2\n",
      "g\n",
      ".Otherchoicesare\n",
      "conceivablebutinthecontextofourtargetapplications,thisoneisappropriate.\n",
      "Mathematically,anyregularandinjectivefunctionon]?0escap,?0init\n",
      "[(respectively]?0escap,?n[)issuited.\n",
      "?i\n",
      "?0?1?2?3?4?5?6?7\n",
      "400\n",
      "200\n",
      "?0init??\n",
      "ri1\n",
      "t0t1tR\n",
      "0\n",
      "?\n",
      "0\n",
      "ri2\n",
      "?0\n",
      "??\n",
      "1,0002,000Times(indays)\n",
      "?i\n",
      "?i\n",
      "escap+?0\n",
      "t0\n",
      "tiR\n",
      "ti1tR\n",
      "t1\n",
      "(b)Fromaveragetoindividualtrajectory.\n",
      "(a)Diversityofindividualtrajectories.\n",
      "Figure1:Modeldescription.Figure1arepresentsatypicalaveragetrajec-\n",
      "toryandseveralindividualones,fortvectorsPi.Therupturetimesare\n",
      "representedbydiamondsandthetimesbystars.Figure1billus-\n",
      "tratesthenon-standardconstraintsfor?0andthetransitionfromtheaverage\n",
      "trajectorytoanindividualone:thetrajectory?iissubjecttoatemporaland\n",
      "6\n",
      "\n",
      "aspacialwarp.Inother\"words\",?i=?1i??01??i11]??,tiR]+?2i??02?\n",
      "?i21]tiR,+?[.4\n",
      "Tosumup,eachindividualtrajectory?idependsontheaveragecurve?0\n",
      "throughe\n",
      "zpop=?0init,?0escap,,tR,t1andrandomzi=?i1,?i2,?i\n",
      ",ri1,ri2,?i.Thisleadstoanon-linearmodel.Moreprecisely,\n",
      "forall(i,j)?J1,nK?J1,kiK,\n",
      "yi,j=ri1?i1(ti,j)??0(tR)+?0(tR)+?i1]??,tiR](ti,j)\n",
      "+ri2?i2(ti,j)??0(tR)+?0(tR)+?i1]tiR,+?[(ti,j)+?i,j0where?i1\n",
      "=?1i??01,?i2=?2i??02andtiR=t0+?i1+tR??t.Figure1providesan\n",
      "illustrationofthe1imodel.Oneachsutheboldblackcurverepresents\n",
      "theaveragetrajectory?0andthecolourcurvesseveralindividualtrajectories.\n",
      "Theaccelerationandthescalingparametershavetobepositiveandequal\n",
      "tooneonaveragewhilethe`timeandspaceshiftsareofanysignsandmust\n",
      "bezeroonaverage.Forthesereasons,weset?i`=e?i\n",
      "`andri`=e?ifor`?\n",
      "f\n",
      "1,2\n",
      "g\n",
      "leadingtoPi=t?i1?i2?i?1i?2i?i.We\n",
      "assumethatPi?N(0,?)where??SpR,p=6.Thisassumptionis\n",
      "importantinviewoftheapplications.Usually,therandomarestudied\n",
      "independently.Here,weareinterestedincorrelationsbetweenthetwophases\n",
      "ofpatient?sresponsetotreatment(seesection4.2).\n",
      "3\n",
      "ParametersestimationwiththeMCMC-SAEMalgorithm\n",
      "Inthissection,weexplainhowtouseastochasticversionoftheEMalgo-\n",
      "rithmtoproducemaximumaposterioriestimatesoftheparameters.3.1\n",
      "Statisticalanalysisofthepiecewise-logisticcurvesmodel\n",
      "Wewanttoestimate(zpop,?,?).ThetheoreticalconvergenceoftheEM\n",
      "algorithm,andafortiorioftheSAEMalgorithm(Delyonetal.,1999),isproved\n",
      "onlyifthemodelbelongstothecurvedexponentialfamily.Moreover,fornu-\n",
      "mericalperformancesthisframeworkisimportant.Withoutfurtherhypothesis,\n",
      "thepiecewise-logisticmodeldoesnotsatisfythisconstraint.Weproceedasin\n",
      "KuhnandLavielle(2005):weassumethatzpopistherealizationofindependent\n",
      "Gaussianrandomvariableswithsmallvariancesandestimatethemeansof\n",
      "thosevariables.So,theparametersweescapinitwanttoestimatearefrom\n",
      "nowon?=?0,?0,?0,tR,t1,?,?.Theandrandomz=(zpop\n",
      ",zi)16i6nareconsideredaslatentvariables.Ourmodelwriteinahierarchical\n",
      "wayas?kinO?O\n",
      "???y|z,??N?i(ti,j),?2??i=1j=1\n",
      "n?O??escap22init,?2)?N(t,?2)?N(t,?2)?z|??N\n",
      "(?N(0,?),?)?N(?,?)?N(??R1initescapR1000?i=1\n",
      "where?init,?escap,,?Rand?1arehyperparametersofthemodel.\n",
      "Theproductmeasures?meanthatthecorrespondingentriesareconsideredto\n",
      "beindependentinourmodel.Ofcourse,itisnotthecasefortheobservations\n",
      "whichareobtainedbyrepeatingmeasurementsforseveralindividualsbutthis\n",
      "assumptionleadsustoamorecomputationallytractablealgorithm.Inthis\n",
      "context,theEMalgorithmisveryttocomputethemaximumlikelihood\n",
      "estimateof?.Duetothenon-linearityofourmodel,astochasticversionofthe\n",
      "7\n",
      "\n",
      "EMalgorithmisadopted,namelytheStochasticApproximationExpectation-\n",
      "Maximization(SAEM)algorithm.Astheconditionaldistributionq(z|y,?)is\n",
      "unknown,theExpectationstepisreplacedusingaMonte-CarloMarkovChain\n",
      "(MCMC)samplingalgorithm,leadingtoconsidertheMCMC-SAEMalgorithm\n",
      "introducedinKuhnandLavielle(2005)andAllassonni?reetal.(2010).It\n",
      "alternatesbetweenasimulationstep,astochasticapproximationstepanda\n",
      "maximizationstepuntilconvergence.Thesimulationstepisachievedusinga\n",
      "symmetricrandomwalkHasting-MetropoliswithinGibbssampler(Robertand\n",
      "Casella,1999).Seethesupplementarymaterialfordetailsaboutalgorithmics.\n",
      "Toensuretheexistenceofthemaximumaposteriori(theorem1),weusea\n",
      "\"partial\"Bayesianformalism,i.e.weassumethefollowingprior(?,?)?W?1\n",
      "(V,m?)?W?1(v,m?)whereV?SpR,v,m?,m??R5\n",
      "andW?1(V,m?)denotestheinverseWishartdistributionwithscale\n",
      "matrixVanddegreesoffreedomm?.InorderfortheinverseWishartto\n",
      "benon-degenerate,thedegreesm?andm?mustsatisfym?>2pandm?>\n",
      "2.Inpractice,weyetusedegeneratepriorsbutwithcorrectposteriors.Tobe\n",
      "consistentwiththeone-dimensioninverseWishartdistribution,wethe\n",
      "densityfunctionofdistributionofhigherdimensionasp\n",
      "!m?\n",
      "|V|11?1\n",
      "fW?1(V,m?)(?)=exp?trV?pp2?pm2?22|?|where?pisthe\n",
      "multivariategammafunction.Themaximizationstepisstraightforwardgiven\n",
      "thetstatisticsofourexponentialmodel:weupdatetheparametersby\n",
      "takingabarycenterbetweenthecorrespondingientstatisticandtheprior.\n",
      "Seethesupplementarymaterialforexplicitequations.3.2\n",
      "ExistenceoftheMaximumaPosteriori\n",
      "Thenexttheoremensuresusthatthemodeliswell-posedandthatthe\n",
      "maximumwearelookingforthroughtheMCMC-SAEMalgorithmexists.Let\n",
      "?thespaceofadmissibleparameters:\n",
      "n\n",
      "o\n",
      "?=?0init,?0escap,,tR,t1,?,??R5?SpR?R+?positive-\n",
      ".Theorem1(ExistenceoftheMAP).Giventhepiecewise-logisticmodel\n",
      "andthechoiceofprobabilitydistributionsfortheparametersandlatentvari-\n",
      "ablesofthemodel,foranydataset(ti,j,yi,j)i?J1,nK,j?J1,kiK,thereexist\n",
      "?bMAP?argmaxq(?|y).???\n",
      "Adetailedproofispostponedtothesupplementarymaterial.\n",
      "4\n",
      "Experimentalresults\n",
      "Thepiecewise-logisticmodelhasbeendesignedforchemotherapymoni-\n",
      "toring.Moresp,wehavemetradiologistsoftheH?pitalEurop?en\n",
      "Georges-Pompidou(HEGP?GeorgesPompidouEuropeanHospital)todesign\n",
      "ourmodel.Inpractice,patientsfromthemetastatickidneycancerand\n",
      "takeadrugeachday.Regularly,theycometotheHEGPtocheckthetumor\n",
      "evolution.Theresponsetoagiventreatmenthasgenerallytwodistinctphases:\n",
      "tumor?ssizereduces;then,thetumorgrowsagain.Apracticalquestionis\n",
      "8\n",
      "\n",
      "toquantifythecorrelationbetweenbothphasesandtodetermineasaccurately\n",
      "aspossibletheindividualrupturetimestiRwhicharerelatedtoanescapeof\n",
      "thepatient?sresponsetotreatment.4.1\n",
      "Syntheticdata\n",
      "Inordertovalidateourmodelandnumericalscheme,werunexperi-\n",
      "mentsonsyntheticdata.Wewellunderstoodthatthecovariancematrix?gives\n",
      "alotofinformationonthehealthstatusofapatient:paceandamplitudeoftu-\n",
      "morprogression,individualrupturetimes...Therefore,wehavetopayspecial\n",
      "attentiontotheestimationof?inthisparagraph.Animportantpointwasto\n",
      "allowalotofntindividualbehaviors.Inoursyntheticexample,Figure\n",
      "1aillustratesthisvariability.Fromasingleaveragetrajectory(?0inboldplain\n",
      "line),wecangenerateindividualswhoarecuredattheend(dot-dashedlines:\n",
      "?3and?4),somewhoseresponsetothetreatmentisbad(dashedlines:?5and\n",
      "?6),somewhoonlyescape(nopositiveresponsetothetreatments?dotted\n",
      "lines:?7).Likewise,wecangenerate\"patients\"withonlypositiveresponsesor\n",
      "noresponseatall.Thecaseofindividual4isinterestinginpractice:thetumor\n",
      "stillgrowsbutsoslowlythatthegrowthisnegligible,atleastintheshort-run.\n",
      "Figure2illustratesthequalitativeperformanceoftheestimation.Weareno-\n",
      "tablyabletounderstandvariousbehaviorsandsubjectswhicharefarfrom\n",
      "theaveragepath,suchastheorangeandthegreencurves.Werepresentonly\n",
      "eindividualsbut200subjectshavebeenusedtoperformtheestimation.To\n",
      "measuretheofthesamplesizeonourmodel/algorithm,wegenerate\n",
      "syntheticdatasetsofvarioussizeandperformtheestimation50timesforeach\n",
      "dataset.Meansandstandarddeviations6\n",
      "RECISTscore(dimentionless)\n",
      "RECISTscore(dimentionless)\n",
      "200\n",
      "100\n",
      "0\n",
      "200\n",
      "100\n",
      "00\n",
      "500\n",
      "1,000Times(indays)\n",
      "0\n",
      "1,500\n",
      "500\n",
      "1,000Times(indays)\n",
      "1,500\n",
      "(b)After600iterations.\n",
      "(a)Initialisation.\n",
      "Figure2:Initialisationand\"results\".Onboththeestimatedtra-\n",
      "jectoriesareinplainlinesandthetargetcurvesindashedlines.The(noisy)\n",
      "observationsarerepresentedbycrosses.Theaveragepathisinboldblackline,\n",
      "theindividualsincolor.Figure2a:Populationparameterszpopandlatent\n",
      "9\n",
      "\n",
      "variableszpopareinitializedattheempiricalmeanoftheobservations;indi-\n",
      "vidualtrajectoriesareinitializedontheaveragetrajectory(P=0,?=0.1Ip\n",
      ",?=1).Figure2b:After600iterations,sometimeless,theestimatedcurves\n",
      "verywelltheobservations.Asthealgorithmisstochastic,estimatedcurves\n",
      "?andelytheindividuals?stillwavearoundthetargetcurves.Table1:\n",
      "Mean(standarddeviation)ofrelativeerror(expressedasapercentage)forthe\n",
      "populationparameterszpopandtheresidualstandarddeviation?for50runs\n",
      "accordingtothesamplesizen.Samplesizen\n",
      "?0init\n",
      "?0escap\n",
      "\n",
      "tR\n",
      "t1\n",
      "?\n",
      "50100150\n",
      "1.63(1.46)2.42(1.50)2.14(1.17)\n",
      "9.45(5.40)9.07(5.19)11.40(5.72)\n",
      "6.23(2.25)7.82(2.43)5.82(2.55)\n",
      "11.58(1.64)13.62(1.31)9.24(1.63)\n",
      "4.41(0.75)5.27(0.60)3.42(0.71)\n",
      "25.24(12.84)10.35(3.96)2.83(2.31)\n",
      "oftherelativeerrorsfortherealparameters,namely?0init,?0escap,,\n",
      "tR,t1and?,arecompiledinTable1.Tocomparethingswhicharecomparable,\n",
      "wehavegeneratedadatasetofsize200andshortenedthemtothedesiredsize.\n",
      "Moreover,toputthealgorithmonamorerealisticsituation,thesynthetic\n",
      "individualtimesarenon-periodicallyspaced,individualsizesvarybetween12\n",
      "and18andtheobservedvaluesarenoisy(?=3).Weremarkthatouralgorithm\n",
      "isstableandthatthebiggerthesamplesize,thebetterwelearntheresidual\n",
      "standarddeviation?.TheparameterstRand?0escaparequitetolearn\n",
      "astheyoccuronthesectionofthetrajectory.However,theerrorwemade\n",
      "isnotcripplingasthemostimportantforcliniciansisthedynamicalongboth\n",
      "phases.Asthealgorithmenablestoestimateboththemeantrajectoryandthe\n",
      "individualdynamic,itsucceedsinestimatingtheinter-individualvariability.\n",
      "Thisendsinagoodestimateofthecovariancematrix?(seere4).4.2\n",
      "Chemotherapymonitoring:RECISTscoreoftreatedpatients\n",
      "WenowrunourestimationalgorithmonrealdatafromHEGP.TheRECIST\n",
      "(ResponseEvaluationCriteriaInSolidTumors)score(Therasseetal.,2000)\n",
      "measuresthetumoralgrowthandisakeyindicatorofthepatientsurvival.\n",
      "Wehaveperformedtheestimationoveradroveof176patientsoftheHEGP.\n",
      "Thereisanaverageof7visitspersubjects(min:3,max:22),withanaverage\n",
      "durationof90daysbetweenconsecutivevisits.Wehaverunthealgorithm\n",
      "severaltimes,withdierentproposallawsforthesampler(aSymmetricRandom\n",
      "WalkHasting-MetropoliswithinGibbsone)andtpriors.Wepresent\n",
      "herearunwithalowresidualstandardvariationinrespecttotheamplitudeof\n",
      "thetrajectoriesandcomplexityofthedataset:?=14.50versusmax(?0init,\n",
      ")??0escap=452.4.Figure3aillustratestheperformanceofthemodelon\n",
      "10\n",
      "\n",
      "theeightpatients.Althoughwecannotexplainallthepathsofprogression,\n",
      "thealgorithmsucceedsinvarioustypesofcurves:fromtheyellowcurve\n",
      "?3whichisratherandonlyescapetothered?7whichisspiky.FromFigure\n",
      "3b,itseemsthattherupturetimesoccurearlyintheprogressioninaverage.\n",
      "Nevertheless,thisresultistobeconsideredwithsomereserve:therupture\n",
      "timegenerallyoccursonastablephaseofthediseaseandtheestimationmay\n",
      "be7\n",
      "RECISTscore(dimentionless)\n",
      "400?0?1?2?3?4?5?6?7?8\n",
      "200\n",
      "00\n",
      "100\n",
      "200300Times(indays)\n",
      "400\n",
      "40\n",
      "20\n",
      "0\n",
      "500\n",
      "0\n",
      "1,0002,0003,0004,000Individualrupturetimes(indays)\n",
      "5,000\n",
      "(b)IndividualrupturetimestiR.\n",
      "(a)After600iterations.\n",
      "IndividualrupturetimestiR(indays)\n",
      "Highscore?\n",
      "10\n",
      "4,000\n",
      "Fastresponse?\n",
      "?Lowstep\n",
      "Highstep?\n",
      "ster?2p?\n",
      "facto\n",
      "de\n",
      "plitu\n",
      "5\n",
      "Low\n",
      "0\n",
      "0\n",
      "step\n",
      "?1001stamplitudefactor?1\n",
      "gh\n",
      "?Slowresponse\n",
      "?5\n",
      "45\n",
      "Hi\n",
      "?2021staccelerationfactor?1\n",
      "11\n",
      "\n",
      "0\n",
      "2ndam\n",
      "0\n",
      "2,000\n",
      "?\n",
      "?5\n",
      "?10?4\n",
      "Spaceshift?\n",
      "0\n",
      "?Lowscore\n",
      "500\n",
      "?2ndFastaccprelogerreatssionSlfaowctpror?2ogress?\n",
      "Lastonset??Earlyonset\n",
      "Timeshift?\n",
      "Figure3:RECISTscore.WekeepconventionsofthepreviousFigure\n",
      "3aistheresultofa600iterationsrun.Werepresenthereonlythe8patients\n",
      "amongthe176.Figure3bisthehistogramoftherupturetimestiRforthisrun.\n",
      "Inblackboldline,theestimatedaveragerupturetimetRisagoodestimateof\n",
      "theaverageoftheindividualrupturetimesalthoughthereexistsalargerange\n",
      "ofescape.\n",
      "(b)Thespacewarp.\n",
      "(a)Thetimewarp.\n",
      "Figure4:Individualrandom.Figure4a:log-accelerationfactors?i1\n",
      "and?i2againsttimesshifts?i.Figure4b:log-amplitudefactors?1iand?2i\n",
      "againstspaceshifts?i.Inboththecolorcorrespondstotheindividual\n",
      "rupturetimetiR.TheseestimationsholdforthesamerunasFigure3.In\n",
      "Figure4,weplottheindividualestimatesoftherandom(obtainedfrom\n",
      "thelastiteration)incomparisontotheindividualrupturetimes.Eventhough\n",
      "theparameterswhichleadthespacewarp,i.e.?1i,?2iand?iarecorrelated,\n",
      "thecorrelationwiththerupturetimeisnotclear.Inotherwords,thevolume\n",
      "ofthetumorsseemstonotberelevanttoevaluatetheescapeofapatient.On\n",
      "thecontrary,whichislogical,thetimewarpstronglyimpactstherupturetime.\n",
      "4.3\n",
      "Discussionandperspective\n",
      "Weproposehereagenericspatiotemporalmodeltoanalyzelongitudinal\n",
      "manifold-valuedmeasurements.ContrarytoSchirattietal.(2015),theaverage\n",
      "trajectoryisnotassumedtobegeodesicanymore.Thisallowsustoapplyour\n",
      "modeltomorecomplexsituations:inchemotherapymonitoringforexample,\n",
      "wherethepatientsaretreatedandtumorsmayrespond,stabilizeorprogress\n",
      "duringthetreatment,withtconductsforeachphase.Attheageof\n",
      "personalizedmedicine,togivephysiciansdecisionsupportsystemsisreallyim-\n",
      "portant.Thereforelearningcorrelationsbetweenbothphasesiscrucial.This\n",
      "hasbeentakenintoaccounthere.Forpurposeofworkingwithmorecompli-\n",
      "cateddata,medicalimagesforinstance,wehavepresentedourmodelina\n",
      "verygenericversion.ThenwemadeitexplicitforRECISTscoresmonitoring\n",
      "andperformedexperimentsondatafromtheHEGP.However,wehavestudied\n",
      "12\n",
      "\n",
      "thatdatasetasifallpatientsbehavesimilarly,whichisnottrueinpractice.\n",
      "Webelievethatapossibleameliorationofourmodelistoputitintoamix-\n",
      "turemodel.Lastly,theSAEMalgorithmisreallysensitivetoinitialconditions.\n",
      "Thisphenomenonisemphasizedbythenon-independencebetweentheindivid-\n",
      "ualvariables:actually,theaveragetrajectory?0isnotexactlythetrajectoryof\n",
      "theaverageparameters.Fortunately,themorethesamplesizenincreases,the\n",
      "more?0drawsclosertothetrajectoryoftheaverageparameters.8\n",
      "AcknowledgmentsCetravailbd?unntpublicInvestisse-\n",
      "mentd?avenir,referenceANR-11-LABX0056-LMH.Thisworkwassupported\n",
      "byapublicgrantaspartoftheInvestissementd?avenir,projectreferenceANR-\n",
      "11-LABX-0056-LMH.Travailr?alis?danslecadred?unprojetparla\n",
      "FondationdelaRechercheM?dicale,\"DBI20131228564\".Workperformedasa\n",
      "partofaprojectfundedbytheFondationofMedicalResearch,grantnumber\n",
      "\"DBI20131228564\".\n",
      "2References\n",
      "St?phanieAllassonni?re,EstelleKuhn,andAlainTrouv?.Constructionof\n",
      "bayesiandeformablemodelsviaastochasticapproximationalgorithm:Acon-\n",
      "vergencestudy.Bernoulli,16(3):641?678,082010.MauricioBurotto,Julia\n",
      "Wilkerson,WilfredStein,MotzerRobert,SusanBates,andTitoFojo.Con-\n",
      "tinuingacancertreatmentdespitetumorgrowthmaybevaluable:Sunitinib\n",
      "inrenalcellcarcinomaasexample.PLoSONE,9(5):e96316,2014.Bernard\n",
      "Delyon,MarcLavielle,andEricMoulines.Convergenceofastochasticapprox-\n",
      "imationversionoftheemalgorithm.TheAnnalsofStatistics,27(1):94?128,\n",
      "1999.ArthurDempster,NanM.Laird,andDonaldB.Rubin.Maximumlike-\n",
      "lihoodfromincompletedataviatheemalgorithm.JournaloftheRoyalSta-\n",
      "tisticalSociety.SeriesB(Methodological),39(1):1?38,1977.BernardEscudier,\n",
      "CamilloPorta,M?lanieSchmidinger,NathalieRioux-Leclercq,AxelBex,Vin-\n",
      "centS.Khoo,ViktorGruenvald,andAlanHorwich.Renalcellcarcinoma:\n",
      "Esmoclinicalpracticeguidelinesfordiagnosis,treatmentandfollow-up.An-\n",
      "nalsofOncology,27(suppl5):v58?v68,2016.SylvestreGallot,DominiqueHulin,\n",
      "andJacquesLafontaine.RiemannianGeometry.Universitext.SpringerVerlag\n",
      "BerlinHeidelberg,3edition,2004.EstelleKuhnandMarcLavielle.Maxi-\n",
      "mumlikelihoodestimationinnonlinearmixedmodels.Computational\n",
      "Statistics&DataAnalysis,49(4):1020?1038,2005.NanM.LairdandJamesH.\n",
      "Ware.modelsforlongitudinaldata.Biometrics,38(4):963?974,\n",
      "1982.ChristianP.RobertandGeorgeCasella.MonteCarloStatisticalMeth-\n",
      "ods.SpringerTextsinStatistics.SpringerVerlagNewYork,1999.Christian\n",
      "Rothermundt,AlexandraBailey,LindaCerbone,TimEisen,BernardEscud-\n",
      "ier,SilkeGillessen,ViktorGr?nwald,JamesLarkin,DavidMcDermott,Jan\n",
      "Oldenburg,CamilloPorta,BrianRini,ManuelaSchmidinger,CoraN.Stern-\n",
      "berg,andPaulM.Putora.Algorithmsinthetreatmentofmetastatic\n",
      "clearcellrenalcellcarcinoma?analysisusingdiagnosticnodes.TheOncol-\n",
      "ogist,20(9):1028?1035,2015.ChristianRothermundt,JoschaVonRappard,\n",
      "13\n",
      "\n",
      "TimEisen,BernardEscudier,ViktorGr?nwald,JamesLarkin,DavidMcDer-\n",
      "mott,JanOldenburg,CamilloPorta,BrianRini,ManuelaSchmidinger,Cora\n",
      "N.Sternberg,andPaulM.Putora.Second-linetreatmentformetastaticclear\n",
      "cellrenalcellcancer:experts?consensusalgorithms.WorldJournalofUrology,\n",
      "35(4):641?648,2017.Jean-BaptisteSchiratti,St?phanieAllassonniere,Olivier\n",
      "Colliot,andStanleyDurrleman.Learningspatiotemporaltrajectoriesfrom\n",
      "manifold-valuedlongitudinaldata.InNeuralInformationProcessingSystems,\n",
      "number28inAdvancesinNeuralInformationProcessingSystems.2015.Wil-\n",
      "fredD.Stein,WilliamDougFigg,WilliamDahut,AryehD.Stein,MosheB.\n",
      "Hoshen,DougPrice,SusanE.Bates,andTitoFojo.Tumorgrowthratesde-\n",
      "rivedfromdataforpatientsinaclinicaltrialcorrelatestronglywithpatient\n",
      "survival:Anovelstrategyforevaluationofclinicaltrialdata.TheOncolo-\n",
      "gist,13(10):1046?1054,2008.PatrickTherasse,SusanG.Arbuck,Elizabeth\n",
      "A.Eisenhauer,JantienWanders,RichardS.Kaplan,LarryRubinstein,Jaap\n",
      "Verweij,MartineVanGlabbeke,AllanT.vanOosterom,MichaeleC.Christian,\n",
      "andSteveG.Gwyther.Newguidelinestoevaluatetheresponsetotreatment\n",
      "insolidtumors.JournaloftheNationalCancerInstitute,92(3):205?216,2000.\n",
      "9\n",
      "14\n",
      "\n",
      "PP5630.pdf\n",
      "PP5630.pdf 13\n",
      "MultivariateRegressionwithCalibration\n",
      "Authoredby:\n",
      "HanLiu\n",
      "TuoZhao\n",
      "LieWang\n",
      "Abstract\n",
      "Weproposeanewmethodnamedcalibratedmultivariateregression\n",
      "(CMR)forhighdimensionalmultivariateregressionmodels.Com-\n",
      "paredtoexistingmethods,CMRcalibratestheregularizationforeachre-\n",
      "gressiontaskwithrespecttoitsnoiselevelsothatitissimultaneouslytun-\n",
      "inginsensitiveandachievesanimprovedperformance.Com-\n",
      "putationally,wedevelopantsmoothedproximalgradientalgo-\n",
      "rithmwhichhasaworst-caseiterationcomplexity$O(1/epsilon)$,where\n",
      "$epsilon$isapre-spnumericalaccuracy.Theoretically,weprove\n",
      "thatCMRachievestheoptimalrateofconvergenceinparameterestima-\n",
      "tion.WeillustratetheusefulnessofCMRbythoroughnumericalsimu-\n",
      "lationsandshowthatCMRconsistentlyoutperformsotherhighdimen-\n",
      "sionalmultivariateregressionmethods.WealsoapplyCMRonabrain\n",
      "activitypredictionproblemandthatCMRisascompetitiveasthe\n",
      "handcraftedmodelcreatedbyhumanexperts.\n",
      "1PaperBody\n",
      "GivenadesignmatrixX2Rn?dandaresponsematrixY2Rn?m,weconsider\n",
      "amultivariatelinearmodelY=XB0+Z,whereB02Rd?misanunknown\n",
      "regressioncotmatrixandZ2Rn?misanoisematrix[1].ForamatrixA\n",
      "=[Ajk]2Rd?m,wedenoteAj?=(Aj1,...,Ajm)2RmandA?k=(A1k,...,\n",
      "Adk)T2Rdtobeitsjthrowandkthcolumnrespectively.Weassumethatall\n",
      "Zi??sareindependentlysampledfromanm-dimensionalGaussiandistribution\n",
      "withmean0andcovariancematrix?2Rm?m.\n",
      "Wecanrepresentthemultivariatelinearmodelasanensembleofunivariate\n",
      "linearregressionmodels:Y?k=XB0?k+Z?k,k=1,...,m.Thenweget\n",
      "amulti-tasklearningproblem[3,2,26].Multi-tasklearningexploitsshared\n",
      "commonstructureacrosstaskstoobtainimprovedestimationperformance.In\n",
      "thepastdecade,tprogresshasbeenmadetowardsdesigningavariety\n",
      "ofmodelingassumptionsformultivariateregression.Apopularassumptionis\n",
      "thatalltheregressiontasksshareacommonsparsitypattern,i.e.,manyB0j??s\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arezerovectors.Suchajointsparsityassumptionisanaturalextensionofthat\n",
      "forunivariatelinearregressions.SimilartotheL1-regularizationusedinLasso\n",
      "[23],wecanadoptgroupregularizationtoobtainagoodestimatorofB0[25,24,\n",
      "19,13].Besidestheaforementionedapproaches,thereareothermethodsthat\n",
      "aimtoexploitthecovariancestructureofthenoisematrixZ[7,22].For?The\n",
      "authorsarelistedinalphabeticalorder.Thisworkispartiallysupportedby\n",
      "thegrantsNSFIIS1408910,NSFIIS1332109,NSFGrantDMS-1005539,NIH\n",
      "R01MH102339,NIHR01GM083084,andNIHR01HG06841.?TuoZhaoisalso\n",
      "withDepartmentofOperationsResearchandFinancialEngineering\n",
      "atPrincetonUniversity.\n",
      "1\n",
      "instance,[22]assumethatallZi??sfollowamultivariateGaussiandistribu-\n",
      "tionwithasparseinversecovariancematrix?=?1.Theyproposeaniterative\n",
      "algorithmtoestimatesparseB0and?bymaximizingthepenalizedGaussian\n",
      "log-likelihood.Suchaniterativeprocedureiseinmanyapplications,\n",
      "butthetheoreticalanalysisisduetoitsnonconvexformulation.Inthis\n",
      "paper,weassumeanuncorrelatedstructureforthenoisematrixZ,i.e.,?=2\n",
      "2diag(12,22,...,m1,m).Underthissetting,wecantlysolve\n",
      "theresultingestimationproblemwithaconvexprogramasfollowsb=argmin\n",
      "p1||YXB||2+||B||1,p,B(1.1)FnBqP2where>0isatuning\n",
      "parameter,and||A||F=j,kAjkistheFrobeniusnormofamaPdqPm\n",
      "2trixA.Popularchoicesofpincludep=2andp=1:||B||1,2=j=1\n",
      "k=1BjkandPd||B||1,1=j=1max1?k?m|Bjk|.Computationally,\n",
      "theoptimizationproblemin(1.1)canbetlysolvedbysomeorder\n",
      "algorithms[11,12,4].\n",
      "Theproblemwiththeuncorrelatednoisestructureisamenabletostatistical\n",
      "analysis.Undersuitableconditionsonthenoiseanddesignmatrices,letmax\n",
      "=maxkk,ifwechoose=pbin(1.1)achievestheopti2c?maxlogd+m1\n",
      "1/p,forsomec>1,thentheestimatorBmalratesofconvergence1[13],i.e.,\n",
      "thereexistssomeuniversalconstantCsuchthatwithhighprobability,wehave\n",
      "!rr1bslogdsm12/p0p||BB||F?C?max+,nmnmwheres\n",
      "isthenumberofrowswithnon-zeroentriesinB0.However,theestimatorin\n",
      "(1.1)hastwodrawbacks:(1)Allthetasksareregularizedbythesametuning\n",
      "parameter,eventhoughttasksmayhavetk?s.Thusmore\n",
      "estimationbiasisintroducedtothetaskswithsmallerk?stocompensatethe\n",
      "taskswithlargerk?s.Inanotherword,thesetasksarenotcalibrated.(2)The\n",
      "tuningparameterselectioninvolvestheunknownparametermax.Thisrequires\n",
      "tuningtheregularizationparameteroverawiderangeofpotentialvaluestoget\n",
      "agoodperformance.\n",
      "Toovercometheabovetwodrawbacks,weformulateanewconvexpro-\n",
      "gramnamedcalibratedmultivariateregression(CMR).TheCMRestimatoris\n",
      "tobethesolutionofthefollowingconvexprogram:b=argmin||Y\n",
      "XB||2,1+||B||1,p,B(1.2)PqP\n",
      "B\n",
      "where||A||2,1=kisthenonsmoothL2,1normofamatrixA=\n",
      "[Ajk]2Rd?m.Thisisamultivariateextensionofthesquare-rootLasso[5].\n",
      "2\n",
      "\n",
      "Similartothesquare-rootLasso,thetuningparameterselectionofCMRdoes\n",
      "notinvolvemax.Moreover,theL2,1lossfunctioncanbeviewedasaspecial\n",
      "exampleoftheweightedleastsquareloss,whichcalibrateseachregressiontask\n",
      "(Seemoredetailsin?2).ThusCMRadaptstotk?sandachievesbetter\n",
      "performancethantheordinarymultivariateregressionestimator\n",
      "(OMR)in(1.1).2jAjk\n",
      "Sinceboththelossandpenaltyfunctionsin(1.2)arenonsmooth,CMR\n",
      "iscomputationallymorechallengingthanOMR.TotlysolveCMR,we\n",
      "proposeasmoothedproximalgradient(SPG)algorithmwithaniterationcom-\n",
      "plexityO(1/?),where?isthepre-spaccuracyoftheobjectivevalue[18,\n",
      "4].Theoretically,weprovideientconditionsunderwhichCMRachieves\n",
      "theoptimalratesofconvergenceinparameterestimation.Numericalexperi-\n",
      "mentsonbothsyntheticandrealdatashowthatCMRuniversallyoutperforms\n",
      "existingmultivariateregressionmethods.Forabrainactivitypredictiontask,\n",
      "predictionbasedonthefeaturesselectedbyCMRtlyoutperformsthat\n",
      "basedonthefeaturesselectedbyOMR,andisevencompetitivewiththatbased\n",
      "onthehandcraftedfeaturesselectedbyhumanexperts.Notations:Givenavec-\n",
      "torv=(v1,...,vd)T2Rd,for1?p?1,wetheLp-vector?P\n",
      "?1/pdpnormofvas||v||p=if1?p<1and||v||p=max1?j?d\n",
      "|vj|ifp=1.j=1|vj|1\n",
      "Therateofconvergenceisoptimalwhenp=2,i.e.,theregularizationfunc-\n",
      "tionis||B||1,p\n",
      "2\n",
      "GiventwomatricesA=[Ajk]andC=[Cjk]2Rd?m,wetheinner\n",
      "productofAPdPmandCashA,Ci=j=1k=1AjkCjk=tr(ATC),where\n",
      "tr(A)isthetraceofamatrixA.WeuseA?k=(A1k,...,Adk)TandAj?\n",
      "=(Aj1,...,Ajm)todenotethekthcolumnandjthrowofA.LetSbe\n",
      "somesubspaceofRd?m,weuseAStodenotetheprojectionofAontoS:2\n",
      "AS=argminpC2S||CA||F.Moreover,wedenetheFrobeniusand\n",
      "spectralnormsofAas||A||F=hA,Aiand||A||2=1(A),1(A)\n",
      "thelargestsingularvalueofA.Inaddition,Pismwethematrixblock\n",
      "normsas||A||2,1=k=1||A?k||2,||A||2,1=max1?k?m\n",
      "||A?k||2,Pd||A||1,p=j=1||Aj?||p,and||A||1,q\n",
      "=max1?j?d||Aj?||q,where1?p?1and1?q?1.Itiseasytoverify\n",
      "that||A||2,1isthedualnormof||A||2,1.Let1/1=0,thenif1/p\n",
      "+1/q=1,||A||1,qand||A||1,parealsodualnormsofeachother.\n",
      "2\n",
      "Method\n",
      "Wesolvethemultivariateregressionproblembythefollowingconvexpro-\n",
      "gram,b=argmin||YXB||2,1+||B||1,p.B\n",
      "(2.1)\n",
      "B\n",
      "Theonlybetween(2.1)and(1.1)isthatwereplacetheL2-loss\n",
      "functionbythenonsmoothL2,1-lossfunction.TheL2,1-lossfunctioncan\n",
      "beviewedasaspecialexampleoftheweightedsquarelossfunction.More\n",
      "sp,weconsiderthefollowingoptimizationproblem,mX1b=argmin\n",
      "3\n",
      "\n",
      "p||Y?kXB?k||22+||B||1,p,B(2.2)knBk=1\n",
      "whereknisaweightassignedtocalibratethekthregressiontask.Without\n",
      "priorknowledgeonk?s,weusethefollowingreplacementofk?s,1ek=p\n",
      "||Y?kXB?k||2,k=1,...,m.(2.3)nByplugging(2.3)intotheobjective\n",
      "functionin(2.2),weget(2.1).Inanotherword,CMRcalibratesttasks\n",
      "bysolvingapenalizedweightedleastsquareprogramwithweightsin\n",
      "(2.3).1p\n",
      "Theoptimizationproblemin(2.1)canbesolvedbythealternatingdirection\n",
      "methodofmultipliers(ADMM)withaglobalconvergenceguarantee[20].How-\n",
      "ever,ADMMdoesnottakefulladvantageoftheproblemstructurein(2.1).For\n",
      "example,eventhoughtheL2,1normisnonsmooth,itistiableonly\n",
      "whenataskachievesexactzeroresidual,whichisunlikelyinapplications.In\n",
      "thispaper,weapplythedualsmoothingtechniqueproposedby[18]toobtain\n",
      "asmoothsurrogatefunctionsothatwecanavoiddirectlyevaluatingthesub-\n",
      "gradientoftheL2,1lossfunction.Thuswegaincomputationallike\n",
      "othersmoothlossfunctions.WeconsidertheFenchel?sdualrepresentationof\n",
      "theL2,1loss:||Y\n",
      "XB||2,1=\n",
      "max\n",
      "||U||2,1?1\n",
      "hU,Y\n",
      "XBi.\n",
      "(2.4)\n",
      "Let?>0beasmoothingparameter.ThesmoothapproximationoftheL2,1\n",
      "losscanbeobtainedbysolvingthefollowingoptimizationproblem?||Y\n",
      "XB||?=maxhU,YXBi||U||2F,(2.5)2||U||2,1?1where\n",
      "||U||2Fistheproximityfunction.Duetothefactthat||U||2F?\n",
      "m||U||22,1,weobtainthefollowinguniformboundbycombing(2.4)and\n",
      "(2.5),m?||YXB||2,1?||YXB||??||YXB||2,1.(2.6)2\n",
      "From(2.6),weseethattheapproximationerrorintroducedbythesmoothing\n",
      "procedurecanbecontrolledbyasuitable?.Figure2.1showsseveraltwo-\n",
      "dimensionalexamplesoftheL2normbBwithsmoothedbyrent??s.The\n",
      "optimizationproblemin(2.5)hasaclosedformsolutionUBbU?k=(Y?k\n",
      "XB?k)/max\n",
      "f\n",
      "||Y?kXB?k||2,?\n",
      "g\n",
      ".Thenextlemmashowsthat||Y\n",
      "XB||?issmoothinBwithasimpleformofgradient.3\n",
      "(a)?=0\n",
      "(b)?=0.1\n",
      "(c)?=0.25\n",
      "(d)?=0.5\n",
      "Figure2.1:TheL2norm(?=0)anditssmoothsurrogateswith?=0.1,\n",
      "0.25,0.5.Alarger?makestheapproximationmoresmooth,butintroducesa\n",
      "largerapproximationerror.Lemma2.1.Forany?>0,||YXB||?isa\n",
      "convexandcontinuouslytiablefunctioninB.Inaddition,G?(B)?the\n",
      "gradientof||YXB||?w.r.t.B?hastheform??bB,YXBi+?||U\n",
      "bB||2/2@hUFbB.G?(B)==XTU(2.7)@BMoreover,let=\n",
      "||X||22,thenwehavethatG?(B)isLipschitzcontinuousinBwiththe\n",
      "4\n",
      "\n",
      "Lipschitzconstant/?,i.e.,foranyB0,B002Rd?m,bB0UbB00i||F?1\n",
      "||XTX(B0B00)||F?||B0B00||F.||G?(B0)G?(B00)||F\n",
      "=||hX,U??\n",
      "Lemma2.1isadirectresultofTheorem1in[18]andimpliesthat||Y\n",
      "XB||?hasgoodcomputationalstructure.Thereforeweapplythesmooth\n",
      "proximalgradientalgorithmtosolvethesmoothedversionoftheoptimization\n",
      "problemasfollows,e=argmin||YXB||?+||B||1,p.B(2.8)B\n",
      "Wethenadoptthefastproximalgradientalgorithmtosolve(2.8)[4].To\n",
      "derivethealgorithm,wethreesequencesofauxiliaryvariables\n",
      "f\n",
      "A(t)\n",
      "g\n",
      ",\n",
      "f\n",
      "V(t)\n",
      "g\n",
      ",and\n",
      "f\n",
      "H(t)\n",
      "g\n",
      "withA(0)=H(0)=V(0)=B(0),asequenceofweights\n",
      "f\n",
      "?t=2/(t+1)\n",
      "g\n",
      ",andanonincreasingsequenceofstep-sizes\n",
      "f\n",
      "?t>0\n",
      "g\n",
      ".For\n",
      "simplicity,wecanset?t=?/.Inpractice,weusethebacktrackinglinesearch\n",
      "todynamicallyadjust?ttoboosttheperformance.Atthetthiteration,we\n",
      "takeV(t)=(1?t)B(t1)+?tA(t1).Wethenconsideraquadratic\n",
      "approximationof||YXH||?as??1QH,V(t),?t=||YXV(t)\n",
      "||?+hG?(V(t)),HV(t)i+||HV(t)||2F.2?te(t)=V(t)?tG?\n",
      "(V(t)),wetakeConsequently,letH??1e(t)||2+||H||1,p.(2.9)\n",
      "H(t)=argminQH,V(t),?t+||H||1,p=argmin||HHF2?tHHno\n",
      "(t)ej??max1?t/||Hej?||2,0.MoreWhenp=2,(2.9)hasaclosed\n",
      "formsolutionHj?=HdetailsaboutotherchoicesofpintheL1,pnormcanbe\n",
      "foundin[11]and[12].Toensurethattheobjectivevalueisnonincreasing,we\n",
      "chooseB(t)=\n",
      "argminB2\n",
      "f\n",
      "H(t),B(t\n",
      "1)\n",
      "g\n",
      "Atlast,wetakeA(t)=B(t1)+?1t(H(t)B(twhere\"isthestopping\n",
      "precision.\n",
      "||Y\n",
      "1)\n",
      "XB||?+||B||1,p.\n",
      "(2.10)\n",
      ").Thealgorithmstopswhen||H(t)V(t)||F?\",\n",
      "Thenumericalrateofconvergenceoftheproposedalgorithmwithrespect\n",
      "totheoriginaloptimizationproblem(2.1)ispresentedinthefollowingtheorem.\n",
      "pbF/?Theorem2.2.Givenapre-spaccuracy?andlet?=?/m,after\n",
      "t=2m||B(0)B||(t)(t)b2,1+||B||b1,p+?.1=O(1/?)\n",
      "iterations,wehave||YXB||2,1+||B||1,p?||YXB||\n",
      "TheproofofTheorem2.2isprovidedinAppendixA.1.Thisresultachieves\n",
      "theminimaxoptimalrateofconvergenceoverallstorderalgorithms[18].4\n",
      "3\n",
      "StatisticalProperties\n",
      "Fornotationalsimplicity,weeare-scalednoisematrixW=[Wik]2\n",
      "Rn?mwithWik=Zik/k,whereEZ2ik=k2.ThusWisarandommatrix\n",
      "withallentrieshavingmean0andvariance1.WeG0tobethegradient\n",
      "of||YXB||2,1atB=B0.Itiseasytoseethat\n",
      "XTZ?kXTW?kkXTW?k==||Z?k||2||W?kk||2||W?k\n",
      "||2doesnotdependontheunknownquantitieskforallk=1,...,m.G0?k\n",
      "5\n",
      "\n",
      "worksasanimportantpivotalinouranalysis.Moreover,ouranalysisexploits\n",
      "thedecomposabilityoftheL1,pnorm[17].Moresp,weassumethat\n",
      "B0hassrowswithallzeroentriesandeG0?k=\n",
      "S=C2Rd?m|Cj?=0foralljsuchthatB0j?=0,\n",
      "N=C2R\n",
      "d?m\n",
      "|Cj?=0foralljsuchthat\n",
      "B0j?\n",
      "6=0.\n",
      "(3.1)(3.2)\n",
      "NotethatwehaveB2SandtheL1,pnormisdecomposablewithrespectto\n",
      "thepair(S,N),i.e.,||A||1,p=||AS||1,p+||AN||1,p.The\n",
      "nextlemmashowsthatwhenissuitablychosen,thesolutiontotheoptimization\n",
      "problemin(2.1)liesinarestrictedset.bbetheoptimumto(2.1),and1/p+\n",
      "1/q=1.WedenotetheLemma3.1.LetB02SandB0bbestimationerroras\n",
      "=BB.Ifc||G0||1,qforsomec>1,wehave?c+1b2Mc:=2Rd?m\n",
      "|||N||1,p?||S||1,p.(3.3)c10\n",
      "TheproofofLemma3.1isprovidedinAppendixB.1.Toprovethemain\n",
      "result,wealsoneedtoassumethatthedesignmatrixXthefollowing\n",
      "condition.Assumption3.1.LetB02S,thenthereexistpositiveconstants?\n",
      "andc>1suchthat||X||Fp??min.n||||F2Mc\n",
      "f\n",
      "0\n",
      "g\n",
      "Assumption\n",
      "3.1isthegeneralizationoftherestrictedeigenvalueconditionsforanalyzing\n",
      "univariatesparselinearmodels[17,15,6],Manycommonexamplesofrandom\n",
      "designsatisfythisassumption[13,21].NotethatLemma3.1isadeterministic\n",
      "resultoftheCMRestimatorfora.SinceGisessentiallyarandommatrix,\n",
      "weneedtoshowthatcR?(G0)holdswithhighprobabilitytodeliveraconcrete\n",
      "rateofconvergencefortheCMRestimatorinthenexttheorem.pTheorem\n",
      "3.2.WeassumethateachcolumnofXisnormalizedasm1/21/pkX?jk2=\n",
      "nforallj=1,...,d.Thenforsomeuniversalconstantc0andlargeenoughn,\n",
      "takingp2c(m11/p+logd)p=,(3.4)1c0withprobabilityatleast12exp(\n",
      "2logd)2expnc20/8+logm,wehave!rrr1b16cmax1+c0sm12/ps\n",
      "logd0p||BB||F?2+.?(c1)1c0nnmm\n",
      "TheproofofTheorem3.2isprovidedinAppendixB.2.pNotethatwhenwe\n",
      "choosep=2,thecolumnnormalizationconditionisreducedtokX?jk2=n.\n",
      "Meanwhile,thecorrespondingerrorboundisfurtherreducedto!rr1bsslog\n",
      "d0p||BB||F=OP+,nnmm\n",
      "whichachievestheminimaxoptimalrateofconvergencepresentedin[13].\n",
      "SeeTheorem6.1in[13]formoretechnicaldetails.FromTheorem3.2,wesee\n",
      "thatCMRachievesthesameratesofconvergenceasthenoncalibratedcounter-\n",
      "part,butthetuningparameterin(3.4)doesnotinvolvek?s.ThereforeCMR\n",
      "notonlycalibratesalltheregressiontasks,butalsomakesthetuningparameter\n",
      "selectioninsensitivetomax.5\n",
      "4\n",
      "NumericalSimulations\n",
      "Tocomparethepleperformancebetweenthecalibratedmultivari-\n",
      "ateregression(CMR)andordinarymultivariateregression(OMR),wegenerate\n",
      "6\n",
      "\n",
      "atrainingdatasetof200samples.Moresp,weusethefollowingdata\n",
      "generationscheme:(1)GenerateeachrowofthedesignmatrixXi?,i=1,...,\n",
      "200,independentlyfroma800-dimensionalnormaldistributionN(0,?)where\n",
      "?jj=1and?j`=0.5forall`6=j.(2)Letk=1,...,13,settheregression\n",
      "cotmatrixB02R800?13asB01k=3,B02k=2,B04k=1.5,andB0jk\n",
      "=0forallj6=1,2,4.(3)GeneratetherandomnoisematrixZ=WD,where\n",
      "W2R200?13withallentriesofWareindependentlygeneratedfromN(0,1),\n",
      "andDiseitherofthefollowingmatrices??DI=max?diag20/4,21/4,\n",
      "???,211/4,212/42R13?13DH=max?I2R13?13.Wegeneratea\n",
      "validationsetof200samplesfortheregularizationparameterselectionanda\n",
      "testingsetof10,000samplestoevaluatethepredictionaccuracy.\n",
      "Innumericalexperiments,wesetmax=1,2,and4toillustratethetuning\n",
      "insensitivityofCMR.TheregularizationparameterofbothCMRandpOMR\n",
      "ispchosenoveragrid?=240/40,239/40,???,217/40,218/40,where\n",
      "0=logd+m.TheoptimalregulareXeBb||2,whereizationparameterb\n",
      "isdeterminedbythepredictionerrorasb=argmin2?||YFbdenotesthe\n",
      "obtainedestimateusingtheregularizationparameter,andXeandYedenote\n",
      "theBdesignandresponsematricesofthevalidationset.Sincethenoiselevel\n",
      "k?saretinregressiontasks,weadoptthefollowingthreecrite1bF,\n",
      "Adj.Pre.Err.=riatoevaluatetheempiricalperformance:Pre.Err.=10000\n",
      "||YXB||110212bbB||,whereXandYdenotesthedesignXB)D\n",
      "||F,andEst.Err.=m||BF10000m||(Yandresponsematricesof\n",
      "thetestingset.\n",
      "AllsimulationsareimplementedbyMATLABusingaPCwithIntelCore\n",
      "i53.3GHzCPUand16GBmemory.CMRissolvedbytheproposedsmoothing\n",
      "proximalgradientalgorithm,wherewesetthestoppingprecision\"=104,the\n",
      "smoothingparameter?=104.OMRissolvedbythemonotonefastproximal\n",
      "gradientalgorithm,wherewesetthestoppingprecision\"=104.Wesetp\n",
      "=2,buttheextensiontoarbitraryp>2isstraightforward.Wecompare\n",
      "thesmoothedproximalgradient(SPG)algorithmwiththeADMMalgorithm\n",
      "(thedetailedderivationofADMMcanbefoundinAppendixA.2).Weadopt\n",
      "thebacktrackinglinesearchtoacceleratebothalgorithmswithashrinkage\n",
      "parameter?=0.8.Wesetmax=2fortheadoptedmultivariatelinearmodels.\n",
      "Weconduct200simulations.TheresultsarepresentedinTable4.1.TheSPG\n",
      "andADMMalgorithmsattainsimilarobjectivevalues,butSPGisupto4times\n",
      "fasterthanADMM.Bothalgorithmsalsoachievesimilarestimationerrors.We\n",
      "thencomparethestatisticalperformancebetweenCMRandOMR.Tables4.2\n",
      "and4.3summarizetheresultsaveragedover200replicates.Inaddition,we\n",
      "alsopresenttheresultsoftheoracleestimator,whichisobtainedbysolving\n",
      "(2.2),sinceweknowthetruevaluesofk?s.Notethattheoracleestimatoris\n",
      "onlyforcomparisonpurpose,anditisnotapracticalestimator.SinceCMR\n",
      "calibratestheregularizationforeachtaskwithrespecttok,CMRuniversally\n",
      "outperformsOMR,andachievesalmostthesameperformanceastheoracle\n",
      "estimatorwhenweadoptthescalematrixDItogeneratetherandomnoise.\n",
      "Meanwhile,whenweadoptthescalematrixDH,whereallk?sarethesame,\n",
      "CMRandOMRachievesimilarperformance.ThisfurtherimpliesthatCMR\n",
      "7\n",
      "\n",
      "canbeasafereplacementofOMRformultivariateregressions.Inaddition,we\n",
      "alsoexaminetheoptimalregularizationparametersforCMRandOMRoverall\n",
      "replicates.Wevisualizethedistributionofall200selectedb?susingthekernel\n",
      "densityestimator.Inparticular,weadopttheGaussiankernel,andthekernel\n",
      "bandwidthisselectedbasedonthe10foldcrossvalidation.Figure4.1illustrates\n",
      "theestimateddensityfunctions.Thehorizontalaxis??bcorrespondstothe\n",
      "rescaledregularizationparameteraslogplogd+pm.Weseethattheoptimal\n",
      "regularizationparametersofOMRtlyvarywithtmax.In\n",
      "contrast,theoptimalregularizationparametersofCMRaremoreconcentrated.\n",
      "Thisisinconsistentwithourclaimedtuninginsensitivity.6\n",
      "Table4.1:Quantitivecomparisonofthecomputationalperformancebetween\n",
      "SPGandADMMwiththenoisematricesgeneratedusingDI.Theresultsare\n",
      "averagedover200replicateswithstandarderrorsinparentheses.SPGand\n",
      "ADMMattainsimilarobjectivevalues,butSPGisuptoabout4timesfaster\n",
      "thanADMM.\n",
      "2\n",
      "0\n",
      "0\n",
      "0.5\n",
      "0\n",
      "Algorithm\n",
      "Timing(second)\n",
      "Obj.Val.\n",
      "Num.Ite.\n",
      "Est.Err.\n",
      "SPGADMM\n",
      "2.8789(0.3141)8.4731(0.8387)\n",
      "508.21(3.8498)508.22(3.7059)\n",
      "493.26(52.268)437.7(37.4532)\n",
      "0.1213(0.0286)0.1215(0.0291)\n",
      "SPGADMM\n",
      "3.2633(0.3200)11.976(1.460)\n",
      "370.53(3.6144)370.53(3.4231)\n",
      "565.80(54.919)600.94(74.629)\n",
      "0.0819(0.0205)0.0822(0.0233)\n",
      "SPGADMM\n",
      "3.7868(0.4551)18.360(1.9678)\n",
      "297.24(3.6125)297.25(3.3863)\n",
      "652.53(78.140)1134.0(136.08)\n",
      "0.1399(0.0284)0.1409(0.0317)\n",
      "Table4.2:Quantitivecomparisonofthestatisticalperformancebetween\n",
      "CMRandOMRwiththenoisematricesgeneratedusingDI.Theresultsare\n",
      "averagedover200simulationswiththestandarderrorsinparentheses.CMR\n",
      "universallyoutperformsOMR,andachievesalmostthesameperformanceas\n",
      "theoracleestimator.Method\n",
      "Pre.Err.\n",
      "8\n",
      "\n",
      "Adj.Pre.Err\n",
      "Est.Err.\n",
      "1\n",
      "OracleCMROMR\n",
      "5.8759(0.0834)5.8761(0.0673)5.9012(0.0701)\n",
      "1.0454(0.0149)1.0459(0.0123)1.0581(0.0162)\n",
      "0.0245(0.0086)0.0249(0.0071)0.0290(0.0091)\n",
      "2\n",
      "OracleCMROMR\n",
      "23.464(0.3237)23.465(0.2598)23.580(0.2832)\n",
      "1.0441(0.0148)1.0446(0.0121)1.0573(0.0170)\n",
      "0.0926(0.0342)0.0928(0.0279)0.1115(0.0365)\n",
      "4\n",
      "OracleCMROMR\n",
      "93.532(0.8843)93.542(0.9794)94.094(1.0978)\n",
      "1.0418(0.0962)1.0421(0.0118)1.0550(0.0166)\n",
      "0.3342(0.1255)0.3346(0.1063)0.4125(0.1417)\n",
      "max\n",
      "Table4.3:Quantitivecomparisonofthestatisticalperformancebetween\n",
      "CMRandOMRwiththenoisematricesgeneratedusingDH.Theresultsare\n",
      "averagedover200simulationswiththestandarderrorsinparentheses.CMR\n",
      "andOMRachievesimilarperformance.Method\n",
      "Pre.Err.\n",
      "Adj.Pre.Err\n",
      "Est.Err.\n",
      "1\n",
      "CMROMR\n",
      "13.565(0.1408)13.697(0.1554)\n",
      "1.0435(0.0108)1.0486(0.0142)\n",
      "0.0599(0.0164)0.0607(0.0128)\n",
      "2\n",
      "CMROMR\n",
      "54.171(0.5771)54.221(0.6173)\n",
      "1.0418(0.0110)1.0427(0.0118)\n",
      "0.2252(0.0649)0.2359(0.0821)\n",
      "4\n",
      "CMROMR\n",
      "215.98(2.104)216.19(2.391)\n",
      "1.0384(0.0101)1.0394(0.0114)\n",
      "0.80821(0.25078)0.81957(0.31806)\n",
      "max\n",
      "1.4\n",
      "Oracle(1)Oracle(2)Oracle(4)CMR(1)CMR(2)CMR(4)OMR(1)OMR(2)\n",
      "OMR(4)\n",
      "1.2\n",
      "1\n",
      "9\n",
      "\n",
      "0.8\n",
      "0.6\n",
      "1.4\n",
      "1\n",
      "0.8\n",
      "0.6\n",
      "0.4\n",
      "0.4\n",
      "0.2\n",
      "0.2\n",
      "0?2\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "0\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "CMR(1)CMR(2)CMR(4)OMR(1)OMR(2)OMR(4)\n",
      "1.2\n",
      "0?2\n",
      "2.5\n",
      "(a)ThenoisematricesaregeneratedusingDI\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "0\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "2.5\n",
      "(b)ThenoisematricesaregeneratedusingDH\n",
      "Figure4.1:Thedistributionsoftheselectedregularizationparametersusing\n",
      "thekerneldensityestimator.Thenumbersintheparenthesesaremax?s.The\n",
      "optimalregularizationparametersofOMRarespreaderwithtmaxthan\n",
      "thoseofCMRandtheoracleestimator.7\n",
      "5\n",
      "RealDataExperiment\n",
      "WeapplyCMRonabrainactivitypredictionproblemwhichaimstobuilda\n",
      "parsimoniousmodeltopredictaperson?sneuralactivitywhenseeingastimulus\n",
      "word.AsisillustratedinFigure5.1,foragivenstimulusword,weencode\n",
      "itintoanintermediatesemanticfeaturevectorusingsomecorpusstatistics.\n",
      "Wethenmodelthebrain?sneuralactivitypatternusingCMR.Creatingsuch\n",
      "apredictivemodelnotonlyenablesustoexplorenewanalyticaltoolsforthe\n",
      "10\n",
      "\n",
      "fMRIdata,butalsohelpsustogaindeeperunderstandingonhowhumanbrain\n",
      "representsknowledge[16].PredictfMRIbrainactivitypatternsinresponseto\n",
      "textstimulus89/:4:2%,-.&2\n",
      "!\"#$%)/01'2!\"#$%&'()*'\n",
      "%0334'&\n",
      "(Mitchelletal.,Science,2008)\n",
      "!\"#$%0334'&stimulusword\n",
      "!\"#$%50//'.&\n",
      "%50//'.&\n",
      "predictedactivitiesfor\"apple\"\n",
      "\"apple\"\n",
      "!\"#$%6)*7*4'&\n",
      "%6)*7*4'&\n",
      "+',%,-.&\n",
      "?\n",
      "Model\n",
      "intermediatesemanticfeatures\n",
      "Standardsolution\n",
      "Oursolution\n",
      "Linearmodels(Morerestrictive)\n",
      "(Lessrestrictive)\n",
      "(a)illustrationofthedatacollectionprocedureNonlinearmodels.\n",
      "mappinglearnedfromfMRIdata\n",
      "(b)modelforpredictingfMRIbrainactivitypattern\n",
      "Figure5.1:AnillustrationofthefMRIbrainactivitypredictionproblem[16].\n",
      "(a)Tocollectthe;5'%'<3'.)/'+=2%0.'%*-+&:*='&%)+%>\")=*5'44%'=%0?%8*)'+*'%@AB\n",
      "data,ahumanparticipantseesasequenceofEnglishwordsandtheirimages.\n",
      "ThecorrespondingfMRIimagesarerecordedtorepresentthebrainactivity\n",
      "patterns;(b)Tobuildapredictivemodel,eachstimuluswordisencodedinto\n",
      "intermediatesemanticfeatures(e.g.theco-occurrencestatisticsofthisstimulus\n",
      "wordinalargetextcorpus).Theseintermediatefeaturescanthenbeused\n",
      "topredictthebrainactivitypattern.Ourexperimentsinvolves9participants,\n",
      "andTable5.1summarizesthepredictionperformanceoftmethodson\n",
      "theseparticipants.Weseethatthepredictionbasedonthefeaturesselected\n",
      "byCMRcantlyoutperformsthatbasedonthefeaturesselectedbyOMR,\n",
      "andisascompetitiveasthatbasedonthehandcraftedfeaturesselectedby\n",
      "humanexperts.Butduetothespacelimit,wepresentthedetailsofthereal\n",
      "dataexperimentinthetechnicalreportversion.Table5.1:Predictionaccura-\n",
      "ciesoftmethods(higherisbetter).CMRoutperformsOMRfor8out\n",
      "of9participants,andoutperformsthehandcraftedbasiswordsfor6outof9\n",
      "participantsMethod\n",
      "P.1\n",
      "CMR0.840OMR0.803Handcraft0.822\n",
      "6\n",
      "P.2\n",
      "P.3\n",
      "11\n",
      "\n",
      "P.4\n",
      "P.5\n",
      "P.6\n",
      "P.7\n",
      "P.8\n",
      "P.9\n",
      "0.7940.7890.776\n",
      "0.8610.8010.773\n",
      "0.6510.6020.727\n",
      "0.8230.7660.782\n",
      "0.7220.6230.865\n",
      "0.7380.7260.734\n",
      "0.7200.7490.685\n",
      "0.7800.7650.819\n",
      "Discussions\n",
      "Arelatedmethodisthesquare-rootsparsemultivariateregression[8].They\n",
      "solvetheconvexprogramwiththeFrobeniuslossfunctionandL1,pregulariza-\n",
      "tionfunctionb=argmin||YBB\n",
      "XB||F+||B||1,p.\n",
      "(6.1)\n",
      "TheFrobeniuslossfunctionin(6.1)makestheregularizationparameter\n",
      "selectionindependentofmax,butitdoesnotcalibratetregression\n",
      "tasks.Notethatwecanrewrite(6.1)as1bb)=argminp1||YXB||2+\n",
      "||B||1,ps.t.(B,=p||YXB||F.(6.2)FnmnmB,Sincein(6.2)is\n",
      "notsptoanyindividualtask,itcannotcalibratetheregularization.Thus\n",
      "itisfundamentallytfromCMR.8\n",
      "2References\n",
      "[1]T.WAnderson.Anintroductiontomultivariatestatisticalanalysis.Wi-\n",
      "leyNewYork,1958.[2]RieKubotaAndoandTongZhang.Aframework\n",
      "forlearningpredictivestructuresfrommultipletasksandunlabeleddata.The\n",
      "JournalofMachineLearningResearch,6(11):1817?1853,2005.[3]JBaxter.\n",
      "Amodelofinductivebiaslearning.JournalofIntelligenceResearch,\n",
      "12:149?198,2000.[4]A.BeckandMTeboulle.Fastgradient-basedalgorithms\n",
      "forconstrainedtotalvariationimagedenoisinganddeblurringproblems.IEEE\n",
      "TransactionsonImageProcessing,18(11):2419?2434,2009.[5]A.Belloni,V.\n",
      "Chernozhukov,andLWang.Square-rootlasso:pivotalrecoveryofsparsesig-\n",
      "nalsviaconicprogramming.Biometrika,98(4):791?806,2011.[6]PeterJBickel,\n",
      "YaacovRitov,andAlexandreBTsybakov.Simultaneousanalysisoflassoand\n",
      "dantzigselector.TheAnnalsofStatistics,37(4):1705?1732,2009.[7]L.Breiman\n",
      "andJ.HFriedman.Predictingmultivariateresponsesinmultiplelinearregres-\n",
      "sion.JournaloftheRoyalStatisticalSociety:SeriesB,59(1):3?54,2002.[8]\n",
      "FlorentinaBunea,JohannesLederer,andYiyuanShe.Thegroupsquare-root\n",
      "12\n",
      "\n",
      "lasso:Theoreticalpropertiesandfastalgorithms.IEEETransactionsonInfor-\n",
      "mationTheory,60:1313?1325,2013.[9]IainMJohnstone.Chi-squareoracle\n",
      "inequalities.LectureNotes-MonographSeries,pages399?418,2001.[10]Michel\n",
      "LedouxandMichelTalagrand.ProbabilityinBanachSpaces:isoperimetryand\n",
      "processes.Springer,2011.[11]H.Liu,M.Palatucci,andJZhang.Block-\n",
      "wisecoordinatedescentproceduresforthemulti-tasklasso,withapplications\n",
      "toneuralsemanticbasisdiscovery.InProceedingsofthe26thAnnualInter-\n",
      "nationalConferenceonMachineLearning,pages649?656.ACM,2009.[12]\n",
      "J.LiuandJYe.t`1/`qnormregularization.Technicalreport,Ari-\n",
      "zonaStateUniversity,2010.[13]K.Lounici,M.Pontil,S.VanDeGeer,and\n",
      "A.BTsybakov.Oracleinequalitiesandoptimalinferenceundergroupsparsity.\n",
      "TheAnnalsofStatistics,39(4):2164?2204,2011.[14]N.MeinshausenandP.\n",
      "B?uhlmann.Stabilityselection.JournaloftheRoyalStatisticalSociety:Se-\n",
      "riesB,72(4):417?473,2010.[15]NicolaiMeinshausenandBinYu.Lasso-type\n",
      "recoveryofsparserepresentationsforhigh-dimensionaldata.TheAnnalsof\n",
      "Statistics,37(1):246?270,2009.[16]T.M.Mitchell,S.V.Shinkareva,A.Carlson,\n",
      "K.M.Chang,V.L.Malave,R.A.Mason,andM.AJust.Predictinghumanbrain\n",
      "activityassociatedwiththemeaningsofnouns.Science,320(5880):1191?1195,\n",
      "2008.[17]SahandN.Negahban,PradeepRavikumar,MartinJ.Wainwright,\n",
      "andBinYu.Aframeworkforhigh-dimensionalanalysisofm-estimators\n",
      "withdecomposableregularizers.StatisticalScience,27(4):538?557,2012.[18]\n",
      "Y.Nesterov.Smoothminimizationofnon-smoothfunctions.Mathematical\n",
      "Programming,103(1):127?152,2005.[19]G.Obozinski,M.J.Wainwright,and\n",
      "M.IJordan.Supportunionrecoveryinhigh-dimensionalmultivariateregression.\n",
      "TheAnnalsofStatistics,39(1):1?47,2011.[20]HuaOuyang,NiaoHe,Long\n",
      "Tran,andAlexanderGray.Stochasticalternatingdirectionmethodofmultipli-\n",
      "ers.InProceedingsofthe30thInternationalConferenceonMachineLearning,\n",
      "pages80?88,2013.[21]GarveshRaskutti,MartinJWainwright,andBinYu.\n",
      "Restrictedeigenvaluepropertiesforcorrelatedgaussiandesigns.TheJournal\n",
      "ofMachineLearningResearch,11(8):2241?2259,2010.[22]A.J.Rothman,E.\n",
      "Levina,andJZhu.Sparsemultivariateregressionwithcovarianceestimation.\n",
      "JournalofComputationalandGraphicalStatistics,19(4):947?962,2010.[23]\n",
      "R.Tibshirani.Regressionshrinkageandselectionviathelasso.Journalofthe\n",
      "RoyalStatisticalSociety,SeriesB,58(1):267?288,1996.[24]B.A.Turlach,W.N.\n",
      "Venables,andS.JWright.47(3):349?363,2005.\n",
      "Simultaneousvariableselection.\n",
      "Technometrics,\n",
      "[25]M.YuanandYLin.Modelselectionandestimationinregression\n",
      "withgroupedvariables.JournaloftheRoyalStatisticalSociety:SeriesB,\n",
      "68(1):49?67,2005.[26]JianZhang.Aprobabilisticframeworkformulti-task\n",
      "learning.PhDthesis,CarnegieMellonUniversity,LanguageTechnologiesInsti-\n",
      "tute,SchoolofComputerScience,2006.\n",
      "9\n",
      "13\n",
      "\n",
      "PP6462.pdf\n",
      "PP6462.pdf 15\n",
      "SolvingMarginalMAPProblemswithNP\n",
      "OraclesandParityConstraints\n",
      "Authoredby:\n",
      "CarlaP.Gomes\n",
      "BartSelman\n",
      "StefanoErmon\n",
      "YexiangXue\n",
      "ZhiyuanLi\n",
      "Abstract\n",
      "Arisingfrommanyapplicationsattheintersectionofdecision-making\n",
      "andmachinelearning,MarginalMaximumAPosteriori(MarginalMAP)\n",
      "problemsunifythetwomainclassesofinference,namelymaximization\n",
      "(optimization)andmarginalinference(counting),andarebelievedto\n",
      "havehighercomplexitythanbothofthem.WeproposeXOR\n",
      "MMAP,\n",
      "anovelapproachtosolvetheMarginalMAPproblem,whichrepresents\n",
      "theintractablecountingsubproblemwithqueriestoNPoracles,subject\n",
      "toadditionalparityconstraints.XOR\n",
      "MMAPprovidesaconstantfactor\n",
      "approximationtotheMarginalMAPproblem,byencodingitasasingle\n",
      "optimizationinapolynomialsizeoftheoriginalproblem.Weevaluate\n",
      "ourapproachinseveralmachinelearninganddecision-makingapplica-\n",
      "tions,andshowthatourapproachoutperformsseveralstate-of-the-art\n",
      "MarginalMAPsolvers.\n",
      "1PaperBody\n",
      "Typicalinferencequeriestomakepredictionsandlearnprobabilisticmodels\n",
      "fromdataincludethemaximumaposteriori(MAP)inferencetask,whichcom-\n",
      "putesthemostlikelyassignmentofasetofvariables,aswellasthemarginal\n",
      "inferencetask,whichcomputestheprobabilityofaneventaccordingtothe\n",
      "model.AnothercommonqueryistheMarginalMAP(MMAP)problem,which\n",
      "involvesbothmaximization(optimizationoverasetofvariables)andmarginal\n",
      "inference(averagingoveranothersetofvariables).MarginalMAPproblems\n",
      "arisenaturallyinmanymachinelearningapplications.Forexample,learning\n",
      "latentvariablemodelscanbeformulatedasaMMAPinferenceproblem,where\n",
      "thegoalistooptimizeoverthemodel?sparameterswhilemarginalizingall\n",
      "thehiddenvariables.MMAPproblemsalsoarisenaturallyinthecontextof\n",
      "1\n",
      "\n",
      "decision-makingunderuncertainty,wherethegoalistoadecision(opti-\n",
      "mization)thatperformswellonaverageacrossmultipleprobabilisticscenarios\n",
      "(averaging).TheMarginalMAPproblemisknowntobeNPPP-complete[18],\n",
      "whichiscommonlybelievedtobeharderthanbothMAPinference(NP-hard)\n",
      "andmarginalinference(#P-complete).Assupportingevidence,MMAPprob-\n",
      "lemsareNP-hardevenontreestructuredprobabilisticgraphicalmodels[13].\n",
      "AsidefromattemptstosolveMMAPproblemsexactly[17,15,14,16],previous\n",
      "approximateapproachesfallintotwocategories,ingeneral.Thecoreideaof\n",
      "approachesinbothcategoriesis?\n",
      "ThisresearchwasdonewhenZhiyuanLiwasanexchangestudentatCornell\n",
      "University.\n",
      "30thConferenceonNeuralInformationProcessingSystems(NIPS2016),\n",
      "Barcelona,Spain.\n",
      "toelyapproximatetheintractablemarginalization,whichoftenin-\n",
      "volvesaveragingoveranexponentiallylargenumberofscenarios.Oneclassof\n",
      "approaches[13,11,19,12]usevariationalformstorepresenttheintractable\n",
      "sum.Thentheentireproblemcanbesolvedwithmessagepassingalgorithms,\n",
      "whichcorrespondtosearchingforthebestvariationalapproximationinaniter-\n",
      "ativemanner.Asanotherfamilyofapproaches,SampleAverageApproximation\n",
      "(SAA)[20,21]usesasetofsamplestorepresenttheintractablesum,which\n",
      "thentransformstheentireproblemintoarestrictedoptimization,onlyconsid-\n",
      "eringanumberofsamples.Bothapproachestreattheoptimizationand\n",
      "marginalizingcomponentsseparately.However,wewillshowthatbysolving\n",
      "thesetwotasksinanintegratedmanner,wecanobtaintcomputa-\n",
      "tionalbErmonetal.[8,9]recentlyproposedanalternativeapproach\n",
      "toapproximateintractablecountingproblems.Theirkeyideaisamechanism\n",
      "totransformacountingproblemintoaseriesofoptimizationproblems,each\n",
      "correspondingtotheoriginalproblemsubjecttorandomlygeneratedXORcon-\n",
      "straints.Basedonthismechanism,theydevelopedanalgorithmprovidinga\n",
      "constant-factorapproximationtothecounting(marginalization)problem.We\n",
      "proposeanovelalgorithm,calledXOR\n",
      "MMAP,whichapproximatesthein-\n",
      "tractablesumwithaseriesofoptimizationproblems,whichinturnarefolded\n",
      "intotheglobaloptimizationtask.Therefore,weelyreducetheoriginal\n",
      "MMAPinferencetoasinglejointoptimizationofpolynomialsizeoftheoriginal\n",
      "problem.WeshowthatXOR\n",
      "MMAPprovidesaconstantfactorapproxima-\n",
      "tiontotheMarginalMAPproblem.Ourapproachalsoprovidesupperand\n",
      "lowerboundsontheresult.Thequalityoftheboundscanbeimproved\n",
      "incrementallywithincreasedcomputationalWeevaluateouralgorithm\n",
      "onunweightedSATinstancesandonweightedMarkovRandomFieldmodels,\n",
      "comparingouralgorithmwithvariationalmethods,aswellassampleaverage\n",
      "approximation.Wealsoshowtheenessofouralgorithmonapplications\n",
      "incomputervisionwithdeepneuralnetworksandincomputationalsustainabil-\n",
      "ity.OursustainabilityapplicationshowshowMMAPproblemsarealsofound\n",
      "inscenariosofsearchingforoptimalpolicyinterventionstomaximizetheout-\n",
      "comesofprobabilisticmodels.Asaexample,weconsideranetworkdesign\n",
      "applicationtomaximizethespreadofcascades[20],whichincludemodeling\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animalmovementsorinformationinsocialnetworks.Inthissetting,\n",
      "themarginalsofaprobabilisticdecisionmodelrepresenttheprobabilitiesfora\n",
      "cascadetoreachcertaintargetstates(averaging),andtheoverallnetworkde-\n",
      "signproblemistomakeoptimalpolicyinterventionsonthenetworkstructure\n",
      "tomaximizethespreadofthecascade(optimization).Asasecondexample,\n",
      "inacrowdsourcingdomain,probabilisticmodelsareusedtomodelpeople?s\n",
      "behavior.Theorganizerwouldliketoanoptimalincentivemechanism(op-\n",
      "timization)tosteerpeople?stowardscrucialtasks,takingintoaccountthe\n",
      "probabilisticbehavioralmodel(averaging)[22].WeshowthatXOR\n",
      "MMAPis\n",
      "abletoconsiderablybettersolutionsthanthosefoundbypreviousmethods,\n",
      "aswellasprovidetighterbounds.\n",
      "2\n",
      "Preliminaries\n",
      "ProblemLetA=\n",
      "f\n",
      "0,1\n",
      "g\n",
      "mbethesetofallpossibleassignments\n",
      "tobinaryvariablesa1,...,amandX=\n",
      "f\n",
      "0,1\n",
      "g\n",
      "nbethesetofassignmentsto\n",
      "binaryvariablesx1,...,xn.Letw(x,a):X?A?R+beafunctionthatmaps\n",
      "everyassignmenttoanon-negativevalue.Typicalqueriesoveraprobabilistic\n",
      "modelincludethePmaximizationtask,whichrequiresthecomputationof\n",
      "maxa?Aw(a),andthemarginalinferencetaskx?Xw(x),whichsumsover\n",
      "X.Arisingnaturallyfrommanymachinelearningapplications,thefollowing\n",
      "MarginalMaximumAPosteriori(MarginalMAP)problemisajointinference\n",
      "task,whichcombinesthetwoaforementionedinferencetasks:Xmaxw(x,a).\n",
      "(1)a?A\n",
      "x?X\n",
      "PWeconsiderthecasewherethecountingproblemx?Xw(x,a)andthe\n",
      "maximizationproblemmaxa?A#w(a)areoversetsofexponentialsize,\n",
      "thereforebothareintractableingeneral.CountingbyHashingandOptimiza-\n",
      "tionOurapproachisbasedonarecenttheoreticalresultthattransformsa\n",
      "countingproblemtoaseriesofoptimizationproblems[8,9,2,1].Afamilyof\n",
      "functionsH=\n",
      "f\n",
      "h:\n",
      "f\n",
      "0,1\n",
      "g\n",
      "n?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "k\n",
      "g\n",
      "issaidtobepairwiseindependentifthe\n",
      "followingtwoconditions2\n",
      "Algorithm1:XOR\n",
      "Binary(w:A?X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",a0,k)\n",
      "Samplefunctionhk:X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "kfromapair-wiseindependentfunction\n",
      "family;QueryanNPOracleonwhetherW(a0,hk)=\n",
      "f\n",
      "x?X:w(a0,x)=1,\n",
      "hk(x)=0\n",
      "g\n",
      "isempty;ReturntrueifW(a0,hk)6=?,otherwisereturnfalse.\n",
      "holdforanyfunctionhrandomlychosenfromthefamilyH:(1)?x?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "n,\n",
      "therandomvariableh(x)isuniformlydistributedin\n",
      "f\n",
      "0,1\n",
      "g\n",
      "kand(2)?x1,x2?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "n,x16=x2,therandomvariablesh(x1)andh(x2)areindependent.\n",
      "WesamplematricesA?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "k?nandvectorb?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "kuniformlyat\n",
      "randomtoformthefunctionfamilyHA,b=\n",
      "f\n",
      "hA,b:hA,b(x)=Ax+bmod\n",
      "2\n",
      "g\n",
      ".ItispossibletoshowthatHA,bispairwiseindependent[8,9].Noticethat\n",
      "inthiscase,eachfunctionhA,b(x)=Ax+bmod2correspondstokparity\n",
      "constraints.Oneusefulwaytothinkaboutpairwiseindependentfunctionsis\n",
      "toimaginethemasfunctionsthatrandomlyprojectelementsin\n",
      "f\n",
      "0,1\n",
      "g\n",
      "ninto\n",
      "2kbuckets.Bh(g)=\n",
      "f\n",
      "x?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "n:hA,b(x)=g\n",
      "g\n",
      "tobea?bucket?\n",
      "thatincludesallelementsin\n",
      "f\n",
      "0,1\n",
      "g\n",
      "nwhosemappedvaluehA,b(x)isvector\n",
      "3\n",
      "\n",
      "g(g?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "k).Intuitively,ifwerandomlysampleafunctionhA,bfroma\n",
      "pairwiseindependentfamily,thenwegetthefollowing:x?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "nhasan\n",
      "equalprobabilitytobeinanybucketB(g),andthebucketlocationsofanytwo\n",
      "telementsx,yareindependent.\n",
      "33.1\n",
      "XOR\n",
      "MMAPAlgorithmBinaryCase\n",
      "WesolvetheMarginalMAPproblemforthebinarycase,inwhichthe\n",
      "functionw:A?X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "outputseither0or1.Wewillextendtheresult\n",
      "totheweightedcaseinthenextsection.Sincea?Aoftenrepresentdecision\n",
      "variableswhenMMAPproblemsareusedindecisionmaking,wecalla\n",
      "assignmenttovectora=a0a?solutionstrategy?.Tosimplifythenotation,we\n",
      "useW(a0)torepresenttheset\n",
      "f\n",
      "x?X:w(a0,x)=1\n",
      "g\n",
      ",anduseW(a0,hk\n",
      ")torepresenttheset\n",
      "f\n",
      "x?X:w(a0,x)=1andhk(x)=0\n",
      "g\n",
      ",inwhichhkis\n",
      "sampledfromapairwiseindependentkfunctionfamilythatPmapsXto\n",
      "f\n",
      "0,1\n",
      "g\n",
      ".Wewrite#w(a0)asshorthandforthecount|\n",
      "f\n",
      "x?X:w(a0,x)=1\n",
      "g\n",
      "|\n",
      "=x?Xw(a0,x).Ouralgorithmdependsonthefollowingresult:Theorem3.1.\n",
      "(Ermonet.al.[8])Forasolutionstrategya0?A,?Suppose#w(a0)\n",
      "?2k0,thenforanyk?k0,withprobability1?XOR\n",
      "Binary(w,a0,k?\n",
      "c)=true.\n",
      "2c(2c?1)2,\n",
      "Algorithm\n",
      "?Suppose#w(a0)<2k0,thenforanyk?k0,withprobability1?\n",
      "XOR\n",
      "Binary(w,a0,k+c)=false.\n",
      "2c(2c?1)2,\n",
      "Algorithm\n",
      "TounderstandTheorem3.1intuitively,wecanthinkofhkasafunction\n",
      "thatmapseveryelementinsetW(a0)into2kbuckets.Becausehkcomes\n",
      "fromapairwiseindependentfunctionfamily,eachelementinW(a0)willhave\n",
      "anequalprobabilitytobeinanyoneofthe2kbuckets,andthebucketsin\n",
      "whichanytwoelementsenduparemutuallyindependent.Supposethecount\n",
      "ofsolutionsforastrategy#w(a0)is2k0,thenwithhighprobability,\n",
      "therewillbeatleastoneelementlocatedinarandomlyselectedbucketifthe\n",
      "numberofbuckets2kislessthan2k0.Otherwise,withhighprobabilitythere\n",
      "willbenoelementinarandomlyselectedbucket.Theorem3.1providesus\n",
      "withawaytoobtainaroughcounton#w(a0)viaaseriesoftestsonwhether\n",
      "W(a0,hk)isempty,subjecttoextraparityfunctionshk.Thistransforms\n",
      "acountingproblemtoaseriesofNPqueries,whichcanalsobethoughtofas\n",
      "optimizationqueries.ThistransformationisextremelyhelpfulfortheMarginal\n",
      "MAPproblem.Asnotedearlier,themainchallengeforthemarginalMAP\n",
      "problemistheintractablesumembeddedinthemaximization.Nevertheless,\n",
      "thewholeproblemcanbere-writtenasasingleoptimizationiftheintractable\n",
      "sumcanbeapproximatedwellbysolvinganoptimizationproblemoverthe\n",
      "samedomain.WethereforedesignAlgorithmXOR\n",
      "MMAP,whichisableto\n",
      "provideaconstantfactorapproximationtotheMarginalMAPproblem.The\n",
      "wholealgorithmisshowninAlgorithm3.Initsmainprocedure3\n",
      "4\n",
      "\n",
      "Algorithm2:XOR\n",
      "K(w:A?X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",k,T)SampleTpair-wiseinde-\n",
      "pendenthashfunctions(1)(2)(T)hk,hk,...,hk:X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "k;Query\n",
      "OracleTX\n",
      "maxa?A,x(i)?X\n",
      "w(a,x(i))\n",
      "(2)\n",
      "i=1(i)hk(x(i))\n",
      "s.t.\n",
      "=0,i=1,...,T.\n",
      "ReturntrueifthemaxvalueislargerthandT/2e,otherwisereturnfalse.\n",
      "Algorithm3:XOR\n",
      "MMAP(w:A?X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",n=log2|X|,m=log2\n",
      "|A|,T)k=n;whilek>0doifXOR\n",
      "K(w,k,T)thenReturn2k;endk?\n",
      "k?1;endReturn1;\n",
      "XOR\n",
      "K,thealgorithmtransformstheMarginalMAPproblemintoanop-\n",
      "timizationoverthesumofTreplicatesoftheoriginalfunctionw.Here,x(i)\n",
      "?Xisareplicateoftheoriginalx,andw(a,x(i))istheoriginalfunctionw\n",
      "buttakesx(i)asoneoftheinputs.Allreplicatessharecommoninputa.In\n",
      "addition,eachreplicateissubjecttoanindependentsetofparityconstraintson\n",
      "x(i).Theorem3.2statesthatXOR\n",
      "MMAPprovidesaconstant-factorapprox-\n",
      "imationtotheMarginalMAPproblem:Theorem3.2.ForT?mln2+ln(n/?)\n",
      ",withprobability1??,XOR\n",
      "MMAP(w,log2|X|,log2|A|,T)??(c)\n",
      "2coutputsa2-approximationtotheMarginalMAPproblem:maxa?A#w(a).\n",
      "??(c)isaconstant.Letusrstunderstandthetheoreminanintuitiveway.\n",
      "Withoutlosinggenerality,supposetheoptimalvaluemaxa?A#w(a)=2k0.\n",
      "Denotea?astheoptimalsolution,ie,#w(a?)=2k0.AccordingtoTheorem\n",
      "3.1,thesetW(a?,hk)hasahighprobabilitytobenon-empty,foranyfunction\n",
      "hkthatcontainsk<k0parityconstraints.Inthiscase,theoptimizationproblem\n",
      "(i)maxx(i)?X,h(i)(x(i))=0w(a?,x(i))foronereplicatex(i)almostalways\n",
      "returns1.BecausehkkPT(i=1...T)aresampledindependently,thesum\n",
      "i=1w(a?,x(i))islikelytobelargerthandT/2e,sinceeachterminthesum\n",
      "islikelytobe1(underthea?).Furthermore,sinceXOR\n",
      "Kmaximizes\n",
      "thissumoverallpossiblestrategiesa?A,thesumitwillbeatleastas\n",
      "goodastheoneattainedata?,whichisalreadyoverdT/2e.Therefore,we\n",
      "concludethatwhenk<k0,XOR\n",
      "Kwillreturntruewithhighprobability.We\n",
      "candevelopsimilarargumentstoconcludethatXOR\n",
      "Kwillreturnfalsewith\n",
      "highprobabilitywhenmorethank0XORconstraintsareadded.Noticethat\n",
      "replicationsandanadditionalunionboundargumentarenecessarytoestablish\n",
      "theprobabilisticguaranteeinthiscase.Asacounter-example,supposefunction\n",
      "w(x,a)=1ifandonlyifx=a,otherwisew(x,a)=0(m=ninthiscase).If\n",
      "wesetthenumberofreplicatesT=1,thenXOR\n",
      "Kwillalmostalwaysreturn1\n",
      "whenk<n,whichsuggeststhatthereare2nsolutionstotheMMAPproblem.\n",
      "Nevertheless,inthiscasethetrueoptimalvalueofmaxx#w(x,a)is1,which\n",
      "isfarawayfrom2n.Thissuggeststhatatleasttworeplicatesareneeded.\n",
      "Lemma3.3.ForT?ln2?m+ln(n/?),procedureXOR\n",
      "K(w,k)??(c)\n",
      "?Suppose?a??A,s.t.#w(a?)?2k,thenwithprobability1?returnstrue.\n",
      "?n2m,\n",
      "5\n",
      "\n",
      "XOR\n",
      "K(w,k?c,T)\n",
      "?n,\n",
      "XOR\n",
      "K(w,k+c,T)\n",
      "?Suppose?a0?A,s.t.#w(a0)<2k,thenwithprobability1?returns\n",
      "false.\n",
      "Proof.Claim1:Ifthereexistssucha?satisfying#w(a?)?2k,picka0=\n",
      "a?.LetX(i)(a0)=maxx(i)?X,h(i)(x(i))=0w(a0,x(i)),fori=1...,\n",
      "T.FromTheorem3.1,X(i)(a0)=1holdswithk?c\n",
      "probability1?\"Prmaxa?A\n",
      "whereD\n",
      "2c(2c?1)2.\n",
      "TX\n",
      "c\n",
      "Let??(c)=D(12k(2c2?1)2).Bybound,wehave#\n",
      "X\n",
      "(i)\n",
      "(a)?T/2?Pr\n",
      "i=1\n",
      "12ckc2(2?1)2\n",
      "\"\n",
      "TX\n",
      "#X\n",
      "(i)\n",
      "(a0)?T/2?e\n",
      "1k?D(2\n",
      "2c(2c?1)2\n",
      ")T\n",
      "=e??\n",
      "?\n",
      "(c)T\n",
      ",\n",
      "i=1\n",
      "=2ln(2c?1)?ln2?\n",
      "11cln(2c)?ln((2c?1)2?2c)?(?2)ln2.222\n",
      "4\n",
      "(3)\n",
      "?\n",
      "ForT?ln2?m+ln(n/?),wehavee??(c)T?n2?m.Thus,withprobability\n",
      "1???(c)PTmaxi=1X(i)(a)>T/2,whichimpliesthatXOR\n",
      "K(w,k?c,\n",
      "T)returnstrue.\n",
      "?n2m,\n",
      "wehave\n",
      "a?A\n",
      "Claim2:TheproofisalmostthesameasClaim1,exceptthatweneedto\n",
      "useaunionboundtoletthepropertyholdforalla?Asimultaneously.Asa\n",
      "result,thesuccessprobabilitywillbe1?n?insteadof1?n2?m.Theproofis\n",
      "6\n",
      "\n",
      "lefttosupplementarymaterials.Proof.(Theorem3.2)Withprobability1?n\n",
      "n?=1??,theoutputofncallsofXOR\n",
      "K(w,k,T)(withtk=1...\n",
      "n)allsatisfythetwoclaimsinLemma3.3simultaneously.Supposemax#w(a)\n",
      "?[2k0,2k0+1),wehave(i)?k?k0+c+1,XOR\n",
      "K(w,k,T)returnsfalse,\n",
      "(ii)a?A\n",
      "?k?k0?c,XOR\n",
      "K(w,k,T)returnstrue.Therefore,withprobability1?\n",
      "?,theoutputofXOR\n",
      "MMAPisguaranteedtobeamong2k0?cand2k0+c.\n",
      "TheapproximationboundinTheorem3.2isaworst-caseguarantee.We\n",
      "canobtainatightbound(e.g.16-approx)withalargenumberofTreplicates.\n",
      "Nevertheless,wekeepasmallT,thereforealoosebound,inourexperiments,\n",
      "aftertradingbetweentheformalguaranteeandtheempiricalcomplexity.In\n",
      "practice,ourmethodperformswell,evenwithloosebounds.Moreover,XOR\n",
      "K\n",
      "procedureswithtinputkarenotuniformlyhard.Wethereforecanrun\n",
      "theminparallel.Wecanobtainalooserboundatanygiventime,basedon\n",
      "allcompletedXOR\n",
      "Kprocedures.Finally,ifwehaveaccesstoapolynomial\n",
      "approximationalgorithmfortheoptimizationprobleminXOR\n",
      "K,wecanprop-\n",
      "agatethisboundthroughtheanalysis,andagaingetaguaranteedbound,albeit\n",
      "looserfortheMMAPproblem.ReducetheNumberofReplicatesWefurtherde-\n",
      "velopafewvariantsofXOR\n",
      "MMAPinthesupplementarymaterialstoreduce\n",
      "thenumberofreplicates,aswellasthenumberofcallstotheXOR\n",
      "Kpro-\n",
      "cedure,whilepreservingthesameapproximationbound.ImplementationWe\n",
      "solvetheoptimizationprobleminXOR\n",
      "KusingMixedIntegerProgramming\n",
      "(MIP).Withoutlosinggenerality,weassumew(a,x)isanindicatorvariable,\n",
      "whichis1(a,x)satisesconstraintsrepresentedinConjunctiveNormalForm\n",
      "(CNF).WeintroduceextravariablesPtorepresentthesumiw(a,x(i))which\n",
      "isleftinthesupplementarymaterials.TheXORsinEquation2areencodedas\n",
      "MIPconstraintsusingtheYannakakisencoding,similarasin[7].3.2\n",
      "ExtensiontotheWeightedCase\n",
      "Inthissection,westudythemoregeneralcase,wherew(a,x)takesnon-\n",
      "negativerealnumbersinsteadofintegersin\n",
      "f\n",
      "0,1\n",
      "g\n",
      ".Unlikein[8],wechoose\n",
      "tobuildourprooffromtheunweightedcasebecauseitcanelyavoid\n",
      "modelingthemedianofanarrayofnumbers[6],whichistoencodein\n",
      "integerprogramming.Wenoticedrecentwork[4].Itisrelatedbutt\n",
      "fromourapproach.Letw:A?X?R+,andM=maxa,xw(a,x).\n",
      "3.4.WetheembeddingSa(w,l)ofXinX?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "las:\n",
      "w(a,x)2i?1Sa(w,l)=(x,y)|?1?i?l,?l?yi=0.M2\n",
      "(4)\n",
      "Lemma3.5.Letwl0(a,x,y)beanindicatorvariablewhichis1ifandonly\n",
      "if(x,y)isinSa(w,l),i.e.,wl0(a,x,y)=1(x,y)?Sa(w,l).Weclaimthatmax\n",
      "a\n",
      "Xx\n",
      "w(a,x)?\n",
      "XXMmaxwl0(a,x,y)?2maxw(a,x)+M2n?l.2la2ax\n",
      "(5)\n",
      "(x,y)\n",
      "7\n",
      "\n",
      "Proof.Sa(w,l,x0)asthesetof(x,y)pairswithinthesetSa(w,P\n",
      "l)andx=x0,ie,Sa(w,l,x0)=\n",
      "f\n",
      "(x,y)?Sa(w,l):x=x0\n",
      "g\n",
      ".Itisnothard\n",
      "toseethat(x,y)wl0(a,x,y)=Pbetweenx|Sa(w,l,x)|.Inthefollowing,\n",
      "wearegoingtoestablishtherelationshipP|Sa(w,l,x)|andw(a,x).\n",
      "Thenweusetheresulttoshowtherelationshipbetweenx|Sa(w,l,x)|2\n",
      "Ifwsatisfythepropertythatmina,xw(a,x)?2?l?1M,wedon?thavethe\n",
      "M2n?lterm.\n",
      "5\n",
      "P2i?1<andxw(x,a).Case(i):Ifw(a,x)issandwichedbetweentwo\n",
      "exponentiallevels:M2lMiw(a,x)?2l2fori?\n",
      "f\n",
      "0,1,...,l\n",
      "g\n",
      ",accordingto\n",
      "3.4,forany(x,y)?Sa(w,l,x),wehaveyi+1=yi+2=...=yl\n",
      "=0.Thismakes|Sa(w,l,x)|=2i,whichfurtherimpliesthatM|Sa(w,\n",
      "l,x)|M?<w(a,x)?l?|Sa(w,l,x)|,2l22\n",
      "(6)\n",
      "orequivalently,M?|Sa(w,l,x)|<2w(a,x).2lCase(ii):Ifw(a,x)?\n",
      "2Ml+1,wehave|Sa(w,l,x)|=1.Inotherwords,w(a,x)?\n",
      "w(a,x)?2w(a,x)?2\n",
      "(7)\n",
      "MM|Sa(w,l,x)|=l|Sa(w,l,x)|.2l+12\n",
      "(8)\n",
      "Also,M2?l|Sa(w,l,x)|=M2?l?2w(a,x)+M2?l.Hence,the\n",
      "followingboundholdsinbothcases(i)and(ii):M(9)w(a,x)?l|Sa(w,\n",
      "l,x)|?2w(a,x)+M2?l.2ThelemmaholdsbysummingupoverXand\n",
      "maximizingoverAonallsidesofInequality9.WiththeresultofLemma3.5,\n",
      "wearereadytoprovethefollowingapproximationresult:thereisanalgorithm\n",
      "thatgivesac-approximationtosolvetheunweightedTheorem3.6.SupposeP\n",
      "problem:maxa(x,y)wl0(a,x,y),thenwehavea3c-approximationalgorithm\n",
      "tosolvetheweightedPMarginalMAPproblemmaxaxw(a,x).Proof.Letl\n",
      "=ninLemma3.5.ByM=maxa,xw(a,x)?maxamaxa\n",
      "X\n",
      "w(a,x)?\n",
      "x\n",
      "Mmax2la\n",
      "X\n",
      "wl0(a,x,y)?2maxa\n",
      "(x,y)\n",
      "X\n",
      "P\n",
      "x\n",
      "w(a,x)+M?3maxa\n",
      "x\n",
      "w(a,x),wehave:X\n",
      "w(a,x).\n",
      "x\n",
      "Thisisequivalentto:X0XX0M1Mw(a,x)?lmax?lmaxwl(a,x,\n",
      "y)?maxwl(a,x,y).aaa322x(x,y)\n",
      "8\n",
      "\n",
      "4\n",
      "(x,y)\n",
      "Experiments\n",
      "WeevaluateourproposedalgorithmXOR\n",
      "MMAPagainsttwobaselines?\n",
      "theSampleAverageApproximation(SAA)[20]andtheMixedLoopyBelief\n",
      "Propagation(MixedLBP)[13].Thesetwobaselinesareselectedtorepresentthe\n",
      "twomostwidelyusedclassesofmethodsthatapproximatetheembeddedsum\n",
      "inMMAPproblemsintwotways.SAAapproximatestheintractable\n",
      "sumwithanumberofsamples,whiletheMixedLBPusesavariational\n",
      "approximation.WeobtainedtheMixedLBPimplementationfromtheauthorof\n",
      "[13]andweusetheirdefaultparametersettings.SinceMarginalMAPproblems\n",
      "areingeneralveryhardandthereiscurrentlynoexactsolverthatscalesto\n",
      "reasonablylargeinstances,ourmaincomparisonisontherelativeoptimality\n",
      "gap:weobtainPthesolutionamethodforeachPapproach.Thenwe\n",
      "comparethederenceinobjectivefunctionlogx?Xw(amethod,x)?logx?X\n",
      "w(abest,x),inwhichabestisthebestsolutionamongthethreemethods.\n",
      "Clearlyabetteralgorithmwillavectorawhichyieldsalargerobjective\n",
      "function.Thecountingproblemunderasolutionaissolvedusinganexact\n",
      "counterACE[5],whichisonlyusedforcomparingtheresultsoftMMAP\n",
      "solvers.Ourexperimentisonunweightedrandom2-SATinstances.Here,\n",
      "w(a,x)isanindicatorvariableonwhetherthe2-SATinstanceissatisable.\n",
      "TheSATinstanceshave60variables,20ofwhicharerandomlyselectedtoform\n",
      "setA,andtheremainingonesformsetX.Thenumberofclausesvariesfrom1\n",
      "to70.Foranumberofclauses,wePrandomlygenerate20instances,and\n",
      "theleftpanelofFigure1showsthemedianobjectivefunctionx?Xw(amethod\n",
      ",x)ofthesolutionsfoundbythethreeapproaches.Wetunetheconstantsof\n",
      "ourXOR\n",
      "MMAPsoitgivesa210=1024-approximation(2?5?sol?OPT?\n",
      "25?sol,?=10?3).Theupperandlowerboundsareshownindashedlines.\n",
      "SAAuses10,000samples.Onaverage,therunningtimeofouralgorithmis\n",
      "reasonable.When6\n",
      "40\n",
      "upperboundlowerboundMIXED\n",
      "LBPXOR\n",
      "MMAPSAA\n",
      "3020100\n",
      "%solwithin1/8OPT\n",
      "logofnumberofsolutions\n",
      "50MIXED\n",
      "LBPXOR\n",
      "MMAPSAA\n",
      "1.41.21.00.80.60.40.20.0\n",
      "0\n",
      "10\n",
      "2030405060Numberofclauses\n",
      "70\n",
      "0\n",
      "10\n",
      "2030405060Numberofclauses\n",
      "70\n",
      "?4\n",
      "9\n",
      "\n",
      "XORMMAPSAAMIXEDLBP\n",
      "?12\n",
      "1.0\n",
      "1.52.02.5CouplingStrength\n",
      "?20\n",
      "3.0\n",
      "3.5\n",
      "?250.5\n",
      "0?4\n",
      "?30\n",
      "XORMMAPSAAMIXEDLBP\n",
      "?15\n",
      "?2\n",
      "1.0\n",
      "1.52.02.5CouplingStrength\n",
      "?8\n",
      "XORMMAPSAAMIXEDLBP\n",
      "?10?12\n",
      "1.0\n",
      "1.52.02.5CouplingStrength\n",
      "?50\n",
      "3.0\n",
      "3.5\n",
      "0?5\n",
      "?250.5\n",
      "1.0\n",
      "1.52.02.5CouplingStrength\n",
      "3.0\n",
      "3.5\n",
      "3.0\n",
      "3.5\n",
      "0\n",
      "?20?30\n",
      "XORMMAPSAAMIXEDLBP\n",
      "?20\n",
      "3.5\n",
      "0.5\n",
      "?10\n",
      "?15\n",
      "3.0\n",
      "XORMMAPSAAMIXEDLBP\n",
      "?40\n",
      "?10\n",
      "?6\n",
      "?140.5\n",
      "?20\n",
      "10\n",
      "\n",
      "log#w(amethod)?log#w(abest)\n",
      "?8\n",
      "0\n",
      "?10\n",
      "?5\n",
      "?10\n",
      "?6\n",
      "?140.5\n",
      "0\n",
      "log#w(amethod)?log#w(abest)\n",
      "?2\n",
      "?10\n",
      "log#w(amethod)?log#w(abest)\n",
      "log#w(amethod)?log#w(abest)\n",
      "0\n",
      "log#w(amethod)?log#w(abest)\n",
      "log#w(amethod)?log#w(abest)\n",
      "Figure1:(Left)OnPmediancase,thesolutionsa0foundbytheproposed\n",
      "AlgorithmXOR\n",
      "MMAPhavehigherobjectivex?Xw(a0,x)thanthesolutions\n",
      "foundbySAAandMixedLBP,onrandom2-SATinstanceswith60variables\n",
      "andvariousnumberofclauses.Dashedlinesrepresenttheprovedboundsfrom\n",
      "XOR\n",
      "MMAP.(Right)Thepercentageofinstancesthateachalgorithmcan\n",
      "asolutionthatisatleast1/8valueofthebestsolutionsamong3algorithms,\n",
      "withtnumberofclauses.\n",
      "1.0\n",
      "1.52.02.5CouplingStrength\n",
      "XORMMAPSAAMIXEDLBP\n",
      "?40?50\n",
      "3.0\n",
      "3.5\n",
      "0.5\n",
      "1.0\n",
      "1.52.02.5CouplingStrength\n",
      "Figure2:Onmediancase,thesolutionsa0foundbytheproposedAlgo-\n",
      "rithmXOR\n",
      "MMAParebetterthanthesolutionsfoundbySAAandMixed\n",
      "LBP,onweighted12-by-12Isingmodelswithmixedcouplingstrength.(Up)\n",
      "Fieldstrength0.01.(Down)Fieldstrength0.1.(Left)20%variablesareran-\n",
      "domlyselectedformaximization.(Mid)50%formaximization.(Right)80%\n",
      "formaximization.enforcingthe1024-approximationbound,themediantime\n",
      "forasingleXOR\n",
      "kprocedureisinseconds,althoughweoccasionallyhavelong\n",
      "runs(nomorethan30-minutetimeout).Aswecanseefromtheleftpanelof\n",
      "Figure1,bothMixedLBPandSAAmatchtheperformanceofourproposed\n",
      "XOR\n",
      "MMAPoneasyinstances.However,asthenumberofclausesincreases,\n",
      "theirperformancequicklydeteriorates.Infact,forinstanceswithmorethan20\n",
      "(60)clauses,typicallytheavectorsreturnedbyMixedLBP(SAA)donotyield\n",
      "non-zerosolutionvalues.Thereforewearenotabletoplottheirperformance\n",
      "11\n",
      "\n",
      "beyondthetwovalues.Atthesametime,ouralgorithmXOR\n",
      "MMAPcanstill\n",
      "avectorayieldingover220solutionsonlargerinstanceswithmorethan\n",
      "60clauses,whileprovidinga1024-approximation.Next,welookattheperfor-\n",
      "manceofthethreealgorithmsonweightedinstances.Here,wesetthenumber\n",
      "ofreplicatesT=3forouralgorithmXOR\n",
      "MMAP,andwerepeatedlystartthe\n",
      "algorithmwithanincreasingnumberofXORconstraintsk,untilitcompletes\n",
      "forallkortimesoutinanhour.ForSAA,weuse1,000samples,whichisthe\n",
      "largestwecanusewithinthememorylimit.Allalgorithmsaregivenaone-\n",
      "hourtimeanda4Gmemorylimit.ThesolutionsfoundbyXOR\n",
      "MMAPare\n",
      "considerablybetterthantheonesfoundbyMixedLBPandSAAonweighted\n",
      "instances.Figure2showstheperformanceofthethreealgorithmson12-by-12\n",
      "Isingmodelswithmixedcouplingstrength,tstrengthsandnumber\n",
      "ofvariablestoformsetA.Allvaluesinthearemedianvaluesacross20\n",
      "instances(inlog10).Inall6casesinFigure2,ouralgorithmXOR\n",
      "MMAPis\n",
      "thebestamongthethreeapproximatealgorithms.Ingeneral,thein\n",
      "performanceincreasesasthecouplingstrengthincreases.Theseinstancesare\n",
      "challengingforthestate-of-the-artcompletesolvers.Forexample,thestate-of-\n",
      "the-artexactsolver7\n",
      "puv\n",
      "t=T\n",
      "t=2v\n",
      "uT\n",
      "S\n",
      "Log2Probability\n",
      "t=1\n",
      "?15\n",
      "SAAXOR\n",
      "MMAP\n",
      "?20?25?3030\n",
      "35\n",
      "40\n",
      "4550Budgets\n",
      "55\n",
      "60\n",
      "Figure3:(Left)Theimagecompletiontask.Solversaregivendigitsofthe\n",
      "upperpartasshownintherow.Solversneedtocompletethedigitsbased\n",
      "onatwo-layerdeepbeliefnetworkandtheupperpart.(2ndRow)completion\n",
      "givenbyXOR\n",
      "MMAP.(3rdRow)SAA.(4thRow)MixedLoopyBeliefProp-\n",
      "agation.(Middle)Graphicalillustrationofthenetworkcascadeproblem.Red\n",
      "circlesarenodestopurchase.Linesrepresentcascadeprobabilities.Seemain\n",
      "text.(Right)OurXOR\n",
      "MMAPperformsbetterthanSAAonasetofnetwork\n",
      "cascadebenchmarks,withtbudgets.AOBBwithmini-bucketheuristics\n",
      "andmomentmatching[14]runsoutof4Gmemoryon60%ofinstanceswith\n",
      "20%variablesrandomlyselectedasmaxvariables.Wealsonoticethatthesolu-\n",
      "tionfoundbyourXOR\n",
      "MMAPisalreadyclosetotheground-truth.Onsmaller\n",
      "10-by-10IsingmodelswhichtheexactAOBBsolvercancompletewithinthe\n",
      "memorylimit,themedianbetweenthelog10countofthesolutions\n",
      "12\n",
      "\n",
      "foundbyXOR\n",
      "MMAPandthosefoundbytheexactsolveris0.3,whilethedif-\n",
      "ferencesbetweenthesolutionvaluesofXOR\n",
      "MMAPagainstthoseoftheMixed\n",
      "BPorSAAareontheorderof10.WealsoapplytheMarginalMAPsolverto\n",
      "animagecompletiontask.Welearnatwo-layerdeepbeliefnetwork[3,10]\n",
      "froma14-by-14MNISTdataset.Thenforabinaryimagethatonlycontains\n",
      "theupperpartofadigit,weaskthesolvertocompletethelowerpart,basedon\n",
      "thelearnedmodel.ThisisaMarginalMAPtask,sinceoneneedstointegrate\n",
      "overthestatesofthehiddenvariables,andquerythemostlikelystatesofthe\n",
      "lowerpartoftheimage.Figure3showstheresultofafewdigits.Aswecansee,\n",
      "SAAperformspoorly.Inmostcases,itonlymanagestocomeupwithalight\n",
      "dotforall10tdigits.MixedLoopyBeliefPropagationandourproposed\n",
      "XOR\n",
      "MMAPperformwell.ThegoodperformanceofMixedLBPmaybedueto\n",
      "thefactthattheweightsonpairwisefactorsinthelearneddeepbeliefnetwork\n",
      "arenotverycombinatorial.Finally,weconsideranapplicationthatapplies\n",
      "decision-makingintomachinelearningmodels.Thisnetworkdesignapplication\n",
      "maximizesthespreadofcascadesinnetworks,whichisimportantinthedomain\n",
      "ofsocialnetworksandcomputationalsustainability.Inthisapplication,weare\n",
      "givenastochasticgraph,inwhichthesourcenodeattimet=0is\n",
      "Foranodevattimet,itwillbeifoneofitsancestornodesattimet\n",
      "?1isandtheoftheedgeconnectingthetwonodesis\n",
      "?on?.Anedgeconnectingnodeuandvhasprobabilitypu,vtobeturnedon.\n",
      "Anodewillnotbeifitisnotpurchased.Ourgoalistopurchasea\n",
      "setofnodeswithinabudget,soastomaximizetheprobabilitythatthe\n",
      "targetnodeisWereferthereaderto[20]formorebackgroundknowl-\n",
      "edge.Thisapplicationcannotbecapturedbygraphicalmodelsduetoglobal\n",
      "constraints.Therefore,wearenotabletorunmixedLBPonthisproblem.We\n",
      "considerasetofsyntheticnetworks,andcomparetheperformanceofSAAand\n",
      "ourXOR\n",
      "MMAPwithtbudgets.Aswecanseefromtherightpanelof\n",
      "Figure3,thenodesthatourXOR\n",
      "MMAPdecidestopurchaseresultinhigher\n",
      "probabilitiesofthetargetnodebeingcomparedtoSAA.Eachdotin\n",
      "theisthemedianvalueover30networksgeneratedinasimilarway.\n",
      "5\n",
      "Conclusion\n",
      "WeproposeXOR\n",
      "MMAP,anovelconstantapproximationalgorithmtosolve\n",
      "theMarginalMAPproblem.Ourapproachrepresentstheintractablecounting\n",
      "subproblemwithqueriestoNPoracles,subjecttoadditionalparityconstraints.\n",
      "Inouralgorithm,theentireproblemcanbesolvedbyasingleoptimization.\n",
      "Weevaluateourapproachonseveralmachinelearninganddecision-making\n",
      "applications.WeareabletoshowthatXOR\n",
      "MMAPoutperformsseveralstate-\n",
      "of-the-artMarginalMAPsolvers.XOR\n",
      "MMAPprovidesanewangletosolving\n",
      "theMarginalMAPproblem,openingthedoortonewresearchdirectionsand\n",
      "applicationsinrealworlddomains.AcknowledgmentsThisresearchwassup-\n",
      "portedbyNationalScienceFoundation(Awards#0832782,1522054,1059284,\n",
      "1649208)andFutureofLifeInstitute(Grant2015-143902).8\n",
      "13\n",
      "\n",
      "2References\n",
      "[1]DimitrisAchlioptasandPeiJiang.Stochasticintegrationviaerror-correcting\n",
      "codes.InProc.UncertaintyinIntelligence,2015.[2]VaishakBelle,\n",
      "GuyVandenBroeck,andAndreaPasserini.Hashing-basedapproximateproba-\n",
      "bilisticinferenceinhybriddomains.InProceedingsofthe31stUAIConference,\n",
      "2015.[3]YoshuaBengio,PascalLamblin,DanPopovici,andHugoLarochelle.\n",
      "Greedylayer-wisetrainingofdeepnetworks.InAdvancesinNeuralInformation\n",
      "ProcessingSystems19,2006.[4]SupratikChakraborty,DrorFried,Kuldeep\n",
      "S.Meel,andMosheY.Vardi.Fromweightedtounweightedmodelcounting.\n",
      "InProceedingsofthe24thInterationalJointConferenceonAI(IJCAI),2015.\n",
      "[5]MarkChavira,AdnanDarwiche,andManfredJaeger.Compilingrelational\n",
      "bayesiannetworksforexactinference.Int.J.Approx.Reasoning,2006.[6]\n",
      "StefanoErmon,CarlaP.Gomes,AshishSabharwal,andBartSelman.Embed\n",
      "andproject:Discretesamplingwithuniversalhashing.InAdvancesinNeural\n",
      "InformationProcessingSystems(NIPS),pages2085?2093,2013.[7]StefanoEr-\n",
      "mon,CarlaP.Gomes,AshishSabharwal,andBartSelman.Optimizationwith\n",
      "parityconstraints:Frombinarycodestodiscreteintegration.InProceedings\n",
      "oftheTwenty-NinthConferenceonUncertaintyinIntelligence,UAI,\n",
      "2013.[8]StefanoErmon,CarlaP.Gomes,AshishSabharwal,andBartSel-\n",
      "man.Tamingthecurseofdimensionality:Discreteintegrationbyhashingand\n",
      "optimization.InProceedingsofthe30thInternationalConferenceonMachine\n",
      "Learning,ICML,2013.[9]StefanoErmon,CarlaP.Gomes,AshishSabharwal,\n",
      "andBartSelman.Low-densityparityconstraintsforhashing-baseddiscrete\n",
      "integration.InProceedingsofthe31thInternationalConferenceonMachine\n",
      "Learning,ICML,2014.[10]HintonandRuslanSalakhutdinov.Reduc-\n",
      "ingthedimensionalityofdatawithneuralnetworks.Science,313(5786):504?\n",
      "507,2006.[11]JiarongJiang,PiyushRai,andHalDaum?III.Message-passing\n",
      "forapproximateMAPinferencewithlatentvariables.InAdvancesinNeural\n",
      "InformationProcessingSystems24,2011.[12]JunkyuLee,RaduMarinescu,\n",
      "RinaDechter,andAlexanderT.Ihler.Fromexacttoanytimesolutionsfor\n",
      "marginalMAP.InProceedingsoftheThirtiethAAAIConferenceon\n",
      "Intelligence,AAAI,2016.[13]QiangLiuandAlexanderT.Ihler.Variational\n",
      "algorithmsformarginalMAP.JournalofMachineLearningResearch,14,2013.\n",
      "[14]RaduMarinescu,RinaDechter,andAlexanderIhler.Pushingforward\n",
      "marginalmapwithbsearch.InProceedingsofthe24thInternational\n",
      "ConferenceonIntelligence(IJCAI),2015.[15]RaduMarinescu,Rina\n",
      "Dechter,andAlexanderT.Ihler.AND/ORsearchformarginalMAP.InPro-\n",
      "ceedingsoftheThirtiethConferenceonUncertaintyinIntelligence,\n",
      "UAI,2014.[16]DenisDerataniMau?andCassioPolpodeCampos.Anytime\n",
      "marginalMAPinference.InProceedingsofthe29thInternationalConference\n",
      "onMachineLearning,ICML,2012.[17]JamesD.ParkandAdnanDarwiche.\n",
      "Solvingmapexactlyusingsystematicsearch.InProceedingsoftheNineteenth\n",
      "ConferenceonUncertaintyinIntelligence(UAI),2003.[18]JamesD.\n",
      "ParkandAdnanDarwiche.Complexityresultsandapproximationstrategies\n",
      "formapexplanations.J.Artif.Int.Res.,2004.[19]WeiPing,QiangLiu,and\n",
      "14\n",
      "\n",
      "AlexanderT.Ihler.DecompositionboundsformarginalMAP.InAdvancesin\n",
      "NeuralInformationProcessingSystems28,2015.[20]DanielSheldon,Bistra\n",
      "N.Dilkina,AdamN.Elmachtoub,RyanFinseth,AshishSabharwal,JonCon-\n",
      "rad,CarlaP.Gomes,DavidB.Shmoys,WilliamAllen,OleAmundsen,and\n",
      "WilliamVaughan.Maximizingthespreadofcascadesusingnetworkdesign.In\n",
      "UAI,2010.[21]ShanXue,AlanFern,andDanielSheldon.Schedulingcon-\n",
      "servationdesignsformaximumyvianetworkcascadeoptimization.J.\n",
      "Artif.Intell.Res.(JAIR),2015.[22]YexiangXue,IanDavies,DanielFink,\n",
      "ChristopherWood,andCarlaP.Gomes.Avicaching:Atwostagegameforbias\n",
      "reductionincitizenscience.InProceedingsofthe15thInternationalConference\n",
      "onAutonomousAgentsandMultiagentSystems(AAMAS),2016.\n",
      "9\n",
      "15\n",
      "\n",
      "PP4659.pdf\n",
      "PP4659.pdf 19\n",
      "Topic-PartitionedMultinetworkEmbeddings\n",
      "Authoredby:\n",
      "HannaM.Wallach\n",
      "Peter\n",
      "JustonMoore\n",
      "BruceDesmarais\n",
      "Abstract\n",
      "Weintroduceajointmodelofnetworkcontentandcontextdesignedfor\n",
      "exploratoryanalysisofemailnetworksviavisualizationoftopic-sp\n",
      "communicationpatterns.Ourmodelisanadmixturemodelfortextand\n",
      "networkattributeswhichusesmultinomialdistributionsoverwordsas\n",
      "mixturecomponentsforexplainingtextandlatentEuclideanpositions\n",
      "ofactorsasmixturecomponentsforexplainingnetworkattributes.We\n",
      "validatetheappropriatenessofourmodelbyachievingstate-of-the-art\n",
      "performanceonalinkpredictiontaskandbyachievingsemanticcoher-\n",
      "enceequivalenttothatoflatentDirichletallocation.Wedemonstratethe\n",
      "capabilityofourmodelfordescriptive,explanatory,andexploratoryanal-\n",
      "ysisbyinvestigatingtheinferredtopic-spcommunicationpatternsof\n",
      "anewgovernmentemaildataset,theNewHanoverCountyemailcorpus.\n",
      "1PaperBody\n",
      "WeintroduceanewBayesianadmixturemodelintendedforexploratoryanal-\n",
      "ysisofcommunicationnetworks?sp,thediscoveryandvisualizationof\n",
      "topic-spsubnetworksinemaildatasets.Ourmodelproducesprincipled\n",
      "visualizationsofemailnetworks,i.e.,visualizationsthathaveprecisemathemat-\n",
      "icalinterpretationsintermsofourmodelanditsrelationshiptotheobserved\n",
      "data.Wevalidateourmodelingassumptionsbydemonstratingthatourmodel\n",
      "achievesbetterlinkpredictionperformancethanthreestate-of-the-artnetwork\n",
      "modelsandexhibitstopiccoherencecomparabletothatoflatentDirichletallo-\n",
      "cation.Weshowcaseourmodel?sabilitytodiscoverandvisualizetopic-spec\n",
      "communicationpatternsusinganewemaildataset:theNewHanoverCounty\n",
      "emailnetwork.Weprovideanextensiveanalysisofthesecommunicationpat-\n",
      "terns,leadingustorecommendourmodelforanyexploratoryanalysisofemail\n",
      "networksorothersimilarly-structuredcommunicationdata.Finally,weadvo-\n",
      "cateforprincipledvisualizationasaprimaryobjectiveinthedevelopmentof\n",
      "newnetworkmodels.\n",
      "1\n",
      "\n",
      "1\n",
      "Introduction\n",
      "Thestructuresoforganizationalcommunicationnetworksarecriticaltocol-\n",
      "laborativeproblemsolving[1].Althoughitisseldompossibleforresearchersto\n",
      "directlyobservecompleteorganizationalcommunicationnetworks,emaildata\n",
      "setsprovideonemeansbywhichtheycanatleastpartiallyobserveandreason\n",
      "aboutthem.Asaresult?andespeciallyinlightoftheirrichtextualdetail,exist-\n",
      "inginfrastructure,andwidespreadusage?emaildatasetsholdthepotentialto\n",
      "answermanyimportantscienandpracticalquestionswithintheorganiza-\n",
      "tionalandsocialsciences.Whilesomequestionsmaybeansweredbystudying\n",
      "thestructureofanemailnetworkasawhole,other,morenuanced,questionscan\n",
      "onlybeansweredatnerlevelsofgranularity?sp,bystudyingtopic-\n",
      "spsubnetworks.Forexample,breaksincommunication(orduplicated\n",
      "communication)aboutparticulartopicsmayindicateaneedforsomeformof\n",
      "organizationalrestructuring.Inordertofacilitatethestudyofthesekindsof\n",
      "questions,wepresentanewBayesianadmixturemodelintendedfordiscovering\n",
      "andsummarizingtopic-spcommunicationsubnetworksinemaildatasets.\n",
      "Thereareanumberofprobabilisticmodelsthatincorporatebothnetworkand\n",
      "textdata.Althoughsomeofthesemodelsarespforemailnetworks\n",
      "(e.g.,McCallumetal.?sauthor?recipient?topicmodel[2]),mostareintended\n",
      "fornetworksofdocuments,suchaswebpagesandthelinksbetweenthem[3]\n",
      "oracademicpapersandtheircitations[4].Incontrast,anemailnetworkis\n",
      "morenaturallyviewedasanetworkofactorsexchangingdocuments,i.e.,actors\n",
      "areassociatedwithnodeswhiledocumentsareassociatedwithedges.Inother\n",
      "words,anemailnetworkamultinetworkinwhichtheremaybemultiple\n",
      "edges(oneperemail)betweenanypairofactors.Perhapsmoreimportantly,\n",
      "muchoftherecentworkonmodelingnetworksandtexthasfocusedontasks\n",
      "suchas?\n",
      "WorkdoneattheUniversityofMassachusettsAmherst\n",
      "1\n",
      "=\n",
      "+\n",
      "+\n",
      "Figure1:Ourmodelpartitionsanobservedemailnetwork(left)intotopic-\n",
      "spsubnetworks(right)byassociatingeachauthor?recipientedgeinthe\n",
      "observednetworkwithasingletopic.predictinglinksordetectingcommu-\n",
      "nities.Instead,wetakeacomplementaryapproachandfocusonexploratory\n",
      "analysis.Sp,ourgoalistodiscoverandvisualizetopic-spsub-\n",
      "networks.Ratherthantakingatwo-stageapproachinwhichsubnetworksare\n",
      "discoveredusingonemodelandvisualizedusinganother,wepresentasingle\n",
      "probabilisticmodelthatpartitionsanobservedemailnetworkintotopic-sp\n",
      "subnetworkswhilesimultaneouslyproducingavisualrepresentationofeachsub-\n",
      "network.Ifnetworkmodelingandvisualizationareundertakenseparately,the\n",
      "resultantvisualizationsmaynotdirectlyreectthemodelanditsrelationshipto\n",
      "theobserveddata.Rather,thesevisualizationsprovideaviewofthemodeland\n",
      "thedataseenthroughthelensofthevisualizationalgorithmanditsassociated\n",
      "2\n",
      "\n",
      "assumptions,soanyconclusionsdrawnfromsuchvisualizationscanbebiased\n",
      "byartifactsofthevisualizationalgorithm.Producingprincipledvisualizations\n",
      "ofnetworks,i.e.,visualizationsthathavepreciseinterpretationsintermsofan\n",
      "associatednetworkmodelanditsrelationshiptotheobserveddata,remainsan\n",
      "openchallengeinstatisticalnetworkmodeling[5].Addressingthisopenchal-\n",
      "lengewasaprimaryobjectiveinthedevelopmentofournewmodel.Inorderto\n",
      "discoverandvisualizetopic-spsubnetworks,ourmodelmustassociateeach\n",
      "author?recipientedgeintheobservedemailnetworkwithatopic,asshownin\n",
      "Figure1.OurmodeldrawsuponideasfromlatentDirichletallocation(LDA)\n",
      "[6]toidentifyasetofcorpus-widetopicsofcommunication,aswellasthesubset\n",
      "oftopicsthatbestdescribeeachobservedemail.Wemodelnetworkstructure\n",
      "usinganapproachsimilartothatofetal.?slatentspacemodel(LSM)[7]\n",
      "soastofacilitatevisualization.Givenanobservednetwork,LSMassociates\n",
      "eachactorinthenetworkwithapointinK-dimensionalEuclideanspace.For\n",
      "anypairofactors,thesmallerthedistancebetweentheirpoints,themorelikely\n",
      "theyaretointeract.IfK=2orK=3,theseinteractionprobabilities,collec-\n",
      "tivelyknownasa?communicationpattern?,canbedirectlyvisualizedin2-or\n",
      "3-dimensionalspaceviathelocationsoftheactor-sppoints.Ourmodelex-\n",
      "tendsthisideabyassociatingaK-dimensionalEuclideanspacewitheachtopic.\n",
      "Observedauthor?recipientedgesareexplicitlyassociatedwithtopicsviathe\n",
      "K-dimensionaltopic-spcommunicationpatterns.Inthenextsection,we\n",
      "presentthemathematicaldetailsofournewmodelandoutlineacorresponding\n",
      "inferencealgorithm.Wethenintroduceanewemaildataset:theNewHanover\n",
      "County(NHC)emailnetwork.Althoughourmodelisintendedforexploratory\n",
      "analysis,wetestourmodelingassumptionsviathreevalidationtasks.InSection\n",
      "4.1,weshowthatourmodelachievesbetterlinkpredictionperformancethan\n",
      "threestate-of-the-artnetworkmodels.Wealsodemonstratethatourmodelis\n",
      "capableofinferringtopicsthatareascoherentasthoseinferredusingLDA.\n",
      "Together,theseexperimentsindicatethatourmodelisanappropriatemodelof\n",
      "networkstructureandthatmodelingthisstructuredoesnotcompromisetopic\n",
      "quality.Asavalidationexperiment,weshowthatsyntheticdatagenerated\n",
      "usingourmodelpossessessimilarnetworkstatisticstothoseoftheNHCemail\n",
      "network.InSection4.4,weshowcaseourmodel?sabilitytodiscoverandvisu-\n",
      "alizetopic-specccommunicationpatternsusingtheNHCnetwork.Wegive\n",
      "anextensiveanalysisofthesecommunicationpatternsanddemonstratethat\n",
      "theyprovideaccessiblevisualizationsofemailbasedcollaborationwhilepossess-\n",
      "ingprecise,meaningfulinterpretationswithinthemathematicalframeworkof\n",
      "ourmodel.Theseleadustorecommendourmodelforanyexploratory\n",
      "analysisofemailnetworksorothersimilarly-structuredcommunicationdata.\n",
      "Finally,weadvocateforprincipledvisualizationasaprimaryobjectiveinthe\n",
      "developmentofnewnetworkmodels.\n",
      "2\n",
      "Topic-PartitionedMultinetworkEmbeddings\n",
      "Inthissection,wepresentournewprobabilisticgenerativemodel(andasso-\n",
      "ciatedinferencealgorithm)forcommunicationnetworks.Forconcreteness,we\n",
      "frameourdiscussionofthismodelin2\n",
      "3\n",
      "\n",
      "termsofemaildata,althoughitisgenerallyapplicabletoanysimilarly-\n",
      "structuredcommunicationdata.Thegenerativeprocessandgraphicalmodel\n",
      "areprovidedinthesupplementarymaterials.(d)\n",
      "(d)\n",
      "Asingleemail,indexedbyd,isrepresentedbyasetoftokensw(d)=\n",
      "f\n",
      "wn\n",
      "g\n",
      "Nn=1thatcomprisethetextofthatemail,anintegera(d)?\n",
      "f\n",
      "1,...,A\n",
      "g\n",
      "indicatingtheidentityofthatemail?sauthor,anda(d)setofbinaryvariables\n",
      "y(d)=\n",
      "f\n",
      "yr\n",
      "g\n",
      "Ar=1indicatingwhethereachoftheAactorsinthenetworkis\n",
      "arecipientofthatemail.Forsimplicity,weassumethatauthorsdonotsend\n",
      "emailstothemselves(d)(i.e.,yr=0ifr=a(d)).Givenareal-worldemail\n",
      "datasetD=\n",
      "ff\n",
      "w(d),a(d),y(d)\n",
      "gg\n",
      "Dd=1,ourmodelpermitsinferenceofthe\n",
      "topicsexpressedinthetextoftheemails,asetoftopic-spK-dimensional\n",
      "embeddings(i.e.,pointsinK-dimensionalEuclideanspace)oftheAactorsinthe\n",
      "network,andapartitionofthefullcommunicationnetworkintoasetoftopic-\n",
      "spsubnetworks.AsinLDA[6],a?topic?tischaracterizedbyadiscrete\n",
      "distributionoverVwordtypeswithprobabilityvector?(t).Asymmetric\n",
      "Dirichletpriorwithconcentrationparameter?isplacedover?=\n",
      "f\n",
      "?(1),...,\n",
      "?(T)\n",
      "g\n",
      ".Tocapturetherelationshipbetweenthetopicsexpressedinanemailand\n",
      "thatemail?srecipients,eachtopictisalsoassociatedwitha?communication\n",
      "pattern?:anA?A(t)matrixofprobabilitiesP(t).Givenanemailabouttopic\n",
      "t,authoredbyactora,elementparistheprobabilityofactoraincludingactorr\n",
      "asarecipientofthatemail.InspiredbyLSM[7],eachcommunicationpatternP\n",
      "(t)isrepresentedimplicitlyviaasetofApointsinK-dimensionalEuclidean(t)\n",
      "(t)(t)(t)(t)(t)suchthatpar=pra=?(b(t)?ksa?srk)spaceS(t)=\n",
      "f\n",
      "sa\n",
      "g\n",
      "A\n",
      "a=1andascalarbiastermb(t)withsa?N(0,?12I)andb(t)?N(?,?22).1If\n",
      "K=2orK=3,thisrepresentationenableseachtopic-spcommunication\n",
      "patterntobevisualizedin2-or3-dimensionalspaceviathelocationsofthe\n",
      "pointsassociatedwiththeAactors.Itisworthnotingthatthedimensionsof\n",
      "each(t)K-dimensionalspacehavenoinherentmeaning.Inisolation,eachpoint\n",
      "saconveysnoinformation;however,thedistancebetweenanytwopointshas\n",
      "apreciseandmeaningfulinterpretationinthegenerativeprocess.Sp,\n",
      "therecipientsofanyemailassociatedwithtopictaremorelikelytobethose\n",
      "actorsneartotheemail?sauthorintheEuclideanspacecorrespondingtothat\n",
      "topic.Eachemail,indexedbyd,hasadiscretedistributionovertopics?(d)\n",
      ".AsymmetricDirichletprior(d)withconcentrationparameter?isplaced\n",
      "over?=\n",
      "f\n",
      "?(1),...,?(D)\n",
      "g\n",
      ".Eachtokenwnisassociated(d)(d)(d)(d)\n",
      "withatopicassignmentzn,suchthatzn??(d)andwn??(t)forzn=t.\n",
      "Ourmodeldoesnotincludeadistributionoverauthors;thegenerativeprocessis\n",
      "conditionedupontheiridentities.(d)Theemail-spbinaryvariablesy(d)=\n",
      "f\n",
      "yr\n",
      "g\n",
      "Ar=1indicatetherecipientsofemaildandthusthepresence(orabsence)\n",
      "ofemail-spedgesfromauthora(d)toeachoftheA?1otheractors.\n",
      "Consequently,theremaybemultipleedges(oneperemail)betweenanypairof\n",
      "actors,andDamultinetworkovertheentiresetofactors.Weassume\n",
      "thatthecompletemultinetworkcomprisesT(d)topic-spsubnetworks.In\n",
      "otherwords,eachyrisassociatedwithsometopictandtherefore(t)(d)with\n",
      "topic-spcommunicationpatternP(t)suchthatyr?Bern(par)fora(d)\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=a.Anatural(d)waytoassociateeachyrwithatopicwouldbetodrawa\n",
      "topicassignmentfrom?(d)inamanner(d)analogoustothegenerationof\n",
      "zn;however,asoutlinedbyBleiandJordan[8],thisapproachcanresultin\n",
      "theundesirablescenarioinwhichonesubsetoftopicsisassociatedwithtokens,\n",
      "whileanother(disjoint)subsetisassociatedwithedges.Additionally,models\n",
      "ofannotateddatathatpossessthisexchangeablestructuretendtoexhibitpoor\n",
      "generalization[3,8].Abetterapproach,advocated(d)byBleiandJordan,is\n",
      "todrawatopicassignmentforeachyrfromtheempiricaldistributionover(d)\n",
      "topicsbyz.Bythesetoftopicsassociatedwithedgeswill\n",
      "thereforebeasubsetofthetopicsassociatedwithtokens.Onewayofsimulating\n",
      "thisgenerativeprocessistoassociate(d)(d)eachyrwithapositionn=1,.\n",
      "..,max(1,N(d))andthereforewiththetopicassignmentznat(d)(d)\n",
      "thatposition2bydrawingapositionassignmentxr?U(1,...,max(1,N\n",
      "(d)))foreachyr.This(d)(t)(d)(d)indirectprocedureensuresthatyr?\n",
      "Bern(par)fora(d)=a,xr=n,andzn=t,asdesired.Thefunction?(?)is\n",
      "thelogisticfunction,whilethefunctionk?kisthel2-norm.Emailsthatdo\n",
      "notcontainanytext(i.e.,N(d)=0)conveyinformationaboutthefrequencies\n",
      "ofcommunicationbetweentheirauthorsandrecipients.Asaresult,wedonot\n",
      "omitsuchemailsfromD;instead,we(d)(d)augmenteachonewithasingle,\n",
      "?dummy?topicassignmentz1forwhichthereisnoassociatedtokenw1.1\n",
      "2\n",
      "3\n",
      "2.1\n",
      "Inference\n",
      "(d)DForreal-worlddataD=\n",
      "f\n",
      "w(d),a(d),y(d)\n",
      "g\n",
      "D\n",
      "g\n",
      "d=1,authorsA=\n",
      "d=1,thetokensW=\n",
      "f\n",
      "w(d)D(d)D\n",
      "f\n",
      "a\n",
      "g\n",
      "d=1,andrecipientsY=\n",
      "f\n",
      "y\n",
      "g\n",
      "d=1\n",
      "areobserved,while?,?,S=\n",
      "f\n",
      "S(t)\n",
      "g\n",
      "Tt=1,B=\n",
      "f\n",
      "b(t)\n",
      "g\n",
      "Tt=1,(d)DZ=\n",
      "f\n",
      "z\n",
      "(d)\n",
      "g\n",
      "D\n",
      "g\n",
      "d=1areunobserved.Dirichlet?multinomialconjugacyallows?d=1\n",
      ",andX=\n",
      "f\n",
      "xand?tobemarginalizedout[9],whiletypicalvaluesforthe\n",
      "remainingunobservedvariablescanbesampledfromtheirjointposteriordis-\n",
      "tributionusingMarkovchainMonteCarlomethods.Inthissection,weoutline\n",
      "aMetropolis-within-Gibbssamplingalgorithmthatoperatesbysequentially(t)\n",
      "(d)(d)resamplingthevalueofeachlatentvariable(i.e.,sa,bt,zn,orxr)\n",
      "fromitsconditionalposterior.(d)\n",
      "Sinceznisadiscreterandomvariable,newvaluesmaybesampleddirectly\n",
      "usingP(zn(d)=t|wn(d)=v,Wd,n,A,Y,S,B,Zd,n,X,?,?)?(v|t)\n",
      "yr(d)1?yr(d)+V?Q(t)(t)??(N(t|d)+?)Nd,n(p)(1?p)(d)(t)d,n\n",
      "Ta(d)ra(d)rr:xr=nNd,n+??(d)(d)?y1?yQrr?(t)(t)(1?pa(d)r)\n",
      "r:r6=a(d)(pa(d)r)\n",
      "forN(d)>0otherwise,\n",
      "wheresubscript?d,n?denotesaquantityexcludingdatafrompositionn\n",
      "inemaild.CountN(t)isthetotalnumberoftokensinWassignedtotopict\n",
      "byZ,ofwhichN(v|t)areoftypevandN(t|d)(d)belongtoemaild.New\n",
      "valuesfordiscreterandomvariablexrmaybesampleddirectlyusing(t)\n",
      "(d)P(x(d)r=n|A,Y,S,B,zn=t,Zd,n)?(pa(d)r)\n",
      "yr(d)\n",
      "5\n",
      "\n",
      "(t)\n",
      "(1?pa(d)r)\n",
      "1?yr(d)\n",
      ".\n",
      "(t)\n",
      "Newvaluesforcontinuousrandomvariablessaandb(t)cannotbesampled\n",
      "directlyfromtheirconditionalposteriors,butmayinsteadbeobtainedusing\n",
      "theMetropolis?Hastingsalgorithm.With(t)(t)(t)anon-informativeprior\n",
      "oversa(i.e.,sa?N(0,?)),theconditionalposterioroversaisYN(1|a,r,t)\n",
      "+N(1|r,a,t)N(0|a,r,t)+N(0|r,a,t)(t)(t)P(s(t)(p(t)(1?p(t),a|A,\n",
      "Y,Sa,b,Z,X)?ar)ar)r:r6=a\n",
      "wherecountN(1|a,r,t)=\n",
      "(d)\n",
      "PD\n",
      "(d)=a)1(yr=1)d=11(a\n",
      "N(d)n=1\n",
      "P\n",
      "(d)(d)1(xr=n)1(zn=t).3Counts\n",
      "N(1|r,a,t),N(0|a,r,t),andN(0|r,a,t)aresimilarly.Likewise,\n",
      "withanimproper,noninformativeprioroverb(t)(i.e.,b(t)?N(0,?)),the\n",
      "conditionalposterioroverb(t)isP(b(t)|A,Y,S(t),Z,X)?\n",
      "AYY\n",
      "(p(t)ar)\n",
      "N(1|a,r,t)+N(1|r,a,t)\n",
      "N(0|a,r,t)+N(0|r,a,t)\n",
      "(1?p(t)ar)\n",
      ".\n",
      "a=1r:r<a\n",
      "3\n",
      "Data\n",
      "Duetoavarietyoffactorsinvolvingpersonalprivacyconcernsandtheown-\n",
      "ershipofcontentbyemailserviceproviders,academicresearchersrarelyhave\n",
      "accesstoorganizationalemaildata.Forexample,theEnrondataset[10]?ar-\n",
      "guablythemostwidelystudiedemaildataset?wasonlyreleasedbecauseofa\n",
      "courtorder.Thepublicrecordisanalternativesourceoforganizationalemail\n",
      "data.Publicrecorddatasetsarewidelyavailableandcanbecontinuallyup-\n",
      "dated,yetremainrelativelyuntappedbytheacademiccommunity.Wetherefore\n",
      "introduceandanalyzeanewpublicrecordemaildatasetrelevanttoresearchers\n",
      "intheorganizationalandsocialsciencesaswellasmachinelearningresearchers.\n",
      "Thisdatasetconsistsofemailsbetweenthemanagersofthedepartmentsthat\n",
      "constitutetheexecutivearmofgovernmentatthecountylevelforNewHanover\n",
      "County,NorthCarolina.Inthissemi-autonomouslocalgovernment,county\n",
      "managersactasexecutives,andtheindividualdepartmentsaresynonymous\n",
      "withtheindividualdepartmentsandagenciesin,forinstance,theU.S.federal\n",
      "government.Therefore,notonlydoesthisemaildatasetaviewintothe\n",
      "communicationpatternsofthemanagersofNewHanoverCounty,butanalyses\n",
      "6\n",
      "\n",
      "ofitalsoserveascasestudiesinmodelinginter-agencycommunicationsinthe\n",
      "U.S.federalgovernmentadministration.3\n",
      "Thefunction1(?)evaluatestooneifitsargumentevaluatestotrueand\n",
      "evaluatestozerootherwise.\n",
      "4\n",
      "??\n",
      "??\n",
      "??\n",
      "?\n",
      "ourmodelEroshevabaseline20\n",
      "?\n",
      "MMSBbaseline1LSM\n",
      "50100150NumberofTopics\n",
      "(a)\n",
      "200\n",
      "??\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "??\n",
      "??\n",
      "???\n",
      "0.1\n",
      "?????\n",
      "??\n",
      "?\n",
      "?\n",
      "??\n",
      "0\n",
      "ourmodelEroshevabaseline2\n",
      "MMSBbaseline1LSM\n",
      "50100150NumberofTopics\n",
      "ourmodelEroshevabaseline2LDA\n",
      "?\n",
      "????\n",
      "???\n",
      "?\n",
      "???\n",
      "????\n",
      "???\n",
      "???\n",
      "???\n",
      "???\n",
      "200\n",
      "0\n",
      "7\n",
      "\n",
      "(b)\n",
      "AverageTopicCoherence?90?80?70?60?50\n",
      "??\n",
      "?\n",
      "ourmodelEroshevabaseline2LDA\n",
      "?????????\n",
      "????\n",
      "?110\n",
      "?\n",
      "?\n",
      "?\n",
      "??\n",
      "AverageTopicCoherence?90?80?70?60?50\n",
      "?\n",
      "?\n",
      "?\n",
      "AverageF1Score0.20.3\n",
      "?\n",
      "?\n",
      "?\n",
      "0.0\n",
      "AverageF1Score0.20.3\n",
      "?\n",
      "?\n",
      "?\n",
      "0.0\n",
      "0.1\n",
      "??\n",
      "?\n",
      "?110\n",
      "0.4\n",
      "0.4\n",
      "?\n",
      "?\n",
      "50100150NumberofTopics\n",
      "(c)\n",
      "200\n",
      "??\n",
      "???\n",
      "???\n",
      "0\n",
      "???\n",
      "50100150NumberofTopics\n",
      "???\n",
      "200\n",
      "(d)\n",
      "8\n",
      "\n",
      "Figure2:Averagelinkpredictionperformancefor(a)theNHCemailnet-\n",
      "workand(b)theEnrondataset.ForMMSBandLSM,weonlyreportresults\n",
      "obtainedusingthebest-performinghyperparametervalues.Averagetopicco-\n",
      "herencescoresfor(c)theNHCemailnetworkand(d)theEnrondataset.\n",
      "TheNewHanoverCounty(NHC)emailnetworkcomprisesthecompletein-\n",
      "boxesandoutboxesof30departmentmanagersfromthemonthofFebruary,\n",
      "2011.Intotal,thereare30,909emails,ofwhich8,097wereauthoredbyman-\n",
      "agers.Ofthese8,097emails,1,739weresenttoothermanagers(viathe?To?\n",
      "or?Cc?excludinganyemailssentfromamanagertohim-orherself\n",
      "only.Forourexperiments,weusedthese1,739emailsbetween30actors.To\n",
      "verifythatourmodelisapplicablebeyondtheNHCemailnetwork,wealso\n",
      "performedtwovalidationexperimentsusingtheEnronemaildataset[10].For\n",
      "thisdataset,wetreatedeachunique@enronemailaddressasanactorandused\n",
      "onlythoseemailsbetweenthe50mostactiveactors(determinedbythetotal\n",
      "numbersofemailssentandreceived).Emailsthatwerenotsenttoatleast\n",
      "oneotheractiveactor(viathe?To?or?Cc?werediscarded.Toavoid\n",
      "duplicateemails,weretainedonlythoseemailsfrom?sentmail?,?sent?,or\n",
      "?sentitems?folders.Thesestepsresultedinatotalof8,322emailsinvolving\n",
      "50actors.Bothdatasetswerepreprocessedtoconcatenatethetextofsubject\n",
      "linesandmessagebodiesandtoremoveanystopwords,URLs,quotedtext,\n",
      "and(wherepossible)signatures.\n",
      "4\n",
      "Experiments\n",
      "Ourmodelisprimarilyintendedasanexploratoryanalysistoolfororga-\n",
      "nizationalcommunicationnetworks.Inthissection,weusetheNHCemail\n",
      "networktoshowcaseourmodel?sabilitytodiscoverandvisualizetopic-sp\n",
      "communicationsubnetworks.First,however,wetestourunderlyingmodeling\n",
      "assumptionsviathreequantitativevalidationtasks,asrecommendedbySchrodt\n",
      "[11].4.1\n",
      "LinkPrediction\n",
      "Inordertogaugeourmodel?spredictiveperformance,weevaluateditsabil-\n",
      "itytopredicttherecipientsof?test?emails,fromeithertheNHCemailnetwork\n",
      "ortheEnrondataset,conditionedonthetextofthoseemailsandtheidentities\n",
      "oftheirauthors.Foreachtestemaild,thebinaryvariables(d)indicatingthe\n",
      "recipientsofthatemail,i.e.,\n",
      "f\n",
      "yr\n",
      "g\n",
      "Ar=1,weretreatedasunobserved.Typical\n",
      "valuesforthesevariablesweresampledfromtheirjointposteriordistribution\n",
      "andcomparedtothetruevaluestoyieldanF1score.Weformedatestsplit\n",
      "ofeachdatasetbyrandomlyselectingemailswithprobability0.1.Foreach\n",
      "dataset,weaveragedtheF1scoresovererandomtestsplits.Wecompared\n",
      "ourmodel?sperformancewiththatoftwobaselinesandthreeexistingnetwork\n",
      "models,therebysituatingitwithintheexistingliterature.Givenatestemail\n",
      "authoredbyactora,oursimplestbaselinena??velypredictsthatactorawill\n",
      "includeactorrasarecipientofthatemailwithprobabilityequaltothenumber\n",
      "ofnon-testemailssentfromactoratoactorrdividedbythetotalnumberof\n",
      "non-testemailssentbyactora.Oursecondbaselineisavariantofourmodel\n",
      "inwhicheachtopic-spcommunicationpatternP(t)isrepresentedexplic-\n",
      "9\n",
      "\n",
      "itlyviaA(A+1)/2probabilitiesdrawnfromasymmetricBetapriorwith\n",
      "concentrationparameter?.Comparingourmodeltothisvariantenablesusto\n",
      "validateourassumptionthattopic-spcommunicationpatternscanindeed\n",
      "beaccuratelyrepresentedbyasetofApoints(oneperactor)inK-dimensional\n",
      "Euclideanspace.Wealsocomparedourmodel?sperformancetothatofthree\n",
      "existingnetworkmodels:avariantofEroshevaetal.?smodelforanalyzing\n",
      "scienpublications[4],LSM[7],andthe5\n",
      "mixed-membershipstochasticblockmodel(MMSB)[12].Eroshevaetal.?s\n",
      "modelcanbeviewedas(d)avariantofourmodelinwhichthetopicassignment\n",
      "foreachyrisdrawnfrom?(d)insteadof(d)theempiricaldistributionover\n",
      "topicsbyz.Likeoursecondbaseline,eachtopic-spcommunication\n",
      "patternisrepresentedexplicitlyviaprobabilitiesdrawnfromasymmetricBeta\n",
      "priorwithconcentrationparameter?;however,unlikethisbaseline,eachone\n",
      "isrepresentedusingAprob(t)(t)abilitiessuchthatpar=pr.LSMcanbe\n",
      "viewedasanetwork-onlyvariantofourmodelinwhichtextisnotmodeled.Asa\n",
      "result,therearenotopicsandasinglecommunicationpatternP.Thispattern\n",
      "isrepresentedimplicitlyviaasetofAactor-sppointsinK-dimensional\n",
      "Euclideanspace.Finally,MMSBisawidely-usedmodelformixed-membership\n",
      "communitydiscoveryinnetworks.(d)\n",
      "Forourmodelandallitsvariants,typicalvaluesfor\n",
      "f\n",
      "yr\n",
      "g\n",
      "Ar=1canbe\n",
      "sampledfromtheirjointposteriordistributionusinganappropriately-moed\n",
      "versionoftheMetropolis-within-GibbsalgorithminSection2.1.Inallour\n",
      "experiments,weranthisalgorithmfor40,000?50,000iterations.Oniteration\n",
      "i,weeachproposaldistributiontobeaGaussiandistributioncentered\n",
      "onthevaluefromiterationi?1withcovariancematrixmax(1,100/i)\n",
      "I,therebyresultinginlargercovariancesforearlieriterations.Beta?binomial\n",
      "conjugacyallowstheelementsofP(t)tobemarginalizedoutinbothour\n",
      "secondbaselineandEroshevaetal.?smodel.ForMMSB,typicalvaluescan\n",
      "besampledusingamoversionofChang?sGibbssamplingalgorithm[13].\n",
      "Weranthisalgorithmfor5,000iterations.Forallmodelsinvolvingtopics,we\n",
      "setconcentrationparameter?to1fortheNHCnetworkand2fortheEnron\n",
      "dataset.Forbothdatasets,wesetconcentrationparameter?to0.01V.4We\n",
      "variedthenumberoftopicsfrom1to200.Inordertofacilitatevisualization,\n",
      "weused2-dimensionalEuclideanspacesforourmodel.ForLSM,however,we\n",
      "variedthedimensionalityoftheEuclideanspacefrom1to200.Wereportonly\n",
      "thoseresultsobtainedusingthebest-performingdimensionality.Foroursecond\n",
      "baselineandEroshevaetal.?smodel,wesetconcentrationparameter?to0.02.\n",
      "ForMMSB,weperformedagridsearchoverallhyperparametervaluesandthe\n",
      "numberofblocksand,aswithLSM,reportonlythoseresultsobtainedusing\n",
      "thebest-performingvalues.5F1scores,averagedovererandomtestsplits\n",
      "ofeachdataset,areshowninFigure2.Althoughourmodelisintendedfor\n",
      "exploratoryanalysis,itachievesbetterlinkpredictionperformancethanthe\n",
      "othermodels.Furthermore,thefactthatourmodeloutperformsoursecond\n",
      "baselineandEroshevaetal.?smodelvalidatesourassumptionthattopic-sp\n",
      "communicationpatternscanindeedbeaccuratelyrepresentedbyasetofA\n",
      "actor-sppointsin2-dimensionalEuclideanspace.4.2\n",
      "10\n",
      "\n",
      "TopicCoherence\n",
      "Whenevaluatingunsupervisedtopicmodels,topiccoherencemetrics[14,\n",
      "15]areoftenusedasaproxyforsubjectiveevaluationofsemanticcoherence.\n",
      "Inordertodemonstratethatincorporatingnetworkdatadoesnotimpairour\n",
      "model?sabilitytomodeltext,wecomparedthecoherenceoftopicsinferred\n",
      "usingourmodelwiththecoherenceoftopicsinferredusingLDA,oursecond\n",
      "baseline,andEroshevaetal.?smodel.Foreachmodel,wevariedthenumberof\n",
      "topicsfrom1to200anddrewesamplesfromthejointposteriordistribution\n",
      "overtheunobservedrandomvariablesinthatmodel.Weevaluatedthetopics\n",
      "resultingfromeachsampleusingMimnoetal.?scoherencemetric[14].Topic\n",
      "coherence,averagedovertheesamples,isshowninFigure2.Ourmodel\n",
      "achievescoherencecomparabletothatofLDA.Thisresult,whencombined\n",
      "withtheresultsinSection4.1,demonstratesthatourmodelcanachievestate-\n",
      "of-the-artpredictiveperformancewhileproducingcoherenttopics.4.3\n",
      "PosteriorPredictiveChecks\n",
      "Weusedposteriorpredictivecheckingtoassesstheextenttowhichour\n",
      "modelisa?goodfortheNHCemailnetwork[16,17].Sp,we\n",
      "fournetworkstatistics(i.e.,fourdiscrepancyfunctions)thatsummarize\n",
      "meaningfulaspectsoftheNHCnetwork:generalizedgraphtransitivity,thedyad\n",
      "intensitydistribution,thevertexdegreedistribution,andthegeodesicdistance\n",
      "distribution.6Wethengenerated1,000syntheticnetworksfromtheposterior\n",
      "predictivedistributionimpliedbyour4Thesevalueswereobtainedbyslice\n",
      "samplingtypicalvaluesfortheconcentrationparametersinLDA.Theyare\n",
      "consistentwiththeconcentrationparametervaluesusedinpreviouswork[9].5\n",
      "ThesevaluescorrespondtoaDir(0.1,...,0.1)prioroverblockmemberships,\n",
      "aBeta(0.1,0.1)prioroverdiagonalentriesoftheblockmodel,aBeta(0.01,0.01)\n",
      "prioroverentries,and30blocks.6Thesestatisticsarein\n",
      "thesupplementarymaterials.\n",
      "6\n",
      "50\n",
      "60\n",
      "??\n",
      "40\n",
      "0.655\n",
      "0.665\n",
      "Transitivity\n",
      "(a)\n",
      "400200\n",
      "0\n",
      "0.645\n",
      "600\n",
      "?\n",
      "??????\n",
      "20\n",
      "0\n",
      "SimulatedQuantile\n",
      "11\n",
      "\n",
      "100\n",
      "1.2\n",
      "800Degree\n",
      "SimulatedQuantile\n",
      "Frequency\n",
      "150\n",
      "1.4\n",
      "??\n",
      "80\n",
      "200\n",
      "????\n",
      "??????\n",
      "?????\n",
      "00\n",
      "20\n",
      "40\n",
      "????????????\n",
      "??????\n",
      "60\n",
      "1.00.80.60.40.20.00.00.20.40.60.81.01.2\n",
      "ObservedQuantile\n",
      "Actor(SortedbyObservedDegree)\n",
      "(b)\n",
      "(c)\n",
      "ObservedQuantile\n",
      "(d)\n",
      "Figure3:FourposteriorpredictivechecksofourmodelusingtheNHCemail\n",
      "networkand100topics:(a)ahistogramofthegraphtransitivityofthesynthetic\n",
      "networks,withthegraphtransitivityoftheNHCemailnetworkindicatedbya\n",
      "verticalline;(b)aquantile?quantileplotcomparingthedistributionofdyadic\n",
      "intensitiesinthesyntheticnetworkstothatoftheobservednetwork;(c)abox\n",
      "plotindicatingthesampleddegreeofeachmanagerinthesyntheticnetworks,\n",
      "withmanagerssortedfromhighesttolowestobserveddegreeandtheirobserved\n",
      "degreesindicatedbyaline;and(d)aquantile?quantileplotcomparingthe\n",
      "observedandsyntheticgeodesicdistancedistributions.\n",
      "modelandtheNHCnetwork.Weappliedeachdiscrepancyfunctiontoeach\n",
      "syntheticnetworktoyieldfourdistributionsoverthevaluesofthefournetwork\n",
      "statistics.Ifourmodelisa?goodfortheNHCnetwork,thesedistributions\n",
      "shouldbecenteredaroundthevaluesofthecorrespondingdiscrepancyfunc-\n",
      "tionswhencomputedusingtheobservedNHCnetwork.AsshowninFigure\n",
      "3,ourmodelgeneratessyntheticnetworkswithdyadintensity,vertexdegree,\n",
      "andgeodesicdistancedistributionsthatareverysimilartothoseoftheNHC\n",
      "network.Thedistributionoversyntheticgraphtransitivityvaluesisnotcen-\n",
      "teredaroundtheobservedgraphtransitivity,buttheobservedtransitivityisnot\n",
      "tlyfarintothetailofthedistributiontowarrantreparameterizationof\n",
      "ourmodel.4.4\n",
      "12\n",
      "\n",
      "ExploratoryAnalysis\n",
      "Inordertodemonstrateourmodel?snovelabilitytodiscoverandvisualize\n",
      "topic-spcommunicationpatterns,weperformedanexploratoryanalysis\n",
      "offoursuchpatternsinferredfromtheNHCemailnetworkusingourmodel.\n",
      "ThesepatternsarevisualizedinFigure4.Eachpatternisrepresentedimplicitly\n",
      "viaasinglesetofApointsin2-dimensionalEuclideanspacedrawnfromtheir\n",
      "jointposteriordistribution.Therecipientsofanyemailassociatedwithtopict\n",
      "aremorelikelytobethoseactorsneartotheemail?sauthorintheEuclidean\n",
      "spacecorrespondingtothattopic.WeselectedthepatternsinFigure4soas\n",
      "tohighlightthetypesofinsightsthatcanbeobtainedusingourmodel.Al-\n",
      "thoughmanystructuralpropertiesmaybeofinterest,wefocusonmodularity\n",
      "andassortativity.Foreachtopic-spcommunicationpattern,weexamined\n",
      "whetherthereareactive,disconnectedcomponentsinthattopic?sEuclidean\n",
      "space(i.e.,highmodularity).Thepresenceofsuchcomponentsindicatesthat\n",
      "therearegroupsofactorswhoengageinwithin-butnotbetween-groupcom-\n",
      "municationaboutthattopic.Wealsousedacombinationofnodeproximity\n",
      "andnodecolorationtodeterminewhetherthereismorecommunicationbetween\n",
      "departmentsthatbelongtothesame?division?intheNewHanoverCounty\n",
      "governmentorganizationalchartthanbetweendepartmentswithintdi-\n",
      "visions(i.e.,assortativity).InFigure4,weshowonetopicthatexhibitsstrong\n",
      "modularityandlittleassortativity(the?PublicSignage?topic),onetopicthat\n",
      "exhibitsstrongassortativityandlittlemodularity(the?BroadcastMessages?\n",
      "topic),andonetopicthatexhibitsbothstrongassortativityandstrongmodu-\n",
      "larity(the?MeetingScheduling?topic).The?PublicRelations?topic,which\n",
      "includescommunicationwithnewsagencies,ismostlydominatedbyacluster\n",
      "involvingmanydepartments.Finally,the?MeetingScheduling?topicdisplays\n",
      "hierarchicalstructure,withtwoassistantcountymanagerslocatedatthecenters\n",
      "ofgroupsthatcorrespondtotheirdivisions.Exploratoryanalysisofcommunica-\n",
      "tionpatternsisapowerfultoolforunderstandingorganizationalcommunication\n",
      "networks.Forexample,examiningassortativitycanrevealwhetheractualcom-\n",
      "municationpatternsresembleorganizationalstructures.Similarly,ifa\n",
      "communicationpatternexhibitsmodularity,eachdisconnectedcomponentmay\n",
      "bfromorganizationaltofacilitateinter-componentcommunication.\n",
      "Finally,structuralpropertiesotherthanassortativityandmodularitymayalso\n",
      "yieldscienorpracticalinsights,dependingonorganizationalneeds.7\n",
      "PublicSignage\n",
      "BroadcastMessages\n",
      "15changesignssignprocessordinance\n",
      "17fwfyibulletinsummaryweeklegislative?PM\n",
      "CC?\n",
      "400\n",
      "300\n",
      "HL?\n",
      "?AMSF?\n",
      "?PS?DS\n",
      "200\n",
      "13\n",
      "\n",
      "EG?\n",
      "?EG\n",
      "LB?\n",
      "AM?\n",
      "?DS?FN\n",
      "PS?\n",
      "100\n",
      "200\n",
      "?PI\n",
      "TX?\n",
      "?BG\n",
      "LB?\n",
      "FS?\n",
      "0\n",
      "?HR\n",
      "MS?\n",
      "?CM\n",
      "RD?\n",
      "AMAMEMPG?\n",
      "?IT\n",
      "CE?\n",
      "EM?\n",
      "RD?\n",
      "PG?\n",
      "CA?\n",
      "CC?\n",
      "SF?\n",
      "?\n",
      "TX?\n",
      "FS?\n",
      "?300\n",
      "?SS\n",
      "?\n",
      "?\n",
      "?200\n",
      "EV?\n",
      "?IT\n",
      "MS?\n",
      "?100\n",
      "?PM\n",
      "?200\n",
      "?RM\n",
      "0?BGEL?\n",
      "?400\n",
      "?EV\n",
      "?CM\n",
      "14\n",
      "\n",
      "CA?\n",
      "?FN\n",
      "?YS?PI?SS\n",
      "RM?\n",
      "YS?\n",
      "?VS\n",
      "?HL\n",
      "HR?\n",
      "VS?\n",
      "EL?\n",
      "CE?\n",
      "?400\n",
      "?200\n",
      "0\n",
      "200\n",
      "400\n",
      "?300\n",
      "?200\n",
      "?100\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "PublicRelations\n",
      "MeetingScheduling\n",
      "31citybreakdowninformationgive\n",
      "63meetingmarchboardagendaweek\n",
      "EL?\n",
      "FS?\n",
      "400\n",
      "400\n",
      "SF?CA?\n",
      "PS?RM?\n",
      "200\n",
      "200\n",
      "RD?EG?\n",
      "RM?\n",
      "?HR\n",
      "?MSPI?\n",
      "?DS\n",
      "0\n",
      "FS?CE?EV?\n",
      "?CM\n",
      "?ELPG?\n",
      "RD?\n",
      "?TX\n",
      "15\n",
      "\n",
      "CC?\n",
      "?LB\n",
      "?CE\n",
      "?EM\n",
      "?AM\n",
      "?HRBG?\n",
      "?FN\n",
      "?HL\n",
      "0\n",
      "?PM??SSLB?HL\n",
      "?EM?AM?\n",
      "?200\n",
      "IT?PG?BG\n",
      "CA?\n",
      "MS?\n",
      "?200\n",
      "?PS\n",
      "?CM\n",
      "?EG\n",
      "?SS\n",
      "IT?\n",
      "TX?\n",
      "0\n",
      "?\n",
      "?600\n",
      "?400\n",
      "CC?\n",
      "?400\n",
      "AM\n",
      "YS?\n",
      "?AM\n",
      "VS?\n",
      "DS\n",
      "?PI\n",
      "?200\n",
      "?FN\n",
      "YS??\n",
      "?400\n",
      "?PM\n",
      "VS?\n",
      "SF?\n",
      "AssistantCountyManagerBudgetCooperativeExtensionCountyAttorney\n",
      "CountyCommissionersCountyManagerDevelopmentServicesElectionsEmer-\n",
      "gencyManagementEngineeringEnvironmentalManagementFinanceFireSer-\n",
      "vicesHealthHumanResourcesInformationTechnologyLibraryMuseumParks\n",
      "andGardensPlanningandInspectionsPretrialReleaseScreeningProperty\n",
      "16\n",
      "\n",
      "ManagementRegisterofDeedsRiskManagementSocialServicesTax\n",
      "?VeteranServicesYouthEmpowermentServices\n",
      "AMBGCECACCCMDSELEMEGEVFNFSHLHRITLBMSPG\n",
      "PIPSPMRDRMSFSSTXVSYS\n",
      "EV?\n",
      "200\n",
      "400\n",
      "600\n",
      "?200\n",
      "0\n",
      "200\n",
      "400\n",
      "Figure4:Fourtopic-spcommunicationpatternsinferredfromtheNHC\n",
      "emailnetwork.Eachpatternislabeledwithahuman-selectednameforthe\n",
      "correspondingtopic,alongwiththattopic?smostprobablewordsinorderof\n",
      "decreasingprobability.Thesizeofeachmanager?sacronyminq(t)\n",
      "(t)\n",
      "(t)\n",
      "topict?spattern(givenby0.45+1.25da/maxada,wheredaisthedegree\n",
      "ofactorainthatsubnetwork)indicateshowoftenthatmanagercommunicates\n",
      "aboutthattopic.Managers?acronymsarecoloredaccordingtotheirrespective\n",
      "divisionintheNewHanoverCountyorganizationalchart.Theacronym?AM?\n",
      "appearstwiceinallplotsbecausetherearetwoassistantcountymanagers.\n",
      "5\n",
      "Conclusions\n",
      "WeintroducedanewBayesianadmixturemodelforthediscoveryandvi-\n",
      "sualizationoftopic-spcommunicationsubnetworks.Althoughourmodel\n",
      "isintendedforexploratoryanalysis,thevalidationexperimentsdescribedin\n",
      "Sections4.1and4.2demonstratethatourmodelcanachievestateof-the-art\n",
      "predictiveperformancewhileexhibitingtopiccoherencecomparabletothatof\n",
      "LDA.Toshowcaseourmodel?sabilitytodiscoverandvisualizetopic-sp\n",
      "communicationpatterns,weintroducedanewdataset(theNHCemailnet-\n",
      "work)andanalyzedfoursuchpatternsinferredfromthisdatasetusingour\n",
      "model.Viathisanalysis,wereareabletoexaminetheextenttowhichactual\n",
      "communicationpatternsresembleorganizationalstructuresandidentify\n",
      "groupsofmanagerswhoengageinwithin-butnotbetween-groupcommunica-\n",
      "tionaboutcertaintopics.Together,thesepredictiveandexploratoryanalyses\n",
      "leadustorecommendourmodelforanyexploratoryanalysisofemailnetworks\n",
      "orothersimilarly-structuredcommunicationdata.Finally,ourmodeliscapa-\n",
      "bleofproducingprincipledvisualizationsofemailnetworks,i.e.,visualizations\n",
      "thathaveprecisemathematicalinterpretationsintermsofthismodelandits\n",
      "relationshiptotheobserveddata.Weadvocateforprincipledvisualizationas\n",
      "aprimaryobjectiveinthedevelopmentofnewnetworkmodels.\n",
      "AcknowledgmentsThisworkwassupportedinpartbytheCenterforIn-\n",
      "telligentInformationRetrievalandinpartbytheNSFGRFPundergrant\n",
      "17\n",
      "\n",
      "#1122374.Anyopinions,andconclusionsorrecommendationsex-\n",
      "pressedinthismaterialarethoseoftheauthorsanddonotnecessarily\n",
      "thoseofthesponsors.8\n",
      "2References\n",
      "[1]W.MasonandD.J.Watts.Collaborativelearninginnetworks.Proceedings\n",
      "oftheNationalAcademyofSciences,109(3):764?769,2012.[2]A.McCal-\n",
      "lum,A.Corrada-Emmanuel,andX.Wang.Topicandrolediscoveryinsocial\n",
      "networks.InProceedingsoftheInternationalJointConferenceon\n",
      "Intelligence,2005.[3]J.ChangandD.M.Blei.Relationaltopicmodelsfor\n",
      "documentnetworks.InProceedingsoftheTwelfthInternationalConferenceon\n",
      "IntelligenceandStatistics,2009.[4]E.Erosheva,S.Fienberg,and\n",
      "J.y.Mixed-membershipmodelsofscienpublications.Proceedings\n",
      "oftheNationalAcademyofSciences,101(Suppl.1),2004.[5]S.EFienberg.\n",
      "Abriefhistoryofstatisticalmodelsfornetworkanalysisandopenchallenges.\n",
      "JournalofComputationalandGraphicalStatistics,22,2012.[6]D.M.Blei,\n",
      "A.Y.Ng,andM.I.Jordan.LatentDirichletallocation.JournalofMachine\n",
      "LearningResearch,3:993?1022,2003.[7]P.D.A.E.Raftery,andM.S.\n",
      "Handcock.Latentspaceapproachestosocialnetworkanalysis.Journalofthe\n",
      "AmericanStatisticalAssociation,97(460):1090?1098,2002.[8]D.M.Bleiand\n",
      "M.I.Jordan.Modelingannotateddata.InProceedingsoftheTwenty-Sixth\n",
      "AnnualInternationalACMSIGIRConferenceonResearchandDevelopmentin\n",
      "InformationRetrieval,pages127?134,2003.[9]T.L.andM.Steyvers.\n",
      "Findingscientopics.ProceedingsoftheNationalAcademyofSciences,\n",
      "101(Suppl.1),2004.[10]B.KlimtandY.Yang.IntroducingtheEnroncorpus.\n",
      "InProceedingsoftheFirstConferenceonEmailandAnti-Spam,2004.[11]\n",
      "P.ASchrodt.Sevendeadlysinsofcontemporaryquantitativepoliticalanalysis.\n",
      "InProceedingsoftheAnnualAmericanPoliticalScienceAssociationMeeting\n",
      "andExhibition,2010.[12]E.M.Airoldi,D.M.Blei,S.E.Fienberg,andE.P.\n",
      "Xing.Mixedmembershipstochasticblockmodels.JournalofMachineLearning\n",
      "Research,9:1981?2014,2008.[13]J.Chang.Uncovering,Understanding,and\n",
      "PredictingLinks.PhDthesis,PrincetonUnversity,2011.[14]D.Mimno,H.M.\n",
      "Wallach,E.T.M.Leenders,andA.McCallum.Optimizingsemanticcoherence\n",
      "intopicmodels.InProceedingsoftheConferenceonEmpiricalMethodsin\n",
      "NaturalLanguageProcessing,2011.[15]D.Newman,J.H.Lau,K.Grieser,\n",
      "andT.Baldwin.Automaticevaluationoftopiccoherence.InProceedingsof\n",
      "HumanLanguageTechnologies:TheAnnualConferenceoftheNorthAmerican\n",
      "ChapteroftheAssociationforComputationalLinguistics,pages100?108,2010.\n",
      "[16]D.R.Hunter,M.S.Handcock,C.T.Butts,S.M.Goodreau,andM.Morris.\n",
      "ergm:Apackagetosimulateanddiagnoseexponential-familymodelsfor\n",
      "networks.JournalofStatisticalSoftware,24(3):1?29,2008.[17]D.Mimnoand\n",
      "D.M.Blei.Bayesiancheckingfortopicmodels.InProceedingsoftheCon-\n",
      "ferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages227?237,\n",
      "2011.\n",
      "18\n",
      "\n",
      "9\n",
      "19\n",
      "\n",
      "PP5235.pdf\n",
      "PP5235.pdf 14\n",
      "ParallelSamplingofHDPsusingSub-Cluster\n",
      "Splits\n",
      "Authoredby:\n",
      "JohnW.FisherIII\n",
      "JasonChang\n",
      "Abstract\n",
      "WedevelopasamplingtechniqueforHierarchicalDirichletprocess\n",
      "models.Theparallelalgorithmbuildsupon[Chang&Fisher2013]by\n",
      "proposinglargesplitandmergemovesbasedonlearnedsub-clusters.The\n",
      "additionalglobalsplitandmergemovesdrasticallyimproveconvergencein\n",
      "theexperimentalresults.Furthermore,wediscoverthatcross-validation\n",
      "techniquesdonotadequatelydetermineconvergence,andthatprevious\n",
      "samplingmethodsconvergeslowerthanwerepreviouslyexpected.\n",
      "1PaperBody\n",
      "HierarchicalDirichletProcess(HDP)mixturemodelswerestintroducedby\n",
      "Tehetal.[2].HDPsextendtheDirichletProcess(DP)tomodelgroupsofdata\n",
      "withsharedclusterstatistics.Sincetheirinception,HDPsandrelatedmodels\n",
      "havebeenusedinmanystatisticalproblems,includingdocumentanalysis[2],\n",
      "objectcategorization[3],andasapriorforhiddenMarkovmodels[4].Thesuc-\n",
      "cessofHDPshasgarneredmuchinterestininferencealgorithms.Variational\n",
      "techniques[5,6]areoftenusedfortheirparallelizationandspeed,butlackthe\n",
      "limitingguaranteesofMarkovchainMonteCarlo(MCMC)methods.Unfor-\n",
      "tunately,MCMCalgorithmstendtoconvergeslowly.Inthiswork,weextend\n",
      "therecentDPSub-Clusteralgorithm[1]toHDPstoaccelerateconvergenceby\n",
      "inferring?sub-clusters?inparallelandusingthemtoproposelargesplitmoves.\n",
      "ExtensionstotheHDParecomplicatedbytheadditionalDP,whichviolates\n",
      "conjugacyassumptionsusedin[1].Furthermore,split/mergemovesrequire\n",
      "computingthejointmodellikelihood,which,priortothiswork,wasunknown\n",
      "inthecommonDirectAssignmentHDPrepresentation[2].Wediscoverthat\n",
      "toverlapinclusterdistributionsnecessitatesnewglobalsplit/merge\n",
      "movesthatchangeallclusterssimultaneously.Ourexperimentsonsynthetic\n",
      "andreal-worlddatavalidatetheimprovedconvergenceoftheproposedmethod.\n",
      "Additionally,ouranalysisofjointsummarystatisticssuggeststhatotherMCMC\n",
      "methodsmayconvergeprematurelyintime.\n",
      "1\n",
      "\n",
      "2\n",
      "RelatedWork\n",
      "Theseminalworkof[2]introducedtheChineseRestaurantFranchise(CRF)\n",
      "andtheDirectAssignment(DA)samplingalgorithmsfortheHDP.Sincethen,\n",
      "manyalternativeshavebeendeveloped.BecauseHDPinferenceoftenextends\n",
      "methodsfromDPs,wediscussrelevantworkonbothmodelsthatfocus\n",
      "onconvergenceandscalability.CurrentmethodsaresummarizedinTable1.\n",
      "SimpleGibbssamplingmethods,suchasCRForDA,mayconvergeslowlyin\n",
      "complexmodels.Workssuchas[11,12,13,14]addressthisissueinDPswith\n",
      "split/mergemoves.WangandBlei[7]developedtheonlysplit/mergeMCMC\n",
      "methodforHDPsbyextendingtheSequentiallyAllocatedMerge-Split(SAMS)\n",
      "algorithmofDPsdevelopedin[13].Unfortunately,reportedresultsin[7]only\n",
      "showamarginalimprovementoverGibbssampling.Ourexperimentssuggest\n",
      "thatthisislikelyduetopropertiesofthespsampler,andthatat\n",
      "formulationtlyimprovesconvergence.Additionally,SAMScannotbe\n",
      "parallelized,andisthereforeonlytestedonacorpuswith263Kwords.By\n",
      "designingaparallelalgorithm,wetestonacorpusof100Mwords.1\n",
      "Table1:CapabilitiesofMCMCSamplingAlgorithmsforHDPsCRF[2]DA\n",
      "[2]SAMS[7]FSD[4]Hog-Wild[8]Super-Cluster[9]ProposedModel\n",
      "XXX?XXXMCMCGuaranteesXXXX?XXNon-ConjugatePriors?\n",
      "??X??XParallelizable???XXXXLocalSplits/Merges??X??\n",
      "?XGlobalSplits/Merges??????X?potentiallypossiblewithsome\n",
      "adapatationoftheDPMetropolis-Hastingsframeworkof[10].\n",
      "TherehasalsobeenworkonparallelsamplingalgorithmsforHDPs.Fox\n",
      "etal.[4]generalizestheworkofIshwaranandZarepour[15]byapproximating\n",
      "thehighest-levelDPwithasymmetricDirichlet(FSD).Iterationsofthis\n",
      "approximationcanbeparallelized,butthemodelorderisundesirable\n",
      "sinceitnolongergrowswiththedata.Furthermore,ourexperimentssuggest\n",
      "thatthisalgorithmexhibitspoorconvergence.Newmanetal.[8]presentan\n",
      "alternativeparallelapproximationrelatedtoHog-WildGibbssampling[16,17].\n",
      "EachprocessorindependentlyrunsaGibbssampleronitsassigneddatafollowed\n",
      "byaresynchronizationstepacrossallprocessors.Thisapproximationhasshown\n",
      "toperformwelloncross-validationmetrics,butlosesthelimitingguaranteesof\n",
      "MCMC.Additionally,wewillshowthatcross-validationmetricsarenotsuitable\n",
      "toanalyzeconvergence.AnexactparallelalgorithmforDPsandHDPswas\n",
      "recentlydevelopedbyWillamsonetal.[9]bygroupingclustersintoindependent\n",
      "super-clusters.Unfortunately,theparallelizationdoesnotscalewell[18],and\n",
      "convergenceisoftenimpeded[1].Regardlessofexactness,allcurrentparallel\n",
      "samplingalgorithmsexhibitpoorconvergenceduetotheirlocalnature,while\n",
      "split/mergeproposalsareessentiallyctiveandcannotbeparallelized.2.1\n",
      "DPSub-ClustersAlgorithm\n",
      "TherecentDPSub-Clusteralgorithm[1]addressestheseissuesbycombin-\n",
      "ingnon-ergodicMarkovchainsintoanergodicchainandproposingsplitsfrom\n",
      "learnedsub-clusters.WereviewrelevantaspectsoftheDPSub-Cluster\n",
      "algorithmhere.MCMCalgorithmstypicallysatisfytwoconditions:detailed\n",
      "balanceandergodicity.Detailedbalanceensuresthatthetargetdistributionis\n",
      "2\n",
      "\n",
      "astationarydistributionofthechain,whileergodicityguaranteesuniquenessof\n",
      "thestationarydistribution.Themethodof[1]combinesaGibbssamplerthat\n",
      "isrestrictedtonon-emptyclusterswithaMetropolis-Hastings(MH)algorithm\n",
      "thatproposessplitsandmerges.SinceanyGibbsorMHsamplerde-\n",
      "tailedbalance,thetrueposteriordistributionisguaranteedtobeastationary\n",
      "distributionofthechain.Furthermore,thecombinationofthetwosamplers\n",
      "enforcesergodicityandguaranteestheconvergencetothestationarydistribu-\n",
      "tion.TheDPSub-Clusteralgorithmalsoaugmentsthemodelwithauxiliary\n",
      "variablesthatlearnatwocomponentmixturemodelforeachcluster.These\n",
      "?sub-clusters?aresubsequentlyusedtoproposesplitsthatarelearnedover\n",
      "timeinsteadofbuiltinasingleiterationlikepreviousmethods.Inthispaper,\n",
      "weextendthesetechniquestoHDPs.Aswewillshow,considerableworkis\n",
      "neededtoaddressthehigher-levelDPandtheoverlappingdistributionsthat\n",
      "existintopicmodeling.\n",
      "3\n",
      "HierarchicalDirichletProcesses\n",
      "WebeginwithabriefreviewoftheequivalentCRFandDArepresentations\n",
      "oftheHDP[2]depictedinFigures1a?1b.DuetotheuseofHDPsin\n",
      "topicmodeling,werefertothevariableswiththeirtopicmodelingnames.?\n",
      "isthecorpus-level,globaltopicproportions,?kistheparameterfortopick,\n",
      "andxjiistheithwordindocumentj.Here,theCRFandDArepresentations\n",
      "depart.IntheCRF,??jisdrawnfromastick-breakingprocess[19],andeach\n",
      "?customer?(i.e.,word)isassignedtoa?table?throughtji?Categorical(?\n",
      "?j).Thehigher-levelDPthenassigns?dishes?(i.e.,topics)totablesviakjt\n",
      "?Categorical(?).Theassociationofcustomerstodishesthroughthetablesis\n",
      "equivalenttoassigningawordtoatopic.IntheCRF,multipletablescanbe\n",
      "assignedthesamedish.TheDAformulationcombinesthesemultipleinstances\n",
      "anddirectlyassignsawordtoatopicwithzji.Theresultingdocument-sp\n",
      "topicproportions,?j,aggregatesmultiple??jvalues.For2\n",
      "(a)HDPCRFModel\n",
      "(b)HDPDAModel\n",
      "(c)HDPAugmentedDAModel\n",
      "Figure1:Graphicalmodels.(c)Hyper-parametersareomittedandauxiliary\n",
      "variablesaredotted.\n",
      "Figure2:Visualizationofaugmentedsamplespace.reasonswhichwillbe\n",
      "discussed,inferenceintheDAformulationstillreliesonsomeaspectsofthe\n",
      "CRF.Weadoptthenotationof[2],wherethenumberoftablesinrestaurant\n",
      "jservingdishkisdenotedmjk,andthenumberofcustomersinrestaurant\n",
      "jattableteatingdishkisnjtk.MarginalPPcountsarerepresentedwith\n",
      "dots,e.g.,nj??,t,knjtkandmj?,kmjkrepresentthenumberofcustomers\n",
      "anddishesinrestaurantj,respectively.Wereferthereaderto[2]foradditional\n",
      "details.\n",
      "4\n",
      "RestrictedParallelSampling\n",
      "WedrawontheDPSub-Clusteralgorithmtocombinearestricted,parallel\n",
      "Gibbssamplerwithsplit/mergemoves(asdescribedinSection2.1).Theformer\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isdetailedhere,andthelatterisdevelopedinSection5.Becausetherestricted\n",
      "Gibbssamplercannotcreatenewtopics,dimensionsoftheevectors?,\n",
      "?,and?associatedwithemptyclustersneednotbeinstantiated.Extending\n",
      "theDAsamplingalgorithmof[2]resultsinthefollowingrestrictedposterior\n",
      "distributions:p(?|m)=Dir(m?1,...,m?K,?),p(?j|?,z)=Dir(??1+\n",
      "nj?1,...,??K+nj?K,??K+1),p(?k|x,z)?fx(xIk;?k)f?(?k;?),PK\n",
      "p(zji|x,?j,?)?k=1?jkfx(xji;?k)1I[zji=k],p(mjk|?,z)=fm(mjk;\n",
      "??k,nj?k),\n",
      "?(??k)mjk.?(??k+nj?k)s(nj?k,mjk)(??k)\n",
      "(1)(2)(3)(4)(5)\n",
      "Sincep(?|?)isnotknownanalytically,weusetheauxiliaryvariable,mjk\n",
      ",asderivedby[2,20].Here,s(n,m)denotesunsignedStirlingnumbersofthe\n",
      "kind.Wenotethat?and?arenow(K+1)?lengthvectorspartitioning\n",
      "thespace,wherethelastcomponents,?K+1and?j(K+1),aggregatetheweight\n",
      "ofallemptytopics.Additionally,Ik,\n",
      "f\n",
      "j,i;zji=k\n",
      "g\n",
      "denotesthesetofindices\n",
      "intopick,andfxandf?denotetheobservationandpriordistributions.We\n",
      "notethatiff?isconjugatetofx,Equation(3)staysinthesamefamily\n",
      "ofparametricdistributionsasf?(?;?).Equations(1?5),eachofwhichcan\n",
      "besampledinparallel,fullyspecifytherestrictedGibbssampler.Theastute\n",
      "readermaynoticesimilaritieswiththeFSDapproximationusedin[4].The\n",
      "mainarethatthe?distributioninEquation(1)isexact,andthat\n",
      "samplingzinEquation(4)isexplicitlyrestrictedtonon-emptyclusters.Unlike\n",
      "[4],however,thissamplerisguaranteedtoconvergetothetrueHDPmodel\n",
      "whencombinedwithanysplitmove(cf.Section2.1).\n",
      "5\n",
      "AugmentedSub-ClusterSpaceforSplitsandMerges\n",
      "Inthissectionwedeveloptheaugmented,sub-clustermodel,whichisaimed\n",
      "atatwocomponentmixturemodelcontainingalikelysplitofthedata.\n",
      "Asdemonstratedin[1],thesesplitsperformwellinDPsbecausetheyimprove\n",
      "ateveryiterationofthealgorithm.Unfortunately,becausethesesplitsperform\n",
      "poorlyinHDPs,wemodifytheformulationtoproposemoremoves.\n",
      "Foreachtopic,k,wettwosub-topics,k`andkr,referredtoasthe?left?and\n",
      "?right?sub-topics.Eachtopicisaugmentedwithauxiliaryglobalsub-topic\n",
      "proportions,?k=\n",
      "f\n",
      "?k`,?kr\n",
      "g\n",
      ",document3\n",
      "levelsub-topicproportions,?jk=\n",
      "f\n",
      "?jk`,?jkr\n",
      "g\n",
      ",andsub-topicparam-\n",
      "eters,?k=\n",
      "f\n",
      "?k`,?kr\n",
      "g\n",
      ".Furthermore,asub-topicassignment,zji?\n",
      "f\n",
      "`,r\n",
      "g\n",
      "is\n",
      "associatedwitheachword,xji.TheaugmentedspaceissummarizedinFigure\n",
      "1candvisualizedinFigure2.Theseauxiliaryvariablesaredenotedwiththe\n",
      "samesymbolastheir?regular-topic?counterpartstoalludetotheirsimilari-\n",
      "ties.Extendingtheworkof[1],weadoptthefollowingauxiliarygenerativeand\n",
      "marginalposteriordistributions:GenerativeDistributions\n",
      "MarginalPosteriorDistributionsp(?k|?)=Dir(?+m?k`,?+m?kr),\n",
      "p(?k)=Dir(?,?),p(?jk|?k)=Dir(??k`,??kr),YYp(?k|?,z,\n",
      "x)=f?(?kh;?)Zji(?,?,z,x),\n",
      "Zji(?,?,z,x),\n",
      "YKYk=1\n",
      "4\n",
      "\n",
      "p(?jk|?)=Dir(??k`+nj?k`,??kr+nj?kr),(7)p(?kh|?)?fx(xIkh;\n",
      "?kh)f?(?kh;?),\n",
      "(8)\n",
      "p(zji|?)??jzjizjifx(xji;?zjizji)\n",
      "(9)\n",
      "p(mjkh|?)=fm(mjkh;??kh,nj?kh),\n",
      "(10)\n",
      "j,i?Ik\n",
      "h?\n",
      "f\n",
      "`,r\n",
      "g\n",
      "p(z|?,?,z,x)=\n",
      "(6)\n",
      "?jkzjifx(xji;?kzji)\n",
      "j,i?IkZji(?,?,z,x)\n",
      "Xh?\n",
      "f\n",
      "`,r\n",
      "g\n",
      ",\n",
      "?jzjihfx(xji;?zjih),\n",
      "where?denotesallothervariables.Fullderivationsaregiveninthesupple-\n",
      "ment.NoticethesimilaritybetweentheseposteriordistributionsandEquations\n",
      "(1?5).InferenceisperformedbyinterleavingthesamplingofEquations(1?5)\n",
      "withEquations(6?10).Furthermore,eachstepcanbeparallelized.5.1\n",
      "Sub-TopicSplit/MergeProposals\n",
      "WeadoptaMetropolis-Hastings(MH)[21]frameworkthatproposesasplit/merge\n",
      "fromthesubtopicsandeitheracceptsorrejectsit.Denotingv,\n",
      "f\n",
      "?,?,z,?\n",
      "g\n",
      "and\n",
      "v,\n",
      "f\n",
      "?,?,z,?\n",
      "g\n",
      "asthesetofregularandauxiliaryvariables,asampledproposal,\n",
      "f\n",
      "?v,v?\n",
      "g\n",
      "?q(?v,v?|v)isacceptedwithprobabilityhi?v)q(v|x,??\n",
      "v)q(v|x,v,v)?=min1,p(x,?v)p(v|x,??Pr[\n",
      "f\n",
      "v,v\n",
      "g\n",
      "=\n",
      "f\n",
      "?v,v\n",
      "g\n",
      "]=min[1,\n",
      "H].(11)?p(x,v)p(v|x,v)q(?v|x,v)q(v|x,v,?v)H,isknownastheHast-\n",
      "ingsratio.Algorithm1outlinesageneralsplit/mergeMHframework,where\n",
      "steps1?2proposeasamplefromq(?v|x,v)q(v?|x,v,v,v?).Samplingthe\n",
      "variablesotherthanz?isdetailedhere,afterwhichwediscussthreeversionsof\n",
      "Algorithm1withvariantsonsamplingz?.Algorithm1Split-MergeFramework\n",
      "?documentproportions,??1.Proposeassignments,z?,globalproportions,\n",
      "?,?,andparameters,?.2.Defertheproposalofauxiliaryvariablestothe\n",
      "restrictedsamplingofEquations(1?10).3.Accept/rejecttheproposalwith\n",
      "theHastingsratio.?InMetropolis-Hastings,convergencetypicallyimproves\n",
      "astheproposaldistributionis(Step1:?):closertothetargetdistribution.\n",
      "Thus,itwouldbeidealtopropose??fromp(?|?z).Unfortunately,p(?|z)\n",
      "cannotbeexpressedanalyticallywithoutconditioningonthedishcounts,m?k\n",
      ",asinEquation(1).Sincethedistributionofdishcountsdependson?itself,\n",
      "weapproximateitsvaluewithm?jk(z),argmaxmp(m|?=1/K,z)=arg\n",
      "maxm\n",
      "?(1/K)1m?(1/K+nj?k)s(nj?k,m)(K),\n",
      "(12)\n",
      "wheretheglobaltopicproportionshaveessentiallybeensubstitutedwith\n",
      "1/K.Wenotethatthedependenceonzisimpliedthroughthecounts,n.We\n",
      "5\n",
      "\n",
      "thenproposeglobaltopicsproportionsfrom?z)=p(?|?m(????q(?|?\n",
      "?z))=Dir(m??1(?z),???,m??K(?z),?).\n",
      "(13)\n",
      "Wewilldenotem?jk,m?jk(z)andm??jk,m?jk(?z).Weemphasize\n",
      "thattheapproximatem??jkisonlyusedforaproposaldistribution,andthe\n",
      "resultingchainwillstillsatisfydetailedbalance.(Step1:??):Conditioned\n",
      "on?andz,thedistributionof?isknowntobeDirichlet.Thus,we?z?)by\n",
      "samplingdirectlyfromthetrueposteriordistributionofEquation(2).propose\n",
      "???p(??|?,?Iff?isconjugatetofx,wesample??directlyfromthe\n",
      "posteriorofEquation(3).If(Step1:?):non-conjugatemodels,anyproposal\n",
      "canbeusedwhileadjustingforitintheHastingsratio.4\n",
      "(Step2):WeusetheDeferredMHsamplerdevelopedin[1],whichsets\n",
      "q(v?|x,v?)=p(v?|x,v?)bydeferringthesamplingofauxiliaryvariablesto\n",
      "therestrictedsamplerofSection5.Splitsandmergesarethenonlyproposed\n",
      "fortopicswhereauxiliaryvariableshavealreadyburned-in.Inpracticeburnin\n",
      "isquitefast,andisdeterminedbymonitoringthesub-topicdatalikelihoods.\n",
      "(Step3):Finally,theaboveproposalsresultsinthefollowingtheHastingsratio:\n",
      "H=\n",
      "?z)p(x|?p(?,?z)p(?,z)p(x|z)\n",
      "?\n",
      "?q(z|?v,v)q(?|z)?z).q(?z|v,v)q(?|?\n",
      "(14)\n",
      "Thedatalikelihood,p(x|z)isknownanalytically,andq(?|z)canbecal-\n",
      "culatedaccordingtoEquation13.Thepriordistribution,p(?,z),isexpressed\n",
      "inthefollowingproposition:Proposition5.1.Letzbeasetoftopicassign-\n",
      "mentswithintegervaluesin\n",
      "f\n",
      "1,...,K\n",
      "g\n",
      ".Let?bea(K+1)?lengthvector\n",
      "representingglobaltopicweights,and?K+1bethesumofweightsassociated\n",
      "withemptytopics.Thepriordistribution,p(?,z),marginalizingover?,canbe\n",
      "expressedashihYDYKYK?(??+n)i?(?)??1kj?kp(?,z)=??K+1?k?1\n",
      "?.(15)?(?+nj??)?(??k)k=1\n",
      "k=1\n",
      "j=1\n",
      "Proof.Seesupplementalmaterial.TheremainingterminEquation(14),q(?\n",
      "z|v,v),istheprobabilityofproposingaparticularsplit.Inthefollowingsec-\n",
      "tions,wedescribethreepossiblesplitconstructionsusingthesub-clusters.Since\n",
      "?theotherstepsremainthesame,weonlydiscusstheproposaldistributions\n",
      "forz?and?.5.1.1\n",
      "DeterministicSplit/MergeProposals\n",
      "Themethodof[1]constructsasplitdeterministicallybycopyingthesub-\n",
      "clusterlabelsforasinglecluster.Werefertothisproposalasalocalsplit,\n",
      "whichonlychangesassignmentswithinonetopic,asopposedtoaglobalsplit\n",
      "(discussedshortly),whichchangesalltopicassignments.Alocaldeterministic\n",
      "splitwillessentiallybeacceptedifthejointlikelihoodincreases.Unfortunately,\n",
      "asweshowinthesupplement,samplesfromthetypicalsetofanHDPdonot\n",
      "havehighlikelihood.Deterministicsplitandmergeproposalsare,consequently,\n",
      "6\n",
      "\n",
      "veryrarelyaccepted.Wenowsuggesttwoalternativepairsofsplitandmerge\n",
      "proposals,eachwiththeirownbanddrawbacks.5.1.2\n",
      "LocalSplit/MergeProposals\n",
      "Here,wedepartfromtheapproachof[1]bysamplingalocalsplitoftopica\n",
      "intotopicsbandc.Temporaryparameters,\n",
      "f\n",
      "??b,??c,??b,??c\n",
      "g\n",
      ",andtopic\n",
      "assignments,z?,aresampledaccordingto)YX(??b,??c)=?a?(?a`,\n",
      "?ar),??kfx(xji;??k)1I[?zji=k].(16)=?q(?z|v,v)?(??b,??c)=\n",
      "(?a`,?ar),j,i?Iak?\n",
      "f\n",
      "b,c\n",
      "g\n",
      "Wenotethatasamplefromq(?z|v,v)isalready\n",
      "drawnfromtherestrictedGibbssamplerdescribedinEquation(9).Therefore,\n",
      "noadditionalcomputationisneededtoproposethesplit.Ifthesplitisrejected,\n",
      "thez?issimplyusedasthenextsampleoftheauxiliaryzforclustera.A??\n",
      "isthendrawnbysplitting?ainto??band??caccordingtoalocalversionof\n",
      "Equation(13):???b,m???c).q(??b,??c|?z,?a)=Dir(??b/?a,??c\n",
      "/?a;m\n",
      "(17)\n",
      "Thecorrespondingmergemovecombinestopicsbandcintotopicaby\n",
      "deterministicallyperformingq(?zji|v)=1I[?zji=a],\n",
      "q(??a|v)=?(??a?(?b+?c)).\n",
      "?j,i?Ib?Ic,\n",
      "ThisresultsinthefollowingHastingsratioforalocalsplit(derivationin\n",
      "supplement):??YYm?+m??c??QM?(???k+?nj?k)p(x|?z)m?\n",
      "?b)?(m??c)?a?b?(??a)1K+1,H=??(??m??bm??z|v,v)QS\n",
      "?(??a+nj?a)??cp(x|z)q(??(m?+m?)?(???)?b\n",
      "?c\n",
      "??b\n",
      "??c\n",
      "K\n",
      "j\n",
      "k?\n",
      "f\n",
      "b,c\n",
      "g\n",
      "(18)\n",
      "(19)\n",
      "k\n",
      "whereQSKandQMKaretheprobabilitiesofselectingaspsplitor\n",
      "mergewithKtopics.Werecordq(?z|v,v)whensamplingfromEquation\n",
      "(9),andallothertermsarecomputedviatstatistics.WesetQSK=1\n",
      "byproposingallsplitsateachiteration.QMKwillbediscussedshortly.5\n",
      "TheHastingsratioforamergeisessentiallythereciprocalofEquation(19).\n",
      "However,thereverse?and??,whicharenotreadilysplitmove,q(z|?v,v?),\n",
      "reliesontheinferredsub-topicparameters,?availableduetotheDeferredMH\n",
      "algorithm.Instead,weapproximatetheHastingsratiobysubstitutingthetwo\n",
      "originaltopicparameters,?band?c,fortheproposedsub-topics.Thequality\n",
      "ofthisapproximationrestsonthesimilaritybetweentheregular-topicsandthe\n",
      "sub-topics.Generatingthereversemovethatsplitstopicaintobandccan\n",
      "thenbeapproximatedasY?zjifx(xji;?zji)bbLccq(z|?v,v?)?=L(20)\n",
      "LbcLcb,j,i?Ib?Ic?bfx(xi;?b)+?cfx(xi;?c)YYLkk,?kfx(xji;?k),\n",
      "Lkl,[?kfx(xji;?k)+?lfx(xji;?l)].(21)j,i?Ik\n",
      "7\n",
      "\n",
      "j,i?Ik\n",
      "AllofthetermsinEquation(20)arealreadycalculatedintherestricted\n",
      "Gibbssteps.WhenaggregatedcorrectlyintheK?Kmatrix,L,theHastings\n",
      "ratioforanyproposedmergeisevaluatedinconstanttime.However,iftopicsb\n",
      "andcaremergedintoa,furthermergingawithanotherclustercannotbe\n",
      "cientlycomputedwithoutloopingthroughthedata.Wethereforeonlypropose\n",
      "bK/2cmergesbygeneratingarandompermutationoftheintegers[1,K],and\n",
      "proposingtomergedisjointneighbors.Forexample,iftherandompermutation\n",
      "forK=7is\n",
      "f\n",
      "3174265\n",
      "g\n",
      ",weproposeto2bK/2cmergetopics3and1,topics\n",
      "7and4,andtopics2and6.ThisresultsinQMK=K(K?1).5.1.3\n",
      "GlobalSplit/MergeProposals\n",
      "Inmanyapplicationswhereclustershavetoverlap(e.g.,topicmod-\n",
      "eling),localsplitsmaybetooconstrainedsinceonlypointswithinasingletopic\n",
      "change.Wenowdevelopaglobalsplitandmergemove,whichreassignthe\n",
      "datainalltopics.Aglobalsplitconstructstemporarytopic?followedby\n",
      "proposingtopicassignmentsforallwordswith:proportions,??,andparam-\n",
      "eters,?,)Y?(??b,??c)=?a?(?a`,?ar),??k=?k,?k6=a,?z?jifx\n",
      "(xji;??z?ji)=?q(?z|v,v)=.(22)P(??b,??c)=(?a`,?ar),??k=?k,\n",
      "?k6=a,??kfx(xji;??k)j,i\n",
      "k\n",
      "Similarly,thecorrespondingmergemoveisconstructedaccordingto)Y?\n",
      "??a=?b+?c,??k=?k,?k6=b,c,?z?jifx(xji;??z?ji).(23)=?q(?z\n",
      "|v,v)=P??a?q(??a|z,x),??k=?k,?k6=b,c,??kfx(xji;??k)j,i\n",
      "k\n",
      "Theproposalfor??aiswritteninageneralform;ifpriorsareconjugate,\n",
      "oneshouldproposedirectlyfromtheposterior.AfterEquations(22)?(23),??\n",
      "issampledviaEquation(13).AllremainingstepsfollowAlgorithm1.The\n",
      "resultingHastingsratioforaglobalsplit(seesupplement)isexpressedasKD\n",
      "K+1Dm?YYY?(mY???a|z)QM??k?k?(???k+?nj?k)z)q(z|?\n",
      "?(??k)??k)m???)p(x|?v,v)q(K+1.(24)H=??(?+?m??q(?z\n",
      "|v,v)?(m??k)?(??k+nj?k)QS?(???k)?(?+m???)p(x|z)K??k?k\n",
      "j=1\n",
      "k=1\n",
      "k=1\n",
      "j=1\n",
      "Similartolocalmerges,theHastingsratioforaglobalmergedependson\n",
      "theproposedsub-topicsparameters.Weapproximatethesewiththemain-topic\n",
      "parameterspriortothemerge.Unlikethelocalsplit/mergeproposals,proposing\n",
      "z?requirestcomputationbyloopingthroughalldatapoints.Assuch,\n",
      "weonlyproposeasingleglobalsplitandmergeeachiteration.Thus,QSK=\n",
      "1/KandQMK=2/(K(K?1)).Weemphasizethatthedevelopedglobalmoves\n",
      "areverytfrompreviouslocalsplit/mergemovesinDPsandHDPs(e.g.,\n",
      "[1,7,11,13,14]).Weconjecturethatthisisthereasonthesplit/mergemoves\n",
      "in[7]onlymadenegligibleimprovement.\n",
      "6\n",
      "Experiments\n",
      "8\n",
      "\n",
      "WenowtesttheproposedHDPSub-Clustersmethodontopicmodeling.The\n",
      "algorithmissummarizedinthefollowingsteps:(1)initialize?andzrandomly;\n",
      "(2)sample?,?,?,and?viaEquations(2,3,7,8);(3)samplezandzvia\n",
      "Equations(4,9);(4)proposebK2clocalmergesfollowedbyKlocalsplits;\n",
      "(5)proposeaglobalmergefollowedbyaglobalsplit;(6)samplemandmvia\n",
      "Equations(5,10);(7)sample?and?viaEquations(1,6);(8)repeatfromStep\n",
      "2untilconvergence.Wethehyper-parameters,butresamplingtechniques\n",
      "[2]caneasilybeincorporated.Allresultsareaveragedover10samplepaths.\n",
      "Sourcecodecanbedownloadedfromhttp://people.csail.mit.edu/jchang7.6\n",
      "(a)VisualizingTopics\n",
      "20100-210\n",
      "secs(logscale)\n",
      "10\n",
      "1\n",
      "20\n",
      "Num.Topics\n",
      "1Proc.2Procs.\n",
      "GlobalCombined\n",
      "4Procs.8Procs.\n",
      "10\n",
      "(b)Split/MergeMoves\n",
      "0-210\n",
      "10\n",
      "secs(logscale)\n",
      "(c)Parallelization\n",
      "100-2\n",
      "Combined\n",
      "HOWLogLike.\n",
      "Det.Local\n",
      "Num.Topics\n",
      "Num.Topics\n",
      "20\n",
      "1\n",
      "-2.5-3-3.5-4-31010\n",
      "secs(logscale)\n",
      "10\n",
      "2\n",
      "10\n",
      "3\n",
      "(d)AlgorithmComparison\n",
      "-8-8\n",
      "-8.4\n",
      "Num.Topics\n",
      "100\n",
      "-8.2\n",
      "50-8.40\n",
      "9\n",
      "\n",
      "0\n",
      "secs\n",
      "10000\n",
      "NumberofTopics\n",
      "-8-8.2\n",
      "-8\n",
      "-8.4100\n",
      "Num.Topics\n",
      "-8.2\n",
      "-7.8\n",
      "-7.8\n",
      "50-8.40\n",
      "100\n",
      "(a)APResultswithtInitializations\n",
      "-8.2\n",
      "HOWLogLikelihood\n",
      "HOWLogLike.\n",
      "-7.8\n",
      "-7.8\n",
      "HOWLogLikelihood\n",
      "HOWLogLike.\n",
      "Figure3:Synthetic?bars?example.(a)Visualizingtopicworddistributions\n",
      "withoutsplits/mergesforK=5.(b)?(c)Numberofinferredtopicsfort\n",
      "split/mergeproposalsandparallelizations.(d)Comparingsamplingalgorithms\n",
      "withasingleprocessorandinitializedtoasingletopic.\n",
      "0\n",
      "secs\n",
      "20000\n",
      "NumberofTopics\n",
      "100\n",
      "(b)APResultswithSwitchingAlgorithms\n",
      "Figure4:ResultsonAP.(a)1,25,50,and75initialtopics.(b)Switching\n",
      "algorithmsat1000secs.\n",
      "6.1\n",
      "SyntheticBarsDataset\n",
      "Wesynthesized200documentsfromthe?bars?exampleof[22]witha\n",
      "dictionaryof25wordsthatcanbearrangedina5x5grid.Eachofthe10\n",
      "truetopicsformsahorizontalorverticalbar.Tovisualizethesub-topics,we\n",
      "initializeto5topicsanddonotproposesplitsormerges.Theresultingregular-\n",
      "andsub-topicsareshowninFigure3a.Noticehowthesub-topicscapture\n",
      "likelysplits.Next,weconsidertsplit/mergeproposalsinFigure3b.\n",
      "The?Combined?algorithmuseslocalandglobalmoves.Thedeterministic\n",
      "movesareoftenrejectedresultinginslowconvergence.Whileglobalmovesare\n",
      "notneededinsuchawell-separateddataset,wehaveobservedthatthemake\n",
      "atimpactinreal-worlddatasets.Furthermore,sinceeverystepof\n",
      "thesamplingalgorithmcanbeparallelized,weachievealinearspeedupinthe\n",
      "10\n",
      "\n",
      "numberofprocessors,asshowninFigure3c.Figure3dcomparesconvergence\n",
      "withoutparallelizationtotheDirectAssignment(DA)samplerandtheFinite\n",
      "SymmetricDirichlet(FSD)oforder20.Sinceallalgorithmsshouldsample\n",
      "fromthesamemodel,thegoalhereistoanalyzeconvergencespeed.Weplot\n",
      "twosummarystatistics:thelikelihoodofasingleheld-outword(HOW)from\n",
      "eachdocument,andthenumberofinferredtopics.WhiletheHOWlikelihood\n",
      "forFSDconvergesat1second,thenumberoftopicsconvergesat100seconds.\n",
      "Thissuggeststhatcross-validationtechniques,whichevaluatemodelcannot\n",
      "solelydetermineMCMCconvergence.WenotethatFSDtendstocreate\n",
      "allLtopicsandslowlyremovethem.6.2\n",
      "Real-WorldCorporaDatasets\n",
      "Next,weconsidertheAssociatedPress(AP)dataset[23]with436Kwords\n",
      "in2Kdocuments.WemanuallysettheFSDorderto100.Resultsusing16cores\n",
      "(exceptDA,whichcannotbeparallelized)with1,25,50,and75initialtopics\n",
      "areshowninFigure4a.Allsamplersshouldconvergetothesamestatistics\n",
      "regardlessoftheinitialization.WhileHOWlikelihoodconvergesfor3/4FSD\n",
      "initializations,thenumberoftopicsindicatesthatnoDAorFSDsamplepaths\n",
      "haveconverged.Unlikethewell-separated,syntheticdataset,theSub-Clusters\n",
      "methodthatonlyuseslocalsplitsandmergesdoesnotconvergetoagood\n",
      "solutionhere.Incontrast,allinitializationsoftheSub-Clustersmethodhave\n",
      "convergedtoahighHOWlikelihoodwithonlyapproximately20topics.The\n",
      "pathtakenbyeachsamplerinthejointHOWlikelihood/numberoftopicsspace\n",
      "isshownintherightpanelofFigure4a.Thisvisualizationhelpstoillustrate\n",
      "thetapproachestakenbyeachalgorithm.Figure5aPshowsconfusion\n",
      "matrices,C,oftheinferredtopics.EachelementofCisas:Cr,c=xfx\n",
      "(x;?r)logfx(x;?c),andcapturesthelikelihoodofarandomwordfromtopic\n",
      "r7\n",
      "(a)ConfusionMatricesforAP\n",
      "(b)FourTopicsfromNYTimes\n",
      "-8.6-8.2\n",
      "Num.Topics\n",
      "200100\n",
      "-8.60\n",
      "-1\n",
      "1010\n",
      "0\n",
      "secs(logscale)\n",
      "4\n",
      "5\n",
      "10100\n",
      "NumberofTopics\n",
      "-8.7-8.7\n",
      "-9-9.3\n",
      "-9\n",
      "200Num.Topics\n",
      "-7.8\n",
      "11\n",
      "\n",
      "-8.2\n",
      "100-9.30\n",
      "200\n",
      "(a)EnronResults\n",
      "HOWLogLikelihood\n",
      "HOWLogLike.\n",
      "-7.8HOWLogLikelihood\n",
      "HOWLogLike.\n",
      "Figure5:(a)ConfusionmatricesonAPforSUB-CLUSTERS,DA,and\n",
      "FSD(lefttoright).Outlinesareoverlaidtocomparesize.(b)Fourinferred\n",
      "topicsfromtheNYTimesarticles.\n",
      "-1\n",
      "1010\n",
      "0\n",
      "secs(logscale)\n",
      "4\n",
      "5\n",
      "10100\n",
      "NumberofTopics\n",
      "200\n",
      "(b)NYTimesResults\n",
      "Figure6:Resultson(a)Enronemailsand(b)NYTimesarticlesfor1and\n",
      "50initialtopics.\n",
      "evaluatedundertopicc.DAandFSDbothconvergetomanytopicsthat\n",
      "areeasilyconfused,whereastheSub-Clustersmethodconvergestoasmaller\n",
      "setofmoredistinguishabletopics.Rigorousproofsaboutconvergencearequite\n",
      "Furthermore,eventhoughtheapproximationsmadeincalculatingthe\n",
      "Hastingsratiosforlocalandglobalsplits(e.g.,Equation(20))arebackedby\n",
      "intuition,theycomplicatetheanalysis.Instead,weruneachsamplepathfor\n",
      "2,000seconds.After1,000seconds,weswitchtheSub-Clusterssamplepaths\n",
      "toFSDandallothersamplepathstoSubClusters.Markovchainsthathave\n",
      "convergedshouldnotchangewhenswitchingthesampler.Figure4bshows\n",
      "thatswitchingfromDA,FSD,orthelocalversionofSub-Clustersimmediately\n",
      "changesthenumberoftopics,butswitchingSub-ClusterstoFSDhasno\n",
      "Webelievethatthenumberoftopicsisslightlyhigherintheformerbecause\n",
      "theSub-Clustermethodstrugglestocreatesmalltopics.Byconstruction,the\n",
      "splitsmakelargemoves,incontrasttoDAandFSD,whichoftencreatesingle\n",
      "wordtopics.ThissuggeststhatalternatingbetweenFSDandSub-Clustersmay\n",
      "workwell.Finally,weconsidertwolargedatasetsfrom[24]:EnronEmailswith\n",
      "6Mwordsin40KdocumentsandNYTimesArticleswith100Mwordsin300K\n",
      "documents.WenotethattheNYTimesdatasetis3ordersofmagnitudelarger\n",
      "thanthoseconsideredintheHDPsplit/mergeworkof[7].Again,wemanually\n",
      "settheFSDorderto200.ResultsareshowninFigure6initializedto1and\n",
      "50topics.Insuchlargedatasets,itistopredictconvergencetimes;\n",
      "after28hours,itseemsasthoughnoalgorithmshaveconverged.However,the\n",
      "Sub-Clustersmethodseemstobeapproachingasolution,whereasFSDhasyet\n",
      "12\n",
      "\n",
      "toprunetopicsandDAhasyettotoachieveagoodcross-validationscore.\n",
      "FourinferredtopicsusingtheSub-ClustersmethodontheNYTimesdataset\n",
      "arevisualizedinFigure5b.Thesewordsseemtodescribeplausibletopics(e.g.,\n",
      "music,terrorism,basketball,andwine).\n",
      "7\n",
      "Conclusion\n",
      "WehavedevelopedanewparallelsamplingalgorithmfortheHDPthatpro-\n",
      "posessplitandmergemoves.Unlikepreviousattempts,theproposedglobal\n",
      "splitsandmergesexhibittlyimprovedconvergenceinavarietyof\n",
      "datasets.Wehavealsoshownthatcross-validationmetricsinisolationcanlead\n",
      "totheerroneousconclusionthatanMCMCsamplingalgorithmhasconverged.\n",
      "Byconsideringthenumberoftopicsandheld-outlikelihoodjointly,weshow\n",
      "thatprevioussamplingalgorithmsconvergeveryslowly.AcknowledgmentsThis\n",
      "researchwaspartiallysupportedbytheofNavalResearchMultidisci-\n",
      "plinaryResearchInitiativeprogram,awardN000141110688andbyVITALITE,\n",
      "whichreceivessupportfromArmyResearchMultidisciplinaryResearch\n",
      "Initiativeprogram,awardW911NF-11-1-0391.8\n",
      "2References\n",
      "[1]J.ChangandJ.W.Fisher,III.ParallelsamplingofDPmixturemodels\n",
      "usingsub-clusterssplits.InAdvancesinNeuralInformationandProcessing\n",
      "Systems,Dec2013.[2]Y.W.Teh,M.I.Jordan,M.J.Beal,andD.M.Blei.\n",
      "HierarchicalDirichletprocesses.JournaloftheAmericanStatisticalAssoci-\n",
      "ation,101(476):1566?1581,2006.[3]E.B.Sudderth.GraphicalModelsfor\n",
      "VisualObjectRecognitionandTracking.PhDthesis,MassachusettsInstitute\n",
      "ofTechnology,2006.[4]E.B.Fox,E.B.Sudderth,M.I.Jordan,andA.S.\n",
      "Willsky.AnHDP-HMMforsystemswithstatepersistence.InInternational\n",
      "ConferenceonMachineLearning,July2008.[5]Y.W.Teh,K.Kurihara,and\n",
      "M.Welling.CollapsedvariationalinferenceforHDP.InAdvancesinNeuralIn-\n",
      "formationProcessingSystems,volume20,2008.[6]M.BryantandE.Sudderth.\n",
      "TrulynonparametriconlinevariationalinferenceforHierarchicalDirichletpro-\n",
      "cesses.InAdvancesinNeuralInformationProcessingSystems,2012.[7]C.\n",
      "WangandDBlei.Asplit-mergeMCMCalgorithmfortheHierarchicalDirich-\n",
      "letprocess.arXiv:1207.1657[stat.ML],2012.[8]D.Newman,A.Asuncion,P.\n",
      "Smyth,andM.Welling.Distributedalgorithmsfortopicmodels.Journalof\n",
      "MachineLearningResearch,10:1801?1828,December2009.[9]S.Williamson,\n",
      "A.Dubey,andE.P.Xing.ParallelMarkovchainMonteCarlofornonparamet-\n",
      "ricmixturemodels.InInternationalConferenceonMachineLearning,2013.\n",
      "[10]R.Neal.MarkovchainsamplingmethodsforDirichletprocessmixture\n",
      "models.JournalofComputationalandGraphicalStatistics,9(2):249?265,June\n",
      "2000.[11]S.JainandR.Neal.Asplit-mergeMarkovchainMonteCarlopro-\n",
      "cedurefortheDirichletprocessmixturemodel.JournalofComputationaland\n",
      "GraphicalStatistics,13:158?182,2000.[12]P.J.GreenandS.Richardson.\n",
      "ModellingheterogeneitywithandwithouttheDirichletprocess.Scandinavian\n",
      "13\n",
      "\n",
      "JournalofStatistics,pages355?375,2001.[13]D.B.Dahl.Animprovedmerge-\n",
      "splitsamplerforconjugateDirichletprocessmixturemodels.Technicalreport,\n",
      "UniversityofWisconsin-MadisonDept.ofStatistics,2003.[14]S.Jainand\n",
      "R.Neal.SplittingandmergingcomponentsofanonconjugateDirichletpro-\n",
      "cessmixturemodel.BayesianAnalysis,2(3):445?472,2007.[15]H.Ishwaran\n",
      "andM.Zarepour.Exactandapproximatesum-representationsfortheDirich-\n",
      "letprocess.CanadianJournalofStatistics,30:269?283,2002.[16]F.Niu,B.\n",
      "Recht,C.R?e,andS.J.Wright.Hogwild!:Alock-freeapproachtoparalleliz-\n",
      "ingstochasticgradientdescent.InAdvancesinNeuralInformationProcessing\n",
      "Systems,2011.[17]M.J.Johnson,J.Saunderson,andA.S.Willsky.Analyzing\n",
      "hogwildparallelgaussiangibbssampling.InAdvancesinNeuralInformation\n",
      "ProcessingSystems,2013.[18]Y.GalandZ.Ghahramani.Pitfallsintheuse\n",
      "ofparallelinferencefortheDirichletprocess.InWorkshoponBigLearning,\n",
      "NIPS,2013.[19]J.Sethuraman.AconstructiveofDirichletpriors.\n",
      "StatsticaSinica,pages639?650,1994.[20]C.E.Antoniak.MixturesofDirich-\n",
      "letprocesseswithapplicationstoBayesiannonparametricproblems.Annalsof\n",
      "Statistics,2(6):1152?1174,1974.[21]W.K.Hastings.MonteCarlosampling\n",
      "methodsusingMarkovchainsandtheirapplications.Biometrika,57(1):97?109,\n",
      "1970.[22]T.L.andM.Steyvers.Findingscientopics.Proceed-\n",
      "ingsoftheNationalAcademyofSciences,101:5228?5235,April2004.[23]D.\n",
      "M.Blei,A.Y.Ng,andM.I.Jordan.LatentDirichletallocation.Journalof\n",
      "MachineLearningResearch,3:993?1022,March2003.[24]K.BacheandM.\n",
      "Lichman.UCIMachineLearningRepository,2013.\n",
      "9\n",
      "14\n",
      "\n",
      "PP5357.pdf\n",
      "PP5357.pdf 11\n",
      "InferencebyLearning:Speeding-upGraphical\n",
      "ModelOptimizationviaaCoarse-to-Fine\n",
      "CascadeofPruning\n",
      "Authoredby:\n",
      "NikosKomodakis\n",
      "BrunoConejo\n",
      "SebastienLeprince\n",
      "JeanPhilippeAvouac\n",
      "Abstract\n",
      "Weproposeageneralandversatileframeworkthattlyspeeds-\n",
      "upgraphicalmodeloptimizationwhilemaintaininganexcellentsolution\n",
      "accuracy.Theproposedapproach,refereedasInferencebyLearningor\n",
      "IbyL,reliesonamulti-scalepruningschemethatprogressivelyreduces\n",
      "thesolutionspacebyuseofacascadeoflearnt\n",
      "WethoroughlyexperimentwithclassiccomputervisionrelatedMRF\n",
      "problems,whereournovelframeworkconstantlyyieldsattime\n",
      "speed-up(withrespecttothemosttinferencemethods)andob-\n",
      "tainsamoreaccuratesolutionthandirectlyoptimizingtheMRF.We\n",
      "makeourcodeavailableon-line.\n",
      "1PaperBody\n",
      "GraphicalmodelsincomputervisionOptimizationofundirectedgraphicalmod-\n",
      "elssuchasMarkovRandomFields,MRF,orConditionalRandomFields,CRF,\n",
      "isoffundamentalimportanceincomputervision.Currently,awidespectrum\n",
      "ofproblemsincludingstereomatching[25,13],opticalwestimation[27,16],\n",
      "imagesegmentation[23,14],imagecompletionanddenoising[10],or,object\n",
      "recognition[8,2]relyonthemodeofthedistributionassociatedto\n",
      "therandomi.e.,theMaximumAPosteriori(MAP)solution.TheMAP\n",
      "estimation,oftenreferredasthelabelingproblem,isposedasanenergymini-\n",
      "mizationtask.WhilethistaskisNP-Hard,strongoptimumsolutionsoreven\n",
      "theoptimalsolutionscanbeobtained[3].Overthepast20years,tremendous\n",
      "progresshasbeenmadeintermofcomputationalcost,and,manyt\n",
      "techniqueshavebeendevelopedsuchasmovemakingapproaches[3,19,22,21,\n",
      "28],andmessagepassingmethods[9,32,18,20].Areviewoftheireness\n",
      "1\n",
      "\n",
      "hasbeenpublishedin[31,12].Nevertheless,theeverincreasingdimensionality\n",
      "oftheproblemsandtheneedforlargersolutionspacegreatlychallengethese\n",
      "tech?ThisworkwassupportedbyUSGSthroughtheMeasurementsofsurface\n",
      "rupturesproducedbycontinentalearthquakesfromopticalimageryandLiDAR\n",
      "project(USGSAwardG13AP00037),theTerrestrialHazardObservationand\n",
      "ReportingCenterofCaltech,andtheMoorefoundationthroughtheAdvanced\n",
      "EarthSurfaceObservationProject(AESOPGrant2808).\n",
      "1\n",
      "niquesaseventhebestoneshaveahighlysuper-linearcomputationalcost\n",
      "andmemoryrequirementrelativelytothedimensionalityoftheproblem.Our\n",
      "goalinthisworkistodevelopageneralMRFoptimizationframeworkthatcan\n",
      "provideatspeed-upforsuchmethodswhilemaintainingtheaccuracy\n",
      "oftheestimatedsolutions.Ourstrategyforaccomplishingthisgoalwillbeto\n",
      "graduallyreduce(byatamount)thesizeofthediscretestatespacevia\n",
      "exploitingthefactthatanoptimallabelingistypicallyfarfrombeingrandom.\n",
      "Indeed,mostMRFoptimizationproblemsfavorsolutionsthatarepiecewise\n",
      "smooth.Infact,thisspatialstructureoftheMAPsolutionhasalreadybeen\n",
      "exploitedinpriorworktoreducethedimensionalityofthesolutionspace.Re-\n",
      "latedworkAsetofmethodsofthistype,referredhereforshortasthe\n",
      "super-pixelapproach[30],agroupingheuristictomergemanyrandom\n",
      "variablestogetherinsuper-pixels.Thegroupingheuristiccanbeenergy-aware\n",
      "ifitisbasedontheenergytominimizeasin[15],or,energyagnosticother-\n",
      "wiseasin[7,30].Allrandomvariablesbelongingtothesamesuper-pixelare\n",
      "forcedtotakethesamelabel.Thisrestrictsthesolutionspaceandresultsinan\n",
      "optimizationspeed-upasasmallernumberofvariablesneedstobeoptimized.\n",
      "Thesuper-pixelapproachhasbeenappliedwithsegmentation,stereoandob-\n",
      "jectrecognition[15].However,ifthegroupingheuristicmergesvariablesthat\n",
      "shouldhaveatlabelintheMAPsolution,onlyanapproximatelabeling\n",
      "iscomputed.Inpractice,generalyettgroupingheuristicsisdif-\n",
      "Thisrepresentsthekeylimitationofsuper-pixelapproaches.Onewayto\n",
      "overcomethislimitationistomimicthemulti-scaleschemeusedincontinuous\n",
      "optimizationbybuildingacoarsetorepresentationofthegraphicalmodel.\n",
      "Similarlytothesuperpixelapproach,suchamulti-scalemethod,reliesagainon\n",
      "agroupingofvariablesforbuildingtherequiredcoarsetorepresentation\n",
      "[17,24,26].However,contrarytothesuper-pixelapproach,ifthegrouping\n",
      "mergesvariablesthatshouldhaveatlabelintheMAPsolution,there\n",
      "alwaysexistsascaleatwhichthesevariablesarenotgrouped.Thisproperty\n",
      "thusensuresthattheMAPsolutioncanstillberecovered.Nevertheless,inorder\n",
      "tomanageatspeed-upoftheoptimization,themulti-scaleapproach\n",
      "alsoneedstoprogressivelyreducethenumberoflabelsperrandomvariable\n",
      "(i.e.,thesolutionspace).Typically,thisisachievedbyuse,forinstance,ofa\n",
      "heuristicthatkeepsonlyasmallnumberoflabelsaroundtheoptimallabel\n",
      "ofeachnodefoundatthecurrentscale,whilepruningallotherlabels,which\n",
      "arethereforenotconsideredthereafter[5].Thisstrategy,however,maynotbe\n",
      "optimalorevenvalidforalltypesofproblems.Furthermore,suchapruning\n",
      "heuristicistotallyinappropriate(andcanthusleadtoerrors)fornodeslocated\n",
      "2\n",
      "\n",
      "alongdiscontinuityboundariesofanoptimalsolution,wheresuchboundaries\n",
      "arealwaysexpectedtoexistinpractice.Analternativestrategyfollowedby\n",
      "someothermethodsreliesonselectingasubsetoftheMRFnodesateachscale\n",
      "(basedonsomecriterion)andthengtheirlabelsaccordingtotheoptimal\n",
      "solutionestimatedatthecurrentscale(essentially,suchmethodscontractthe\n",
      "entirelabelsetofanodetoasinglelabel).However,suchaingstrategymay\n",
      "betooaggressiveandcanalsoeasilyleadtoeliminatinggoodlabels.Proposed\n",
      "approachOurmethodsimultaneouslymakesuseofthefollowingtwostrategies\n",
      "forspeeding-uptheMRFoptimizationprocess:(i)itsolvestheproblemthrough\n",
      "amulti-scaleapproachthatgraduallytheMAPestimationbasedona\n",
      "representationofthegraphicalmodel,(ii)and,atthesametime,\n",
      "itprogressivelyreducesthelabelspaceofeachvariablebycleverlyutilizing\n",
      "theinformationcomputedduringtheaboveprocess.Toachieve\n",
      "that,weproposetotlyrevisitthewaythatthepruningofthesolution\n",
      "spacetakesplace.Moresp(i)wemakeuseofandincorporateinto\n",
      "theaboveprocessapruningschemethatallowsanarbitrarysubset\n",
      "oflabelstobediscarded,wherethissubsetcanbetforeachnode,(ii)\n",
      "additionally,andmostimportantly,insteadoftryingtomanuallycomeupwith\n",
      "somecriteriafordecidingwhatlabelstopruneorkeep,weintroducetheidea\n",
      "ofrelyingentirelyonasequenceoftrainedfortakingsuchdecisions,\n",
      "wheretperscaleareused.2\n",
      "WenamesuchanapproachInferencebyLearning,andshowthatitispartic-\n",
      "ularlytandeinreducingthelabelspacewhileomittingveryfew\n",
      "correctlabels.Furthermore,wedemonstratethatthetrainingoftheseclassi-\n",
      "canbedonebasedonfeaturesthatarenotapplicationspbutdepend\n",
      "solelyontheenergyfunction,whichthusmakesourapproachgenericandappli-\n",
      "cabletoanyMRFproblem.Theendresultofthisprocessistoobtainbothan\n",
      "importantspeed-upandatdecreaseinmemoryconsumptionasthe\n",
      "solutionspaceisprogressivelyreduced.Furthermore,aseachscalethe\n",
      "MAPestimation,afurtherspeed-upisobtainedasaresultofawarm-startini-\n",
      "tializationthatcanbeusedwhentransitioningbetweentscales.Before\n",
      "proceeding,itisworthalsonotingthatthereexistsabodyofpriorwork[29]\n",
      "thatfocusesonthelabelsofasubsetofnodesofthegraphicalmodelby\n",
      "searchingforapartiallabelingwiththeso-calledpersistencyproperty(which\n",
      "meansthatthislabelingisprovablyguaranteedtobepartofanoptimalsolu-\n",
      "tion).However,ingsuchasetofpersistentvariablesistypicallyverytime\n",
      "consuming.Furthermore,inmanycasesonlyalimitednumberofthesevari-\n",
      "ablescanbedetected.Asaresult,thefocusoftheseworksisentirelyt\n",
      "fromours,sincethemainmotivationinourcaseishowtoobtainat\n",
      "speed-upfortheoptimization.Hereafter,weassumewithoutlossofgenerality\n",
      "thatthegraphicalmodelisadiscretepairwiseCRF/MRF.However,onecan\n",
      "straightforwardlyapplyourapproachtohigherordermodels.Outlineofthe\n",
      "paperWereviewtheoptimizationproblemrelatedtoadiscretepairwise\n",
      "MRFandintroducethenecessarynotationsinsection2.Wedescribeourgen-\n",
      "eralmulti-scalepruningframeworkinsection3.Weexplainhowclassiare\n",
      "trainedinsection4.Experimentalresultsandtheiranalysisarepresentedin5.\n",
      "3\n",
      "\n",
      "Finally,weconcludethepaperinsection6.\n",
      "2\n",
      "Notationandpreliminaries\n",
      "TorepresentadiscreteMRFmodelM,weusethefollowingnotation\n",
      "M=V,E,L,\n",
      "f\n",
      "?i\n",
      "g\n",
      "i?V,\n",
      "f\n",
      "?ij\n",
      "g\n",
      "(i,j)?E.\n",
      "(1)\n",
      "HereVandErepresentrespectivelythenodesandedgesofagraph,andL\n",
      "representsadiscretelabelset.Furthermore,foreveryi?Vand(i,j)?E,the\n",
      "functions?i:L?Rand?ij:L2?Rrepresentandpairwisecosts(thatare\n",
      "alsoknownconnectivelyasMRFpotentialsrespectivelyunary?=\n",
      "f\n",
      "?i\n",
      "g\n",
      "i?V,\n",
      "f\n",
      "?ij\n",
      "g\n",
      "(i,j)?E).Asolutionx=(xi)i?Vofthismodelconsistsofonevariableper\n",
      "vertexi,takingvaluesinthelabelsetL,andthetotalcost(energy)E(x|M)\n",
      "ofsuchasolutionisE(x|M)=\n",
      "X\n",
      "X\n",
      "?i(xi)+\n",
      "i?V\n",
      "?ij(xi,xj).\n",
      "(i,j)?E\n",
      "ThegoalofMAPestimationistoasolutionthathasminimumenergy,\n",
      "i.e.,computesxMAP=argminE(x|M).x?L|V|\n",
      "TheaboveminimizationtakesplaceoverthefullsolutionspaceofmodelM,\n",
      "whichisL|V|.HerewewillalsomakeuseofaprunedsolutionspaceS(M,\n",
      "A),whichisbasedonabinaryfunctionA:V?L?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "(referredto\n",
      "asthepruningmatrixhereafter)thatspecithestatus(activeorpruned)of\n",
      "alabelforagivenvertex,i.e.,\n",
      "1iflabellisactiveatvertexiA(i,l)=(2)0iflabellisprunedatvertex\n",
      "iDuringoptimization,activelabelsareretainedwhileprunedlabelsaredis-\n",
      "carded.BasedonagivenA,thecorrespondingprunedsolutionspaceofmodel\n",
      "MisasnoS(M,A)=x?L|V||(?i),A(i,xi)=1.\n",
      "3\n",
      "MultiscaleInferencebyLearning\n",
      "InthissectionwedescribetheoverallstructureofourMAPestimation\n",
      "framework,beginningbyexplaininghowtoconstructthecoarse-to-nerepre-\n",
      "sentationoftheinputgraphicalmodel.3\n",
      "3.1\n",
      "Modelcoarsening\n",
      "GivenamodelMasin(1)),wewishtocreatea?coarser?version\n",
      "ofthismodelM0=V0,E0,L,\n",
      "f\n",
      "?0i\n",
      "g\n",
      "i?V0,\n",
      "f\n",
      "?0ij\n",
      "g\n",
      "(i,j)?E0.Intuitively,we\n",
      "wanttopartitionthenodesofMintogroups,andtreateachgroupasasingle\n",
      "nodeofthecoarsermodelM0(theimplicitassumptionisthatnodesofMthat\n",
      "aregroupedtogetherareassignedthesamelabel).Tothatend,wewillmake\n",
      "useofagroupingfunctiong:V?N.Thenodesandedgesofthecoarsermodel\n",
      "arethenasfollowsV0=\n",
      "f\n",
      "i0|?i?V,i0=g(i)\n",
      "g\n",
      ",0\n",
      "0\n",
      "0\n",
      "4\n",
      "\n",
      "(3)\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "E=\n",
      "f\n",
      "(i,j)|?(i,j)?E,i=g(i),j=g(j),i6=j\n",
      "g\n",
      ".\n",
      "(4)\n",
      "Furthermore,theunaryandpairwisepotentialsofM0aregivenby(?i0?V\n",
      "0),Figure1:Blackcircles:V,Blacklines:E,Redsquares:V0,Bluelines:E\n",
      "0.\n",
      "(?(i0,j0)?E0),\n",
      "?0i0(l)\n",
      "?0i0j0(l0,l1)=\n",
      "P=Pi?V|i0=g(i)+(i,j)?E|i0=g(i)=g(j)X(i,j)?E|i0=g(i),j0=g(j)\n",
      "?i(l),(5)?ij(l,l)?ij(l0,l1).(6)\n",
      "Withaslightabuseofnotation,wewillhereafteruseg(M)todenotethe\n",
      "coarsermodelresultingfromMwhenusingthegroupingfunctiong,i.e.,we\n",
      "g(M)=M0.Also,givenasolutionx0ofM0,wecan?upsample?it\n",
      "intoasolutionxofMbysettingxi=x0g(i)foreachi?V.Wewillusethe\n",
      "followingnotationinthiscase:g?1(x0)=x.Weprovideatoyexamplein\n",
      "supplementarymaterials.3.2\n",
      "optimizationandlabelpruning\n",
      "ToestimatetheMAPofaninputmodelM,weconstructaseriesofN\n",
      "+1progressivelycoarsermodels(M(s))0?s?NbyuseofasequenceofNgrouping\n",
      "functions(g(s))0?s<N,whereM(0)=Mand(?s),M(s+1)=g(s)(M(s)).\n",
      "Thisprovidesamultiscalerepresentationoftheoriginalmodel.,\n",
      "wheretheelementsoftheresultingmodelsaredenotedasfollows:\n",
      "(s)(s)M(s)=V(s),E(s),L,\n",
      "f\n",
      "?i\n",
      "g\n",
      "i?V(s),\n",
      "f\n",
      "?ij\n",
      "g\n",
      "(i,j)?E(s)Inourframework,\n",
      "MAPestimationproceedsfromthecoarsesttothescale(i.e.,frommodel\n",
      "M(N)toM(0)).Duringthisprocess,apruningmatrixA(s)iscomputedat\n",
      "eachscales,whichisusedfordeningarestrictedsolutionspaceS(M(s),A(s)\n",
      ").TheelementsofthematrixA(N)atthecoarsestscaleareallsetequalto1\n",
      "(i.e.,nolabelpruningisusedinthiscase),whereasinallotherscalesA(s)is\n",
      "computedbyuseofatrainedf(s).Moresp,atanygivenscale\n",
      "s,thefollowingstepstakeplace:i.Weapproximatelyminimize(viaanyexisting\n",
      "MRFoptimizationmethod)theenergyofthemodelM(s)overtherestricted\n",
      "solutionspaceS(M(s),A(s)),i.e.,wecomputex(s)?argminx?S(M(s),A(s)\n",
      ")E(x|M(s)).ii.Giventheestimatedsolutionx(s),afeaturemapz(s):V\n",
      "(s)?L?RKiscomputedatthecurrentscale,andatrainedf(s):\n",
      "RK?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "usesthisfeaturemapz(s)toconstructthepruningmatrixA(s?1)\n",
      "forthenextscaleasfollows(?i?V(s?1),?l?L),A(s?1)(i,l)=f(s)(z(s)\n",
      "(g(s?1)(i),l)).iii.Solutionx(s)is?upsampled?intox(s?1)=[g(s?1)]?1\n",
      "(x(s))andusedastheinitializationfortheoptimizationatthenextscales?1.\n",
      "Notethat,dueto(5)and(6),itholdsE(x(s?1)|M(s?1))=E(x(s)|M(s)).\n",
      "Therefore,thisinitializationensuresthatenergywillcontinuallydecreaseifthe\n",
      "sameistruefortheoptimizationappliedperscale.Furthermore,itcanallowfor\n",
      "5\n",
      "\n",
      "awarm-startingstrategywhentransitioningbetweenscales.Thepseudocode\n",
      "oftheresultingalgorithmappearsinAlgo.1.4\n",
      "Algorithm1:InferencebylearningframeworkData:ModelM,grouping\n",
      "functions(g(s))0?s<N,(f(s))0<s?NResult:x(0)Computethecoarse\n",
      "tosequenceofMRFs:M(0)?Mfors=[0...N?1]doM(s+1)?g\n",
      "(s)(M(s))OptimizethecoarsetosequenceofMRFsoverprunedsolution\n",
      "spaces:(?i?V(N),?l?L),A(N)(i,l)?1Initializex(N)fors=[N...0]\n",
      "doUpdatex(s)byiterativeminimization:x(s)?argminx?S(M(s),A(s))\n",
      "E(x|M(s))ifs6=0thenComputefeaturemapz(s)Updatepruningmatrix\n",
      "fornextscale:A(s?1)(i,l)=f(s)(z(s)(g(s?1)(i),l))Upsamplex(s)for\n",
      "initializingsolutionx(s?1)atnextscale:x(s?1)?[g(s?1)]?1(x(s))\n",
      "4\n",
      "Featuresandforlabelpruning\n",
      "Foreachscales,weexplainhowthesetoffeaturescomprisingthefeature\n",
      "mapz(s)iscomputedandhowwetrainthef(s).Thisis\n",
      "acrucialstepforourapproach.Indeed,ifthewronglypruneslabels\n",
      "thatbelongtotheMAPsolution,then,onlyanapproximatelabelingmightbe\n",
      "foundatthenestscale.Moreover,keepingtoomanyactivelabelswillresult\n",
      "inapoorspeed-upforMAPestimation.4.1\n",
      "Features\n",
      "Thefeaturemapz(s):V(s)?L?RKisformedbystackingKindividual\n",
      "real-valuedfeaturesonV(s)?L.Weproposetocomputefeatures\n",
      "thatarenotapplicationspbutdependsolelyontheenergyfunctionand\n",
      "thecurrentsolutionx(s).Thismakesourapproachgenericandapplicable\n",
      "toanyMRFproblem.However,asweestablishageneralframework,sp\n",
      "applicationfeaturescanbestraightforwardlyaddedinfuturework.Presenceof\n",
      "strongdiscontinuityThisbinaryfeature,PSD(s),accountsfortheexistenceof\n",
      "dis(s)(s)continuityinsolutionx(s)whenastronglink(i.e.,?ij(xi,xj)>?)\n",
      "existsbetweenneighbors.Itsfollowsforanyvertexi?V(s)andany\n",
      "labell?L:\n",
      "(s)(s)1?(i,j)?E(s)|?ij(xi,xj)>?PSD(s)(i,l)=(7)0otherwise\n",
      "LocalenergyvariationThisfeaturerepresentsthelocalvariationoftheenergy\n",
      "aroundthecurrentsolutionx(s).Itaccountsforboththeunaryandpairwise\n",
      "termsassociatedtoavertexandalabel.Asin[11],weremovethelocalenergy\n",
      "ofthecurrentsolutionasitleadstoahigherdiscriminativepower.Thelocal\n",
      "energyvariationfeature,LEV(s),isforanyi?V(s)andl?Las\n",
      "follows:(s)\n",
      "LEV\n",
      "(s)\n",
      "(i,l)=\n",
      "(s)\n",
      "(s)\n",
      "NV(i)\n",
      "(s)\n",
      "(s)\n",
      "?i(l)??i(xi)\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s)\n",
      "(s)\n",
      "(s)\n",
      "(s)\n",
      "X\n",
      "?ij(l,xj)??ij(xi,xj)\n",
      "j:(i,j)?E(s)\n",
      "NE(i)\n",
      "+\n",
      "(s)\n",
      "(s)\n",
      "(8)\n",
      "(s)\n",
      "withNV(i)=card\n",
      "f\n",
      "i0?V(s?1):g(s?1)(i0)=i\n",
      "g\n",
      "andNE(i)=card\n",
      "f\n",
      "(i0,\n",
      "j0)?E(s?1):g(s?1)(i0)=i,g(s?1)(j0)=j\n",
      "g\n",
      ".Unary?coarsening?This\n",
      "feature,UC(s),aimstoestimateanapproximationofthecoarseninginduced\n",
      "intheMRFunarytermswhengoingfrommodelM(s?1)tomodelM(s),i.e.,\n",
      "asaresultof5\n",
      "applyingthegroupingfunctiong(s?1).Itisforanyi?V(s)andl\n",
      "?Lasfollows(s?1)\n",
      "UC(s)(i,l)=\n",
      "|?i0\n",
      "Xi0?V(s?1)|g(s?1)(i0)=i\n",
      "(s)\n",
      "(l)?\n",
      "?i(l)(s)\n",
      "NV(i)\n",
      "(s)\n",
      "|(9)\n",
      "NV(i)\n",
      "FeaturenormalizationThefeaturesarebydesigninsensitivetoanyadditive\n",
      "termappliedonalltheunaryandpairwiseterms.However,westillneedto\n",
      "applyanormalizationtotheLEV(s)andUC(s)featurestomaketheminsensi-\n",
      "tivetoanypositiveglobalscalingfactorappliedonboththeunaryandpairwise\n",
      "terms(suchscalingvariationsarecommonlyusedincomputervision).Hence,\n",
      "wesimplydividegroupoffeatures,LEV(s)andUC(s)bytheirrespectivemean\n",
      "value.4.2\n",
      "\n",
      "TotrainthewearegivenasinputasetofMRFinstances(all\n",
      "ofthesameclass,e.g.,stereo-matching)alongwiththegroundtruthMAP\n",
      "solutions.WeextractasubsetofMRFsforlearningandasubsetforon-\n",
      "linetesting.ForeachMRFinstanceinthetrainingset,weapplythealgorithm\n",
      "1withoutanypruning(i.e.,A(s)?1)and,ateachscale,wekeeptrackofthe\n",
      "features(s)z(s)andalsocomputethebinaryfunctionXMAP:V(s)?L?\n",
      "f\n",
      "0,\n",
      "1\n",
      "g\n",
      "asfollows:\n",
      "7\n",
      "\n",
      "1,iflisthegroundtruthlabelfornodei(0)(?i?V,?l?L),XMAP(i,l)\n",
      "=0,otherwise\n",
      "(s)(s?1)(?s>0)(?i?V(s),?l?L),XMAP(i,l)=XMAP\n",
      "(i0,l),i0?V(s?1):g(s)(i0)=i(s)\n",
      "W\n",
      "wheredenotesthebinaryORoperator.Thevalues0and1inXMAP\n",
      "respectivelythetwoclassesc0andc1whentrainingthef(s),wherec0\n",
      "meansthatthelabelcanbeprunedandc1thatthelabelshouldnotbepruned.\n",
      "Totreatseparatelythenodesthatareontheborderofastrongdiscontinuity,\n",
      "wesplitthefeaturemap(s)(s)(s)(s)z(s)intotwogroupsz0andz1,where\n",
      "z0containsonlyfeatureswherePSD(s)=0andz1containsonlyfeatureswhere\n",
      "PSD(s)=1(strongdiscontinuity).Foreachgroup,wetrainastandardlinearC-\n",
      "SVMclaswithl2-normregularization(regularizationparameterwassetto\n",
      "C=10).Thelineargivegoodenoughaccuracyduringtrainingwhile\n",
      "alsobeingfasttoevaluateattesttimeDuringtraining(andforeachgroup),\n",
      "wealsointroduceweightstobalancethetnumberofelementsineach\n",
      "class(c0ismuchlargerthanc1),andtoalsostronglypenalize\n",
      "inc1(assuchcanhaveamoredrasticimpactontheaccuracy\n",
      "ofMAPestimation).Tocard(c0)accomplishthat,wesettheweightforclass\n",
      "c0to1,andtheweightforclassc1to?card(c,where1)card(?)counts\n",
      "thenumberoftrainingsamplesineachclass.Parameter?isapositivescalar\n",
      "(commontobothgroups)usedfortuningthepenalizationof\n",
      "inc1(itwillbereferredtoasthepruningaggressivenessfactorhereafterasit\n",
      "theamountoflabelsthatgetpruned).Duringon-linetesting,depending\n",
      "onthevalueofthePSDfeature,f(s)appliesthelinear(s)(s)learned\n",
      "ongroupz0ifPSD(s)=0,orthelinearlearnedongroupz1ifPSD(s)\n",
      "=1.\n",
      "5\n",
      "Experimentalresults\n",
      "WeevaluateourframeworkonpairwiseMRFsfromstereo-matching,image\n",
      "restoration,and,opticalwestimationproblems.ThecorrespondingMRF\n",
      "graphsconsistofregular4-connectedgridsinthiscase.Ateachscale,the\n",
      "groupingfunctionmergestogetherverticesof2?2subgrids.Weleavemore\n",
      "advancedgroupingfunctions[15]forfuturework.AsMRFoptimizationsubrou-\n",
      "tine,weusetheFast-PDalgorithm[21].Wemakeourcodeavailableon-line[4].\n",
      "ExperimentalsetupForthestereomatchingproblem,weestimatethedispar-\n",
      "itymapfromimagesIRandILwhereeachlabelencodesapotentialdisparity\n",
      "d(discretizedatquarterofapixelprecision),withMRFpotentials?p(d)=\n",
      "||IL(yp,xp)?IR(yp,xp?d)||1and?pq(d0,d1)=wpq|d0?d1\n",
      "|,withtheweightwpqvaryingbasedontheimagegradient(parametersare\n",
      "adjustedforeachsequence).Wetraintheonthewell-knownTsukuba\n",
      "stereo-pair(61labels),anduseallother6\n",
      "(a)Speed-up\n",
      "(b)Activelabelratio\n",
      "(c)Energyratio\n",
      "(d)Labelagreement\n",
      "Figure2:PerformanceofourInferencebyLearningframework:(Toprow)\n",
      "8\n",
      "\n",
      "stereomatching,(Middlerow)opticalw,(Bottomrow)imagerestoration.For\n",
      "stereomatching,theAverageMiddleburycurverepresentstheaveragevalueof\n",
      "thestatisticfortheentireMiddleburydataset[6](2001,2003,2005and2006)\n",
      "(37stereopairs).\n",
      "stereo-pairsof[6](2001,2003,2005and2006)fortesting.Forimagerestora-\n",
      "tion,weestimatethepixelintensityofanoisyandincompleteimageIwithMRF\n",
      "potentials?p(l)=||I(yp,xp)?l||22and?(l0,l1)=25min(||l0?\n",
      "l1||22,200).WetraintheonthePenguinimagestereo-pair(256\n",
      "labels),anduseHouse(256labels)fortesting(dataset[31]).Fortheopticalw\n",
      "estimation,weestimateasubpixel-accurate2Ddisplacementbetweentwo\n",
      "framesbyextendingthestereomatchingformulationto2D.Usingthedataset\n",
      "of[1],wetraintheonArmy(1116labels),andtestonRubberWhale\n",
      "(625labels)andDimetrodon(483labels).Forallexperiments,weuse5scales\n",
      "andsetin(7)?=5w?pqwithw?pqbeingthemeanvalueofedgeweights.\n",
      "EvaluationsWeevaluatethreeoptimizationstrategies:thedirectoptimization\n",
      "(i.e.,optimizingthefullMRFatthescale),themulti-scaleoptimization\n",
      "(?=0,i.e.,ourframeworkwithoutanypruning),andourInferencebyLearn-\n",
      "ingoptimization,whereweexperimentwithterrorratios?thatrange\n",
      "between0.001and1.Weassesstheperformancebycomputingtheenergyratio,\n",
      "i.e.,theratiobetweenthecurrentenergyandtheenergycomputedbythedirect\n",
      "optimization,thebestlabelagreement,i.e.,theproportionoflabelsthatcoin-\n",
      "cideswiththelabelsofthelowestcomputedenergy,thespeed-upfactor,i.e.,\n",
      "theratioofcomputationtimebetweenthedirectoptimizationandthecurrent\n",
      "optimizationstrategy,and,theactivelabelratio,i.e.,thepercentageofactive\n",
      "labelsatthescale.ResultsanddiscussionForallproblems,wepresent\n",
      "inFig.2theperformanceofourInferencebyLearningapproachforalltested\n",
      "aggressivenessfactorsandshowinFig.3estimatedresultsfor?=0.01.We\n",
      "presentadditionalresultsinthesupplementarymaterial.Foreveryproblem\n",
      "andaggressivenessfactorsuntil?=0.1,ourpruning-basedoptimizationob-\n",
      "tainsalowerenergy(column(c)ofFig.2)inlesscomputationtime,achieving\n",
      "aspeed-upfactor(column(a)ofFig.2)closeto5forStereo-matching,above\n",
      "10forwandupto3forimagerestoration.(notethatthesespeed-up\n",
      "factorsarewithrespecttoanalgorithm,FastPD,thatwasthemostt\n",
      "oneinrecentcomparisons[12]).Thepercentageofactivelabels(Fig.2column\n",
      "(b))stronglycorrelateswiththespeed-upfactor.Thebestlabelingagreement\n",
      "(Fig.2column(d))isneverworsethan97%(exceptfortheimagerestoration\n",
      "problemsbecauseofthein-paintedarea)7\n",
      "TsukubaVenusTeddyArmyDimet.House\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "(d)\n",
      "(e)\n",
      "(f)\n",
      "Figure3:ResultsofourInferencebyLearningframeworkfor?=0.1.\n",
      "EachrowisatMRFproblem.(a)originalimage,(b)groundtruth,(c)\n",
      "9\n",
      "\n",
      "solutionofthepruningframework,(d,e,f)percentageofactivelabelspervertex\n",
      "forscale0,1and2(black0%,white100%).\n",
      "andisalwaysabove99%for?60.1.Asexpected,lesspruninghappensnear\n",
      "labeldiscontinuitiesasillustratedincolumn(d,e,f)ofFig.3justifyingtheuse\n",
      "ofadedicatedlinearMoreover,largehomogeneouslylabeledregions\n",
      "areprunedearlierinthecoarsetoscale.\n",
      "6\n",
      "Conclusionandfuturework\n",
      "OurInferencebyLearningapproachconsistentlyspeeds-upthegraphical\n",
      "modeloptimizationbyatamountwhilemaintaininganexcellentac-\n",
      "curacyofthelabelingestimation.Onmostexperiments,itevenobtainsa\n",
      "lowerenergythandirectoptimization.Infuturework,weplantoexperiment\n",
      "withproblemsthatrequiregeneralpairwisepotentialswheremessage-passing\n",
      "techniquescanbemoreectivethangraph-cutbasedmethodsbutareatthe\n",
      "sametimemuchslower.Ourframeworkisguaranteedtoprovideanevenmore\n",
      "dramaticspeedupinthiscasesincethecomputationalcomplexityofmessage-\n",
      "passingmethodsisquadraticwithrespecttothenumberoflabelswhilebeing\n",
      "linearforgraph-cutbasedmethodsusedinourexperiments.Wealsointend\n",
      "toexploretheuseofapplicationspfeatures,learnthegroupingfunctions\n",
      "usedinthescheme,jointlytrainthecascadeofclassi,and\n",
      "applyourframeworktohighordergraphicalmodels.\n",
      "2References\n",
      "[1]S.Baker,S.Roth,D.Scharstein,M.J.Black,J.P.Lewis,andR.Szeliski.A\n",
      "databaseandevaluationmethodologyforopticalw.InICCV2007.,2007.[2]\n",
      "MartinBergtholdt,J?orgKappes,StefanSchmidt,andChristophSchn?orr.A\n",
      "studyofparts-basedobjectclassdetectionusingcompletegraphs.IJCV,2010.\n",
      "[3]Y.Boykov,O.Veksler,andR.Zabih.Fastapproximateenergyminimization\n",
      "viagraphcuts.PAMI,2001.[4]B.Conejo.http://imagine.enpc.fr/?conejob/ibyl/.\n",
      "8\n",
      "[5]B.Conejo,S.Leprince,F.Ayoub,andJ.P.Avouac.Fastglobalstereo\n",
      "matchingviaenergypyramidminimization.ISPRSAnn.Photogramm.Re-\n",
      "moteSens.SpatialInf.Sci.,2014.[6]MiddleburyStereoDatasets.[7]Pedro\n",
      "F.FelzenszwalbandDanielP.Huttenlocher.tgraph-basedimageseg-\n",
      "mentation.IJCV,2004.[8]PedroF.FelzenszwalbandDanielP.Huttenlocher.\n",
      "Pictorialstructuresforobjectrecognition.IJCV,2005.[9]P.F.Felzenszwalb\n",
      "andD.P.Huttenlocher.tbeliefpropagationforearlyvision.InCVPR,\n",
      "2004.[10]W.T.FreemanandE.C.Pasztor.Learninglow-levelvision.In\n",
      "ICCV,1999.[11]XiaoyanHuandP.Mordohai.Aquantitativeevaluation\n",
      "ofmeasuresforstereovision.PAMI.,2012.[12]J.H.Kappes,B.\n",
      "Andres,F.A.Hamprecht,C.Schnorr,S.Nowozin,D.Batra,SungwoongKim,\n",
      "B.X.Kausler,J.Lellmann,N.Komodakis,andC.Rother.Acomparativestudy\n",
      "ofmoderninferencetechniquesfordiscreteenergyminimizationproblems.In\n",
      "CVPR,2013.[13]JunhwanKim,V.Kolmogorov,andR.Zabih.Visualcorre-\n",
      "10\n",
      "\n",
      "spondenceusingenergyminimizationandmutualinformation.InICCV,2003.\n",
      "[14]S.Kim,C.Yoo,S.Nowozin,andP.Kohli.Imagesegmentationusinghigher-\n",
      "ordercorrelationclustering,2014.[15]TaesupKim,S.Nowozin,P.Kohli,and\n",
      "C.D.Yoo.Variablegroupingforenergyminimization.InCVPR,2011.[16]\n",
      "T.Kohlberger,C.Schnorr,A.Bruhn,andJ.Weickert.Domaindecomposition\n",
      "forvariationalwcomputation.IEEETransactionsonInformation\n",
      "Theory/ImageProcessing,2005.[17]PushmeetKohli,VictorS.Lempitsky,\n",
      "andCarstenRother.Uncertaintydrivenmulti-scaleoptimization.InDAGM-\n",
      "Symposium,2010.[18]V.Kolmogorov.Convergenttree-reweightedmessage\n",
      "passingforenergyminimization.PAMI,2006.[19]V.KolmogorovandR.\n",
      "Zabin.Whatenergyfunctionscanbeminimizedviagraphcuts?PAMI,2004.\n",
      "[20]N.Komodakis,N.Paragios,andG.Tziritas.Mrfoptimizationviadual\n",
      "decomposition:Message-passingrevisited.InCVPR,2007.[21]N.Komodakis,\n",
      "G.Tziritas,andN.Paragios.Fast,approximatelyoptimalsolutionsforsingle\n",
      "anddynamicmrfs.InCVPR,2007.[22]M.PawanKumarandDaphneKoller.\n",
      "Mapestimationofsemi-metricmrfsviahierarchicalgraphcuts.InUAI,2009.\n",
      "[23]M.P.Kumar,P.H.S.Ton,andA.Zisserman.Objcut.InCVPR,2005.[24]\n",
      "H.Lombaert,YiyongSun,L.Grady,andChenyangXu.Amultilevelbanded\n",
      "graphcutsmethodforfastimagesegmentation.InICCV2005.,2005.[25]T.\n",
      "Meltzer,C.Yanover,andY.Weiss.Globallyoptimalsolutionsforenergymin-\n",
      "imizationinstereovisionusingreweightedbeliefpropagation.InICCV,2005.\n",
      "[26]P.PerezandF.Heitz.Restrictionofamarkovrandomonagraph\n",
      "andmultiresolutionstatisticalimagemodeling.IEEETransactionsonInforma-\n",
      "tionTheory/ImageProcessing,1996.[27]S.RothandM.J.Black.Fieldsof\n",
      "experts:aframeworkforlearningimagepriors.InCVPR,2005.[28]C.Rother,\n",
      "V.Kolmogorov,V.Lempitsky,andM.Szummer.Optimizingbinarymrfsvia\n",
      "extendedroofduality.InCVPR,2007.[29]AlexanderShekhovtsov.Maximum\n",
      "persistencyinenergyminimization.InCVPR,2014.[30]JianboShiandJi-\n",
      "tendraMalik.Normalizedcutsandimagesegmentation.PAMI.,2000.[31]R.\n",
      "Szeliski,R.Zabih,D.Scharstein,O.Veksler,V.Kolmogorov,AseemAgarwala,\n",
      "M.Tappen,andC.Rother.Acomparativestudyofenergyminimizationmeth-\n",
      "odsformarkovrandomwithsmoothness-basedpriors.PAMI,2008.[32]\n",
      "M.J.Wainwright,T.S.Jaakkola,andA.S.Willsky.Mapestimationviaagree-\n",
      "mentontrees:messagepassingandlinearprogramming.IEEETransactionson\n",
      "InformationTheory/ImageProcessing,2005.\n",
      "9\n",
      "11\n",
      "\n",
      "PP6110.pdf\n",
      "PP6110.pdf 14\n",
      "UnsupervisedDomainAdaptationwithResidual\n",
      "TransferNetworks\n",
      "Authoredby:\n",
      "MichaelI.Jordan\n",
      "MingshengLong\n",
      "HanZhu\n",
      "JianminWang\n",
      "Abstract\n",
      "Therecentsuccessofdeepneuralnetworksreliesonmassiveamounts\n",
      "oflabeleddata.Foratargettaskwherelabeleddataisunavailable,do-\n",
      "mainadaptationcantransferalearnerfromantsourcedomain.\n",
      "Inthispaper,weproposeanewapproachtodomainadaptationindeep\n",
      "networksthatcanjointlylearnadaptiveandtransferablefea-\n",
      "turesfromlabeleddatainthesourcedomainandunlabeleddatainthe\n",
      "targetdomain.Werelaxaassumptionmadebyprevious\n",
      "methodsandassumethatthesourceandtargetr\n",
      "byaresidualfunction.Weenableadaptationbypluggingseveral\n",
      "layersintodeepnetworktoexplicitlylearntheresidualfunctionwithrefer-\n",
      "encetothetargetWefusefeaturesofmultiplelayerswithtensor\n",
      "productandembedthemintoreproducingkernelHilbertspacestomatch\n",
      "distributionsforfeatureadaptation.Theadaptationcanbeachievedin\n",
      "mostfeed-forwardmodelsbyextendingthemwithnewresiduallayersand\n",
      "lossfunctions,whichcanbetrainedtlyviaback-propagation.Em-\n",
      "piricalevidenceshowsthatthenewapproachoutperformsstateoftheart\n",
      "methodsonstandarddomainadaptationbenchmarks.\n",
      "1PaperBody\n",
      "Deepnetworkshavetlyimprovedthestateoftheartforawidevariety\n",
      "ofmachine-learningproblemsandapplications.Unfortunately,theseimpressive\n",
      "gainsinperformancecomeonlywhenmassiveamountsoflabeleddataareavail-\n",
      "ableforsupervisedtraining.Sincemanuallabelingofttrainingdatafor\n",
      "diverseapplicationdomainsisoftenprohibitive,forproblemsshortof\n",
      "labeleddata,thereisstrongincentivetoestablishingtivealgorithmstore-\n",
      "ducethelabelingconsumption,typicallybyleveraginglabeleddata\n",
      "fromatbutrelatedsourcedomain.However,thislearningparadigm\n",
      "fromtheshiftindatadistributionsacrosstdomains,whichposes\n",
      "1\n",
      "\n",
      "amajorobstacleinadaptingpredictivemodelsforthetargettask[1].Domain\n",
      "adaptation[1]ismachinelearningundertheshiftbetweentrainingandtest\n",
      "distributions.Arichlineofapproachestodomainadaptationaimtobridge\n",
      "thesourceandtargetdomainsbylearningdomain-invariantfeaturerepresenta-\n",
      "tionswithoutusingtargetlabels,sothatthelearnedfromthesource\n",
      "domaincanbeappliedtothetargetdomain.Recentstudieshaveshownthat\n",
      "deepnetworkscanlearnmoretransferablefeaturesfordomainadaptation[2,\n",
      "3],bydisentanglingexplanatoryfactorsofvariationsbehinddomains.Latest\n",
      "advanceshavebeenachievedbyembeddingdomainadaptationinthepipeline\n",
      "ofdeepfeaturelearningwhichcanextractdomain-invariantrepresentations[4,\n",
      "5,6,7].Thepreviousdeepdomainadaptationmethodsworkundertheassump-\n",
      "tionthatthesourcecanbedirectlytransferredtothetargetdomain\n",
      "uponthelearneddomain-invariantfeaturerepresentations.Thisassumptionis\n",
      "ratherstrongasinpracticalapplications,itisofteninfeasibletocheckwhether\n",
      "thesourceandtargetcanbesharedornot.Hencewefo-\n",
      "cusinthispaperonamoregeneral,andsafe,domainadaptationscenarioin\n",
      "whichthesourcecandtargetr30thConferenceonNeural\n",
      "InformationProcessingSystems(NIPS2016),Barcelona,Spain.\n",
      "byasmallperturbationfunction.Thegoalofthispaperistosimultane-\n",
      "ouslylearnadaptiveandtransferablefeaturesfromlabeleddatainthe\n",
      "sourcedomainandunlabeleddatainthetargetdomainbyembeddingtheadap-\n",
      "tationsofbothclasandfeaturesinadeeparchitecture.Motivated\n",
      "bythestateoftheartdeepresiduallearning[8],winneroftheImageNetILSVRC\n",
      "2015challenge,weproposeanewResidualTransferNetwork(RTN)approach\n",
      "todomainadaptationindeepnetworkswhichcansimultaneouslylearnadaptive\n",
      "andtransferablefeatures.Werelaxtheassumption\n",
      "madebypreviousmethodsandassumethatthesourceandtarget\n",
      "byasmallresidualfunction.Weenableadaptationbyplugging\n",
      "severallayersintodeepnetworkstoexplicitlylearntheresidualfunctionwith\n",
      "referencetothetargetInthisway,thesourceandtarget\n",
      "canbebridgedtightlyintheback-propagationprocedure.Thetar-\n",
      "getistailoredtothetargetdatabetterbyexploitingthelow-density\n",
      "separationcriterion.Wefusefeaturesofmultiplelayerswithtensorproduct\n",
      "andembedthemintoreproducingkernelHilbertspacestomatchdistributions\n",
      "forfeatureadaptation.Theadaptationcanbeachievedinmostfeed-forward\n",
      "modelsbyextendingthemwithnewresiduallayersandlossfunctions,and\n",
      "canbetrainedtlyusingstandardback-propagation.Extensiveevidence\n",
      "suggeststhattheRTNapproachoutperformsseveralstateofartmethodson\n",
      "standarddomainadaptationbenchmarks.\n",
      "2\n",
      "RelatedWork\n",
      "Domainadaptation[1]buildsmodelsthatcanbridgetdomainsor\n",
      "tasks,whichmitigatestheburdenofmanuallabelingformachinelearning[9,10,\n",
      "11,12],computervision[13,14,15]andnaturallanguageprocessing[16].The\n",
      "maintechnicalproblemofdomainadaptationisthatthedomaindiscrepancyin\n",
      "probabilitydistributionsoftdomainsshouldbeformallyreduced.Deep\n",
      "2\n",
      "\n",
      "neuralnetworkscanlearnabstractrepresentationsthatdisentangletex-\n",
      "planatoryfactorsofvariationsbehinddatasamples[17]andmanifestinvariant\n",
      "factorsunderlyingtpopulationsthattransferwellfromoriginaltasksto\n",
      "similarnoveltasks[3].Thusdeepneuralnetworkshavebeenexploredfordo-\n",
      "mainadaptation[18,19,15],multimodalandmulti-tasklearning[16,20],where\n",
      "tperformancegainshavebeenwitnessedrelativetopriorshallowtrans-\n",
      "ferlearningmethods.However,recentadvancesshowthatdeepnetworkscan\n",
      "learnabstractfeaturerepresentationsthatcanonlyreduce,butnotremove,the\n",
      "cross-domaindiscrepancy[18,4].Datasetshifthasposedabottlenecktothe\n",
      "transferabilityofdeepfeatures,resultinginstatisticallyunboundedriskfortar-\n",
      "gettasks[21,22].Somerecentworkaddressestheaforementionedproblemby\n",
      "deepdomainadaptation,whichbridgesthetwoworldsofdeeplearninganddo-\n",
      "mainadaptation[4,5,6,7].Theyextenddeepconvolutionalnetworks(CNNs)\n",
      "todomainadaptationeitherbyaddingoneormultipleadaptationlayersthrough\n",
      "whichthemeanembeddingsofdistributionsarematched[4,5],orbyaddinga\n",
      "fullyconnectedsubnetworkasadomaindiscriminatorwhilstthedeepfeatures\n",
      "arelearnedtoconfusethedomaindiscriminatorinadomain-adversarialtrain-\n",
      "ingparadigm[6,7].Whileperformancewastlyimproved,thesestate\n",
      "oftheartmethodsmayberestrictedbytheassumptionthatunderthelearned\n",
      "domain-invariantfeaturerepresentations,thesourcecanbedirectly\n",
      "transferredtothetargetdomain.Inparticular,thisassumptionmaynothold\n",
      "whenthesourceandtargetcannotbeshared.Astheoreti-\n",
      "callystudiedin[22],whenthecombinederroroftheidealjointhypothesisis\n",
      "large,thenthereisnosinglethatperformswellonbothsourceand\n",
      "targetdomains,sowecannotagoodtargetclasserbydirectlytransferring\n",
      "fromthesourcedomain.ThisworkisprimarilymotivatedbyHeetal.[8],the\n",
      "winneroftheImageNetILSVRC2015challenge.Theypresentdeepresidual\n",
      "learningtoeasethetrainingofverydeepnetworks(hundredsoflayers),termed\n",
      "residualnets.Theresidualnetsexplicitlyreformulatethelayersaslearning\n",
      "residualfunctions?F(x)withreferencetothelayerinputsx,insteadofdirectly\n",
      "learningtheunreferencedfunctionsF(x)=?F(x)+x.Themethodfocuses\n",
      "onstandarddeeplearninginwhichtrainingdataandtestdataaredrawnfrom\n",
      "identicaldistributions,henceitcannotbedirectlyappliedtodomainadapta-\n",
      "tion.Inthispaper,weproposetobridgethesourcefS(x)andtarget\n",
      "fT(x)bytheresiduallayerssuchthatthemismatchacross\n",
      "domainscanbeexplicitlymodeledbytheresidualfunctions?F(x)inadeep\n",
      "learningarchitecture.Althoughtheideaofadaptingsourceclastotarget\n",
      "domainbyaddingaperturbationfunctionhasbeenstudiedby[23,24,25],these\n",
      "methodsrequiretargetlabeleddatatolearntheperturbationfunction,which\n",
      "cannotbeappliedtounsuperviseddomainadaptation,thefocusofthisstudy.\n",
      "Anotherdistinctionisthattheirperturbationfunctionisintheinput\n",
      "spacex,whiletheinputtoourresidualfunctionisthetargetfT(x),\n",
      "whichcancapturetheconnectionbetweenthesourceandtargetclassimore\n",
      "ely.2\n",
      "3\n",
      "ResidualTransferNetworks\n",
      "3\n",
      "\n",
      "sInunsuperviseddomainadaptationproblem,wearegivenasourcedomain\n",
      "Ds=\n",
      "f\n",
      "(xsi,yis)\n",
      "g\n",
      "ni=1ofnstlabeledexamplesandatargetdomainDt=\n",
      "f\n",
      "xtj\n",
      "g\n",
      "nj=1ofntunlabeledexamples.Thesourcedomainandtargetdomainare\n",
      "sampledfromtprobabilitydistributionspandqrespectively,andp\n",
      "6=q.Thegoalofthispaperistodesignadeepneuralnetworkthatenables\n",
      "learningoftransfery=fs(x)andy=ft(x)toclosethesource-target\n",
      "discrepancy,suchthattheexpectedtargetriskRt(ft)=E(x,y)?q[ft(x)6=y]\n",
      "canbeboundedbyleveragingthesourcedomainsuperviseddata.\n",
      "Thechallengeofunsuperviseddomainadaptationarisesinthatthetarget\n",
      "domainhasnolabeleddata,whilethesourcefstrainedonsource\n",
      "domainDscannotbedirectlyappliedtothetargetdomainDtduetothedistri-\n",
      "butiondiscrepancyp(x,y)6=q(x,y).Thedistributiondiscrepancymaygive\n",
      "risetomismatchesinbothfeaturesandi.e.p(x)6=q(x)andfs(x)\n",
      "6=ft(x).Bothmismatchesshouldbebyjointadaptationoffeaturesand\n",
      "toenablectivedomainadaptation.adaptationismore\n",
      "thanfeatureadaptationbecauseitisdirectlyrelatedtothelabelsbut\n",
      "thetargetdomainisfullyunlabeled.Notethatthestateoftheartdeepfea-\n",
      "tureadaptationmethods[5,6,7]generallyassumecanbesharedon\n",
      "adapteddeepfeatures.Thispaperassumesfs6=ftandpresentsanend-to-end\n",
      "deeplearningframeworkforadaptation.Deepnetworks[17]canlearn\n",
      "distributed,compositional,andabstractrepresentationsfornaturaldatasuchas\n",
      "imageandtext.Thispaperaddressesunsuperviseddomainadaptationwithin\n",
      "deepnetworksforjointlylearningtransferablefeaturesandadaptive\n",
      "Weextenddeepconvolutionalnetworks(CNNs),i.e.AlexNet[26],tonovel\n",
      "residualtransfernetworks(RTNs)asshowninFigure1.Denotebyfs(x)the\n",
      "sourceandtheempiricalerrorofCNNonsourcedomaindataDsis\n",
      "minfs\n",
      "ns1XL(fs(xsi),yis),nsi=1\n",
      "(1)\n",
      "whereL(?,?)isthecross-entropylossfunction.Basedonthequantiation\n",
      "studyoffeaturetransferabilityindeepconvolutionalnetworks[3],convolutional\n",
      "layerscanlearngenericfeaturesthataretransferableacrossdomains[3].Hence\n",
      "weopttoinsteadofdirectlyadapt,thefeaturesofconvolutional\n",
      "layerswhentransferringpre-traineddeepmodelsfromsourcedomaintotarget\n",
      "domain.3.1\n",
      "FeatureAdaptation\n",
      "DeepfeatureslearnedbyCNNscandisentangleexplanatoryfactorsofvari-\n",
      "ationsbehinddatadistributionstoboostknowledgetransfer[19,17].However,\n",
      "thelatestliteraturendingsrevealthatdeepfeaturescanreduce,butnotre-\n",
      "move,thecross-domaindistributiondiscrepancy[3],whichmotivatesthestate\n",
      "oftheartdeepfeatureadaptationmethods[5,6,7].Deepfeaturesinstandard\n",
      "CNNsmusteventuallytransitionfromgeneraltospalongthenetwork,and\n",
      "thetransferabilityoffeaturesandwilldecreasewhenthecross-domain\n",
      "discrepancyincreases[3].Inotherwords,theshiftsinthedatadistributions\n",
      "lingerevenaftermultilayerfeatureabstractions.Inthispaper,weperformfea-\n",
      "tureadaptationbymatchingthefeaturedistributionsofmultiplelayers`?L\n",
      "4\n",
      "\n",
      "acrossdomains.Wereducefeaturedimensionsbyaddingabottlenecklayerf\n",
      "cbontopofthelastfeaturelayerofCNNs,andthenCNNsonsource\n",
      "labeledexamplessuchthatthefeaturedistributionsofthesourceandtargetare\n",
      "madesimilarundernewfeaturerepresentationsinmultiplelayersL=\n",
      "f\n",
      "fcb,f\n",
      "cc\n",
      "g\n",
      ",asshowninFigure1.Toadaptmultiplefeaturelayersectively,wepro-\n",
      "posethetensorproductbetweenfeaturesofmultiplelayerstoperformlossless\n",
      "multi-layerfeaturefusion,i.e.zsi,>?Lxs`iandztj,>?Lxt`.Wethenperform\n",
      "featureadaptationbyminimizingtheMaximumMeanDiscrepancyj(MMD)\n",
      "[27]betweensourceandtargetdomainsusingthefusionfeatures(dubbedtensor\n",
      "MMD)as\n",
      "nsXnsnsXntntXntXXXkzsi,zsjkzsi,ztjkzti,ztjminDL(Ds,\n",
      "Dt)=+?2,(2)fs,ftn2sn2tnsnti=1j=1i=1j=1i=1j=10\n",
      "2\n",
      "wherethecharacteristickernelk(z,z0)=e?kvec(z)?vec(z)k/bistheGaus-\n",
      "siankernelfunctiononthevectorizationoftensorszandz0withband-\n",
      "widthparameterb.tfromDAN[5]thatadaptsmultiplefeaturelayers\n",
      "usingmultipleMMDpenalties,thispaperadaptsmultiplefeaturelayersby\n",
      "fusingthemandthenadaptingthefusedfeatures.Theadvantageofourmethod\n",
      "againstDAN[5]isthatourmethodcancapturefullinteractionsacrossmulti-\n",
      "layerfeaturesandfacilitateeasiermodelselection,whileDAN[5]needs|L|\n",
      "independentMMDpenaltiesforadapting|L|layers.3\n",
      "Xs\n",
      "fcbAlexNet,ResNet?\n",
      "Xt\n",
      "fcb\n",
      "?\n",
      "fcc\n",
      "fc2\n",
      "fT(x)\n",
      "MMD\n",
      "?\n",
      "fc1\n",
      "?f(x)\n",
      "fS(x)=fT(x)+?f(x)fcc\n",
      "?f\n",
      "S\n",
      "(x)\n",
      "Ys\n",
      "fcb\n",
      "Xs\n",
      "?\n",
      "fcc\n",
      "Xs\n",
      "Zs\n",
      "weightlayer?F(x)x\n",
      "MMD\n",
      "5\n",
      "\n",
      "fT(x)\n",
      "entropyminimization\n",
      "Yt\n",
      "fcb\n",
      "Xt\n",
      "Zt\n",
      "?\n",
      "weightlayer\n",
      "fcc\n",
      "Xt\n",
      "F(x)=\n",
      "+\n",
      "?F(x)+x\n",
      "Figure1:(left)ResidualTransferNetwork(RTN)fordomainadaptation,\n",
      "basedonwell-establishedarchitectures.Duetodatasetshift,(1)thelast-layer\n",
      "featuresaretailoredtodomain-spstructuresthatarenotsafelytransfer-\n",
      "able,henceweaddabottlenecklayerfcbthatisadaptedjointlywiththe\n",
      "layerfccbythetensorMMDmodule;(2)Supervisedare\n",
      "notsafelytransferable,hencewebridgethembytheresiduallayersfc1?fc2so\n",
      "thatfS(x)=fT(x)+?f(x).(middle)ThetensorMMDmoduleformulti-layer\n",
      "featureadaptation.(right)Thebuildingblockfordeepresiduallearning;In-\n",
      "steadofusingtheresidualblocktomodelfeaturemappings,weuseittobridge\n",
      "thesourcefS(x)andtargetfT(x)withx,fT(x),F(x),fS\n",
      "(x),and?F(x),?f(x).3.2\n",
      "Adaptation\n",
      "Asfeatureadaptationcannotremovethemismatchinmodels,\n",
      "wefurtherperformadaptationtolearntransferthatmake\n",
      "domainadaptationmoree.Althoughthesourcefs(x)and\n",
      "targetft(x)aret,fs(x)6=ft(x),theyshouldberelatedto\n",
      "ensurethefeasibilityofdomainadaptation.Itisreasonabletoassumethatfs\n",
      "(x)andft(x)onlybyasmallperturbationfunction?f(x).Priorwork\n",
      "onadaptation[23,24,25]assumesthatft(x)=fs(x)+?f(x),where\n",
      "theperturbation?f(x)isafunctionofinputfeaturex.However,thesemethods\n",
      "requiretargetlabeleddatatolearntheperturbationfunction,whichcannotbe\n",
      "appliedtounsuperviseddomainadaptationwheretargetdomainhasnolabeled\n",
      "data.Howtobridgefs(x)andft(x)inaframeworkisakeychallengeof\n",
      "unsuperviseddomainadaptation.Wepostulatethattheperturbationfunction\n",
      "?f(x)canbelearnedjointlyfromthesourcelabeleddataandtargetunlabeled\n",
      "data,giventhatthesourceandtargetareproperlyconnected.\n",
      "Toenableadaptation,considerF(x)asanoriginalmappingby\n",
      "afewstackedlayers(convolutionalorfullyconnectedlayers)inFigure1(right),\n",
      "wherexdenotestheinputstotheoftheselayers[8].Ifonehypothesizesthat\n",
      "multiplenonlinearlayerscanasymptoticallyapproximatecomplicatedfunctions,\n",
      "thenitisequivalenttohypothesizethattheycanasymptoticallyapproximate\n",
      "theresidualfunctions,i.e.F(x)?x.Ratherthanexpectingstackedlayers\n",
      "toapproximateF(x),oneexplicitlyletstheselayersapproximatearesidual\n",
      "6\n",
      "\n",
      "function?F(x),F(x)?x,withtheoriginalfunctionbeing?F(x)+x.The\n",
      "operation?F(x)+xisperformedbyashortcutconnectionandanelement-\n",
      "wiseaddition,whiletheresidualfunctionisparameterizedbyresiduallayers\n",
      "withineachresidualblock.Althoughbothformsareabletoasymptotically\n",
      "approximatethedesiredfunctions,theeaseoflearningist.Inreality,it\n",
      "isunlikelythatidentitymappingsareoptimal,butitshouldbeeasiertothe\n",
      "perturbationswithreferencetoanidentitymapping,thantolearnthefunction\n",
      "asnew.Theresiduallearningisthekeytothesuccessfultrainingofverydeep\n",
      "networks.Thedeepresidualnetwork(ResNet)framework[8]bridgestheinputs\n",
      "andoutputsoftheresiduallayersbytheshortcutconnection(identitymapping)\n",
      "suchthatF(x)=?F(x)+x,whicheasesthelearningofresidualfunction?F\n",
      "(x)(similartotheperturbationfunctionacrossthesourceandtarget\n",
      "Basedonthiskeyobservation,weextendtheCNNarchitectures(Figure1,left)\n",
      "bypluggingintheresidualblock(Figure1,right).Wereformulatetheresidual\n",
      "blocktobridgethesourceclasfS(x)andtargetfT(x)bylettingx\n",
      ",fT(x),F(x),fS(x),and?F(x),?f(x).NotethatfS(x)istheoutputsofthe\n",
      "element-wiseadditionoperatorandfT(x)istheoutputsofthe\n",
      "layerfcc,bothbeforesoftmaxactivation?(?),fs(x),?(fS(x)),ft(x),\n",
      "?(fT(x)).Wecanconnectthesourceandtarget(before\n",
      "activation)bytheresidualblockasfS(x)=fT(x)+?f(x),\n",
      "(3)\n",
      "whereweusefunctionsfSandfTbeforesoftmaxforresidualblocktoensure\n",
      "thatthefsandftwilloutputprobabilities.Residuallayersf\n",
      "c1?fc2arefully-connectedlayerswithc?cunits,wherecisthenumberof\n",
      "classes.WesetthesourcefSastheoutputsoftheresidualblockto\n",
      "makeitbettertrainablefromthesource-labeleddatabydeepresiduallearning\n",
      "[8].Inotherwords,ifwesetfTastheoutputsoftheresidualblock,thenwe\n",
      "maybeunabletolearnitsuccessfullyaswedonothavetargetlabeleddata\n",
      "andthusstandardback-propagationwillnotwork.Deepresiduallearning[8]\n",
      "ensurestooutputvalid|?f(x)||fT(x)|?|fS(x)|,andmore\n",
      "importantly,4\n",
      "makestheperturbationfunction?f(x)dependentonboththetargetc\n",
      "fT(x)(duetothefunctionaldependency)aswellasthesourcefS\n",
      "(x)(duetotheback-propagationpipeline).Althoughwesuccessfullycastthe\n",
      "adaptationintotheresiduallearningframeworkwhiletheresidual\n",
      "learningframeworktendstomakethetargetft(x)notdeviatemuch\n",
      "fromthesourcefs(x),westillcannotguaranteethatft(x)will\n",
      "thetarget-spstructureswell.Toaddressthisproblem,wefurtherexploit\n",
      "theentropyminimizationprinciple[28]fortheadaptation,\n",
      "whichencouragesthelow-densityseparationbetweenclassesbyminimizingthe\n",
      "entropyofclass-conditionaldistributionfjt(xti)=p(yit=j|xti;ft)ontarget\n",
      "domaindataDtasminft\n",
      "nt\n",
      "1XHftxti,nti=1\n",
      "(4)\n",
      "ttwherePcH(?)istheentropyfunctionofclass-conditionaldistribution\n",
      "7\n",
      "\n",
      "ft(xi)asH(ft(xi))=?j=1fjt(xti)logfjt(xti),cisthenumber\n",
      "ofclasses,andfjt(xti)istheprobabilityofpredictingpointxtitoclassj.\n",
      "Byminimizingentropypenalty(4),thetargetft(x)ismadedirectly\n",
      "accessibletotarget-unlabeleddataandwillamenditselftopassthroughthe\n",
      "targetlow-densityregions.\n",
      "3.3\n",
      "ResidualTransferNetwork\n",
      "Toenableeunsuperviseddomainadaptation,weproposeResidual\n",
      "TransferNetwork(RTN),whichjointlylearnstransferablefeaturesandadaptive\n",
      "byintegratingdeepfeaturelearning(1),featureadaptation(2),and\n",
      "adaptation(3)?(4)inanend-to-enddeeplearningframework,min\n",
      "fS=fT+?f\n",
      "+\n",
      "ns1XL(fs(xsi),yis)nsi=1nt\n",
      "?XHftxtinti=1\n",
      "(5)\n",
      "+?DL(Ds,Dt),where?and?aretheparametersforthe\n",
      "tensorMMDpenalty(2)andentropypenalty(4)respectively.Theproposed\n",
      "RTNmodel(5)isenabledtolearnbothtransferablefeaturesandadaptiveclas-\n",
      "Asadaptationproposedinthispaperandfeatureadaptation\n",
      "studiedin[5,6]aretailoredtoadapttlayersofdeepnetworks,theycan\n",
      "complementeachothertoestablishbetterperformance.Sincetrainingdeep\n",
      "CNNsrequiresalargeamountoflabeleddatathatisprohibitiveformanydo-\n",
      "mainadaptationapplications,westartwiththeCNNmodelspre-trainedon\n",
      "ImageNet2012dataanditas[5].ThetrainingofRTNmainlyfollows\n",
      "standardback-propagation,withtheresidualtransferlayersforadap-\n",
      "tationas[8].Notethat,theoptimizationoftensorMMDpenalty(2)requires\n",
      "carefully-designedalgorithmtoestablishlinear-timetraining,asdetailedin[5].\n",
      "Wealsoadoptbilinearpooling[29]toreducethedimensionsoffusionfeatures\n",
      "intensorMMD(2).\n",
      "4\n",
      "Experiments\n",
      "Weevaluatetheresidualtransfernetworkagainststateofthearttransfer\n",
      "learninganddeeplearningmethods.Codesanddatasetswillbeavailableat\n",
      "https://github.com/thuml/transfer-c4.1\n",
      "Setup\n",
      "[13]isabenchmarkfordomainadaptation,comprising4,110im-\n",
      "agesin31classescollectedfromthreedistinctdomains:Amazon(A),which\n",
      "containsimagesdownloadedfromamazon.com,Webcam(W)andDSLR(D),\n",
      "whichcontainimagestakenbywebcameraanddigitalSLRcamerawithdif-\n",
      "ferentphotographicalsettings,respectively.Toenableunbiasedevaluation,we\n",
      "evaluateallmethodsonallsixtransfertasksA?W,D?W,W?D,A?D,\n",
      "D?AandW?Aasin[5,7].h[14]isbuiltbyselectingthe10\n",
      "commoncategoriessharedby-31andCaltech256(C),andiswidelyused\n",
      "bypreviousmethods[14,30].Wecanbuild12transfertasks:A?W,D?W,\n",
      "W?D,A?D,D?A,W?A,A?C,W?C,D?C,C?A,C?W,andC?D.\n",
      "8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While-31hasmorecategoriesandismorefordomainadaptation\n",
      "algorithms,5\n",
      "hprovidesmoretransfertaskstoenableanunbiasedlookat\n",
      "datasetbias[31].WeadoptDeCAF7[2]featuresforshallowtransfermeth-\n",
      "odsandoriginalimagesfordeepadaptationmethods.Wecomparewithboth\n",
      "conventionalandthestateofthearttransferlearninganddeeplearningmeth-\n",
      "ods:TransferComponentAnalysis(TCA)[9],GeodesicFlowKernel(GFK)\n",
      "[14],DeepConvolutionalNeuralNetwork(AlexNet[26]),DeepDomainCon-\n",
      "fusion(DDC)[4],DeepAdaptationNetwork(DAN)[5],andReverseGradient\n",
      "(RevGrad)[6].TCAisaconventionaltransferlearningmethodbasedonMMD-\n",
      "regularizedKernelPCA.GFKisamanifoldlearningmethodthatinterpolates\n",
      "acrossannumberofintermediatesubspacestobridgedomains.DDC\n",
      "isthemethodthatmaximizesdomaininvariancebyaddingtoAlexNet\n",
      "anadaptationlayerusinglinear-kernelMMD[27].DANlearnsmoretrans-\n",
      "ferablefeaturesbyembeddingdeepfeaturesofmultipletask-splayersto\n",
      "reproducingkernelHilbertspaces(RKHSs)andmatchingtdistributions\n",
      "optimallyusingmulti-kernelMMD.RevGradimprovesdomainadaptationby\n",
      "makingthesourceandtargetdomainsindistinguishableforadiscriminative\n",
      "domainviaanadversarialtrainingparadigm.Togodeeperwiththe\n",
      "ofadaptation(residualtransferblock)andfeatureadaptation\n",
      "(tensorMMDmodule),weperformablationstudybyevaluatingseveralvari-\n",
      "antsofRTN:(1)RTN(mmd),whichaddsthetensorMMDmoduletoAlexNet;\n",
      "(2)RTN(mmd+ent),whichfurtheraddstheentropypenaltytoAlexNet;(3)\n",
      "RTN(mmd+ent+res),whichfurtheraddstheresidualmoduletoAlexNet.Note\n",
      "thatRTN(mmd)improvesDAN[5]byreplacingthemultipleMMDpenaltiesin\n",
      "DANbyasingletensorMMDpenaltyinRTN(mmd),whichfacilitatesmuch\n",
      "easierparameterselection.Wefollowstandardprotocolsandusealllabeled\n",
      "sourcedataandallunlabeledtargetdatafordomainadaptation[5].Wecom-\n",
      "pareaverageaccuracyofeachtransfertaskusingthreerandom\n",
      "experiments.ForMMD-basedmethods(TCA,DDC,DAN,andRTN),weuse\n",
      "Gaussiankernelwithbandwidthbsettomedianpairwisesquareddistanceson\n",
      "trainingdata,i.e.medianheuristic[27].Astherearenotargetlabeleddata\n",
      "inunsuperviseddomainadaptation,modelselectionprovesForall\n",
      "methods,weperformcross-valuationonlabeledsourcedatatoselectcandidate\n",
      "parameters,thenconductvalidationontransfertaskA?Wbyrequiringone\n",
      "labeledexamplepercategoryfromtargetdomainWasthevalidationset,and\n",
      "theselectedparametersthroughoutalltransfertasks.Weimplementall\n",
      "deepmethodsbasedonthedeep-learningframework,andfrom\n",
      "videdmodelsofAlexNet[26]pre-trainedonImageNet.ForRTN,We\n",
      "allthefeaturelayers,trainbottlenecklayerfcb,layerfcc\n",
      "andresiduallayersfc1?fc2,allthroughstandardback-propagation.Sincethese\n",
      "newlayersaretrainedfromscratch,wesettheirlearningratetobe10times\n",
      "thatoftheotherlayers.Weusemini-batchstochasticgradientdescent(SGD)\n",
      "withmomentumof0.9andthelearningrateannealingstrategyimplementedin\n",
      "RevGrad[6]:thelearningrateisnotselectedthroughagridsearchduetohigh\n",
      "computationalcost?itisadjustedduringSGD?0usingthefollowingformula:\n",
      "9\n",
      "\n",
      "?p=(1+?p)?,wherepisthetrainingprogresslinearlychangingfrom0to\n",
      "1,?0=0.01,?=10and?=0.75,whichisoptimizedforlowerroronthe\n",
      "sourcedomain.AsRTNcanworkstablyacrossttransfertasks,the\n",
      "MMDpenaltyparameter?andentropypenalty?areselectedonA?W\n",
      "andthenas?=0.3,?=0.3forallothertransfertasks.4.2\n",
      "Results\n",
      "Theaccuracyresultsonthesixtransfertasksofare\n",
      "showninTable1,andtheresultsonthetwelvetransfertasksofh\n",
      "areshowninTable2.TheRTNmodelbasedonAlexNet(Figure1)outperforms\n",
      "allcomparisonmethodsonmosttransfertasks.Inparticular,RTNsubstantially\n",
      "improvestheaccuracyonhardtransfertasks,e.g.A?WandC?W,wherethe\n",
      "sourceandtargetdomainsareveryt,andachievescomparableaccuracy\n",
      "oneasytransfertasks,D?WandW?D,wheresourceandtargetdomains\n",
      "aresimilar[13].TheseresultssuggestthatRTNisabletolearnmoreadaptive\n",
      "andtransferablefeaturesforsaferdomainadaptation.Fromthere-\n",
      "sults,wecanmakeinterestingobservations.(1)Standarddeep-learningmethods\n",
      "(AlexNet)performcomparablywithtraditionalshallowtransfer-learningmeth-\n",
      "odswithdeepDeCAF7featuresasinput(TCAandGFK).Theonly\n",
      "betweenthesetwosetsofmethodsisthatAlexNetcantaketheadvantageof\n",
      "supervisedonthesource-labeleddata,whileTCAandGFKcan\n",
      "takeboftheirdomainadaptationprocedures.Thisresultthe\n",
      "currentpracticethatsupervisedisimportantfortransferringsource\n",
      "totargetdomain[19],andsustainstherecentdiscoverythatdeepneu-\n",
      "ralnetworkslearnabstractfeaturerepresentation,whichcanonlyreduce,but\n",
      "notremove,thecross-domaindiscrepancy[3].Thisrevealsthatthetwoworlds\n",
      "ofdeep6\n",
      "Table1:Accuracyone-31datasetusingstandardprotocol[5]forun-\n",
      "supervisedadaptation.MethodTCA[9]GFK[14]AlexNet[26]DDC[4]DAN\n",
      "[5]RevGrad[6]RTN(mmd)RTN(mmd+ent)RTN(mmd+ent+res)\n",
      "A?W59.0?0.058.4?0.060.6?0.461.0?0.568.5?0.373.0?0.670.0?0.471.2?0.3\n",
      "73.3?0.3\n",
      "D?W90.2?0.093.6?0.095.4?0.295.0?0.396.0?0.196.4?0.496.1?0.396.4?0.2\n",
      "96.8?0.2\n",
      "W?D88.2?0.091.0?0.099.0?0.198.5?0.399.0?0.199.2?0.399.2?0.399.2?0.1\n",
      "99.6?0.1\n",
      "A?D57.8?0.058.6?0.064.2?0.364.9?0.466.8?0.267.6?0.469.8?0.271.0?0.2\n",
      "D?A51.6?0.052.4?0.045.5?0.547.2?0.550.0?0.449.8?0.450.2?0.350.5?0.3\n",
      "W?A47.9?0.046.1?0.048.3?0.549.4?0.649.8?0.350.0?0.350.7?0.251.0?0.1\n",
      "Avg65.866.768.869.371.772.172.973.7\n",
      "Table2:Accuracyonhdatasetusingstandardprotocol[5]for\n",
      "unsupervisedadaptation.MethodA?WD?WW?DA?DD?AW?AA?CW?C\n",
      "D?CC?AC?WC?DAvgTCA[9]84.496.999.482.890.485.681.275.579.6\n",
      "92.188.187.987.0GFK[14]89.597.098.186.089.888.576.277.177.990.7\n",
      "78.077.185.5AlexNet[26]79.597.7100.087.487.183.883.073.079.091.9\n",
      "83.787.186.1DDC[4]83.198.1100.088.489.084.983.573.479.291.985.4\n",
      "88.887.1DAN[5]91.898.5100.091.790.092.184.181.280.392.090.689.3\n",
      "10\n",
      "\n",
      "90.1RTN(mmd)93.298.5100.091.788.090.784.081.380.491.089.890.4\n",
      "90.0RTN(mmd+ent)93.898.6100.092.993.692.787.884.883.493.296.6\n",
      "93.992.6RTN(mmd+ent+res)95.299.2100.095.593.892.588.186.684.6\n",
      "93.796.994.293.4\n",
      "learninganddomainadaptationcannotreinforceeachothersubstantially\n",
      "inthetwo-steppipeline,whichmotivatescarefully-designeddeepadaptation\n",
      "architecturestounifythem.(2)Deep-transferlearningmethodsthatreduce\n",
      "thedomaindiscrepancybydomain-adaptivedeepnetworks(DDC,DANand\n",
      "RevGrad)substantiallyoutperformstandarddeeplearningmethods(AlexNet)\n",
      "andtraditionalshallowtransfer-learningmethodswithdeepfeaturesasthe\n",
      "input(TCAandGFK).Thisthatincorporatingdomain-adaptation\n",
      "modulesintodeepnetworkscanimprovedomainadaptationperformance.By\n",
      "adaptingsource-targetdistributionsinmultipletask-spelayersusingopti-\n",
      "malmulti-kerneltwo-samplematching,DANperformsthebestingeneralamong\n",
      "thepriordeep-transferlearningmethods.(3)Theproposedresidualtransfer\n",
      "network(RTN)performsthebestandsetsupanewstateoftheartresulton\n",
      "thesebenchmarkdatasets.tfromallthepreviousdeep-transferlearn-\n",
      "ingmethodsthatonlyadaptthefeaturelayersofdeepneuralnetworkstolearn\n",
      "moretransferablefeatures,RTNfurtheradaptsthelayerstobridgethe\n",
      "sourceandtargetclainanend-to-endresiduallearningframework,which\n",
      "cancorrectthemismatchmoreely.Togodeeperintot\n",
      "modulesofRTN,weshowtheresultsofRTNvariantsinTables1and2.(1)RTN\n",
      "(mmd)slightlyoutperformsDAN,butRTN(mmd)hasonlyoneMMDpenalty\n",
      "parameterwhileDANhastwoorthree.ThustheproposedtensorMMDmod-\n",
      "uleiseforadaptingmultiplefeaturelayersusingasingleMMDpenalty,\n",
      "whichisimportantforeasymodelselection.(2)RTN(mmd+ent)performssub-\n",
      "stantiallybetterthanRTN(mmd).Thishighlightstheimportanceofentropy\n",
      "minimizationforlow-densityseparation,whichexploitstheclusterstructureof\n",
      "target-unlabeleddatasuchthatthetargecanbebetteradaptedto\n",
      "thetargetdata.(3)RTN(mmd+ent+res)performsthebestacrossallvari-\n",
      "ants.Thishighlightstheimportanceofresidualtransferoflayersfor\n",
      "learningmoreadaptivecThisiscriticalasinpracticalapplications,\n",
      "thereisnoguaranteethatthesourceclasserandtargetcanbesafely\n",
      "shared.Itisworthnotingthat,theentropypenaltyandtheresidualmodule\n",
      "shouldbeusedtogether,otherwisetheresidualfunctiontendstolearnuseless\n",
      "zeromappingsuchthatthesourceandtargetarenearlyidentical[8].\n",
      "4.3\n",
      "Discussion\n",
      "PredictionsVisualization:WerespectivelyvisualizeinFigures2(a)?2(d)the\n",
      "t-SNEembeddings[2]ofthepredictionsbyDANandRTNontransfertaskA?\n",
      "W.Wecanmakethefollowingobservations.(1)ThepredictionsmadebyDAN\n",
      "inFigure2(a)?2(b)showthatthetargetcategoriesarenotwelldiscriminated\n",
      "bythesourcecwhichimpliesthattargetdataisnotwellcompatible\n",
      "withthesourceHencethesourceandtargetshouldnot\n",
      "beassumedtobeidentical,whichhasbeenacommonassumptionmadebyall\n",
      "priordeepdomainadaptationmethods[4,5,6,7].(2)Thepredictionsmadeby\n",
      "11\n",
      "\n",
      "RTNinFigures2(c)?2(d)showthatthetargetcategoriesarediscriminated7\n",
      "(a)DAN:Source=A\n",
      "(b)DAN:Target=W\n",
      "(c)RTN:Source=A\n",
      "(d)RTN:Target=W\n",
      "6\n",
      "fS(x)\n",
      "fT(x)\n",
      "?f(x)\n",
      "420\n",
      "mean\n",
      "deviation\n",
      "Statistics\n",
      "(a)LayerResponses\n",
      "-0.5\n",
      "-1fs\n",
      "-1.5\n",
      "10\n",
      "ft\n",
      "20\n",
      "Class\n",
      "(b)Shift\n",
      "30\n",
      "AverageAccuracy(%)\n",
      "LayerResponses\n",
      "8\n",
      "WeightParameters\n",
      "Figure2:Visualization:(a)-(b)t-SNEofDANpredictions;(c)-(d)t-SNEof\n",
      "RTNpredictions.10090807060\n",
      "A?W\n",
      "500.010.040.070.1\n",
      "C?W\n",
      "0.4\n",
      "0.7\n",
      "1\n",
      "?\n",
      "(c)Accuracyw.r.t.?\n",
      "Figure3:(a)layerresponses;(b)shift;(c)sensitivityof?(dashed\n",
      "linesshowbestbaselines).betterbythetarget(largerclass-to-class\n",
      "distances),whichsuggeststhatresidualtransferofisareasonable\n",
      "extensiontopreviousdeepfeatureadaptationmethods.RTNsimultaneously\n",
      "learnsmoreadaptiveclassiandmoretransferablefeaturestoenableec-\n",
      "tivedomainadaptation.LayerResponses:WeshowinFigure3(a)themeans\n",
      "andstandarddeviationsofthelayerresponses[8],whicharetheoutputsoffT\n",
      "(x)(fcclayer),?f(x)(fc2layer),andfS(x)(afterelement-wisesumopera-\n",
      "tor),respectively.Thisexposestheresponsestrengthoftheresidualfunctions.\n",
      "12\n",
      "\n",
      "Theresultsshowthattheresidualfunction?f(x)havegenerallymuchsmaller\n",
      "responsesthantheshortcutfunctionfT(x).Theseresultssupportourmoti-\n",
      "vationthattheresidualfunctionsaregenerallysmallerthanthenon-residual\n",
      "functions,astheycharacterizethesmallgapbetweenthesourceand\n",
      "targetThesmallresidualfunctioncanbelearnedelyviadeep\n",
      "residuallearning[8].Shift:Tojustifythatthereexistsaclassi\n",
      "shiftbetweensourcefsandtargetft,wetrainfsonsource\n",
      "domainandftontargetdomain,bothprovidedwithlabeleddata.BytakingA\n",
      "assourcedomainandWastargetdomain,theweightparametersoftheclassi-\n",
      "(e.g.softmaxregression)areshowninFigure3(b),whichshowsthatfsand\n",
      "ftaresubstantiallyt.ParameterSensitivity:Wecheckthesensitivity\n",
      "ofentropyparameter?ontransfertasksA?W(31classes)andC?W(10\n",
      "classes)byvaryingtheparameterin\n",
      "f\n",
      "0.01,0.04,0.07,0.1,0.4,0.7,1.0\n",
      "g\n",
      ".The\n",
      "resultsareshowninFigures3(c),withthebestresultsofthebaselinesshownas\n",
      "dashedlines.TheaccuracyofRTNincreasesandthendecreasesas?varies\n",
      "anddemonstratesadesirablebell-shapedcurve.Thisjourmotivationof\n",
      "jointlylearningtransferablefeaturesandadaptivebytheRTNmodel,\n",
      "asagoodbetweenthemcanpromotetransferperformance.\n",
      "5\n",
      "Conclusion\n",
      "Thispaperpresentedanovelapproachtounsuperviseddomainadaptation\n",
      "indeepnetworks,whichenablesend-to-endlearningofadaptiveand\n",
      "transferablefeatures.Similartomanypriordomainadaptationtechniques,fea-\n",
      "tureadaptationisachievedbymatchingthedistributionsoffeaturesacross\n",
      "domains.However,unlikepreviouswork,theproposedapproachalsosupports\n",
      "adaptation,whichisimplementedthroughanewresidualtransfermod-\n",
      "ulethatbridgesthesourceclaserandtargetcThismakestheap-\n",
      "proachagoodcomplementtoexistingtechniques.Theapproachcanbetrained\n",
      "bystandardback-propagation,whichisscalableandcanbeimplementedby\n",
      "mostdeeplearningpackage.Futureworkconstitutessemi-superviseddomain\n",
      "adaptationextensions.\n",
      "AcknowledgmentsThisworkwassupportedbytheNationalNaturalScience\n",
      "FoundationofChina(61502265,61325008),NationalKeyR&DProgramof\n",
      "China(2016YFB1000701,2015BAF32B01),andTNListKeyProject.8\n",
      "2References\n",
      "[1]S.J.PanandQ.Yang.Asurveyontransferlearning.TKDE,22(10):1345?1359,\n",
      "2010.[2]J.Donahue,Y.Jia,O.Vinyals,J.N.Zhang,E.Tzeng,and\n",
      "T.Darrell.Decaf:Adeepconvolutionalactivationfeatureforgenericvisual\n",
      "recognition.InICML,2014.[3]J.Yosinski,J.Clune,Y.Bengio,andH.Lip-\n",
      "son.Howtransferablearefeaturesindeepneuralnetworks?InNIPS,2014.[4]\n",
      "E.Tzeng,J.N.Zhang,K.Saenko,andT.Darrell.Deepdomaincon-\n",
      "fusion:Maximizingfordomaininvariance.2014.[5]M.Long,Y.Cao,J.Wang,\n",
      "andM.I.Jordan.Learningtransferablefeatureswithdeepadaptationnet-\n",
      "13\n",
      "\n",
      "works.InICML,2015.[6]Y.GaninandV.Lempitsky.Unsuperviseddomain\n",
      "adaptationbybackpropagation.InICML,2015.[7]E.Tzeng,J.N.\n",
      "Zhang,K.Saenko,andT.Darrell.Simultaneousdeeptransferacrossdomains\n",
      "andtasks.InICCV,2015.[8]K.He,X.Zhang,S.Ren,andJ.Sun.Deep\n",
      "residuallearningforimagerecognition.InCVPR,2016.[9]S.J.Pan,I.W.\n",
      "Tsang,J.T.Kwok,andQ.Yang.Domainadaptationviatransfercomponent\n",
      "analysis.TNNLS,22(2):199?210,2011.[10]L.Duan,I.W.Tsang,andD.Xu.\n",
      "Domaintransfermultiplekernellearning.TPAMI,34(3):465?479,2012.[11]\n",
      "K.Zhang,B.Sch?lkopf,K.Muandet,andZ.Wang.Domainadaptationunder\n",
      "targetandconditionalshift.InICML,2013.[12]X.WangandJ.Schneider.\n",
      "Flexibletransferlearningundersupportandmodelshift.InNIPS,2014.[13]K.\n",
      "Saenko,B.Kulis,M.Fritz,andT.Darrell.Adaptingvisualcategorymodelsto\n",
      "newdomains.InECCV,2010.[14]B.Gong,Y.Shi,F.Sha,andK.Grauman.\n",
      "Geodesicwkernelforunsuperviseddomainadaptation.InCVPR,2012.[15]\n",
      "J.S.Guadarrama,E.Tzeng,R.Hu,J.Donahue,R.Girshick,T.Dar-\n",
      "rell,andK.Saenko.LSDA:Largescaledetectionthroughadaptation.InNIPS,\n",
      "2014.[16]R.Collobert,J.Weston,L.Bottou,M.Karlen,K.Kavukcuoglu,\n",
      "andP.Kuksa.Naturallanguageprocessing(almost)fromscratch.JMLR,\n",
      "12:2493?2537,2011.[17]Y.Bengio,A.Courville,andP.Vincent.Representa-\n",
      "tionlearning:Areviewandnewperspectives.TPAMI,35(8):1798?1828,2013.\n",
      "[18]X.Glorot,A.Bordes,andY.Bengio.Domainadaptationforlarge-scalesen-\n",
      "timentAdeeplearningapproach.InICML,2011.[19]M.Oquab,\n",
      "L.Bottou,I.Laptev,andJ.Sivic.Learningandtransferringmid-levelimage\n",
      "representationsusingconvolutionalneuralnetworks.InCVPR,June2013.[20]\n",
      "J.Ngiam,A.Khosla,M.Kim,J.Nam,H.Lee,andA.Y.Ng.Multimodaldeep\n",
      "learning.InICML,2011.[21]Y.Mansour,M.Mohri,andA.Rostamizadeh.\n",
      "Domainadaptation:Learningboundsandalgorithms.InCOLT,2009.[22]S.\n",
      "Ben-David,J.Blitzer,K.Crammer,A.Kulesza,F.Pereira,andJ.W.Vaughan.\n",
      "Atheoryoflearningfromtdomains.MLJ,79(1-2):151?175,2010.[23]\n",
      "J.Yang,R.Yan,andA.G.Hauptmann.Cross-domainvideoconceptdetection\n",
      "usingadaptivesvms.InMM,pages188?197.ACM,2007.[24]LixinDuan,\n",
      "IvorWTsang,DongXu,andTat-SengChua.Domainadaptationfrommulti-\n",
      "plesourcesviaauxiliaryclaInICML,pages289?296.ACM,2009.[25]\n",
      "L.Duan,D.Xu,I.W.Tsang,andJ.Luo.Visualeventrecognitioninvideosby\n",
      "learningfromwebdata.TPAMI,34(9):1667?1680,2012.[26]A.Krizhevsky,I.\n",
      "Sutskever,andG.E.Hinton.Imagenetclasscationwithdeepconvolutional\n",
      "neuralnetworks.InNIPS,2012.[27]A.Gretton,K.Borgwardt,M.Rasch,B.\n",
      "Sch?lkopf,andA.Smola.Akerneltwo-sampletest.JMLR,13:723?773,March\n",
      "2012.[28]Y.GrandvaletandY.Bengio.Semi-supervisedlearningbyentropy\n",
      "minimization.InNIPS,2004.[29]Tsung-YuLin,AruniRoyChowdhury,and\n",
      "SubhransuMaji.Bilinearcnnmodelsforvisualrecognition.In\n",
      "CVPR,pages1449?1457,2015.[30]B.Sun,J.Feng,andK.Saenko.Returnof\n",
      "frustratinglyeasydomainadaptation.InAAAI,2016.[31]A.TorralbaandA.\n",
      "A.Efros.Unbiasedlookatdatasetbias.InCVPR,2011.\n",
      "9\n",
      "14\n",
      "\n",
      "PP4707.pdf\n",
      "PP4707.pdf 13\n",
      "ExpectationPropagationinGaussianProcess\n",
      "DynamicalSystems\n",
      "Authoredby:\n",
      "ShakirMohamed\n",
      "MarcDeisenroth\n",
      "Abstract\n",
      "Richandcomplextime-seriesdata,suchasthosegeneratedfromen-\n",
      "gineeringsys-tems,markets,videosorneuralrecordingsare\n",
      "nowacommonfeatureofmoderndataanalysis.Explainingthephe-\n",
      "nomenaunderlyingthesediversedatasetsrequiresandaccurate\n",
      "models.Inthispaper,wepromoteGaussianprocessdynamicalsystems\n",
      "asarichmodelclassappropriateforsuchanalysis.Inparticular,we\n",
      "presentamessagepassingalgorithmforapproximateinferenceinGPDSs\n",
      "basedonexpectationpropagation.Byphrasinginferenceasageneral\n",
      "mes-sagepassingproblem,weiterateforward-backwardsmoothing.We\n",
      "obtainmoreaccurateposteriordistributionsoverlatentstructures,re-\n",
      "sultinginimprovedpre-dictiveperformancecomparedtostate-of-the-art\n",
      "GPDSsmoothers,whicharespe-cialcasesofourgeneraliterativemes-\n",
      "sagepassingalgorithm.Hence,weprovideaunifyingapproachwithin\n",
      "whichtocontextualizemessagepassinginGPDSs.\n",
      "1PaperBody\n",
      "Richandcomplextime-seriesdata,suchasthosegeneratedfromengineering\n",
      "systems,markets,videos,orneuralrecordingsarenowacommonfea-\n",
      "tureofmoderndataanalysis.Explainingthephenomenaunderlyingthesedi-\n",
      "versedatasetsrequiresandaccuratemodels.Inthispaper,wepromote\n",
      "Gaussianprocessdynamicalsystemsasarichmodelclassthatisappropriatefor\n",
      "suchananalysis.Wepresentanewapproximatemessage-passingalgorithmfor\n",
      "BayesianstateestimationandinferenceinGaussianprocessdynamicalsystems,\n",
      "anonparametricprobabilisticgeneralizationofcommonlyusedstate-spacemod-\n",
      "els.Wederiveourmessage-passingalgorithmusingExpectationPropagation\n",
      "andprovideaunifyingperspectiveonmessagepassingingeneralstate-space\n",
      "models.WeshowthatexistingGaussianandsmoothersappearasspecial\n",
      "caseswithinourinferenceframework,andthattheseexistingapproachescan\n",
      "beimproveduponusingiteratedmessagepassing.Usingbothsyntheticand\n",
      "1\n",
      "\n",
      "real-worlddata,wedemonstratethatiteratedmessagepassingcanimprovein-\n",
      "ferenceinawiderangeoftasksinBayesianstateestimation,thusleadingto\n",
      "improvedpredictionsandmoreedecisionmaking.\n",
      "1\n",
      "Introduction\n",
      "TheKalmananditsextensions[1],suchastheextendedandunscented\n",
      "Kalman[7],areprincipledstatisticalmodelsthathavebeenwidelyused\n",
      "forsomeofthemostchallengingandmission-criticalapplicationsinautomatic\n",
      "control,robotics,machinelearning,andeconomics.Indeed,wherevercomplex\n",
      "time-seriesarefound,KalmanhavebeensuccessfullyappliedforBayesian\n",
      "stateestimation.However,inpractice,timeseriesoftenhaveanunknowndy-\n",
      "namicalstructure,andtheyarehighdimensionalandnoisy,violatingmanyof\n",
      "theassumptionsmadeinestablishedapproachesforstateestimation.Inthis\n",
      "paper,welookbeyondtraditionallineardynamicalsystemsandadvancethe\n",
      "state-ofthe-artinstateestimationbydevelopingnovelinferencealgorithmsfor\n",
      "theclassofnonlinearGaussianprocessdynamicalsystems(GPDS).GPDSsare\n",
      "non-parametricgeneralizationsofstate-spacemodelsthatallowforinference\n",
      "intimeseries,usingGaussianprocess(GP)probabilitydistributionsovernon-\n",
      "lineartransitionandmeasurementdynamics.GPDSsarethusabletocapture\n",
      "complexdynamicalstructurewithfewassumptions,makingthemofbroadin-\n",
      "terest.Thisinteresthassparkedthedevelopmentofgeneralapproachesfor\n",
      "andsmoothinginGPDSs,suchas[8,3,5].Inthispaper,wefurther\n",
      "developinferencealgorithmsforGPDSsandmakethefollowingcontributions:\n",
      "(1)WedevelopaniterativelocalmessagepassingframeworkforGPDSsbased\n",
      "onExpectationPropagation(EP)[11,10],whichallowsfortofthe\n",
      "posteriordistributionand,hence,improvedinference.(2)Weshowthatthegen-\n",
      "eralmessage-passingframeworkrecoverstheEPupdatesforexistingdynamical\n",
      "systemsasaspecialcaseandexposetheimplicitmodelingassumptionsmade\n",
      "inthesemodels.WeshowthatEPinGPDSsencapsulatesallGPDSforward-\n",
      "backwardsmoothers[5]asaspecialcaseandtransformsthemintoiterative\n",
      "algorithmsyieldingmoreaccurateinference.*Authorscontributedequally.\n",
      "1\n",
      "2\n",
      "GaussianProcessDynamicalSystems\n",
      "Gaussianprocessdynamicalsystemsareageneralclassofdiscrete-time\n",
      "state-spacemodelswithxt=h(xt?1)+wt,wt?N(0,Q),h?GPh,\n",
      "(1)zt=g(xt)+vt,vt?N(0,R),g?GPg,(2)\n",
      "wheret=1,...,T.Here,x?RDisalatentstatethatevolvesovertime,\n",
      "andz?RE,E?D,aremeasurements.Weassumei.i.d.additiveGaussian\n",
      "systemnoisewandmeasurementnoisev.Thecentralfeatureofthismodel\n",
      "classisthatboththemeasurementfunctiongandthetransitionfunctionh\n",
      "arenotexplicitlyknownorparametricallyspbutinsteaddescribedby\n",
      "probabilitydistributionsoverthesefunctions.Thefunctiondistributionsare\n",
      "non-parametricGaussianprocesses(GPs),andwewriteh?GPhandg?GP\n",
      "g,respectively.AGPisaprobabilitydistributionp(f)overfunctionsfthatis\n",
      "spbyameanfunction?fandacovariancefunctionkf[15].Consideraset\n",
      "2\n",
      "\n",
      "oftraininginputsX=[x1,...,xn]>and2correspondingtrainingtargetsy\n",
      "=[y1,...yn]>,yi=f(xi)+w,w?N(0,?w).Theposteriorpredictive\n",
      "distributionatatestinputx?isGaussiandistributedN(y?|?f(x?),?f2\n",
      "(x?))with?1?1mean?f(x?)=k>yandvariance?f2(x?)=k???k>k?,\n",
      "wherek?=kf(X,x?),?K?Kk??=kf(x?,x?),andKisthekernelmatrix.\n",
      "SincetheGPisanon-parametricmodel,itsuseinGPDSsisdesirableasit\n",
      "resultsinfewerrestrictivemodelassumptions,comparedtodynamicalsystems\n",
      "basedonparametricfunctionapproximatorsforthetransitionandmeasurement\n",
      "functions(1)?(2).Inthispaper,weassumethattheGPmodelsaretrained,\n",
      "i.e.,thetraininginputsandcorrespondingtargetsaswellastheGPhyperpa-\n",
      "rametersareknown.ForbothGPhandGPgintheGPDS,weusedzeroprior\n",
      "meanfunctions.Ascovariancefunctionskhandkgweusesquared-exponential\n",
      "covariancefunctionswithautomaticrelevancedeterminationplusanoiseco-\n",
      "variancefunctiontoaccountforthenoisein(1)?(2).Existingworkforlearning\n",
      "GPDSsincludestheGaussianprocessdynamicalmodel(GPDM)[20],which\n",
      "tacklesthechallengingtaskofanalyzinghumanmotionin(high-dimensional)\n",
      "videosequences.Morerecently,variational[2]andEM-based[19]approaches\n",
      "forlearningGPDSwereproposed.ExactBayesianinference,i.e.,and\n",
      "smoothing,inGPDSsisanalyticallyintractablebecauseofthedependencyof\n",
      "thestatesandmeasurementsonpreviousstatesthroughthenonlinearityofthe\n",
      "GP.Wethusmakeuseofapproximationstoinfertheposteriordistributions\n",
      "p(xt|Z)overlatentstatesxt,t=1,...,T,givenasetofobservationsZ\n",
      "=z1:T.Existingapproximateinferenceapproachesforandforward-\n",
      "backwardsmoothingarebasedoneitherlinearization,particlerepresentations,\n",
      "ormomentmatchingasapproximationstrategies[8,3,5].Aprincipledin-\n",
      "corporationoftheposteriorGPmodeluncertaintyintoinferenceinGPDSsis\n",
      "necessary,butintroducesadditionaluncertainty.Intrackingproblemswhere\n",
      "thelocationofanobjectisnotdirectlyobserved,thisadditionalsourceofun-\n",
      "certaintycaneventuallyleadtolosingtrackofthelatentstate.Inthispaper,we\n",
      "addressthisproblemandproposeapproximatemessagepassingbasedonEP\n",
      "formoreaccurateinference.Wewillshowthatforward-backwardsmoothing\n",
      "inGPDSs[5]bfromtheiterativetschemeofEP,leadingto\n",
      "moreaccurateposteriordistributionsoverthelatentstateand,hence,tomore\n",
      "informativepredictionsandimproveddecisionmaking.\n",
      "3\n",
      "BayesianStateEstimationusingExpectationPropagation\n",
      "ExpectationPropagation[10,11]isawidely-useddeterministicalgorithm\n",
      "forapproximateBayesianinferencethathasbeenshowntobehighlyaccurate\n",
      "inmanyproblems,includingsparseregressionmodels[17],GP[9],\n",
      "andinferenceindynamicalsystems[13,6,18].EPisderivedusingafactor-\n",
      "graph,inwhichthedistributionQoverthelatentstatep(xt|Z)isrepresented\n",
      "astheproductoffactors(xt),i.e.,p(xt|Z)=i(xt).EPthenspeces\n",
      "anQiterativemessagepassingalgorithminwhichp(xt|Z)isapproximated\n",
      "byadistributionq(xt)=iqi(xt),usingapproximatemessagesqi(xt).In\n",
      "EP,qandthemessagesqiaremembersoftheexponentialfamily,andqis\n",
      "determinedsuchthatthetheKL-divergenceKL(p||q)isminimized.EPis\n",
      "3\n",
      "\n",
      "provablyrobustforlog-concavemessages[17]andinvariantunderinvertible\n",
      "variabletransformations[16].Inpractice,EPhasbeenshowntobemoreaccu-\n",
      "ratethancompetingapproximateinferencemethods[9,17].Inthecontextof\n",
      "thedynamicalsystem(1)?(2),weconsiderfactorgraphsoftheformofFig.1\n",
      "withthreetypesofmessages:forward,backward,andmeasurementmessages,\n",
      "denotedbythesymbols2\n",
      "qB(xt)\n",
      "xt\n",
      "qM(xt)\n",
      "p(xt+1|xt)\n",
      "qB(xt)\n",
      "qC(xt+1)\n",
      "xt+1\n",
      "qC(xt)qB(xt+1)\n",
      "xt\n",
      "qM(xt)\n",
      "qM(xt+1)\n",
      "xt+1\n",
      "qC(xt+1)\n",
      "qM(xt+1)\n",
      "Figure1:Factorgraph(left)andfullyfactoredgraph(right)ofageneral\n",
      "dynamicalsystem.Algorithm1GaussianEPforDynamicalSystems1:Init:\n",
      "SetallfactorsqitoN(0,?I);Setq(x1)=p(x1)andmarginalsq(xt6=1)=\n",
      "N(0,1010I)2:repeat3:fort=1toTdo4:forallfactorsqi(xt),wherei=\n",
      "B,M,Cdo5:Computecavitydistributionqi(xt)=q(xt)/qi(xt)=N(xt\n",
      "|?i,?i)with?1?1?i=(??1,t??i)\n",
      "6:\n",
      "?1?i=?i(??1t?t??i?i)\n",
      "Determinemomentsof(xt)qi(xt),e.g.,viathederivativesoflogZi(?i\n",
      ",?i)=log?(xt)qi(xt)dxt\n",
      "7:\n",
      "(3)\n",
      "(4)\n",
      "Updatetheposteriorq(xt)?N(xt|?t,?t)andtheapproximatefactor\n",
      "qi(xt):?t=?i+?i?>m,i\n",
      "?m:=dlogZi/d?,\n",
      "i?t=?i??i(?>m?m?2?s)?i\n",
      "?s:=dlogZi/d?\n",
      "i\n",
      "qi(xt)=q(xt)/q(xt)\n",
      "(5)(6)(7)\n",
      "8:endfor9:endfor10:untilConvergenceormaximumnumberofiterations\n",
      "exceeded\n",
      "B,C,M,respectively.ForEPinference,weassumeafully-factoredgraph,\n",
      "usingwhichwecomputethemarginalposteriordistributionsp(x1|Z),...,\n",
      "p(xT|Z),ratherthanthefulljointdistributionp(X|Z)=p(x1,...,xT\n",
      "4\n",
      "\n",
      "|Z).Boththestatesxtandmeasurementsztarecontinuousvariablesandthe\n",
      "messagesqiareunnormalizedGaussians,i.e.,qi(xt)=siN(xt|?i,?i)3.1\n",
      "ImplicitLinearizationsRequireExplicitConsideration\n",
      "Alg.1describesthemainstepsofGaussianEPfordynamicalsystems.For\n",
      "eachnodextinthefully-factoredfactorgraphinFig.1,EPcomputesthree\n",
      "messages:aforward,backward,andmeasurementmessage,denotedbyqB(xt\n",
      "),qC(xt),andqM(xt),respectively.TheEPalgorithmupdatesthemarginal\n",
      "q(xt)andthemessagesqi(xt)inthreesteps.First,thecavitydistributionq\n",
      "i(xt)iscomputed(step5inAlg.1)byremovingqi(xt)fromthemarginal\n",
      "q(xt).Second,intheprojectionstep,themomentsof(xt)qi(xt)are\n",
      "computed(step6),whereisthetruefactor.Intheexponentialfamily,the\n",
      "requiredmomentscanbecomputedusingthederivativesofthelog-partition\n",
      "function(normalizingconstant)logZiof(xt)qi(xt)[10,11,12].Third,the\n",
      "momentsofthemarginalq(xt)aresettothemomentsof(xt)qi(xt),and\n",
      "themessageqi(xt)isupdated(step7).Weapplythisprocedurerepeatedly\n",
      "toalllatentstatesxt,t=1,...,T,untilconvergence.EPdoesnot\n",
      "directlyaGaussianapproximationqitothenon-Gaussianfactor.Instead,\n",
      "EPdeterminesthemomentsofqiinthecontextofthecavitydistributionsuch\n",
      "thatqi=proqi]/qi,whereproj[?]istheprojectionoperator,returning\n",
      "themomentsofitsargument.Toupdatetheposteriorq(xt)andthemessages\n",
      "qi(xt),EPcomputesthelog-partitionfunctionlogZiin(4)tocompletethe\n",
      "projectionstep.However,fornonlineartransitionandmeasurementmodels3\n",
      "in(1)?(2),computingZiinvolvessolvingintegralsoftheformZZp(a)=\n",
      "p(a|xt)p(xt)dxt=N(a|m(xt),S(xt))N(xt|b,B)dxt,\n",
      "(8)\n",
      "wherea=ztforthemeasurementmessage,ora=xt+1fortheforward\n",
      "andbackwardmessages.Innonlineardynamicalsystemsm(xt)isanonlin-\n",
      "earmeasurementortransitionfunction.InGPDSs,m(xt)andS(xt)arethe\n",
      "correspondingpredictiveGPmeansandcovariances,respectively,whichare\n",
      "nonlinearlyrelatedtoxt.Becauseofthenonlineardependenciesbetweena\n",
      "andxt,solving(8)isanalyticallyintractable.Weproposetoapproximatep(a)\n",
      "byaGaussiandistribution?ThisGaussianapproximationisonlycorrectfor\n",
      "alinearrelationshipa=Jxt,where??).N(a|?,Jisindependentofxt.\n",
      "Hence,theGaussianapproximationisanimplicitlinearizationofthefunctional\n",
      "relationshipbetweenaandxt,elylinearizingeitherthetransitionor\n",
      "themeasurementmodels.WhencomputingEPupdatesusingthederivatives\n",
      "?mand?saccordingto(5),itiscrucialtoexplicitlyaccountfortheimplicit\n",
      "linearizationassumptioninthederivatives?otherwise,theEPupdatesarein-\n",
      "consistent.Forexample,inthemeasurementandthebackwardmessage,we\n",
      "directly?i).Theconsis?i,?approximatethepartitionfunctionsZi,i?\n",
      "f\n",
      "M,\n",
      "C\n",
      "g\n",
      "byGaussiansZ?i(a)=N(?itentderivativesd(logZ?i)/d?iandd(logZ?i\n",
      ")/d?ofZ?iwithrespecttothemeanandcovarianceofthecavitydistribution\n",
      "qareobtainedbyapplyingthechainrule,suchthat?m=?s=?i????i\n",
      "?idlogZd?i?idlogZd?i\n",
      "==\n",
      "?i???i?logZ?i??i???i\n",
      "5\n",
      "\n",
      "?i???logZ?i??i??\n",
      "=J>?RE?D,\n",
      "?i????i\n",
      "?i)?1J>?R1?D,?i)>(?=(a??\n",
      "?i?i?logZ?iZ?i????=12??(log?RD?D,?i)>???i???i=JI4\n",
      "J>?RE?E?D?D,\n",
      "(9)(10)(11)\n",
      "whereI4?RD?D?D?Disanidentitytensor.Notethatwiththeimplicit\n",
      "linearmodela=Jxt,?i/??ivanish.AlthoughweapproximateZibya\n",
      "GaussianZ?i,?i/??iand??thederivatives???i,whichalso?iand\n",
      "covariancematrix?wearestillfreetochooseamethodofcomputingitsmean\n",
      "??iaregeneralfunctions?i)/??i.However,evenif??iand?\n",
      "thecomputationofJ=?(??i/??imustequalthecorrespondingpartial?i\n",
      "/??iand??of?iand?i,thederivatives??i?/??imustbesetto0.Hence,\n",
      "theimplicitlinearization?i/??iand??derivativesin(11),and??expressed\n",
      "bytheGaussianapproximationZ?imustbeexplicitlytakenintoaccountinthe\n",
      "derivativestoguaranteeconsistentEPupdates.3.2\n",
      "MessagesinGaussianProcessDynamicalSystems\n",
      "WenowdescribeeachofthemessagesneededforinferenceinGPDSs,and\n",
      "outlinetheapproximationsrequiredtocomputethepartitionfunctionin(4).\n",
      "Updatingamessagerequiresaprojectiontocomputethemomentsofthenew\n",
      "posteriormarginalq(xt),followedbyaGaussiandivisiontoupdatethemessage\n",
      "itself.Fortheprojectionstep,wecomputeapproximatepartitionfunctionsii\n",
      "Z?i,wherei?\n",
      "f\n",
      "M,B,C\n",
      "g\n",
      ".UsingthederivativesdlogZ?i/d?tanddlogZ?i\n",
      "/d?t,weupdatethemarginalq(xt),see(5).MeasurementMessageForthe\n",
      "measurementmessageinaGPDS,thepartitionfunctionisZZMMMMZM\n",
      "(?t,?t)=fM(xt)qM(xt)dxt?fM(xt)N(xt|?t,?t)dxt,(12)fM(xt)\n",
      "=p(zt|xt)=N(zt|?g(xt),?g(xt)),\n",
      "(13)\n",
      "wherefMisthetruemeasurementfactor,and?g(xt)and?g(xt)arethe\n",
      "predictivemeanandcovarianceofthemeasurementGPGPg.In(12),we\n",
      "madeitexplicitthatZMdependsonthemomentsMM?tand?tofthecavity\n",
      "distributionqM(xt).Theintegralin(12)isoftheform(8),butisintractable\n",
      "sincesolvingitcorrespondstoaGPpredictionatuncertaininputs[14],resulting\n",
      "innonGaussianpredictivedistributions.However,themeanandcovarianceofa\n",
      "GaussianapproximationZ?MtoZMcanbecomputedanalytically:eitherusing\n",
      "exactmomentmatching[14,3],orapproximatelybyexpectedlinearizationof\n",
      "theposteriorGP[8];detailsaregivenin[4].Themomentsof4\n",
      "MMZ?Marealsofunctionsofthemean?tandvariance?tofthecavity\n",
      "distribution.BytakingthelinearizationassumptionoftheGaussianapproxima-\n",
      "tionintoaccountexplicitly(here,weimplicitlylinearizeGPg)whencomputing\n",
      "thederivatives,theEPupdatesremainconsistent,seeSec.3.1.\n",
      "BackwardMessageToupdatethebackwardmessageqC(xt),werequire\n",
      "thepartitionfunctionZZCCCCZC(?t,?t)=fC(xt)qC(xt)dxt?fC\n",
      "(xt)N(xt|?t,?t)dxt,(14)ZZfC(xt)=p(xt+1|xt)qB(xt+1)dxt+1\n",
      "=N(xt+1|?h(xt),?h(xt))qB(xt+1)dxt+1.(15)Here,thetruefactor\n",
      "6\n",
      "\n",
      "fC(xt)in(15)takesintoaccountthecouplingbetweenxtandxt+1,which\n",
      "waslostinassumingthefullfactorizationinFig.1.Thepredictivemeanand\n",
      "covarianceofGPharedenoted?h(xt)and?h(xt),respectively.Using(15)\n",
      "in(14)andreorderingtheintegrationyieldsZZCCZC(?t,?t)?qB(xt+1\n",
      ")p(xt+1|xt)qC(xt)dxtdxt+1.(16)?C)by?C,?Weapproximate\n",
      "theinnerintegralin(16),whichisoftheform(8),byN(xt+1|?CCC\n",
      "??Cand?momentmatching[14],forinstance.Notethat?arefunctions\n",
      "of?tand?t.ThisGaussianapproximationimplicitlylinearizesGPh.Now,\n",
      "(16)canbecomputedanalytically,andB?C+?B)ofZCthatallowsusto\n",
      "?C,?weobtainaGaussianapproximationZ?C=N(?t+1|?t+1update\n",
      "themomentsofq(xt)andthemessageqC(xt).ForwardMessagepartition\n",
      "function\n",
      "Similarly,fortheforwardmessage,theprojectionstepinvolvescomputing\n",
      "the\n",
      "ZZBBBBZB(?t,?t)=fB(xt)qB(xt)dxt=fB(xt)N(xt|?t,?t\n",
      ")dxt,(17)ZZfB(xt)=p(xt|xt?1)qC(xt?1)dxt?1=N(xt|?f(xt?1),?f\n",
      "(xt?1))qC(xt?1)dxt?1,wherethetruefactorfB(xt)takesintoaccountthe\n",
      "couplingbetweenxt?1andxt,seeFig.1.Here,thetruefactorfB(xt)isof\n",
      "theform(8).WeproposetoapproximatefB(xt)directlybyaGaussian?B\n",
      ").ThisapproximationimplicitlylinearizesGPh.Weobtaintheupdated?B,\n",
      "?qB(xt)?N(?posteriorq(xt)byGaussianmultiplication,i.e.,q(xt)?qB\n",
      "(xt)qB(xt).Withthisapproximationwedonotupdatetheforwardmessage\n",
      "incontext,i.e.,thetruefactorfB(xt)isdirectlyapproximatedinsteadofthe\n",
      "productfB(xt)qB(xt),whichcanresultinsuboptimalapproximation.3.3\n",
      "EPUpdatesforGeneralGaussianSmoothers\n",
      "WecaninterprettheEPcomputationsinthecontextofclassicalGaussian\n",
      "andsmoothing[1].Duringtheforwardsweep,themarginalq(xt)=\n",
      "qC(xt)correspondstothedistributionp(xt|z1:t).Moreover,the\n",
      "cavitydistributionqM(xt)correspondstothetimeupdatep(xt|z1:t?1).\n",
      "Inthebackwardsweep,themarginalq(xt)isthesmoothingdistributionp(xt\n",
      "|Z),incorporatingthemeasurementsoftheentiretimeseries.Themeanand\n",
      "covarianceofZ?Ccanbeinterpretedasthemeanandcovarianceofthetime\n",
      "updatep(xt+1|z1:t).Updatingthemomentsoftheposteriorq(xt)viathe\n",
      "derivativesofthelog-partitionfunctionrecoversexactlythestandardGaussian\n",
      "EPupdatesindynamicalsystemsdescribedbyQiandMinka[13].Forexample,\n",
      "whenincorporatinganupdatedmeasurementmessage,themomentsin(5)can\n",
      "alsobexzMMMMzxM,respectively,where?t=writtenas?t=?t+K(zt\n",
      "??z)and?t=?t?K?tMMxzMMM?1Mcov[xt,zt]andK=?t(?z).\n",
      "Here,?z=E[g(xt)]and?z=cov[g(xt)],wherext?qM(xt).Similarly,the\n",
      "updatedmomentsofq(xt)withanewbackwardmessagevia(5)C\n",
      "C\n",
      "C\n",
      ">correspondtotheupdates[13]?t=?t+L(?t+1??t+1)and?t=?Ct\n",
      "+L(?t+1??t+1)L,CCCCCwhereL=cov[xt,xt+1](?t+1)?1.Here,\n",
      "we?t+1=E[h(xt)]and?t+1=cov[h(xt)],wherext?qC(xt).\n",
      "5\n",
      "7\n",
      "\n",
      "Table1:Performancecomparisononthesyntheticdataset.Lowervalues\n",
      "arebetter.NLLxMAExNLLz\n",
      "EKS?2.04?0.070.03?2.0?10?3?0.69?0.11\n",
      "EP-EKS?2.17?0.040.03?2.0?10?3?0.73?0.11\n",
      "GPEKS?1.67?0.220.04?4.6?10?2?0.75?0.08\n",
      "EP-GPEKS?1.87?0.140.04?4.6?10?2?0.81?0.07\n",
      "GPADS+1.67?0.371.79?0.211.93?0.28\n",
      "EP-GPADS?1.91?0.100.04?4?10?3?0.77?0.07\n",
      "Theiterativemessage-passingalgorithminAlg.1providesanEP-basedgen-\n",
      "eralizationandaunifyingviewofexistingapproachesforsmoothingindynami-\n",
      "calsystems,e.g.,(Extended/Unscented/Cubature)Kalmansmoothingandthe\n",
      "correspondingGPDSsmoothers[5].Computingthemessagesviathederivatives\n",
      "oftheapproximatelog-partitionfunctionslogZ?irecoversnotonlystandard\n",
      "EPupdatesindynamicalsystems[13],butalsothestandardKalmansmooth-\n",
      "ingupdates[1].Usinganypredictionmethod(e.g.,unscentedtransformation,\n",
      "linearization),wecancomputeGaussianapproximationsof(8).This\n",
      "thecomputationoflogZ?ianditsderivativeswithrespecttothemoments\n",
      "ofthecavitydistribution,see(9)?(10).Hence,ourmessage-passingformula-\n",
      "tionisalsogeneralasitincludesallconceivableGaussianothersin\n",
      "(GP)DSs,solelydependingonthepredictiontechniqueused.\n",
      "4\n",
      "ExperimentalResults\n",
      "WeevaluatedourproposedEP-basedmessagepassingalgorithmonthree\n",
      "datasets:asyntheticdataset,alow-dimensionalsimulatedmechanicalsys-\n",
      "temwithcontrolinputs,andahigh-dimensionalmotion-capturedataset.We\n",
      "comparedtoexistingstate-of-the-artforward-backwardsmoothersinGPDSs,\n",
      "sptheGPEKS[8],whichisbasedontheexpectedlinearizationofthe\n",
      "GPmodels,andtheGPADS[5],whichusesmoment-matching.Wereferto\n",
      "ourEPgeneralizationsofthesemethodsasEP-GPEKSandEP-GPADS.Inall\n",
      "ourexperiments,weevaluatedtheinferencemethodsusingtestsequencesof\n",
      "measurementsZ=[z1,...,zT].Wereportthenegativelog-likelihoodof\n",
      "predictedmeasurementsusingtheobservedtestsequence(NLLz).Whenever\n",
      "available,wealsocomparedtheinferredposteriordistributionq(X)?p(X|Z)\n",
      "ofthelatentstateswiththeunderlyinggroundtruthusingtheaveragenegative\n",
      "log-likelihood(NLLx)andMeanAbsoluteErrors(MAEx).WeterminatedEP\n",
      "after100iterationsorwhentheaveragenormsoftheofthemeans\n",
      "andcovariancesofq(X)intwosubsequentEPiterationsweresmallerthan10?6\n",
      ".4.1\n",
      "SyntheticData\n",
      "Weconsideredthenonlineardynamicalsystemxt+1=4sin(xt)+w,\n",
      "w?N(0,0.12),\n",
      "zt=4sin(xt)+v,\n",
      "v?N(0,0.12).\n",
      "Weusedp(x1)=N(0,1)asapriorontheinitiallatentstate.Weassumed\n",
      "accesstothelatentstateandtrainedthedynamicsandmeasurementGPsusing\n",
      "30randomlygeneratedpoints,resultinginamodelwithasubstantialamount\n",
      "8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ofposteriormodeluncertainty.ThelengthofthetesttrajectoryusedwasT\n",
      "=20timesteps.Tab.1reportsthequalityoftheinferredposteriordistri-\n",
      "butionsofthelatentstatetrajectoriesusingtheaverageNLLx,MAEx,and\n",
      "NLLz(withstandarderrors),averagedover10independentscenarios.Forthis\n",
      "dataset,wealsocomparedtotheExtendedKalmanSmoother(EKS)andan\n",
      "EP-iteratedEKS(EP-EKS).Bothinferencemethodsmakeuseoftheknown\n",
      "transitionandmeasurementmappingshandg,respectively.Iteratedforward-\n",
      "backwardsmoothingwithEP(EP-EKS,EP-GPEKS,EPGPADS)improvedthe\n",
      "smoothingposteriorsusingasinglesweeponly(EKS,GPEKS,GPADS).The\n",
      "GPADSperformedpoorlyacrossallourevaluationcriteriafortworeasons:\n",
      "First,theGPsweretrainedusingfewdatapoints,resultinginposteriordistri-\n",
      "butionswithahighdegreeofuncertainty.Second,predictivevariancesusing\n",
      "moment-matchingaregenerallyconservativeandincreasedtheuncertaintyeven\n",
      "further.ThisuncertaintycausedtheGPADStoquicklylosetrackoftheperiod\n",
      "ofthestate,asshowninFig.2(a).Byiteratingforward-backwardsmoothing\n",
      "usingEP(EP-GPADS),theposteriorsp(xt|Z)wereiterativelyand\n",
      "thelatentstatecouldbefollowedcloselyasindicatedbyboththesmallblue\n",
      "errorbarsinFig.2(a)andallperformancemeasuresinTab.1.EPsmoothing\n",
      "typicallyrequiredasmallnumberofiterationsfortheinferredposteriordis-\n",
      "tributiontocloselytrackthetruestate,Fig.2(b).Onaverage,EPrequired\n",
      "fewerthan10iterationstoconvergetoagoodsolutioninwhichthemeanof\n",
      "thelatent-stateposteriorcloselymatchedthegroundtruth.6\n",
      "AverageNLLperdatapoint\n",
      "5LatentState\n",
      "2\n",
      "TruestatePosteriorstatedistribution(EP?GPADS)Posteriorstatedistri-\n",
      "bution(GPADS)\n",
      "0\n",
      "?52\n",
      "4\n",
      "6\n",
      "8\n",
      "1012Timestep\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "1GPADSEP?GPADS\n",
      "0?1?25\n",
      "(a)Exampletrajectorydistributionswith95%bounds.\n",
      "10\n",
      "15EPiteration\n",
      "20\n",
      "25\n",
      "30\n",
      "9\n",
      "\n",
      "(b)AverageNLLxasafunctionoftheEPiterationwithtwicethestandard\n",
      "error.\n",
      "Figure2:(a)PosteriorlatentstatedistributionsusingEP-GPADS(blue)\n",
      "andtheGPADS(gray).Thegroundtruthisshowninred(dashed).The\n",
      "GPADSquicklylosestrackoftheperiodofthestaterevealedbythelarge\n",
      "posterioruncertainty.EPwithmomentmatching(EP-GPADS)intheGPDS\n",
      "iterativelytheGPADSposteriorandcancloselyfollowthetruelatent\n",
      "statetrajectory.(b)AverageNLLxperdatapointinlatentspacewithstandard\n",
      "errorsoftheposteriorstatedistributionscomputedbytheGPADSandtheEP-\n",
      "GPADSasafunctionofEPiterations.4.2\n",
      "PendulumTracking\n",
      "WeconsideredapendulumtrackingproblemtodemonstrateGPDSinference\n",
      "inmultidimensionalsettings,aswellastheabilitytohandlecontrolinputs.The\n",
      "statexofthesystemis?Thependulumgivenbytheangle?measuredfrom\n",
      "beinguprightandtheangularvelocity?.usedhasamassof1kgandalength\n",
      "of1m,andrandomtorquesu?[?2,2]Nmwereappliedforaduration200\n",
      "ms(zero-order-holdcontrol).Thesystemnoisecovariancewassetto?w=\n",
      "diag(0.32,0.12).Thestatewasmeasuredindirectlybytwobearingssensors\n",
      "withcoordinates(x1,y1)=(?2,0)and(xaccordingtoz=[z1,z2]>+v,v\n",
      "?2,y2)=(?0.5,?0.5),respectively,\n",
      "sin??yN0,diag(0.12,0.052)withzi=arctancos??xii,i=1,2.We\n",
      "trainedtheGPmodelsusing4randomlygeneratedtrajectoriesoflengthT=\n",
      "20timesteps,startingfromaninitialstatedistributionp(x1)=N(0,diag(?2\n",
      "/162,0.52))aroundtheuprightposition.Fortesting,wegenerated12random\n",
      "trajectoriesstartingfromp(x1).Tab.2summarizestheperformanceTable2:\n",
      "Performancecomparisononthependulum-swingofthevariousinferencemeth-\n",
      "ods.data.Lowervaluesarebetter.Generally,the(EP-)GPADSperformed\n",
      "betterthanthe(EP-)GPEKSNLLxMAExNLLzGPEKS?0.35?0.390.30?\n",
      "0.02?2.41?0.047acrossallperformancemeasures.EP-GPEKS?0.33?0.44\n",
      "0.31?0.02?2.39?0.038Thisindicatesthatthe(EP-)GPEKSGPADS?0.80\n",
      "?0.060.30?0.02?2.37?0.042fromovtposteriEP-GPADS\n",
      "?0.85?0.050.29?0.02?2.40?0.037orscomparedto(EP-)GPADS,whichis\n",
      "especiallypronouncedinthedegradingNLLxvalueswithincreasingEPitera-\n",
      "tionsandtherelativelyhighstandarderrors.Inabout20%ofthetestcases,the\n",
      "inferencemethodsbasedonexplicitlinearizationoftheposteriormeanfunction\n",
      "(GPEKSandEP-GPEKS)ranintonumericalproblemstypicaloflinearizations\n",
      "[5],i.e.,ovtposteriordistributionsthatcausednumericalproblems.\n",
      "WeexcludedtheserunsfromtheresultsinTab.2.Theinferencealgorithms\n",
      "basedonmomentmatching(GPADSandEP-GPADS)werenumericallystable\n",
      "astheirpredictionsaretypicallymorecoherentduetoconservativeapproxima-\n",
      "tionsofmomentmatching.4.3\n",
      "MotionCaptureData\n",
      "Weconsideredmotioncapturedata(fromhttp://mocap.cs.cmu.edu/,sub-\n",
      "ject64)containing10trialsofgolfswingsrecordedat120Hz,whichwesub-\n",
      "sampledto20Hz.Afterremovingobservationdimensionswithnovariability\n",
      "wewereleftwithobservationszt?R56,whichwerethenwhitenedasapre-\n",
      "10\n",
      "\n",
      "processingstep.Fortrials1?7(403datapoints),weusedtheGPDM[20]to\n",
      "learnMAPestimatesofthelatentstatesxt?R3.Theseestimatedlatentstates\n",
      "andtheircorrespondingobservationsareusedtotraintheGPmodelsGPfand\n",
      "GPg.Trials8?10wereusedastest7\n",
      "Figure3:Latentspaceposteriordistribution(95%denceellipsoids)ofa\n",
      "testtrajectoryofthegolf-swingmotioncapturedata.Thefurthertheellipsoids\n",
      "areseparatedthefasterthemovement.datawithoutgroundtruthlabels.The\n",
      "GPDM[20]focusesonlearningaGPDS;weareinterestedingoodapproximate\n",
      "inferenceinthesemodels.Fig.3showsthelatent-stateposteriordistributionof\n",
      "asingletestsequence(trial10)obtainedfromtheEP-GPADS.Themostsignif-\n",
      "icantpredictionerrorsinobservedspaceoccurredintheregioncorresponding\n",
      "totheyellow/redellipsoids,whichisalow-dimensionalembeddingofthemo-\n",
      "tionwhenthegolfplayerhitstheball,i.e.,theperiodsofhighacceleration\n",
      "(poses3?5).Tab.3summarizestheresultsofinferenceonthegolfdatasetin\n",
      "alltesttrials:IteratingforwardbackwardsmoothingbymeansofEPimproved\n",
      "theinferredposteriordistributionsoverthelatentstates.Theposteriordistri-\n",
      "butionsinlatentspaceinferredbytheEP-GPEKSweretighterthantheones\n",
      "inferredbytheEP-GPADS.TheNLLz-valuesabitfromthisov\n",
      "dence,butthepredictiveperformanceoftheEP-GPADSandEP-GPEKSwere\n",
      "similar.Generally,inferencewasmoreinareaswithfastmovements\n",
      "(poses3?5inFig.3)wheretrainingdataweresparse.Thecomputationalde-\n",
      "mandthetwoTable3:Averageinferenceperformance(NLLz,motioninference\n",
      "methodsforGPDSswecapturedataset).Lowervaluesarebetter.presented\n",
      "isvastlyt.HighdimensionalapproximateinferenceTesttrialGPEKS\n",
      "EP-GPEKSGPADSEP-GPADSTrial814.2013.8214.2814.09inthemotion\n",
      "captureexampleusingTrial915.6314.7115.1914.84momentmatching(EP-\n",
      "GPADS)was26.6825.7325.6425.42Trial10abouttwoordersofmagnitude\n",
      "slowerthanapproximateinferencebasedonlinearizationoftheposteriorGP\n",
      "mean(EP-GPEKS):Forupdatingtheposteriorandthemessagesforasingle\n",
      "timeslice,theEP-GPEKSrequiredlessthan0.5s,theEP-GPADStookabout\n",
      "20s.Hence,numericalstabilityandmorecoherentposteriorinferencewiththe\n",
      "EP-GPADStradeagainstcomputationaldemands.\n",
      "5\n",
      "Conclusion\n",
      "WehavepresentedanapproximatemessagepassingalgorithmbasedonEP\n",
      "forimprovedinferenceandBayesianstateestimationinGPdynamicalsys-\n",
      "tems.Ourmessage-passingformulationgeneralizescurrentinferencemethodsin\n",
      "GPDSstoiterativeforward-backwardsmoothing.Thisgeneralizationallowsfor\n",
      "improvedpredictionsandcomprisesexistingmethodsforinferenceinthewider\n",
      "theoryfordynamicalsystemsasaspecialcase.Ournewinferenceapproach\n",
      "makesthefullpoweroftheGPDSmodelavailableforthestudyofcomplex\n",
      "time-seriesdata.Futureworkincludesinvestigatingalternativestolineariza-\n",
      "tionandmomentmatchingwhencomputingmessages,andthemoregeneral\n",
      "problemoflearninginGaussianprocessdynamicalsystems.Acknowledgements\n",
      "WethankZhikunWangforhelpingwiththemotioncaptureexperimentand\n",
      "JanPetersforvaluablediscussions.Theresearchleadingtotheseresultshas\n",
      "11\n",
      "\n",
      "receivedfundingfromtheEuropeanCommunity?sSeventhFrameworkPro-\n",
      "gramme(FP7/2007?2013)undergrantagreement#270327(ComPLACS)and\n",
      "theCanadianInstituteforAdvancedResearch(CIFAR).8\n",
      "2References\n",
      "[1]B.D.O.AndersonandJ.B.Moore.OptimalFiltering.DoverPublications,\n",
      "2005.[2]A.Damianou,M.K.Titsias,andN.D.Lawrence.VariationalGaus-\n",
      "sianProcessDynamicalSystems.InAdvancesinNeuralInformationProcessing\n",
      "Systems.2011.[3]M.P.Deisenroth,M.F.Huber,andU.D.Hanebeck.Ana-\n",
      "lyticMoment-basedGaussianProcessFiltering.InProceedingsofthe26thIn-\n",
      "ternationalConferenceonMachineLearning,pages225?232.Omnipress,2009.\n",
      "[4]M.P.DeisenrothandS.Mohamed.ExpectationPropagationinGaussian\n",
      "ProcessDynamicalSystems:ExtendedVersion,2012.http://arxiv.org/abs/1207.2940.\n",
      "[5]M.P.Deisenroth,R.Turner,M.Huber,U.D.Hanebeck,andC.E.Ras-\n",
      "mussen.RobustFilteringandSmoothingwithGaussianProcesses.IEEE\n",
      "TransactionsonAutomaticControl,2012.[6]T.HeskesandO.Zoeter.Expec-\n",
      "tationPropagationforApproximateInferenceinDynamicBayesianNetworks.\n",
      "InProceedingsoftheInternationalConferenceonUncertaintyinIn-\n",
      "telligence,pages216?233,2002.[7]S.J.JulierandJ.K.Uhlmann.Unscented\n",
      "FilteringandNonlinearEstimation.ProceedingsoftheIEEE,92(3):401?422,\n",
      "March2004.[8]J.KoandD.Fox.GP-BayesFilters:BayesianFilteringusing\n",
      "GaussianProcessPredictionandObservationModels.AutonomousRobots,\n",
      "27(1):75?90,2009.[9]M.KussandC.E.Rasmussen.AssessingApproximate\n",
      "InferenceforBinaryGaussianProcessJournalofMachineLearn-\n",
      "ingResearch,6:1679?1704,2005.[10]T.P.Minka.ExpectationPropagation\n",
      "forApproximateBayesianInference.InProceedingsofthe17thConferenceon\n",
      "UncertaintyinIntelligence,pages362?369.MorganKaufmanPublish-\n",
      "ers,2001.[11]T.P.Minka.AFamilyofAlgorithmsforApproximateBayesian\n",
      "Inference.PhDthesis,MassachusettsInstituteofTechnology,2001.[12]T.P.\n",
      "Minka.EP:AQuickReference.2008.[13]Y.QiandT.Minka.Expecta-\n",
      "tionPropagationforSignalDetectioninFlat-FadingChannels.InProceedings\n",
      "oftheIEEEInternationalSymposiumonInformationTheory,2003.[14]J.\n",
      "Qui?nonero-Candela,A.Girard,J.Larsen,andC.E.Rasmussen.Propagation\n",
      "ofUncertaintyinBayesianKernelModels?ApplicationtoMultiple-StepAhead\n",
      "Forecasting.InIEEEInternationalConferenceonAcoustics,SpeechandSignal\n",
      "Processing,pages701?704,2003.[15]C.E.RasmussenandC.K.I.Williams.\n",
      "GaussianProcessesforMachineLearning.TheMITPress,2006.[16]M.W.\n",
      "Seeger.ExpectationPropagationforExponentialFamilies.Technicalreport,\n",
      "UniversityofCaliforniaBerkeley,2005.[17]M.W.Seeger.BayesianInfer-\n",
      "enceandOptimalDesignfortheSparseLinearModel.JournalofMachine\n",
      "LearningResearch,9:759?813,2008.[18]M.ToussaintandC.Goerick.From\n",
      "MotorLearningtoInteractionLearninginRobotics,chapterABayesianView\n",
      "onMotorControlandPlanning,pages227?252.Springer-Verlag,2010.[19]\n",
      "R.Turner,M.P.Deisenroth,andC.E.Rasmussen.State-SpaceInferenceand\n",
      "12\n",
      "\n",
      "LearningwithGaussianProcesses.InProceedingsoftheInternationalConfer-\n",
      "enceonIntelligenceandStatistics,volumeJMLR:W&CP9,pages\n",
      "868?875,2010.[20]J.M.Wang,D.J.Fleet,andA.Hertzmann.Gaussian\n",
      "ProcessDynamicalModelsforHumanMotion.IEEETransactionsonPattern\n",
      "AnalysisandMachineIntelligence,30(2):283?298,2008.\n",
      "9\n",
      "13\n",
      "\n",
      "PP3928.pdf\n",
      "PP3928.pdf 14\n",
      "t-logisticregression\n",
      "Authoredby:\n",
      "S.v.n.Vishwanathan\n",
      "NanDing\n",
      "Abstract\n",
      "Weextendlogisticregressionbyusingt-exponentialfamilieswhich\n",
      "wereintroducedrecentlyinstatisticalphysics.Thisgivesrisetoareg-\n",
      "ularizedriskminimizationproblemwithanon-convexlossfunction.An\n",
      "tblockcoordinatedescentoptimizationschemecanbederivedfor\n",
      "estimatingtheparameters.Becauseofthenatureofthelossfunction,our\n",
      "algorithmistoleranttolabelnoise.Furthermore,unlikeotheralgorithms\n",
      "whichemploynon-convexlossfunctions,ouralgorithmisfairlyrobustto\n",
      "thechoiceofinitialvalues.Weverifyboththeseobservationsempirically\n",
      "onanumberofsyntheticandrealdatasets.\n",
      "1PaperBody\n",
      "Manymachinelearningalgorithmsminimizearegularizedrisk[1]:m\n",
      "J(?)=?(?)+Remp(?),whereRemp(?)=\n",
      "1?l(xi,yi,?).mi=1\n",
      "(1)\n",
      "Here,?isaregularizerwhichpenalizescomplex?;andRemp,theempirical\n",
      "risk,isobtainedbyaveragingthelossloverthetrainingdataset\n",
      "f\n",
      "(x1,y1),.\n",
      "..,(xm,ym)\n",
      "g\n",
      ".Inthispaperourfocusisonbinaryclassi?cation,wherein\n",
      "featuresofadatapointxareextractedviaafeaturemap?andthelabel\n",
      "isusuallypredictedviasign(??(x),??).Ifwede?nethemarginofatraining\n",
      "example(x,y)asu(x,y,?):=y??(x),??,thenmanypopularlossfunctions\n",
      "forbinaryclassi?cationcanbewrittenasfunctionsofthemargin.Examples\n",
      "include1l(u)=0ifu>0and1otherwise.l(u)=max(0,1?u)l(u)=exp(?u)\n",
      "l(u)=log(1+exp(?u))\n",
      "(0?1loss)(HingeLoss)(ExponentialLoss)(LogisticLoss).\n",
      "(2)(3)(4)(5)\n",
      "The0?1lossisnon-convexanddif?culttohandle;ithasbeenshown\n",
      "thatitisNP-hardtoevenapproximatelyminimizetheregularizedriskwith\n",
      "the0?1loss[2].Therefore,otherlossfunctionscanbeviewedasconvex\n",
      "proxiesofthe0?1loss.Hingelossleadstosupportvectormachines(SVMs),\n",
      "exponentiallossisusedinAdaboost,andlogisticregressionusesthelogisticloss.\n",
      "1\n",
      "\n",
      "Convexityisaveryattractivepropertybecauseitensuresthattheregularized\n",
      "riskminimizationproblemhasauniqueglobaloptimum[3].However,aswas\n",
      "recentlyshownbyLongandServedio[4],learningalgorithmsbasedonconvex\n",
      "lossfunctionsarenotrobusttonoise2.Intuitively,theconvexlossfunctions\n",
      "growsatleastlinearlywithslope|l?(0)|asu?(??,0),whichintroducesthe\n",
      "overwhelmingimpactfromthedatawithu?0.Therehasbeensomerecent\n",
      "andsomenotso-recentworkonusingnon-convexlossfunctionstoalleviatethe\n",
      "aboveproblem.Forinstance,arecentmanuscriptby[5]usesthecdfofthe\n",
      "Guassiandistributiontode?neanon-convexloss.1\n",
      "Weslightlyabusenotationandusel(u)todenotel(u(x,y,?)).Although,the\n",
      "analysisof[4]iscarriedoutinthecontextofboosting,webelieve,theresults\n",
      "holdforalargerclassofalgorithmswhichminimizearegularizedriskwitha\n",
      "convexlossfunction.2\n",
      "1\n",
      "Inthispaper,wecontinuethislineofinquiryandproposeanon-convexloss\n",
      "functionwhichis?rmlygroundedinprobabilitytheory.Bylossextendinglogis-\n",
      "ticregressionfromtheexLogisticexpponentialfamilytothet-exponentialfam6\n",
      "ily,anaturalextensionofexponentialfamilyHingeofdistributionsstudiedin\n",
      "statisticalphysics[6?10],weobtainthet-logisticregression4algorithm.Fur-\n",
      "thermore,weshowthatasimpleblockcoordinatedescentschemecanbeused\n",
      "tosolvetheresultantregularized20-1lossriskminimizationproblem.Analysis\n",
      "ofthisprocedurealsointuitivelyexplainswhytmarginlogisticregressionisable\n",
      "tohandlelabel-4-2024noise.\n",
      "Figure1:Somecommonlyusedlossfunctionsforbinary\n",
      "Ourpaperisstructuredasfollows:Insec-classi?cation.The0-1lossis\n",
      "non-convex.Thehinge,expotion2webrie?yreviewlogisticregressionnential,\n",
      "andlogisticlossesareconvexupperboundsoftheespeciallyinthecontextof\n",
      "exponentialfam-0-1loss.ilies.Insection3,wereviewt-exponentialfamilies,\n",
      "whichformthebasisforourproposedt-logisticregressionalgorithmintroduced\n",
      "insection4.Insection5weutilizeideasfromconvexmultiplicativeprogram-\n",
      "mingtodesignanoptimizationstrategy.Experimentsthatcompareournew\n",
      "approachtoexistingalgorithmsonanumberofpubliclyavailabledatasetsare\n",
      "reportedinsection6,andthepaperconcludeswithadiscussionandoutlookin\n",
      "section7.Sometechnicaldetailsaswellasextraexperimentalresultscanbe\n",
      "foundinthesupplementarymaterial.\n",
      "2\n",
      "LogisticRegression\n",
      "Sincewebuildupontheprobabilisticunderpinningsoflogisticregression,\n",
      "webrie?yreviewsomesalientconcepts.Detailscanbefoundinanystandard\n",
      "textbooksuchas[11]or[12].Assumewearegivenalabeleddataset(X,Y)=\n",
      "f\n",
      "(x1,y1),...,(xm,ym)\n",
      "g\n",
      "withthexi?sdrawnfromsomedomainXand\n",
      "thelabelsyi?\n",
      "f\n",
      "?1\n",
      "g\n",
      ".Givenafamilyofconditionaldistributionsparameterized\n",
      "by?,usingBayesrule,andmakingastandardiidassumptionaboutthedata\n",
      "allowsustowritep(?|X,Y)=p(?)\n",
      "m?\n",
      "i=1\n",
      "2\n",
      "\n",
      "p(yi|xi;?)/p(Y|X)?p(?)\n",
      "m?\n",
      "i=1\n",
      "p(yi|xi;?)\n",
      "(6)\n",
      "wherep(Y|X)isclearlyindependentof?.Tomodelp(yi|xi;?),\n",
      "considertheconditionalexponentialfamilyofdistributionsp(y|x;?)=exp\n",
      "(??(x,y),???g(?|x)),\n",
      "(7)\n",
      "g(?|x)=log(exp(??(x,+1),??)+exp(??(x,?1),??)).\n",
      "(8)\n",
      "withthelog-partitionfunctiong(?|x)givenbyIfwechoosethefeature\n",
      "map?(x,y)=thatp(y|x;?)isthelogisticfunctionp(y|x;?)=\n",
      "y2?(x),\n",
      "anddenoteu=y??(x),??thenitiseasytosee\n",
      "1exp(u/2)=.exp(u/2)+exp(?u/2)1+exp(?u)\n",
      "(9)\n",
      "ByassumingazeromeanisotropicGaussianpriorN(0,?1?I)for?,plugging\n",
      "in(9),andtakinglogarithms,wecanrewrite(6)asm??2?logp(?|X,Y)\n",
      "=???+log(1+exp(?yi??(xi),??))+const..2i=1\n",
      "(10)\n",
      "Logisticregressioncomputesamaximuma-posteriori(MAP)estimatefor?\n",
      "byminimizing(10)asafunctionof?.Comparing(1)and(10)itiseasytosee\n",
      "thattheregularizeremployedinlogistic2regressionis?2???,whiletheloss\n",
      "functionisthenegativelog-likelihood?logp(y|x;?),whichthanksto(9)can\n",
      "beidenti?edwiththelogisticloss(5).2\n",
      "3\n",
      "t-ExponentialfamilyofDistributions\n",
      "Inthissectionwewilllookatgeneralizationsofthelogandexpfunctions\n",
      "whichwere?rstintroducedinstatisticalphysics[6?9].Someextensionsand\n",
      "machinelearningapplicationswerepresentedin[13].Infact,amoregeneral\n",
      "classoffunctionswasstudiedinthesepublications,butforourpurposeswewill\n",
      "restrictourattentiontotheso-calledt-exponentialandt-logarithmfunctions.\n",
      "Thet-exponentialfunctionexptfor(0<t<2)isde?nedasfollows:?exp(x)if\n",
      "t=1expt(x):=1/(1?t)otherwise.[1+(1?t)x]+\n",
      "(11)\n",
      "where(?)+=max(?,0).SomeexamplesareshowninFigure2.Clearly,\n",
      "exptgeneralizestheusualexpfunction,whichisrecoveredinthelimitast?\n",
      "1.Furthermore,manyfamiliarpropertiesofexparepreserved:exptfunctions\n",
      "areconvex,non-decreasing,non-negativeandsatisfyexpt(0)=1[9].Butexpt\n",
      "doesnotpreserveoneveryimportantpropertyofexp,namelyexpt(a+b)?=\n",
      "expt(a)?expt(b).Onecanalsode?netheinverseofexptnamelylogtas?\n",
      "log(x)ift=1?(12)logt(x):=?1?t?1/(1?t)otherwise.x\n",
      "Similarly,logt(ab)?=logt(a)+logt(b).FromFigure2,itisclearthat\n",
      "exptdecaystowards0moreslowlythantheexpfunctionfor1<t<2.This\n",
      "importantpropertyleadstoafamilyofheavytaileddistributionswhichwewill\n",
      "3\n",
      "\n",
      "laterexploit.t=1(logistic)exptt=1.5exp(x)7logtt?06t=0.5t=0.55\n",
      "t=1.3log(x)24t=1.6t?0t=1.51t=1.93x02-112345670-1loss\n",
      "1-2-3-2-1012x-3-4-2\n",
      "loss6420\n",
      "2\n",
      "4\n",
      "margin\n",
      "Figure2:Left:exptandMiddle:logtforvariousvaluesoftindicated.\n",
      "Theright?guredepictsthet-logisticlossfunctionsfortvaluesoft.\n",
      "Whent=1,werecoverthelogisticlossAnalogoustotheexponentialfamilyof\n",
      "distributions,thet-exponentialfamilyofdistributionsisde?nedas[9,13]:p(x;\n",
      "?):=expt(??(x),???gt(?)).\n",
      "(13)\n",
      "qt(x;?):=p(x;?)t/Z(?)\n",
      "(14)\n",
      "Aprominentmemberofthet-exponentialfamilyistheStudent?s-tdistribu-\n",
      "tion[14].Justlikeintheexponentialfamilycase,gtthelog-partitionfunction\n",
      "ensuresthatp(x;?)isnormalized.However,noclosedformsolutionexists\n",
      "forcomputinggtexactlyingeneral.Acloselyrelateddistribution,whichof-\n",
      "tenappearswhenworkingwitht-exponentialfamiliesistheso-calledescort\n",
      "distribution[9,13]:whereZ(?)=integratesto1.\n",
      "?\n",
      "p(x;?)dxisthenormalizingconstantwhichensuresthattheescortdistri-\n",
      "butiont\n",
      "Althoughgt(?)isnotthecumulantfunctionofthet-exponentialfamily,\n",
      "itstillpreservesconvexity.Inaddition,itisveryclosetobeingamoment\n",
      "generatingfunction??gt(?)=Eqt(x;?)[?(x)].\n",
      "(15)\n",
      "Theproofisprovidedinthesupplementarymaterial.Ageneralversionof\n",
      "thisresultappearsasLemma3.8inSears[13]andaversionspecializedtothe\n",
      "generalizedexponentialfamiliesappearsasProposition5.2in[9].Themain\n",
      "from??g(?)ofthenormalexponentialfamilyisthatnow??gt(?)\n",
      "isequaltotheexpectationofitsescortdistributionqt(x;?)insteadofp(x;?).\n",
      "3\n",
      "4\n",
      "BinaryClassi?cationwiththet-exponentialFamily\n",
      "Int-logisticregressionwemodelp(y|x;?)viaaconditionalt-exponential\n",
      "familydistributionp(y|x;?)=expt(??(x,y),???gt(?|x)),(16)where\n",
      "1<t<2,andcomputethelog-partitionfunctiongtbynotingthatexpt(??(x,\n",
      "+1),???gt(?|x))+expt(??(x,?1),???gt(?|x))=1.(17)Even\n",
      "thoughnoclosedformsolutionexists,onecancomputegtgiven?andxusing\n",
      "numericaltechniquesef?ciently.TheStudent?s-tdistributioncanberegarded\n",
      "asacounterpartoftheisotropicGaussianpriorinthet-exponentialfamily[14].\n",
      "RecallthataonedimensionalStudent?s-tdistributionisgivenby??(v+1)/2?\n",
      "(x??)2?((v+1)/2)1+St(x|?,?,v)=?,(18)v?v??(v/2)?1/2where?(?)\n",
      "denotestheusualGammafunctionandv>1sothatthemeanis?nite.Ifwe\n",
      "4\n",
      "\n",
      "selecttsatisfying?(v+1)/2=1/(1?t)anddenote,??2/(v+1)??((v+1)/2)\n",
      ",?=?v??(v/2)?1/2thenbysomesimplebuttediouscalculation(includedin\n",
      "thesupplementarymaterial)???)2/2?g?t)St(x|?,?,v)=exp(??(x(19)\n",
      "t\n",
      "2??=where?(t?1)v?\n",
      "andg?t=\n",
      "??1.t?1\n",
      "Therefore,weworkwiththeStudent?s-tpriorinoursetting:p(?)=\n",
      "d?\n",
      "p(?j)=\n",
      "j=1\n",
      "d?\n",
      "j=1\n",
      "St(?j|0,2/?,(3?t)/(t?1)).\n",
      "(20)\n",
      "Here,thedegreeoffreedomforStudent?s-tdistributionischosensuchthat\n",
      "italsobelongstotheexptfamily,whichinturnyieldsv=(3?t)/(t?1).The\n",
      "Student?s-tpriorisusuallypreferredtotheGaussianpriorwhentheunderlying\n",
      "distributionisheavy-tailed.Inpractice,itisknowntobearobust3alternative\n",
      "totheGaussiandistribution[16,17].Asbefore,ifwelet?(x,y)=y2?(x)and\n",
      "plotthenegativelog-likelihood?logp(y|x;?),thenwenolongerobtaina\n",
      "convexlossfunction(seeFigure2).Similarly,?logp(?)isnolongerconvex\n",
      "whenweusetheStudent?s-tprior.Thismakesoptimizingtheregularizedrisk\n",
      "challenging,thereforeweemployadrentstrategy.Sincelogtisalsoamono-\n",
      "tonicallyincreasingfunction,insteadofworkingwithlog,wecanequivalently\n",
      "workwiththelogtfunction(12)andminimizethefollowingobjectivefunction:\n",
      "m??J(?)=?logtp(?)p(yi|xi;?)/p(Y|X)1=t?1\n",
      "?\n",
      "i=1\n",
      "p(?)\n",
      "m?\n",
      "i=1\n",
      "p(yi|xi;?)/p(Y|X)\n",
      "?1?t\n",
      "+\n",
      "1,1?t\n",
      "(21)\n",
      "wherep(Y|X)isindependentof?.Using(13),(18),and(11),wecan\n",
      "furtherwritem?d??????y?i?2/2?g?t)??(xi),??gt(?|xi))\n",
      "+const..1+(1?t)(???1+(1?t)(J(?)?j2?????i=1??j=1?rj(?)\n",
      "=\n",
      "d?\n",
      "j=1\n",
      "rj(?)\n",
      "m?\n",
      "li(?)\n",
      "5\n",
      "\n",
      "li(?)+const.\n",
      "(22)\n",
      "i=1\n",
      "3Thereisnouniquede?nitionofrobustness.Forexample,oneofthe\n",
      "de?nitionsisthroughtheoutlierproneness[15]:p(?|X,Y,xn+1,yn+1\n",
      ")?p(?|X,Y)asxn+1??.\n",
      "4\n",
      "Sincet>1,itiseasytoseethatrj(?)>0isaconvexfunctionof?.Onthe\n",
      "otherhand,sincegt?isconvexandt>1itfollowsthatli(?)>0isalsoaconvex\n",
      "functionof?.Insummary,J(?)isaproductofpositiveconvexfunctions.In\n",
      "thenextsectionwewillpresentanef?cientoptimizationstrategyfordealing\n",
      "withsuchproblems.\n",
      "5\n",
      "ConvexMultiplicativeProgramming\n",
      "Inconvexmultiplicativeprogramming[18]weareinterestedinthefollowing\n",
      "optimizationproblem:N?minP(?)?zn(?)s.t.??Rd,(23)?\n",
      "n=1\n",
      "wherezn(?)arepositiveconvexfunctions.Clearly,(22)canbeidenti?ed\n",
      "with(23)bysettingN=d+mandidentifyingzn(?)=rn(?)forn=1,...\n",
      ",dandzn+d(?)=ln(?)forn=1,...,m.Theoptimalsolutionstothe\n",
      "problem(23)canbeobtainedbysolvingthefollowingparametricproblem(see\n",
      "Theorem2.1ofKunoetal.[18]):NN???nzn(?)s.t.??Rd,?>0,?n?\n",
      "1.(24)minminMP(?,?)??\n",
      "?\n",
      "n=1\n",
      "n=1\n",
      "Inlogisticregression,Theoptimizationproblem??in(24)isveryreminis-\n",
      "centoflogisticregression.????ln(?)=?y2n?(xn),?+g(?|xn),while\n",
      "hereln(?)=1+(1?t)y2n?(xn),??gt(?|xn).Thekey\n",
      "isthatint-logisticregressioneachdatapointxnhasaweight(orin?uence)?n\n",
      "associatedwithit.Exactalgorithmshavebeenproposedforsolving(24)(for\n",
      "instance,[18]).However,thecomputationalcostofthesealgorithmsgrowsex-\n",
      "ponentiallywithrespecttoNwhichmakesthemimpracticalforourpurposes.\n",
      "Instead,weapplyablockcoordinatedescentbasedmethod.Themainideais\n",
      "tominimize(24)withrespectto?and?separately.?-Step:Assumethat?is\n",
      "?xed,anddenotez?n=zn(?)torewrite(24)as:min?\n",
      "N?\n",
      "?nz?ns.t.\n",
      "?>0,\n",
      "n=1\n",
      "N?\n",
      "n=1\n",
      "(25)\n",
      "?n?1.\n",
      "Sincetheobjectivefunctionislinearin?andthefeasibleregionisaconvex\n",
      "set,(25)isaconvexoptimizationproblem.Byintroducinganon-negative\n",
      "6\n",
      "\n",
      "Lagrangemultiplier??0,thepartialLagrangiananditsgradientwithrespect\n",
      "to?n?canbewrittenas??NN??(26)L(?,?)=?nz?n+??1??nn=1\n",
      "??L(?,?)=z?n????n.???n?\n",
      "n=1\n",
      "(27)\n",
      "n?=n\n",
      "Settingthegradientto0obtains?=\n",
      "?z?n?\n",
      "K.K.T.conditions[3],wecanconclude\n",
      "?n.Since?Nthatn=1?n\n",
      "n?=n?\n",
      "z?n?>0,itfollowsthat?cannotbe0.Bythe\n",
      "=1.Thisinturnimpliesthat?=z?n??n?or\n",
      "z1,...,?/?zN),with?=(?1,...,?N)=(?/?\n",
      "N?\n",
      "1\n",
      "z?nN.\n",
      "(28)\n",
      "n=1\n",
      "Recallthat?nin(24)istheweight(orin?uence)ofeachtermzn(?).The\n",
      "aboveanalysisshowsthat?=z?n(?)?nremainsconstantforalln.Ifz?n(?)\n",
      "becomesverylargethenitsin?uence?nisreduced.Therefore,pointswithvery\n",
      "largelosshavetheirin?uencecappedandthismakesthealgorithmrobustto\n",
      "outliers.?-Step:Inthisstepwe?x?>0andsolvefortheoptimal?.Thisstep\n",
      "isessentiallythesameaslogisticregression,exceptthateachcomponenthasa\n",
      "weight?here.N?min?nzn(?)s.t.??Rd.(29)?\n",
      "n=1\n",
      "5\n",
      "Thisisastandardunconstrainedconvexoptimizationproblemwhichcanbe\n",
      "solvedbyanytheshelfsolver.InourcaseweusetheL-BFGSQuasi-Newton\n",
      "method.Thisrequiresustocomputethegradient??zn(?):\n",
      "?n?en??zn(?)=??rn(?)=(t?1)???y?n?(xn)???gt(?|xn\n",
      ")forn=1,...,m??zn+d(?)=??ln(?)=(1?t)?y2???ynn=(1?\n",
      "t)?(xn)?Eqt(yn|xn;?)?(xn),22whereendenotestheddimensional\n",
      "vectorwithoneatthen-thcoordinateandzeroselsewhere(n-thunitvector).\n",
      "qt(y|x;?)istheescortdistributionofp(y|x;?)(16):forn=1,...,d\n",
      "qt(y|x;?)=\n",
      "p(y|x;?)t.p(+1|x;?)t+p(?1|x;?)t\n",
      "(30)\n",
      "Theobjectivefunctionismonotonicallydecreasingandisguaranteedto\n",
      "convergetoastablepointofP(?).Weincludetheproofinthesupplementary\n",
      "material.\n",
      "6\n",
      "ExperimentalEvaluation\n",
      "Ourexperimentalevaluationisdesignedtoanswerfournaturalquestions:\n",
      "1)Howdoesthegeneralizationcapability(measuredintermsoftesterror)of\n",
      "7\n",
      "\n",
      "t-logisticregressioncomparewithexistingalgorithmssuchaslogisticregression\n",
      "andsupportvectormachines(SVMs)bothinthepresenceandabsenceofla-\n",
      "belnoise?2)Dothe?variablesweintroducedintheprevioussectionhavea\n",
      "naturalinterpretation?3)Howmuchoverheaddoest-logisticregressionincur\n",
      "ascomparedtologisticregression?4)Howsensitiveisthealgorithmtoinitial-\n",
      "ization?Thelastquestionisparticularlyimportantgiventhatthealgorithm\n",
      "isminimizinganon-convexloss.Toanswertheabovequestionsempirically\n",
      "weusesixdatasets,twoofwhicharesynthetic.TheLong-Servediodatasetis\n",
      "anarti?ciallyconstructeddatasettoshowthatalgorithmswhichminimizea\n",
      "tiableconvexlossarenottoleranttolabelnoiseLongandServedio[4].\n",
      "Theexampleshave21dimensionsandplayoneofthreepossibleroles:large\n",
      "marginexamples(25%,x1,2,...,21=y);pullers(25%,x1,...,11=y,x12,...,21=\n",
      "?y);andpenalizers(50%,Randomlyselectandset5ofthe?rst11coordinates\n",
      "and6outofthelast10coordinatestoy,andsettheremainingcoordinates\n",
      "to?y).TheMease-Wynerisanothersyntheticdatasettotesttheof\n",
      "labelnoise.Theinputxisa20-dimensionalvectorwhereeachcoordinateis\n",
      "uniformlydistributedon[0,1].Thelabelyis?5+1ifj=1xj?2.5and?1\n",
      "otherwise[19].Inaddition,wealsotestonMushroom,USPS-N(9vs.others),\n",
      "Adult,andWebdatasets,whichareoftenusedtoevaluatemachinelearning\n",
      "algorithms(seeTable1insupplementarymaterialfordetails).Forsimplicity,\n",
      "weusetheidentityfeaturemap?(x)=xinallourexperiments,andsett?\n",
      "f\n",
      "1.3,1.6,1.9\n",
      "g\n",
      "fort-logisticregression.Ourcomparatorsarelogisticregression,\n",
      "linearSVMs4,andanalgorithm(theprobit)whichemploystheprobitloss,\n",
      "L(u)=1?erf(2u),usedinBrownBoost/RobustBoost[5].WeusetheL-BFGS\n",
      "algorithm[21]forthe?-stepint-logisticregression.L-BFGSisalsousedto\n",
      "trainlogisticregressionandtheprobitlossbasedalgorithms.Labelnoiseis\n",
      "addedbyrandomlychoosing10%ofthelabelsinthetrainingsetand?ipping\n",
      "them;eachdatasetistestedwithandwithoutlabelnoise.Werandomlyselect\n",
      "andholdout30%ofeachdatasetasavalidationsetandusetherestofthe70%\n",
      "for10-foldcrossvalidation.Theoptimalparametersnamely?fort-logisticand\n",
      "?logisticregressionandCforSVMsischosenbyperformingagridsearchover\n",
      "the?parameterspace2?7,?6,...,7andobservingthepredictionaccuracyover\n",
      "thevalidationset.Theconvergencecriterionistostopwhenthechangeinthe\n",
      "objectivefunctionvalueislessthan10?4.AllcodeiswritteninMatlab,and\n",
      "forthelinearSVMweusetheMatlabinterfaceofLibSVM[22].Experiments\n",
      "wereperformedonaQual-coremachinewithDual2.5Ghzprocessorand32\n",
      "GbRAM.InFigure3,weplotthetesterrorwithandwithoutlabelnoise.In\n",
      "thelattercase,thetesterroroft-logisticregressionisverysimilartologistic\n",
      "regressionandLinearSVM(with0%testerrorin4Wealsoexperimentedwith\n",
      "RampSVM[20],however,theresultsareworserthantheotheralgorithms.We\n",
      "thereforereporttheseresultsinthesupplementarymaterial.\n",
      "6\n",
      "6.0\n",
      "TestError(%)\n",
      "32\n",
      "1.24.5\n",
      "8\n",
      "\n",
      "24\n",
      "0.93.0\n",
      "168\n",
      "1.5\n",
      "0.3\n",
      "0\n",
      "0.0\n",
      "0.0\n",
      "16.8\n",
      "3.2\n",
      "16.0\n",
      "2.4\n",
      "6.0\n",
      "TestError(%)\n",
      "0.6\n",
      "4.53.0\n",
      "1.6\n",
      "15.21.5\n",
      "0.814.4\n",
      "0.0\n",
      "logis.t=1.3t=1.6t=1.9probitSVM\n",
      "logis.t=1.3t=1.6t=1.9probitSVM\n",
      "0.0\n",
      "logis.t=1.3t=1.6t=1.9probitSVM\n",
      "Figure3:Thetesterrorrateofvariousalgorithmsonsixdatasets(leftto\n",
      "right,top:Long-Servedio,Mease-Wyner,Mushroom;bottom:USPS-N,Adult,\n",
      "Web)withandwithout10%labelnoise.Allalgorithmsareinitializedwith?\n",
      "=0.Theblue(light)bardenotesacleandatasetwhilethemagenta(dark)bar\n",
      "aretheresultswithlabelnoiseadded.AlsoseeTable3inthesupplementary\n",
      "material.Long-ServedioandMushroomdatasets),withaslightedgeonsome\n",
      "datasetssuchasMease-Wyner.Whenlabelnoiseisadded,t-logisticregression\n",
      "(especiallywitht=1.9)showssigni?cantly5betterperformancethanallthe\n",
      "otheralgorithmsonalldatasetsexcepttheUSPS-N,whereitismarginally\n",
      "outperformedbytheprobit.ToobtainFigure4weusedthenoisyversionof\n",
      "thedatasets,choseoneofthe10foldsusedinthepreviousexperiment,and\n",
      "plottedthedistributionofthe1/z??obtainedaftertrainingwitht=1.9.To\n",
      "distinguishthepointswithnoisylabelsweplotthemincyanwhiletheother\n",
      "pointsareplottedinred.Analogousplotsforothervaluesoftcanbefoundin\n",
      "thesupplementarymaterial.Recallthat?denotesthein?uenceofapoint.One\n",
      "canclearlyobservethatthe?ofthenoisydataismuchsmallerthanthatof\n",
      "thecleandata,whichindicatesthatthealgorithmisabletoelyidentify\n",
      "thesepointsandcaptheirin?uence.Inparticular,ontheLong-Servediodataset\n",
      "observethe4distinctspikes.Fromlefttoright,the?rstspikecorrespondstothe\n",
      "noisylargemarginexamples,thesecondspikerepresentsthenoisypullers,the\n",
      "thirdspikedenotesthecleanpullers,whiletherightmostspikecorrespondsto\n",
      "thecleanlargemarginexamples.Clearly,thenoisylargemarginexamplesand\n",
      "9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thenoisypullersareassignedalowvalueof?thuscappingtheirin?uenceand\n",
      "leadingtotheperfectclassi?cationofthetestset.Ontheotherhand,logistic\n",
      "regressionisunabletodiscriminatebetweencleanandnoisytrainingsamples\n",
      "whichleadstobadperformanceonnoisydatasets.Detailedtimingexperiments\n",
      "canbefoundinTable4inthesupplementarymaterial.Inanutshell,t-logistic\n",
      "regressiontakeslongertotrainthaneitherlogisticregressionortheprobit.The\n",
      "reasonsarenotdif?culttosee.First,thereisnoclosedformexpressionforgt\n",
      "(?|x).Wethereforeresorttopre-computingitatsome?xedlocationsand\n",
      "usingasplinemethodtointerpolatevaluesatotherlocations.Second,sincethe\n",
      "objectivefunctionisnotconvexseveraliterationsofthe?and?stepsmightbe\n",
      "needed.Surprisingly,theL-BFGSalgorithm,whichisnotdesignedtooptimize\n",
      "nonconvexfunctions,isabletominimize(22)directlyinmanycases.When\n",
      "itdoesconverge,itisoftenfasterthantheconvexmultiplicativeprogramming\n",
      "algorithm.However,onsomecases(asexpected)itfailsto?ndadirectionof\n",
      "descentandexits.AcommonremedyforthisisthebundleL-BFGSwitha\n",
      "trust-regionapproach.[21]Giventhatthet-logisticobjectivefunctionisnon-\n",
      "convex,onenaturallyworriesabouthowtinitialvaluesectthequality\n",
      "ofthe?nalsolution.Toanswerthisquestion,weinitializedthealgorithmwith\n",
      "50trandomlychosen??[?0.5,0.5]d,andreporttestperformancesof\n",
      "thevarioussolutionsobtainedinFigure5.Justlikelogisticregressionwhich\n",
      "usesaconvexlossandhenceconvergestothesamesolutionindependentofthe\n",
      "initialization,thesolutionobtained5\n",
      "Weprovidethesigni?cancetestresultsinTable2ofsupplementarymaterial.\n",
      "7\n",
      "300\n",
      "100060\n",
      "Frequency\n",
      "240\n",
      "800\n",
      "45\n",
      "180\n",
      "600\n",
      "120\n",
      "30\n",
      "400\n",
      "60\n",
      "15\n",
      "200\n",
      "00.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "00.0\n",
      "1.0\n",
      "0.2\n",
      "10\n",
      "\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "00.0\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "6001200\n",
      "8000\n",
      "900\n",
      "6000\n",
      "600\n",
      "4000\n",
      "300\n",
      "2000\n",
      "Frequency\n",
      "45030015000.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "00.0\n",
      "0.2\n",
      "0.4\n",
      "?\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "00.0\n",
      "?\n",
      "?\n",
      "Figure4:Thedistributionof?obtainedaftertrainingt-logisticregression\n",
      "witht=1.9ondatasetswith10%labelnoise.Lefttoright,top:Long-Servedio,\n",
      "Mease-Wyner,Mushroom;bottom:USPSN,Adult,Web.Thered(dark)bars\n",
      "(resp.cyan(light)bars)indicatethefrequencyof?assignedtopointswithout\n",
      "(resp.with)labelnoise.byt-logisticregressionseemsfairlyindependentofthe\n",
      "11\n",
      "\n",
      "initialvalueof?.Ontheotherhand,theperformanceoftheprobit?uctuates\n",
      "widelywithtinitialvaluesof?.probitt=1.9t=1.6t=1.3logistic0\n",
      "10\n",
      "20\n",
      "30\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "0.00\n",
      "0.15\n",
      "0.30\n",
      "0.45\n",
      "probitt=1.9t=1.6t=1.3logistic3.0\n",
      "4.5\n",
      "6.07.5TestError(%)\n",
      "9.0\n",
      "15\n",
      "1821TestError(%)\n",
      "24\n",
      "1.5\n",
      "2.02.5TestError(%)\n",
      "3.0\n",
      "3.5\n",
      "Figure5:TheErrorratebytinitialization.Lefttoright,top:Long-\n",
      "Servedio,Mease-Wyner,Mushroom;bottom:USPS-N,Adult,Web.\n",
      "7\n",
      "DiscussionandOutlook\n",
      "Inthispaper,wegeneralizelogisticregressiontot-logisticregressionbyusing\n",
      "thet-exponentialfamily.Thenewalgorithmhasaprobabilisticinterpretation\n",
      "andismorerobusttolabelnoise.Eventhoughtheresultingobjectivefunction\n",
      "isnon-convex,empiricallyitappearstobeinsensitivetoinitialization.There\n",
      "areanumberofavenuesforfuturework.OnLong-Servedioexperiment,ifthe\n",
      "labelnoiseisincreasedsigni?cantlybeyond10%,theperformanceoft-logistic\n",
      "regressionmaydegrade(seeFig.6insupplementarymaterials).Understanding\n",
      "andexplainingthisissuetheoreticallyandempiricallyremainsanopenproblem.\n",
      "Itwillbeinterestingtoinvestigateift-logisticregressioncanbemarriedwith\n",
      "graphicalmodelstoyieldt-conditionalrandom?elds.Wewillalsofocuson\n",
      "betternumericaltechniquestoacceleratethe?-step,especiallyafasterwayto\n",
      "computegt.8\n",
      "12\n",
      "\n",
      "2References\n",
      "[1]ChoonHuiTeo,S.V.N.Vishwanthan,AlexJ.Smola,andQuocV.Le.\n",
      "Bundlemethodsforregularizedriskminimization.J.Mach.Learn.Res.,\n",
      "11:311?365,January2010.[2]S.Ben-David,N.Eiron,andP.M.Long.Onthe\n",
      "dif?cultyofapproximatelymaximizingagreements.J.Comput.SystemSci.,\n",
      "66(3):496?514,2003.[3]S.BoydandL.Vandenberghe.ConvexOptimization.\n",
      "CambridgeUniversityPress,Cambridge,England,2004.[4]PhilLongand\n",
      "RoccoServedio.Randomclassi?cationnoisedefeatsallconvexpotentialboost-\n",
      "ers.MachineLearningJournal,78(3):287?304,2010.[5]YoavFreund.Amore\n",
      "robustboostingalgorithm.TechnicalReportArxiv/0905.2138,Arxiv,May\n",
      "2009.[6]J.Naudts.Deformedexponentialsandlogarithmsingeneralizedther-\n",
      "mostatistics.PhysicaA,316:323?334,2002.URLhttp://arxiv.org/pdf/cond-\n",
      "mat/0203489.[7]J.Naudts.Generalizedthermostatisticsbasedondeformed\n",
      "exponentialandlogarithmicfunctions.PhysicaA,340:32?40,2004.[8]J.\n",
      "Naudts.Generalizedthermostatisticsandmean-?eldtheory.PhysicaA,332:279?300,\n",
      "2004.[9]J.Naudts.Estimators,escortproabilities,and?-exponentialfamilies\n",
      "instatisticalphysics.JournalofInequalitiesinPureandAppliedMathematics,\n",
      "5(4),2004.[10]C.Tsallis.Possiblegeneralizationofboltzmann-gibbsstatis-\n",
      "tics.J.Stat.Phys.,52,1988.[11]ChristopherBishop.PatternRecognitionand\n",
      "MachineLearning.Springer,2006.[12]TrevorHastie,RobertTibshirani,and\n",
      "JeromeFriedman.TheElementsofStatisticalLearning.Springer,NewYork,2\n",
      "edition,2009.[13]TimothyD.Sears.GeneralizedMaximumEntropy,Convex-\n",
      "ity,andMachineLearning.PhDthesis,AustralianNationalUniversity,2008.\n",
      "[14]AndreSousaandConstantinoTsallis.Student?st-andr-distributions:\n",
      "Uni?edderivationfromanentropicvariationalprinciple.PhysicaA,236:52?57,\n",
      "1994.[15]AO?hagan.Onoutlierrejectionphenomenainbayesinference.Royal\n",
      "StatisticalSociety,41(3):358?367,1979.[16]KennethL.Lange,RoderickJ.\n",
      "A.Little,andJeremyM.G.Taylor.Robuststatisticalmodelingusingthet\n",
      "distribution.JournaloftheAmericanStatisticalAssociation,84(408):881?896,\n",
      "1989.[17]J.Vanhatalo,P.Jylanki,andA.Vehtari.Gaussianprocessregres-\n",
      "sionwithstudent-tlikelihood.InNeuralInformationProcessingSystem,2009.\n",
      "[18]TakahitoKuno,YasutoshiYajima,andHiroshiKonno.Anouterapprox-\n",
      "imationmethodforminimizingtheproductofseveralconvexfunctionsona\n",
      "convexset.JournalofGlobalOptimization,3(3):325?335,September1993.\n",
      "[19]DavidMeaseandAbrahamWyner.Evidencecontrarytothestatistical\n",
      "viewofboosting.J.Mach.Learn.Res.,9:131?156,February2008.[20]R.Col-\n",
      "lobert,F.H.Sinz,J.Weston,andL.Bottou.Tradingconvexityforscalability.\n",
      "InW.W.CohenandA.Moore,editors,MachineLearning,Proceedingsofthe\n",
      "Twenty-ThirdInternationalConference(ICML2006),pages201?208.ACM,\n",
      "2006.[21]J.NocedalandS.J.Wright.NumericalOptimization.Springer\n",
      "SeriesinOperationsResearch.Springer,1999.[22]C.C.ChangandC.J.Lin.\n",
      "LIBSVM:alibraryforsupportvectormachines,2001.Softwareavailableat\n",
      "http://www.csie.ntu.edu.tw/?cjlin/libsvm.[23]FabianSinz.UniverSVM:Sup-\n",
      "portVectorMachinewithLargeScaleCCCPFunctionality,2006.Software\n",
      "availableathttp://www.kyb.mpg.de/bs/people/fabee/universvm.html.\n",
      "13\n",
      "\n",
      "9\n",
      "14\n",
      "\n",
      "PP4921.pdf\n",
      "PP4921.pdf 11\n",
      "GeneralizingAnalyticShrinkageforArbitrary\n",
      "CovarianceStructures\n",
      "Authoredby:\n",
      "Klaus-RobertM?ller\n",
      "DanielBartz\n",
      "Abstract\n",
      "Analyticshrinkageisastatisticaltechniquethatafastalterna-\n",
      "tivetocross-validationfortheregularizationofcovariancematricesand\n",
      "hasappealingconsistencyproperties.Weshowthattheproofofconsis-\n",
      "tencyimpliesboundsonthegrowthratesofeigenvaluesandtheirdis-\n",
      "persion,whichareoftenviolatedindata.Weproveconsistencyunder\n",
      "assumptionswhichdonotrestrictthecovariancestructureandtherefore\n",
      "bettermatchrealworlddata.Inaddition,weproposeanextensionofan-\n",
      "alyticshrinkage{orthogonalcomplementshrinkage{whichadaptstothe\n",
      "covariancestructure.Finallywedemonstratethesuperiorperformance\n",
      "ofournovelapproachondatafromthedomainsofspokenletter\n",
      "andopticalcharacterrecognition,andneuroscience.\n",
      "1PaperBody\n",
      "Theestimationofcovariancematricesisthebasisofmanymachinelearning\n",
      "algorithmsandestimationproceduresinstatistics.Thestandardestimatoris\n",
      "thesamplecovariancematrix:itsentriesareunbiasedandconsistent[1].A\n",
      "well-knownshortcomingofthesamplecovarianceisthesystematicerrorinthe\n",
      "spectrum.Inparticularforhighdimensionaldata,wheredimensionalitypand\n",
      "numberofobservationsnareoftenofthesameorder,largeeigenvaluesareover-\n",
      "undsmalleigenvaluesunderestimated.Aformofregularizationwhichcanalle-\n",
      "viatethisbiasisshrinkage[2]:theconvexcombinationofthesamplecovariance\n",
      "matrixSandamultipleoftheidentityT=p?1trace(S)I,Csh=(1??)S+?T,\n",
      "(1)haspotentiallylowermeansquarederrorandlowerbiasinthespectrum[3].\n",
      "Thestandardprocedureforchosinganoptimalregularizationforshrinkageis\n",
      "cross-validation[4],whichisknowntobetimeconsuming.Foronlinesettings\n",
      "CVcanbecomeunfeasibleandafastermodelselectionmethodisrequired.\n",
      "Recently,analyticshrinkage[3]whichprovidesaconsistentanalyticformula\n",
      "fortheaboveregularizationparameter?hasbecomeincreasinglypopular.It\n",
      "minimizestheexpectedmeansquarederroroftheconvexcombinationwitha\n",
      "1\n",
      "\n",
      "computationalcostofO(p2),whichisnegligiblewhenusedforalgorithmslike\n",
      "LinearDiscriminantAnalysis(LDA)whichareO(p3).Theconsistencyofana-\n",
      "lyticshrinkagereliesonassumptionswhicharerarelytestedinpractice[5].This\n",
      "paperwillthereforeaimtorendertheanalyticshrinkageframeworkmoreprac-\n",
      "ticalandusableforrealworlddata.Wecontributeinthreeaspects:rst,we\n",
      "derivesimpletestsfortheapplicabilityoftheanalyticshrinkageframeworkand\n",
      "observethatformanydatasetsofpracticalrelevancetheassumptionswhich\n",
      "underlyconsistencyarenotSecond,wedesignassumptionswhichbet-\n",
      "terthestatisticalpropertiesobservedinrealworlddatawhichtypicallyhasa\n",
      "lowdimensionalstructure.Underthesenewassumptions,weproveconsistency\n",
      "ofanalyticshrinkage.Weshowacounter-intuitiveresult:fortypicalcovariance\n",
      "structures,noshrinkage?andthereforenoregularization?takesplaceinthe\n",
      "limitofhighdimensionalityandnumberofobservations.Inpractice,thisleads\n",
      "toweakshrinkageanddegradingperformance.Therefore,third,wepropose\n",
      "anextensionoftheshrinkageframework:automaticorthogonalcomplement\n",
      "shrinkage(aoc-shrinkage)1\n",
      "takesthecovariancestructureintoaccountandoutperformsstandardshrink-\n",
      "ageonrealworlddataatamoderateincreaseincomputationtime.Notethat\n",
      "proofsofalltheoremsinthispapercanbefoundinthesupplementalmaterial.\n",
      "2\n",
      "Overviewofanalyticshrinkage\n",
      "Toderiveanalyticshrinkage,theexpectedmeansquarederroroftheshrink-\n",
      "agecovariancematrixeq.(1)asanestimatorofthetruecovariancematrixC\n",
      "isminimized:\n",
      "2\n",
      "?(2)?=argminR(?):=argminEC?(1??)S??T??()n\n",
      "oh\n",
      "X2i=argmin2?CovSij,Tij?VarSij+?2ESij?Tij+VarSij(3)?\n",
      "i,j\n",
      "n\n",
      "oVarS?CovS,Tijijiji,jh.2iPES?Tijiji,j\n",
      "P=\n",
      "?isobtainedbyreplacingexpectationswithsampleestimates:Theanalytic\n",
      "shrinkageestimator?2X\n",
      "11XdSij=Varxisxjs?xitxjt(n?1)nsnt()XXXX\n",
      "112222dSii,Tii=xisxks?xx0Cov(n?1)npntit0itstk\n",
      "b(Sij?Tij)2=(Sij?Tij)2E?arebasedonanalysisofasequence\n",
      "ofstatisticalmodelsTheoreticalresultsontheestimator?indexedbyn.Xn\n",
      "denotesapn?nmatrixofniidobservationsofpnvariableswithmeanzero\n",
      "andcovariancematrix?n.Yn=?TnXndenotesthesameobservationsin\n",
      "theireigenbasis,havingndiagonalcovariance?n=?Tn?n?n.Lowercase\n",
      "lettersxnitandyitdenotetheentriesofXnand?isitsconsistencyinthelarge\n",
      "n,pYn,respectively1.Themaintheoreticalresultontheestimator?limit\n",
      "[3].Adecisiveroleisplayedbyanassumptionontheeighthmoments2inthe\n",
      "eigenbasis:Assumption2(A2,Ledoit/Wolf2004[3]).Thereexistsaconstant\n",
      "K2independentofnsuchthatp?1n\n",
      "2\n",
      "\n",
      "pnX\n",
      "n8E[(yi1)]?K2.\n",
      "i=1\n",
      "3\n",
      "Implicitassumptionsonthecovariancestructure\n",
      "Fromtheassumptionontheeighthmomentsintheeigenbasis,wederive\n",
      "requirementsontheeigenvalueswhichfacilitateanempiricalcheck:Theorem1\n",
      "(largesteigenvaluegrowthrate).LetA2hold.Then,thereexistsalimitonthe\n",
      "growthrateofthelargesteigenvalue\n",
      "?1n=maxVar(yin)=Op1/4.ni\n",
      "Theorem2(dispersiongrowthrate).LetA2hold.Then,thereexistsalimit\n",
      "onthegrowthrateofthenormalizedeigenvaluedispersionXXdn=p?1(?i?\n",
      "p?1?j)2=O(1).nni\n",
      "j\n",
      "1\n",
      "Weshalloftendropthesequenceindexnandtheobservationindextto\n",
      "improvereadabilityofformulas.eighthmomentsarisebecauseVar(Sij),the\n",
      "varianceofthesamplecovariance,isoffourthorderandhastoconverge.Nev-\n",
      "ertheless,evenforfornon-Gaussiandataconvergenceisfast.2\n",
      "2\n",
      "modelA\n",
      "modelB\n",
      "dispersionandlargestEV\n",
      "4\n",
      "40\n",
      "modelB\n",
      "20\n",
      "100\n",
      "10\n",
      "50\n",
      "sampledispersionmax(EV)3.5\n",
      "30\n",
      "3\n",
      "20\n",
      "2.5\n",
      "10\n",
      "2\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "0500\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "3\n",
      "\n",
      "400\n",
      "max(EV)\n",
      "covariancematrices\n",
      "normalizedsampledispersion\n",
      "modelA\n",
      "0500\n",
      "dimensionality\n",
      "Figure1:Covariancematricesanddependencyofthelargesteigenvalue/dispersion\n",
      "onthedimensionality.Averageover100repetitions.\n",
      "normalizedsampledispersion\n",
      "60010\n",
      "sampledispersionmax(EV)\n",
      "100\n",
      "BCIEEGdata\n",
      "40\n",
      "200100\n",
      "200\n",
      "20\n",
      "20\n",
      "10050\n",
      "100\n",
      "4005\n",
      "50\n",
      "00\n",
      "ISOLETspokenletters40\n",
      "200\n",
      "0\n",
      "5001000#assets\n",
      "00\n",
      "100200#pixels\n",
      "0\n",
      "00\n",
      "dimensionality\n",
      "200400#features\n",
      "0600\n",
      "00\n",
      "200#features\n",
      "max(EV)\n",
      "USPShand?writtendigits\n",
      "USstockmarket150\n",
      "0400\n",
      "Figure2:Dependencyofthelargesteigenvalue/dispersiononthedimension-\n",
      "ality.Averageover100randomsubsets.\n",
      "Thetheoremsrestrictthecovariancestructureofthesequenceofmodels\n",
      "whenthedimensionalityincreases.Toillustratethis,wedesigntwosequences\n",
      "4\n",
      "\n",
      "ofmodelsAandBindexedbytheirdimensionalityp,inwhichdimensionsxpi\n",
      "arecorrelatedwithasignalsp:xpi\n",
      "=\n",
      "(0.5+bpi)??pi+?cpisp,withprobabilityPsA/B(i),(0.5+bpi)??pi\n",
      ",else.\n",
      "(4)\n",
      "wherebpiandcpiareuniformrandomfrom[0,1],spandpiarestandard\n",
      "normal,?=1,PsB(i)=0.2andPsA(i)=(i/10+1)?7/8(powerlawdecay).\n",
      "Toavoidsystematicerrors,weholdtheratioofobservationstodimensions\n",
      "np/p=2.TotheleftinFigure1,covariancematricesareshown:Formodel\n",
      "A,thematrixisdenseintheupperleftcorner,themoredimensionsweaddthe\n",
      "moresparsethematrixgets.FormodelB,correlationsarespreadoutevenly.To\n",
      "theright,normalizedsampledispersionandlargesteigenvalueareshown.For\n",
      "modelA,weseethebehaviourfromthetheorems:thedispersionisbounded,\n",
      "thelargesteigenvaluegrowswiththefourthroot.FormodelB,thereisalinear\n",
      "dependencyofbothdispersionandlargesteigenvalue:A2isviolated.Forreal\n",
      "worlddata,wemeasurethedependencyofthelargesteigenvalue/dispersion\n",
      "onthedimensionalitybyaveragingoverrandomsubsets.Figure2showsthe\n",
      "resultsforfourdatasets3:(1)NewYorkStockExchange,(2)USPShand-\n",
      "writtendigits,(3)ISOLETspokenlettersand(4)aBrainComputerInterface\n",
      "EEGdataset.Thelargesteigenvaluesandthenormalizeddispersions(see\n",
      "Figure2)closelyresemblemodelB;alineardependenceonthedimensionality\n",
      "whichviolatesA2isvisible.\n",
      "3\n",
      "fordetailsonthedatasets,seesection5.\n",
      "3\n",
      "4\n",
      "Analyticshrinkageforarbitrarycovariancestructures\n",
      "WereplaceA2byaweakerassumptiononthemomentsinthebasisof\n",
      "theobservationsXwhichdoesnotimposeanyconstraintsonthecovariance\n",
      "structure4:Assumption20(A20).ThereexistsaconstantK2independentof\n",
      "psuchthat?1\n",
      "p\n",
      "pX\n",
      "E[(xpi1)8]?K2.\n",
      "i=1\n",
      "StandardassumptionsFortheproofofconsistency,therelationshipbetween\n",
      "dimensionalityandnumberofobservationshastobeandaweakrestric-\n",
      "tiononthecorrelationoftheproductsofuncorrelatedvariablesisnecessary.We\n",
      "useslightlymoversionsoftheoriginalassumptions[3].Assumption10\n",
      "(A10,Kolmogorovasymptotics).ThereexistsaconstantK1,0?K1??\n",
      "independentofpsuchthatlimp/np=K1.p??\n",
      "Assumption30(A30).Plim\n",
      "i,j,kl,l?Qp\n",
      "pppp2Cov[yi1yj1,yk1yl1]\n",
      "|Qp|\n",
      "5\n",
      "\n",
      "p??\n",
      "=0\n",
      "whereQpisthesetofallquadruplesconsistingofdistinctintegersbetween\n",
      "1andp.AdditionalAssumptionsA10toA30subsumeawiderangeofdisper-\n",
      "sionandeigenvalueToinvestigatetherolewhichthisplays,we\n",
      "categorizesequencesbyaddinganadditionalparameterk.Itwillproveessen-\n",
      "tialforthelimitbehaviorofoptimalshrinkageandtheconsistencyofanalytic\n",
      "shrinkage:Assumption4(A4,growthrateofthenormalizeddispersion).Let\n",
      "?idenotetheeigenvaluesofC.Then,thelimitbehaviourofthenormalized\n",
      "dispersionisparameterizedbyk:XX\n",
      "p?1(?i?p?1?j)2=?max(1,p2k?1),i\n",
      "j\n",
      "where?istheLandauTheta.Insequencesofmodelswithk?0.5the\n",
      "normalizeddispersionisboundedfromaboveandbelow,asinmodelAinthe\n",
      "lastsection.Fork>0.5thenormalizeddispersiongrowswiththedimensionality,\n",
      "fork=1itislinearinp,asinmodelB.Wemaketwotechnicalassumptions\n",
      "toruleoutdegeneratecases.First,weassumethat,onaverage,additional\n",
      "dimensionsmakeapositivecontributiontothemeanvariance:Assumption5\n",
      "(A5).ThereexistsaconstantK3suchthatp?1\n",
      "pX\n",
      "E[(xpi1)2]?K3.\n",
      "i=1\n",
      "Second,weassumethatlimitsontherelationbetweensecond,fourthand\n",
      "eighthmomentsexist:Assumption6(A6,momentrelation).??4,?8,?4and\n",
      "?8:\n",
      "4\n",
      "E[yi8]\n",
      "?\n",
      "(1+?8)E2[yi4]\n",
      "E[yi4]\n",
      "?\n",
      "(1+?4)E2[yi2]\n",
      "E[yi8]\n",
      "?\n",
      "(1+?8)E2[yi4]\n",
      "E[yi4]\n",
      "?\n",
      "(1+?4)E2[yi2]\n",
      "Forconvenience,weindexthesequenceofstatisticalmodelsbypinsteadof\n",
      "n.\n",
      "4\n",
      "Figure3:Illustrationoforthogonalcomplementshrinkage.Theoreticalre-\n",
      "sultsonlimitbehaviourandconsistencyWeareabletoderiveanoveltheorem\n",
      "whichshowsthatunderthesewiderassumptions,shrinkageremainsconsistent:\n",
      "Theorem3(ConsistencyofShrinkage).LetA10,A20,A30,A4,A5,A6hold\n",
      "and\n",
      "6\n",
      "\n",
      "2???m=E(???)/??Then,independentlyofk,denotetheexpected\n",
      "squaredrelativeerroroftheestimate?.limm=0.\n",
      "p??\n",
      "Anunexpectedcaveataccompanyingthisresultisthelimitbehaviourofthe\n",
      "optimalshrinkagestrength??:Theorem4(Limitbehaviour).LetA10,A20,\n",
      "A30,A4,A5,A6hold.Then,thereexist0<bl<bu<1k?0.5k>0.5\n",
      "?n:bl????bulim??=0\n",
      "??\n",
      "p??\n",
      "Thetheoremshowsthatthereisafundamentalproblemwithanalyticshrink-\n",
      "age:ifkislargerthan0.5(alldatasetsinthelastsectionhadk=1)thereis\n",
      "noshrinkageinthelimit.\n",
      "5\n",
      "Automaticorthogonalcomplementshrinkage\n",
      "OrthogonalcomplementshrinkageToobtainashrinkagestrength,we\n",
      "proposeanextensionofshrinkagewecalloc-shrinkage:itleavestheeigendi-\n",
      "rectionuntouchedandperformsshrinkageontheorthogonalcomplementocof\n",
      "thatdirection.Figure3illustratesthisapproach.Itshowsathreedimensional\n",
      "truecovariancematrixwithahighdispersionthatmakesithighlyellipsoidal.\n",
      "Theresultisahighlevelofdiscrepancybetweenthesphericalshrinkagetarget\n",
      "andthetruecovariance.Thebestconvexcombinationoftargetandsample\n",
      "covariancewillputextremelylowweightonthetarget.Thesituationisdif-\n",
      "ferentintheorthogonalcomplementofthersteigendirectionofthesample\n",
      "covariancematrix:there,thediscrepancybetweensamplecovarianceandtar-\n",
      "getisstronglyreduced.Tosimplifythetheoreticalanalysis,letusconsiderthe\n",
      "casewherethereisonlyasinglegrowingeigenvaluewhiletheremainderstays\n",
      "bounded:5\n",
      "Assumption40(A40singlelargeeigenvalue).Letuszi=yi,2?i\n",
      "?p,z1=p?k/2y1.ThereexistconstantsFlandFusuchthatFl?E[zi8]?\n",
      "FuArecentresultfromRandomMatrixTheory[6]allowsustoprovethatthe\n",
      "projectionontheempir?ocicalorthogonalcomplementocbdoesnot\n",
      "theconsistencyoftheestimator?b:0000Theorem5(consistencyofoc-\n",
      "shrinkage).LetA1,A2,A3,A4,A5,A6hold.Inaddition,assumethat16th\n",
      "moments5oftheyiexistandarebounded.Then,independentlyofk,\n",
      "2?lim?oc=0,b?argminQocb(?)p??\n",
      "?\n",
      "whereQdenotesthemeansquarederror(MSE)oftheconvexcombination\n",
      "(cmp.eq.(2)).AutomaticmodelselectionOrthogonalcomplementshrinkage\n",
      "onlyyieldsanadvantageiftheeigenvalueislargeenough.Startingfromeq.\n",
      "(2),wecanconsistentlyestimatetheerrorofstandardshrinkageandorthogonal\n",
      "complementshrinkageandonlyuseoc-shrinkagewhenthebR,oc?b\n",
      "ispositive.Inthesupplementalmaterial,wederiveaformulaofaconservative\n",
      "estimate:?2?bR,cons.,ocbb?m????b?mE???.b=?R,oc?R,occ\n",
      "ocbE\n",
      "Usageofm?=0.45correspondsto75%probabilityofimprovementunder\n",
      "gaussianityandyieldsgoodresultsinpractice.Thesecondtermisrelevant\n",
      "7\n",
      "\n",
      "insmallsamples,settingmE=0.1ist.Adatasetmayhavemulti-\n",
      "plelargeeigenvalues.Itisstraightforwardtoiteratetheprocedureandthus\n",
      "automaticallyselectthenumberofretainedeigendirectionsr?.Wecallthisau-\n",
      "tomaticorthogonalcomplementshrinkage.Analgorithmlistingcanbefoundin\n",
      "thesupplemental.Thecomputationalcostofaoc-shrinkageislargerthanthat\n",
      "ofstandardshrinkageasitadditionallyrequiresaneigendecompositionO(p3)\n",
      "andsomematrixmultiplicationsO(?rp2).Intheapplicationsconsideredhere,\n",
      "thisadditionalcostisnegligible:r?pandtheeigendecompositioncanreplace\n",
      "matrixinversionsforLDA,QDAorportfoliooptimization.10.9\n",
      "PRIAL\n",
      "0.80.70.6Shrinkageoc(1)?Shrinkageoc(2)?Shrinkageoc(3)?Shrinkageoc(4)?Shrinkage\n",
      "aoc?Shrinkage\n",
      "0.50.4\n",
      "1\n",
      "10\n",
      "2\n",
      "10\n",
      "dimensionalityp\n",
      "Figure4:Automaticselectionofthenumberofeigendirections.Average\n",
      "over100runs.\n",
      "6\n",
      "Empiricalvalidation\n",
      "SimulationsTotestthemethod,weextendmodelB(eq.(4),section3)\n",
      "tothreesignals,Psi=(0.1,0.25,0.5).Figure4reportsthepercentageim-\n",
      "provementinaveragelossoverthesamplecovariancematrix,EkS?Ck?\n",
      "EkCsh/oc?sh/aoc?sh?CkPRIALCsh/oc?sh/aoc?sh=,EkS?Ck5The\n",
      "existenceof16thmomentsisneededbecauseweboundtheestimationerrorin\n",
      "eachdirectionbythemaximumoveralldirections,anextremelyconservative\n",
      "approximation.\n",
      "6\n",
      "Table1:Portfoliorisk.Meanabsolutedeviations?103(meansquareddevi-\n",
      "ations?106)oftheresultingportfoliosforthetcovarianceestimators\n",
      "andmarkets.?:=aoc-shrinkagetlybetterthanthismodelatthe\n",
      "5%level,testedbyarandomizationtest.USEUHKsamplecovariance8.56?\n",
      "(156.1?)5.93?(78.9?)6.57?(81.2?)standardshrinkage6.27?(86.4?)\n",
      "4.43?(46.2?)6.32?(76.2?)??0.090.120.10shrinkagetoafactormodel\n",
      "5.56?(69.6?)4.00?(39.1?)6.17?(72.9?)??0.410.440.42aoc-shrinkage\n",
      "5.41(67.0)3.83(36.3)6.11(71.8)??0.750.790.75averager?1.641.171.41\n",
      "Table2:AccuraciesfortasksonISOLETandUSPSdata.?\n",
      ":=tlybetterthanallcomparedmethodsatthe5%level,testedbya\n",
      "randomizationtest.ISOLETUSPSntrain5002000500050020005000LDA\n",
      "75.77%92.29%94.1%72.31%87.45%89.56%LDA(shrinkage)88.92%93.25%\n",
      "94.3%83.77%88.37%89.77%????LDA(aoc)89.69%93.42%94.33%\n",
      "83.95%88.37%89.77%QDA2.783%4.882%14.09%10.11%49.45%72.43%\n",
      "QDA(shrinkage)58.57%75.4%79.25%82.2%88.85%89.67%?QDA(aoc)\n",
      "59.51%80.84%87.35%83.31%89.4%90.07%\n",
      "8\n",
      "\n",
      "ofstandardshrinkage,oc-shrinkageforonetofoureigendirectionsandaoc-\n",
      "shrinkage.?andthereforethePRIALtendtozeroinStandardshrinkage\n",
      "behavesaspredictedbyTheorem4:?thelargen,plimit.Thesameholds\n",
      "forordersofoc-shrinkage?oc(1)andoc(2)?lowerthanthenumberofsignals,\n",
      "butperformancedegradesmoreslowly.Forsmalldimensionalitieseigenvalues\n",
      "aresmallandthereforethereisnoadvantageforoc-shrinkage.Onthecontrary,\n",
      "thehighertheorderofoc-shrinkage,thelargertheerrorbyprojectingoutspu-\n",
      "riouslargeeigenvalueswhichshouldhavebeensubjecttoregularization.The\n",
      "automaticorderselectionaoc-shrinkageleadstoclosetooptimalPRIALforall\n",
      "dimensionalities.RealworlddataI:portfoliooptimizationCovarianceestimates\n",
      "areneededfortheminimizationofportfoliorisk[7].Table1showsportfoliorisk\n",
      "forapproximatelyeightyearsofdailyreturndatafrom1200US,600European\n",
      "and100HongKongstocks,aggregatedfromReuterstickdata[8].Estimation\n",
      "ofcovariancematricesisbasedonshorttimewindows(150days)becauseof\n",
      "thedata?snonstationarity.Despitetheunfavorableratioofobservationsto\n",
      "dimensionality,standardshrinkage?thestocksarehighlycorrelatedandthe\n",
      "sphericaltargetishighlyinapprohasverylowvaluesof?:priate.Shrinkage\n",
      "toafactormodelincorporatingthemarketfactor[9]providesabet-\n",
      "tertarget;itleadstostrongershrinkageandbetterportfolios.Ourproposed\n",
      "aoc-shrinkageyieldsevenstrongershrinkageandtlyoutperformsall\n",
      "comparedmethods.\n",
      "Table3:AccuraciesfortasksonBCIdata.injected\n",
      "noiseinoneelectrode.?:=tlybetterthanallcomparedmethodsat\n",
      "the5%level,testedbyarandomizationtest.?noise010301003001000LDA\n",
      "92.28%92.28%92.28%92.28%92.28%92.28%LDA(shrinkage)92.39%92.94%\n",
      "92.18%88.04%82.15%73.79%??????LDA(aoc)93.27%93.27%93.24%\n",
      "92.88%93.16%93.19%averager?2.08363.09453.08913.08913.08913.097\n",
      "0.0932\n",
      "0.0631\n",
      "0.2532\n",
      "0.0466\n",
      "0.0316\n",
      "0.1266\n",
      "0\n",
      "0\n",
      "0\n",
      "?0.0466\n",
      "?0.0316\n",
      "?0.1266\n",
      "?0.0932\n",
      "?0.0631\n",
      "?0.2532\n",
      "Figure5:Highvariancecomponentsresponsibleforfailureofshrinkagein\n",
      "BCI.?noise=10.Subject1.RealworlddataII:USPSandISOLETWeapplied\n",
      "LinearandQuadraticDiscriminantAnalysis(LDAandQDA)tohand-written\n",
      "9\n",
      "\n",
      "digitrecognition(USPS,1100observationswith256pixelsforeachofthe10dig-\n",
      "its[10])andspokenletterrecognition(ISOLET,617features,7797recordingsof\n",
      "26spokenletters[11],obtainedfromtheUCIMLRepository[12])toassessthe\n",
      "qualityofstandardandaoc-shrinkagecovarianceestimates.Table2showsthat\n",
      "aoc-shrinkageoutperformsstandardshrinkageforQDAandLDAonbothdata\n",
      "setsforttrainingsetsizes.OnlyforLDAandlargesamplesizesonthe\n",
      "relativelylowdimensionalUSPSdata,thereisnobetweenstandard\n",
      "andaoc-shrinkage:theautomaticproceduredecidesthatshrinkageonthewhole\n",
      "spaceisoptimal.RealworlddataIII:Brain-Computer-InterfaceTheBCIdata\n",
      "wasrecordedinastudyinwhich11subjectshadtodistinguishbetweennoisy\n",
      "andnoise-freephonemes[13,14].WeappliedLDAon427standardizedfeatures\n",
      "calculatedfromeventrelatedpotentialsin61electrodestoclassifytwocondi-\n",
      "tions:correctlyidennoise-freeandcorrectlyidennoisyphonemes\n",
      "(ntrain=1000).ForTable3,wesimulatedadditivenoiseinarandomelectrode\n",
      "(100repetitions).Withandwithoutnoise,ourproposedaoc-shrinkageoutper-\n",
      "formsstandardshrinkageLDA.Withoutnoise,r??2highvariancedirections\n",
      "?probablycorrespondingtoocularandfacialmuscleartefacts,depictedtothe\n",
      "leftinFigure5?areleftuntouchedbyaoc-shrinkage.Withinjectednoise,the\n",
      "numberofdirectionsincreasestor??3,astheproceduredetectstheadditional\n",
      "highvariancecomponent?totherightinFigure5?andadaptstheshrinkage\n",
      "proceduresuchthatperformanceremainsForstandardshrinkage,\n",
      "noisetstheanalyticregularizationandperformancedegradesasaresult.\n",
      "7\n",
      "Discussion\n",
      "Analyticshrinkageisafastandaccuratealternativetocross-validationwhich\n",
      "yieldscomparableperformance,e.g.inpredictiontasksandportfoliooptimiza-\n",
      "tion.Thispaperhascontributedbyclarifyingthe(limited)applicabilityofthe\n",
      "analyticshrinkageformula.Inparticularwecouldshowthatitsassumptionsare\n",
      "oftenviolatedinpracticesincerealworlddatahascomplexstructureddepen-\n",
      "dencies.Wethereforeintroducedasetofmoregeneralassumptionstoshrink-\n",
      "agetheory,chosensuchthattheappealingconsistencypropertiesofanalytic\n",
      "shrinkagearepreserved.Wehaveshownthatfortypcialstructureinrealworld\n",
      "data,strongeigendirectionsadverselyshrinkagebydrivingtheshrinkage\n",
      "strengthtozero.Therefore,,wehaveproposedanalgorithmwhichau-\n",
      "tomaticallyrestrictsshrinkagetotheorthogonalcomplementofthestrongest\n",
      "eigendirectionsifappropriate.Thisleadstoimprovedrobustnessand\n",
      "cantperformanceenhancementinsimulationsandonrealworlddatafromthe\n",
      "domainsofspokenletterandopticalcharacterrecognition,andneuro-\n",
      "science.AcknowledgmentsThisworkwassupportedinpartbytheWorldClass\n",
      "UniversityProgramthroughtheNationalResearchFoundationofKoreafunded\n",
      "bytheMinistryofEducation,Science,andTechnology,underGrantR31-10008.\n",
      "WethankGillesBlanchard,DuncanBlythe,ThorstenDickhaus,IreneWinkler\n",
      "andAnnePorbadnikforvaluablecommentsanddiscussions.\n",
      "8\n",
      "10\n",
      "\n",
      "2References\n",
      "[1]TrevorHastie,RobertTibshirani,andJeromeFriedman.TheElements\n",
      "ofStatisticalLearning.Springer,2008.[2]CharlesStein.Inadmissibilityof\n",
      "theusualestimatorforthemeanofamultivariatenormaldistribution.In\n",
      "Proc.3rdBerkeleySympos.Math.Statist.Probability,volume1,pages\n",
      "197?206,1956.[3]OlivierLedoitandMichaelWolf.Awell-conditionedestima-\n",
      "torforlarge-dimensionalcovariancematrices.JournalofMultivariateAnalysis,\n",
      "88(2):365?411,2004.[4]Jerome.H.Friedman.Regularizeddiscriminantanal-\n",
      "ysis.JournaloftheAmericanStatisticalAssociation,84(405):165?175,1989.\n",
      "[5]JulianeSch?aferandKorbinianStrimmer.Ashrinkageapproachtolarge-\n",
      "scalecovariancematrixestimationandimplicationsforfunctionalgenomics.\n",
      "StatisticalApplicationsinGeneticsandMolecularBiology,4(1):1175?1189,\n",
      "2005.[6]BoazNadler.Finitesampleapproximationresultsforprincipalcom-\n",
      "ponentanalysis:Amatrixperturbationapproach.TheAnnalsofStatistics,\n",
      "36(6):2791?2817,2008.[7]HarryMarkowitz.Portfolioselection.Journalof\n",
      "Finance,VII(1):77?91,March1952.[8]DanielBartz,KerrHatrick,Christian\n",
      "W.Hesse,Klaus-RobertM?uller,andStevenLemm.DirectionalVarianceAd-\n",
      "justment:Biasreductionincovariancematricesbasedonfactoranalysiswith\n",
      "anapplicationtoportfoliooptimization.PLoSONE,8(7):e67503,072013.[9]\n",
      "OlivierLedoitandMichaelWolf.Improvedestimationofthecovariancematrix\n",
      "ofstockreturnswithanapplicationtoportfolioselection.JournalofEmpirical\n",
      "Finance,10:603?621,2003.[10]JonathanJ.Hull.Adatabaseforhandwritten\n",
      "textrecognitionresearch.IEEETransactionsonPatternAnalysisandMa-\n",
      "chineIntelligence,16(5):550?554,May1994.[11]MarkAFantyandRonald\n",
      "Cole.Spokenletterrecognition.InAdvancesinNeuralInformationProcess-\n",
      "ingSystems,volume3,pages220?226,1990.[12]KevinBacheandMoshe\n",
      "Lichman.UCImachinelearningrepository.UniversityofCalifornia,Irvine,\n",
      "SchoolofInformationandComputerSciences,2013.[13]AnneKerstinPor-\n",
      "badnigk,Jan-NiklasAntons,BenjaminBlankertz,MatthiasSTreder,Robert\n",
      "Schleicher,SebastianM?oller,andGabrielCurio.UsingERPsforassessingthe\n",
      "(sub)consciousperceptionofnoise.In32ndAnnualIntlConf.oftheIEEE\n",
      "EngineeringinMedicineandBiologySociety,pages2690?2693,2010.[14]Anne\n",
      "KerstinPorbadnigk,MatthiasSTreder,BenjaminBlankertz,Jan-NiklasAn-\n",
      "tons,RobertSchleicher,SebastianM?oller,GabrielCurio,andKlaus-Robert\n",
      "M?uller.Single-trialanalysisoftheneuralcorrelatesofspeechqualitypercep-\n",
      "tion.Journalofneuralengineering,10(5):056003,2013.\n",
      "9\n",
      "11\n",
      "\n",
      "PP6539.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP6539.pdf 14\n",
      "HierarchicalObjectRepresentationfor\n",
      "Open-EndedObjectCategoryLearningand\n",
      "Recognition\n",
      "Authoredby:\n",
      "SeyedHamidrezaKasaei\n",
      "AnaMariaTom?\n",
      "Lu?sSeabraLopes\n",
      "Abstract\n",
      "Mostrobotslacktheabilitytolearnnewobjectsfrompastexperiences.\n",
      "Tomigratearobottoanewenvironmentonemustoftencompletelyre-\n",
      "generatetheknowledge-basethatitisrunningwith.Sinceinopen-ended\n",
      "domainsthesetofcategoriestobelearnedisnotitisnot\n",
      "feasibletoassumethatonecanpre-programallobjectcategoriesrequired\n",
      "byrobots.Therefore,autonomousrobotsmusthavetheabilitytocontin-\n",
      "uouslyexecutelearningandrecognitioninaconcurrentandinterleaved\n",
      "fashion.Thispaperproposesanopen-ended3Dobjectrecognitionsystem\n",
      "whichconcurrentlylearnsboththeobjectcategoriesandthestatistical\n",
      "featuresforencodingobjects.Inparticular,weproposeanextensionof\n",
      "LatentDirichletAllocationtolearnstructuralsemanticfeatures(i.e.top-\n",
      "ics)fromlow-levelfeatureco-occurrencesforeachcategoryindependently.\n",
      "Moreover,topicsineachcategoryarediscoveredinanunsupervisedfash-\n",
      "ionandareupdatedincrementallyusingnewobjectviews.Theapproach\n",
      "containssimilaritieswiththeorganizationofthevisualcortexandbuilds\n",
      "ahierarchyofincreasinglysophisticatedrepresentations.Resultsshow\n",
      "thefuperformanceofthisapproachonttypesofobjects.\n",
      "Moreover,thissystemdemonstratesthecapabilityoflearningfromfew\n",
      "trainingexamplesandcompeteswithstate-of-the-artsystems.\n",
      "1PaperBody\n",
      "Open-endedlearningtheoryincognitivepsychologyhasbeenatopicofcon-\n",
      "siderableinterestformanyresearchers.Thegeneralprincipleisthathumans\n",
      "learntorecognizeobjectcategoriesceaselesslyovertime.Thisabilityallows\n",
      "themtoadapttonewenvironments,byenhancingtheirknowledgefromthe\n",
      "accumulationofexperiencesandtheconceptualizationofnewobjectcategories\n",
      "[1].Inhumansthereisevidenceofhierarchicalmodelsforobjectrecognition\n",
      "1\n",
      "\n",
      "incortex[2].Moreover,inhumansobjectrecognitionskillsandtheunderlying\n",
      "capabilitiesaredevelopedconcurrently[2].Inhierarchicalrecognitiontheories,\n",
      "thehumansequentiallyprocessesinformationaboutthetargetobjectleading\n",
      "totherecognitionresult.Thisbeginswithlowerlevelcorticalprocessorssuch\n",
      "astheelementaryvisualcortexandgo?up?totheinferotemporalcortex(IT)\n",
      "whererecognitionoccurs.Takingthisasinspiration,anautonomousrobotwill\n",
      "processvisualinformationcontinuously,andperformlearningandrecognition\n",
      "concurrently.Inotherwords,apartfromlearningfromabatchoflabelled\n",
      "trainingdata,therobotshouldcontinuouslyupdateandlearnnewobjectcat-\n",
      "egorieswhileworkingintheenvironmentinanopen-endedmanner.Inthis\n",
      "paper,?open-ended?impliesthatthesetofobjectcategoriestobelearned\n",
      "isnotknowninadvance.Thetraininginstancesareextractedfromon-line\n",
      "experiencesofarobot,andthusbecomegraduallyavailableovertime,rather\n",
      "thancompletelyavailableatthebeginningofthelearningprocess.Classical\n",
      "objectrecognitionsystemsareoftendesignedforstaticenvironmentsi.e.train-\n",
      "inge)andtesting(online)aretwoseparatedphases.Iflimitedtraining\n",
      "dataisused,thismightleadtonon-discriminativeobjectrepresentationsand,\n",
      "asaconsequence,topoorobjectrecog30thConferenceonNeuralInformation\n",
      "ProcessingSystems(NIPS2016),Barcelona,Spain.\n",
      "nitionperformance.Therefore,buildingadiscriminativeobjectrepresenta-\n",
      "tionisachallengingsteptoimproveobjectrecognitionperformance.Moreover,\n",
      "timeandmemoryyisalsoimportant.Comparing3Ddirectlybased\n",
      "theirlocalfeaturesiscomputationallyexpensive.Topicmodellingissuitablefor\n",
      "open-endedlearningbecause,notonlyitprovidesshortobjectdescriptions(i.e.\n",
      "optimizingmemory),butalsoenablestprocessingoflargecollections.\n",
      "Thispaperproposesa3Dobjectrecogcategorylayernitionsystemcapableof\n",
      "learningbothviewlayerobjectcategoriesaswellasthetopicsusedtoencode\n",
      "themconcurrentlyandtopiclayerinanopen-endedmanner.WeproBoWlayer\n",
      "poseanextensionofLatentDirichletAllocationtolearnincrementallytopfea-\n",
      "turelayericsforeachcategoryindependently.Moreover,topicsineachcategory\n",
      "arediscoveredinanunsupervisedfashionandupdatedincrementallyusingnew\n",
      "objectviews.AsdepictedinFig.1,theapproachisdesignedtobeusedbya\n",
      "servicerobotworkinginadomes-Figure1:Theproposedmultilayerobject\n",
      "representationbeingticenvironment.Fig.1(left),showsatestedonaservice\n",
      "robot.ItconsistsofelayersofhierarchyPR2robotlookingatsomeobjects\n",
      "onincludingfeaturelayer,BoWlayer,topiclayer,objectviewlayerthetable.\n",
      "Fig.1(right)showsthepointandcategorylayer.cloudofthesceneobtained\n",
      "throughtherobot?sKinectandtheusedrepresentations.Tabletopsobjectsare\n",
      "tracked(signedbytcolors)andprocessedthroughahierarchyofelay-\n",
      "ers.Forinstance,todescribeanobjectview,inthefeaturelayer,aspin-image\n",
      "shapedescriptor[3]isusedtorepresentthelocalshapesoftheobjectint\n",
      "keypoints;afterwards,intheBag-of-Words(BoW)layer,thegivenobjectview\n",
      "isdescribedbyhistogramsoflocalshapefeatures,asinBag-of-Words\n",
      "models;inthetopiclayer,eachtopicisasadiscretedistributionover\n",
      "visualwordsandeachobjectviewisdescribedasarandommixtureoverlatent\n",
      "topicsofthecategoryandstoresthemintothememory(viewlayer).Finally,\n",
      "2\n",
      "\n",
      "thecategorymodelisupdatedbyaddingtheobtainedrepresentation(category\n",
      "layer).Theremainderofthispaperisorganizedasfollows.Insection2,wedis-\n",
      "cussrelatedworks.Section3providesasystemoverview.Themethodologyfor\n",
      "constructingvisualwordsdictionaryispresentedinsection4.Section5describes\n",
      "theproposedobjectrepresentation.Objectcategorylearningandrecognition\n",
      "arethenexplainedinsection6.Evaluationoftheproposedsystemispresented\n",
      "insection7.Finally,conclusionsarepresentedandfutureresearchisdiscussed.\n",
      "2\n",
      "Relatedwork\n",
      "Oneoftheimportanttasksintheofassistiveandservicerobotsisto\n",
      "achievehuman-likeobjectcategorylearningandrecognition.Riesenhuberand\n",
      "Poggio[2]proposedahierarchicalapproachforobjectrecognitionconsistent\n",
      "withphysiologicaldata,inwhichobjectsaremodelledinahierarchyofincreas-\n",
      "inglysophisticatedrepresentations.Sivicetal.[4]proposedanapproachto\n",
      "discoverobjectsinimagesusingProbabilisticLatentSemanticIndexing(pLSI)\n",
      "modelling[5].Bleietal.[6]arguedthatthepLSIisincompleteinthatitpro-\n",
      "videsnoprobabilisticmodelatthelevelofdocuments.TheyextendedthepLSI\n",
      "modelcallingtheapproachLatentDirichletAllocation(LDA).SimilartopLSI\n",
      "andLDA,wediscovertopicsinanunsupervisedfashion.Unlikeourapproach\n",
      "inthispaper,pLSIandLDAdonotincorporateclassinformation.Several\n",
      "workshavebeenpresentedtoincorporateaclasslabelinthegenerativemodel\n",
      "[7][8][9].Bleietal.[7]extendLDAandproposedSupervisedLDA(sLDA).\n",
      "ThesLDAwasusedforsupervisedtextprediction.Later,Wangetal.[8]\n",
      "extendedsLDAtoproblems.AnotherpopularextensionofLDA\n",
      "istheclassLDA(cLDA)[9].Similartoourapproach,theonlysupervisionused\n",
      "bysLDAandcLDAisthecategorylabelofeachtrainingobject.However,\n",
      "therearetwomaindierences.First,thelearnedtopicsinsLDAandcLDAare\n",
      "sharedamongallcategories,whileweproposetolearnsptopicspercate-\n",
      "gory.Second,thesLDAandcLDAapproachesfollowastandardtrain-and-test\n",
      "procedure(i.e.setofclasses,trainandtestdataareknownoravailablein2\n",
      "advance),ourapproachcanincrementallyupdatetopicsusingnewobser-\n",
      "vationsandthesetofclassesiscontinuouslygrowing.Therearesometopic-\n",
      "supervisedapproachese.g.LabeledLDA[10]andsemiLDA[11]thatconsider\n",
      "classlabelsfortopics.Ononehand,theseapproachesneedtensofhoursof\n",
      "manualannotation.Ontheotherhand,ahumancannotprovideasp\n",
      "categorylabelfora3Dlocalshapedescription(e.g.aspin-images[3]).There\n",
      "aresomeLDAapproachesthatsupportincrementallearningofobjectcate-\n",
      "gories.Thebetweenincrementalandopen-endedlearningisthatthe\n",
      "setofclassesisinincrementallearning,whileinopen-endedlearning\n",
      "thesetofclassesiscontinuouslygrowing.Banerjeeetal.proposed[12]online\n",
      "LDA(o-LDA)thatisasimplemoofbatchcollapsedGibbssampler.\n",
      "Theo-LDAappliesthebatchGibbssamplertothefulldatasetandthen\n",
      "samplesnewtopicsforeachnewlyobservedwordusinginformationobserved\n",
      "sofar.Caninietal.[13]extendedo-LDAandproposedanincrementalGibbs\n",
      "samplerforLDA(herereferredtoasI-LDA).TheI-LDAdoesnotneedabatch\n",
      "initializationphaselikeo-LDA.Ino-LDAandI-LDA,thenumberofcategories\n",
      "3\n",
      "\n",
      "iswhileinourapproachthenumberofcategoriesisgrowing.Moreover,\n",
      "o-LDAandI-LDAareusedtodiscovertopicssharedamongallcategories,while\n",
      "ourapproachisusedtodiscoversptopicspercategory.Currently,apop-\n",
      "ularapproachinobjectrecognitionisdeeplearning.However,thereareseveral\n",
      "limitationstouseDeepNeuralNetworks(DNN)inopen-endeddomains.Deep\n",
      "networksareincrementalbynaturebutnotopen-ended,sincetheinclusionof\n",
      "novelcategoriesenforcesarestructuringinthetopologyofthenetwork.More-\n",
      "over,DNNusuallyneedsalotoftrainingdataandlongtrainingtimestoobtain\n",
      "anacceptableaccuracy.Schwarzet.al[14]usedDNNfor3Dobjectcategory\n",
      "learning.TheyclearlyshowedthattheperformanceofDNNdegradeswhenthe\n",
      "sizeofdatasetisreduced.\n",
      "3\n",
      "Systemoverview\n",
      "Themainmotivationofthisworkistoachieveamulti-layeredobjectrep-\n",
      "resentationthatbuildsanincreasinglycomplexobjectrepresentation(seeFig.\n",
      "1).Particularly,astatisticalmodelisusedtogetstructuralsemanticfeatures\n",
      "fromlow-levelfeatureco-occurrences.Thebasicideaisthateachobjectview\n",
      "isdescribedasarandommixtureoverasetoflatenttopics,andeachtopicis\n",
      "asadiscretedistributionovervisualwords(i.e.localshapefeatures).\n",
      "Itmustbepointedoutthatweareusingshapefeaturesratherthansemantic\n",
      "propertiestoencodethestatisticalstructureofobjectcategories[15].Itiseasier\n",
      "toexplainthedetailsusinganexample.Westartbyselectingacategorylabel,\n",
      "forexampleMug.TorepresentanewinstanceofMug,adistributionoverMug\n",
      "topicsisdrawnthatwillspecifywhichintermediatetopicsshouldbeselected\n",
      "forgeneratingeachvisualwordsoftheobject.Accordingtothisdistribution,\n",
      "aparticulartopicisselectedoutofthemixtureofpossibletopicsoftheMug\n",
      "categoryforgeneratingeachvisualwordintheobject.Forinstance,aMug\n",
      "usuallyhasahandle,anda?handle?topicreferstosomevisualwordsthat\n",
      "occurfrequentlytogetherinhandles.Theprocessofdrawingboththetopic\n",
      "andvisualwordisrepeatedseveraltimestochooseasetofvisualwordsthat\n",
      "wouldconstructaMug.Weusestatisticalinferencetechniquesforinverting\n",
      "thisprocesstoautomaticallyoutasetoftopicsforeachcategoryfroma\n",
      "collectionofinstances.Inotherwords,wetrytolearnamodelforeachcate-\n",
      "gory(asetoflatentvariables)thatexplainshoweachobjectobtainsitsvisual\n",
      "words.Inourapproach,thecharacteristicsofsurfacesbelongingtoobjectsare\n",
      "describedbylocalshapefeaturescalledspin-images[3].\n",
      "4\n",
      "Dictionaryconstruction\n",
      "Comparing3Dobjectsbasedontheirlocalfeaturesiscomputationallyex-\n",
      "pensive.Thetopicmodellingapproachdirectlyaddressesthisconcern.Itre-\n",
      "quiresadictionarywithVvisualwords.Usually,thedictionaryiscreatedvia\n",
      "clusteringoftrainingdata,whileinopen-endedlearning,thereisno\n",
      "trainingdataavailableatthebeginningofthelearningprocess.Tocopewith\n",
      "thislimitation,weproposethattherobotfreelyexploresseveralscenesandcol-\n",
      "lectsseveralobjectexperiences.Ingeneral,objectexplorationisachallenging\n",
      "taskbecauseofoftheobjects[16].Sinceasystemofbooleanequa-\n",
      "4\n",
      "\n",
      "tionscanrepresentanyexpressionoranyalgorithm,itisparticularlywellsuited\n",
      "forencodingtheworldandobjectcandidates.SimilartoCollet?swork[16],we\n",
      "haveusedbooleanalgebrabasedonthethreelogicaloperators,namelyAND?,\n",
      "OR?andNOT?.Asetofconstraints,C,isthenEachconstrainthas\n",
      "beenimplementedasafunctionthatreturnseithertrueorfalse(seeTable1).\n",
      "3\n",
      "Table1:Listofusedconstraintswithashortdescriptionforeachone.\n",
      "ConstraintsCtable:?isthiscandidateonatable??Ctrack:?isthiscandidate\n",
      "beingtracked??Csize:?isthiscandidatemanipulatable??Cinstructor:?is\n",
      "thiscandidatepartoftheinstructor?sbody??Crobot:?isthiscandidatepart\n",
      "oftherobot?sbody??Cedge:?isthiscandidateneartotheedgeofthetable??\n",
      "Ckey\n",
      "view:?isthiscandidateakeyview??\n",
      "DescriptionTheinterestobjectcandidateisplacedontopofatable.This\n",
      "constraintisusedtoinferthatthesegmentedobjectisalreadybeingtracked\n",
      "ornot.Rejectlargeobjectcandidate.Rejectcandidatesthatarebelongtothe\n",
      "user?sbody.Rejectcandidatesthatarebelongtotherobot?sbody.Reject\n",
      "candidatesthatareneartotheedgeofthetable.Onlykey-viewsarestored\n",
      "intoPerceptualMemory.\n",
      "Notethat,storingallobjectviewswhiletheobjectisstaticwouldlead\n",
      "tounnecessaryaccumulationofhighlyredundantdata.Therefore,Ckey\n",
      "view\n",
      "isusedtooptimizememoryusageandcomputationwhilekeepingpotentially\n",
      "relevantanddistinctiveinformation.Anobjectviewisselectedasakeyview\n",
      "wheneverthetrackingofanobjectisinitialized(Ctrack),orwhenitbecomes\n",
      "staticagainafterbeingmoved.Incasethehandsaredetectedneartheobject,\n",
      "storingkeyviewsarepostponeduntilthehandsarewithdrawn[17].Usingthese\n",
      "constraints,booleanexpressions,?,arebuilttoencodeobjectcandidatesforthe\n",
      "ObjectExplorationandObjectRecognitionpurposes(seeequations1and2).\n",
      "?exploration=Ctable?Ctrack?Ckey\n",
      "view??(Cinstructor?Crobot),\n",
      "(1)\n",
      "?recognition=Ctable?Ctrack??(Cinstructor?Crobot?Cedge),\n",
      "(2)\n",
      "Thebasicperceptioninfrastructure,whichisstronglybasedonthePoint\n",
      "CloudLibrary(PCL),hasbeendescribedindetailinpreviouspublications\n",
      "[18][19].Atableisdetectedbythedominantplaneinthepointcloud.\n",
      "ThisisdoneusingtheRANSACalgorithm.Theextractionofpolygonalprisms\n",
      "mechanismisusedforcollectingthepointswhichliedirectlyabovethetable.\n",
      "Afterwards,anEuclideanClusterExtractionalgorithmisusedtosegmenteach\n",
      "sceneintoindividualclusters.Everyclusterthattheexplorationex-\n",
      "pressionisselected.Theoutputofthisobjectexplorationisapoolofobject\n",
      "candidates.Subsequently,toconstructapooloffeatures,spin-images[3]are\n",
      "computedfortheselectedpointsextractedfromthepoolofobjectcandidates.\n",
      "Wecomputedaround32000spin-imagesfromthepointcloudofthe194objects\n",
      "views.Finally,thedictionaryisconstructedbyclusteringthefeaturesusingthe\n",
      "k-meansalgorithm.ThecentersoftheVextractedclustersareusedasvisual\n",
      "words,wt(1?t?V).Avideooftherobotexploringanenvironment1is\n",
      "availableat:https://youtu.be/MwX3J6aoAX0.\n",
      "5\n",
      "\n",
      "5\n",
      "Objectrepresentation\n",
      "Ahierarchicalsystemispresentedwhichfollowstheorganizationofthevi-\n",
      "sualcortexandbuildsanincreasinglycomplexobjectrepresentation.Plasticity\n",
      "andlearningcanoccurratalllayersandcertainlyatthetop-mostlayersof\n",
      "thehierarchy.Inthispaper,objectviewrepresentationinthefeaturelayer\n",
      "involvestwomainphases:keypointextractionandcomputationofspinimages\n",
      "forthekeypoints.Forkeypointextraction,avoxelizedgridapproachisused\n",
      "toobtainasmallersetofpointsbytakingonlythenearestneighborpointfor\n",
      "eachvoxelcenter.Afterwards,thespin-imagedescriptorisusedtoencodethe\n",
      "surroundingshapeineachkeypointusingtheoriginalpointcloud(i.e.feature\n",
      "layer).Subsequently,thespinimagesgo?up?totheBoWlayerwhereeach\n",
      "spinimageisassignedtoavisualwordbysearchingforthenearestneighborin\n",
      "thedictionary.Afterwards,eachobjectisrepresentedasasetofvisualwords.\n",
      "Theobtainedrepresentationisthenpresentedasinputtothetopiclayer.The\n",
      "LDAmodelconsistsofthreelevels?parametersincludingcategory-levelparam-\n",
      "eters(i.e.?),whicharesampledonceintheprocessofgeneratingacategory\n",
      "ofobjects;object-levelvariables(i.e.?d),whicharesampledonceperobject,\n",
      "andword-levelvariables(i.e.zd,nandwd,n),whicharesampledeverytimea\n",
      "featureisextracted.Thevariables?,?andzarelatentvariablesthatshould\n",
      "beinferred.Assumeeverythingisobservedandacategorylabelisselectedfor\n",
      "eachobject;i.e.eachobjectbelongstoonecategory.Thejointdistributionof\n",
      "allhiddenandobservedvariablesforacategoryisasfollows:p(c)(w,\n",
      "z,?,?|?,?)=\n",
      "KYz=1\n",
      "p(c)(?z|?)\n",
      "|c|Y\n",
      "p(c)(?d|?)\n",
      "NY\n",
      "p(c)(zd,n|?d)p(c)(wd,n|zd,n,?),\n",
      "(3)\n",
      "n=1\n",
      "d=1\n",
      "1\n",
      "TheROSbagusedinthisvideowascreatedbytheKnowledge-Based\n",
      "SystemsGroup,InstituteofComputerScience,UniversityofOsnabrueck.\n",
      "4\n",
      "where?and?areDirichletpriorhyper-parametersthatthesparsity\n",
      "ofdistributions,andKisthenumberoftopics,|c|isthenumberofknown\n",
      "objectsinthecategorycandNisthenumberofwordsintheobjectd.Each\n",
      "?drepresentsaninstanceofcategorycintopic-spaceasaCartesianhistogram\n",
      "(i.e.topiclayer),wrepresentsanobjectasavectorofvisualwords,w=\n",
      "f\n",
      "w1,\n",
      "w2,...,wN\n",
      "g\n",
      ",whereeachentryrepresentsoneoftheVwordsofthedictionary\n",
      "(i.e.BoWlayer).zisavectoroftopicsandzi=1meanswiwasgeneratedform\n",
      "ithtopic.Itshouldbenoticedthatthereisatopicforeachwordand?isaK?\n",
      "Vmatrix,whichrepresentsword-probabilitymatrixforeachtopic,whereVis\n",
      "6\n",
      "\n",
      "thesizeofdictionaryand?i,j=p(c)(wi|zj);thus,theposteriordistributions\n",
      "ofthelatentvariablesgiventheobserveddataiscomputedasfollows:p(c)(z,\n",
      "?,?|w,?,?)=\n",
      "p(c)(w,z,?,?|?,?),p(c)(w|?,?)\n",
      "(4)\n",
      "Unfortunately,thedenominatoroftheequation4isintractableandcannot\n",
      "becomputedexactly.AcollapsedGibbssamplerisusedtosolvetheinference\n",
      "problem.Since?and?canbederivedfromzi,theyareintegratedoutfromthe\n",
      "samplingprocedure.Inthiswork,foreachcategoryanincrementalLDAmodel\n",
      "iscreated.Wheneveranewtraininginstanceispresented,thecollapsedGibbs\n",
      "samplingisemployedtoupdatetheparametersofthemodel.Thecollapsed\n",
      "Gibbssamplerisusedtoestimatetheprobabilityoftopiczibeingassignedto\n",
      "awordwi,givenallothertopicsassignedtoallotherwords:p(c)(zi=k|z?i\n",
      ",w)?p(c)(zi=k|z?i)?p(c)(wi|z?i,w?i)(c)\n",
      "nw,k,?i+??PK,?PV(c)[k=1nd,k+?]?1w=1nw,k+?nd,k,?i+?\n",
      "(5)\n",
      "wherez?imeansallhiddenvariablesexpectziandz=\n",
      "f\n",
      "zi,z?i\n",
      "g\n",
      ".nd,kis\n",
      "thenumberoftimestopic(c)kisassignedtosomevisualwordinobjectdand\n",
      "nw,kshowsthenumberoftimesvisualwordwassignedtotopick.Inaddition,\n",
      "thedenominatorofthep(c)(zi=k|z?i)isomittedbecauseitdoesnotdepend\n",
      "onzi.Themultinomialparametersets?(c)and?(c)canbeestimatedusing\n",
      "thefollowing(c)equations:nw,k+?nd,k+?(c)(c)?k,d=.(6),and?w,k\n",
      "=(c)nd+K?nk+V?(c)\n",
      "wherenkisthenumberoftimesawordassignedtotopickincategoryc\n",
      "andndisthenumberofwordsexistintheobjectd.Sinceinthisapproach,\n",
      "whathappensnextdependsonlyonthecurrent(c)stateofthesystemandnot\n",
      "onthesequenceofpreviousstates,wheneveranewobjectview,?d,is(c)(c)\n",
      "addedtothecategoryc,nkandnw,kareupdatedincrementally.\n",
      "6\n",
      "Objectcategorylearningandrecognition\n",
      "Wheneveranewobjectviewisaddedtoacategory[17],theobjectcon-\n",
      "ceptualizerretrievesthecurrentmodelofthecategoryaswellasrepresentation\n",
      "ofthenewobjectview,andcreatesanew,orupdatestheexistingcategory.\n",
      "Toexemplifythestrengthofobjectrepresentation,aninstance-basedlearning\n",
      "approachisusedinthecurrentsystem,i.e.objectcategoriesarerepresented\n",
      "bysetsofknowninstances.Theinstance-basedapproachisusedbecauseitis\n",
      "abaselinemethodforcategoryrepresentation.However,moreadvancedap-\n",
      "proacheslikeBayesianapproachcanbeeasilyadapted.Anadvantageofthe\n",
      "instancebasedapproachistofacilitateincrementallearninginanopen-ended\n",
      "fashion.Similarly,abaselinerecognitionmechanismintheformofanearest\n",
      "neighbourclasserwithasimplethresholdingapproachareusedtorecognize\n",
      "agivenobjectview.(c)\n",
      "Thequeryobjectview,Oq,isrepresentedusingthetopicdistribu-\n",
      "tionofeachcategory,?q.Afterwards,toassessthedissimilaritybetweenthe\n",
      "queryobjectandstoredinstancesofcategoryc,(c)?p,thesymmetricKull-\n",
      "backLeiblerdivergence,i.e.DKL(?q,?p),isusedtomeasurethe\n",
      "7\n",
      "\n",
      "betweentwodistributions.Subsequently,theminimumdistancebetweenthe\n",
      "queryobjectandallinstancesofthecategoryc,isconsideredastheObject-\n",
      "CategoryDistance,OCD(.):OCD(?q(c),c)=minDKL(?q(c),?p),c?\n",
      "f\n",
      "1,\n",
      "...,C\n",
      "g\n",
      ".?p?c\n",
      "5\n",
      "(7)\n",
      "Consequently,thequeryobjectisbasedontheminimumOCD(.).\n",
      "If,forallcategories,theOCD(.)islargerthanagivenThreshold\n",
      "(e.g.CT=0.75),thentheobjectisasunknown;otherwise,itis\n",
      "asthecategorythathasthehighestsimilarity.\n",
      "7\n",
      "Experimentalresults\n",
      "Theproposedapproachwasevaluatedusingastandardcross-validationpro-\n",
      "tocolaswellasanopen-endedprotocol.Wealsoreportonademonstrationof\n",
      "thesystem.7.1evaluationAnobjectdatasethasbeenused[18],which\n",
      "contains339viewsof10categoriesofobjects.Thesystemhaset\n",
      "parametersthatmustbewellselectedtoprovideagoodbalancebetweenrecog-\n",
      "nitionperformanceandmemoryusage.Toexaminetheperformanceoft\n",
      "oftheproposedapproach,10-foldcross-validationhasbeenused.\n",
      "Atotalof180experimentswereperformedfortvaluesofeparame-\n",
      "tersofthesystem,namelythevoxelsize(VS),whichdeterminesthenumberof\n",
      "keypointsextractedfromeachobjectview,theimagewidth(IW)andsupport\n",
      "length(SL)ofspinimages,thedictionarysize(DS)andthenumberoftopics\n",
      "(NT).ResultsarepresentedinTable2.Theparametersthatobtainedthebest\n",
      "averageaccuracywasselectedasthedefaultVS=0.03,IW=4\n",
      "andSL=0.05,DS=90andNT=30.Inallexperiments,thenumberofiterations\n",
      "forGibbssamplingwas30and?and?parametersweresetto1and0.1re-\n",
      "spectively.Theaccuracyoftheproposedsystemwiththedefault\n",
      "was0.87.Therefore,thisrationdisplaysagoodbalancebetweenrecog-\n",
      "nitionperformanceandmemoryusage.Theremainingresultswereobtained\n",
      "usingthisTheaccuracyofthesystemineachlayerhasbeen\n",
      "Table3:Objectrecognitionperformancecalculatedindividually.Forcompari-\n",
      "son,theaccuRepresentationAccuracyracyofatopiclayerwithtopicsshared\n",
      "amongallFeatureLayer0.12categoriesisalsocomputed.Resultsarepresented\n",
      "BoWLayer0.79TopicLayer(sharedtopics)0.79inTable3.Oneimportant\n",
      "observationisthattheTopicLayer(ourapproach)0.87overallperformanceof\n",
      "therecognitionsystembasedontopicmodellingispromisingandtheproposed\n",
      "representationiscapableofprovidingdistinctiverepresentationforthegiven\n",
      "object.Moreover,itwasobservedthatthediscriminativepowerofthepro-\n",
      "posedrepresentationwasbetterthantheotherlayers.Inaddition,independent\n",
      "topicsforeachcategoryprovidesbetterrepresentationthansharedtopicsforall\n",
      "categories.Furthermore,ithasbeenobservedthatthediscriminativepowerof\n",
      "sharedtopicsdependsontheorderofintroductionofcategories.Theaccuracy\n",
      "ofobjectrecognitionbasedonpureshapefeatures(i.e.featurelayer)isvery\n",
      "low.TheBoWrepresentationobtainsanacceptableperformance.Thetopic\n",
      "layerprovidesagoodbalancebetweenmemoryusageanddescriptivenesswith\n",
      "8\n",
      "\n",
      "30(i.e.NT=30).ThelengthoftheBoWlayerisaroundthreetimeslarger\n",
      "thantherepresentationofthetopiclayer.Thefeaturelayeristhelesscompact\n",
      "representation.Theseresultsshowthehierarchicalobjectrepresentationbuilds\n",
      "anincreasinglycomplexrepresentation.7.2\n",
      "Open-endedevaluation\n",
      "Theevaluationmethodologies(e.gk-foldcrossvalidation,etc.)are\n",
      "notwellsuitedtoevaluateopen-endedlearningsystems,becausetheydonot\n",
      "abidetothesimultaneousnatureoflearningandrecognition.Thosemethodolo-\n",
      "giesimplythatthesetofcategoriesmustbeAnevaluationprotocol\n",
      "foropen-endedlearningsystemswasproposedin[20].Theideaistoemulate\n",
      "theinteractionsofarecognitionsystemwiththesurroundingenvironmentover\n",
      "longperiodsoftime.Asimulatedteacherwasdevelopedtofollowtheeval-\n",
      "uationprotocolandautonomouslyinteractwiththerecognitionsystemusing\n",
      "threebasicactionsincluding:teach,forteachinganewobjectcategory;ask,to\n",
      "askthesystemwhatisthecategoryofanobjectview;andcorrect,forproviding\n",
      "Table2:ObjectrecognitionperformancefortparametersParameters\n",
      "ValuesAvg.Accuracy(%)\n",
      "VS(m)0.030.048581\n",
      "IW(bins)488383\n",
      "0.0482\n",
      "SL(m)0.050.068383\n",
      "6\n",
      "5082\n",
      "DS(visualwords)6070809082838484\n",
      "3084\n",
      "NT4083\n",
      "5082\n",
      "1.2\n",
      "Exp3\n",
      "Accuracy\n",
      "1\n",
      "0.8\n",
      "0.6\n",
      "camerahand-towelplatewater-bottleonionbag-foodpotato0.2staplernote-\n",
      "bookcapcell-phonepitchercalculator00.4\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "jar-foodbell-pepper\n",
      "shampooscissorsinstant-noodles100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "9\n",
      "\n",
      "200\n",
      "Iterations\n",
      "Figure2:Evolutionofaccuracyvs.numberofquestion/correctioniterations\n",
      "inthe200iterationsofthethirdexperiment.Verticalredlinesandlabels\n",
      "indicatewhenandwhichcategoriesareintroducedtothesystem.\n",
      "correctivefeedback,i.e.thegroundtruthlabelofamisclassedobjectview.\n",
      "Theideaisthat,foreachnewlytaughtcategory,thesimulatedteacherrepeat-\n",
      "edlypicksunseenobjectviewsofthecurrentlyknowncategoriesfromadataset\n",
      "andpresentsthemtothesystem.Itprogressivelyestimatestherecognition\n",
      "accuracyofthesystemand,incasethisaccuracyexceedsagiventhreshold\n",
      "(markedbythehorizontallineinFig.2),introducesanadditionalobjectcate-\n",
      "gory(markedbytheverticallinesandlabelsinFig.2).Thisway,thesystem\n",
      "istrained,andatthesametimetheaccuracyofthesystemiscontinuously\n",
      "estimated.Thesimulatedteachermustbeconnectedtoanobjectdataset.In\n",
      "thiswork,thesimulatedteacherwasconnectedtothelargestavailabledataset\n",
      "namelyRGB-DObjectDatasetconsistingof250,000viewsof300common\n",
      "householdobjects,organizedinto51categories[21].\n",
      "Numberoflearnedcategories\n",
      "Globalaccuracy\n",
      "Table4:Summaryofexperiments.SincetheperformanceofanopenEXP#\n",
      "#QCI#TLC#AICGCA(%)APA(%)endedlearningsystemisnotlimited\n",
      "117403918.386571totheobjectrecognitionaccuracy,28033011.076979\n",
      "whenanexperimentiscarriedout,310993513.206777learningperformance\n",
      "isevaluatedus415183816.296673ingthreedistinctmeasures,includ51579\n",
      "4215.126772ing:(i)thenumberoflearnedcategoriesattheendofanex-\n",
      "periment(TLC),anindicatorofHowmuchdoesitlearn?;(ii)Thenumberof\n",
      "question/correctioniterations(QCI)requiredtolearnthosecategoriesandthe\n",
      "averagenumberofstoredinstancespercategory(AIC),indicatorsofHowfast\n",
      "doesitlearn?(seeFig.3(right));(iii)Globalaccuracy(GCA),\n",
      "anaccuracycomputedusingallpredictionsinacompleteexperiment,andthe\n",
      "averageprotocolaccuracy(APA),indicatorsofHowwelldoesitlearn?(see\n",
      "Fig.3(left)).Sincetheorderofthecategoriesintroducedmayhavean\n",
      "ontheperformanceofthesystem,eexperimentswerecarriedoutinwhich\n",
      "categorieswereintroducedinrandomsequences.ResultsarereportedinTable\n",
      "4.Figure2showstheperformanceofthesystemintheinitial200iterations\n",
      "ofthethirdexperiment.Bycomparingallexperiments,itisvisiblethatinthe\n",
      "experiment,thesystemlearnedmorecategoriesthanotherexperiments.\n",
      "Figure3(left)showstheglobalaccuracyobtainedbytheproposed\n",
      "approachasafunctionofthenumberoflearnedcategories.Inexperiments1,\n",
      "4,5,theaccuracydecreases,andthenstartsslightlygoingupagainas\n",
      "morecategoriesareintroduced.Thisisexpectedsincethenumberofcategories\n",
      "knownbythesystemmakesthetaskmoreHowever,as\n",
      "thenumberoflearnedcategoriesincreases,alsothenumberofinstancesper\n",
      "categoryincreases,whichaugmentsthecategorymodels(topics)andtherefore\n",
      "improvesperformanceofthesystem.Fig.3(right)givesameasureofhowfast\n",
      "thelearningoccurredineachoftheexperimentsandshowsthenumberofques-\n",
      "10\n",
      "\n",
      "tion/correctioniterationsrequiredtolearnacertainnumberofcategories.Our\n",
      "approachlearnedfasterthanthatofSchwarzet.al[14]approach,i.e.our\n",
      "approachrequiresmuchlessexamplesthanSchwarz?swork.Furthermore,we\n",
      "achievedaccuracyaround75%whilestoringlessthan20instancespercategory\n",
      "(seeTable4),whileSchwarzet.al[14]storedmorethan1000traininginstances\n",
      "percategory(seeFig.8in[14]).Inaddition,theyclearlyshowedtheperfor-\n",
      "manceofDNNdegradeswhenthesizeofdatasetisreduced.Exp1Exp2Exp3\n",
      "Exp4Exp5\n",
      "1\n",
      "0.9\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "0.5\n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "45\n",
      "Exp2Exp3\n",
      "35\n",
      "Exp430\n",
      "Exp5\n",
      "174025\n",
      "157920\n",
      "151815\n",
      "109910\n",
      "80350\n",
      "Numberoflearnedcategories\n",
      "Exp1\n",
      "40\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "11\n",
      "\n",
      "1800\n",
      "Iterations\n",
      "Figure3:Systemperformanceduringsimulateduserexperiments.\n",
      "7\n",
      "(a)(b)(c)Figure4:Threesnapshotsshowingobjectrecognitionresults\n",
      "intwoscenarios:twosnapshotsshowtheproposedsystemsupports(a)\n",
      "classicallearningfromabatchoftrainlabelleddataand(b)open-endedlearning\n",
      "fromon-lineexperiences.Snapshot(c)showsobjectrecognitionresultsona\n",
      "sceneofWashingtonscenedataset.\n",
      "7.3\n",
      "Systemdemonstration\n",
      "Toshowthestrengthofobjectrepresentation,arealdemonstrationwas\n",
      "performed,inwhichtheproposedapproachhasbeenintegratedintheobject\n",
      "perceptionsystempresentedin[18].Inthisdemonstrationatableisinfrontofa\n",
      "robotandtwousersinteractwiththesystem.Initially,thesystemonlyhadprior\n",
      "knowledgeabouttheVaseandDishcategories,learnedfrombatchdata(i.e.\n",
      "setofobservationswithgroundtruthlabels),andthereisnoinformationabout\n",
      "othercategories(i.e.Mug,Bottle,Spoon).Throughoutthissession,thesystem\n",
      "mustbeabletorecognizeinstancesoflearnedcategoriesandincrementally\n",
      "learnnewobjectcategories.Figure4illustratesthebehaviourofthesystem:\n",
      "(a)TheinstructorputsobjectTID6(aMug)onthetable.Itisas\n",
      "Unknownbecausemugsarenotknowntothesystem;InstructorlabelsTID6as\n",
      "aMug.ThesystemconceptualizesMugandTID6iscorrectlyrecognized.The\n",
      "instructorplacesaVaseonthetable.ThesystemhaslearnedVasecategoryfrom\n",
      "batchdata,therefore,theVaseisproperlyrecognized(Fig.4(a)).(b)Later,\n",
      "anotherMugisplacedonthetable.ThisparticularMughadnotbeenpreviously\n",
      "seen,butthesystemcanrecognizeit,becausetheMugcategorywaspreviously\n",
      "taught(Fig.4(b)).Thisdemonstrationshowsthatthesystemiscapableof\n",
      "usingpriorknowledgetorecognizenewobjectsinthesceneandlearnaboutnew\n",
      "objectcategoriesinanopen-endedfashion.Avideoofthisdemonstrationis\n",
      "availableat:https://youtu.be/J0QOc\n",
      "Ifde4.Anotherdemonstrationhasbeen\n",
      "performedusingWashingtonRGB-DScenesDatasetv2.Thisdatasetconsists\n",
      "of14scenescontainingasubsetoftheobjectsintheRGB-DObjectDataset,\n",
      "includingbowls,caps,mugs,andsodacansandcerealboxes.Initially,the\n",
      "systemhadnopriorknowledge.Thefourobjectsareintroducedtothe\n",
      "systemusingthesceneandthesystemconceptualizesthosecategories.The\n",
      "systemisthentestedusingthesecondsceneofthedatasetanditcanrecognize\n",
      "allobjectsexceptcerealboxes,becausethiscategorywasnotpreviouslytaught.\n",
      "Theinstructorprovidedcorrectivefeedbackandthesystemconceptualizedthe\n",
      "cerealboxescategory.Afterwards,allobjectsarecorrectlyinall12\n",
      "remainingscenes(Fig.4(c)).Thisevaluationillustratestheprocessofacquiring\n",
      "categoriesinanopen-endedfashion.Avideoofthisdemonstrationisonlineat:\n",
      "https://youtu.be/pe29DYNolBE.\n",
      "8\n",
      "Conclusion\n",
      "12\n",
      "\n",
      "Thispaperpresentedamulti-layeredobjectrepresentationtoenhanceacon-\n",
      "current3Dobjectcategorylearningandrecognition.Inthiswork,foroptimizing\n",
      "therecognitionprocessandmemoryusage,eachobjectviewwashierarchically\n",
      "describedasarandommixtureoverasetoflatenttopics,andeachtopicwas\n",
      "asadiscretedistributionovervisualwords.Thispaperfocusedindetail\n",
      "onunsupervisedobjectexplorationtoconstructadictionaryandconcentrated\n",
      "onsupervisedopen-endedobjectcategorylearningusinganextensionoftopic\n",
      "modelling.Wetransformobjectsfrombag-ofwordsspaceintoalocalsemantic\n",
      "spaceanduseddistributionoverdistributionrepresentationforprovidingpow-\n",
      "erfulrepresentationanddealwiththesemanticgapbetweenlow-levelfeatures\n",
      "andhigh-levelconcepts.Resultsshowedthattheproposedsystemsupports\n",
      "classicallearningfromabatchoftrainlabelleddataandopen-endedlearning\n",
      "fromactualexperiencesofarobot.\n",
      "AcknowledgementsThisworkwasfundedbyNationalFundsthroughFCT\n",
      "projectPEst-OE/EEI/UI0127/2016andFCTscholarshipSFRH/BD/94183/2013.\n",
      "8\n",
      "2References\n",
      "[1]SungmoonJeongandMinhoLee.Adaptiveobjectrecognitionmodelus-\n",
      "ingincrementalfeaturerepresentationandhierarchicalNeural\n",
      "Networks,25:130?140,2012.[2]MaximilianRiesenhuberandTomasoPog-\n",
      "gio.Hierarchicalmodelsofobjectrecognitionincortex.Natureneuroscience,\n",
      "2(11):1019?1025,1999.[3]AE.JohnsonandM.Hebert.Usingspinimagesfor\n",
      "tobjectrecognitionincluttered3Dscenes.PatternAnalysisandMa-\n",
      "chineIntelligence,IEEETransactionson,21(5):433?449,May1999.[4]Josef\n",
      "Sivic,BryanCRussell,AlexeiEfros,AndrewZisserman,WilliamTFreeman,et\n",
      "al.Discoveringobjectsandtheirlocationinimages.InComputerVision,2005.\n",
      "ICCV2005.TenthIEEEInternationalConferenceon,volume1,pages370?377.\n",
      "IEEE,2005.[5]ThomasHofmann.Probabilisticlatentsemanticindexing.In\n",
      "Proceedingsofthe22ndannualinternationalACMSIGIRconferenceonRe-\n",
      "searchanddevelopmentininformationretrieval,pages50?57.ACM,1999.[6]\n",
      "DavidMBlei,AndrewYNg,andMichaelIJordan.Latentdirichletalloca-\n",
      "tion.theJournalofmachineLearningresearch,3:993?1022,2003.[7]JonD\n",
      "andDavidMBlei.Supervisedtopicmodels.InAdvancesinneural\n",
      "informationprocessingsystems,pages121?128,2008.[8]ChongWang,David\n",
      "Blei,andFei-FeiLi.Simultaneousimageandannotation.InCom-\n",
      "puterVisionandPatternRecognition,2009.CVPR2009.IEEEConferenceon,\n",
      "pages1903?1910.IEEE,2009.[9]LiFei-FeiandPietroPerona.Abayesianhi-\n",
      "erarchicalmodelforlearningnaturalscenecategories.InComputerVisionand\n",
      "PatternRecognition,2005.CVPR2005.IEEEComputerSocietyConference\n",
      "on,volume2,pages524?531.IEEE,2005.[10]DanielRamage,DavidHall,\n",
      "RameshNallapati,andChristopherDManning.Labeledlda:Asupervised\n",
      "topicmodelforcreditattributioninmulti-labeledcorpora.InProceedingsof\n",
      "the2009ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:\n",
      "13\n",
      "\n",
      "Volume1-Volume1,pages248?256,2009.[11]YangWang,PayamSabzmey-\n",
      "dani,andGregMori.Semi-latentdirichletallocation:Ahierarchicalmodelfor\n",
      "humanactionrecognition.InHumanMotion?Understanding,Modeling,Cap-\n",
      "tureandAnimation,pages240?254.Springer,2007.[12]ArindamBanerjee\n",
      "andSugatoBasu.Topicmodelsovertextstreams:Astudyofbatchandonline\n",
      "unsupervisedlearning.InSDM,volume7,pages437?442.SIAM,2007.[13]\n",
      "KevinRCanini,LeiShi,andThomasLOnlineinferenceoftopicswith\n",
      "latentdirichletallocation.InInternationalconferenceoncialintelligence\n",
      "andstatistics,pages65?72,2009.[14]MaxSchwarz,HannesSchulz,andSven\n",
      "Behnke.RGB-Dobjectrecognitionandposeestimationbasedonpre-trained\n",
      "convolutionalneuralnetworkfeatures.InRoboticsandAutomation(ICRA),\n",
      "2015IEEEInternationalConferenceon,pages1329?1335.IEEE,2015.[15]\n",
      "JiyeGKim,IrvingBiederman,MarkDLescroart,andKennethJHayworth.\n",
      "Adaptationtoobjectsinthelateraloccipitalcomplex(loc):shapeorsemantics?\n",
      "Visionresearch,49(18):2297?2305,2009.[16]AlvaroCollet,BoXiong,Corina\n",
      "Gurau,MartialHebert,andSiddharthaSSrinivasa.Herbdisc:Towardslife-\n",
      "longroboticobjectdiscovery.TheInternationalJournalofRoboticsResearch,\n",
      "34(1):3?25,2015.[17]GiHyunLim,M.Oliveira,V.Mokhtari,S.Hamidreza\n",
      "Kasaei,A.Chauhan,L.SeabraLopes,andA.M.Tome.Interactiveteaching\n",
      "andexperienceextractionforlearningaboutobjectsandrobotactivities.In\n",
      "RobotandHumanInteractiveCommunication,The23rdIEEEInternational\n",
      "Symposiumon,2014.[18]SHamidrezaKasaei,MiguelOliveira,GiHyunLim,\n",
      "Lu?sSeabraLopes,andAnaMariaTom?.Interactiveopen-endedlearningfor\n",
      "3dobjectrecognition:Anapproachandexperiments.JournalofIntelligent&\n",
      "RoboticSystems,80(3):537?553,2015.[19]MiguelOliveira,Lu?sSeabraLopes,\n",
      "GiHyunLim,S.HamidrezaKasaei,AnaMariaTom?,andAneeshChauhan.\n",
      "3DobjectperceptionandperceptuallearningintheRACEproject.Robotics\n",
      "andAutonomousSystems,75,PartB:614?626,2016.[20]AneeshChauhan\n",
      "andLu?sSeabraLopes.Usingspokenwordstoguideopen-endedcategoryfor-\n",
      "mation.Cognitiveprocessing,12(4):341?354,2011.[21]K.Lai,LiefengBo,\n",
      "XiaofengRen,andD.Fox.Alarge-scalehierarchicalmulti-viewRGB-Dob-\n",
      "jectdataset.InRoboticsandAutomation(ICRA),2011IEEEInternational\n",
      "Conferenceon,pages1817?1824,2011.\n",
      "9\n",
      "14\n",
      "\n",
      "PP4448.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP4448.pdf 14\n",
      "AcceleratedAdaptiveMarkovChainforPartition\n",
      "FunctionComputation\n",
      "Authoredby:\n",
      "CarlaP.Gomes\n",
      "AshishSabharwal\n",
      "BartSelman\n",
      "StefanoErmon\n",
      "Abstract\n",
      "WeproposeanovelAdaptiveMarkovChainMonteCarloalgorithmto\n",
      "computethepartitionfunction.Inparticular,weshowhowtoaccelerate\n",
      "ahistogramsamplingtechniquebytlyreducingthenumber\n",
      "of\\nullmoves\"inthechain,whilemaintainingasymptoticconvergence\n",
      "properties.Ourexperimentsshowthatourmethodconvergesquickly\n",
      "tohighlyaccuratesolutionsonarangeofbenchmarkinstances,outper-\n",
      "formingotherstate-of-the-artmethodssuchasIJGP,TRW,andGibbs\n",
      "samplingbothinrun-timeandaccuracy.Wealsoshowhowobtaininga\n",
      "so-calleddensityofstatesdistributionallowsfortweightlearning\n",
      "inMarkovLogictheories.\n",
      "1PaperBody\n",
      "Weproposeanovelandgeneralmethodtoapproximatethepartitionfunctionof\n",
      "intricateprobabilitydistributionsovercombinatorialspaces.Computing\n",
      "thepartitionfunctionisanotoriouslyhardcomputationalproblem.Onlyafew\n",
      "tractablecasesareknow.Inparticular,ifthecorrespondinggraphicalmodel\n",
      "haslowtreewidth,thentheproblemcanbesolvedexactlyusingmethodsbased\n",
      "ontreedecompositions,suchasthejunctiontreealgorithm[1].Thepartition\n",
      "functionforplanargraphswithbinaryvariablesandnoexternalcanalso\n",
      "becomputedinpolynomialtime[2].WewillconsideranadaptiveMCMC\n",
      "samplingstrategy,inspiredbytheWang-Landaumethod[3],whichisaso-called\n",
      "histogramsamplingstrategyfromstatisticalphysics.Givenacombinatorial\n",
      "spaceandanenergyfunction(forinstance,describingthenegativelog-likelihood\n",
      "ofeachahistogrammethodisasamplingstrategybasedon\n",
      "aMarkovChainthatconvergestoasteadystatewhereitspendsapproximately\n",
      "thesameamountoftimeinstateswithalowdensityof(which\n",
      "areusuallylowenergystates)asinstateswithahighdensity.Wepropose\n",
      "1\n",
      "\n",
      "twokeyimprovementstotheWang-Landaumethod,namelyenergysaturation\n",
      "andafocused-randomwalkcomponent,leadingtoanewandmoret\n",
      "algorithmcalledFocusedFlatSAT.Energysaturationallowsthechaintovisit\n",
      "fewerenergylevels,andtherandomwalkstylemovesreducethenumberof\n",
      "?nullmoves?intheMarkovchain.Bothimprovementsmaintainthesame\n",
      "globalstationarydistribution,whileallowingustogowellbeyondthedomain\n",
      "ofspinglasseswheretheWang-Landaumethodhasbeentraditionallyapplied.\n",
      "Wedemonstratetheenessofourapproachbyacomparisonwithstate-of-\n",
      "the-artmethodstoapproximatethepartitionfunctionorboundit,suchasTree\n",
      "ReweighedBeliefPropagation[4],IJGPSampleSearch[5],andGibbssampling\n",
      "[6].Ourexperimentsshowthatourapproachoutperformstheseapproachesin\n",
      "avarietyofproblemdomains,bothintermsofaccuracyandrun-time.The\n",
      "densityofstatesservesasarichdescriptionoftheunderlyingprobabilistic\n",
      "model.Oncecomputed,itcanbeusedtotlyevaluatethepartition\n",
      "functionforallparametersettingswithout?\n",
      "SupportedbyNSFExpeditionsinComputingawardforComputationalSus-\n",
      "tainability(grant0832782).\n",
      "1\n",
      "theneedforfurtherinferencesteps?astarkcontrastwithcompetingmeth-\n",
      "odsforpartitionfunctioncomputation.Forinstance,instatisticalphysicsap-\n",
      "plications,wecanuseittoevaluatethepartitionfunctionZ(T)forallvaluesof\n",
      "thetemperatureT.Thislevelofabstractioncanbeafundamentaladvantage\n",
      "formachinelearningmethods:infact,inalearningproblemwecanparame-\n",
      "terizeZ(?)accordingtothemodelparametersthatwewanttolearnfromthe\n",
      "trainingdata.Forexample,inthecaseofaMarkovLogictheory[7,8]with\n",
      "weightsw1,...,wKofitsKorderformulas,wecanparameterizethe\n",
      "partitionfunctionasZ(w1,...,wK).Uponanappropriateenergy\n",
      "functionandobtainingthecorrespondingdensityofstates,wecanthenuseef-\n",
      "tevaluationsofthepartitionfunctiontosearchformodelparametersthat\n",
      "bestthetrainingdata,thusobtainingapromisingnewapproachtolearning\n",
      "inMarkovLogicNetworksandgraphicalmodels.\n",
      "2\n",
      "Probabilisticmodelandthepartitionfunction\n",
      "Wefocusonintricateprobabilitydistributionsedoverasetof\n",
      "urations,i.e.,assignmentstoasetofNdiscretevariables\n",
      "f\n",
      "x1,...,xN\n",
      "g\n",
      ",\n",
      "assumedheretobeBooleanforsimplicity.Theprobabilitydistributionisspec-\n",
      "throughasetofcombinatorialfeaturesorconstraintsoverthesevariables.\n",
      "Suchconstraintscanbeeitherhardorsoft,withthei-thsoftconstraintCibeing\n",
      "associatedwithaweightwi.Let?i(x)=1ifaxviolatesCi,\n",
      "and0otherwise.TheprobabilityPw(x)ofxisas0ifxviolatesany\n",
      "hardconstraint,andas!X1Pw(x)=exp?wi?i(x)Z(w)\n",
      "(1)\n",
      "Ci?Csoft\n",
      "otherwise,whereCsoftisthesetofsoftconstraints.Thepartitionfunction,\n",
      "Z(w),issimplythenormalizationconstantforthisprobabilitydistribution,and\n",
      "isgivenby:!Z(w)=\n",
      "2\n",
      "\n",
      "X\n",
      "exp?\n",
      "X\n",
      "wi?i(x)\n",
      "(2)\n",
      "Ci?Csoft\n",
      "x?Xhard\n",
      "whereXhard?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "Nisthesetofsatisfyingallhardcon-\n",
      "straints.Notethataswi??,thesoftconstraintCictivelybecomesahard\n",
      "constraint.Thisfactoredrepresentationiscloselyrelatedtoagraphicalmodel\n",
      "whereweuseweightedBooleanformulastospecifycliquepotentials.Thisis\n",
      "anaturalframeworkforcombiningpurelylogicalandprobabilisticinference,\n",
      "usedforexampletogroundedMarkovLogicNetworks[8,9].Thepar-\n",
      "titionfunctionisaveryimportantquantitybutcomputingitisawell-known\n",
      "computationalchallenge,whichweproposetoaddressbyemployingthe?den-\n",
      "sityofstates?methodtobediscussedshortly.Wewillcompareourapproach\n",
      "againstseveralstate-of-the-artmethodsavailableforcomputingthepartition\n",
      "functionorobtainingboundsonit.Wainwrightetal.[4],forexample,proposed\n",
      "avariationalmethodknownastreere-weighting(TRW)toobtainboundson\n",
      "thepartitionfunctionofgraphicalmodels.UnlikestandardBeliefPropagation\n",
      "schemeswhicharebasedonBethefreeenergies[10],theTRWapproachusesa\n",
      "tree-reweighted(TRW)freeenergywhichconsistsofalinearcombinationoffree\n",
      "energiesonspanningtreesofthemodel.Usingconvexityargumentsitis\n",
      "thenpossibletoobtainupperboundsonvariousquantities,suchasthepartition\n",
      "function.Basedoniteratedjoin-graphpropagation,IJGP-SampleSearch[5]is\n",
      "apopularsolverfortheprobabilityofevidenceproblem(i.e.,partitionfunction\n",
      "computationwithasubsetof?evidence?variablesforgeneralgraphical\n",
      "models.Thismethodisbasedonanimportancesamplingschemewhichisaug-\n",
      "mentedwithsystematicconstraint-basedbacktrackingsearch.Analternative\n",
      "approachistouseGibbssamplingtoestimatethepartitionfunctionbyesti-\n",
      "mating,usingsampleaverage,asequenceofmultipliersthatcorrespondtothe\n",
      "ratiosofthepartitionfunctionevaluatedatntweightlevels[6].Lastly,\n",
      "thepartitionfunctionforplanargraphswhereallvariablesarebinaryandhave\n",
      "onlypairwiseinteractions(i.e.,thezeroexternalcase)canbecalculated\n",
      "exactlyinpolynomialtime[2].Althoughweareinterestedinalgorithmsforthe\n",
      "general(intractable)case,weusedthesoftwareassociatedwiththisapproach\n",
      "toobtainthegroundtruthforplanargraphsandevaluatetheaccuracyofthe\n",
      "estimatesobtainedbyothermethods.2\n",
      "3\n",
      "Densityofstates\n",
      "Ourapproachforcomputingthepartitionfunctionisbasedonsolvingthe\n",
      "densityofstatesproblem.Givenacombinatorialspacesuchastheone\n",
      "earlierandanenergyfunctionE:\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N?R,thedensityofstates(DOS)\n",
      "nisafunctionn:range(E)?Nthatmapsenergylevelstothenumberof\n",
      "withthatenergy,i.e.,n(k)=|\n",
      "f\n",
      "??\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N|E(?)=k\n",
      "g\n",
      "|.\n",
      "Inourcontext,weareinterestedincomputingthenumberof\n",
      "3\n",
      "\n",
      "thatsatisfycertainpropertiesthatarespusinganappropriateenergy\n",
      "function.Forinstance,wemighttheenergyE(?)ofa?to\n",
      "bethenumberofhardconstraintsthatareviolatedby?.Orwemayusethesum\n",
      "oftheweightsoftheviolatedsoftconstraints.Onceweareabletocompute\n",
      "thefulldensityofstates,i.e.,thenumberofateachpossible\n",
      "energylevel,itisstraightforwardtoevaluatethepartitionfunctionZ(w)for\n",
      "anyweightvectorw,bysumminguptermsoftheformn(i)exp(?E(i)),where\n",
      "E(i)denotestheenergyofeveryinstatei.Thisisthemethod\n",
      "weuseinthisworkforestimatingthepartitionfunction.Morecomplexenergy\n",
      "functionsmaybeforotherrelatedtasks,suchasweightlearning,i.e.,\n",
      "givensometrainingdatax?X=\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N,computingargmaxwPw(x)where\n",
      "Pw(x)isgivenbyEquation(1).HerewecantheenergyE(?)tobew\n",
      "?`,where`=(`1,...,`M)givesthenumberofconstraintsofweightwi\n",
      "violatedby?.Ourfocusintherestofthepaperwillthusbeoncomputingthe\n",
      "densityofstatestly.3.1\n",
      "TheMCMCFlatSATalgorithm\n",
      "MCMCFlatSAT[11]isanAdaptiveMarkovChainMonteCarlo(adaptive\n",
      "MCMC)methodforcomputingthedensityofstatesforcombinatorialproblems,\n",
      "inspiredbytheWang-Landaualgorithm[3]fromstatisticalphysics.Interest-\n",
      "ingly,thisalgorithmdoesnotmakeanyassumptionabouttheformorsemantics\n",
      "oftheenergy.Atleastinprinciple,theonlythingitneedsisapartitioningof\n",
      "thestatespace,wherethe?energy?justprovidesanindexoverthesubsetsthat\n",
      "composethepartition.Thealgorithmisbasedonthehistogramideaand\n",
      "worksbytryingtoconstructareversibleMarkovChainonthespace\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N\n",
      "ofallsuchthatthesteadystateprobabilityofa\n",
      "?isinverselyproportionaltothedensityofstatesn(E(?)).Inthisway,the\n",
      "stationarydistributionissuchthatalltheenergylevelsarevisitedequallyoften\n",
      "(i.e.,whenwecountthevisitstoeachenergylevel,weseeavisithistogram).\n",
      "Sp,weaMarkovChainwiththefollowingtransitionprobability:\n",
      "(p???0=\n",
      "1N\n",
      "non(E(?))min1,n(E(?dH(?,?0)=10))dH(?,?0)>1\n",
      "0\n",
      "(3)\n",
      "0wheredH(?,?0)istheHammingdistancebetweenP?and?.The\n",
      "probabilityofaself-loopp???isgivenbythenormalizationconstraintp???+\n",
      "?0|dH(?,?0)=1p???0=1.ThedetailedbalanceequationP(?)p???0=P\n",
      "(?0)p?0??isbyP(?)?1/n(E(?)).Thismeans1thattheMarkov\n",
      "ChainwillreachastationaryprobabilitydistributionP(regardlessoftheinitial\n",
      "state)suchthattheprobabilityofa?withenergyE=E(?)is\n",
      "inverselyproportionaltothenumberofwithenergyE.PThis\n",
      "leadstoanasymptoticallyhistogramoftheenergies1ofthestatesvisited\n",
      "becauseP(E)=?:E(?)=EP(?)?n(E)n(E)=1(i.e.,independentofE).\n",
      "Sincethedensityofstatesisnotknownapriori,andcomputingitisprecisely\n",
      "thegoalofthealgorithm,itisnotpossibletoconstructdirectlyarandomwalk\n",
      "withtransitionprobability(3).Howeveritispossibletostartwithaninitial\n",
      "4\n",
      "\n",
      "guessg(?)forn(?)andkeepupdatingthisestimateg(?)inasystematic\n",
      "waytoproduceaenergyhistogramandsimultaneouslymaketheestimate\n",
      "g(E)convergetothetruevaluen(E)foreveryenergylevelE.Theestimate\n",
      "isadjustedusingamofactorFwhichcontrolsthebetween\n",
      "theconvergencerateofthealgorithmanditsaccuracy(largeinitialvaluesofF\n",
      "leadtofastconvergencetoaratherinaccuratesolution).Forcompleteness,we\n",
      "providethepseudo-codeasAlgorithm1;see[11]fordetails.1\n",
      "Thechainisirreducible,andaperiodic,thereforeergodic.\n",
      "3\n",
      "Algorithm1MCMCFlatSATalgorithmtocomputethedensityofstates1:\n",
      "2:3:4:5:6:7:8:9:\n",
      "Startwithaguessg(E)=1forallE=1,...,mInitializeH(E)=0\n",
      "forallE=1,...,mStartwithamofactorF=F0=1.5repeat\n",
      "Randomlypicka?repeatGenerateanew?0(by\n",
      "avariable)LetE=E(?)andE0=E(?0)(saturatedoenergies)n\n",
      "Set?=?0withprobabilitymin1,\n",
      "g(E)g(E0)\n",
      "(moveacceptance/rejectionstep)\n",
      "10:LetEc=E(?)bethecurrentenergylevel11:Adjustthedensityg(Ec\n",
      ")=g(Ec)?F12:UpdatevisithistogramH(Ec)=H(Ec)+113:untilH\n",
      "is(all?thevaluesareatleast90%ofthemaximumvalue)14:ReduceF,\n",
      "F?F15:ResetthevisithistogramH16:untilFiscloseenoughPto117:\n",
      "NormalizegsothatEg(E)=2N18:returngasestimateofn\n",
      "4\n",
      "FocusedFlatSAT:ntcomputationofdensityofstates\n",
      "WeproposetwocrucialimprovementstoMCMCFlatSAT,namelyenergy\n",
      "saturationandtheintroductionofafocused-randomwalkcomponent,leading\n",
      "toanewalgorithmcalledFocusedFlatSAT.AswewillseeinTable1,Focused-\n",
      "FlatSATprovidesthesameaccuracyasMCMCFlatSATbutisabout10times\n",
      "fasteronthatbenchmark.Moreover,ourresultsfortheIsingmodel(described\n",
      "below)inFigure2demonstratethatFocusedFlatSATscalesmuchbetter.En-\n",
      "ergysaturation.ThetimeneededforeachiterationofMCMCFlatSATtocon-\n",
      "vergeistlybythenumberoftnon-emptyenergylevels\n",
      "(buckets).Inmanycases,theweightstheprobabilitydistributionPw\n",
      "(x)areallpositive(i.e.,thereisanincentivetosatisfytheconstraints),and\n",
      "asanoftheexponentialdiscountinginEquation(1),that\n",
      "violatealargenumberofconstraintshaveanegligiblecontributiontothesum\n",
      "thepartitionfunctionZ.Wethereforeanewsaturatedenergy\n",
      "functionE0(?)=min\n",
      "f\n",
      "E(?),K\n",
      "g\n",
      ",whereKisaparameter.For\n",
      "thepositiveweightscase,thepartitionfunctionZ0associatedwiththesatu-\n",
      "ratedenergyfunctionisaguaranteedupperboundontheoriginalZ,forany\n",
      "K.Whenallconstraintsarehard,Z0=ZforanyvalueK?1becauseonly\n",
      "theenergybucketmatters.Ingeneral,whensoftconstraintsarepresent,\n",
      "theboundgetstighterasKincreases,andwecanobtaintheoreticalworst-case\n",
      "errorboundswhenKischosentobeapercentileoftheenergydistribution(e.g.,\n",
      "saturationatmedianenergyyieldsa2xbound).Inourexperiments,wesetK\n",
      "5\n",
      "\n",
      "tobetheaveragenumberofconstraintsviolatedbyarandom\n",
      "andwefoundthattheerrorintroducedbythesaturationisnegligiblecompared\n",
      "tootherinherentapproximationsindensityofstatesestimation.Intuitively,\n",
      "thisisbecausethestateswheretheprobabilityisconcentratedturnoutto\n",
      "typicallyhaveamuchlowerenergythanK,andthusanexponentiallylarger\n",
      "contributiontoZ.Furthermore,energysaturationpreservestheconnectivityof\n",
      "thechain.FocusedRandomWalk.BothintheoriginalWang-Landaumethod\n",
      "andinMCMCFlatSAT,newaregeneratedbyavariable\n",
      "selecteduniformlyatrandom[3,11].Letuscallthisselection\n",
      "distributiontheproposaldistribution,andletT???0denotetheprobabilityof\n",
      "generatinga?0fromthisdistributionwhilein?.IntheWang-\n",
      "Landaualgorithm,proposedationsarethenrejectedwithaprobability\n",
      "thatdependsonthedensityofstatesoftherespectiveenergylevels.Movere-\n",
      "jectionsobviouslylengthenthemixingtimeoftheunderlyingMarkovChain.\n",
      "Weintroducehereanovelproposaldistributionthattlyreducesthe\n",
      "numberofmoverejections,resultinginmuchfasterconvergencerates.Itis\n",
      "inspiredbylocalsearchSATsolvers[12]andisespeciallycriticalfortheclassof\n",
      "highlycombinatorialenergyfunctionsweconsiderinthiswork.Wenotethatif\n",
      "theacceptanceprobabilityistakentobe\n",
      "n(E(?))T?0??min1,n(E(?0))T???04\n",
      "1400000\n",
      "MCMCFlatSAT\n",
      "Numberofmoves\n",
      "Numberofmoves\n",
      "300000025000002000000\n",
      "Acc.up\n",
      "1500000\n",
      "Acc.sameAcc.down\n",
      "1000000\n",
      "Rej.up500000\n",
      "Rej.same\n",
      "0\n",
      "FocusedFlatSAT\n",
      "1000000\n",
      "Acc.up\n",
      "800000\n",
      "Acc.same\n",
      "600000\n",
      "Acc.down\n",
      "400000\n",
      "Rej.upRej.same\n",
      "0\n",
      "Rej.down123456789111133155177199221243265287309331353\n",
      "375\n",
      "200000\n",
      "123456789111133155177199221243265287309331353375\n",
      "6\n",
      "\n",
      "Rej.down\n",
      "1200000\n",
      "Energylevel\n",
      "Energylevel\n",
      "Figure1:Histogramsdepictingthenumberofproposedmovesacceptedand\n",
      "rejected.Left:MCMCFlatSAT.Right:FocusedFlatSAT.SeePDFforcolor\n",
      "version.thepropertiesofthesteadystatedistributionarepreservedaslong\n",
      "astheproposaldistributionissuchthattheergodicitypropertyismaintained.\n",
      "Inordertounderstandthemotivationbehindthenewproposaldistribution,\n",
      "considerthemoveacceptance/rejectionhistogramshownintheleftpanelof\n",
      "Figure1.Fortheinstanceunderconsideration,MCMCFlatSATconvergedto\n",
      "aathistogramafterhavingvisitedeachofthe385energylevels(onx-axis)\n",
      "roughly2.6Mtimes.Eachcoloredregionshowsthecumulativenumberofmoves\n",
      "(ony-axis)acceptedorrejectedfromeachenergylevel(onx-axis)toanother\n",
      "withahigher,equal,orlowerenergylevel,resp.Thisgivessix\n",
      "possiblemovetypes,andthehistogramshowshowofteniseachtakenatany\n",
      "energylevel.Mostimportantly,noticethatatlowenergylevels,avastmajority\n",
      "ofthemoveswereproposedtoahigherenergylevelandwererejectedbythe\n",
      "algorithm(shownasthedominatingpurpleregion).Thisisanindirectconse-\n",
      "quenceofthefactthatinsuchinstances,inthelowenergyregime,thedensity\n",
      "ofstatesincreasesdrasticallyastheenergylevelisincreases,i.e.,g(E0)g(E)\n",
      "whenE0>E.Asaresult,mostoftheproposedmovesaretohigherenergylevels\n",
      "andareinturnrejectedbythealgorithminthemoveacceptance/rejectionstep\n",
      "discussedabove.Inordertoaddressthisissue,weproposetomodifythepro-\n",
      "posaldistributioninawaythatincreasesthechanceofproposingmovestothe\n",
      "sameorlowerenergylevels,despitethefactthattherearerelativelyfewsuch\n",
      "moves.InspiredbylocalsearchSATsolvers,weenhanceMCMCFlatSATwith\n",
      "afocusedrandomwalkcomponentthatgivespreferencetoselectingvariables\n",
      "tofromviolatedconstraints(ifany),therebyintroducinganindirectbias\n",
      "towardslowerenergystates.Sp,ifthegiven?isasatis-\n",
      "fyingassignment,pickavariableuniformlyatrandomtobeed(thusT???0\n",
      "=1/NwhentheHammingdistancedH(?,?0)=1,zerootherwise).If?isnot\n",
      "asolution,thenwithprobabilitypavariabletobeedischosenuniformly\n",
      "atrandomfromarandomlychosenviolatedconstraint,andwithprobability1\n",
      "?pavariableischosenuniformlyatrandom.Withthisapproach,when?is\n",
      "notsolutionand?and?0onlyonthei-thvariable,P1c?C|i?c?c\n",
      "(?)?1/|c|PT???0=(1?p)+pNc?C?c(?)where?c(?)=1?\n",
      "violatesconstraintcand|c|denotesthenumberofvariablesinconstraint\n",
      "c.Withthisproposaldistributionweensurethatforall1>p?0whenever\n",
      "T???0>0,wealsohaveT?0??>0.Moreover,theconnectivityoftheMarkov\n",
      "Chainispreserved(sincewedon?tremoveanyedgefromtheoriginalMarkov\n",
      "Chain).Wethereforehavethefollowingresult:Proposition1Forallp?[0,\n",
      "1),theMarkovChainwithproposaldistributionT???0denedaboveisirre-\n",
      "ducibleandaperiodic.Thereforeithasauniquestationarydistribution,given\n",
      "by1/n(E(?)).TherightpanelofFigure1showsthemoveacceptance/rejection\n",
      "histogramwhenFocusedFlatSATisused,i.e.,withtheaboveproposaldistribu-\n",
      "7\n",
      "\n",
      "tion.Thesameinstancenowneedsunder1.2Mvisitsperenergylevelforthe\n",
      "methodtoconverge.Moreover,thenumberofrejectedmoves(showninpur-\n",
      "pleandgreen)inlowenergystatesistlyfewerthanthedominating\n",
      "purpleregionintheleftpanel.ThisallowstheMarkovChaintomovemore\n",
      "freelyinthespaceandtoconvergefaster.Figure2showsaruntimecomparison\n",
      "ofFocusedFlatSATagainstMCMCFlatSATonn?nIsingmodels(detailsto\n",
      "bediscussedinSection5).Aswesee,incorporatingenergysaturationreduces\n",
      "thetimetoconvergence(whileachievingthesamelevelofaccuracy),andusing\n",
      "focusedrandomwalkmovesfurtherdecreasestheconvergencetime,especially\n",
      "asnincreases.5\n",
      "30000\n",
      "Time(s)\n",
      "25000\n",
      "MCMCFlatSAT\n",
      "20000\n",
      "MCMCFlatSAT+Saturation\n",
      "15000\n",
      "FocusedFlatSAT\n",
      "1000050000\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "Gridsizen\n",
      "Figure2:RuntimecomparisononferromagneticIsingmodelsonsquare\n",
      "latticesofsizen?n.Table1:Comparisonwithmodelcounters;onlyhard\n",
      "constraints.Runtimeisinseconds.Instance\n",
      "2bitmax6ls8-norm\n",
      "5\n",
      "n\n",
      "m\n",
      "2527661505251001501005003011603\n",
      "Exact#\n",
      "FocusedFlatSatModelsTime\n",
      "2.10?10291.91?10291.40?10141.43?10141.80?10211.86?1021\n",
      "9.31?10165.40?10115.78?1011\n",
      "MCMC-FlatSatModelsTime\n",
      "SampleCountModelsTime\n",
      "SampleMiniSATModelsTime\n",
      "1561.96?10291863?2.40?1028292.08?1029201.34?1014393?\n",
      "1.60?10131451.60?101311.83?102121?1.00?10202401.58?10215\n",
      "8.64?1016189?8.00?10151201.09?10172315.93?10112693?3.10?\n",
      "101011402.22?1011\n",
      "345240128191168\n",
      "Experimentalevaluation\n",
      "8\n",
      "\n",
      "WecompareFocusedFlatSATagainstseveralstate-of-the-artmethodsfor\n",
      "computinganestimateoforboundonthepartitionfunction.2Anevaluation\n",
      "suchasthisisinherentlychallengingasthegroundtruthisveryhardtoobtain\n",
      "andcomputationalboundscanbeordersofmagnitudefromthetruth,mak-\n",
      "ingacomparisonofestimatesnotverymeaningful.Wethereforeproposeto\n",
      "evaluatethemethodsoneithersmallinstanceswhosegroundtruthcanbeeval-\n",
      "uatedby?bruteforce,?orlargerinstanceswhosegroundtruth(orboundson\n",
      "it)canbecomputedanalyticallyorthroughothertoolssuchastmodel\n",
      "counters.Wealsoconsiderplanarcasesforwhichaspecializedpolynomialtime\n",
      "exactalgorithmisavailable.tmethodsforhandlinginstancesofsmall\n",
      "treewidtharealsowellknown;herewepushtheboundariestoinstancesofrel-\n",
      "ativelyhighertreewidth.Forpartitionfunctionevaluation,wecompareagainst\n",
      "thetreere-weighting(TRW)variationalmethodforupperbounds,theiterated\n",
      "join-graphpropagation(IJGP),andGibbssampling;seeSection2foravery\n",
      "briefdiscussionoftheseapproaches.Forweightlearning,wecompareagainst\n",
      "theAlchemysystem.Unlessotherwisesptheenergyfunctionusedis\n",
      "alwaysthenumberofviolatedconstraints,andweusea50%ratioofrandom\n",
      "moves(p=0.5).Thealgorithmisrunfor20iterations,withaninitialmod-\n",
      "factorF0=1.5.Theexperimentswereconductedona16-core2.4\n",
      "GHzIntelXeonmachinewith32GBmemory,runningRedHatLinux.Hard\n",
      "constraints.First,considermodelswithonlyhardconstraints,whicha\n",
      "uniformmeasureonthesetofsatisfyingassignments.Inthiscase,theproblem\n",
      "ofcomputingthepartitionfunctionisequivalenttostandardmodelcounting.\n",
      "WecomparetheperformanceofFocusedFlatSATwithMCMC-FlatSatandwith\n",
      "twostate-of-the-artapproximatemodelcounters:SampleCount[13]andSam-\n",
      "pleMiniSATExact[14].Theinstancesusedaretakenfromearlierwork[11].\n",
      "TheresultsinTable1showthatFocusedFlatSATalmostalwaysobtainsmuch\n",
      "moreaccuratesolutioncounts,andisoftentlyfaster(aboutanorder\n",
      "ofmagnitudefasterthanMCMC-FlatSat).SoftConstraints.WeconsiderP\n",
      "IsingModelsonann?nsquarelatticewhereP(?)=P?exp(?E(?))\n",
      "withE(?)=(i,j)wijI[?i6=?j].HereIistheindicatorfunction.Thisimposes\n",
      "apenaltywijifspins?iand?jarenotaligned.Weconsideraferromagnetic\n",
      "casewherewij=w>0foralledges,andafrustratedcasewithamixture\n",
      "ofpositiveandnegativeinteractions.Thepartitionfunctionfortheseplanar\n",
      "modelsiscomputablewithaspecializedpolynomialtimealgorithm,aslongas\n",
      "thereisnoexternalmagnetic[2].InFigure3,wecomparethetruevalue\n",
      "ofthepartitionfunctionZ?withtheestimateobtainedusingFocusedFlatSAT\n",
      "andwiththeupper2\n",
      "Benchmarkinstancesavailableonlineathttp://www.cs.cornell.edu/?ermonste\n",
      "6\n",
      "80\n",
      "300250\n",
      "60\n",
      "Log10(Z)-Log10(Z*)\n",
      "Log10(Z)-Log10(Z*)\n",
      "70\n",
      "9\n",
      "\n",
      "5040\n",
      "FocusedFlatSAT\n",
      "30\n",
      "TRW\n",
      "2010\n",
      "200150FocusedFlatSAT\n",
      "100\n",
      "TRW500\n",
      "00\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "-50\n",
      "0\n",
      "weightw\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "weightw\n",
      "Figure3:Errorinlog10(Z).Left:40?40ferromagneticgrid.Right:32?32\n",
      "spinglassgrid.Table2:Logpartitionfunctionforweightedformulas.Instance\n",
      "grid32x32grid32x32grid40x402bitmax62bitmax6ls8-\n",
      "normalizedls8-normalizedls8-normalizedls8-normalized\n",
      "4\n",
      "n\n",
      "m\n",
      "Weight\n",
      "log10Z(w)\n",
      "10241024160025225210010030130130130117211983\n",
      "3968396862407667661501501603160316031603673410231\n",
      "11155583666666\n",
      "16.092016.092023.5434>29.3222>29.3222>21.2553>21.2553>11.7324\n",
      ">11.7324>11.7324>11.7324>4.3083>2.2479>1.3424\n",
      "FocusedFlatSatlog10Z(w)Time16.096462816.096462823.48441522\n",
      "30.437336030.437336021.3187521.2551517.665558911.797458911.7974\n",
      "58911.79745894.33791002.3399631.388040\n",
      "IJGP-SampleSearchlog10Z(w)Time14.433060013.8980200015.93862000\n",
      "12.052660012.3802200021.337320021.269420016.5458600-2.3987600-\n",
      "1.74591200-1.85782000-1.830512002.703712001.3688600\n",
      "Gibbslog10Z(w)15.4856\n",
      "10\n",
      "\n",
      "Time651\n",
      "22.312525.1274\n",
      "1650732\n",
      "21.399221.31078.6825-17.356\n",
      "4040708770\n",
      "2.8516-6.71321.3420\n",
      "30017451\n",
      "boundgivenbyTRW(whichisgenerallymuchfasterbutinaccurate),fora\n",
      "rangeofwvalues.Whatisplottedistheaccuracy,logZ?logZ?.Wesee\n",
      "thattheestimateprovidedbyFocusedFlatSATisveryaccuratethroughoutthe\n",
      "rangeofwvalues.Fortheferromagneticmodel,theboundsobtainedbyTRW,\n",
      "ontheotherhand,aretightonlywhentheweightsaretlyhigh,when\n",
      "essentiallyonlythetwogroundstatesofenergyzeromatter.Onspinglasses,\n",
      "wherecomputinggroundstatesisitselfanintractableproblem,TRWisunsur-\n",
      "prisinglyinaccurateeveninthehighweightsregime.Theconsistentaccuracy\n",
      "ofFocusedFlatSAThereisastrongindicationthatthemethodisaccurately\n",
      "computingthedensityofmostoftheunderlyingstates.Thisisbecause,as\n",
      "theweightwchanges,thevalueofthepartitionfunctionisdominatedbythe\n",
      "contributionsofatsetofstates.Table2(top)showsacomparison\n",
      "withIJGP-SampleSearchandGibbsSamplingfortheferromagneticcasewith\n",
      "w=1.HereFocusedFlatSATprovidesthemostaccurateestimates,evenwhen\n",
      "othermethodsaregivenalongerrunningtime.E.g.,IJGPistwoordersof\n",
      "magnitudeforthe32?32grid.3Resultswithotherweightsaresimilarbut\n",
      "omittedduetolimitedspace.FocusedFlatSATalsocantlyoutperforms\n",
      "IJGPandGibbssamplinginaccuracyonthecircuitsynthesisinstance2bit-\n",
      "max6.Allmethodsperformwellonrandomlygenerated3-SATinstances,but\n",
      "FocusedFlatSATismuchfaster.Asanothertestcase,weuseformulasfroma\n",
      "previouslyusedmodelcountingbenchmarkinvolvingn?nLatinSquarecom-\n",
      "pletion[11],andaddaweightwtoeachconstraint.Sincetheseinstanceshave\n",
      "hightreewidth,arenon-planar,andbeyondthereachofdirectenumeration,we\n",
      "don?thavegroundtruthforthisbenchmark.However,weareabletoprovidea\n",
      "lowerbound,4whichisgivenbythenumberofmodelsoftheoriginalformula.\n",
      "OurresultsarereportedinTable2.Ourlowerboundindicatesthattheesti-\n",
      "mategivenbyFocusedFlatSATismoreaccurate,evenwhenothermethodsare\n",
      "givenalongerrunningtime.Asthelast3linesofthetableshow,IJGPand\n",
      "Gibbssamplingimproveinperformanceastheproblemismoreand\n",
      "more,bythevaluesof2,4,or5?cells?andsimplifyingtheinstance.\n",
      "Nonetheless,onthels8-normalizedwithweight6,bothIJGPand\n",
      "Gibbssamplingunderestimatebyover12ordersofmagnitude.3\n",
      "Onsmallerinstanceswithlimitedtreewidth,IJGP-SampleSearchquickly\n",
      "providesgoodestimates.TheupperboundprovidedbyTRWisverylooseon\n",
      "thisbenchmark(possiblybecauseoftheconversiontoapairwiseandnot\n",
      "reported.4\n",
      "7\n",
      "Table3:Weightlearning:likelihoodofthetrainingdataxcomputedusing\n",
      "learnedweights.Type\n",
      "11\n",
      "\n",
      "TrainingData\n",
      "ThreeChain(30)\n",
      "xxxxxxxx\n",
      "FourChain(5)HChain(10)SocialNetwork(5)\n",
      "=data-30-1=data-30-2=dataFC-5-1=dataFC-5-2=dataH-10-1=dataH-\n",
      "10-2=data-SN-1=data-SN-2\n",
      "OptimalLikelihood(O)4.09?10?279.31?10?105.77?10?63.84?10?3\n",
      "1.19?10?92.62?10?92.98?10?82.44?10?9\n",
      "FocusedFlatSATAccuracy(F/O)1.01.01.01.01.01.01.01.0\n",
      "AlchemyAccuracy(A/O)0.080.930.610.0000970.870.530.690.2\n",
      "Weightlearning.SupposethesetofsoftconstraintsCsoftiscomposedof\n",
      "Mdisjointsetsofconstraints\n",
      "f\n",
      "Si\n",
      "g\n",
      "Mi=1,wherealltheconstraintsc?Si\n",
      "havethesameweightwithatwewishtolearnfromdata(forinstance,these\n",
      "constraintscanallbegroundingsofthesameorderformulainMarkov\n",
      "Logic[8]).Letusassumeforsimplicitythattherearenohardconstraints.The\n",
      "probabilityPw(x)canbeparameterizedbyaweightvectorwP=(wwM).\n",
      "ThekeyobservationisthatP1,...,Pthepartitionfunctioncanbewritten\n",
      "asZ(w)=...`1`2`Mn(`1,...,`M)exp(?w?`),wheren(`1,\n",
      "...,`M)givesthenumberofthatviolate`iconstraintsof\n",
      "typeSifori=1,...,M.Thisfunctionn(`1,...,`M)isprecisely\n",
      "thedensityofstatesrequiredtocomputeZ(w)forallvaluesofw,without\n",
      "additionalinferencesteps.Giventrainingdatax?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N,theproblemof\n",
      "weightlearningisthatofargmaxwPw(x)wherePw(x)isgivenby\n",
      "Eqn.(1).Oncewecomputen(`1,...,`M)usingFocusedFlatSAT,wecan\n",
      "tlyevaluateZ(w),andthereforePw(x),asafunctionoftheparameters\n",
      "w=(w1,...,wM).Usingthistevaluationasablack-box,wecan\n",
      "solvetheweightlearningproblemusinganumericaloptimizationpackagewith\n",
      "noadditionalinferencestepsrequired.5Weevaluatethislearningmethodon\n",
      "relativelysimpleinstancesonwhichcommonlyusedsoftwaresuchasAlchemy\n",
      "canbeafewordersofmagnitudefromtheoptimallikelihoodofthetraining\n",
      "data.Sp,Table3comparesthelikelihoodofthetrainingdataunder\n",
      "theweightslearnedbyFocusedFlatSATandbyGenerativeWeightLearning\n",
      "[7],asimplementedinAlchemy,forfourtypesofMarkovLogictheories.The\n",
      "OptimalLikelihoodvalueisobtainedusingapartitionfunctioncomputedeither\n",
      "bydirectenumerationorusinganalyticresultsforthesyntheticinstances.The\n",
      "instanceThreeChain(K)isagroundingofthefollowingorderformulas?xP\n",
      "(x)?Q(x),?xQ(x)?R(x),?xR(x)?P(x)whileFourChain(K)isasimilar\n",
      "chainof4implications.TheinstanceHChain(K)isagroundingof?xP(x)?\n",
      "Q(x)?R(x),?xR(x)?P(x)wherex?\n",
      "f\n",
      "a1,a2,...,aK\n",
      "g\n",
      ".Theinstance\n",
      "SocialNetwork(K)(fromtheAlchemyTutorial)isagroundingofthefollowing\n",
      "orderformulaswherex,y?\n",
      "f\n",
      "a1,a2,...,aK\n",
      "g\n",
      ":?x?yFriend(x,\n",
      "y)?(Smokes(x)?Smokes(y)),?xSmokes(x)?Cancer(x).Table3shows\n",
      "theaccuracyofFocusedFlatSATandAlchemyfortheweightlearningtask,as\n",
      "measuredbytheresultinglikelihoodofobservingthedatainthelearnedmodel,\n",
      "whichwearetryingtomaximize.Theaccuracyismeasuredastheratioofthe\n",
      "optimallikelihood(O)andthelikelihoodinthelearnedmodel(FandA,resp.).\n",
      "12\n",
      "\n",
      "Intheseinstances,FocusedFlatSATalwaysmatchestheoptimallikelihoodup\n",
      "totwodigitsofprecision,whileAlchemycanunderestimateitbyseveralorders\n",
      "ofmagnitude,e.g.,byover4ordersinthecaseofFourChain(5).\n",
      "6\n",
      "Conclusion\n",
      "WeintroducedFocusedFlatSAT,aMarkovChainMonteCarlotechnique\n",
      "basedonthehistogrammethodwitharandomwalkstylecomponentto\n",
      "estimatethepartitionfunctionfromthedensityofstates.Wedemonstrated\n",
      "theenessofourapproachonseveraltypesofproblems.Ourmethod\n",
      "outperformsthecurrentstate-of-the-arttechniquesonavarietyofinstances,\n",
      "attimesbyseveralordersofmagnitude.Moreover,fromthedensityofstates\n",
      "wecanobtaindirectlythepartitionfunctionZ(w)asafunctionofthemodel\n",
      "parametersw.Weshowanapplicationofthispropertytoweightlearningin\n",
      "MarkovLogicNetworks.5Storingthefulldensityfunctionn(`1,...,`M)\n",
      "ofcourserequiresspace(andhencetime)thatisexponentialinM.Onemust\n",
      "usearelativelycoarsepartitioningofthestatespaceforscalabilitywhenMis\n",
      "large.\n",
      "8\n",
      "2References\n",
      "[1]MartinJWainwrightandMichaelIJordan.GraphicalModels,Exponential\n",
      "Families,andVariationalInference.NowPublishersInc.,Hanover,MA,USA,\n",
      "2008.[2]N.N.SchraudolphandD.Kamenetsky.ientexactinferenceinpla-\n",
      "narIsingmodels.InProc.ofNIPS-08,2008.[3]F.WangandDPLandau.Ef-\n",
      "t,multiple-rangerandomwalkalgorithmtocalculatethedensityofstates.\n",
      "PhysicalReviewLetters,86(10):2050?2053,2001.[4]M.J.Wainwright,T.S.\n",
      "Jaakkola,andA.S.Willsky.Anewclassofupperboundsonthelogpartition\n",
      "function.InformationTheory,IEEETransactionson,51(7):2313?2335,2005.\n",
      "[5]VibhavGogateandRinaDechter.SampleSearch:ASchemethatSearches\n",
      "forConsistentSamples.JournalofMachineLearningResearch,2:147?154,2007.\n",
      "[6]MarkJerrumandAlistairSinclair.TheMarkovchainMonteCarlomethod:\n",
      "anapproachtoapproximatecountingandintegration,pages482?520.PWS\n",
      "PublishingCo.,Boston,MA,USA,1997.[7]P.Domingos,S.Kok,H.Poon,M.\n",
      "Richardson,andP.Singla.Unifyinglogicalandstatisticalai.InProc.ofAAAI-\n",
      "06,pages2?7,Boston,Massachusetts,2006.AAAIPress.[8]M.Richardsonand\n",
      "P.Domingos.Markovlogicnetworks.MachineLearning,62(1):107?136,2006.\n",
      "[9]H.PoonandP.Domingos.Soundandtinferencewithprobabilistic\n",
      "anddeterministicdependencies.InProc.ofAAAI-06,pages458?463,2006.[10]\n",
      "J.S.Yedidia,W.T.Freeman,andY.Weiss.Constructingfree-energyapprox-\n",
      "imationsandgeneralizedbeliefpropagationalgorithms.InformationTheory,\n",
      "IEEETransactionson,51(7):2282?2312,2005.[11]S.Ermon,C.Gomes,and\n",
      "B.Selman.ComputingthedensityofstatesofBooleanformulas.InProc.of\n",
      "CP-2010,2010.[12]B.Selman,H.A.Kautz,andB.Cohen.Localsearchstrate-\n",
      "giesforytesting.InDIMACSSeriesinDiscreteMathematicsand\n",
      "13\n",
      "\n",
      "TheoreticalComputerScience,1996.[13]C.P.Gomes,J.A.Sabhar-\n",
      "wal,andB.Selman.Fromsamplingtomodelcounting.InProc.ofIJCAI-07,\n",
      "2007.[14]V.GogateandR.Dechter.Approximatecountingbysamplingthe\n",
      "backtrack-freesearchspace.InProc.ofAAAI-07,pages198?203,2007.\n",
      "9\n",
      "14\n",
      "\n",
      "PP4528.pdf\n",
      "PP4528.pdf 12\n",
      "CalibrationDimensionforGeneral\n",
      "MulticlassLosses\n",
      "Authoredby:\n",
      "ShivaniAgarwal\n",
      "HarishG.Ramaswamy\n",
      "Abstract\n",
      "Westudyconsistencypropertiesofsurrogatelossfunctionsforgeneral\n",
      "multiclassproblems,byagenerallossmatrix.We\n",
      "extendthenotionofcalibration,whichhasbeenstudiedfor\n",
      "binaryandmulticlass0-1problems(andforcertainother\n",
      "spelearningproblems),tothegeneralmulticlasssetting,andderive\n",
      "necessaryandtconditionsforasurrogatelosstobe\n",
      "calibratedwithrespecttoalossmatrixinthissetting.Wethenintroduce\n",
      "thenotionofemph\n",
      "f\n",
      "calibrationdimension\n",
      "g\n",
      "ofamulticlass\n",
      "lossmatrix,whichmeasuresthesmallest`size'ofapredictionspacefor\n",
      "whichitispossibletodesignaconvexsurrogatethatisation\n",
      "calibratedwithrespecttothelossmatrix.Wederivebothupperand\n",
      "lowerboundsonthisquantity,andusetheseresultstoanalyzevariousloss\n",
      "matrices.Inparticular,asoneapplication,weprovideatroute\n",
      "fromtherecentresultofDuchietal.(2010)foranalyzingthey\n",
      "ofdesigning`low-dimensional'convexsurrogatesthatareconsistentwith\n",
      "respecttopairwisesubsetrankinglosses.Weanticipatethe\n",
      "calibrationdimensionmayprovetobeausefultoolinthestudyand\n",
      "designofsurrogatelossesforgeneralmulticlasslearningproblems.\n",
      "1PaperBody\n",
      "Therehasbeensigni?cantinterestandprogressinrecentyearsinunderstand-\n",
      "ingconsistencyoflearningmethodsforvarious?nite-outputlearningproblems,\n",
      "suchasbinaryclassi?cation,multiclass0-1classi?cation,andvariousformsof\n",
      "rankingandmulti-labelpredictionproblems[1?15].Such?nite-outputprob-\n",
      "lemscanallbeviewedasinstancesofageneralmulticlasslearningproblem,\n",
      "whosestructureisde?nedbyalossfunction,orequivalently,byalossmatrix.\n",
      "Whilethestudiesabovehavecontributedtotheunderstandingoflearningprob-\n",
      "lemscorrespondingtocertainformsoflossmatrices,aframeworkforanalyzing\n",
      "consistencypropertiesforageneralmulticlasslearningproblem,de?nedbya\n",
      "generallossmatrix,hasremainedelusive.Inthispaper,weanalyzeconsistency\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ofsurrogatelossesforgeneralmulticlasslearningproblems,buildingonthere-\n",
      "sultsof[3,5?7]andothers.WestartinSection2withsomebackgroundand\n",
      "examplesthatwillbeusedasrunningexamplestoillustrateconceptsthrough-\n",
      "outthepaper,andformalizethenotionofclassi?cationcalibrationwithrespect\n",
      "toagenerallossmatrix.InSection3,wederivebothnecessaryandsuf?cient\n",
      "conditionsforclassi?cationcalibrationwithrespecttogeneralmulticlasslosses;\n",
      "thesearebothofindependentinterestandusefulinourlaterresults.Section\n",
      "4introducesthenotionofclassi?cationcalibrationdimensionofalossmatrix,\n",
      "afundamentalquantitythatmeasuresthesmallest?size?ofapredictionspace\n",
      "forwhichitispossibletodesignaconvexsurrogatethatisclassi?cationcali-\n",
      "bratedwithrespecttothelossmatrix.Wederivebothupperandlowerbounds\n",
      "onthisquantity,andusetheseresultstoanalyzevariouslossmatrices.Asone\n",
      "application,inSection5,weprovideatroutefromtherecentresult\n",
      "ofDuchietal.[10]foranalyzingthedif?cultyofdesigning?low-dimensional?\n",
      "convexsurrogatesthatareconsistentwithrespecttocertainpairwisesubset\n",
      "rankinglosses.WeconcludeinSection6withsomefuturedirections.1\n",
      "2\n",
      "Preliminaries,Examples,andBackground\n",
      "Setup.Wearegiventrainingexamples(X1,Y1),...,(Xm,Ym)drawn\n",
      "i.i.d.fromadistributionDonX?Y,whereXisaninstancespaceandY=[n]\n",
      "=\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "isa?nitesetofclasslabels.Wearealsogivena?nitesetT=[k]\n",
      "=\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      "oftargetlabelsinwhichpredictionsaretobemade,andaloss\n",
      "function?:Y?T?[0,?),where?(y,t)denotesthelossincurredonpredicting\n",
      "t?Twhenthelabelisy?Y.Inmanycommonlearningproblems,T=Y,\n",
      "butingeneral,thesecouldbet(e.g.whenthereisan?abstain?option\n",
      "availabletoaclassi?er,inwhichcasek=n+1).Wewill?nditconvenientto\n",
      "representthelossfunction?asalossmatrixL?Rn?k(hereR+=+[0,?)),\n",
      "andforeachy?[n],t?[k],willdenoteby?ytthe(y,t)-thelementofL,?yt=\n",
      "(L)yt=?(y,t),andby?tthet-thcolumnofL,?t=(?1t,...,?nt)??Rn.\n",
      "Someexamplesfollow:\n",
      "Example1(0-1loss).HereY=T=[n],andthelossincurredis1ifthe\n",
      "predictedlabeltisdrentfromtheactualclasslabely,and0otherwise:?0-1\n",
      "(y,t)=1(t?=y),where1(?)is1iftheargumentistrueand0otherwise.\n",
      "ThelossmatrixL0-1forn=3isshowninFigure1(a).Example2(Ordinal\n",
      "regressionloss).HereY=T=[n],andpredictionstfartherawayfromthe\n",
      "actualclasslabelyarepenalizedmoreheavily,e.g.usingabsolutedistance:\n",
      "?ord(y,t)=|t?y|.ThelossmatrixLordforn=3isshowninFigure\n",
      "1(b).Example3(Hammingloss).HereY=T=[2r]forsomer?N,and\n",
      "thelossincurredonpredictingtwhentheactualclasslabelisyisthenumber\n",
      "?rofbit-positionsinwhichther-bitbinaryrepresentationsoft?1andy?1\n",
      "?Ham(y,t)=i=11((t?1)i?=(y?1)i),whereforanyz?\n",
      "f\n",
      "0,...\n",
      ",2r?1\n",
      "g\n",
      ",zi?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "denotesthei-thbitinther-bitbinaryrepresentationof\n",
      "z.ThelossmatrixLHamforr=2isshowninFigure1(c).Thislossisusedin\n",
      "sequencelabelingtasks[16].Example4(?Abstain?loss).HereY=[n]andT\n",
      "=[n+1],wheret=n+1denotes?abstain?.Onepossiblelossfunctioninthis\n",
      "settingassignsalossof1toincorrectpredictionsin[n],0tocorrectpredictions,\n",
      "2\n",
      "\n",
      "and12forabstaining:?(?)(y,t)=1(t?=y)1(t?[n])+121(t=n+1).\n",
      "ThelossmatrixL(?)forn=3isshowninFigure1(d).Thegoalintheabove\n",
      "settingistolearnfromthetrainingexamplesafunctionh:X?[k]withlow\n",
      "expectedlossonanewexampledrawnfromD,whichwewillrefertoasthe\n",
      "?-riskofh:n??er?D[h]=E(X,Y)?D?(Y,h(X))=EXpy(X)?(y,h(X))=\n",
      "EXp(X)??h(X),(1)y=1\n",
      "wherepy(x)=P(Y=y|X=x)underD,andp(x)=(p1(x),...,pn\n",
      "(x))??Rndenotestheconditionalprobabilityvectoratx.Inparticular,the\n",
      "goalistolearnafunctionwith?-riskclosetotheoptimal?-risk,de?nedas?\n",
      "er?,?D=\n",
      "inf\n",
      "h:X?[k]\n",
      "er?D[h]=\n",
      "inf\n",
      "h:X?[k]\n",
      "EXp(X)??h(X)=EXminp(X)??t.t?[k]\n",
      "(2)\n",
      "Minimizingthediscrete?-riskdirectlyistypicallydif?cultcomputationally;\n",
      "consequently,oneusuallyemploysasurrogatelossfunction?:Y?T??R+\n",
      "operatingonasurrogatetargetspaceT??Rdforsomeappropriated?N,1\n",
      "andminimizes(approximately,basedonthetrainingsample)the?-riskinstead,\n",
      "de?nedfora(vector)functionf:X?T?asn??er?[f]=E?(Y,f(X))=E\n",
      "py(X)?(y,f(X)).(3)X(X,Y)?DDy=1\n",
      "Thelearnedfunctionf:X?T?isthenusedtomakepredictionsin[k]via\n",
      "sometransformationpred:T??[k]:thepredictiononanewinstancex?X\n",
      "isgivenbypred(f(x)),andthe?-riskincurrediser?D[pred?f].Asan\n",
      "example,severalalgorithmsformulticlassclassi?cationwithrespectto0-1loss\n",
      "learnafunctionoftheformf:X?Rnandpredictaccordingtopred(f(x))=\n",
      "argmaxt?[n]ft(x).\n",
      "Belowwewill?nditusefultorepresentthesurrogatelossfunction?vian\n",
      "real-valuedfunctions?y:T??R+de?nedas?y(?t)=?(y,?t)fory?[n],or\n",
      "equivalently,asavector-valuedfunction?:T??Rn+de?nedas?(?t)=(?1\n",
      "(?t),...,?n(?t))?.Wewillalsode?nethesets????R?=?(?t):?t?T?\n",
      "andS?=conv(R?),(4)whereforanyA?Rn,conv(A)denotestheconvex\n",
      "hullofA.1\n",
      "?+,whereR?+=R+?\n",
      "f\n",
      "?\n",
      "g\n",
      "and?(y,?t)=???t?Equivalently,one\n",
      "cande?ne?:Y?Rd?R/T?.\n",
      "2\n",
      "?\n",
      "011\n",
      "101\n",
      "110\n",
      "?\n",
      "?\n",
      "012\n",
      "(a)\n",
      "3\n",
      "\n",
      "101\n",
      "210\n",
      "?\n",
      "?\n",
      "0?1?12\n",
      "(b)\n",
      "11022011(c)\n",
      "?21?1?0\n",
      "?\n",
      "011?101110\n",
      "121212\n",
      "(d)\n",
      "??\n",
      "Figure1:LossmatricescorrespondingtoExamples1-4:(a)L0-1forn=3;\n",
      "(b)Lordforn=3;(c)LHamforr=2(n=4);(d)L(?)forn=3.Under\n",
      "suitableconditions,algorithmsthatapproximatelyminimizethe?-riskbasedon\n",
      "atrainingsampleareknowntobeconsistentwithrespecttothe?-risk,i.e.to\n",
      "converge(inprobability)totheoptimal?-risk,de?nedas?\n",
      "er?,?D=\n",
      "infer?D[f]=\n",
      "f:X?T?\n",
      "infEXp(X)??(f(X))=EXinfp(X)?z=EXinfp(X)?z.z?R?\n",
      "f:X?T?\n",
      "z?S?\n",
      "(5)Thisraisesthenaturalquestionofwhether,foragivenloss?,there\n",
      "aresurrogatelosses?forwhichconsistencywithrespecttothe?-riskalso\n",
      "guaranteesconsistencywithrespecttothe?-risk,i.e.guaranteesconvergence\n",
      "(inprobability)totheoptimal?-risk(de?nedinEq.(2)).Thisquestionhas\n",
      "beenstudiedindetailforthe0-1loss,andforsquarelossesoftheform?(y,t)\n",
      "=ay1(t?=y),whichcanbeanalyzedsimilarlytothe0-1loss[6,7].Inthis\n",
      "paper,weconsiderthisquestionforgeneralmulticlasslosses?:[n]?[k]?R+,\n",
      "includingrectangularlosseswithk?=n.Theonlyassumptionwemakeon?is\n",
      "thatforeacht?[k],?p??nsuchthatargmint??[k]p??t?=\n",
      "f\n",
      "t\n",
      "g\n",
      "(otherwisethe\n",
      "labeltneverneedstobepredictedandcansimplybeignored).2De?nitionsand\n",
      "Results.Wewillneedthefollowingde?nitionsandbasicresults,generalizing\n",
      "thoseof[5?7].Thenotionofclassi?cationcalibrationwillbecentraltoourstudy;\n",
      "asTheorem3belowshows,classi?cationcalibrationofasurrogateloss?w.r.t.\n",
      "?correspondstothepropertythatconsistencyw.r.t.?-riskimpliesconsistency\n",
      "w.r.t.?-risk.Proofsoftheseresultsarestraightforwardgeneralizationsofthose\n",
      "in[6,7]andareomitted.De?nition1(Classi?cationcalibration).Asurrogate\n",
      "lossfunction?:[n]?T??R+issaidtobeclassi?cationcalibratedwithrespect\n",
      "toalossfunction?:[n]?[k]?R+overP??nifthereexistsafunctionpred:\n",
      "T??[k]suchthatp??(?t)>infp??(?t).?p?P:inf?t?T?\n",
      "??t?T?:pred(?t)?argmin/tp?t\n",
      "4\n",
      "\n",
      "Lemma2.Let?:[n]?[k]?R+and?:[n]?T??R+.Then?is\n",
      "classi?cationcalibratedwithrespectto?overP??nthereexistsafunction\n",
      "pred?:S??[k]suchthat?p?P:\n",
      "inf\n",
      "?z?S?:pred?(z)?argmin/tp?t\n",
      "p?z>\n",
      "infp?z.\n",
      "z?S?\n",
      "Theorem3.Let?:[n]?[k]?R+and?:[n]?T??R+.Then?is\n",
      "classi?cationcalibratedwithrespectto?over?n?afunctionpred:T??[k]\n",
      "suchthatforalldistributionsDonX?[n]andallsequencesofrandom(vector)\n",
      "functionsfm:X?T?(dependingon(X1,Y1),...,(Xm,Ym)),3P\n",
      "P\n",
      "er??er?,?D[fm]?D\n",
      "implieser?D[pred?fm]??er?,?D.?De?nition4(Positivenormals).\n",
      "Let?:[n]?T?R+.Foreachpointz?S?,thesetofpositivenormalsatzis\n",
      "de?nedas4???NS?(z)=p??n:p?(z?z?)?0?z??S?.De?nition5\n",
      "(Triggerprobabilities).Let?:[n]?[k]?R+.Foreacht?[k],thesetoftrigger\n",
      "probabilitiesoftwithrespectto?isde?nedas?????Q?t=p??n:p?\n",
      "(?t??t?)?0?t??[k]=p??n:t?argmint??[k]p??t?.Examplesof\n",
      "triggerprobabilitysetsforvariouslossesareshowninFigure2.2\n",
      "Here?ndenotestheprobabilitysimplexinRn,?n=\n",
      "f\n",
      "p?Rn:pi?0?i\n",
      "?[n],P3Here??denotesconvergenceinprobability.4Thesetofpositive\n",
      "normalsisnon-emptyonlyatpointszintheboundaryofS?.\n",
      "3\n",
      "?n\n",
      "i=1\n",
      "pi=1\n",
      "g\n",
      ".\n",
      "Q10-1=\n",
      "f\n",
      "p??3:p1?max(p2,p3)\n",
      "g\n",
      "Qord=\n",
      "f\n",
      "p??3:p1?1=\n",
      "f\n",
      "p?\n",
      "?3:p2?max(p1,p3)\n",
      "g\n",
      "QordQ0-1=\n",
      "f\n",
      "p??3:p1?22=\n",
      "f\n",
      "p??3:p3?\n",
      "max(p1,p2)\n",
      "g\n",
      "QordQ0-1=\n",
      "f\n",
      "p??3:p3?33\n",
      "12\n",
      "g\n",
      "12,p312\n",
      "g\n",
      "?\n",
      "(a)\n",
      "12\n",
      "g\n",
      "(?)Q1(?)Q2(?)Q3(?)Q4\n",
      "=\n",
      "f\n",
      "p??3:p1?=\n",
      "f\n",
      "p??3:p2?=\n",
      "f\n",
      "p??3:p3?\n",
      "12\n",
      "g\n",
      "12\n",
      "g\n",
      "12\n",
      "g\n",
      "=\n",
      "f\n",
      "p??3:max(p1,p2,p3)?\n",
      "12\n",
      "g\n",
      "(b)(c)Figure2:Triggerprobabilitysetsfor(a)0-1loss?0-1;(b)ordinal\n",
      "regressionloss?ord;and(c)?abstain?loss?(?);allforn=3,forwhichthe\n",
      "probabilitysimplexcanbevisualizedeasily.Calculationsofthesesetscanbe\n",
      "foundintheappendix.Wenotethatsuchsetshavealsobeenstudiedin[17,\n",
      "18].\n",
      "3\n",
      "5\n",
      "\n",
      "NecessaryandSuf?cientConditionsforClassi?cationCalibration\n",
      "Westartbygivinganecessaryconditionforclassi?cationcalibrationofa\n",
      "surrogateloss?withrespecttoanymulticlassloss?over?n,whichrequires\n",
      "thepositivenormalsofallpointsz?S?tobe?well-behaved?w.r.t.?and\n",
      "generalizesthe?admissibility?conditionusedfor0-1lossin[7].Allproofsnot\n",
      "includedinthemaintextcanbefoundintheappendix.Theorem6.Let?:\n",
      "[n]?T??R+beclassi?cationcalibratedwithrespectto?:[n]?[k]?R+over\n",
      "?n.Thenforallz?S?,thereexistssomet?[k]suchthatNS?(z)?Q?t.\n",
      "Wenotethat,asin[7],itispossibletogiveanecessaryandsuf?cient\n",
      "conditionforclassi?cationcalibrationintermsofasimilarpropertyholdingfor\n",
      "positivenormalsassociatedwithprojectionsofS?inlowerdimensions.Instead,\n",
      "belowwegiveatsuf?cientconditionthatwillbehelpfulinshowing\n",
      "classi?cationcalibrationofcertainsurrogates.Inparticular,weshowthatfor\n",
      "asurrogateloss?tobeclassi?cationcalibratedwithrespectto?over?n,it\n",
      "issuf?cientfortheabovepropertyofpositivenormalstoholdonlyata?nite\n",
      "numberofpointsinR?,aslongastheirpositivenormalsetsjointlycover?n:\n",
      "?Theorem7.Let?r?:[n]?[k]?R+and?:[n]?T?R+.Supposethereexist\n",
      "r?Nandz1,...,zr?R?suchthatj=1NS?(zj)=?nandforeachj?\n",
      "[r],?t?[k]suchthatNS?(zj)?Q?t.Then?isclassi?cationcalibratedwith\n",
      "respectto?over?n.ComputationofNS?(z).Theconditionsintheabove\n",
      "resultsbothinvolvethesetsofpositivenormalsNS?(z)atvariouspointsz?\n",
      "S?.Thusinordertousetheaboveresultstoshowthatasurrogate?is(or\n",
      "isnot)classi?cationcalibratedwithrespecttoaloss?,oneneedstobeableto\n",
      "computeorcharacterizethesetsNS?(z).Herewegiveamethodforcomputing\n",
      "thesesetsforcertainsurrogatelosses?andpointsz?S?.Lemma8.LetT??\n",
      "Rdbeaconvexsetandlet?:T??Rn+beconvex.5Letz=?(?t)forsome?t\n",
      "?T?suchthatforeachy?[n],thesubtialof?yat?tcanbewritten\n",
      "as??y(?t)=?nconv(\n",
      "f\n",
      "w1y,...,wsyy\n",
      "g\n",
      ")forsomesy?Nandw1y,...,\n",
      "wsyy?Rd.6Lets=y=1sy,andlet??B=[byj]?Rn?s,A=w11...\n",
      "ws11w12...ws22......w1n...wsnn?Rd?s;wherebyjis1ifthej-th\n",
      "columnofAcamefrom\n",
      "f\n",
      "w1y,...,wsyy\n",
      "g\n",
      "and0otherwise.Then??NS?\n",
      "(z)=p??n:p=Bqforsomeq?Null(A)??s,whereNull(A)?Rsdenotes\n",
      "thenullspaceofthematrixA.5\n",
      "Avectorfunctionisconvexifallitscomponentfunctionsareconvex.?+\n",
      "atapointu0?Rdisde?nedasRecall?thatthesubtialofaconvex\n",
      "function?:Rd??R??(u0)=w?Rd:?(u)??(u0)?w?(u?u0)?u?Rd\n",
      "andisaconvexsetinRd(e.g.see[19]).6\n",
      "4\n",
      "WegiveanexampleillustratingtheuseofTheorem7andLemma8toshow\n",
      "classi?cationcalibrationofacertainsurrogatelosswithrespecttotheordinal\n",
      "regressionloss?ordde?nedinExample2:Example5(Classi?cationcalibrated\n",
      "surrogateforordinalregressionloss).Considertheordinalregressionloss?ord\n",
      "de?nedinExample2forn=3.LetT?=R,andlet?:\n",
      "f\n",
      "1,2,3\n",
      "g\n",
      "?R?R+be\n",
      "de?nedas(seeFigure3)?(y,t?)=|t??y|?y?\n",
      "f\n",
      "1,2,3\n",
      "g\n",
      ",t??R.(6)?\n",
      "?????????ThusR?=?(t)=|t?1|,|t?2|,|t?3|:t?R\n",
      ".Wewillshowthereare3pointsinR?satisfyingtheconditionsofTheorem7.\n",
      "6\n",
      "\n",
      "Speci?cally,considert?1=1,t?2=2,andt?3=3,givingz1=?(t?1)=(0,1,\n",
      "2)?,z2=?(t?2)=(1,0,1)?,andz3=?(t?3)=(2,1,0)?inR?.Observe\n",
      "thatT?hereisaconvexsetand?:T??R3isaconvexfunction.Moreover,for\n",
      "t?1=1,wehave??1(1)??2(1)??3(1)\n",
      "===\n",
      "[?1,1]=conv(\n",
      "f\n",
      "+1,?1\n",
      "g\n",
      ");\n",
      "f\n",
      "?1\n",
      "g\n",
      "=conv(\n",
      "f\n",
      "?1\n",
      "g\n",
      ");\n",
      "f\n",
      "?1\n",
      "g\n",
      "=conv(\n",
      "f\n",
      "?1\n",
      "g\n",
      ").\n",
      "Therefore,wecanuseLemma8tocomputeNS?(z1).Heres=4,and??\n",
      "1100A=[+1?1?1?1];B=0010.0001ThisgivesNS?(z1)\n",
      "===\n",
      "Figure3:Thesurrogate??p??3:p=(q1+q2,q3,q4)forsomeq?\n",
      "?4,q1?q2?q3?q4=0??p??3:p=(q1+q2,q3,q4)forsomeq?\n",
      "?4,q1=12??p??3:p1?12?\n",
      "=Qord1.ordAsimilarprocedureyieldsNS?(z2)=Qord2andNS?\n",
      "(z3)=Q3.Thus,byTheorem7,wegetthatord?isclassi?cationcalibrated\n",
      "withrespectto?over?3.Wenotethatingeneral,computationalprocedures\n",
      "suchasFourier-Motzkinelimination[20]canbehelpfulincomputingNS?(z)\n",
      "viaLemma8.\n",
      "4\n",
      "Classi?cationCalibrationDimension\n",
      "Wenowturntothestudyofafundamentalquantityassociatedwiththe\n",
      "propertyofclassi?cationcalibrationwithrespecttoageneralmulticlassloss\n",
      "?.Speci?cally,intheaboveexample,wesawthattodevelopaclassi?cation\n",
      "calibratedsurrogatelossw.r.t.theordinalregressionlossforn=3,itwas\n",
      "suf?cienttoconsiderasurrogatetargetspaceT?=R,withdimensiond=1;\n",
      "inaddition,thisyieldedaconvexsurrogate?:R?R3+whichcanbeused\n",
      "indevelopingcomputationallyef?cientalgorithms.Infactthesamesurrogate\n",
      "targetspacewithd=1canbeusedtodevelopasimilarconvex,classi?cation\n",
      "calibratedsurrogatelossw.r.t.theordinalregressionlossforanyn?N.However\n",
      "notalllosses?havesuch?low-dimensional?surrogates.Thisraisesthenatural\n",
      "questionofwhatisthesmallestdimensiondthatsupportsaconvexclassi?cation\n",
      "calibratedsurrogateforagivenmulticlassloss?,andleadsustothefollowing\n",
      "de?nition:De?nition9(Classi?cationcalibrationdimension).Let?:[n]?\n",
      "[k]?R+.De?netheclassi?cationcalibrationdimension(CCdimension)of?as\n",
      "??CCdim(?)=mind?N:?aconvexsetT??Rdandaconvexsurrogate?\n",
      ":T??Rn+?thatisclassi?cationcalibratedw.r.t.?over?n,iftheaboveset\n",
      "isnon-empty,andCCdim(?)=?otherwise.\n",
      "Fromtheabovediscussion,CCdim(?ord)=1foralln.Inthefollowing,\n",
      "wewillbeinterestedindevelopinganunderstandingoftheCCdimensionfor\n",
      "generallosses?,andinparticularinderivingupperandlowerboundsonthis.\n",
      "5\n",
      "4.1\n",
      "UpperBoundsontheClassi?cationCalibrationDimension\n",
      "WestartwithasimpleresultthatestablishesthattheCCdimensionofany\n",
      "multiclassloss?is?nite,andinfactisstrictlysmallerthanthenumberofclass\n",
      "labelsn.???n?1Lemma10.Let?:[n]?[k]?R+.LetT?=?t?Rn?1:j=1\n",
      "7\n",
      "\n",
      "t?j?1,andforeachy?[n],let+?y:T??R+begivenby??y(?t)=1(y\n",
      "?=n)(t?y?1)2+t?j2.j?[n?1],j?=y\n",
      "Then?isclassi?cationcalibratedwithrespectto?over?n.Inparticular,\n",
      "since?isconvex,CCdim(?)?n?1.\n",
      "Itmayappearsurprisingthattheconvexsurrogate?intheabovelemmais\n",
      "classi?cationcalibratedwithrespecttoallmulticlasslosses?onnclasses.How-\n",
      "everthismakesintuitivesense,sinceinprinciple,foranymulticlassproblem,if\n",
      "onecanestimatetheconditionalprobabilitiesofthenclassesaccurately(which\n",
      "requiresestimatingn?1real-valuedfunctionsonX),thenonecanpredicta\n",
      "targetlabelthatminimizestheexpectedlossaccordingtotheseprobabilities.\n",
      "Minimizingtheabovesurrogateelycorrespondstosuchclassprobability\n",
      "estimation.Indeed,theabovelemmacanbeshowntoholdforanysurrogate\n",
      "thatisastrictlypropercompositemulticlassloss[21].Inpractice,whenthe\n",
      "numberofclasslabelsnislarge(suchasinasequencelabelingtask,where\n",
      "nisexponentialinthelengthoftheinputsequence),theaboveresultisnot\n",
      "veryhelpful;insuchcases,itisofinteresttodevelopalgorithmsoperatingon\n",
      "asurrogatetargetspaceinalower-dimensionalspace.Nextwegiveat\n",
      "upperboundontheCCdimensionthatdependsontheloss?,andforcertain\n",
      "losses,canbesigni?cantlytighterthanthegeneralboundabove.Theorem11.\n",
      "Let?:[n]?[k]?R+.ThenCCdim(?)?rank(L),therankofthelossmatrix\n",
      "L.Proof.Letrank(L)=d.Wewillconstructaconvexclassi?cationcalibrated\n",
      "surrogateloss?for?withsurrogatetargetspaceT??Rd.\n",
      "Let?t1,...,?tdbelinearlyindependentcolumnsofL.Let\n",
      "f\n",
      "e1,...,\n",
      "ed\n",
      "g\n",
      "denotethestandardbasis?:Rd?RnbyinRd.Wecande?nealinear\n",
      "function??j)=?t?j?[d].?(ej\n",
      "?=z.ThenforeachzinthecolumnspaceofL,thereexistsauniquevector\n",
      "u?Rdsuchthat?(u)?t)=?t.Inparticular,thereexistuniquevectorsu1\n",
      ",...,uk?Rdsuchthatforeacht?[k],?(uLetT?=conv(\n",
      "f\n",
      "u1,...,uk\n",
      "g\n",
      "),andde?ne?:T??Rn+as??t);?(?t)=?(?kwenotethattheresulting\n",
      "vectorsarealwaysinRn+,sincebyde?nition,forany?t=t=1?tutfor?k\n",
      "???k,?(?t)=t=1?t?t,and?t?Rn+?t?[k].Thefunction?isclearly\n",
      "convex.Toshow?isclassi?cationcalibratedw.r.t.?over?n,wewilluse\n",
      "Theorem7.Speci?cally,considerthekpointszt=?(ut)=?t?R?fort?[k].\n",
      "Byde?nitionof?,wehaveS?=conv(\n",
      "f\n",
      "?1,...,?k\n",
      "g\n",
      ");fromthede?nitionsof\n",
      "positivenormalsandtriggerprobabilities,itthenfollowsthatNS?(zt)=NS?\n",
      "(?t)=Q?tforallt?[k].ThusbyTheorem7,?isclassi?cationcalibrated\n",
      "w.r.t.?over?n.Example6(CCdimensionofHammingloss).Considerthe\n",
      "Hammingloss?Hamde?nedinExample3,forn=2r.Foreachi?[r],de?ne\n",
      "?i?Rnas?+1if(y?1)i,thei-thbitinther-bitbinaryrepresentationof\n",
      "(y?1),is1?iy=?1otherwise.ThenthelossmatrixLHamsatis?es\n",
      "r\n",
      "LHam=\n",
      "r?1?ee??i?i?,22i=1\n",
      "whereeisthen?1allonesvector.Thusrank(LHam)?r+1,givingus\n",
      "CCdim(?Ham)?r+1.Forr?3,thisisasigni?cantlytighterupperbound\n",
      "thantheboundof2r?1givenbyLemma10.6\n",
      "8\n",
      "\n",
      "WenotethattheupperboundofTheorem11neednotalwaysbetight:for\n",
      "example,fortheordinalregressionloss,forwhichwealreadyknowCCdim(?ord\n",
      ")=1,thetheoremactuallygivesanupperboundofn,whichisevenweaker\n",
      "thanthatimpliedbyLemma10.4.2\n",
      "LowerBoundontheClassi?cationCalibrationDimension\n",
      "InthissectionwegivealowerboundontheCCdimensionofalossfunction\n",
      "?andillustrateitbyusingittocalculatetheCCdimensionofthe0-1loss.\n",
      "Section5wewillexploreconsequencesofthelowerboundforclassi?cationcali-\n",
      "bratedsurrogatesforcertaintypesofrankinglosses.Wewillneedthefollowing\n",
      "de?nition:De?nition12.ThefeasiblesubspacedimensionofaconvexsetCat\n",
      "p?C,denotedby?C(p),isde?nedasthedimensionofthesubspaceFC(p)\n",
      "?(?FC(p)),whereFC(p)istheconeoffeasibledirectionsofCatp.7The\n",
      "followinggivesalowerboundontheCCdimensionofaloss?intermsofthe\n",
      "feasiblesubspacedimensionofthetriggerprobabilitysetsQ?tatcertainpoints\n",
      "p?Q?t:\n",
      "Theorem13.Let?:[n]?[k]?R+.Thenforallp?relint(?n)andt?arg\n",
      "mint?p??t?(i.e.suchthatp?Q?t):8CCdim(?)?n??Q?t(p)?1.The\n",
      "proofrequiresextensionsofthede?nitionofpositivenormalsandthenecessary\n",
      "conditionofTheorem6tosequencesofpointsinS?andisquitetechnical.In\n",
      "theappendix,weprovideaproofinthespecialcasewhenp?relint(?n)issuch\n",
      "thatinfz?S?p?zisachievedinS?,whichdoesnotrequiretheseextensions.\n",
      "Fullproofdetailswillbeprovidedinalongerversionofthepaper.Boththe\n",
      "proofofthelowerboundanditsapplicationsmakeuseofthefollowinglemma,\n",
      "whichgivesamethodtocalculatethefeasiblesubspacedimensionforcertain\n",
      "convexsetsCandpointsp?C:??Lemma14.LetC=u?Rn:A1u?\n",
      "b1,A2u?b2,A3u=b3.Letp?Cbesuchthat?1???1??AA,\n",
      "thedimensionofthenullspaceof.A1p=b1,A2p<b2.Then?C(p)=\n",
      "nullity3AA3TheabovelowerboundallowsustocalculatepreciselytheCC\n",
      "dimensionofthe0-1loss:Example7(CCdimensionof0-1loss).Considerthe\n",
      "0-1loss?0-1de?nedinExample1.Takep=(n1,...,n1)??relint(?n).\n",
      "Thenp?Q0-1tforallt?[k]=[n](seeFigure2);inparticular,0-1wehavep\n",
      "?Q0-1.NowQcanbewrittenas11??0-1Q1=q??n:q1?qy?y?\n",
      "f\n",
      "2,\n",
      "...,n\n",
      "g\n",
      "???=q?Rn:?en?1In?1q?0,?q?0,e?nq=1\n",
      "g\n",
      ",\n",
      "whereen?1,endenotethe(n?1)?1andn?1allonesandIn?1denotes\n",
      "??vectors,respectively,the(n?1)?(n?1)identitymatrix.Moreover,we\n",
      "have?en?1In?1p=0,?p<0.Therefore,byLemma14,wehave?????11\n",
      "0...0???101...0???????????en?1In?1..???=0.?Q0-1(p)\n",
      "=nullity=nullity??.????1en???100...1??111...1Thusby\n",
      "Theorem13,wegetCCdim(?0-1)?n?1.Combinedwiththeupperboundof\n",
      "Lemma10,thisgivesCCdim(?0-1)=n?1.7ForasetC?Rnandpointp?\n",
      "C,theconeoffeasibledirectionsofCatpisde?nedasFA(p)=\n",
      "f\n",
      "v?Rn:??0\n",
      ">0suchthatp+?v?C???(0,?0)\n",
      "g\n",
      ".8Hererelint(?n)denotestherelative\n",
      "interiorof?n:relint(?n)=\n",
      "f\n",
      "p??n:py>0?y?[n]\n",
      "g\n",
      ".\n",
      "7\n",
      "5\n",
      "ApplicationtoPairwiseSubsetRanking\n",
      "9\n",
      "\n",
      "Weconsideranapplicationoftheaboveframeworktoanalyzingcertain\n",
      "typesofsubsetrankingproblems,whereeachinstancex?Xconsistsofaquery\n",
      "togetherwithasetofrdocuments(forsimplicity,r?Nhereis?xed),andthe\n",
      "goalistolearnapredictorwhichgivensuchaninstancewillreturnaranking\n",
      "(permutation)oftherdocuments[8].Duchietal.[10]showedrecentlythat\n",
      "forcertainpairwisesubsetrankinglosses?,?ndingapredictorthatminimizes\n",
      "the?-riskisanNP-hardproblem.Theyalsoshowedthatseveralcommonpair-\n",
      "wiseconvexsurrogatelossesthatoperateonT?=Rr(andareusedtolearn\n",
      "scoresfortherdocuments)failtobeclassi?cationcalibratedwithrespectto\n",
      "suchlosses?,evenundersomelow-noiseconditionsonthedistribution,and\n",
      "proposedanalternativeconvexsurrogate,alsooperatingonT?=Rr,thatis\n",
      "classi?cationcalibratedundercertainconditionsonthedistribution(i.e.overa\n",
      "strictsubsetoftheassociatedprobabilitysimplex).Hereweprovideanalterna-\n",
      "tiveroutetoanalyzingthedif?cultyofobtainingconsistentsurrogatesforsuch\n",
      "pairwisesubsetrankingproblemsusingtheclassi?cationcalibrationdimension.\n",
      "Speci?cally,wewillshowthatevenforasimplesettingofsuchproblems,the\n",
      "classi?cationcalibrationdimensionoftheunderlyingloss?isgreaterthanr,\n",
      "andthereforenoconvexsurrogateoperatingonT??Rrcanbeclassi?cation\n",
      "calibratedw.r.t.suchalossoverthefullprobabilitysimplex.Formally,wewill\n",
      "identifythesetofclasslabelsYwithasetGof?preferencegraphs?,whichare\n",
      "simplydirectedacyclicgraphs(DAGs)overrvertices;foreachdirectededge\n",
      "(i,j)inapreferencegraphg?Gassociatedwithaninstancex?X,thei-th\n",
      "documentinthedocumentsetinxispreferredoverthej-thdocument.Here\n",
      "wewillconsiderasimplesettingwhereeachpreferencegraphhasexactlyone\n",
      "edge,sothat|Y|=|G|=r(r?1);inthissetting,wecanassociateeach\n",
      "g?Gwiththeedge(i,j)itcontains,whichwewillwriteasg(i,j).Thetarget\n",
      "labelsconsistofpermutationsoverrobjects,sothatT=Srwith|T|=\n",
      "r!.Considernowthefollowingsimplepairwiseloss?pair:Y?T?R+:??\n",
      "?pair(g(i,j),?)=1?(i)>?(j).(7)11Letp=(r(r?1),...,r(r?1))??\n",
      "relint(?r(r?1)),andobservethatp??pair=?\n",
      "Thusp\n",
      "?\n",
      "(?pair?\n",
      "?\n",
      "?pair??)\n",
      "=0??,??T,andsop??\n",
      "Qpair?\n",
      "???T.\n",
      "12\n",
      "forall??T.\n",
      "Let(?1,...,?r!)beany?xedorderingofthepermutationsinT,\n",
      "andconsiderQpair?1,de?nedbypair??)?0fort=2,...,r!and\n",
      "theintersectionofr!?1half-spacesoftheformq?(?pair?1?tthesimplex\n",
      "constraintsq??r(r?1).Moreover,fromtheaboveobservation,p?Qpair?1\n",
      "satis?espair??)=0?t=2,...,r!.Therefore,byLemma14,wegetp?\n",
      "10\n",
      "\n",
      "(?pair?1?t?????pairpairpair?Qpair(p)=nullity(?pair,?1???2),...\n",
      ",(??1???r!),e?1\n",
      "(8)\n",
      "T\n",
      "g\n",
      "spansawhereeisther(r?1)?1allonesvector.Itisnothardtosee\n",
      "thattheset\n",
      "f\n",
      "?pair?:???r(r?1)?r(r?1)dimensionalspace,andhencethe\n",
      "nullityoftheabovematrixisatmostr(r?1)??1.22??r(r?1)+1?1=?\n",
      "2.InThusbyTheorem13,wegetthatCCdim(?pair)?r(r?1)?r(r?1)2\n",
      "2pairparticular,forr?5,thisgivesCCdim(?)>r,andthereforeestablishes\n",
      "thatnoconvexsurrogate?operatingonasurrogatetargetspaceT??Rrcan\n",
      "beclassi?cationcalibratedwithrespectto?paironthefullprobabilitysimplex\n",
      "?r(r?1).\n",
      "6\n",
      "Conclusion\n",
      "Wedevelopedaframeworkforanalyzingconsistencyforgeneralmulticlass\n",
      "learningproblemsde?nedbyagenerallossmatrix,introducedthenotionof\n",
      "classi?cationcalibrationdimensionofamulticlassloss,andusedthistoan-\n",
      "alyzeconsistencypropertiesofsurrogatelossesforvariousgeneralmulticlass\n",
      "problems.Aninterestingdirectionwouldbetodevelopagenericprocedure\n",
      "fordesigningconsistentconvexsurrogatesoperatingona?minimal?surrogate\n",
      "targetspaceaccordingtotheclassi?cationcalibrationdimensionofthelossma-\n",
      "trix.Itwouldalsobeofinteresttoextendtheresultsheretoaccountfornoise\n",
      "conditionsasin[9,10].8\n",
      "AcknowledgmentsWewouldliketothanktheanonymousreviewersforhelp-\n",
      "fulcomments.HGthanksMicrosoftResearchIndiaforatravelgrant.Thisre-\n",
      "searchissupportedinpartbyaRamanujanFellowshiptoSAfromDSTandan\n",
      "Indo-USJointCenterAwardfromtheIndo-USScience&TechnologyForum.\n",
      "2References\n",
      "[1]G?aborLugosiandNicolasVayatis.Onthebayes-riskconsistencyofregu-\n",
      "larizedboostingmethods.AnnalsofStatistics,32(1):30?55,2004.[2]Wenxin\n",
      "Jiang.ProcessconsistencyforAdaBoost.AnnalsofStatistics,32(1):13?29,\n",
      "2004.[3]TongZhang.Statisticalbehaviorandconsistencyofclassi?cation\n",
      "methodsbasedonconvexriskminimization.AnnalsofStatistics,32(1):56?134,\n",
      "2004.[4]IngoSteinwart.Consistencyofsupportvectormachinesandotherreg-\n",
      "ularizedkernelclassi?ers.IEEETransactionsonInformationTheory,51(1):128?142,\n",
      "2005.[5]PeterBartlett,MichaelJordan,andJonConvexity,classi?cation\n",
      "andriskbounds.JournaloftheAmericanStatisticalAssociation,101(473):138?156,\n",
      "2006.[6]TongZhang.Statisticalanalysisofsomemulti-categorylargemar-\n",
      "ginclassi?cationmethods.JournalofMachineLearningResearch,5:1225?1251,\n",
      "2004.[7]AmbujTewariandPeterBartlett.Ontheconsistencyofmulticlass\n",
      "classi?cationmethods.JournalofMachineLearningResearch,8:1007?1025,\n",
      "2007.[8]DavidCossockandTongZhang.Statisticalanalysisofbayesoptimal\n",
      "subsetranking.IEEETransactionsonInformationTheory,54(11):5140?5154,\n",
      "2008.[9]FenXia,Tie-YanLiu,JueWang,WenshengZhang,andHangLi.\n",
      "11\n",
      "\n",
      "Listwiseapproachtolearningtorank:Theoryandalgorithm.InInterna-\n",
      "tionalConferenceonMachineLearning,2008.[10]JohnDuchi,LesterMackey,\n",
      "andMichaelJordan.Ontheconsistencyofrankingalgorithms.InInterna-\n",
      "tionalConferenceonMachineLearning,2010.[11]PradeepRavikumar,Ambuj\n",
      "Tewari,andEunhoYang.OnNDCGconsistencyoflistwiserankingmethods.\n",
      "InInternationalConferenceonArti?cialIntelligenceandStatistics(AISTATS),\n",
      "volume15.JMLR:W&CP,2011.[12]DavidCl?ementCalauz`enes,\n",
      "PatrickGallinari,andNicolasUsunier.Learningscoringfunctionswithorder-\n",
      "preservinglossesandstandardizedsupervision.InInternationalConferenceon\n",
      "MachineLearning,2011.[13]WeiGaoandZhi-HuaZhou.Ontheconsistency\n",
      "ofmulti-labellearning.InConferenceonLearningTheory,2011.[14]Wojciech\n",
      "Kotlowski,KrzysztofDembczynski,andEykeHuellermeier.Bipartiteranking\n",
      "throughminimizationofunivariateloss.InInternationalConferenceonMachine\n",
      "Learning,2011.[15]IngoSteinwart.Howtocomparetlossfunctionsand\n",
      "theirrisks.ConstructiveApproximation,26:225?287,2007.[16]BenTaskar,\n",
      "CarlosGuestrin,andDaphneKoller.Max-marginMarkovnetworks.InNeural\n",
      "InformationProcessingSystems,2003.[17]DeirdreO?Brien,MayaGupta,and\n",
      "RobertGray.Cost-sensitivemulti-classclassi?cationfromprobabilityestimates.\n",
      "InInternationalConferenceonMachineLearning,2008.[18]NicolasLambert\n",
      "andYoavShoham.Elicitingtruthfulanswerstomultiple-choicequestions.In\n",
      "ACMConferenceonElectronicCommerce,2009.[19]DimitriBertsekas,An-\n",
      "geliaNedic,andAsumanOzdaglar.ConvexAnalysisandOptimization.Athena\n",
      "Scienti?c,2003.[20]JeanGallier.Notesonconvexsets,polytopes,polyhedra,\n",
      "combinatorialtopology,VoronoidiagramsandDelaunaytriangulations.Tech-\n",
      "nicalreport,DepartmentofComputerandInformationScience,Universityof\n",
      "Pennsylvania,2009.[21]ElodieVernet,RobertC.Williamson,andMarkD.\n",
      "Reid.Compositemulticlasslosses.InNeuralInformationProcessingSystems,\n",
      "2011.9\n",
      "12\n",
      "\n",
      "PP5582.pdf\n",
      "PP5582.pdf 12\n",
      "ApproximatingHierarchicalMV-setsfor\n",
      "HierarchicalClustering\n",
      "Authoredby:\n",
      "ShaulMarkovitch\n",
      "AssafGlazer\n",
      "MichaelLindenbaum\n",
      "OmerWeissbrod\n",
      "Abstract\n",
      "Thegoalofhierarchicalclusteringistoconstructaclustertree,which\n",
      "canbeviewedasthemodalstructureofadensity.Forthispurpose,we\n",
      "useaconvexoptimizationprogramthatcantlyestimateafamily\n",
      "ofhierarchicaldensesetsinhigh-dimensionaldistributions.Wefurther\n",
      "extendexistinggraph-basedmethodstoapproximatetheclustertreeofa\n",
      "distribution.Byavoidingdirectdensityestimation,ourmethodisableto\n",
      "handlehigh-dimensionaldatamoretlythanexistingdensity-based\n",
      "approaches.Wepresentempiricalresultsthatdemonstratethesuperiority\n",
      "ofourmethodoverexistingones.\n",
      "1PaperBody\n",
      "Dataclusteringisaclassicunsupervisedlearningtechnique,whosegoalisdivid-\n",
      "inginputdataintodisjointsets.Standardclusteringmethodsattempttodivide\n",
      "inputdataintodiscretepartitions.InHierarchicalclustering,thegoalisto\n",
      "nestedpartitionsofthedata.Thenestedpartitionsrevealthemodalstructure\n",
      "ofthedatadensity,whereclustersareassociatedwithdenseregions,separated\n",
      "byrelativelysparseones[27,13].Underthenonparametricassumptionthatthe\n",
      "dataissampledi.i.d.fromacontinuousdistributionFwithLebesguedensityf\n",
      "inRd,Hartiganobservedthatfhasahierarchicalstructure,calleditscluster\n",
      "tree.DenoteLf(c)=\n",
      "f\n",
      "x:f(x)?c\n",
      "g\n",
      "asthelevelsetoffatlevelc.Then,the\n",
      "connectedcomponentsinLf(c)arethehigh-densityclustersatlevelc,andthe\n",
      "collectionofallhigh-densityclustersforcT?0hasahierarchicalstructure,\n",
      "whereforanytwoclustersAandB,eitherA?B,B?A,orAB=?.\n",
      "Lf?c?0.23?Lf?c?0.11?\n",
      "Figure1:Aunivariate,tri-modaldensityfunctionanditscorresponding\n",
      "clustertreeareillustrated.Figure1showsaplotofaunivariate,tri-modal\n",
      "densityfunction.TheclustertreeofthedensityF?0.67functionisshownon\n",
      "1\n",
      "\n",
      "topofthedensityfunction.Thehigh-densityclustersarenodesinthecluster\n",
      "tree.Leavesareassociatedwithmodesinthedensityfunction.66.7%\n",
      "66.7%\n",
      "33.3%\n",
      "33.3%\n",
      "1\n",
      "F?0.5\n",
      "Giventhedensityf,theclustertreecanbeconstructuredinastraightfor-\n",
      "wardmannerviaarecursivealgorithm[23].Westartbysettingtherootnode\n",
      "withasingleclustercontainingtheentirespace,correspondingtoc=0.We\n",
      "thenrecursivelyincreasecuntilthenumberofconnectedcomponentsincreases,\n",
      "atwhichpointweanewlevelofthetree.Theprocessisrepeatedaslong\n",
      "asthenumberofconnectedcomponentsincreases.InFigure1,forexample,\n",
      "therootnodehastwodaughternodes,whichwerefoundatlevelc=0.11.The\n",
      "nexttwodescendantsoftheleftnodewerefoundatlevelc=0.23.Acommon\n",
      "approachforhierarchicalclusteringistouseadensityestimationmethodto\n",
      "obtainf[18,5,23],andthenestimatetheclustertreeusingtherecursivemethod\n",
      "describedabove.However,onemajordrawbackinthisapproachisthatareli-\n",
      "abledensityestimationishardtoobtain,especiallyinhigh-dimensionaldata.\n",
      "Analternativeapproachistoestimatethelevelsetsdirectly,withoutaseparate\n",
      "densityestimationstep.Todoso,wetheminimumvolumeset(MV-set)\n",
      "atlevel?asthesubsetoftheinputspacewiththesmallestvolumeandprobabil-\n",
      "itymassofatleast?.MV-setsofadistribution,whicharealsolevelsetsofthe\n",
      "densityf(undertregularityconditions),arehierarchicalby\n",
      "Thewell-knownOne-ClassSVM(OCSVM)[20]cantlytheMV-set\n",
      "atasplevel?.AnaiveapproachforingahierarchyofMV-setsisto\n",
      "traindistinctOCSVMs,oneforeachMV-set,andenforcehierarchybyinter-\n",
      "sectionoperationsontheoutput.However,thissolutionisnotwellsuitedfor\n",
      "asetofhierarchicalMV-sets,becausethenaturalhierarchyofMV-sets\n",
      "isnotexploited,leadingtoasuboptimalsolution.Inthisstudywepropose\n",
      "anovelmethodforconstructingclustertreesbydirectlyestimatingMV-sets,\n",
      "whileguaranteeingconvergencetoagloballyoptimumsolution.Ourmethod\n",
      "utilizestheq-OneClassSVM(q-OCSVM)method[11],whichcanberegarded\n",
      "asanaturalextensionoftheOCSVM,tojointlytheMV-setsatasetof\n",
      "levels\n",
      "f\n",
      "?i\n",
      "g\n",
      ".Byavoidingdirectdensityestimation,ourmethodisabletohandle\n",
      "high-dimensionaldatamoretlythanexistingdensity-basedapproaches.\n",
      "Byjointlyconsideringtheentirespectrumofdesiredlevels,agloballyoptimum\n",
      "solutioncanbefound.Wecombinethisapproachwithagraph-basedheuristic,\n",
      "foundtobesuccessfulinhigh-dimensionaldata[2,23],forhighdensity\n",
      "clustersintheapproximatedMV-sets.,weconstructafullyconnected\n",
      "graphwhosenodescorrespondtofeaturevectors,andremoveedgesbetween\n",
      "nodesconnectedbylow-densityregions.Theconnectedcomponentsinthere-\n",
      "sultinggraphcorrespondtohighdensityclusters.Theadvantageofourmethod\n",
      "isdemonstratedempiricallyonsyntheticandrealdata,includingareconstruc-\n",
      "tionofanevolutionarytreeofhumanpopulationsusingthehigh-dimensional\n",
      "1000genomesdataset.\n",
      "2\n",
      "\n",
      "2\n",
      "Background\n",
      "Ournovelmethodforhierarchicalclusteringbelongstoafamilyofnon-\n",
      "parametricclusteringmethods.Unlikeparametricmethods,whichassumethat\n",
      "eachgroupiisassociatedwithadensitybelongingtosomefamilyofpara-\n",
      "metricdensities,non-parametricmethodsassumethateachgroupisassociated\n",
      "withmodesofadensityf[27].Non-parametricmethodsaimtorevealthemodal\n",
      "structureoff[13,28,14].Hierarchicalclusteringmethodscanbedividedinto\n",
      "agglomerative(bottomup)anddivisive(topdown)methods.Agglomerative\n",
      "methods(e.g.single-linkage)startwithnsingletonclusters,oneforeachtrain-\n",
      "ingfeaturevector,andworkbyiterativelylinkingtwoclosestclusters.Divisive\n",
      "methods,ontheotherhand,startwithallfeaturevectorsinasinglecluster\n",
      "andrecursivelydivideclustersintosmallersub-clusters.Whilesingle-linkage\n",
      "wasfound,intheory,tohavebetterstabilityandconvergencepropertiesin\n",
      "comparisontoaverage-linkageandcomplete-linkage[4],itisfrequentlycrit-\n",
      "icizedbypractitionersduetothechainingSingle-linkageignoresthe\n",
      "densityoffeaturevectorsinclusters,andthusmayerroneouslyconnecttwo\n",
      "modes(clusters)withafewfeaturevectorsconnectingthem,thatis,a?chain?\n",
      "offeaturevectors.Wishart[27]suggestedovercomingthisbyconducting\n",
      "aone-levelanalysisofthedata.Theideaistoestimateasplevelsetof\n",
      "thedatadensity(Lf(c)),andtoremovenoisyfeatures2\n",
      "outsidethislevelthatcouldotherwiseleadtothechainingThecon-\n",
      "nectedcomponentsleftinLf(c)aretheclusters;expansionsofthisideacan\n",
      "befoundin[9,26,6,3].Indeed,thisanalysisismoreresistanttothechain-\n",
      "ingHowever,oneofitsmajordrawbacksisthatnosinglelevelsetcan\n",
      "revealallthemodesofthedensity.Therefore,variousstudieshaveproposed\n",
      "estimatingtheentirehierarchicalstructureofthedata(theclustertree)using\n",
      "densityestimates[13,1,22,18,5,23,17,19].Thesemethodsareconsideredas\n",
      "divisivehierarchicalclusteringmethods,astheystartbyassociatingallfeature\n",
      "vectorstotherootnode,whichisthenrecursivelydividedtosub-clustersby\n",
      "incrementallyexploringlevelsetsofdenserregions.Ourproposedmethodbe-\n",
      "longstothisgroupofdivisivemethods.Stuetzle[22]usedthenearestneighbor\n",
      "densityestimatetoconstructtheclustertreeandpointedoutitsconnectionto\n",
      "single-linkageclustering.Kerneldensityestimateswereusedinotherstudies\n",
      "[23,19].ThebisectingK-means(BiKMean)methodisanotherdivisivemethod\n",
      "thatwasfoundtoworkelyinclusteranalysis[16],althoughitprovides\n",
      "notheoreticalguaranteeforthecorrectclustertreeoftheunderlying\n",
      "density.Hierarchicalclusteringmethodscanbeusedasanexplorationtool\n",
      "fordataunderstanding[16].Thenonparametricassumption,bywhichdensity\n",
      "modescorrespondtohomogenousfeaturevectorswithrespecttotheirclassla-\n",
      "bels,canbeusedtoinferthehierarchicalclassstructureofthedata[15].An\n",
      "implicitassumptionisthattheclosertwofeaturevectorsare,thelesslikely\n",
      "theywillbetohaventclasslabels.Interestingly,thisassumption,which\n",
      "doesnotnecessarilyholdforalldistributions,isbeingdiscussedlatelyinthe\n",
      "contextofhierarchicalsamplingmethodsforactivelearning[8,7,25],where\n",
      "thecorrectnessofsuchahierarchicalmodelingapproachissaidtodependon\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the?ProbabilisticLipschitzness?assumptionaboutthedatadistribution.\n",
      "3\n",
      "ApproximatingMV-setsforHierarchicalClustering\n",
      "Ourproposedmethodconsistsof(a)estimatingMV-setsusingtheq-OCSVM\n",
      "method;(b)usingagraph-basedmethodforahierarchyofhighdensity\n",
      "regionsintheMV-sets,and(c)constructingaclustertreeusingtheseregions.\n",
      "Thesestagesaredescribedindetailbelow.3.1\n",
      "EstimatingMV-Sets\n",
      "WebeginbydescribingtheOne-ClassSVM(OCSVM)method.Let\n",
      "X=\n",
      "f\n",
      "x1,...,xn\n",
      "g\n",
      "beasetoffeaturevectorssampledi.i.d.withrespect\n",
      "toF.ThefunctionfCreturnedbytheOCSVMalgorithmisspbythe\n",
      "solutionofthisquadraticprogram:11Xminn||w||2??+?i,w?F\n",
      ",??R,??R2?ni(1)s.t.(w??(xi))????i,?i?0,where?isavectorof\n",
      "theslackvariables.Recallthatalltrainingexamplesxiforwhich(w??(x))??\n",
      "?0arecalledsupportvectors(SVs).Outliersarereferredtoasexamplesthat\n",
      "strictlysatisfy(w??(x))??<0.Bysolvingtheprogramfor?=1??,we\n",
      "canusetheOCSVMtoapproximatetheMV-setC(?).Let0<?1<?2,...\n",
      ",<?q<1beasequenceofqquantiles.Theq-OCSVMmethodgeneralizesthe\n",
      "OCSVMalgorithmforapproximatingasetofMV-sets\n",
      "f\n",
      "C1,...,Cq\n",
      "g\n",
      "such\n",
      "thatahierarchyconstraintCi?Cjisfori<j.GivenX,theq-OCSVM\n",
      "algorithmsolvesthisprimalprogram:min\n",
      "w,?j,?j\n",
      "qqXX1Xq||w||2??j+?j,i2?nij=1j=1j\n",
      "(2)\n",
      "s.t.(w??(xi))??j??j,i,?j,i?0,j?[q],i?[n],where?j=1??j.\n",
      "ThisprogramgeneralizesEquation(1)tothecaseofndingmultiple,parallel\n",
      "half-spacedecisionfunctionsbysearchingforaglobalminimumovertheirsum\n",
      "ofobjectivefunctions:thecouplingbetweenqhalf-spacesisdonebysumming\n",
      "qOCSVMprograms,whileforcingtheseprogramstosharethesamew.Asa\n",
      "result,theqhalf-spacesinthesolutionofEquation(2)onlybytheirbias\n",
      "terms,andarethusparalleltoeachother.Thisprogramisconvex,andthusa\n",
      "globalminimumcanbefoundinpolynomialtime.3\n",
      "Glazeretal.[11]provesthattheq-OCSVMalgorithmcanbeusedtoap-\n",
      "proximatetheMV-setsofadistribution.3.1.1\n",
      "Generalizingq-OCSVMforFindinganNumberofApproximated\n",
      "MV-sets\n",
      "Theq-OCSVManumberofqapproximatedMV-sets,whichcap-\n",
      "turetheoverallstructureoftheclustertree.However,inordertobetterresolve\n",
      "indensitylevelsbetweendatapoints,wewouldlikethesolutionto\n",
      "beextendedforannumberofhierarchicalsets.Ourapproach\n",
      "fordoingsoreliesontheparallelismpropertyoftheapproximatedMV-setsin\n",
      "theq-OCSVMsolution.AnnumberofapproximatedMV-setsareasso-\n",
      "ciatedwithseparatinghyperplanesinFthatareparalleltotheqhyperplanes\n",
      "intheq-OCSVMsolution.Notethateveryprojectedfeaturevector?(x)lieson\n",
      "auniqueseparatinghyperplanethatisparalleltotheqhyperplanesby\n",
      "thesolution,andthedistancedis(x)=(w??(x))??isttodetermine\n",
      "4\n",
      "\n",
      "whetherxislocatedinsideeachoftheapproximatedMV-sets.Wewouldlike\n",
      "toknowtheprobabilitymassassociatedwitheachofthehyperplanes.\n",
      "Forthispurpose,wecouldsimilarlyestimatetheexpectedprobabilitymassof\n",
      "theapproximatedMVsetforanyx?Rd.When?(x)liesstrictlyon\n",
      "oneofthei?[q]hyperplanes,thenxisconsideredaslyingontheboundaryof\n",
      "thesetapproximatingC(?i).When?(x)doesnotsatisfythiscondition,weuse\n",
      "alinearinterpolationto?foritscorrespondingapproximatedMV-set:\n",
      "Let?i,?i+1bethebiastermsassociatedwiththeiandi+1approximated\n",
      "MV-setsthatsatisfy?i>(w??(x))>?i+1.Thenwelinearlyinterpolate(w\n",
      "??(x))alongthe[?i+1,?i]intervalforanintermediate??(?i,?i+1).For\n",
      "thecompletionoftheweset?0=maxx?X(w??(x))and?q+1=\n",
      "minx?X(w??(x)).3.2\n",
      "FindingaHierarchyofHigh-DensityRegions\n",
      "Toahierarchyofhighdensityregions,weadoptagraph-basedapproach.\n",
      "Weconstructafully-connectedgraphwhosenodescorrespondtofeaturevec-\n",
      "tors,andremoveedgesbetweennodesseparatedbylow-densityregions.The\n",
      "connectedcomponentsintheresultinggraphcorrespondtohighdensityregions.\n",
      "Themethodproceedsasfollows.Let?(x)betheexpectedprobabilitymassof\n",
      "theapproximatedMV-setbyx.Let?i,sbethemaximalvalueof?(x)\n",
      "overthelinesegmentconnectingthefeaturevectorsxiandxsinX:?i,s=max\n",
      "?(txi+(1?t)xs).t?[0,1]\n",
      "(3)\n",
      "LetGbeacompletegraphbetweenpairsoffeaturevectorsinXwithedges\n",
      "equalto?i,s1.Highdensityclustersatlevel?aredenedastheconnected\n",
      "componentsinthegraphG(?)inducedbyremovingedgesfromGwith?i,s>?.\n",
      "Thismethodguaranteesthattwofeaturevectorsinthesameclusteroftheap-\n",
      "proximatedMV-setatlevel?wouldsurelylieinthesameconnectedcomponent\n",
      "inG(?).However,theoppositewouldnotnecessaryhold?when?i,s>?and\n",
      "acurveconnectingxiandxsexistsinthecluster,xiandxsmighterroneously\n",
      "befoundintconnectedcomponents.Nevertheless,itwasempirically\n",
      "shownthaterroneoussplitsofclustersarerareifthedensityfunctionissmooth\n",
      "[23].Onewaytoimplementthismethodforhighdensityclustersis\n",
      "toiterativelyndconnectedcomponentsinG(?),whenateachiteration?is\n",
      "incrementallyincreased(startingfrom?=0),untilalltheclustersarefound.\n",
      "However,[23]observedthatwecansimplifythismethodbyworkingonlyon\n",
      "thegraphGanditsminimalspanningtreeT.Consequently,wecancompute\n",
      "ahierarchyofhigh-densityregionsintwosteps:First,constructGanditsmin-\n",
      "imalspanningtreeT.Then,removeedgesfromTindescendingorderoftheir\n",
      "weightssuchthattheconnectedcomponentsleftafterremovinganedgewith\n",
      "weight?correspondtoahighdensityclusteratlevel?.Connectedcomponents\n",
      "withasinglefeaturevectoraretreatedasoutliersandremoved.1Wecalculated\n",
      "?i,sinGbycheckingthe?(x)valuesfor20pointssampledfromthelinesegment\n",
      "betweenxiandxs.Thesameapproachwasalsousedby[2]and[23].\n",
      "4\n",
      "3.3\n",
      "ConstructingaClusterTree\n",
      "5\n",
      "\n",
      "Thehierarchyresultingfromtheproceduredescribedabovedoesnotform\n",
      "afullpartitionofthedata,asineachedgeremovalstepafractionofthe\n",
      "dataisleftoutsidethenewlyformedhighdensityclusters.Toconstructafull\n",
      "partition,featurevectorsleftoutsideateachstepareassignedtotheirnearest\n",
      "cluster.Additionally,whenaclusterissplitintosub-clusters,allitsassigned\n",
      "featurevectorsareassignedtooneofthenewsub-clusters.Thechoiceofkernel\n",
      "widthhasastrongontheresultingclustertree.Ontheonehand,a\n",
      "largebandwidthmayleadtotheinnerproductsinducedbythekernelfunction\n",
      "beingconstant;thatis,manyexamplesinthetraindataareprojectedtothe\n",
      "samepointinF.Hence,theapproximatedMV-setscouldeventuallybeequal,\n",
      "resultinginaclustertreewithasinglenode.Ontheotherhand,asmall\n",
      "bandwidthmayleadtotheinnerproductsbecomingclosertozero;thatis,\n",
      "pointsinFtendtolieonorthogonalaxes,resultinginaclustertreewithmany\n",
      "branchesandleaves.Webelievethatthebestapproachforchoosingthecorrect\n",
      "bandwidthisbasedonthenumberofmodesthatweexpecttoforthe\n",
      "densityfunction.Byusingagridsearchoverpossible?values,wecanchoose\n",
      "thebandwidththatresultsinaclustertreeinwhichtheexpectednumberof\n",
      "modesisthesameasthenumberweexpect.\n",
      "4\n",
      "EmpiricalAnalysis\n",
      "Weevaluateourhierarchicalclusteringmethodonsyntheticandrealdata.\n",
      "Whilethequalityofanestimatedclustertreeforthesyntheticdatacanbe\n",
      "evaluatedbycomparingtheresultingtreewiththetruemodalstructureofthe\n",
      "density,alternativequalitymeasuresarerequiredtoestimatetheof\n",
      "hierarchicalclusteringmethodsonhigh-dimensionaldatawhenthedensityis\n",
      "unknown.Inthefollowingsectionweintroduceourproposedmeasure.4.1\n",
      "TheQualityMeasure\n",
      "OneprominentmeasureistheF-measure,whichwasextendedby[16]to\n",
      "evaluatethequalityofestimatedclustertrees.Recallthatclassesrefertothe\n",
      "true(unobserved)classassignmentoftheobservedvectors,whereasclusters\n",
      "refertotheirtree-assignedpartition.Foraclusterjandclassi,ni,jas\n",
      "thenumberoffeaturevectorsofclassiinclusterj,andni,njasthenumber\n",
      "offeaturevectorsassociatedwithclassiandwithclusterj,respectively.The\n",
      "F-measureforclusterjandclass2?Recall?PrecisionnniisgivenbyFi,j\n",
      "=Recalli,ji,j+Precisioni,ji,j,whereRecalli,j=ni,jandPrecisioni,j=ni,j\n",
      ".TheijF-measurefortheclustertreeisXniF=max\n",
      "f\n",
      "Fi,j\n",
      "g\n",
      ".(4)nji\n",
      "TheF-measurewasfoundtobeausefultoolfortheevaluationofhierarchical\n",
      "clusteringmethods[21],asitquanhowwellwecouldextractkclusters,one\n",
      "foreachclass,thatarerelatively?pure?andlargeenoughwithrespecttotheir\n",
      "associatedclass.However,wefoundittousethismeasuredirectlyin\n",
      "ouranalysis,becauseitappearstopreferovedtrees,withalargenumberof\n",
      "spuriousclusters.Wesuggestcorrectingthisbiasviacross-validation.Wesplit\n",
      "thedataXintotwoequal-sizedtrainandtestsets,andconstructatreeusing\n",
      "thetrainset.Testexamplesarerecursivelyassignedtoclustersinthetreeina\n",
      "top-downmanner,andtheF-measureiscalculatedaccordingtotheresulting\n",
      "tree.Whenanalyticalboundariesofclustersinthetreearenotavailable(such\n",
      "6\n",
      "\n",
      "asinourmethod),werecursivelyassigneachtestexampleinaclustertothe\n",
      "sub-clustercontainingitsnearestneighborinthetrainset,usingEuclidean\n",
      "distance.4.2\n",
      "ReferenceMethods\n",
      "Wecompareourmethodwithmethodsfordensityestimation,thatcanalso\n",
      "beusedtoconstructagraphG.Forthispurpose,sincef(x)isusedinsteadof\n",
      "?(x),wehadtoadjustthewayweconstruct5\n",
      "GandT2.Akerneldensityestimator(KDE)andnearestneighborden-\n",
      "sityestimator(NNE),similartotheoneusedby[23],areusedascompeting\n",
      "methods.Inaddition,wecompareourmethodwiththebisectingK-means\n",
      "(BiKMean)method[21]forhierarchicalclustering.4.3\n",
      "ExperimentswithSyntheticData\n",
      "Werunourhierarchicalclusteringmethodondatasampledfromasynthetic,\n",
      "two-dimensional,trimodaldistribution.Thisdistributionisbya3-\n",
      "Gaussianmixturedistribution.20i.i.d.pointsweresampledfortrainingour\n",
      "q-OCSVMmethod,with?1=0.25,?2=0.5,?3=0.75(3-quantiles),andwith\n",
      "abandwidth?,whichresultsinaclustertreewith3modes.Theleftsideof\n",
      "Figure2showsthedatasampled,andthe3approximatedhierarchicalMV-sets.\n",
      "TheresultingQ=3,N=20,?=153-modesclustertreeisshownintherightside\n",
      "ofFigure2.2.52Leaf1:\n",
      "f\n",
      "1\n",
      "g\n",
      "1.51\n",
      "Branch4:\n",
      "f\n",
      "12\n",
      "g\n",
      ",P=0.68\n",
      "0.50\n",
      "Leaf2:\n",
      "f\n",
      "2\n",
      "g\n",
      "?0.5\n",
      "Branch5:\n",
      "f\n",
      "123\n",
      "g\n",
      ",P=0.85\n",
      "?1?1.5?2\n",
      "Leaf3:\n",
      "f\n",
      "3\n",
      "g\n",
      "?0.5\n",
      "?2.5?2.5\n",
      "?2\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "0\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "0\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "2.5\n",
      "Figure2:Left:Datasampledfortrainingourq-OCSVMmethodandthe\n",
      "3approximatedMV-sets;Right:Theclustertreeestimatedfromthesynthetic\n",
      "7\n",
      "\n",
      "data.Themostfrequentlabelineachmode,denotedincurlybracketsnext\n",
      "toeachleaf,deesthelabelofthemode.Branchesarelabeledwiththe\n",
      "probabilitymassassociatedwiththeirlevelset..Weusedourproposedand\n",
      "referencemethodonthedatatoobtainclustertreeswithtnumbersof\n",
      "modes(leaves).Thenumberofmodescanbetweakedbychangingthevalueof\n",
      "?fortheqOCSVMandKDEmethods,andbypruningnodesofsmallsizefor\n",
      "theNNEandBiKMeanmethods.20testexampleswerei.i.d.sampledfromthe\n",
      "samedistributiontoestimatetheresultingF-measures.TheleftsideofFigure\n",
      "3showstheF-measureforeachmethodintermsofchangesinthenumberof\n",
      "modesintheresultingtree.Forallmethods,theF-measureisboundedby\n",
      "0.8aslongasthenumberofmodesisgreaterthan3,correctlysuggestingthe\n",
      "presenceof3modesforthedata.4.4\n",
      "Theoliveoildataset\n",
      "Theoliveoildataset[10]consistsof572oliveoilexamples,with8features\n",
      "each,from3regionsinItaly(R1,R2,R3),eachonefurtherdividedinto3\n",
      "sub-areas.TherightsideofFigure3showstheF-measureforeachmethodin\n",
      "termsofchangesinthenumberofmodesinthetree.Theq-OCSVMmethod\n",
      "dominatestheotherthreemethodswhenthenumberofmodesishigherthan5,\n",
      "withanaverageF=0.62,whileitsbestcompetitor(KDE)hasanaverageF=\n",
      "0.55.ItcanbeseenthatthevariabilityoftheF-measureplotsishigherforthe\n",
      "q-OCSVMandKDEmethodsthanfortheBiKMeansandNNEmethods.This\n",
      "isaconsequenceofthefactthatthestructureofunprunednodesremainsthe\n",
      "samefortheBiKMeansandNNEmethods,whereast?valuesmaylead\n",
      "todrenttreestructuresfortheq-OCSVMandKDEmethods.Thecluster\n",
      "treesestimatedusingtheq-OCSVMandKDEmethodsareshowninFigure4.\n",
      "Foreachmethod,wechosetoshowtheclustertreewiththesmallestnumberof\n",
      "modeswithleavescorrespondingtoall8labels.Theq-OCSVMmethodgroups\n",
      "leavesassociatedwiththe8areasinto3clusters,whichperfectlycorresponds\n",
      "tothehierarchicalstructureofthelabels.Incontrast,modesestimatedusing\n",
      "theKDEmethodcannotbegroupedinto3homogeneousclusters.2Whena\n",
      "densityestimatorfisused,pi,s=mint?[0,1]p(tf(xi)+(1?t)f(xs))areset\n",
      "tobetheedgeweights,G(c)isinducedbyremovingedgesfromGwithpi,s<c,\n",
      "andTisasthemaximalspanningtreeofG(insteadoftheminimal).\n",
      "6\n",
      "CCvs.F\n",
      "CCvs.F\n",
      "0.85\n",
      "0.65\n",
      "0.8\n",
      "0.6\n",
      "0.75\n",
      "0.55F?Measure\n",
      "F?Measure\n",
      "0.9\n",
      "0.70.65\n",
      "0.45q-OCSVMClusterTree\n",
      "8\n",
      "\n",
      "0.6\n",
      "0.4qOCSVMKDEBiKMeansNNE\n",
      "0.550.5\n",
      "0.5\n",
      "1\n",
      "2\n",
      "3Numberofmodes\n",
      "4\n",
      "qOCSVMKDEBiKMeansNNE\n",
      "0.350.3\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "81012Numberofmodes\n",
      "14\n",
      "16\n",
      "18\n",
      "R1\n",
      "20R2\n",
      "Figure3:Left:TheF-measuresofeachmethodareplottedintermsofthe\n",
      "numberofmodesintheestimatedclustertrees.TheF-measuresarecalculated\n",
      "usingthesynthetictestdata;Right:R3Fmeasurefortheoliveoildataset,cal-\n",
      "culatedusing286testexamples,isshownintermsofthenumberofmodesin\n",
      "theclustertree.KDEClusterTree\n",
      "q-OCSVMClusterTree\n",
      "R1R1\n",
      "R2R2R3R1R3\n",
      "R3R1R1\n",
      "KDEClusterTree\n",
      "Figure4:Left:Clustertreefortheoliveoildataestimatedwithq-OCSVM;\n",
      "Right:ClustertreeforR1theoliveoildataestimatedwithKDE.Oneprominent\n",
      "advantageofourmethodisthatwecanusetheestimatedprobabilitymassof\n",
      "branchesinthetreetobetterunderstandtheR2modalstructureofthedata.For\n",
      "instance,wecanlearnfromFigure4thattheR2clusterisfoundinarelatively\n",
      "sparseMV-setatlevel0.89,whileR3itstwonodesarefoundinamuchdenser\n",
      "MV-setatlevel0.12.Probabilitymassesforhighdensityclusterscanalsobe\n",
      "estimatedusingtheKDEmethod,butunlikeourmethod,theoreticalguarantees\n",
      "R1R3arenotprovided.R1R1\n",
      "The1000genomesdataset\n",
      "4.5\n",
      "Wehavealsoevaluatedourmethodonthe1000genomesdataset[24].Hier-\n",
      "archicalclusteringapproachesnaturallyariseingeneticpopulationstudies,as\n",
      "theycanreconstructtreesthatdescribeevolutionaryhistoryandareoftenthe\n",
      "9\n",
      "\n",
      "stepinevolutionarystudies[12].Thereconstructionofpopulationstruc-\n",
      "tureisalsocrucialforgeneticmappingstudies,whichsearchforgeneticfactors\n",
      "underlyinggeneticdiseases.Inthisexperimentweevaluatedourmethod?sca-\n",
      "pabilitytoreconstructtheevolutionaryhistoryofpopulationsrepresentedin\n",
      "the1000genomesdataset,whichconsistsofwholegenomesequencesof1,092\n",
      "humanindividualsfrom14distinctpopulations.Weusedatrinaryrepresenta-\n",
      "tionwhereineachindividualisrepresentedasavectoroffeaturescorresponding\n",
      "to0,1or2.Everyfeaturerepresentsaknowngeneticvariation(withrespect\n",
      "tothestandardhumanreferencegenome3),wherethenumberindicatesthe\n",
      "numberofvariedgenomecopies.Weuseddataprocessedbythe1000Genomes\n",
      "Consortium,whichinitiallycontained2.25millionvariations.Toreducedimen-\n",
      "sionality,weusedthe1,000featuresthathadthehighestinformationgainwith\n",
      "respecttothepopulations.Weexcludedfromtheanalysishighlygenetically\n",
      "admixedpopulations(Colombian,MexicanandPuerto3\n",
      "http://genomereference.org\n",
      "7\n",
      "Ricanancestry),becausetheevolutionaryhistoryofadmixedpopulations\n",
      "cannotberepresentedbyatree.Afterexclusion,911individualsremainedin\n",
      "theanalysis.q-OCSVMClusterTree\n",
      "CCvs.F0.5\n",
      "0.45\n",
      "European\n",
      "0.4\n",
      "R1\n",
      "0.35F?Measure\n",
      "0.30.250.2\n",
      "R2EastAsian\n",
      "0.150.1\n",
      "0\n",
      "KDEClusterTree\n",
      "5\n",
      "10\n",
      "15Numberofmodes\n",
      "20\n",
      "R3\n",
      "African\n",
      "qOCSVMBiKMeansSL\n",
      "0.05\n",
      "25\n",
      "Figure5:Left:F-measureforthe1000genomesdataset,calculatedusing\n",
      "455testexamples;Right:Clustertreeforthe1000genomesdataestimatedwith\n",
      "q-OCSVM.ThelabelsareGBR(BritishinEnglandandScotland),TSI(Toscani\n",
      "inItalia),CEU(UtahResidentswithNorthernandWesternR1Europeanan-\n",
      "cestry),FIN(FinnishinFinland),CHB(HanChineseinBejing,China),CHS\n",
      "(SouthernHanChinese),ASW(AmericansofAfricanAncestryinSWUSA),\n",
      "YRI(YorubainIbadan,Nigera),andLWK(LuhyainWebuye,Kenya).The\n",
      "10\n",
      "\n",
      "leftsideofFigure5showsthatq-OCSVMdominatestheothermethodsfor\n",
      "everynumberofmodestested,demonstratingitssuperiorityinR2highdimen-\n",
      "sionalsettings.Namely,itachievesanF-measureof0.4for>2modes,whereas\n",
      "competingmethodsobtainanF-measureof0.35.KDEwasnotevaluatedasit\n",
      "isnotapplicableduetoR3thehighdatadimensionality.Toobtainameaning-\n",
      "fultree,weincreasedtheR1numberofmodesuntilleavescorrespondingtoall\n",
      "threemajorhumanpopulationgroups(African,R3EastAsianandEuropean)\n",
      "representedinthedatasetappeared.Thetreeobtainedbyusing28modesR1is\n",
      "shownintherightsideofFigure5,indicatingthatq-OCSVMclusteringsuc-\n",
      "cessfullydistinguishesR1betweenthesethreepopulationgroups.Additionally,\n",
      "itcorrespondswiththewell-establishedtheorythatadivergenceofasingle\n",
      "ancestralpopulationintoAfricanandEurasianpopulationstookplaceinthe\n",
      "distantpast,andthatEurasiansdivergedintoEastAsianandEuropeanpopu-\n",
      "lationsatalatertime[12].ThelargernumberofleavesrepresentingEuropean\n",
      "populationsmayresultfromthelargernumberofEuropeanindividualsand\n",
      "populationsinthe1000genomesdataset.\n",
      "5\n",
      "Discussion\n",
      "Inthisresearchweusetheq-OCSVMmethodasaplug-inmethodforhi-\n",
      "erarchicalclusteringinhighdimensionaldistributions.Theq-OCSVMmethod\n",
      "estimatesthelevelsets(MV-sets)directlywithoutadensityestimationstep.\n",
      "Therefore,weexpecttoachievemoreaccurateresultsthanapproachesbased\n",
      "ondensityestimation.Furthermore,sinceweknow?foreachapproximated\n",
      "MV-set,webelieveoursolutionwouldbemoreinterpretableandinformative\n",
      "thanasolutionprovidedbyadensityestimation-basedmethod.\n",
      "2References\n",
      "[1]MihaelAnkerst,MarkusMBreunig,Hans-PeterKriegel,andJ?orgSander.\n",
      "Optics:orderingpointstoidentifytheclusteringstructure.ACMSIGMOD\n",
      "Record,28(2):49?60,1999.[2]AsaBen-Hur,DavidHorn,HavaTSiegelmann,\n",
      "andVladimirVapnik.Supportvectorclustering.TheJournalofMachineLearn-\n",
      "ingResearch,2:125?137,2002.[3]G?erardBiau,Beno??tCadre,andBruno\n",
      "Pelletier.Agraph-basedestimatorofthenumberofclusters.ESAIM:Proba-\n",
      "bilityandStatistics,11(1):272?280,2007.8\n",
      "[4]GunnarCarlssonandFacundoM?emoli.Characterization,stabilityand\n",
      "convergenceofhierarchicalclusteringmethods.TheJournalofMachineLearn-\n",
      "ingResearch,99:1425?1470,2010.[5]GunnarCarlssonandFacundoM?emoli.\n",
      "Multiparameterhierarchicalclusteringmethods.InasaToolfor\n",
      "Research,pages63?70.Springer,2010.[6]AntonioCuevas,ManuelFebrero,\n",
      "andRicardoFraiman.Clusteranalysis:afurtherapproachbasedondensity\n",
      "estimation.ComputationalStatistics&DataAnalysis,36(4):441?459,2001.[7]\n",
      "SanjoyDasgupta.Twofacesofactivelearning.TheoreticalComputerScience,\n",
      "412(19):1767?1781,2011.[8]SanjoyDasguptaandDanielHsu.Hierarchi-\n",
      "calsamplingforactivelearning.InICML,pages208?215.ACM,2008.[9]\n",
      "11\n",
      "\n",
      "MartinEster,Hans-PeterKriegel,J?orgSander,andXiaoweiXu.Adensity-\n",
      "basedalgorithmfordiscoveringclustersinlargespatialdatabaseswithnoise.In\n",
      "KDD,volume96,pages226?231,1996.[10]MForina,CArmanino,SLanteri,\n",
      "andETiscornia.ofoliveoilsfromtheirfattyacidcomposition.\n",
      "FoodResearchandDataAnalysis,pages189?214,1983.[11]AssafGlazer,\n",
      "MichaelLindenbaoum,andShaulMarkovitch.q-ocsvm:Aq-quantileestimator\n",
      "forhigh-dimensionaldistributions.InAdvancesinNeuralInformationPro-\n",
      "cessingSystems,pages503?511,2013.[12]I.Gronau,M.J.Hubisz,etal.\n",
      "Bayesianinferenceofancienthumandemographyfromindividualgenomese-\n",
      "quences.NatureGenetics,43(10):1031?1034,Oct2011.[13]JohnAHartigan.\n",
      "ClusteringAlgorithms.JohnWiley&Sons,Inc.,NewYork,1975.[14]AnilK\n",
      "Jain.Dataclustering:50yearsbeyondk-means.PatternRecognitionLetters,\n",
      "31(8):651?666,2010.[15]DaphneKollerandMehranSahami.Hierarchi-\n",
      "callyclassifyingdocumentsusingveryfewwords.InICML,pages170?178.\n",
      "MorganKaufmannPublishersInc.,1997.[16]BjornarLarsenandChinatsu\n",
      "Aone.Fastandetextminingusinglinear-timedocumentclustering.In\n",
      "SIGKDD,ACM,pages16?22,1999.?[17]AlvaroMart??nez-P?erez.Adensity-\n",
      "sensitivehierarchicalclusteringmethod.arXivpreprintarXiv:1210.6292,2012.\n",
      "[18]PhilippeRigolletandR?egisVert.Optimalratesforplug-inestimatorsof\n",
      "densitylevelsets.Bernoulli,15(4):1154?1178,2009.[19]AlessandroRinaldo,\n",
      "AartiSingh,RebeccaNugent,andLarryWasserman.Stabilityofdensitybased\n",
      "clustering.JournalofMachineLearningResearch,13:905?948,2012.[20]Bern-\n",
      "hardSch?olkopf,JohnC.Platt,JohnC.Shawe-Taylor,AlexJ.Smola,and\n",
      "RobertC.Williamson.Estimatingthesupportofahigh-dimensionaldistri-\n",
      "bution.NeuralComputation,13(7):1443?1471,2001.[21]MichaelSteinbach,\n",
      "GeorgeKarypis,andVipinKumar.Acomparisonofdocumentclusteringtech-\n",
      "niques.InKDDWorkshoponTextMining,2000.[22]WernerStuetzle.Esti-\n",
      "matingtheclustertreeofadensitybyanalyzingtheminimalspanningtreeof\n",
      "asample.Journalof20(1):025?047,2003.[23]WernerStuetzle\n",
      "andRebeccaNugent.Ageneralizedsinglelinkagemethodforestimatingthe\n",
      "clustertreeofadensity.JournalofComputationalandGraphicalStatistics,\n",
      "19(2),2010.[24]The1000GenomesProjectConsortium.Anintegratedmap\n",
      "ofgeneticvariationfrom1,092humangenomes.Nature,491:1,2012.[25]Ruth\n",
      "Urner,SharonWandShaiBen-David.Plal:Cluster-basedactivelearning.\n",
      "InCOLT,pages1?22,2013.[26]G.Walther.Granulometricsmoothing.The\n",
      "AnnalsofStatistics,pages2273?2299,1997.[27]DavidWishart.Modeanalysis:\n",
      "AgeneralizationofnearestneighborwhichreduceschainingNumerical\n",
      "Taxonomy,76:282?311,1969.[28]RuiXu,DonaldWunsch,etal.Surveyof\n",
      "clusteringalgorithms.IEEETransactionsonNeuralNetworks,16(3):645?678,\n",
      "2005.9\n",
      "12\n",
      "\n",
      "PP4098.pdf\n",
      "PP4098.pdf 13\n",
      "NonparametricDensityEstimationforStochastic\n",
      "OptimizationwithanObservableStateVariable\n",
      "Authoredby:\n",
      "DavidM.Blei\n",
      "LaurenHannah\n",
      "WarrenPowell\n",
      "Abstract\n",
      "Westudyconvexstochasticoptimizationproblemswhereanoisyob-\n",
      "jectivefunctionvalueisobservedafteradecisionismade.Thereare\n",
      "manystochasticoptimizationproblemswhosebehaviordependsonan\n",
      "exogenousstatevariablewhichtheshapeoftheobjectivefunction.\n",
      "Currently,thereisnogeneralpurposealgorithmtosolvethisclassofprob-\n",
      "lems.Weusenonparametricdensityestimationforthejointdistribution\n",
      "ofstate-outcomepairstocreateweightsforpreviousobservations.The\n",
      "weightselygroupsimilarstates.Thosesimilartothecurrentstate\n",
      "areusedtocreateaconvex,deterministicapproximationoftheobjective\n",
      "function.Weproposetwosolutionmethodsthatdependontheprob-\n",
      "lemcharacteristics:function-basedandgradient-basedoptimization.We\n",
      "twoweightingschemes,kernelbasedweightsandDirichletprocess\n",
      "basedweights,forusewiththesolutionmethods.Theweightsandsolu-\n",
      "tionmethodsaretestedonasyntheticmulti-productnewsvendorproblem\n",
      "andthehouraheadwindcommitmentproblem.OurresultsshowDirich-\n",
      "letprocessweightscansubstantialbtsoverkernelbasedweights\n",
      "and,moregenerally,thatnonparametricestimationmethodsprovidegood\n",
      "solutionstootherwiseintractableproblems.\n",
      "1PaperBody\n",
      "Instochasticoptimization,adecisionmakermakesadecisionandfacesarandom\n",
      "costbasedonthatdecision.Thegoalistochooseadecisionthatminimizes\n",
      "theexpectedcostusinginformationfrompreviousobservations.Stochastic\n",
      "optimizationproblemswithcontinuousdecisionspaceshavemanyviableso-\n",
      "lutionmethods,includingfunctionaveragingandstochasticgradientdescent\n",
      "[20].However,inmanysituationsconditionsforthepreviousobservationsmay\n",
      "notbethesameasthecurrentconditions;theconditionscanbeviewedas\n",
      "statevariables.Therearecurrentlynogeneralpurposesolutionmethodsfor\n",
      "stochasticoptimizationproblemswithstatevariables,althoughtheywouldbe\n",
      "1\n",
      "\n",
      "usefulforenergy,dynamicpricing,inventorycontrolandreinforcement\n",
      "learningapplications.Weconsiderthenewsvendorproblem,aclassicinventory\n",
      "managementproblem,toillustrateexistingsolutionmethodsforstochasticopti-\n",
      "mizationproblemswithstatevariablesandtheirlimitations.Here,newspapers\n",
      "canbeboughtinadvanceforcostc,anduptoDofthemcanbesoldforprice\n",
      "p,whereDisarandomdemand;thegoalistodeterminehowmanypapers\n",
      "shouldbeorderedsoastomaximizetheexpectedAstatevariablethat\n",
      "containsinformationabouttherandomdemandmayalsobeincluded.Forex-\n",
      "ample,arainyforecastmaycorrelatetoalowerdemandwhileasunnyforecast\n",
      "maycorrelatetoahigher.Anaturalsolutionmethodwouldbetopartition\n",
      "thepreviousobservationsinto?rainy?and?sunny?bins,andthensolvethe\n",
      "problemforeachpartition.Thisessentiallymodelstheproblemasasingletime\n",
      "periodMarkovDecisionProcessandsolvestheproblemaccordingly[16,21].\n",
      "Partitioningmethodsworkwhenthestatespacecantakeasmallnumberof\n",
      "discretevalues.1\n",
      "Twoproblemsarisewithpartitioningmethodswhenthestatespacebecomes\n",
      "larger.First,thenumberofstatesgrowsexponentiallywiththedimensionof\n",
      "thestatespace.Ifthereare10attributes,likeweather,stockprices,daysuntil\n",
      "anelection,etc,andeachcantake100values,thentherewillbe1020individ-\n",
      "ualstates.Second,previousobservationsaresparseoverthesestates;avast\n",
      "numberofobservationsmustbegatheredbeforethereareenoughtomakearea-\n",
      "sonabledecisionforagivenstate.Ratherthanpartitioning,weproposeusing\n",
      "observationsfrom?similar?statestocreateadeterministicdecision-expected\n",
      "costfunction,alsocalledanobjectivefunction,thatisconditionedonapar-\n",
      "ticularstate.Similarmethodshavebeenproposedinanapproximatedynamic\n",
      "programmingsettingthatusebasisfunctions,suchaslinearandpolynomial\n",
      "predictors,toconstructapproximatevaluefunctions[22,14].Basisfunctions,\n",
      "however,arehardtochoosemanuallyandautomaticselectionisanareaof\n",
      "activeresearch[12].Moreover,basisfunctionsdonotguaranteethattheap-\n",
      "proximateobjectivefunctionisconvexinthedecision.Weproposeusingnon-\n",
      "parametricdensityestimationforthejointstateandoutcomedistributionto\n",
      "groupobservationsfrom?similar?stateswithweights.Thesearethenused\n",
      "toconstructdeterministic,convexapproximationsofthenoisyfunctiongiven\n",
      "thecurrentobservedinformation.Theresultsareadeterministic,convexmath\n",
      "program.Thesecanbetlysolvedbyanumberofcommercialsolvers,\n",
      "evenwithverylargedecisionspaces(10to1,000+variablesandconstraints).\n",
      "Wegivetwomethodstoconstructanapproximateobjectivefunctionusingpre-\n",
      "viousobservations.Theisafunction-basedmethod.Insomecases,entire\n",
      "randomobjectivefunctionscanbeviewedretrospectively.Forexample,ifthe\n",
      "demandisknowninthenewsvendorproblem,thenthevalueofalldecisions\n",
      "isalsoknown.Intheseparticularcases,theapproximateobjectivefunctionis\n",
      "modeledasaweightedaverageoftheobservedfunctions.Thesecondmethodis\n",
      "basedonstochasticgradients.Insomecases,itisnotpossibletoobserveentire\n",
      "functionsorobservedfunctionsmaybetoocomplextomanipulate.Whenthis\n",
      "happens,weproposeconstructingaseparable,piecewiselinearapproximateob-\n",
      "jectivefunction.Apiecewiselinear,convexfunctioniscreatedineachdecision\n",
      "2\n",
      "\n",
      "dimensionbygeneratingaslopefunctionfromaweighted,order-restrictedre-\n",
      "gressionofthegradients,andthenintegratingthatfunction.Theresultisan\n",
      "approximateobjectivefunctionthatisnotnecessarilythesameastheoriginal\n",
      "objectivefunction,butonethathasthesameminima.Bothmethodsdepend\n",
      "heavilyonweightstocapturedependencebetweenthestateandtheoutcome.\n",
      "Weproposetwoweightingschemes:kernelsweightsandDirichletprocessmix-\n",
      "turemodelweights.Kernelsaresimpletoimplement,butDirichletprocess\n",
      "mixturemodelshavecertainappealingproperties.First,theyactasalocal\n",
      "bandwidthselectoracrossthestatespace;second,theweightsaregenerated\n",
      "bypartitionsratherthanproductsofuni-dimensionalweights,sotheresults\n",
      "scalebettertohigher-dimensionalsettings.Wecontributenovelalgorithmsfor\n",
      "stochasticoptimizationproblemswithastatevariablethatworkwithlarge,\n",
      "continuousdecisionspacesandproposeanewuseofDirichletprocessmixture\n",
      "models.Wegiveempiricalanalysisforthesemethodswhereweshowpromising\n",
      "resultsontestproblems.Thepaperisorganizedasfollows.InSection2,were-\n",
      "viewtraditionalfunction-basedandgradientbasedoptimizationmethodsandin\n",
      "eachcasepresentnovelalgorithmstoaccommodateanobservablestatevariable.\n",
      "Wepresentanempiricalanalysisofourmethodsforsyntheticnewsvendordata\n",
      "andthehouraheadwindcommitmentprobleminSection4andadiscussionin\n",
      "Section5.\n",
      "2\n",
      "Stochasticoptimizationforproblemswithanobservablestatevariable\n",
      "TraditionalstochasticoptimizationproblemshavetheformminE[F(x,Z)]\n",
      ",\n",
      "x?X\n",
      "(1)\n",
      "wherex?Rdisthedecision,Z:???isarandomoutcome,Xisadecision\n",
      "setandF(x,Z(?))isarandomobjectivefunction[20].Inthenewsvendor\n",
      "problem,whichwewilluseasarunningexample,xisthestockingleveland\n",
      "Zistherandomdemand.GivenxandZ(?),Fisdeterministic.Whenastate\n",
      "variableisinlcuded,weobservearandomstateS?Sthatmay\n",
      "FandthedistributionofZ,thenwemakeadecisionx,andweobserve\n",
      "therandomvariableZ.Eq.(1)becomesminE[F(x,s,Z)|S=s].(2)x?X\n",
      "2\n",
      "Traditionalstochasticoptimizationtechniquesrequireustosamplefrom\n",
      "theconditionaldistributionofp(Z|S=s),treatingeachstateobservation\n",
      "independently[20].Wewillusenonparametricdensityestimationforthejoint\n",
      "distributionof(S,Z)totakeintoaccountthatsimilarvaluesofSZ\n",
      "andFinasimilarway.Wenowdescribenewmethodsforfunction-basedand\n",
      "gradientbasedoptimizationforproblemswithanobservablestatevariable.2.1\n",
      "Function-basedoptimizationwithanobservablestatevariable\n",
      "Function-basedoptimizationisusedwhenasingleoutcome?cantellusthe\n",
      "valueofalldecisionsgiventhatoutcome[19].Forexample,inthenewsvendor\n",
      "problem,ifthedemandisknownthenthevalueofallinventorylevelsisknown.\n",
      "Function-basedoptimizationreliesonsamplingasetofscenarios,?1,...,?n\n",
      "from?,toapproximateEq.(1):n\n",
      "3\n",
      "\n",
      "min\n",
      "x?X\n",
      "1XF(x,Z(?i)).ni=1\n",
      "(3)\n",
      "SinceEq.(3)isdeterministicgiven?1:n,deterministicsolutionmethodscan\n",
      "beused.Thesemethodsarewelldevelopedandareimplementedinavariety\n",
      "ofcommercialsolvers.Whenastatevariableisintroduced,wewishtosolve\n",
      "Eq.(2)foraquerystates?S.However,scenariosarenoti.i.d.from\n",
      "thedistributionp(Z|S=s),butratherfromthejointdistribution(p(Z,S).\n",
      "Let(Si,Z(?i+1))n?1i=0beasetofnobservations.Insteadoftakinganaive\n",
      "averageoftheobservationsasinEq.(3),weweighttheobservationsbasedon\n",
      "thedistancebetweenthequerystatePn?1sandeachobservationSiwithweight\n",
      "wn(s,Si).Theweightsmustsumto1,i=0wn(s,Si)=1,andtheweights\n",
      "maychangewiththenumberofobservations,n.SetF?n(x|s)=\n",
      "n?1X\n",
      "wn(s,Si)F(x,Si,Z(?i+1)).\n",
      "(4)\n",
      "minF?n(x|s).\n",
      "(5)\n",
      "i=0\n",
      "Theoptimizationproblembecomesx?X\n",
      "NotethatbecauseF(x,Si,Z(?i+1))isconvexinxforeverySiand?i+1,\n",
      "F?n(x|s)isconvexandEq.(5)canbesolvedwithacommercialsolver.We\n",
      "discussweightfunctionsinSection3.2.2\n",
      "Gradient-basedoptimizationwithanobservablestatevariable\n",
      "Ingradient-basedoptimization,wenolongerobserveanentirefunctionF(x,\n",
      "S,Z(?)),butonlyaderivativetakenatx,?i,s,?i+1)=?xF(xi,s,Z(?i+1\n",
      ")).?(x(6)Stochasticapproximationisthemostpopularwaytosolvestochastic\n",
      "optimizationproblemsusingagradient;itmogradientsearchalgorithms\n",
      "toaccountforrandomgradients[17,9].Thegeneralideaistooptimizexby\n",
      "iterating,xn+1=?X(xn?an?xF(xn,Z(?n+1)),\n",
      "(7)\n",
      "where?XisaprojectionbackintotheconstraintsetX,?xF(xn,Z(?n+1\n",
      "))isastochasticgradientatxnandanisastepsize.Otherapproachesto\n",
      "gradient-basedoptimizationhaveincludedconstructionofpiecewiselinear,con-\n",
      "vexfunctionstoapproximateF(x)intheregionwherexisneartheoptimal\n",
      "decision,x?[15].Includingastatevariableintogradient-basedoptimization\n",
      "islessstraightforwardthanitisforfunction-basedoptimization.Weruninto\n",
      "becausewechoosexngivenSn.WhenweincludestateSn,thede-\n",
      "cisionxnisbasedonthestateSn.Butxn?1dependsonSn?1,sonoiterative\n",
      "procedurelikeEq.(7)canbeused.Moreover,constructingtheapproximate\n",
      "functionF?n(x|s)isnottrivialbecausethestochasticgradientsdependon\n",
      "bothxnandSn.Therefore,weproposemodelingF(x|s)withapiecewise\n",
      "linear,convex,separableapproximation.EvenifF(x|s)isnotitselfsepa-\n",
      "rable,weaimtoapproximateitwithasimpler(separable)functionthathas\n",
      "4\n",
      "\n",
      "thesameminimumforalls.Approximatingtheminimumiseasierthan\n",
      "approximating3\n",
      "?\n",
      "1.5\n",
      "2\n",
      "1.0\n",
      "1\n",
      "weight0.3\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0\n",
      "response\n",
      "StochasticGradient\n",
      "1.5\n",
      "?0.5?1?1.5\n",
      "0.5\n",
      "0.0\n",
      "0.60.7\n",
      "?0.5\n",
      "0.8\n",
      "?20\n",
      "?1.0\n",
      "0.2\n",
      "0.9\n",
      "10.4\n",
      "?\n",
      "0.8\n",
      "?1.5\n",
      "0.6\n",
      "0.6\n",
      "1.0\n",
      "0.4\n",
      "0.8\n",
      "0.21\n",
      "0\n",
      "StateVariable\n",
      "DecisionVariable\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "decision\n",
      "?\n",
      "5\n",
      "\n",
      "1.50.251.0\n",
      "weight0.3\n",
      "0.20\n",
      "0.40.5\n",
      "0.0\n",
      "value\n",
      "response\n",
      "0.5\n",
      "0.60.7\n",
      "?0.5\n",
      "0.10\n",
      "0.8?1.0\n",
      "0.15\n",
      "0.9?\n",
      "?1.5\n",
      "0.05\n",
      "1.0\n",
      "0.000.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "0.0\n",
      "0.2\n",
      "decision\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "decision\n",
      "Figure1:Agraphicaldepictionofgradient-basedmethodinonedimension\n",
      "foramaximizationproblem.(Topleft)Observegradients,state.(Topright)\n",
      "Weightobservationsbasedonstate.(Bottomleft)Fitisotonicregressionto\n",
      "weightedslopes.(Bottomright)Integrateisotonicregressiontoformfnk(xn\n",
      "|Sn).\n",
      "theentireconvexfunction[4,15].Moreover,convexregressioniseasierin\n",
      "onedimensionthanmultipledimensions.WeapproximateE[F(x,s,Z)]bya\n",
      "seriesofseparablefunctions,F?n(x|s)=\n",
      "dX\n",
      "fnk(xk|s),\n",
      "k=1\n",
      "wherexkisthekthcomponentofx.Weenforceconvexityrestrictionson\n",
      "fnk(x|s)foreverys?S.Unlikethefunction-basedmethod,thegradient-based\n",
      "methodisafundamentallyonlinealgorithm:xnisusedtochoosexn+1.Given\n",
      "Sn,wechoosexnasfollows,xn=argminx?X\n",
      "dX\n",
      "6\n",
      "\n",
      "fnk(xk|Sn).\n",
      "k=1\n",
      "?n,Sn,?n+1).Theobservations(xi,Si,?(x?i,Si,?i+1))n?1\n",
      "areusedtoupWethenreceive?(xi=0?dateFn(x|s)sequentially.Fixk\n",
      "?\n",
      "f\n",
      "1,...,d\n",
      "g\n",
      ";wewanttoconstructapiecewiselinearfnk(x|s)dkby\n",
      "constructinganincreasingslopefunction,vnk(x|Sn)=dxfn(x|Sn)based\n",
      "onthestochasticgradientobservations,??1:n.Weuseweightstogroupthe\n",
      "gradientsfromstates?similar?toSnandaweightedisotonic(orderrestricted)\n",
      "regressiontoconstructvnk(x|Sn).Orderthedecisionobservationsxk[0],.\n",
      "..,xk[n?1],andthensolvetoslopesforthedecision-orderedspace,vnk\n",
      "(x0:n?1|Sn)=argminv\n",
      "n?1X\n",
      "wnSn,S[i]\n",
      "?k,S[i],?[i+1])?v[i]?(x[i]\n",
      "2\n",
      ",\n",
      "(8)\n",
      "i=0\n",
      "subjectto:v[i?1]?v[i],i=1,...,n?1.Firstvnk(x|Sn)isgenerated\n",
      "byinterpolatingthepointestimatesfromEq.(8)acrossthekthdimensionof\n",
      "thedecisionspace,andthenfk(x|Sn)iscreatedbyintegratingvnk(x|Sn\n",
      ").Themonotonicityofvnk(x|Sn)ensurestheconvexityoffnk(x|Sn).See\n",
      "Figure1foranexample.ThegeneralmethodforconstructingF?n(x|s)isas\n",
      "follows:4\n",
      "1.ObserveSnandconstructingweights((wn(Sn,Si))n?1i=0,n?12.\n",
      "Usetheweightswn(Sn,Si)i=0,previousdecisionsx0:n?1andgradientsto\n",
      "constructkslopesv1:K(Sn)withEq.(8),3.Reconstructfk(x|Sn)from\n",
      "theslopesandconstructF?(x|Sn)from(fk(x|Sn))dk=1,andxn=arg\n",
      "minF?n(x|Sn).4.ChoosexngivenF?(x|Sn):x?XDetailsaregivenin\n",
      "thesupplementarymaterial.Wenowdiscussthechoiceofweightfunctions.\n",
      "3\n",
      "Weightfunctions\n",
      "Likethechoiceofstepsizeinstochasticapproximation,thechoiceofweight\n",
      "functionsinEqs.(4)and(8)determineswhetherandunderwhichcondi-\n",
      "tionsfunction-basedandgradient-basedoptimizationproduceacceptablere-\n",
      "sults.Weightingfunctionsrelyondensityestimationprocedurestoapproxi-\n",
      "matetheconditionaldensityf(z|s),wheresisthestateandzistheresponse.\n",
      "Conditionaldensityestimationweightsobservationsfromajointdistributionto\n",
      "createaconditionaldistribution.Weusethistoobtainweightsfromtwonon-\n",
      "parametricdensityestimators,kernelsandDirichletprocessmixturemodels.\n",
      "3.1\n",
      "Kernelweights\n",
      "Kernelweightsrelyonkernelfunctions,K(s),tobeevaluatedateachob-\n",
      "servationtoapproximatetheconditionaldensity.AcommonchoiceforKwith\n",
      "continuouscovariatesistheGaussiankernel,Kh(s)=(2?h)?1/2exp\n",
      "f\n",
      "?s2/2h\n",
      "g\n",
      ",\n",
      "7\n",
      "\n",
      "wherethevariancehiscalledthebandwidth.Kernelweightshavetheadvan-\n",
      "tageofbeingsimpleandeasytoimplement.Thesimplestandmostuniversally\n",
      "applicableweightingschemeisbasedontheNadaraya-Watsonestimator[10,\n",
      "23].IfK(s)isthekernelandhnisthebandwidthafternobservations,\n",
      "n?1Xwn(s,Si)=K((s?Si)/hn)/K((s?Sj)/hn).j=0\n",
      "Kernelestimatorsrequireawellsampledspace,arepoorinhigherdimensions\n",
      "andhighlysensitivetobandwidthsize[5].3.2\n",
      "Dirichletprocessweights\n",
      "Oneofthecursesofdimensionalityissparsenessofdata:asthenumberof\n",
      "dimensionsgrows,thedistancebetweenobservationsgrowsexponentially.In\n",
      "kernelregression,thismeansthatonlyahandfulofobservationshaveweights\n",
      "thatareelynon-zero,producingnon-stableestimates.Instead,wewould\n",
      "liketoaverageresponsesfor?similar?observations.Weproposemodelingthe\n",
      "distributionofthestatevariablewithaDirichletprocessmixturemodel,which\n",
      "isthendecomposedintoweights.Dirichletprocessmixturemodels.Amixture\n",
      "modelrepresentsadistribution,P?g(s),asaweightedsumofsimpler\n",
      "distributions,g(s|?i),parameterizedby?i,g(s)=i=1pig(s|?i).Here,pi\n",
      "isthemixingproportionforcomponenti.WecanuseaDirichletprocess(DP)\n",
      "withbasemeasureG0andconcentrationparameter?toplaceadistribution\n",
      "overthejointdistributionof(pi,?i),themixtureproportionandlocationof\n",
      "componenti[6,1].AssumethatdataS1,...,Snareiidwithadistribution\n",
      "thatismodeledbyamixtureoverdistributionG(?),P?DP(?,G0),?i|P?\n",
      "P,Si|?i?G(?i).(9)ThedistributionPdrawnfromaDirichletprocessisan\n",
      "almostsurelydiscretemeasureoverparameters,withthemixtureproportion\n",
      "associatedwith?astheatomicweight.ThehiddenmeasurePinEq.(9)can\n",
      "beintegratedouttoobtainaconditionaldistributionof?n|?1:n?1[3]n?1X\n",
      "1??n|?1,...,?n?1???i+G0.(10)?+n?1i=1?+n?1Here,\n",
      "??istheDiracmeasurewithmassat?.Eq.(10)isknownasaPolyaurn\n",
      "posterior;thevariable?nhaspositiveprobabilityofassumingthevalueofone\n",
      "ofthepreviouslyobserved?i,butitalsocantakeanewvaluedrawnfromG0\n",
      "withpositiveprobability.Theparameter?controlshowlikely?nistotakea\n",
      "newvalue.WenowdiscusshowweightscanbeconstructedfromEq.(9).5\n",
      "Dirichletprocessmixturemodelweights.ADirichletprocessmixturemodel\n",
      "canbeusedtomodelanunknowndensity,butitcansimultaneouslybeused\n",
      "toproduceadistributionofthepartitionstructureofobserveddata[13,8].\n",
      "ThisisshowninthePolyaurnposteriorofEq.(10);eachhiddenparameter\n",
      "haspositiveprobabilityoftakingthesamevalueasanotherparameter.Iftwo\n",
      "hiddenparametershavethesamevalue,theyareinthesamepartition/cluster.\n",
      "Thepartitionstructureinducesweightsontheobservations,proportionalto1\n",
      "iftheyareinthesamecluster,0ifnot.Letp=\n",
      "f\n",
      "C1,...,Cn(p)\n",
      "g\n",
      "bethe\n",
      "partitionoftheobservations\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      ".HereCi=\n",
      "f\n",
      "j:?j=?i?\n",
      "g\n",
      "?isthe\n",
      "partitionsetgeneratedbyn(p)uniqueparametervalues,denoted?1?,...\n",
      ",?n(p).Nowsupposethatweknowthepartitionp.Givenp,weincludethe\n",
      "querystatesintoclusterCiwithprobabilityZps(Ci|p)=P(s?Ci|p,\n",
      "S1:n)?|Ci|g(s|??)dHCi(??),where|Ci|isthenumberofelements\n",
      "inCi,andHCi(??)istheposteriordistributionof??conditionedonG0and\n",
      "8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thesetofobservations\n",
      "f\n",
      "Sj:Sj?Ci\n",
      "g\n",
      ".Givenp,theweightingfunctionisthe\n",
      "probabilitythatthehiddenparameterforswouldbe?i,thehiddenparameter\n",
      "forSi,n(p)\n",
      "wn(s,Si)|p=\n",
      "Xps(Cj|p)1\n",
      "f\n",
      "Si?Cj\n",
      "g\n",
      ".|Cj|j=1\n",
      "(11)\n",
      "Eq.(11)isconditionedonapartitionstructure,buttheDirichletprocess\n",
      "producesadistributionoverpartitionstructures.Let?(p)bethepriordis-\n",
      "tributionforpartitionspand?(p|S0:n?1)theposterior.Integratingofthe\n",
      "partitionposterior,weobtainunconditionalweights,(m)\n",
      "Mn(pXps(Cj|p)1XX1\n",
      "f\n",
      "Si?Cj\n",
      "g\n",
      "??(p|S1:n)|Cj|Mm=1j=1\n",
      "j=1n(p)\n",
      "wn(s,Si)=\n",
      "Xp\n",
      ")\n",
      "ps(Cj|p(m))1\n",
      "f\n",
      "Si?Cj\n",
      "g\n",
      ".|Cj|\n",
      "(12)\n",
      "Itisinfeasibletointegrateoverallofthepartitions;therefore,weapprox-\n",
      "imateEq.(12)byperformingaMonteCarlointegrationwithMposterior\n",
      "partitionsamples,(p(m))Mm=1.Weobtain(p(m))MbygeneratingMiid\n",
      "samplesofthehiddenparameters,?,fromtheposteriorofEq.0:n?1m=1(9)\n",
      "withGibbssampling[11].\n",
      "44.1\n",
      "EmpiricalanalysisMulti-productconstrainednewsvendorproblem\n",
      "Amulti-productnewsvendorproblemisaclassicoperationsresearchinven-\n",
      "torymanagementproblem.Inthetwoproductproblem,anewsvendorisselling\n",
      "productsAandB.Shemustdecidehowmuchofeachproducttostockinthe\n",
      "faceofrandomdemand,DAandDB.AandBcanbebeboughtfor(cA,cB)\n",
      "andsoldfor(pA,pB),respectively.Anyinventorynotsoldislost.Let(xA,\n",
      "xB)bethestockingdecisionsforAandBrespectively;itissubjecttoabudget\n",
      "constraint,bAxA+bBxB?b,andastorageconstraint,rAxA+rBxB?r.\n",
      "AnobservablestateS=(S1,S2)containsinformationaboutDAandDB.\n",
      "Theproblemis,max?cAxA?cBxB+E[pAmin(xA,DA)+pBmin(xB\n",
      ",DB)|S=s]\n",
      "xA,xB\n",
      "subjectto:bAxA+bBxB?b,\n",
      "(13)\n",
      "rAxA+rBxB?r.\n",
      "WegenerateddataforProblem(13)inthefollowingway.Demandand\n",
      "twostatevariablesweregeneratedinajointlytrimodalGaussianmixture.The\n",
      "followingmethodswerecompared.Function-basedwithkernelandGradient-\n",
      "basedwithkernel.Bandwidthisselectedaccordingtothe?ruleofthumb?\n",
      "methodofthenppackageforR,hj=1.06?jn?1/(4+d),where?jisas\n",
      "min(sd,interquartilerange/1.349)[7].Function-basedwithDPandGradient-\n",
      "basedwithDP.Weusedthefollowinghierarchicalmodel,P?DP(?,G0),\n",
      "2?i=(?i,s,?i,s)|P?P,\n",
      "9\n",
      "\n",
      "6\n",
      "2Si,j|?i?N(?i,s,j,?i,s,j),j=1,2.\n",
      "TwoProductNewsvendorAlgorithmKernelGradient?BasedDPGradi-\n",
      "ent?BasedKernelFunction?BasedDPFunction?Based\n",
      "16\n",
      "Value\n",
      "14121086\n",
      "Optimal20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "NumberofObservations\n",
      "Figure2:Gradient-basedandfunction-basedmethodsasafunctionofnum-\n",
      "berofdatapointssampled.Resultsareaveragedover100testproblemswith\n",
      "observeddemand.\n",
      "PosteriorsamplesweredrawnusingGibbssamplingwithafullycollapsed\n",
      "samplerrunfor500iterationswitha200iterationburn-inwithsamplestaken\n",
      "every5iterations.Optimal.Thesearetheoptimaldecisionswithknownmixing\n",
      "parametersandunknowncomponents.Results.Decisionsweremadeunder\n",
      "eachregimeovereightsamplepaths;100teststate/demandpairswere\n",
      "anddecisionsweremadefortheseproblemsgiventheobservedstates/decisions\n",
      "inthesamplepathforeachmethod.ResultsaregiveninFigure2.Thekernel\n",
      "andDirichletprocessweightsperformedapproximatelyequallyforeachmethod,\n",
      "butthefunction-basedmethodsconvergedmorequicklythanthegradient-based\n",
      "methods.4.2\n",
      "Houraheadwindcommitment\n",
      "Inthehouraheadwindcommitmentproblem,awindfarmmanagermust\n",
      "decidehowmuchenergytopromiseautilityanhourinadvance,incorporating\n",
      "knowledgeaboutthecurrentstateoftheworld.Thedecisionistheamount\n",
      "ofwindenergypledged,ascalarvariable.Ifmoreenergyispledgedthanis\n",
      "generated,themustbeboughtonthespotmarket,whichisexpensive\n",
      "withapricethatisunknownwhenthedecisionismade;otherwise,theexcessis\n",
      "lost.Thegoalistomaximizeexpectedrevenue.Theobservablestatevariable\n",
      "isthetimeofday,timeofyear,windhistoryfromthepasttwohours,contract\n",
      "priceandcurrentspotprice,TiDPiSWi?1Sixi\n",
      "=====\n",
      "timeofday,currentspotprice,windspeedanhourago,observablestate\n",
      "variableamountofenergypledged,\n",
      "TiYPiCWiYi+1(x)\n",
      "=====\n",
      "timeofyear,contractprice,currentwindspeed,(TiD,TiY,PiC,PiS,Wi\n",
      ",Wi?1),SPiCx?Pi+1max(x?Wi+1,0).\n",
      "STherevenuethatthewindfarmreceives,Yi+1(x),dependsonthevari-\n",
      "ablesPi+1andWi+1,whicharenotknownuntilthenexthour.Weused\n",
      "windspeeddatafromtheNorthAmericanLandDataAssimilationSystem\n",
      "10\n",
      "\n",
      "withhourlyobservationsfrom2002?2005inthefollowinglocations:Amarillo,\n",
      "TX.Latitude:35.125N,Longitude:101.50W.Thedatahavestrongdailyand\n",
      "seasonalpatterns.Themeanwindlevelis186.29(m/s)3withstandarddevi-\n",
      "ation244.86.Tehachapi,CA.Latitude:35.125N,Longitude:118.25W.The\n",
      "datahavestrongseasonalpatterns.Themeanwindlevelis89.45(m/s)3with\n",
      "standarddeviation123.47.\n",
      "Cleanspotandcontractpricedataforthetimeperiodwereunavailable,so\n",
      "contractpricesweregeneratedbyGaussianrandomvariableswithameanof1\n",
      "andvarianceof0.10.Spotpricesweregeneratedbyamean-reverting(Ornstein-\n",
      "Uhlenbeck)processwithameanfunctionthatvariesbytimeofdayandtime\n",
      "ofyear[18].Thedatawereanalyzedseparatelyforeachlocation;theywere\n",
      "dividedbyyear,withoneyearusedfortrainingandtheotherthreeusedfor\n",
      "testing.Thefollowingmethodswerecomparedonthisdataset:Knownwind.\n",
      "Thewindisknown,allowingmaximumpossiblecommitment,xi=Wi+1(?i+1\n",
      ").Itservesasanupperboundforallofthemethods.7\n",
      "METHOD/LOCATIONTEHACHAPI,CAKNOWNWINDFUNC-\n",
      "TIONWITHKERNELFUNCTIONWITHDPIGNORESTATEAMAR-\n",
      "ILLO,TXKNOWNWINDFUNCTIONWITHKERNELFUNCTION\n",
      "WITHDPIGNORESTATE\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "97.578.8(80.8%)85.1(87.3%)30.4(31.1%)\n",
      "94.577.3(81.8%)82.6(87.4%)31.1(32.9%)\n",
      "73.758.9(79.9%)63.9(86.7%)22.8(30.9%)\n",
      "91.872.1(78.5%)79.6(86.7%)29.3(31.9%)\n",
      "186.0155.1(83.4%)168.2(90.4%)70.3(37.8%)\n",
      "175.2149.6(85.4%)160.6(91.7%)68.7(39.2%)\n",
      "184.9154.7(83.7%)167.1(90.4%)69.6(37.6%)\n",
      "175.2146.2(83.5%)159.4(91.0%)66.1(37.7%)\n",
      "Table1:Meanvaluesofdecisionsbymethod,yearanddataset.Percentages\n",
      "oftheupperbound,KnownWind,aregivenfortheothermethods.\n",
      "Function-basedwithkernel.Function-basedoptimizationwheretheweights\n",
      "aregeneratedbyaGaussiankernel.Bandwidthisselectedaccordingtothe\n",
      "?ruleofthumb?methodofthenppackageforR,hj=1.06?jn?1/(4+d),where\n",
      "?jisedasmin(sd,interquartilerange/1.349)[7].Function-basedwithDP.\n",
      "Function-basedoptimizationwithDirichletprocessbasedweights.Wemodel\n",
      "thestatedistributionwiththefollowinghierarchicalmodel,P?DP(?,G0),\n",
      "TiD|?iPiC|?i\n",
      "?i|P?P,\n",
      "?vonMises(?i,D,?D),\n",
      "TiY|?i?vonMises(?i,Y,?Y),\n",
      "2?N(?i,C,?i,C),\n",
      "2PiS|?i?N(?i,S,?i,S),\n",
      "2Wi|?i?N(?i,W1,?i,W1),\n",
      "11\n",
      "\n",
      "2Wi?1|?i?N(?i,W2,?i,W2),\n",
      "2222?i=(?i,D,?i,Y,?i,C,?i,C,?i,S,?i,S,?i,W1,?i,W1,?i,W2,\n",
      "?i,W2).\n",
      "Wemodeledthetimeofday,TiD,andyear,TiY,withavonMisesdistri-\n",
      "bution,anexponentialfamilydistributionovertheunitsphere;thedispersion\n",
      "parameters,?Dand?Y,arehyperparameters.ThebasemeasurewasNormal-\n",
      "InverseGammaforPiC,PiS,WiandWi?1anduniformforthemeansofTiD\n",
      "andTiY.100posteriorsamplesweredrawnusingGibbssamplingwithacol-\n",
      "lapsedsamplerforallconjugatedimensionsaftera1,000iterationburn-inand\n",
      "10iterationpulsebetweensamples.Pn?1Ignorestate.Sampleaverageapprox-\n",
      "imationisused,F?n(x|s)=n1i=0Yi+1(x).Results.Resultsarepresented\n",
      "inTable1.Wedisplaythevalueofeachalgorithm,alongwithpercentagesof\n",
      "KnownWindfortheotherthreemethods.Bothformsoffunction-basedopti-\n",
      "mizationoutperformedthealgorithminwhichthestatevariablewasignored\n",
      "byalargemargin(?45%ofthebestpossiblevalue).Dirichletprocessweights\n",
      "outperformedkernelweightsbyasmallerbutstilltmargin(5.6?8.2%\n",
      "ofbestpossiblevalue).\n",
      "5\n",
      "Discussion\n",
      "Wepresentedtwonewmethodstosolvestochasticoptimizationproblems\n",
      "withanobservablestatevariable,includingstatevariablesthataretoolarge\n",
      "forpartitioning.Ourmethodsmakeminimalassumptions.Theyarepromis-\n",
      "ingadditionstoareasthatrelyonobservationaldatatomakedecisionsunder\n",
      "changingconditions(energy,dynamicpricing,inventorymanagement),\n",
      "andsomecommunitiesthatmakesequentialdecisionsunderuncertainty(re-\n",
      "inforcementlearning,stochasticprogramming,simulationoptimization).Our\n",
      "methodscanaccommodatemuchlargerstateanddecisionspacesthanMDPs\n",
      "andothertablelookupmethods,particularlywhencombinedwithDirichlet\n",
      "processmixturemodelweights.Unlikeexistingobjectivefunctionapproxima-\n",
      "tionmethods,suchasbasisfunctions,ourmethodsprovideconvexobjective\n",
      "functionapproximationsthatcanbeusedwithavarietyofcommercialsolvers.\n",
      "AcknowledgmentsTheresearchwasfundedinpartbytheAirForceof\n",
      "ScienResearchunderAFOSRcontractFA9550-08-1-0195,andtheNSFun-\n",
      "dergrantCMMI-0856153.DavidM.BleiissupportedbyONR175-6343,NSF\n",
      "CAREER0745520,AFOSR-09NL202andtheAlfredP.Sloanfoundation.8\n",
      "2References\n",
      "[1]Antoniak,C.E.[1974],?MixturesofDirichletprocesseswithapplicationsto\n",
      "Bayesiannonparametricproblems?,TheAnnalsofStatistics2(6),1152?1174.\n",
      "[2]Bennett,K.P.andParrado-Hern?andez,E.[2006],?Theinterplayofop-\n",
      "timizationandmachinelearningresearch?,TheJournalofMachineLearning\n",
      "Research7,1265?1281.[3]Blackwell,D.andMacQueen,J.B.[1973],?Fergu-\n",
      "sondistributionsviaPolyaurnschemes?,TheAnnalsStatistics1(2),353?355.\n",
      "[4]Cheung,R.K.andPowell,W.B.[2000],?SHAPE-Astochastichybridap-\n",
      "12\n",
      "\n",
      "proximationprocedurefortwo-stagestochasticprograms?,OperationsResearch\n",
      "48(1),73?79.[5]Fan,J.andGijbels,I.[1996],LocalPolynomialModelling\n",
      "andItsApplications,Chapman&Hall/CRC.[6]Ferguson,T.S.[1973],?A\n",
      "Bayesiananalysisofsomenonparametricproblems?,TheAnnalsofStatis-\n",
      "tics1(2),209?230.[7]HaT.andRacine,J.S.[2008],?Nonparametric\n",
      "econometrics:Thenppackage?,JournalofStatisticalSoftware27(5),1?32.[8]\n",
      "Ishwaran,H.andJames,L.F.[2003],?GeneralizedweightedChineserestau-\n",
      "rantprocessesforspeciessamplingmixturemodels?,StatisticaSinica13(4),\n",
      "1211?1236.[9]Kiefer,J.andWolfowitz,J.[1952],?Stochasticestimationof\n",
      "themaximumofaregressionfunction?,TheAnnalsofMathematicalStatistics\n",
      "23(3),462?466.[10]Nadaraya,E.A.[1964],?Onestimatingregression?,The-\n",
      "oryofProbabilityanditsApplications9(1),141?142.[11]Neal,R.M.[2000],\n",
      "?MarkovchainsamplingmethodsforDirichletprocessmixturemodels?,Journal\n",
      "ofComputationalandGraphicalStatistics9(2),249?265.[12]Parr,R.,Painter-\n",
      "WakC.,Li,L.andLittman,M.[2007],Analyzingfeaturegenerationfor\n",
      "value-functionapproximation,in?Proceedingsofthe24thinternationalconfer-\n",
      "enceonMachinelearning?,ACM,p.744.[13]Pitman,J.[1996],?Somede-\n",
      "velopmentsoftheBlackwell-MacQueenurnscheme?,LectureNotes-Monograph\n",
      "Series30,245?267.[14]Powell,W.B.[2007],ApproximateDynamicProgram-\n",
      "ming:Solvingthecursesofdimensionality,Wiley-Blackwell.[15]Powell,W.B.,\n",
      "Ruszczy?nski,A.andTopaloglu,H.[2004],?Learningalgorithmsforseparable\n",
      "approximationsofdiscretestochasticoptimizationproblems?,Mathematicsof\n",
      "OperationsResearch29(4),814?836.[16]Puterman,M.L.[1994],Markovdeci-\n",
      "sionprocesses:Discretestochasticdynamicprogramming,JohnWiley&Sons,\n",
      "Inc.NewYork,NY,USA.[17]Robbins,H.andMonro,S.[1951],?Astochastic\n",
      "approximationmethod?,TheAnnalsofMathematicalStatistics22(3),400?407.\n",
      "[18]Schwartz,E.S.[1997],?Thestochasticbehaviorofcommodityprices:Im-\n",
      "plicationsforvaluationandhedging?,TheJournalofFinance52(3),923?973.\n",
      "[19]Shapiro,A.,Homem-deMello,T.andKim,J.[2002],?Conditioningofcon-\n",
      "vexpiecewiselinearstochasticprograms?,MathematicalProgramming94(1),\n",
      "1?19.[20]Spall,J.C.[2003],Introductiontostochasticsearchandoptimiza-\n",
      "tion:estimation,simulation,andcontrol,JohnWileyandSons.[21]Sutton,R.\n",
      "S.andBarto,A.G.[1998],Introductiontoreinforcementlearning,MITPress\n",
      "Cambridge,MA,USA.[22]Tsitsiklis,J.N.andVanRoy,B.[2001],?Regression\n",
      "methodsforpricingcomplexAmericanstyleoptions?,IEEETransactionson\n",
      "NeuralNetworks12(4),694?703.[23]Watson,G.S.[1964],?Smoothregression\n",
      "analysis?,Sankhy?a:TheIndianJournalofStatistics,SeriesA26(4),359?372.\n",
      "9\n",
      "13\n",
      "\n",
      "PP5807.pdf\n",
      "PP5807.pdf 17\n",
      "PolicyEvaluationUsingthe?-Return\n",
      "Authoredby:\n",
      "GeorgiosTheocharous\n",
      "GeorgeKonidaris\n",
      "ScottNiekum\n",
      "PhilipS.Thomas\n",
      "Abstract\n",
      "Weproposethe?-returnasanalternativetothe?-returncurrently\n",
      "usedbytheTD(?)familyofalgorithms.Thebofthe?-returnis\n",
      "thatitaccountsforthecorrelationoftlengthreturns.Becauseit\n",
      "istocomputeexactly,wesuggestonewayofapproximatingthe\n",
      "?-return.Weprovideempiricalstudiesthatsuggestthatitissuperiorto\n",
      "the?-returnand?-returnforavarietyofproblems.\n",
      "1PaperBody\n",
      "Mostreinforcementlearning(RL)algorithmslearnavaluefunction?afunction\n",
      "thatestimatestheexpectedreturnobtainedbyfollowingagivenpolicyfroma\n",
      "givenstate.talgorithmsforestimatingthevaluefunctionhavetherefore\n",
      "beenaprimaryfocusofRLresearch.ThemostwidelyusedfamilyofRLalgo-\n",
      "rithms,theTD(?)family[1],formsanestimateofreturn(calledthe?-return)\n",
      "thatblendslow-variancebutbiasedtemporalderencereturnestimateswith\n",
      "high-variancebutunbiasedMonteCarloreturnestimates,usingaparameter??\n",
      "[0,1].WhileseveraltalgorithmsexistwithintheTD(?)family?theorig-\n",
      "inallinear-timealgorithm[1],least-squaresformulations[2],andmethodsfor\n",
      "adapting?[3],amongothers?the?-returnformulationhasremainedunchanged\n",
      "sinceitsintroductionin1988[1].RecentlyKonidarisetal.[4]proposedthe\n",
      "?-returnasanalternativetothe?-return,whichusesamoreaccuratemodel\n",
      "ofhowthevarianceofareturnincreaseswithitslength.However,boththe?\n",
      "and?-returnsfailtoaccountforthecorrelationofreturnsoftlengths,\n",
      "insteadtreatingthemasstatisticallyindependent.Weproposethe?-return,\n",
      "whichuseswell-studiedstatisticaltechniquestodirectlyaccountforthecor-\n",
      "relationofreturnsoftlengths.However,unlikethe?and?-returns,\n",
      "the?-returnisnotsimpletocompute,andoftencanonlybeapproximated.We\n",
      "proposeamethodforapproximatingthe?-return,andshowthatitoutperforms\n",
      "the?and?-returnsonarangeofolicyevaluationproblems.\n",
      "2\n",
      "1\n",
      "\n",
      "ComplexBackups\n",
      "Estimatesofreturnlieattheheartofvalue-functionbasedRLalgorithms:\n",
      "anestimate,V??,ofthevaluefunction,V?,estimatesreturnfromeach\n",
      "state,andthelearningprocessaimstoreducetheerrorbetweenestimatedand\n",
      "observedreturns.ForbrevitywesuppressthedependenciesofV?andV??on\n",
      "?andwriteVandV?.Temporal(TD)algorithmsuseanestimateof\n",
      "thereturnobtainedbytakingasingletransitionintheMarkovdecisionprocess\n",
      "(MDP)[5]andthenestimatingtheremainingreturnusingtheestimateofthe\n",
      "valuefunction:RsTD=rt+?V?(st+1),t1\n",
      "isthereturnestimatefromstatest,rtistherewardforgoingfromstto\n",
      "st+1viaactionwhereRsTDtat,and??[0,1]isadiscountparameter.\n",
      "MonteCarloalgorithms(forepisodictasks)donotuseintermediateestimates\n",
      "butinsteadusethefullreturn,RsMC=t\n",
      "L?1X\n",
      "?irt+i,\n",
      "i=0\n",
      "foranepisodeLtransitionsinlengthaftertimet(weassumethatLis\n",
      "Thesetwotypesofreturnestimatescanbeconsideredinstancesofthe\n",
      "moregeneralnotionofann-stepreturn,!n?1X(n)iRs=?rt+i+?nV?\n",
      "(st+n),t\n",
      "i=0\n",
      "forn?1.Here,ntransitionsareobservedfromtheMDPandtheremaining\n",
      "portionofreturnisestimatedusingtheestimateofthevaluefunction.Since\n",
      "st+Lisastatethatoccursaftertheendofanepisode,weassumethatV?(st+L\n",
      ")=0,always.Acomplexreturnisaweightedaverageofthe1,...,Lstep\n",
      "returns:Rs?t=\n",
      "LX\n",
      "w?(n,L)Rs(n),t\n",
      "(1)\n",
      "n=1\n",
      "wherew?(n,L)areweightsand??\n",
      "f\n",
      "?,?,?\n",
      "g\n",
      "willbeusedtospecify\n",
      "theweightingschemesoftapproaches.Thequestionthatthispaper\n",
      "proposesananswertois:whatweightingschemewillproducethebestestimates\n",
      "ofthetrueexpectedreturn?The?-return,Rs?t,istheweightingschemethat\n",
      "isusedbytheentirefamilyofTD(?)algorithms[5].Itusesaparameter??\n",
      "[0,1]thatdetermineshowtheweightgiventoareturndecreasesasthelength\n",
      "ofthereturnincreases:((1??)?n?1ifn<LPn?1w?(n,L)=1?i=1w?(i)\n",
      "ifn=L.,which,whichhaslowvariancebuthighbias.When?=1,Rs?t\n",
      "=RsMCWhen?=0,Rs?t=RsTDtthashighvariancebutisunbiased.\n",
      "Intermediatevaluesof?blendthehigh-biasbutlow-varianceestimatesfrom\n",
      "shortreturnswiththelow-biasbuthigh-varianceestimatesfromthelonger\n",
      "returns.Thesuccessofthe?-returnislargelyduetoitssimplicity?TD(?)using\n",
      "linearfunctionapproximationhasper-time-steptimecomplexitylinearinthe\n",
      "numberoffeatures.However,thiscomesatacost:the?-returnisnot\n",
      "foundedonaprincipledstatisticalderivation.1Konidarisetal.[4]remedied\n",
      "thisrecentlybyshowingthatthe?-returnisthemaximumlikelihoodestimator\n",
      "2\n",
      "\n",
      "ofV(st)(1)(2)(L)giventhreeassumptions.Sp,Rs?t?argmaxx?R\n",
      "Pr(Rst,Rst,...,Rst|V(st)=x)if(1)\n",
      "(L)\n",
      "Assumption1(Independence).Rst,...,Rstareindependentrandom\n",
      "variables,(n)\n",
      "(n)\n",
      "Assumption2(UnbiasedNormalEstimators).Rstisnormallydistributed\n",
      "withmeanE[Rst]=V(st)foralln.(n)\n",
      "Assumption3(GeometricVariance).Var(Rst)?1/?n.Althoughthis\n",
      "resultprovidesatheoreticalfoundationforthe?-return,itisbasedonthree\n",
      "typicallyfalseassumptions:thereturnsarehighlycorrelated,onlytheMonte\n",
      "Carloreturnisunbiased,andthevarianceofthen-stepreturnsfromeachstate\n",
      "donotusuallyincreasegeometrically.Thissuggeststhreeareaswherethe?-\n",
      "returnmightbeimproved?itcouldbemotobetteraccountforthe(n)\n",
      "correlationofreturns,thebiasofthetreturns,andthetrueformof\n",
      "Var(Rst).The?-returnusesanapproximateformulaforthevarianceofann-\n",
      "stepreturninplaceofAssumption3.Thisallowsthe?-returntobetteraccount\n",
      "forhowthevarianceofreturnsincreaseswiththeir1Tobeclear:thereisa\n",
      "wealthoftheoreticalandempiricalanalysesofalgorithmsthatusethe?-return.\n",
      "Untilrecentlytherewasnotaderivationofthe?-returnastheestimatorofV\n",
      "(st)thatoptimizessomeobjective(e.g.,maximizesloglikelihoodorminimizes\n",
      "expectedsquarederror).\n",
      "2\n",
      "length,whilesimultaneouslyremovingtheneedforthe?parameter.The\n",
      "?-returnisgivenbytheweightingscheme:Pn(i=1?2(i?1))?1w?(n,L)=\n",
      "PLPn?.2(i?1))?1n?=1(i=1?\n",
      "3\n",
      "The?-Return\n",
      "Weproposeanewcomplexreturn,the?-return,thatimprovesuponthe?\n",
      "and?returnsbyaccount(20)(21)ingforthecorrelationsofthereturns.To\n",
      "emphasizethisproblem,noticethatRstandRstwillbealmostidentical(per-\n",
      "fectlycorrelated)formanyMDPs(particularlywhen?issmall).Thismeans\n",
      "thatAssumption1isparticularlyegregious,andsuggeststhatanewcomplex\n",
      "returnmightimproveuponthe?and?-returnsbyproperlyaccountingforthe\n",
      "correlationofreturns.Weformulatetheproblemofhowbesttocombinedif-\n",
      "ferentlengthreturnstoestimatethetrueexpectedreturnasalinearregression\n",
      "problem.Thisreformulationallowsustoleveragethewellunderstoodproperties\n",
      "oflinearregressionalgorithms.ConsideraregressionproblemwithLpoints,\n",
      "f\n",
      "(xi,yi)\n",
      "g\n",
      "Li=1,wherethevalueofyidependsonthevalueofxi.Thegoalis\n",
      "topredictyigiven(i)xi.Wesetxi=1andyi=Rst.Wecanthenconstruct\n",
      "thedesignmatrix(avectorinthiscase),(1)(2)(L)|Lx=1=[1,...,1]?\n",
      "Randtheresponsevector,y=[Rst,Rst,...,Rst]|.Weseekare?This??\n",
      "willbeourestimateofthetrueexpectedgressioncot,???R,suchthat\n",
      "y?x?.return.Generalizedleastsquares(GLS)isamethodforselecting??\n",
      "whentheyiarenotnecessarilyindependentandmayhavetvariances.\n",
      "Sp,ifweusealinearmodelwith(possiblycorrelated)mean-zeronoise\n",
      "3\n",
      "\n",
      "tomodelthedata,i.e.,y=x?+,where??Risunknown,isarandomvector,\n",
      "E[]=0,andVar(|x)=?,thentheGLSestimator??=(x|??1x)?1x|??1\n",
      "y,\n",
      "(2)\n",
      "isthebestlinearunbiasedestimator(BLUE)for?[6]?thelinearunbiased\n",
      "estimatorwiththelowestpossiblevariance.Inoursettingtheassumptions\n",
      "aboutthetruemodelthatproducedthedatabecomethat(1)(2)(L)[Rst,Rst\n",
      ",...,Rst]|=[V(st),V(st),...,V(st)]|+,whereE[]=0(i.e.,the\n",
      "returnsareallunbiasedestimatesofthetrueexpectedreturn)andVar(|x)=\n",
      "?.Sincex=1inourcase,(i)(j)(i)(j)Var(|x)(i,j)=Cov(Rst?V(st),\n",
      "Rst?V(st))=Cov(Rst,Rst),whereVar(|x)(i,j)denotestheelementof\n",
      "Var(|x)intheithrowandjthcolumn.?givesusthecomplexreturn:So,\n",
      "usingonlyAssumption2,GLS((2),solvedfor?)?(1)?????1Rst1?(2)?\n",
      "?1???Rst?1??1?????=??[11...1]??...??[11...1]??..\n",
      "?.(L)1Rst|\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "f\n",
      "z1=PL\n",
      "?1(n,m)n,m=1?\n",
      "P?1(n,m)R(n)=Lstn,m=1?\n",
      "whichcanbewrittenintheformof(1)withweights:PL??1(n,m)w?(n,\n",
      "L)=PLm=1,?1(?n,m)n?,m=1?(i)\n",
      "????,??\n",
      "g\n",
      "(3)\n",
      "(j)\n",
      "where?isanL?Lmatrixwith?(i,j)=Cov(Rst,Rst).Noticethat\n",
      "the?-returnisageneralizationofthe?and?returns.The?-returncanbe\n",
      "obtainedbyreintroducingthefalseassumptionthatthereturnsareindependent\n",
      "andthattheirvariancegrowsgeometrically,i.e.,bymaking?adiagonalmatrix\n",
      "with?n,n=??n.Similarly,the?-returncanbePnobtainedbymaking?a\n",
      "diagonalmatrixwith?n,n=i=1?2(i?1).3\n",
      "NoticethatRs?tisaBLUEofV(st)ifAssumption2holds.SinceAs-\n",
      "sumption2doesnothold,the?-returnisnotanunbiasedestimatorofV(s).\n",
      "Still,weexpectittooutperformthe?and?-returnsbecauseitaccountsfor\n",
      "thecorrelationofn-stepreturnsandtheydonot.However,insomecasesit\n",
      "mayperformworsebecauseitisstillbasedonthefalseassumptionthatallof\n",
      "thereturnsareunbiasedestimatorsofV(st).Furthermore,givenAssumption\n",
      "2,theremaybebiasedestimatorsofV(st)thathavelowerexpectedmean\n",
      "squarederrorthanaBLUE(whichmustbeunbiased).\n",
      "4\n",
      "Approximatingthe?-Return\n",
      "Inpracticethecovariancematrix,?,isunknownandmustbeapproximated\n",
      "fromdata.Thisapproach,knownasfeasiblegeneralizedleastsquares(FGLS),\n",
      "canperformworsethanordinaryleastsquaresgiventdatatoac-\n",
      "curatelyestimate?.Wemustthereforeaccuratelyapproximate?fromsmall\n",
      "amountsofdata.Tostudytheaccuracyofcovariancematrixestimates,we\n",
      "estimated?usingalargenumberoftrajectoriesforfourrentdomains:a\n",
      "5?5gridworld,avariantofthecanonicalmountaincardomain,areal-world\n",
      "digitalmarketingproblem,andacontinuouscontrolproblem(DAS1),allof\n",
      "4\n",
      "\n",
      "whicharedescribedinmoredetailinsubsequentexperiments.Thecovariance\n",
      "matrixestimatesaredepictedinFigures1(a),2(a),3(a),and4(a).Wedonot\n",
      "specifyrowsandcolumnsinthebecauseallcovariancematricesandes-\n",
      "timatesthereofaresymmetric.Becausetheywerecomputedfromaverylarge\n",
      "numberoftrajectories,wewilltreatthemasgroundtruth.Wemustestimate\n",
      "the?-returnwhenonlyafewtrajectoriesareavailable.Figures1(b),2(b),3(b),\n",
      "and4(b)showdirectempiricalestimatesofthecovariancematricesusingonly\n",
      "afewtrajectories.Theseempiricalapproximationsarepoorduetothevery\n",
      "limitedamountofdata,exceptforthedigitalmarketingdomain,wherea?few?\n",
      "trajectoriesmeans10,000.ThesolidblackentriesinFigures1(f),2(f),3(f),\n",
      "and4(f)showtheweights,w?(n,L),onrentlengthreturnswhenusing\n",
      "testimatesof?.Thenoiseinthedirectempiricalestimateofthecovari-\n",
      "ancematrixusingonlyafewtrajectoriesleadstopoorestimatesofthereturn\n",
      "weights.Whenapproximating?fromasmallnumberoftrajectories,wemust\n",
      "becarefultoavoidthisovoftheavailabledata.Onewaytodothisis\n",
      "toassumeacompactparametricmodelfor?.Belowwedescribeaparametric\n",
      "modelof?thathasonlyfourparameters,regardlessofL(whichdetermines\n",
      "thesizeof?).Weusethisparametricmodelinourexperimentsasaproofof\n",
      "concept?weshowthatthe?-returnusingeventhissimpleestimateof?can\n",
      "produceimprovedresultsovertheotherexistingcomplexreturns.Wedonot\n",
      "claimthatthisschemeforestimating?isparticularlyprincipledornoteworthy.\n",
      "4.1\n",
      "EstimatingEntriesof?\n",
      "NoticeinFigures1(a),2(a),3(a),and4(a)thatforj>i,Cov(Rsit,Rsjt\n",
      ")?Cov(Rsit,Rsit)=Var(Rsit).Thisstructurewouldmeanthatwecan\n",
      "in?givenitsdiagonalvalues,leavingonlyLparameters.Wenowexplain\n",
      "whythisrelationshipisreasonableingeneral,andnotjustanartifactofour\n",
      "domains.Wecanwriteeachentryin?asarecurrencerelation:Cov[Rs(i),\n",
      "Rs(j)]=Cov[Rs(i),Rs(j?1)+?j?1(rt+j+?V?(st+j)?V?(st+j?1)]ttt\n",
      "t=Cov[Rs(i),Rs(j?1)]+?j?1Cov[Rs(i),rt+j+?V?(st+j)?V?(st+j?1\n",
      ")],ttt\n",
      "wheni<j.Thetermrt+j+?V?(st+j)?V?(st+j?1)isthetemporal\n",
      "errorjstepsinthefuture.TheproposedassumptionthatCov(Rsi\n",
      "t,Rsjt)=Var(Rsit)isequivalenttoassumingthatthecovarianceofthis\n",
      "temporalerrorandthei-stepreturnisnegligible:(i)?j?1Cov[Rst,\n",
      "rt+j+?V?(st+j)?V?(st+j?1)]?0.Theapproximateindependenceofthese\n",
      "twotermsisreasonableingeneralduetotheMarkovproperty,whichensures\n",
      "thatatleasttheconditional(i)covariance,Cov[Rst,rt+j+?V?(st+j)?V?\n",
      "(st+j?1)|st],iszero.Becausethisrelationshipisnotexact,the\n",
      "entriestendtogrowastheygetfartherfromthediagonal.However,especially\n",
      "whensometrajectoriesarepaddedwithabsorbingstates,thisrelationshipis\n",
      "quiteaccuratewhenj=L,sincethetemporalerrorsattheabsorbing\n",
      "state(i)(i)(L?1)areallzero,andCov[Rst,0]=0.Thisresultsinat\n",
      "betweenCov[Rst,Rst]4\n",
      "25\n",
      "30\n",
      "5\n",
      "\n",
      "20\n",
      "20\n",
      "25\n",
      "30\n",
      "2020\n",
      "15\n",
      "1510\n",
      "10\n",
      "100\n",
      "5\n",
      "?100\n",
      "00\n",
      "005\n",
      "5\n",
      "20\n",
      "10\n",
      "20\n",
      "10\n",
      "15\n",
      "15\n",
      "1020\n",
      "525\n",
      "25\n",
      "5\n",
      "15\n",
      "15\n",
      "1020\n",
      "5\n",
      "20\n",
      "10\n",
      "15\n",
      "15\n",
      "1020\n",
      "00\n",
      "5\n",
      "20\n",
      "10\n",
      "15\n",
      "15\n",
      "10\n",
      "5\n",
      "1020\n",
      "5\n",
      "525\n",
      "25\n",
      "6\n",
      "\n",
      "(a)Empirical?from1(b)Empirical?from5(c)Approximate?from(d)\n",
      "Approximate?frommilliontrajectories.trajectories.1milliontrajectories.5\n",
      "trajectories.1\n",
      "1,000\n",
      "MeanSquaredError\n",
      "Weight,w(n,20)\n",
      "Variance\n",
      "30\n",
      "15\n",
      "00\n",
      "1\n",
      "20\n",
      "ReturnLengthEmpirical1M\n",
      "Approx1M\n",
      "Empirical5\n",
      "Approx5\n",
      "100\n",
      "20\n",
      "-0.2\n",
      "App?,1.95394\n",
      "?=0.8,3.19055\n",
      "10\n",
      "1\n",
      "ReturnLength,nEmpirical1M\n",
      "Approx1M\n",
      "Empirical5\n",
      "ReturnType\n",
      "Approx5\n",
      "(e)Approximateandempiri-(f)Approximateandempiricalweights(g)\n",
      "Meansquarederrorfrometrajeccaldiagonalsof?.foreachreturn.tories.\n",
      "Figure1:GridworldResults.\n",
      "80\n",
      "200\n",
      "8060\n",
      "150\n",
      "60100\n",
      "100\n",
      "40\n",
      "40\n",
      "20\n",
      "0\n",
      "0\n",
      "?1000\n",
      "?20010\n",
      "0010\n",
      "302015\n",
      "7\n",
      "\n",
      "305\n",
      "40\n",
      "3020\n",
      "5\n",
      "40\n",
      "15\n",
      "30\n",
      "10\n",
      "5\n",
      "25\n",
      "20\n",
      "2015\n",
      "30\n",
      "10\n",
      "10\n",
      "3025\n",
      "20\n",
      "2015\n",
      "30\n",
      "1040\n",
      "25\n",
      "20\n",
      "00\n",
      "10\n",
      "30\n",
      "25\n",
      "20\n",
      "50\n",
      "20\n",
      "105\n",
      "40\n",
      "(a)Empirical?from1(b)Empirical?from2(c)Approximate?from(d)\n",
      "Approximate?frommilliontrajectories.trajectories.1milliontrajectories.2\n",
      "trajectories.1\n",
      "10,000\n",
      "Approx1M\n",
      "Empirical2\n",
      "Approx2\n",
      "?\n",
      "App?\n",
      "?=1\n",
      "?=0.9\n",
      "Emp?\n",
      "ReturnType\n",
      "?=0.8\n",
      "?=0.7\n",
      "8\n",
      "\n",
      "?=0.6\n",
      "ReturnLength,nEmpirical1M\n",
      "?=0.5\n",
      "-0.2\n",
      "App?,76.39?=0.4\n",
      "Approx2\n",
      "WIS,144.4810?=0.3\n",
      "Approx1M\n",
      "Empirical2\n",
      "30\n",
      "?=0.2\n",
      "ReturnLengthEmpirical1M\n",
      "1\n",
      "30\n",
      "?=0\n",
      "0\n",
      "100\n",
      "?=0.1\n",
      "0\n",
      "1,000\n",
      "IS\n",
      "80\n",
      "WIS\n",
      "MeanSquaredError\n",
      "Weight,w(n,11)\n",
      "Variance\n",
      "160\n",
      "(e)Approximateandempiri-(f)Approximateandempiricalweights(g)\n",
      "Meansquarederrorfromtwotrajeccaldiagonalsof?.foreachreturn.tories.\n",
      "Figure2:MountainCarResults.\n",
      "5\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.15\n",
      "0.15\n",
      "0.15\n",
      "0.15\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.05\n",
      "0.05\n",
      "0.05\n",
      "9\n",
      "\n",
      "0.05\n",
      "0\n",
      "01\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9101\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "0\n",
      "13\n",
      "2\n",
      "10\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9101\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "7\n",
      "9\n",
      "2\n",
      "10\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "10\n",
      "\n",
      "7\n",
      "8\n",
      "9101\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "6\n",
      "5\n",
      "9\n",
      "8\n",
      "2\n",
      "3\n",
      "10\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9101\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "7\n",
      "10\n",
      "9\n",
      "(a)Empirical?from1(b)Empirical?from(c)Approximate?from\n",
      "(d)Approximate?frommilliontrajectories.10000trajectories.1million\n",
      "trajectories.10000trajectories.1\n",
      "0.08\n",
      "1\n",
      "MeanSquaredError\n",
      "0.004\n",
      "Weight,w(n,10)\n",
      "10\n",
      "App?,0.00110.002\n",
      "?=0,0.0011Emp?,0.0007\n",
      "Approx1M\n",
      "Empirical10k\n",
      "App?\n",
      "?\n",
      "?=1\n",
      "Emp?\n",
      "11\n",
      "\n",
      "?=0.9\n",
      "?=0.8\n",
      "?=0.7\n",
      "?=0.6\n",
      "ReturnLength,nEmpirical1M\n",
      "?=0.5\n",
      "-0.5\n",
      "?=0.4\n",
      "Approx10k\n",
      "?=0.3\n",
      "Approx1M\n",
      "Empirical10k\n",
      "?=0.2\n",
      "10\n",
      "ReturnLengthEmpirical1M\n",
      "?=0\n",
      "0\n",
      "IS\n",
      "0\n",
      "?=0.1\n",
      "0WIS\n",
      "Variance\n",
      "0.16\n",
      "ReturnType\n",
      "Approx10k\n",
      "(e)Approximateandempiri-(f)Approximateandempiricalweights(g)\n",
      "Meansquarederrorfrom10000tracaldiagonalsof?.foreachreturn.jectories.\n",
      "Figure3:DigitalMarketingResults.\n",
      "40\n",
      "30\n",
      "40\n",
      "25\n",
      "30\n",
      "20\n",
      "30\n",
      "20\n",
      "20\n",
      "10\n",
      "20\n",
      "10\n",
      "0\n",
      "10\n",
      "00\n",
      "?100\n",
      "00\n",
      "1510\n",
      "12\n",
      "\n",
      "5\n",
      "5\n",
      "20\n",
      "10\n",
      "25\n",
      "25\n",
      "15\n",
      "15\n",
      "1020\n",
      "20\n",
      "10\n",
      "15\n",
      "15\n",
      "5\n",
      "5\n",
      "20\n",
      "10\n",
      "1020\n",
      "5\n",
      "5\n",
      "15\n",
      "15\n",
      "1020\n",
      "20\n",
      "10\n",
      "15\n",
      "15\n",
      "500\n",
      "1020\n",
      "5\n",
      "525\n",
      "25\n",
      "(a)Empirical?from(b)Empirical?from10(c)Approximate?from(d)\n",
      "Approximate?from10000trajectories.trajectories.10000trajectories.10\n",
      "trajectories.1\n",
      "Approx10K\n",
      "Empirical10\n",
      "Approx10\n",
      "App?\n",
      "?\n",
      "Emp?\n",
      "?=0.6\n",
      "?=0.5\n",
      "?=0.4\n",
      "?=0.3\n",
      "ReturnLength,nEmpirical10K\n",
      "13\n",
      "\n",
      "?=0\n",
      "-0.5\n",
      "?=0.2\n",
      "Approx10\n",
      "?=0.1\n",
      "Approx10K\n",
      "Empirical10\n",
      "IS\n",
      "ReturnLengthEmpirical10K\n",
      "20\n",
      "WIS\n",
      "10\n",
      "?=1\n",
      "?=1,3.47436App?,3.1070\n",
      "10\n",
      "?=0.9\n",
      "20\n",
      "0\n",
      "?=0.8\n",
      "1\n",
      "?=0,3.2102\n",
      "10\n",
      "?=0.7\n",
      "20\n",
      "MeanSquaredError\n",
      "Weight,w(n,10)\n",
      "Variance\n",
      "40\n",
      "100\n",
      "ReturnType\n",
      "(e)Approximateandempiri-(f)Approximateandempiricalweights(g)\n",
      "Meansquarederrorfrom10trajeccaldiagonalsof?.foreachreturn.tories.\n",
      "Figure4:FunctionalElectricalStimulationResults.\n",
      "6\n",
      "(i)\n",
      "(L)\n",
      "andCov[Rst,Rst].Ratherthantrytomodelthisdrop,whichcan\n",
      "theweightstly,wereintroducetheassumptionthattheMonteCarlo\n",
      "returnisindependentoftheotherreturns,makingtheelementsof\n",
      "thelastrowandcolumnzero.EstimatingDiagonalEntriesof?\n",
      "4.2\n",
      "Theremainingquestionishowbesttoapproximatethediagonalof?froma\n",
      "verysmallnumberoftrajectories.Considerthesolidanddottedblackcurvesin\n",
      "Figures1(e),2(e),3(e),and4(e),whichdepictthediagonalsof?whenestimated\n",
      "fromeitheralargenumberorsmallnumberoftrajectories.Whenusingonly\n",
      "afewtrajectories,thediagonalincludesthatcanhavet\n",
      "14\n",
      "\n",
      "impactsontheresultingweights.However,whenusingmanytrajectories(which\n",
      "wetreatasgivinggroundtruth),thediagonaltendstoberelativelysmooth\n",
      "andmonotonicallyincreasinguntilitplateaus(ignoringtheentry).This\n",
      "suggestsusingasmoothparametricformtoapproximatethediagonal,whichwe\n",
      "doasfollows.(i)LetvidenotethesamplevarianceofRstfori=1...L.Let\n",
      "v+bethelargestsamplevariance:v+=maxi?\n",
      "f\n",
      "1,...,L\n",
      "g\n",
      "vi.Weparameterize\n",
      "thediagonalusingfourparameters,k1,k2,v+,andvL:??ifi=1?k1\n",
      "?ifi=L?k1,k2,v+,vL(i,i)=vL??min\n",
      "f\n",
      "v,kk(1?t)\n",
      "g\n",
      "otherwise.+12\n",
      "?(1,1)=k1setstheinitialvariance,andvListhevarianceoftheMonteCarlo\n",
      "return.Theparameterv+enforcesaceilingonthevarianceofthei-stepreturn,\n",
      "andk2capturesthegrowthrateofthevariance,muchlike?.Weselectthek1\n",
      "andk2thatminimizethemeansquarederrorbetween?i)andvi,andset\n",
      "v+andvLdirectlyfromthedata.2?(i,Thisreducestheproblemofestimating\n",
      "?,anL?Lmatrix,toestimatingfournumbersfromreturn?ascomputed\n",
      "frommanytrajectories.data.ConsiderFigures1(c),2(c),3(c),and4(c),which\n",
      "depict?Thebetweentheseestimatesandthegroundtruthshow\n",
      "thatthisparameterizationisnotperfect,aswecannotrepresentthetrue?\n",
      "exactly.However,theestimateisreasonableandtheresultingweights(solid\n",
      "red)arevisuallysimilartothegroundtruthweights(solidblack)inFigures\n",
      "1(f),2(f),3(f),and4(f).Wecannowgetaccurateestimatesof?fromvery\n",
      "fewtrajectories.Figures?whencomputedfromonlyafewtrajectories.Note\n",
      "theirsimilarity1(d),2(d),3(d),and4(d)show??to?whenusingalarge\n",
      "numberoftrajectories,andthattheresultingweightsredinFigures\n",
      "1(f),2(f),3(f),and4(f))aresimilartothethoseobtainedusingmanymore\n",
      "trajectories(theredbars).Pseudocodeforapproximatingthe?-returnis\n",
      "providedinAlgorithm1.Unlikethe?-return,whichcanbecomputedfroma\n",
      "singletrajectory,the?-returnrequiresasetoftrajectoriesinordertoestimate\n",
      "?.ThepseudocodeassumesthateverytrajectoryisoflengthL,whichcanbe\n",
      "achievedbypaddingshortertrajectorieswithabsorbingstates.\n",
      "2\n",
      "Weincludetheconstraintsthatk2?[0,1]and0?k1?v+.\n",
      "7\n",
      "Algorithm1:Computingthe?-return.Require:ntrajectoriesbeginningat\n",
      "sandoflengthL.(i)\n",
      "1.ComputeRsfori=1,...,Landforeachtrajectory.(i)\n",
      "2.Computethesamplevariances,vi=Var(Rs),fori=1,...,L.3.Set\n",
      "v+=maxi?\n",
      "f\n",
      "1,...,L\n",
      "g\n",
      "vi.4.Searchforthek1andk2thatminimizethemean\n",
      "squarederrorbetweenviand?k,k,v,v(i,i)fori=1,...,L.?1\n",
      "2\n",
      "+\n",
      "L\n",
      "?k,k,v,v(i,i),usingthe5.FillthediagonaloftheL?Lmatrix,?,with\n",
      "?(i,i)=?12+Loptimizedk1andk2.6.Fillalloftheotherentrieswith\n",
      "?(i,j)=?(i,i)wherej>i.If(i=Lorj=L)andi6=jthenset?(i,j)=0\n",
      "instead.7.Computetheweightsforthereturnsaccordingto(3).8.Compute\n",
      "the?-returnforeachtrajectoryaccordingto(1).\n",
      "15\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Experiments\n",
      "Approximationsofthe?-returncould,inprinciple,replacethe?-returnin\n",
      "thewholefamilyofTD(?)algorithms.However,usingthe?-returnforTD(?)\n",
      "raisesseveralinterestingquestionsthatarebeyondthescopeofthisinitialwork\n",
      "(e.g.,istherealinear-timewaytoestimatethe?-return?Sinceat?\n",
      "isneededforeverystate,howcanthe?-returnbeusedwithfunctionapproxi-\n",
      "mationwheremoststateswillneverberevisited?).Wethereforefocusonthe\n",
      "spproblemofolicypolicyevaluation?estimatingtheperformanceofa\n",
      "policyusingtrajectoriesgeneratedbyapossiblytpolicy.Thisproblem\n",
      "isofinterestforapplicationsthatrequiretheevaluationofaproposedpolicy\n",
      "usinghistoricaldata.Duetospaceconstraints,werelegatethedetailsofour\n",
      "experimentstotheappendixinthesupplementaldocuments.However,there-\n",
      "sultsoftheexperimentsareclear?Figures1(g),2(g),3(g),and4(g)showthe\n",
      "meansquarederror(MSE)ofvalueestimateswhenusingvariousmethods.3\n",
      "Noticethat,foralldomains,usingthe?-return(theEMP?andAPP?labels)\n",
      "resultsinlowerMSEthanthe?-returnandthe?-returnwithanysettingof?.\n",
      "6\n",
      "Conclusions\n",
      "Recentworkhasbeguntoexplorethestatisticalbasisofcomplexestimates\n",
      "ofreturn,andhowwemightreformulatethemtobemorestatisticallyt\n",
      "[4].Wehaveproposedareturnestimatorthatimprovesuponthe?and?-\n",
      "returnsbyaccountingforthecovarianceofreturnestimates.Ourresultsshow\n",
      "thatunderstandingandexploitingthefactthatincontrolsettings?unlikein\n",
      "standardsupervisedlearning?observedsamplesaretypicallyneitherindepen-\n",
      "dentnoridenticallydistributed,cansubstantiallyimprovedatainan\n",
      "algorithmoftpracticalimportance.Many(largelypositive)theoret-\n",
      "icalpropertiesofthe?-returnandTD(?)havebeendiscoveredoverthepast\n",
      "fewdecades.Thislineofresearchintoothercomplexreturnsisstillinitsin-\n",
      "fancy,andsotherearemanyopenquestions.Forexample,canthe?-return\n",
      "beimproveduponbyremovingAssumption2orbykeepingAssumption2but\n",
      "usingabiasedestimator(notaBLUE)?Isthereamethodforapproximating\n",
      "the?-returnthatallowsforvaluefunctionapproximationwiththesametime\n",
      "complexityasTD(?),orwhichbetterleveragesourknowledgethattheenviron-\n",
      "mentisMarkovian?WouldTD(?)usingthe?-returnbeconvergentinthesame\n",
      "settingsasTD(?)?Whilewehopetoanswerthesequestionsinfuturework,it\n",
      "isalsoourhopethatthisworkwillinspireotherresearcherstorevisittheprob-\n",
      "lemofconstructingastatisticallyprincipledcomplexreturn.3Tocomputethe\n",
      "MSEweusedalargenumberofMonteCarlorolloutstoestimatethetruevalue\n",
      "ofeachpolicy.\n",
      "8\n",
      "16\n",
      "\n",
      "2References\n",
      "[1]R.S.Sutton.Learningtopredictbythemethodsoftemporal\n",
      "MachineLearning,3(1):9?44,1988.[2]S.J.BradtkeandA.G.Barto.Linear\n",
      "least-squaresalgorithmsfortemporallearning.MachineLearning,\n",
      "22(1-3):33?57,March1996.[3]C.DowneyandS.Sanner.Temporal\n",
      "Bayesianmodelaveraging:ABayesianperspectiveonadaptinglambda.In\n",
      "Proceedingsofthe27thInternationalConferenceonMachineLearning,pages\n",
      "311?318,2010.[4]G.D.Konidaris,S.Niekum,andP.S.Thomas.TD?:\n",
      "Re-evaluatingcomplexbackupsintemporaldrencelearning.InAdvances\n",
      "inNeuralInformationProcessingSystems24,pages2402?2410,2011.[5]R.\n",
      "S.SuttonandA.G.Barto.ReinforcementLearning:AnIntroduction.MIT\n",
      "Press,Cambridge,MA,1998.[6]T.KariyaandH.Kurata.GeneralizedLeast\n",
      "Squares.Wiley,2004.[7]D.Precup,R.S.Sutton,andS.Singh.Eligibility\n",
      "tracesforolicypolicyevaluation.InProceedingsofthe17thInternational\n",
      "ConferenceonMachineLearning,pages759?766,2000.[8]A.R.Mahmood,H.\n",
      "Hasselt,andR.S.Sutton.Weightedimportancesamplingforolicylearn-\n",
      "ingwithlinearfunctionapproximation.InAdvancesinNeuralInformation\n",
      "ProcessingSystems27,2014.[9]J.R.TetreaultandD.J.Litman.Comparing\n",
      "theutilityofstatefeaturesinspokendialogueusingreinforcementlearning.In\n",
      "ProceedingsoftheHumanLanguageTechnology/NorthAmericanAssociation\n",
      "forComputationalLinguistics,2006.[10]G.D.Konidaris,S.Osentoski,andP.\n",
      "S.Thomas.Valuefunctionapproximationinreinforcementlearningusingthe\n",
      "Fourierbasis.InProceedingsoftheTwenty-FifthConferenceonIntel-\n",
      "ligence,pages380?395,2011.[11]G.TheocharousandA.Hallak.Lifetimevalue\n",
      "marketingusingreinforcementlearning.InThe1stMultidisciplinaryConfer-\n",
      "enceonReinforcementLearningandDecisionMaking,2013.[12]P.S.Thomas,\n",
      "G.Theocharous,andM.Ghavamzadeh.Higholicyevaluation.\n",
      "InProceedingsoftheTwenty-NinthConferenceonIntelligence,2015.\n",
      "[13]D.Blana,R.F.Kirsch,andE.K.Chadwick.Combinedfeedforwardand\n",
      "feedbackcontrolofaredundant,nonlinear,dynamicmusculoskeletalsystem.\n",
      "MedicalandBiologicalEngineeringandComputing,47:533?542,2009.[14]P.\n",
      "S.Thomas,M.S.Branicky,A.J.vandenBogert,andK.M.Jagodnik.Appli-\n",
      "cationoftheactor-criticarchitecturetofunctionalelectricalstimulationcontrol\n",
      "ofahumanarm.InProceedingsoftheTwentyFirstInnovativeApplicationsof\n",
      "Intelligence,pages165?172,2009.[15]P.M.Pilarski,M.R.Dawson,\n",
      "T.Degris,F.Fahimi,J.P.Carey,andR.S.Sutton.Onlinehumantrainingofa\n",
      "myoelectricprosthesiscontrollerviaactor-criticreinforcementlearning.InPro-\n",
      "ceedingsofthe2011IEEEInternationalConferenceonRehabilitationRobotics,\n",
      "pages134?140,2011.[16]K.JagodnikandA.vandenBogert.Aproportional\n",
      "derivativeFEScontrollerforplanararmmovement.In12thAnnualConfer-\n",
      "enceInternationalFESSociety,Philadelphia,PA,2007.[17]N.HansenandA.\n",
      "Ostermeier.Completelyderandomizedself-adaptationinevolutionstrategies.\n",
      "EvolutionaryComputation,9(2):159?195,2001.\n",
      "9\n",
      "17\n",
      "\n",
      "PP7221.pdf\n",
      "PP7221.pdf 13\n",
      "MatrixNormEstimationfromaFewEntries\n",
      "Authoredby:\n",
      "SewoongOh\n",
      "AshishKhetan\n",
      "Abstract\n",
      "Singularvaluesofadatainamatrixformprovideinsightsonthe\n",
      "structureofthedata,theedimensionality,andthechoiceofhyper-\n",
      "parametersonhigher-leveldataanalysistools.However,inmanypractical\n",
      "applicationssuchascollaborativeandnetworkanalysis,weonly\n",
      "getapartialobservation.Undersuchscenarios,weconsiderthefunda-\n",
      "mentalproblemofrecoveringvariousspectralpropertiesoftheunderlying\n",
      "matrixfromasamplingofitsentries.Weproposeaframeworkof\n",
      "estimatingtheSchatten$k$-normsofamatrixforseveralvaluesof$k$,\n",
      "andusingtheseassurrogatesforestimatingspectralpropertiesofinter-\n",
      "est,suchasthespectrumitselfortherank.Thispaperfocusesonthe\n",
      "technicalchallengesinaccuratelyestimatingtheSchattennormsfroma\n",
      "samplingofamatrix.Weintroduceanovelunbiasedestimatorbasedon\n",
      "countingsmallstructuresinagraphandprovideguaranteesthatmatch\n",
      "itsempiricalperformances.OurtheoreticalanalysisshowsthatSchatten\n",
      "normscanberecoveredaccuratelyfromstrictlysmallernumberofsamples\n",
      "comparedtowhatisneededtorecovertheunderlyinglow-rankmatrix.\n",
      "Numericalexperimentssuggestthatwetlyimproveuponacom-\n",
      "petingapproachofusingmatrixcompletionmethods.\n",
      "1PaperBody\n",
      "Computingandanalyzingthesetofsingularvaluesofadatainamatrixform,\n",
      "whichiscalledthespectrum,provideinsightsintothegeometryandtopology\n",
      "ofthedata.Suchaspectralanalysisisroutinelyastepingeneraldata\n",
      "analysiswiththegoalofcheckingifthereexistsalowerdimensionalsubspace\n",
      "explainingtheimportantaspectsofthedata,whichitselfmightbehighdimen-\n",
      "sional.Concretely,itisastepindimensionalityreductionmethodssuchas\n",
      "principalcomponentanalysisorcanonicalcorrelationanalysis.However,spec-\n",
      "tralanalysisbecomeschallenginginpracticalscenarioswherethedataisonly\n",
      "partiallyobserved.Wecommonlyobservepairwiserelationsofrandomlychosen\n",
      "pairs:eachuseronlyratesafewmoviesinrecommendationsystems,andeach\n",
      "player/teamonlyplaysagainstafewopponentsinsports.Inotherapplications,\n",
      "wehavemorestructuredsamples.Forexample,inanetworkanalysiswemight\n",
      "1\n",
      "\n",
      "beinterestedinthespectrumoftheadjacencymatrixofalargenetwork,but\n",
      "onlygettoseetheconnectionswithinasmallsubsetofnodes.Whateverthe\n",
      "samplingpatternis,typicalnumberofpairedrelationsweobserveistly\n",
      "smallerthanthedimensionofthedatamatrix.Westudyallsuchvariations\n",
      "insamplingpatternsforpartiallyobserveddatamatrices,andaskthefollow-\n",
      "ingfundamentalquestion:canweestimatespectralpropertiesofadatamatrix\n",
      "frompartialobservations?Webuildonthefactthatseveralspectralproperties\n",
      "ofinterest,suchasthespectrumitselfortherank,canbeestimatedaccurately\n",
      "viaestimatingtheSchattenk-normsofamatrixandthenaggregatingthose\n",
      "normstoestimatethespectralproperties.Inthispaper,wefocusonthePd\n",
      "challengingtaskofestimatingtheSchattenk-normsaskMkk=(i=1\n",
      "?i(M)k)1/k,where?1(M)??????d(M)aresingularvaluesof\n",
      "thedatamatrixM?Rd?d.OnceweobtainaccurateestimatesofSchatten\n",
      "k-norms,theseestimates,aswellascorrespondingperformanceguarantees,can\n",
      "readilybetranslatedintoaccurateestimatesofthespectralpropertiesofinter-\n",
      "est.31stConferenceonNeuralInformationProcessingSystems(NIPS2017),\n",
      "LongBeach,CA,USA.\n",
      "1.1\n",
      "Setup\n",
      "WewanttoestimatetheSchattenk-normofapositivematrix\n",
      "M?Rd?dfromasubsetofitsentries.Therestrictiontopositives\n",
      "matricesisfornotationalconvenience,andouranalyses,theestimator,andthe\n",
      "talgorithmsnaturallygeneralizetoanynon-squarematrices.Namely,\n",
      "wecanextendourframeworktobipartitegraphsandestimateSchattenk-norm\n",
      "ofanymatrixforanyevenk.Let?denotethesetofindicesofsamplesweare\n",
      "givenandletP?(M)=\n",
      "f\n",
      "(i,j,Mij)\n",
      "g\n",
      "(i,j)??denotethesamples.Withaslight\n",
      "abuseofnotation,weusedP?(M)toalsodenotethed?dsampledmatrix:\n",
      "Mijif(i,j)??,P?(M)ij=0otherwise,anditshouldbeclearfromthe\n",
      "contextwhichonewereferto.Althoughweproposeaframeworkthatgenerally\n",
      "appliestoanyprobabilisticsampling,itisnecessarytoproposespsampling\n",
      "scenariostoprovidetightanalysesontheperformance.Hence,wefocuson\n",
      "Erd?s-R?nyisampling.Thereisanextensivelineofresearchinlow-rankmatrix\n",
      "completionproblems[3,11],whichaddressesafundamentalquestionofhow\n",
      "manysamplesarerequiredtocompleteamatrix(i.e.estimateallthemissing\n",
      "entries)fromasmallsubsetofsampledentries.Itistypicallyassumedthat\n",
      "eachentryofthematrixissampledindependentlywithaprobabilityp?(0,1].\n",
      "WerefertothisscenarioasErd?s-R?nyisampling,astheresultingpatternof\n",
      "thesamplesencodedasagraphisdistributedasanErd?s-R?nyirandomgraph.\n",
      "Thespectralpropertiesofsuchansampledmatrixhavebeenwellstudiedinthe\n",
      "literature[7,1,6,11,14].Inparticular,itisknownthattheoriginalmatrixis\n",
      "closeinspectralnormtothesampledonewherethemissingentriesarein\n",
      "withzerosandproperlyrescaledundercertainincoherenceassumptions.This\n",
      "suggestsusingthesingularvaluesof(d2/|?|)P(M)directlyforestimating\n",
      "theSchattennorms.However,inthesub-linearregimeinwhichthenumberof\n",
      "samples|?|=d2piscomparabletoortlysmallerthanthedegrees\n",
      "offreedominrepresentingasymmetricrank-rmatrix,whichisdr?r2,the\n",
      "2\n",
      "\n",
      "spectrumofthesampledmatrixistlytfromthespectrumof\n",
      "theoriginalmatrixasshowninFigure1.Weneedtodesignnovelestimators\n",
      "thataremoresampleetinthesub-linearregimewhered2pdr.50\n",
      "?histogramof\n",
      "f\n",
      "?i(M)\n",
      "g\n",
      "di=1\n",
      "40\n",
      "30\n",
      "histogramof(rescaled)\n",
      "f\n",
      "?i(P?(M))\n",
      "g\n",
      "di=1\n",
      "?\n",
      "20\n",
      "10\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "Figure1:Histogramof(positive)singularvaluesofMwithrankr=100(in\n",
      "yellow),andsingularvaluesofthesampledmatrix(inblack).1.2\n",
      "Summaryoftheapproachandpreviewofresults\n",
      "WeproposeusinganalternativeexpressionoftheSchattenk-normforpos-\n",
      "itivematricesasthetraceofthek-thpowerofM,i.e.(kMkk)k\n",
      "=Tr(Mk).ThissumoftheentriesalongthediagonalofMkisthesumof\n",
      "totalweightsofalltheclosedwalksoflengthk.ConsidertheentriesofMas\n",
      "weightsonacompletegraphKdoverdnodes(withself-loops).Aclosedwalk\n",
      "oflengthkisasasequenceofnodesw=(w1,w2,...,wk+1)with\n",
      "w1=wk+1,whereweallowrepeatednodesandrepeatededges.Theweight\n",
      "ofaclosedwalkw=(w1,...,wk,w1)isasQk?M(w)?i=1\n",
      "Mwiwi+1,whichistheproductoftheweightsalongthewalk.Itfollowsthat\n",
      "XkMkkk=?M(w).(1)w:alllengthkclosedwalks\n",
      "Followingthenotationsfromenumerationofsmallsimplecyclesinagraph\n",
      "by[2],wepartitionthissummationintothosewiththesamepatternHthatwe\n",
      "callak-cyclicpseudograph.Let2\n",
      "Ck=(Vk,Ek)denotetheundirectedsimplecyclegraphwithknodes,e.g.\n",
      "A3inFigure2isC3.Weexpandthestandardnotionofsimplek-cyclicgraphs\n",
      "toincludemultiedgesandloops,hencethenamepseudograph.1\n",
      "WeanunlabelledandundirectedpseudographH=(VH,EH)tobea\n",
      "k-cyclicpseudographfork?3ifthereexistsanontonode-mappingfromCk=\n",
      "(Vk,Ek),i.e.f:Vk?VH,andaone-to-oneedge-mappingg:Ek?EHsuch\n",
      "thatg(e)=(f(ue),f(ve))foralle=(ue,ve)?Ek.WeuseHktodenotethe\n",
      "setofallk-cyclicpseudographs.Weusec(H)tothenumberoftnode\n",
      "mappingsffromCktoak-cyclicpseudographH.\n",
      "A1\n",
      "A2\n",
      "A3\n",
      "c(A1)=1\n",
      "c(A2)=3\n",
      "c(A3)=6\n",
      "3\n",
      "\n",
      "Figure2:The3-cyclicpseudographsH3=\n",
      "f\n",
      "A1,A2,A3\n",
      "g\n",
      ".Intheabove\n",
      "example,eachmemberofH3isadistinctpatternthatcanbemappedfromC3\n",
      ".ForA1,itisclearthatthereisonlyonemappingfromC3toA1(i.e.c(A1\n",
      ")=1).ForA2,onecanmapanyofthethreenodestotheleft-nodeofA2\n",
      ",hencec(A2)=3.ForA3,anyofthethreenodescanbemappedtothe\n",
      "bottom-left-nodeofA3andalsoonecanmaptherestofthenodesclockwiseor\n",
      "counter-clockwise,resultinginc(A3)=6.Fork?7,allthek-cyclicpseudo\n",
      "graphsaregivenintheAppendixE(SeeFigures8?13).Eachclosedwalkwof\n",
      "lengthkisassociatedwithoneofthegraphsinHk,asthereisauniqueHthat\n",
      "thewalkisanEuleriancycleof(underaone-to-onemappingofthenodes).We\n",
      "denotethisgraphbyH(w)?Hk.Consideringtheweightofawalk?M(w),\n",
      "therearemultipledistinctwalkswiththesameweight.Forexample,alength-3\n",
      "walkw=(v1,v2,v2,v1)hasH(w)=A2andthereare3walkswiththe\n",
      "sameweight?(w)=(Mv1v2)2Mv2v2,i.e.(v1,v2,v2,v1),(v2,v2,v1\n",
      ",v2),and(v2,v1,v2,v2).Thismultiplicityoftheweightdependsonlyon\n",
      "thestructureH(w)ofawalk,anditisexactlyc(H(w))thenumberofmappings\n",
      "fromCktoH(w)in1.Thetotalsumoftheweightsofclosedwalks\n",
      "oflengthkcanbepartitionedintotheirrespectivepattern,whichwillmake\n",
      "computationofsuchtermsmoret(seeSection2)andalsode-biasing\n",
      "straightforward(seeEquation(3)):XkMkkk=?M(H)c(H),(2)H?Hk\n",
      "wherewithaslightabuseofanotation,welet?M(H)forH?Hkbethesum\n",
      "ofalldistinctweightsofwalkswwithH(w)=H,andc(H)isthemultiplicity\n",
      "ofeachdistinctweight.ThisisanalternativetoolforcomputingtheSchatten\n",
      "normwithoutexplicitlycomputingthe?i(M)?s.\n",
      "Givenonlytheaccesstoasubsetofsampledentries,onemightbetempted\n",
      "toapplytheaboveformulatothesampledmatrixwithanappropriatescaling,\n",
      "i.e.k(d2/|?|)P?(M)kkk=P2(d/|?|)H?Hk?P?(M)(H)c(H),to\n",
      "estimatekMkkk.However,thisistlybiased.Toeliminatethebias,we\n",
      "proposerescalingeachtermin(1)bytheinverseoftheprobabilityofsampling\n",
      "thatparticularwalkw(i.e.theprobabilitythatalledgesinwaresampled).\n",
      "Acrucialobservationisthat,foranysamplingmodelthatisinvariantundera\n",
      "relabellingofthenodes,thisprobabilityonlydependsonthepatternH(w).In\n",
      "particular,thisistrueforErd?s-R?nyisampling.Basedonthisobservation,we\n",
      "introduceanovelestimatorthatde-biaseseachgroupseparately:X1bk(P?\n",
      "(M))=??P(M)(H)c(H),(3)p(H)?H?Hk\n",
      "wherep(H)istheprobabilitythepatternHissampled.Itimmediately\n",
      "followsthatthisestimatorisbk(P?(M))]=kMkk,wheretherandomnessis\n",
      "in?.However,computingthisunbiased,i.e.E?[?kestimatecanbechallenging.\n",
      "NaiveenumerationoverallclosedwalksoflengthktakestimescalingasO(d\n",
      "?k?1),where?isthemaximumdegreeofthegraph.Exceptforextremely\n",
      "sparsegraphs,thisisimpractical.Inspiredbytheworkof[2]incountingshort\n",
      "cyclesinagraph,weintroduceanovelandtmethodforcomputingthe\n",
      "proposedestimateforsmallvaluesofk.3\n",
      "Proposition2ForapositivematrixMandanysamplingpattern\n",
      "?,theproposedbk(P?(M))in(3)canbecomputedintimeO(d?)fork?\n",
      "f\n",
      "3,4,5,6,7\n",
      "g\n",
      ",where?<2.373estimate?bk(P?(M))canbecomputedin\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeO(d)istheexponentofmatrixmultiplication.Fork=1or2,?andO(d2\n",
      "),respectively.\n",
      "Thisboundholdsregardlessofthedegree,andthecomplexitycanbeeven\n",
      "smallerforsparsegraphsasmatrixmultiplicationsaremorecient.Wegive\n",
      "aconstructiveproofbyintroducinganovelalgorithmachievingthiscomplexity\n",
      "inSection2.Fork?8,ourapproachcanpotentiallybeextended,butthe\n",
      "complexityoftheproblemfundamentallychangesasitisatleastashardas\n",
      "countingK4inagraph,forwhichthebestknownruntimeisO(d?+1)for\n",
      "generalgraphs[12].Wemakethefollowingcontributionsinthispaper:?We\n",
      "introducein(3)anovelunbiasedestimatoroftheSchattenk-normofapositive\n",
      "matrixM,fromarandomsamplingofitsentries.Ingeneral,the\n",
      "complexityofcomputingtheestimatescalesasO(d?k)where?isthemaximum\n",
      "degree(numberofsampledentriesinacolumn)inthesampledmatrix.We\n",
      "introduceanoveltalgorithmforcomputingtheestimatein(3)exactly\n",
      "forsmallk?7,whichinvolvesonlymatrixoperations.Thisalgorithmis\n",
      "tlymoretandhasrun-timescalingasO(d?)independentof\n",
      "thedegreeandforallk?7(seeProposition2).\n",
      "?UnderthecanonicalErd?s-R?nyisampling,weshowthattheSchatten\n",
      "k-normofanincoherentrank-rmatrixcanbeapproximatedwithinanycon-\n",
      "stantmultiplicativeerror,withnumberofsamplesscalingasO(dr1?2/k)(see\n",
      "Theorem1).Inparticular,thisisstrictlysmallerthanthenumberofsamples\n",
      "necessarytocompletethematrix,whichscalesasO(drlogd).Belowthismatrix\n",
      "completionthreshold,numericalexperimentsthattheproposedestima-\n",
      "tortlyoutperformssimpleheuristicsofusingsingularvaluesofthe\n",
      "sampledmatricesdirectlyorapplyingstate-of-the-artmatrixcompletionmeth-\n",
      "ods(seeFigure4).?GivenestimationofKSchattennorms,itisstraight\n",
      "forwardtoestimatespectralproperties.WeapplyourSchattennormestimates\n",
      "totheapplicationofestimatingthegeneralizedrankstudiedin[20]andesti-\n",
      "matingthespectrumstudiedin[13].Weprovideperformanceguaranteesfor\n",
      "bothapplicationsandprovideexperimentalresultssuggestingweimproveupon\n",
      "othercompetingmethods.Duetospacelimitations,theseresultsareincluded\n",
      "inAppendixB.Intheremainder,weprovideancientimplementationofthe\n",
      "estimator(3)forsmallkinSection2.InSection3,weprovideatheoretical\n",
      "analysisofourestimator.1.3\n",
      "Relatedwork\n",
      "SeveralSchattennormestimationproblemsundertresourcecon-\n",
      "strainedscenarioshavebeenstudied.However,thoseapproachesassumesp\n",
      "noisyobservationswhichallowthemtouse\n",
      "PtherelationEkf(M)gk22=if(?i(M))2whichholdsforastandard\n",
      "i.i.d.Gaussiang?N(0,I)andanypolynomialfunctionf(?).Thismakesthe\n",
      "estimationtlyeasierthanoursetting,andnoneofthosealgorithmscan\n",
      "beappliedunderourrandomsamplingmodel.Inparticular,countingsmall\n",
      "structureforde-biasingisnotrequired.[20,8]and[9]proposemultiplying\n",
      "Gaussianrandomvectorstothedatamatrix,inordertoreducecommunication\n",
      "and/orcomputation.[13]proposesaninterestingestimatorforthespectrumof\n",
      "thecovariancematrixfromsamplesofrandomavector.[15]proposesimilar\n",
      "5\n",
      "\n",
      "estimatorsforSchattennormsfromrandomlinearprojectionsofadatamatrix,\n",
      "and[16]studytheproblemforsparsedatamatricesinastreamingmodel.One\n",
      "ofourcontributionisthatweproposeantalgorithmforcomputingthe\n",
      "weightedcountsofsmallstructuresinSection2,whichcantlyimprove\n",
      "uponlesstcounterpartin,forexample,[13].Underthesetting\n",
      "of[13](andalso[15]),themainideaoftheestimatorPnisthattheweightof\n",
      "eachlength-kcycleintheobservedempiricalcovariancematrix(1/n)i=1Xi\n",
      "XiTprovidesanunbiasedestimatorofkE[XXT]kkk.Onepreferstosumover\n",
      "theweightsofasmanycyclesascomputationallyallowedinordertoreducethe\n",
      "variance.Ascountingallcyclesisingeneralcomputationallyhard,theypropose\n",
      "countingonlyincreasingcycles(whichonlyaccountsforonly1/k!fractionof\n",
      "allthecycles),whichcanbecomputedintimeO(d?).Ifonehasant\n",
      "methodtocountallthe(weighted)cycles,thenthevarianceoftheestimator\n",
      "couldpotentiallydecreasebyanorderofk!.Fork?7,ourproposedalgorithm\n",
      "inSection2providesexactlysuchanestimator.4\n",
      "Wereplace[13,Algorithm1]withours,andrunthesameexperimentto\n",
      "showcasetheimprovementinFigure3,fordimensiond=2048andvarious\n",
      "valuesofnumberofsamplesncomparingthemultiplicativeerrorinestimating\n",
      "kE[XXT]kkk,fork=7.Withthesamerun-time,tgainisachieved\n",
      "bysimplysubstitutingourproposedalgorithmforcountingsmallstructures,\n",
      "inthesub-routine.Ingeneral,theientalgorithmweproposemightbeof\n",
      "independentinteresttovariousapplications,andcandirectlysubstitute(and\n",
      "tlyimproveupon)otherpopularbutlesstcounterparts.100\n",
      "increasingsimplecyclesallsimplecycles\n",
      "10\n",
      "T]kk?kE[XXT]kk||kE[XXkkkE[XXT]kkk\n",
      "1\n",
      "0.1\n",
      "0.01256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "numberofsamples,n\n",
      "Figure3:Byreplacing[13,Algorithm1]thatonlycountsincreasingcycles\n",
      "withourproposedalgorithmthatcountsallcycles,cantgainisacheived\n",
      "inestimatingkE[XXT]kkk,fork=7.Themainchallengeunderoursampling\n",
      "scenarioisthatexistingcountingmethodslikethatof[13]cannotbeapplied,\n",
      "regardlessofhowmuchcomputationalpowerwehave.Underthematrixcom-\n",
      "pletionscenario,weneedto(a)sumoverallsmallstructuresH?Hkandnotjust\n",
      "Ckasin[13];and(b)foreachstructureweneedtosumoverallsubgraphswith\n",
      "thesamestructureandnotjustthosewalkswhoselabelsformamonotonically\n",
      "increasingsequenceasin[13].\n",
      "2\n",
      "tAlgorithm\n",
      "InthissectionwegiveaconstructiveproofofProposition2.Incomputing\n",
      "theestimatein(3),c(H)canbecomputedintimeO(k!)andsupposep(H)has\n",
      "6\n",
      "\n",
      "beencomputed(wewillexplainhowtocomputep(H)forEr?s-R?nyisampling\n",
      "inSection3).Thebottlenecktheniscomputingtheweights?P?(M)(H)for\n",
      "eachH?Hk.Let?M(H)??M(H)c(H).Wegivematrixmultiplicationbased\n",
      "equationstocompute?M(H)foreveryH?Hkfork?\n",
      "f\n",
      "3,4,5,6,7\n",
      "g\n",
      ".This\n",
      "establishesthat?M(H),andhence?M(H),canbecomputedintimeO(d?),\n",
      "provingProposition2.ForanymatrixA?Rd?d,letdiag(A)tobeadiagonal\n",
      "matrixsuchthat(diag(A))ii=Aii,foralli?[d]and(diag(A))i,j=0,forall\n",
      "i6=j?[d].ForagivenmatrixM?Rd?d,thefollowing:OMtobe\n",
      "matrixofentriesofMthatisPOM?M?diag(M)andweletDM\n",
      "?diag(M).Lettr(A)denotetraceofA,thatistr(A)=i?[d]Aii,andletA?B\n",
      "denotethestandardmatrixmultiplicationoftwomatricesAandBtomakeit\n",
      "moreexplicit.Considercomputing?M(H)forH?H3aslabeledinFigure2:\n",
      "?M(A1)=tr(DM?DM?DM)?M(A2)=3tr(DM?OM?OM)?M(A3)=\n",
      "tr(OM?OM?OM)\n",
      "(4)(5)(6)\n",
      "Theweightedsum?M(A1)issumofPallweightsofwalksoflength\n",
      "3thatconsistsofthreeself-loops.Onecanshowthat?M(A1)=i?[d]Mii3,\n",
      "whichinourmatrixoperationnotationsis(4).Similarly,?M(A3)isthesumof\n",
      "weightsoflength3walkswithnoself-loop,whichleadsto(6).?M(A2)isthe\n",
      "sumofweightsoflength3walkswithasingleself-loop,whichleadsto(5).The\n",
      "factor3accountsforthefactthattheselfloopcouldhavebeenplacedatvarious\n",
      "positions.Similarly,foreachk-cyclicpseudographsinHkfork?7,computing\n",
      "?M(H)involvesafewmatrixoperationswithrun-timeO(d?).Weprovidethe\n",
      "completesetofexplicitexpressionsinAppendixF.AMATLABimplementation\n",
      "oftheestimator(3),thatincludesasitssub-routinesthecomputationofthe\n",
      "weightsofallk-cyclicpseudographs,isavailablefordownloadat5\n",
      "https://github.com/khetan2/Schatten\n",
      "norm\n",
      "estimation.Theexplicitfor-\n",
      "mulaeinAppendixFtogetherwiththeimplementationintheaboveurlmight\n",
      "beofinteresttootherproblemsinvolvingcountingsmallstructuresingraphs.\n",
      "bk(P?(M))=(1/p)PP?(M)ii,whichcanbecomputedFork=1,the\n",
      "estimatorto?ibk(P?(M))=(1/p)PP?(M)2,whichintime\n",
      "O(d).Fork=2,theestimatorto?iji,jcanbecomputedintime\n",
      "O(|?|).However,fork?8,thereexistswalksoverK4,acliqueover4\n",
      "nodes,thatcannotbedecomposedintosimplecomputationsinvolvingmatrix\n",
      "operations.ThebestknownalgorithmforasimplertaskofcountingK4has\n",
      "run-timescalingasO(d?+1),whichisfundamentallyderent.Algorithm1\n",
      "Schattenk-normestimatorRequire:P?(M),k,Hk,p(H)forallH?Hkbk\n",
      "(P?(M))Ensure:?1:ifk?7then2:ForeachH?Hk,compute?P?(M)\n",
      "(H)usingtheformulafromEq.(4)?(6)fork=3andEq.(43)?(186)fork?\n",
      "f\n",
      "4,5,6,7\n",
      "g\n",
      "1bk(P?(M))?P3:?H?Hkp(H)?P?(M)(H)4:elsebk(P?\n",
      "(M))?Algorithm2[P?(M),k,Hk,p(H)forallH?Hk]5:?[AppendixA]\n",
      "6:endif\n",
      "3\n",
      "Performanceguarantees\n",
      "UnderthestylizedbutcanonicalErd?s-R?nyisampling,noticethattheprob-\n",
      "abilityp(H)thatweobservealledgesinawalkwithpatternHisp(H)=pm(H)\n",
      "7\n",
      "\n",
      ",\n",
      "(7)\n",
      "wherepistheprobabilityanedgeissampledandm(H)isthenumberof\n",
      "distinctedgesinak-cyclicpseudographH.Plugginginthisvalueofp(H),which\n",
      "canbecomputedintimelinearink,intotheestimator(3),wegetanestimate\n",
      "customizedforErd?s-R?nyisampling.Givenarank-rmatrixM,theyof\n",
      "estimatingpropertiesofMfromsampledentriesiscapturedbytheincoherence\n",
      "oftheoriginalmatrixM,whichwedenoteby?(M)?R[3].Formally,letM?\n",
      "U?U>bethesingularvaluedecompositionofapositivematrixwhere\n",
      "Uisad?rorthonormalmatrixand??diag(?1,???,?r)withsingular\n",
      "values?1??2??????r>0.LetUi,rdenotethei-throwandj-thcolumn\n",
      "entryofmatrixU.Theincoherence?(M)isasthesmallestpositive\n",
      "value?suchthatthefollowingholds:Pr2A1.Foralli?[d],wehavea=1Uia\n",
      "(?a/?1)??r/d.Pr?A2.Foralli6=j?[d],wehave|a=1UiaUja(?a/?1\n",
      ")|??r/d.Theincoherencemeasureshowwellspreadoutthematrixisand\n",
      "isacommonmeasureofyincompletingamatrixfromrandomsamples\n",
      "[3,11].3.1\n",
      "Performanceguarantee\n",
      "Foranyd?dpositivematrixMofrankrwithincoherence?(M\n",
      ")=?andtheeconditionnumber?=?max(M)/?min(M),we\n",
      "()(dp)k?1rkpk?122k??(??)g(k)max1,,k?1,(8)ddb?(M))/kM\n",
      "kk)??2(r1?2/k/dp)ksuchthatthevarianceofourestimatorisboundedby\n",
      "Var(?(PkasweshowintheproofofTheorem1inSectionD.1.Here,g(k)=\n",
      "O(k!).6\n",
      "Theorem1(UpperboundundertheErd?s-R?nyisampling)Foranyinteger\n",
      "k?[3,?),any?>0,anyrank-rpositivematrixM?Rd?d,and\n",
      "giveni.i.d.samplesoftheentriesofMwithprobabilityp,theproposedestimate\n",
      "of(3)achievesnormalizederror?withprobabilityboundedby!\n",
      "bk(P?(M))?kMkk??2r1?2/kkkP.(9)???2k?dpkMkk\n",
      "Consideratypicalscenariowhere?,?,andkarewithrespecttodandr.\n",
      "ThentheChebyshev?sboundin(9)impliesthatthesampled2p=O(dr1?2/k\n",
      ")isttorecoverkMkkkuptoarbitrarilysmallmultiplicativeerrorand\n",
      "arbitrarilysmall(butstrictlypositive)errorprobability.Thisisstrictlyless\n",
      "thantheknownminimaxsamplecomplexityforrecoveringtheentirelow-rank\n",
      "matrix,whichscalesis?(rdlogd).Asweseektoestimateonlyapropertyof\n",
      "thematrix(i.e.theSchattenk-norm)andnotthewholematrixitself,wecan\n",
      "bemoretonthesamplecomplexitybyafactorofr2/kinrankanda\n",
      "factoroflogdinthedimension.Weemphasizeherethatsuchagaincanonlybe\n",
      "establishedusingtheproposedestimatorbasedonthestructureofthek-cyclic\n",
      "pseudographs.Wewillshowempiricallythatthestandardmatrixcompletion\n",
      "approachesfailinthecriticalregimeofsamplesbelowtherecoverythresholdof\n",
      "O(rdlogd).\n",
      "d=500,r=1001\n",
      "proposedestimatorscaledsampledmatrixmatrixcompletion\n",
      "proposedestimatorscaledsampledmatrixmatrixcompletion\n",
      "0.8\n",
      "8\n",
      "\n",
      "relativeerror\n",
      "0.8\n",
      "relativeerror\n",
      "d=500,r=5001\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "00.010.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "samplingprobability,p\n",
      "0.8\n",
      "0.9\n",
      "00.010.1\n",
      "1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "samplingprobability,p\n",
      "0.8\n",
      "0.9\n",
      "1\n",
      "Figure4:Theproposedestimatoroutperformsbothbaselineapproaches\n",
      "belowthematrixcompletionthreshold.Fork=5,comparisonoftheabsolute\n",
      "relativeerrorinestimatedSchattennormthatis\n",
      "bk(P?(M)),kMkk?kMkk=?kk/kMkkforthethreealgorithms:(1)\n",
      "theproposedestimator,kMk\n",
      "k\n",
      "k\n",
      "k\n",
      "(2)Schattennormofthescaledsampledmatrix,kMkkk=k(1/p)Pr(P?\n",
      "(M))kkk,(3)Schattennorm\n",
      "f=AltMin(P?(M))from[10],kMfkk,wherePr(?)istheofthecompleted\n",
      "matrix,Mkkk=kMkstandardbestrank-rprojectionofamatrix.?is\n",
      "generatedbyErd?s-R?nyisamplingofmatrixMwithprobabilityp.\n",
      "9\n",
      "\n",
      "Figure4isascatterplotoftheabsoluterelativeerrorinestimatedSchatten\n",
      "k-norm,kMkkk?\n",
      "kMkkk/kMkkk,fork=5,forthreeapproaches:theproposedestima-\n",
      "tor,Schattennormofthescaledsampledmatrix(afterrank-rprojection),and\n",
      "Schattennormofthecompletedmatrix,usingstate-of-the-artalternatingmin-\n",
      "imizationalgorithm[10].Allthethreeestimatorsareevaluated20timesfor\n",
      "eachvalueofp.Misasymmetricpositivematrixofsized=500,\n",
      "andrankr=100(leftpanel)andr=500(rightpanel).SingularvectorsUof\n",
      "M=U?U>,aregeneratedbyQRdecompositionofN(0,Id?d)and?i,iis\n",
      "uniformlydistributedover[1,2].Foralowrankmatrixontheleft,thereisa\n",
      "clearcriticalvalueofp'0.45,abovewhichmatrixcompletionisexactwithhigh\n",
      "probability.However,thisalgorithmknowstheunderlyingrankandcrucially\n",
      "exploitsthefactthattheunderlyingmatrixisexactlylow-rank.Incomparison,\n",
      "ourapproachisagnostictothelow-rankassumptionbuttheaccuratees-\n",
      "timatethatisadaptivetotheactualrankinadata-drivenmanner.Usingthe\n",
      "rsingularvaluesofthe(rescaled)sampledmatrixfailsmiserablyforall\n",
      "regimes(wetruncatetheerroratoneforillustrationpurposes).Inthispaper,\n",
      "weareinterestedinthe7\n",
      "regimewhereexactmatrixcompletionisimpossibleaswedonothaveenough\n",
      "samplestoexactlyrecovertheunderlyingmatrix:p?0.45intheleftpaneland\n",
      "allregimesintherightpanel.\n",
      "Thetconditionofd2p=O(dr1?2/k)inTheorem1holdsforabroad\n",
      "rangeofparameterswheretherankistlysmallr=O(dk/((k?1)(k?2))\n",
      ")(toensurethatthetermin?2dominates).However,thefollowingresults\n",
      "inFigure5onnumericalexperimentssuggestthatouranalysisholdsmore\n",
      "generallyforallregimesoftherankr,eventhoseclosetod.Misgenerated\n",
      "usingsettingssimilartothatofFigure4.Empiricalprobabilitiesarecomputed\n",
      "byaveragingover100instances.\n",
      "OnemighthopetotightentheChebyshevboundbyexploitingthefactthat\n",
      "thecorrelationamongthesummandsinourestimator(3)isweak.Thiscanbe\n",
      "madepreciseusingrecentresultfrom[18],whereaBernstein-typeboundwas\n",
      "provedforsumofpolynomialsofindependentrandomvariablesthatareweakly\n",
      "correlated.Theterminthebound(10)isthenaturalBernstein-typebound\n",
      "correspondingtotheChebyshev?sboundin(9).However,undertheregime\n",
      "wherekislargeorpislarge,thecorrelationamongthesummandsbecome\n",
      "stronger,andthesecondandthirdterminthebound(10)startstodominate.\n",
      "Inthetypicalregimeofinterestwhere?,?,kared2p=O(dr1?2/k\n",
      "),andtlysmallrankr=O(dk/((k?1)(k?2))),theerrorprobabilityis\n",
      "dominatedbythersttermintheright-handsideof(10).Neitheroneofthe\n",
      "twoboundsin(9)and(10)dominatestheother,anddependingonthevalues\n",
      "oftheproblemparameters,wemightwanttoapplytheonethatistighter.We\n",
      "provideaproofinSectionD.2.Theorem2UnderthehypothesesofTheorem\n",
      "1,theerrorprobabilityisupperboundedby!\n",
      "bk(P?(M))?kMkk?k???PkMkkk\n",
      "1/k\n",
      "k()2\n",
      "10\n",
      "\n",
      "samplingprobability,p\n",
      "e2maxe\n",
      "???2\n",
      "dp\n",
      "r1?2/k\n",
      "k=2\n",
      "k=3\n",
      "k=4\n",
      "k=5\n",
      "k=6\n",
      "k=7\n",
      "0.2\n",
      "?(dp)\n",
      ",e\n",
      "1\n",
      "?d?rk?1\n",
      "?(dp)\n",
      ",e\n",
      "?d?rk?1\n",
      ",e?\n",
      "?dp?\n",
      "k=2\n",
      "k=3\n",
      "k=4\n",
      "k=5\n",
      "k=6\n",
      "k=7\n",
      "0.2\n",
      "(10)\n",
      ".\n",
      "1\n",
      "0.80.6\n",
      "0.80.6\n",
      "0.02\n",
      "0.020.4\n",
      "0.4\n",
      "0.20.002\n",
      "05\n",
      "50\n",
      "0.20.002\n",
      "500\n",
      "05\n",
      "50\n",
      "500\n",
      "rank,r\n",
      "11\n",
      "\n",
      "Figure5:Eachcolormapineachblockfork?\n",
      "f\n",
      "2,3,4,5,6,7\n",
      "g\n",
      "show\n",
      "empiricalprobabilityofthe\n",
      "bk(P?(M))/kMkk??,for?=0.5(leftpanel)and?=0.2(rightpanel).\n",
      "?iseventkMkkk??kgeneratedbyErd?s-R?nyisamplingofmatrixMwith\n",
      "probabilityp(verticalaxis).Misasymmetricpositivesemi-deitematrix\n",
      "ofsized=1000.Thesolidlinescorrespondtoourtheoreticalpredictionp=\n",
      "(1/d)r1?2/k.Thesetworesultsshowthatthesamplesizeofd2p=O(dr1?2/k\n",
      ")isttoestimateaSchattenk-normaccurately.Ingeneral,wedonot\n",
      "expecttogetauniversalupperboundthatistlytighterforallr,\n",
      "becauseforaspecialcaseofr=d,thefollowingcorollaryof[15,Theorem3.2]\n",
      "providesalowerbound;itisnecessarytohavesamplesized2p=?(d2?4/k)\n",
      "whenr=d.Hence,thegapisatmostafactorofr2/kinthesamplecomplexity.\n",
      "Corollary1ConsideranylinearobservationX?RnofamatrixM?Rd?dand\n",
      "anyestimate?(X)satisfying(1??k)kMkkk??(X)?(1+?k)kMkkkforany\n",
      "Mwithprobabilityatleast3/4,where?k=(1.2k?1)/(1.2k+1).Then,n=\n",
      "?(d2?4/k).8\n",
      "Fork?\n",
      "f\n",
      "1,2\n",
      "g\n",
      ",preciseboundscanbeobtainedwithsimpleranalyses.In\n",
      "particular,wehavethefollowingremarks,whoseprooffollowsimmediately\n",
      "byapplyingChebyshev?sinequalityandBernstien?sinequalityalongwiththe\n",
      "incoherenceassumptions.Remark3Fork=1,theprobabilityoferrorin(9)is\n",
      "upperboundedbymin\n",
      "f\n",
      "?1,?2\n",
      "g\n",
      ",where??2(??)21(??)2(??)?1?1?2.,\n",
      "and?2?2exp+??dp2dp3dp\n",
      "Remark4Fork=2,theprobabilityoferrorin(9)isupperboundedby\n",
      "min\n",
      "f\n",
      "?1,?2\n",
      "g\n",
      ",where?2(??)41(??)4r2r2(??)2r?1?1?22.2+,and?2?\n",
      "2exp?2++??dpd2d2pd3d2p\n",
      "?Whenk=2,forranksmallr?Cd,weonlyneedd2p=?(1)samplesfor\n",
      "recoveryuptoanyarbitrarysmallmultiplicativeerror.Whenrankrislarge,\n",
      "ourestimatorrequiresd2p=?(d)forbothk?\n",
      "f\n",
      "1,2\n",
      "g\n",
      ".Acknowledgments\n",
      "ThisworkwaspartiallysupportedbyNSFgrantsCNS-1527754,CCF-1553452,\n",
      "CCF-1705007andGOOGLEFacultyResearchAward.\n",
      "2References\n",
      "[1]DimitrisAchlioptasandFrankMcSherry.Fastcomputationoflowrank\n",
      "matrixapproximations.InProceedingsofthethirty-thirdannualACMsym-\n",
      "posiumonTheoryofcomputing,pages611?618.ACM,2001.[2]N.Alon,\n",
      "R.Yuster,andU.Zwick.Findingandcountinggivenlengthcycles.Algo-\n",
      "rithmica,17(3):209?223,1997.[3]E.J.Cand?sandB.Recht.Exactmatrix\n",
      "completionviaconvexoptimization.FoundationsofComputationalMathemat-\n",
      "ics,9(6):717?772,2009.[4]E.DiNapoli,E.Polizzi,andY.Saad.t\n",
      "estimationofeigenvaluecountsinaninterval.NumericalLinearAlgebrawith\n",
      "Applications,2016.[5]KhaledMElbassioni.Apolynomialdelayalgorithmfor\n",
      "generatingconnectedinducedsubgraphsofagivencardinality.J.GraphAlgo-\n",
      "rithmsAppl.,19(1):273?280,2015.[6]U.FeigeandE.Ofek.Spectraltechniques\n",
      "appliedtosparserandomgraphs.RandomStruct.Algorithms,27(2):251?275,\n",
      "12\n",
      "\n",
      "2005.[7]J.Friedman,J.Kahn,andE.Szemer?di.Onthesecondeigenvaluein\n",
      "randomregulargraphs.InProceedingsoftheTwenty-FirstAnnualACMSym-\n",
      "posiumonTheoryofComputing,pages587?598,Seattle,Washington,USA,\n",
      "may1989.ACM.[8]I.Han,D.Malioutov,H.Avron,andJ.Shin.Approx-\n",
      "imatingthespectralsumsoflarge-scalematricesusingchebyshevapproxima-\n",
      "tions.arXivpreprintarXiv:1606.00942,2016.[9]I.Han,D.Malioutov,andJ.\n",
      "Shin.Large-scalelog-determinantcomputationthroughstochasticchebyshev\n",
      "expansions.InICML,pages908?917,2015.[10]P.Jain,P.Netrapalli,and\n",
      "S.Sanghavi.Low-rankmatrixcompletionusingalternatingminimization.In\n",
      "STOC,pages665?674,2013.[11]R.H.Keshavan,A.Montanari,andS.Oh.\n",
      "Matrixcompletionfromafewentries.InformationTheory,IEEETransactions\n",
      "on,56(6):2980?2998,2010.[12]T.Kloks,D.Kratsch,andH.M?ller.Find-\n",
      "ingandcountingsmallinducedsubgraphstly.InformationProcessing\n",
      "Letters,74(3):115?121,2000.9\n",
      "[13]W.KongandG.Valiant.Spectrumestimationfromsamples.arXiv\n",
      "preprintarXiv:1602.00061,2016.[14]C.M.Le,E.Levina,andR.Vershynin.\n",
      "Sparserandomgraphs:regularizationandconcentrationofthelaplacian.arXiv\n",
      "preprintarXiv:1502.03049,2015.[15]Y.Li,H.L.Nguy?n,andD.P.Woo\n",
      "Onsketchingmatrixnormsandthetopsingularvector.InProceedingsofthe\n",
      "Twenty-FifthAnnualACM-SIAMSymposiumonDiscreteAlgorithms,pages\n",
      "1562?1581.SocietyforIndustrialandAppliedMathematics,2014.[16]Y.Li\n",
      "andD.P.WooOnapproximatingfunctionsofthesingularvaluesin\n",
      "astream.arXivpreprintarXiv:1604.08679,2016.[17]J.C.MasonandD.\n",
      "C.Handscomb.Chebyshevpolynomials.CRCPress,2002.[18]W.Schudy\n",
      "andM.Sviridenko.Bernstein-likeconcentrationandmomentinequalitiesfor\n",
      "polynomialsofindependentrandomvariables:multilinearcase.arXivpreprint\n",
      "arXiv:1109.5193,2011.[19]RyuheiUeharaetal.Thenumberofconnected\n",
      "componentsingraphsanditsapplications.Manuscript.URL:http://citeseerx.\n",
      "ist.psu.edu/viewdoc/summary,1999.[20]Y.Zhang,M.J.Wainwright,\n",
      "andM.I.Jordan.Distributedestimationofgeneralizedmatrixrank:t\n",
      "algorithmsandlowerbounds.arXivpreprintarXiv:1502.01403,2015.\n",
      "10\n",
      "13\n",
      "\n",
      "PP3872.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP3872.pdf 11\n",
      "3DObjectRecognitionwithDeepBeliefNets\n",
      "Authoredby:\n",
      "E.Hinton\n",
      "VinodNair\n",
      "Abstract\n",
      "WeintroduceanewtypeofDeepBeliefNetandevaluateitona3D\n",
      "objectrecognitiontask.Thetop-levelmodelisathird-orderBoltzmann\n",
      "machine,trainedusingahybridalgorithmthatcombinesbothgenerative\n",
      "anddiscriminativegradients.PerformanceisevaluatedontheNORB\n",
      "database(normalized-uniformversion),whichcontainsstereo-pairimages\n",
      "ofobjectsundertlightingconditionsandviewpoints.Ourmodel\n",
      "achieves6.5%erroronthetestset,whichisclosetothebestpublished\n",
      "resultforNORB(5.9%)usingaconvolutionalneuralnetthathasbuilt-in\n",
      "knowledgeoftranslationinvariance.Itsubstantiallyoutperformsshal-\n",
      "lowmodelssuchasSVMs(11.6%).DBNsareespeciallysuitedforsemi-\n",
      "supervisedlearning,andtodemonstratethisweconsideramover-\n",
      "sionoftheNORBrecognitiontaskinwhichadditionalunlabeledimages\n",
      "arecreatedbyapplyingsmalltranslationstotheimagesinthedatabase.\n",
      "Withtheextraunlabeleddata(andthesameamountoflabeleddataas\n",
      "before),ourmodelachieves5.2%error,makingitthecurrentbestresult\n",
      "forNORB.\n",
      "1PaperBody\n",
      "Recentworkondeepbeliefnets(DBNs)[10],[13]hasshownthatitispossibleto\n",
      "learnmultiplelayersofnon-linearfeaturesthatareusefulforobject\n",
      "withoutrequiringlabeleddata.Thefeaturesaretrainedonelayeratatimeas\n",
      "arestrictedBoltzmannmachine(RBM)usingcontrastivedivergence(CD)[4],\n",
      "orassomeformofautoencoder[20],[16],andthefeatureactivationslearnedby\n",
      "onemodulebecomethedatafortrainingthenextmodule.Afterapre-training\n",
      "phasethatlearnslayersoffeatureswhicharegoodatmodelingthestatistical\n",
      "structureinasetofunlabeledimages,supervisedbackpropagationcanbeused\n",
      "tothefeaturesfor[7].Alternatively,can\n",
      "beperformedbylearningatoplayeroffeaturesthatmodelsthejointdensity\n",
      "oftheclasslabelsandthehighestlayerofunsupervisedfeatures[6].These\n",
      "unsupervisedfeatures(plustheclasslabels)thenbecomethepenultimatelayer\n",
      "ofthedeepbeliefnet[6].Earlyworkondeepbeliefnetswasevaluatedusing\n",
      "theMNISTdatasetofhandwrittendigits[6]whichhastheadvantagethat\n",
      "1\n",
      "\n",
      "afewmillionparametersareadequateformodelingmostofthestructurein\n",
      "thedomain.For3Dobjecthowever,manymoreparametersare\n",
      "probablyrequiredtoallowadeepbeliefnetwithnopriorknowledgeofspatial\n",
      "structuretocaptureallofthevariationscausedbylightingandviewpoint.Itis\n",
      "notyetclearhowwelldeepbeliefnetsperformat3Dobjectclaswhen\n",
      "comparedwithshallowtechniquessuchasSVM?s[19],[3]ordeepdiscriminative\n",
      "techniqueslikeconvolutionalneuralnetworks[11].Inthispaper,wedescribe\n",
      "abettertypeoftop-levelmodelfordeepbeliefnetsthatistrainedusinga\n",
      "combinationofgenerativeanddiscriminativegradients[5],[8],[9].Weevaluate\n",
      "themodelonNORB[12],whichisacarefullydesignedobjectrecognitiontask\n",
      "thatrequires1\n",
      "hj\n",
      "hj\n",
      "lk\n",
      "lkvi\n",
      "vi\n",
      "(a)\n",
      "h1\n",
      "(b)\n",
      "h2\n",
      "l1\n",
      "h1\n",
      "h2W112\n",
      "l1l2\n",
      "l2v1(c)\n",
      "ddNhhhiddenunits\n",
      "v1v2\n",
      "v2(d)\n",
      "W212\n",
      "W111W122W211W222W121\n",
      "W221\n",
      "Nvvisibleunits\n",
      "(e)\n",
      "Figure1:TheThird-OrderRestrictedBoltzmannMachine.(a)Everyclique\n",
      "inthemodelcontainsavisibleunit,hiddenunit,andlabelunit.(b)Our\n",
      "shorthandnotationforrepresentingthecliquein(a).(c)Amodelwithtwoof\n",
      "eachunittype.Thereisonecliqueforeverypossibletripletofunitscreatedby\n",
      "selectingoneofeachtype.The?restricted?architectureprecludescliqueswith\n",
      "multipleunitsofthesametype.(d)Ourshorthandnotationforrepresenting\n",
      "themodelin(c).(e)The3Dtensorofparametersforthemodelin(c).The\n",
      "architectureisthesameasthatofanimplicitmixtureofRBMs[14],butthe\n",
      "inferenceandlearningalgorithmshavechanged.\n",
      "generalizationtonovelobjectinstancesundervaryinglightingconditions\n",
      "andviewpoints.OurmodeltlyoutperformsSVM?s,anditalsoout-\n",
      "performsconvolutionalneuralnetswhengivenadditionalunlabeleddatapro-\n",
      "ducedbysmalltranslationsofthetrainingimages.WeuserestrictedBoltzmann\n",
      "2\n",
      "\n",
      "machinestrainedwithone-stepcontrastivedivergenceasourbasicmodulefor\n",
      "learninglayersoffeatures.Thesearefullydescribedelsewhere[6],[1]andthe\n",
      "readerisreferredtothosesourcesfordetails.\n",
      "2\n",
      "AThird-OrderRBMastheTop-LevelModel\n",
      "Untilnow,theonlytop-levelmodelthathasbeenconsideredforaDBNis\n",
      "anRBMwithtwotypesofobservedunits(oneforthelabel,anotherforthe\n",
      "penultimatefeaturevector).Wenowconsideranalternativemodelforthetop-\n",
      "leveljointdistributioninwhichtheclasslabelmultiplicativelyinteractswith\n",
      "boththepenultimatelayerunitsandthehiddenunitstodeterminetheenergy\n",
      "ofafullguration.ItisaBoltzmannmachinewiththree-waycliques[17],\n",
      "eachcontainingapenultimatelayerunitvi,ahiddenunithj,andalabelunit\n",
      "lk.See1forasummaryofthearchitecture.Notethattheparameters\n",
      "nowforma3Dtensor,insteadofamatrixasintheearlier,bipartitemodel.\n",
      "Considerthecasewherethecomponentsofvandharestochasticbinaryunits,\n",
      "andlisadiscretevariablewithKstatesrepresentedby1-of-Kencoding.The\n",
      "modelcanbeintermsofitsenergyfunctionXE(v,h,l)=?Wijkvi\n",
      "hjlk,(1)i,j,k\n",
      "whereWijkisalearnablescalarparameter.(Weomitbiastermsfromall\n",
      "expressionsforclarity.)Theprobabilityofafull\n",
      "f\n",
      "v,h,l\n",
      "g\n",
      "isthen\n",
      "exp(?E(v,h,l)),(2)ZPwhereZ=v?,h?,l?exp(?E(v?,h?,l?))is\n",
      "thepartitionfunction.Marginalizingoverhgivesthedistributionovervandl\n",
      "alone.P(v,h,l)=\n",
      "2\n",
      "Themainbetweenthenewtop-levelmodelandtheearlieroneis\n",
      "thatnowtheclasslabelmultiplicativelymodulateshowthevisibleandhidden\n",
      "unitscontributetotheenergyofafullIfthelabel?skthunitis\n",
      "1(andtherestare0),thenthekthsliceofthetensordeterminestheenergy\n",
      "function.Inthecaseofsoftactivations(i.e.morethanonelabelhasnon-zero\n",
      "probability),aweightedblendofthetensor?sslicessptheenergyfunction.\n",
      "Theearliertop-level(RBM)modellimitsthelabel?stochangingthebiases\n",
      "intothehiddenunits,whichmoonlyhowthehiddenunitscontributeto\n",
      "theenergyofafull.Thereisnodirectinteractionbetweenthe\n",
      "labelandthevisibleunits.Introducingdirectinteractionsamongallthreesets\n",
      "ofvariablesallowsthemodeltolearnfeaturesthatarededicatedtoeachclass.\n",
      "Thisisausefulpropertywhentheobjectclasseshavesubstantiallyt\n",
      "appearancesthatrequireverytfeaturestodescribe.UnlikeanRBM,\n",
      "themodelstructureisnotbipartite,butitisstill?restricted?inthesensethat\n",
      "therearenodirectconnectionsbetweentwounitsofthesametype.2.1\n",
      "Inference\n",
      "ThedistributionsthatwewouldliketobeabletoinferareP(l|v)(to\n",
      "classifyaninput),andP(v,l|h)andP(h|v,l)(forCDlearning).Fortunately,\n",
      "allthreedistributionsaretractabletosamplefromexactly.Thesimplestcaseis\n",
      "P(h|v,l).Oncelisobserved,themodelreducestoanRBMwhoseparameters\n",
      "arethekthsliceofthe3Dparametertensor.AsaresultP(h|v,l)isa\n",
      "factorizeddistributionthatcanbesampledexactly.Forarestrictedthird-order\n",
      "3\n",
      "\n",
      "modelwithNvvisibleunits,NhhiddenunitsandNlclasslabels,thedistribution\n",
      "P(l|v)canbeexactlycomputedinO(NvNhNl)time.Thisresultfollows\n",
      "fromtwoobservations:1)settinglk=1reducesthemodeltoanRBMdened\n",
      "bythekthsliceofthetensor,and2)thenegativelogprobabilityofv,upto\n",
      "anadditiveconstant,underthisRBMisthefreeenergy:Fk(v)=?\n",
      "NhX\n",
      "NvXWijkvi)).log(1+exp(\n",
      "(3)\n",
      "i=1\n",
      "j=1\n",
      "TheideaistocomputeFk(v)foreachsettingofthelabel,andthen\n",
      "convertthemtoadiscretedistributionbytakingthesoftmaxofthenegative\n",
      "freeenergies:exp(?Fk(v))P(lk=1|v)=PNl.k=1exp(?Fk(v))\n",
      "(4)\n",
      "Equation3requiresO(NvNh)computation,whichisrepeatedNltimesfor\n",
      "atotalofO(NvNhNl)computation.Wecanusethesamemethodtocompute\n",
      "P(l|h).Simplyswitchtheroleofvandhinequation3tocomputethefree\n",
      "energyofhunderthekthRBM.(Thisispossiblesincethemodelissymmetric\n",
      "withrespecttovandh.)ThenconverttheresultingNlfreeenergiestothe\n",
      "probabilitiesP(lk=1|h)withthesoftmaxfunction.Nowitbecomespossible\n",
      "toexactlysampleP(v,l|h)bysampling?l?P(l|h).Suppose??P\n",
      "(v|h,l?k=1)canbel?k=1.Thenthemodelreducestoitskth-sliceRBM\n",
      "fromwhichv?easilysampled.Theresult\n",
      "f\n",
      "?v,l\n",
      "g\n",
      "isanunbiasedsample\n",
      "fromP(v,l|h).2.2\n",
      "Learning\n",
      "GivenasetofNlabeledtrainingcases\n",
      "f\n",
      "(v1,l1),(v2,l2),...,(vN,lN\n",
      ")\n",
      "g\n",
      ",wewanttolearnthe3DparametertensorWfortherestrictedthird-order\n",
      "model.Whentrainedasthetop-levelmodelofaDBN,thevisiblevectorvis\n",
      "apenultimatelayerfeaturevector.Wecanalsotrainthemodeldirectlyon\n",
      "imagesasashallowmodel,inwhichcasevisanimage(inrowvectorform).\n",
      "InbothcasesthelabellrepresentstheNlobjectcategoriesusing1-of-Nlen-\n",
      "coding.ForthesamereasonsasinthecaseofanRBM,maximumlikelihood\n",
      "learningisintractablehereaswell,sowerelyonContrastiveDivergencelearn-\n",
      "inginstead.CDwasoriginallyformulatedinthecontextoftheRBMandits\n",
      "bipartitearchitecture,buthereweextendittothenon-bipartitearchitecture\n",
      "ofthethird-ordermodel.3\n",
      "Anunbiasedestimateofthemaximumlikelihoodgradientcanbecomputed\n",
      "byrunningaMarkovchainthatalternativelysamplesP(h|v,l)andP(v,\n",
      "l|h)untilitreachesequilibrium.Contrastivedivergenceusestheparameter\n",
      "updatesgivenbythreehalf-stepsofthischain,withthechaininitializedfrom\n",
      "atrainingcase(ratherthanarandomstate).Asexplainedinsection2.1,both\n",
      "ofthesedistributionsareeasytosamplefrom.ThestepsforcomputingtheCD\n",
      "parameterupdatesaresummarizedbelow:ContrastivedivergencelearningofP\n",
      "(v,l):1.Givenalabeledtrainingpair\n",
      "f\n",
      "v+,lk+=1\n",
      "g\n",
      ",sampleh+?P(h|v+\n",
      ",lk+=1).2.3.4.5.\n",
      "4\n",
      "\n",
      "ComputetheouterproductDk+=v+h+T.Sample\n",
      "f\n",
      "v?,l?\n",
      "g\n",
      "?P(v,\n",
      "l|h+).Letmbetheindexofthecomponentofl?setto1.?=1).Sample\n",
      "h??P(h|v?,lm?=v?h?T.ComputetheouterproductDm\n",
      "LetW?,?,kdenotetheNh?Nvmatrixofparameterscorrespondingtothe\n",
      "kthslicealongthelabeldimensionofthe3Dtensor.ThentheCDupdatefor\n",
      "W?,?,kis:?W?,?,k=Dk+?Dk?,\n",
      "(5)\n",
      "W?,?,k?W?,?,k+??W?,?,k,(6)where?isalearningrateparameter.\n",
      "Typically,theupdatescomputedfroma?mini-batch?oftrainingcases(asmall\n",
      "subsetoftheentiretrainingset)areaveragedtogetherintooneupdateandthen\n",
      "appliedtotheparameters.\n",
      "3\n",
      "CombiningGradientsforGenerativeandDiscriminativeModels\n",
      "InpracticetheMarkovchainusedinthelearningofP(v,l)canfrom\n",
      "slowmixing.Inparticular,thelabell?generatedinstep3aboveisunlikelytobe\n",
      "tfromthetruelabell+ofthetrainingcaseusedinstep1.Empirically,\n",
      "thechainhasatendencytostay?stuck?onthesamestateforthelabelvariable\n",
      "becauseinthepositivephasethehiddenactivitiesareinferredwiththelabel\n",
      "clampedtoitstruevalue.Sothehiddenactivitiescontaininformationabout\n",
      "thetruelabel,whichgivesitanadvantageovertheotherlabels.Considerthe\n",
      "extremecasewhereweinitializetheMarkovchainwithatrainingpair\n",
      "f\n",
      "v+,\n",
      "lk+=1\n",
      "g\n",
      "andthelabelvariableneverchangesfromitsinitialstateduringthe\n",
      "chain?sentirerun.Int,themodelthatendsupbeinglearnedisaclass-\n",
      "conditionalgenerativedistributionP(v|lk=1),representedbythekthslice\n",
      "RBM.TheparameterupdatesareidenticaltothosefortrainingNlindependent\n",
      "RBMs,oneperclass,withonlythetrainingcasesofeachclassbeingusedto\n",
      "learntheRBMforthatclass.Notethatthisisverydrentfromthemodel\n",
      "insection2:heretheenergyfunctionsimplementedbytheclass-conditional\n",
      "RBMsarelearnedindependentlyandtheirenergyunitsarenotcommensurate\n",
      "witheachother.Alternatively,wecanoptimizethesamesetofparametersto\n",
      "representyetanotherdistribution,P(l|v).Theadvantageinthiscaseisthat\n",
      "theexactgradientneededformaximumlikelihoodlearning,?logP(l|v)/?W,\n",
      "canbecomputedinO(NvNhNl)time.Thegradientexpressioncanbederived\n",
      "withsomestraightforwardtiationofequation4.Thedisadvantageis\n",
      "thatitcannotmakeuseofunlabeleddata.Also,astheresultsshow,learning\n",
      "apurelydiscriminativemodelatthetoplevelofaDBNgivesmuchworse\n",
      "performance.However,nowanewwayoflearningP(v,l)becomesapparent:\n",
      "wecanoptimizetheparametersbyusingaweightedsumofthegradientsforlog\n",
      "P(v|l)andlogP(l|v).Asexplainedbelow,thisapproach1)avoidstheslow\n",
      "mixingoftheCDlearningforP(v,l),and2)allowslearningwithbothlabeled\n",
      "andunlabeleddata.Itresemblespseudo-likelihoodinhowitoptimizesthetwo\n",
      "conditionaldistributionsinplaceofthejointdistribution,excepthereoneofthe\n",
      "conditionals(P(v|l))isstilllearnedonlyapproximately.Inourexperiments,a\n",
      "modeltrainedwiththishybridlearningalgorithmhasthehighest\n",
      "accuracy,beatingbothagenerativemodeltrainedusingCDaswellasapurely\n",
      "discriminativemodel.4\n",
      "5\n",
      "\n",
      "Themainstepsofthealgorithmarelistedbelow.\n",
      "HybridlearningalgorithmforP(v,l):Let\n",
      "f\n",
      "v+,lk+=1\n",
      "g\n",
      "bealabeled\n",
      "trainingcase.Generativeupdate:CDlearningofP(v|l)1.Sampleh+?P\n",
      "(h|v+,lk+=1).2.ComputetheouterproductDk+=v+h+T.3.Sample\n",
      "v??P(v|h+,lk+=1).4.Sampleh??P(h|v?,lk+=1).5.Compute\n",
      "theouterproductDk?=v?h?T.g6.Computeupdate?W?,?,k=Dk+?\n",
      "Dk?.\n",
      "Discriminativeupdate:MLlearningofP(l|v)1.ComputelogP(lc=\n",
      "1|v+)forc?\n",
      "f\n",
      "1,...,Nl\n",
      "g\n",
      ".2.Usingtheresultfromstep1andthetrue\n",
      "labellk+=1,computetheupdated?W?,?,k=?logP(l|v)/?W?,?,cforc\n",
      "?\n",
      "f\n",
      "1,...,Nl\n",
      "g\n",
      ".ThetwotypesofupdateforthecthsliceofthetensorW?,?,c\n",
      "arethencombinedbyaweightedsum:gdW?,?,c?W?,?,c+?(?W?,?,c+\n",
      "??W?,?,c),(7)where?isaparameterthatsetstherelativeweightingofthe\n",
      "generativeanddiscriminativeupdates,and?isthelearningrate.Asbefore,\n",
      "theupdatesfromamini-batchoftrainingcasescanbeaveragedtogetherand\n",
      "appliedasasingleupdatetotheparameters.Inexperiments,weset?bytrying\n",
      "tvaluesandevaluatingclaaccuracyonavalidationset.Note\n",
      "thatthegenerativepartintheabovealgorithmissimplyCDlearningofthe\n",
      "RBMforthekthclass.Theearlierproblemofslowmixingdoesnotappearin\n",
      "thehybridalgorithmbecausethechaininthegenerativepartdoesnotinvolve\n",
      "samplingthelabel.Semi-supervisedlearning:Thehybridlearningalgorithm\n",
      "canalsomakeuseofunlabeledtrainingcasesbytreatingtheirlabelsasmissing\n",
      "inputs.ThemodelinfersthemissinglabelbysamplingP(l|vu)foran\n",
      "unlabeledtrainingcasevu.Thegenerativeupdateisthencomputedbytreating\n",
      "theinferredlabelasthetruelabel.(Thediscriminativeupdatewillalwaysbe\n",
      "zerointhiscase.)Thereforetheunlabeledtrainingcasescontributeanextra\n",
      "generativetermtotheparameterupdate.\n",
      "4\n",
      "Sparsity\n",
      "Discriminativeperformanceisimprovedbyusingbinaryfeaturesthatare\n",
      "onlyrarelyactive.Sparseactivitiesareachievedbyspecifyingadesiredproba-\n",
      "bilityofbeingactive,p<<1,andthenaddinganadditionalpenaltytermthat\n",
      "encouragesanexponentiallydecayingaverage,q,oftheactualprobabilityof\n",
      "beingactivetobeclosetop.Thenaturalerrormeasuretouseisthecross\n",
      "entropybetweenthedesiredandactualdistributions:plogq+(1?p)log(1\n",
      "?q).Forlogisticunitsthishasasimplederivativeofp?qwithrespecttothe\n",
      "totalinputtoaunit.Thisderivativeisusedtoadjustboththebiasandthe\n",
      "incomingweightsofeachhiddenunit.Wetriedvariousvaluesforpand0.1\n",
      "workedwell.Inadditiontospecifyingpitisnecessarytospecifyhowfastthe\n",
      "estimateofqdecays.Weusedqnew=0.9?qold+0.1?qcurrentwhere\n",
      "qcurrentistheaverageprobabilityofactivationforthecurrentmini-batchof\n",
      "100trainingcases.Itisalsonecessarytospecifyhowstrongthepenaltyterm\n",
      "shouldbe,butthisiseasytosetempirically.Wemultiplythepenaltygradient\n",
      "byacotthatischosentoensurethat,onaverage,qisclosetopbut\n",
      "thereisstilltvariationamongtheqvaluesforthiddenunits.\n",
      "Thispreventsthepenaltytermfromdominatingthelearning.One5\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addedadvantageofthissparsenesspenaltyisthatitrevivesanyhiddenunits\n",
      "whoseaverageactivitiesaremuchlowerthanp.\n",
      "55.1\n",
      "EvaluatingDBNsontheNORBObjectRecognitionTaskNORBDatabase\n",
      "Foradetaileddescriptionsee[12].TheeobjectclassesinNORBare\n",
      "animals,humans,planes,trucks,andcars.Thedatasetcomesintwot\n",
      "versions,normalized-uniformandjittered-cluttered.Inthispaperweusethe\n",
      "normalized-uniformversion,whichhasobjectscentredintheimageswitha\n",
      "uniformbackground.Thereare10instancesofeachobjectclass,imagedunder\n",
      "6illuminationsand162viewpoints(18azimuths?9elevations).Theinstances\n",
      "aresplitintotwodisjointsets(pre-spinthedatabase)ofveeachto\n",
      "thetrainingandtestsets,bothcontaining24,300cases.Soattesttime\n",
      "atrainedmodelhastorecognizeunseeninstancesofthesameobjectclasses.\n",
      "Pre-processing:Asingletraining(andtest)caseisastereo-pairofgrayscale\n",
      "images,eachofsize96?96.Tospeedupexperiments,wereducedimensionality\n",
      "byusinga?foveal?imagerepresentation.Thecentral64?64portionofan\n",
      "imageiskeptatitsoriginalresolution.Theremaining16pixel-wideringaround\n",
      "itiscompressedbyreplacingnon-overlappingsquareblocksofpixelswiththe\n",
      "averagevalueofablock.Wesplittheringintofoursmallerones:theoutermost\n",
      "ringhas8?8blocks,followedbyaringof4?4blocks,andtwoinnermost\n",
      "ringsof2?2blocks.Thefovealrepresentationreducesthedimensionalityofa\n",
      "stereo-pairfrom18432to8976.Allourmodelstreatthestereo-pairimagesas\n",
      "8976dimensionalvectors1.5.2\n",
      "TrainingDetails\n",
      "Modelarchitecture:ThetwomaindecisionstomakewhentrainingDBNs\n",
      "arethenumberofhiddenlayerstogreedilypre-trainandthenumberofhidden\n",
      "unitstouseineachlayer.Tosimplifytheexperimentsweconstrainthenumber\n",
      "ofhiddenunitstobethesameatalllayers(includingthetop-levelmodel).We\n",
      "havetriedhiddenlayersizesof2000,4000,and8000units.Wehavealsotried\n",
      "modelswithtwo,one,ornogreedilypre-trainedhiddenlayers.Toavoidclutter,\n",
      "onlytheresultsforthebestsettingsofthesetwoparametersaregiven.The\n",
      "bestresultsaregivenbytheDBNwithonegreedilypre-trained\n",
      "sparsehiddenlayerof4000units(regardlessofthetypeoftop-levelmodel).A\n",
      "DBNtrainedonthepre-processedinputwithonegreedilypre-trainedlayerof\n",
      "4000hiddenunitsandathird-ordermodelontopofit,alsowith4000hidden\n",
      "units,hasroughly116millionlearnableparametersintotal.Thisisroughly\n",
      "twoordersofmagnitudemoreparametersthansomeoftheearlyDBNstrained\n",
      "ontheMNISTimages[6],[10].TrainingsuchamodelinMatlabonanIntel\n",
      "Xeon3GHzmachinetakesalmosttwoweeks.SeearecentpaperbyRainaet\n",
      "al.[15]thatusesGPUstotrainadeepmodelwithroughlythesamenumber\n",
      "ofparametersmuchmorequickly.WeputGaussianunitsatthelowest(pixel)\n",
      "layeroftheDBN,whichhavebeenshowntobetiveformodellinggrayscale\n",
      "images[7].See[7],[21]fordetailsaboutGaussianunits.\n",
      "6\n",
      "Results\n",
      "Theresultsarepresentedinthreeparts:part1comparesdeepmodelsto\n",
      "7\n",
      "\n",
      "shallowones,alltrainedusingCD.Part2comparesCDtothehybridlearning\n",
      "algorithmfortrainingthetop-levelmodelofaDBN.Part3comparesDBNs\n",
      "trainedwithandwithoutunlabeleddata,usingeitherCDorthehybridalgo-\n",
      "rithmatthetoplevel.Forcomparison,herearesomepublishedresultsfordis-\n",
      "criminativemodelsonnormalized-uniformNORB(withoutanypre-processing)\n",
      "[2],[12]:logisticregression19.6%,kNN(k=1)18.4%,GaussiankernelSVM\n",
      "11.6%,convolutionalneuralnet6.0%,convolutionalnet+SVMhybrid5.9%.1\n",
      "Knowledgeaboutimagetopologyisusedonlyalongthe(mostlyempty)borders,\n",
      "andnotinthecentralportionthatactuallycontainstheobject.\n",
      "6\n",
      "6.1\n",
      "Deepvs.ShallowModelsTrainedwithCD\n",
      "WeconsiderhereDBNswithonegreedilypre-trainedlayerandatop-level\n",
      "modelthatcontainsthegreedilypretrainedfeaturesasits?visible?layer.The\n",
      "correspondingshallowversiontrainsthetop-levelmodeldirectlyonthepixels\n",
      "(usingGaussianvisibleunits),withnopre-trainedlayersinbetween.UsingCD\n",
      "asthelearningalgorithm(forbothgreedypretrainingandatthetop-level)with\n",
      "thetwotypesoftop-levelmodelsgivesusfourpossibilitiestocompare.Thetest\n",
      "errorratesforthesefourmodels(seetable1)showthatonegreedilypre-trained\n",
      "layerreducestheerrorsubstantially,evenwithoutanysubsequentg\n",
      "ofthepre-trainedlayer.ModelShallowDeep\n",
      "RBMwithlabelunit22.8%11.9%\n",
      "Third-orderRBM20.8%7.6%\n",
      "Table1:NORBtestseterrorratesfordeepandshallowmodelstrainedusing\n",
      "CDwithtwotypesoftop-levelmodels.Thethird-orderRBMoutperformsthe\n",
      "standardRBMtop-levelmodelwhentheybothhavethesamenumberofhidden\n",
      "units,butabettercomparisonmightbetomatchthenumberofparametersby\n",
      "increasingthehiddenlayersizeofthestandardRBMmodelbyetimes(i.e.\n",
      "20000hiddenunits).WehavetriedtrainingsuchanRBM,buttheerrorrate\n",
      "isworsethantheRBMwith4000hiddenunits.6.2\n",
      "Hybridvs.CDLearningfortheTop-levelModel\n",
      "Wenowcomparethetwoalternativesfortrainingthetop-levelmodelofa\n",
      "DBN.Therearefourpossiblecombinationsoftop-levelmodelsandlearning\n",
      "algorithms,andtable2liststheirerrorrates.AlltheseDBNssharethesame\n",
      "greedilypre-trainedlayer?onlythetop-levelmodelamongthem.\n",
      "LearningalgorithmCDHybrid\n",
      "RBMwithlabelunit11.9%10.4%\n",
      "Third-orderRBM7.6%6.5%\n",
      "Table2:NORBtestseterrorratesfortop-levelmodelstrainedusingCD\n",
      "andthehybridlearningalgorithms.Thelowererrorratesofhybridlearningare\n",
      "partlyduetoitsabilitytoavoidthepoormixingofthelabelvariablewhenCD\n",
      "isusedtolearnthejointdensityP(v,l)andpartlyduetoitsgreateremphasis\n",
      "ondiscrimination(butwithstrongregularizationprovidedbyalsolearningP\n",
      "(v|l)).6.3\n",
      "Semi-supervisedvs.SupervisedLearning\n",
      "8\n",
      "\n",
      "Inthispart,wecreateadditionalimagesfromtheoriginalNORBtrain-\n",
      "ingsetbyapplyingglobaltranslationsof2,4,and6pixelsineightdirections\n",
      "(twohorizontal,twoverticalandfourdiagonaldirections)totheoriginalstereo-\n",
      "pairimages2.These?jittered?imagesaretreatedasextraunlabeledtraining\n",
      "casesthatarecombinedwiththeoriginallabeledcasestoformamuchlarger\n",
      "trainingset.Notethatwecouldhaveassignedthejitteredimagesthesame\n",
      "classlabelastheirsourceimages.Bytreatingthemasunlabeled,thegoalisto\n",
      "testwhetherimprovingtheunsupervised,generativepartofthelearningalone\n",
      "canimprovediscriminativeperformance.Therearetwowaystouseunlabeled\n",
      "data:1.Useitforgreedypre-trainingofthelowerlayersonly,andthentrain\n",
      "thetop-levelmodelasbefore,withonlylabeleddataandthehybridalgorithm.\n",
      "2\n",
      "Thesametranslationisappliedtobothimagesinthestereo-pair.\n",
      "7\n",
      "2.Useitforlearningthetop-levelmodelaswell,nowwiththesemi-\n",
      "supervisedvariantofthehybridalgorithmatthetop-level.Table3liststhe\n",
      "resultsforbothoptions.Top-levelmodel(hyrbidlearningonly)RBMwith\n",
      "labelunitThird-ordermodel\n",
      "Unlabeledjitterforpre-traininglowerlayer?NoYesNoYesYes\n",
      "Unlabeledjitteratthetop-level?\n",
      "Error\n",
      "NoNoNoNoYes\n",
      "10.4%9.0%6.5%5.3%5.2%\n",
      "Table3:NORBtestseterrorratesforDBNstrainedwithandwithout\n",
      "unlabeleddata,andusingthehybridlearningalgorithmatthetop-level.The\n",
      "keyconclusionfromtable3isthatsimplyusingmoreunlabeledtrainingdatain\n",
      "theunsupervised,greedypre-trainingphasealonecantlyimprovethe\n",
      "accuracyoftheDBN.Itallowsathird-ordertop-levelmodelto\n",
      "reduceitserrorfrom6.5%to5.3%,whichbeatsthecurrentbestpublishedresult\n",
      "fornormalized-uniformNORBwithoutusinganyextralabeleddata.Using\n",
      "moreunlabeleddataalsoatthetoplevelfurtherimprovesaccuracy,butonly\n",
      "slightly,to5.2%.Nowconsideradiscriminativemodelatthetop,representing\n",
      "thedistributionP(l|v).Unlikeinthegenerativecase,theexactgradientof\n",
      "thelog-likelihoodistractabletocompute.Table4showstheresultsofsome\n",
      "discriminativemodels.Thesemodelsusethesamegreedilypre-trainedlower\n",
      "layer,learnedwithunlabeledjitter.Theyinhowthetop-levelparameters\n",
      "areinitialized,andwhethertheyusethejitteredimagesasextralabeledcasesfor\n",
      "learningP(l|v).Wecomparetrainingthediscriminativetoplevelmodel?from\n",
      "scratch?(randominitializaInitializationUsejitteredtion)versusinitializingits\n",
      "parameterstothoseoftop-levelimagesasErrorofagenerativemodellearnedby\n",
      "thehybridalparameterslabeled?gorithm.Wealsocomparetheofusing\n",
      "theRandomNo13.4%jitteredimagesasextralabeledcases.AsmenRandom\n",
      "Yes7.1%tionedbefore,itispossibletoassignthejitteredModelwithimagesthe\n",
      "samelabelsastheoriginalNORB5.2%errorYes5.0%imagestheyaregenerated\n",
      "from,whichexpandsfromtable3thelabeledtrainingsetby25times.The\n",
      "botTable4:NORBtestseterrorratesfordis-tomtworowsoftable4compare\n",
      "9\n",
      "\n",
      "adiscriminativecriminativethird-ordermodelsatthetopthird-ordermodel\n",
      "initializedwithandwithoutpre-training.Pre-trainedinitialization(5.0%)level.\n",
      "tlyimprovesaccuracyoverrandominitialization(7.1%).Butnote\n",
      "thatdiscriminativetrainingonlymakesasmalladditionalimprovement(5.2%\n",
      "to5.0%)overtheaccuracyofthepre-trainedmodelitself.\n",
      "7\n",
      "Conclusions\n",
      "Ourresultsmakeastrongcasefortheuseofgenerativemodelinginobject\n",
      "recognition.Themaintwopointsare:1)Unsupervised,greedy,generative\n",
      "learningcanextractanimagerepresentationthatsupportsmoreaccurateobject\n",
      "recognitionthantherawpixelrepresentation.2)IncludingP(v|l)inthe\n",
      "objectivefunctionfortrainingthetop-levelmodelresultsinbetterclasscation\n",
      "accuracythanusingP(l|v)alone.Infutureworkweplantofactorizethe\n",
      "third-orderBoltzmannmachineasdescribedin[18]sothatsomeofthetop-\n",
      "levelfeaturescanbesharedacrossclasses.8\n",
      "2References\n",
      "[1]Y.Bengio,P.Lamblin,P.Popovici,andH.Larochelle.GreedyLayer-Wise\n",
      "TrainingofDeepNetworks.InNIPS,2006.[2]Y.BengioandY.LeCun.Scaling\n",
      "learningalgorithmstowardsAI.InLarge-ScaleKernelMachines,2007.[3]D.\n",
      "DeCosteandB.Scholkopf.TrainingInvariantSupportVectorMachines.Ma-\n",
      "chineLearning,46:161?190,2002.[4]G.E.Hinton.Trainingproductsofexperts\n",
      "byminimizingcontrastivedivergence.NeuralComputation,14(8):1711?1800,\n",
      "2002.[5]G.E.Hinton.ToRecognizeShapes,FirstLearntoGenerateImages.\n",
      "TechnicalReportUTMLTR2006-04,Dept.ofComputerScience,Universityof\n",
      "Toronto,2006.[6]G.E.Hinton,S.Osindero,andY.Teh.Afastlearningalgo-\n",
      "rithmfordeepbeliefnets.NeuralComputation,18:1527?1554,2006.[7]G.E.\n",
      "HintonandR.Salakhutdinov.Reducingthedimensionalityofdatawithneural\n",
      "networks.Science,313:504?507,2006.[8]M.Kelm,C.Pal,andA.McCallum.\n",
      "CombiningGenerativeandDiscriminativeMethodsforPixelClaswith\n",
      "Multi-ConditionalLearning.InICPR,2006.[9]H.LarochelleandY.Bengio.\n",
      "UsingDiscriminativeRestrictedBoltzmannMachines.InICML,\n",
      "pages536?543,2008.[10]H.Larochelle,D.Erhan,A.Courville,J.Bergstra,\n",
      "andY.Bengio.Anempiricalevaluationofdeeparchitecturesonproblemswith\n",
      "manyfactorsofvariation.InICML,pages473?480,2007.[11]Y.LeCun,L.\n",
      "Bottou,Y.Bengio,andP.Gradient-basedlearningappliedtodocu-\n",
      "mentrecognition.ProceedingsoftheIEEE,86(11):2278?2324,November1998.\n",
      "[12]Y.LeCun,F.J.Huang,andL.Bottou.Learningmethodsforgenericob-\n",
      "jectrecognitionwithinvariancetoposeandlighting.InCVPR,Washington,\n",
      "D.C.,2004.[13]H.Lee,R.Grosse,R.Ranganath,andA.Ng.Convolutional\n",
      "DeepBeliefNetworksforScalableUnsupervisedLearningofHierarchicalRep-\n",
      "resentations.InICML,2009.[14]V.NairandG.E.Hinton.Implicitmixtures\n",
      "ofrestrictedboltzmannmachines.InNeuralinformationprocessingsystems,\n",
      "2008.[15]R.Raina,A.Madhavan,andA.Ng.Large-scaleDeepUnsuper-\n",
      "10\n",
      "\n",
      "visedLearningusingGraphicsProcessors.InICML,2009.[16]Marc?Aurelio\n",
      "Ranzato,Fu-JieHuang,Y-LanBoureau,andYannLeCun.Unsupervisedlearn-\n",
      "ingofinvariantfeaturehierarchieswithapplicationstoobjectrecognition.In\n",
      "Proc.ComputerVisionandPatternRecognitionConference(CVPR?07).IEEE\n",
      "Press,2007.[17]T.J.Sejnowski.Higher-orderBoltzmannMachines.InAIP\n",
      "ConferenceProceedings,pages398?403,1987.[18]G.TaylorandG.E.Hin-\n",
      "ton.FactoredConditionalRestrictedBoltzmannMachinesforModelingMotion\n",
      "Style.InICML,2009.[19]V.Vapnik.StatisticalLearningTheory.JohnWiley\n",
      "andSons,1998.[20]P.Vincent,H.Larochelle,Y.Bengio,andP.A.Manzagol.\n",
      "ExtractingandComposingRobustFeatureswithDenoisingAutoencoders.In\n",
      "ICML,2008.[21]M.Welling,M.Rosen-Zvi,andG.E.Hinton.Exponential\n",
      "familyharmoniumswithanapplicationtoinformationretrieval.InNIPS17,\n",
      "2005.\n",
      "9\n",
      "11\n",
      "\n",
      "PP6945.pdf\n",
      "PP6945.pdf 12\n",
      "LimitationsonVariance-Reductionand\n",
      "AccelerationSchemesforFiniteSums\n",
      "Optimization\n",
      "Authoredby:\n",
      "YossiArjevani\n",
      "Abstract\n",
      "Westudytheconditionsunderwhichoneisabletotlyap-\n",
      "plyvariance-reductionandaccelerationschemesonsumsproblems.\n",
      "First,weshowthatperhapssurprisingly,thesumstructure,byitself,\n",
      "isnottforobtainingacomplexityboundof$tilde\n",
      "f\n",
      "cO\n",
      "g\n",
      "((n+L/mu)ln(1/epsilon))$\n",
      "for$L$-smoothand$mu$-stronglyconvexsums-onemustalso\n",
      "knowexactlywhichindividualfunctionisbeingreferredtobytheoracle\n",
      "ateachiteration.Next,weshowthatforabroadclassof\n",
      "andcoordinate-descentsumsalgorithms(including,e.g.,SDCA,\n",
      "SVRG,SAG),itisnotpossibletogetan`accelerated'complexitybound\n",
      "of$tilde\n",
      "f\n",
      "cO\n",
      "g\n",
      "((n+sqrt\n",
      "f\n",
      "nL/mu\n",
      "g\n",
      ")ln(1/epsilon))$,unlessthestrongcon-\n",
      "vexityparameterisgivenexplicitly.Lastly,weshowthatwhenthisclass\n",
      "ofalgorithmsisusedforminimizing$L$-smoothandnon-stronglyconvex\n",
      "sums,theoptimalcomplexityboundis$tilde\n",
      "f\n",
      "cO\n",
      "g\n",
      "(n+L/epsilon)$,\n",
      "assumingthat(onaverage)thesameupdateruleisusedforanyiteration,\n",
      "and$tilde\n",
      "f\n",
      "cO\n",
      "g\n",
      "(n+sqrt\n",
      "f\n",
      "nL/epsilon\n",
      "g\n",
      ")$,otherwise.\n",
      "1PaperBody\n",
      "Anoptimizationproblemprincipaltomachinelearningandstatisticsisthatof\n",
      "sums:n\n",
      "minF(w):=\n",
      "w?Rd\n",
      "1X(w),ni=1\n",
      "(1)\n",
      "wheretheindividualfunctionsareassumedtopossesssomefavorableana-\n",
      "lyticalproperties,suchasLipschitz-continuity,smoothnessorstrongconvexity\n",
      "(see[16]fordetails).Wemeasuretheiterationcomplexityofagivenoptimiza-\n",
      "tionalgorithmbydetermininghowmanyevaluationsofindividualfunctions\n",
      "(viasomeexternaloracleprocedure,alongwiththeirgradient,Hessian,etc.)\n",
      "areneededinordertoobtainan-solution,i.e.,apointw?Rdwhichsatises\n",
      "1\n",
      "\n",
      "E[F(w)?minw?RdF(w)]<(wheretheexpectationistakenw.r.t.thealgo-\n",
      "rithmandtheoraclerandomness).Arguably,thesimplestwayofminimizing\n",
      "sumproblemsisbyusingoptimizationalgorithmsforgeneraloptimiza-\n",
      "tionproblems.Forconcretenessofthefollowingdiscussion,letusassumeforthe\n",
      "momentthattheindividualfunctionsareL-smoothand?-stronglyconvex.In\n",
      "thiscase,byapplyingvanillaGradientDescent(GD)orAcceleratedGradient\n",
      "Descent(AGD,[16]),oneobtainsiterationcomplexityof\n",
      "???n?ln(1/),(2)O(n?ln(1/))orO?hideslogarithmicrespectively,\n",
      "where?:=L/?denotestheconditionnumberoftheproblemandOfactorsin\n",
      "theproblemparameters.However,whereassuchboundsenjoylogarithmicde-\n",
      "pendenceon31stConferenceonNeuralInformationProcessingSystems(NIPS\n",
      "2017),LongBeach,CA,USA.\n",
      "theaccuracylevel,themultiplicativedependenceonnrendersthisapproach\n",
      "unsuitableformodernapplicationswherenisverylarge.Atapproach\n",
      "totackleasumproblemisbyreformulatingitasastochasticoptimization\n",
      "problem,i.e.,minw?RdEi?U([n])(w)],andthenapplyingageneralstochastic\n",
      "method,such\n",
      "asSGD,whichallowsiterationcomplexityofO(1/)orO1/2(dependingon\n",
      "theproblemparameters).Thesemethodsrateswhichdonotdependon\n",
      "n,andarethereforeattractiveforsituationswhereoneseeksforasolutionof\n",
      "relativelylowaccuracy.Anevidentdrawbackofthesemethodsistheirbroad\n",
      "applicabilityforstochasticoptimizationproblems,whichmaywiththe\n",
      "goaloftlyexploitingtheuniquenoisestructureofsums(indeed,in\n",
      "thegeneralstochasticsetting,theseratescannotbeimproved,e.g.,[1,18]).In\n",
      "recentyears,amajorbreakthroughwasmadewhenstochasticmethodsspecial-\n",
      "izedinitesumsSAG[19]andSDCA[21],andthenSAGA[10],SVRG\n",
      "[11],SDCAwithoutduality[20],andothers)wereshowntoobtainiteration\n",
      "complexityof?O((n+?)ln(1/)).\n",
      "(3)\n",
      "Theabilityofthesealgorithmstoenjoybothlogarithmicdependenceonthe\n",
      "accuracyparameterandanadditivedependenceonniswidelyattributedto\n",
      "thefactthatthenoiseofnitesumproblemsdistributesoverasetofsize\n",
      "n.Perhapssurprisingly,inthispaperweshowthatanotherkeyingredientis\n",
      "crucial,namely,ameanofknowingwhichindividualfunctionisbeingreferred\n",
      "tobytheoracleateachiteration.Inparticular,thisshowsthatvariance-\n",
      "reductionmechanisms(see,e.g.,[10,Section3])cannotbeappliedwithout\n",
      "explicitlyknowingthe?identity?oftheindividualfunctions.Onthemore\n",
      "practicalside,thisresultshowsthatwhendataaugmentation(e.g.,[14])is\n",
      "donewithoutanexplicitenumerationoftheaddedsamples,itisimpossibleto\n",
      "obtainiterationcomplexityasstatedin(3,see[7]forrelevantupperbounds).\n",
      "Althoughvariance-reductionmechanismsareessentialforobtaininganadditive\n",
      "dependenceonn(asshownin(3)),theydonotnecessarilyyield?accelerated?\n",
      "rateswhichdependonthesquarerootoftheconditionnumber(asshownin\n",
      "(2)forAGD).Recently,genericaccelerationschemeswereusedby[13]and\n",
      "acceleratedSDCA[22]toobtainiterationcomplexityof\n",
      "??(n+nk)ln(1/).O(4)Thequestionofwhetherthisrateisoptimal\n",
      "2\n",
      "\n",
      "wasansweredelyby[23,12,5,3].Thecategoryoflowerbounds\n",
      "exploitsthedegreeoffreedombyad-(orandimensionalspace\n",
      "toshowthatanyandacertainclassofsecond-ordermethodscannot\n",
      "obtainbetterratesthan(4)intheregimewherethenumberofiterationsisless\n",
      "thanO(d/n).Thesecondcategoryoflowerboundsisbasedonmaintainingthe\n",
      "complexityofthefunctionalformoftheiterates,therebyestablishingbounds\n",
      "forst-orderandcoordinate-descentalgorithmswhosestepsizesareoblivious\n",
      "totheproblemparameters(e.g.,SAG,SAGA,SVRG,SDCA,SDCAwithout\n",
      "duality)foranynumberofiterations,regardlessofdandn.Inthiswork,we\n",
      "furtherextendthetheoryofoblivioussumalgorithms,byshowingthat\n",
      "ifaandacoordinate-descentoracleareused,thenaccelerationis\n",
      "notpossiblewithoutanexplicitknowledgeofthestrongconvexityparameter.\n",
      "Thisimpliesthatincaseswhereonlypoorestimationofthestrongconvexity\n",
      "isavailable,fasterratesmaybeobtainedthrough?adaptive?algorithms(see\n",
      "relevantdiscussionsin[19,4]).Next,weshowthatinthesmoothandconvex\n",
      "case,obliviousnitesumalgorithmswhich,onaverage,applythesameupdate\n",
      "ruleateachiteration(e.g.,SAG,SDCA,SVRG,SVRG++[2],andtypically,\n",
      "otheralgorithmswithavariance-reductionmechanismasdescribedin[10,Sec-\n",
      "tion3]),areboundtoiterationpcomplexityof?(n+L/),whereLdenotes\n",
      "thesmoothnessparameter(ratherthan?(n+nL/)).Toshowthis,weemploy\n",
      "arestartingscheme(see[4])whichexplicitlyintroducesthestrongconvexity\n",
      "parameterintoalgorithmsthataredesignedforsmoothandconvexfunctions.\n",
      "Finally,weusethisschemetoestablishatightdimension-freelowerboundfor\n",
      "smoothandconvexsumswhichholdsforobliviousalgorithmswitha\n",
      "orderandacoordinate-descentoracle.Tosummarize,ourcontributions(in\n",
      "orderofappearance)arethefollowing:?InSection2,weprovethatinthe\n",
      "settingofstochasticoptimization,havingsupportednoise(asin\n",
      "sumproblems)isnottforobtaininglinearconvergencerateswith2\n",
      "alineardependenceonn-onemustalsoknowexactlywhichindividual\n",
      "functionisbeingreferredtobytheoracleateachiteration.Derivingsimilarre-\n",
      "sultsforvarioussettings,weshowthatSDCA,acceleratedSDCA,SAG,SAGA,\n",
      "SVRG,SVRG++andothersumalgorithmsmusthaveaproperenumera-\n",
      "tionoftheindividualfunctionsinordertoobtaintheirstatedconvergencerate.\n",
      "?InSection3.1,welaythefoundationsoftheframeworkofgeneralCLIalgo-\n",
      "rithms(see[3]),whichenablesustoformallyaddressobliviousalgorithms(e.g.,\n",
      "whenstepsizesarescheduledregardlessofthefunctionathand).Insection\n",
      "3.2,weimproveupon[4],byshowingthat(inthisgeneralizedframework)the\n",
      "optimaliterationcomplexityofoblivious,deterministicorstochastic,sum\n",
      "algorithmswithbothandcoordinate-descentoraclescannotperform\n",
      "betterthan?(n+?ln(1/)),unlessthestrongconvexityparameterisprovided\n",
      "explicitly.Inparticular,thericherexpressivenesspowerofthisframeworkal-\n",
      "lowsaddressingincrementalgradientmethods,suchasIncrementalGradient\n",
      "Descent[6]andIncrementalAggregatedGradient[8,IAG].?InSection3.3,\n",
      "weshowthat,intheL-smoothandconvexcase,theoptimalcomplexitybound\n",
      "(intermsoftheaccuracyparameter)ofobliviousalgorithmswhosepupdate\n",
      "rulesare?+nL/),asobtained,(onaverage)foranyiterationis?(n+\n",
      "3\n",
      "\n",
      "L/)(ratherthenO(ne.g.,byacceleratedSDCA).Toshowthis,weinvoke\n",
      "arestartingscheme(usedby[4])toexplicitlyintroducestrongconvexityinto\n",
      "algorithmsfornitesumswithsmoothandconvexindividuals,andthenap-\n",
      "plytheresultderivedinSection3.2.?InSection3.4,weusethereduction\n",
      "introducedinSection3.3,toshowthattheoptimaliterationcomplexityofmin-\n",
      "imizingL-smoothandconvexsumsusingobliviousalgorithmspequipped\n",
      "withaandacoordinate-descentoracleis?n+nL/.\n",
      "2\n",
      "TheImportanceofIndividualIdentity\n",
      "Inthefollowing,weaddressthestochasticsettingofsumproblems\n",
      "(1)whereoneisequippedwithastochasticoraclewhich,uponreceivingacall,\n",
      "returnssomeindividualfunctionchosenuniformlyatrandomandhidesitsin-\n",
      "dex.Weshowthatnotknowingtheidentityofthefunctionreturnedbythe\n",
      "oracle(asopposedtoanincrementaloraclewhichaddressesthespindi-\n",
      "vidualfunctionschosenbytheuser),signtlyharmstheoptimalattainable\n",
      "performance.Tothisend,wereducethestatisticalproblemofestimatingthe\n",
      "biasofanoisycoinintothatofoptimizingsums.Thisreduction(pre-\n",
      "sentedbelow)makesanextensiveuseofelementaryandtoolsfrom\n",
      "informationtheory,allofwhichcanbefoundin[9].First,givenn?N,we\n",
      "thefollowingsumproblem\n",
      "1n??+n+??F?:=f+f,n22\n",
      "(5)\n",
      "wherenisw.l.o.g.assumedtobeodd,??\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "andf+,f?are\n",
      "somefunctions(tobelater).Wethenthefollowingdiscrepancy\n",
      "measurebetweenF1andF?1fortvaluesofn(seealso[1]),??(n)=\n",
      "min\n",
      "f\n",
      "F1(w)+F?1(w)?F1??F?1\n",
      "g\n",
      ",w?Rd\n",
      "(6)\n",
      "whereF??:=infwF?(w).Itiseasytoverifythatnosolutioncanbe\n",
      "?(n)/4-optimalforbothF1andF?1,atthesametime.Thus,byrunninga\n",
      "givenoptimizationalgorithmlongenoughtoobtain?(n)/4-solutionw.h.p.,we\n",
      "candeducethevalueof?.Also,notethat,onecansimplifythecomputationof\n",
      "?(n)bychoosingconvexf+,f?suchthatf+(w)=f?(?w).Indeed,inthis\n",
      "case,??wehaveF1(w)=F?1(?w)(inparticular,F1?=F?1),andsinceF1\n",
      "(w)+F?1(w)?F1??F?1isconvex,itmustattainitsminimumatw=0,\n",
      "whichyields?(n)=2(F1(0)?F1?).\n",
      "(7)\n",
      "Next,welet??\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "bedrawnuniformlyatrandom,andthenuse\n",
      "thegivenoptimizationalgorithmtoestimatethebiasofarandomvariableX\n",
      "which,conditionedon?,takes+1w.p.1/2+?/2n,and?1w.p.1/2??/2n.\n",
      "Toimplementthestochasticoracledescribedabove,3\n",
      "conditionedon?,wedrawki.i.d.copiesofX,denotedbyX1,...,Xk,\n",
      "andreturnf?,ifXi=?,andf+,otherwise.Now,ifkissuchthat?(n),40\n",
      "forboth?=?1and?=1,thenbyMarkovinequality,wehavethat\n",
      "PF?(w(k))?F????(n)/4??1/10E[F?(w(k))?F??|?]?\n",
      "(8)\n",
      "4\n",
      "\n",
      "(notethatF?(w(k))?F??isanon-negativerandomvariable).Wemay\n",
      "nowtrytoguessthevalueof?usingthefollowingestimator??(w(k))=\n",
      "argmin\n",
      "f\n",
      "F?0(w(k))?F??0\n",
      "g\n",
      ",?0?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "whoseprobabilityoferror,asfollowsbyInequality(8),isP(??6=?)?\n",
      "1/10.\n",
      "(9)\n",
      "Lastly,weshowthattheexistenceofanestimatorfor?withhighprobability\n",
      "ofsuccessimpliesthatk=?(n2).Tothisend,notethatthecorresponding\n",
      "conditionaldependencestructureofthisprobabilisticsettingcanbemodeledas\n",
      "follows:??X1,...,Xk???.Thus,wehave(a)\n",
      "(b)\n",
      "(c)\n",
      "H(?|X1,...,Xk)?H(?|??)?Hb(P(??6=?))?\n",
      "1,2\n",
      "(10)\n",
      "whereH(?)andHb(?)denotetheShannonentropyfunctionandthebinary\n",
      "entropyfunction,respectively,(a)followsbythedataprocessinginequality(in\n",
      "termsofentropy),(b)followsbyFano?sinequalityand(c)followsfromEquation\n",
      "(9).Applyingstandardentropyidentities,weget(d)\n",
      "H(?|X1,...,Xk)=H(X1,...,Xk|?)+H(?)?H(X1,...,\n",
      "Xk)(e)\n",
      "=kH(X1|?)+1?H(X1,...,Xk)\n",
      "(f)\n",
      "?kH(X1|?)+1?kH(X1),\n",
      "(11)\n",
      "where(d)followsfromBayesrule,(e)followsbythefactthatXi,conditioned\n",
      "on?,arei.i.d.and(f)followsfromthechainruleandthefactthatconditioning\n",
      "reducesentropy.CombiningthiswithInequality(10)andrearranging,wehave\n",
      "k?\n",
      "11n2?=,22(H(X1)?H(X1|?))22(1/n)\n",
      "wherethelastinequalityfollowsfromthefactthatH(X1)=1andthe\n",
      "followingestimationforthe2binaryentropyfunction:Hb(p)?1?4(p?\n",
      "1/2)(seeLemma2,AppendixA).Thus,wearriveatthefollowingstatement.\n",
      "Lemma1.Theminimalnumberofstochasticoraclecallsrequiredtoobtain\n",
      "?(n)/40-optimalsolutionforproblem(5)is?n2/2.Instantiatingthisschemes\n",
      "forf+,f?ofvariousanalyticalpropertiesyieldsthefollowing.Theorem1.\n",
      "Whensolvingasumproblemin1)withastochasticoracle,one\n",
      "needsatleastn2/2oraclecallsinordertoobtainanaccuracylevelof:1.\n",
      "?+140n2\n",
      "forsmoothandstronglyconvexindividualswithcondition?.\n",
      "2.\n",
      "L40n2\n",
      "forL-smoothandconvexindividuals.\n",
      "3.\n",
      "M240?n2\n",
      "Mif?n?1,andconvexindividuals.\n",
      "5\n",
      "\n",
      "M20n\n",
      "??40,otherwise,for(M+?)-Lipschitzcontinuousand?-strongly\n",
      "4\n",
      "Proof1.Dene,f?(w)=\n",
      "1>(w?q)A(w?q),2\n",
      "whereAisad?ddiagonalmatrixwhosediagonalentriesare?,1...,\n",
      "1,andq=(1,1,0,...,0)>isad-dimensionalvector.Onecaneasilyverify\n",
      "thatf?aresmoothandstronglyconvexfunctionswithconditionnumber?,\n",
      "andthat\n",
      "?>11?1w?qAw?q+F?(w)=1?2q>Aq.2nn2nTherefore,the\n",
      "minimizerofF?is(?/n)q,andusingEquation(7),weseethat?(n)=\n",
      "?+1n2.\n",
      "2.Wef?(w)=\n",
      "L2kw?e1k.2\n",
      "Onecaneasilyverifythatf?areL-smoothandconvexfunctions,andthat\n",
      "theminimizerofF?is(?/n)e1.ByEquation(7),weget?(n)=nL2.3.We\n",
      "f?(w)=Mkw?e1k+\n",
      "?2kwk,2\n",
      "overtheunitball.Clearly,f?are(M+?)-Lipschitzcontinuousand?-\n",
      "stronglyconvexMfunctions.ItcanbevthattheminimizerofF?is(?\n",
      "min\n",
      "f\n",
      "?n,1\n",
      "g\n",
      ")e1.Therefore,byEquation(7),weseethatinthiscasewehave\n",
      "(2MM2?n?1.?(n)=?n2Mn??o.w.\n",
      "AfewconclusionscanbereadilymadefromTheorem1.First,ifagiven\n",
      "optimizationalgorithmobtainsaniterationcomplexityofanorderofc(n,?)\n",
      "ln(1/),uptologarithmicfactors(includingthenormoftheminimizerwhich,in\n",
      "ourconstruction,isofanorderof1/nandcoupledwiththeaccuracyparameter),\n",
      "forsolvingsmoothandstronglyconvexsumproblemswithastochastic\n",
      "oracle,then\n",
      "n2?c(n,?)=?.ln(n2/(?+1))Thus,thefollowingholdsforoptimiza-\n",
      "tionofsumswithsmoothandstronglyconvexindividuals.Corollary1.In\n",
      "ordertoobtainlinearconvergenceratewithlineardependenceonn,onemust\n",
      "knowtheindexoftheindividualfunctionaddressedbytheoracle.Thisimplies\n",
      "thatvariance-reductionmethodssuchas,SAG,SAGA,SDCAandSVRG(pos-\n",
      "siblycombiningwithaccelerationschemes),whichexhibitlineardependenceon\n",
      "n,cannotbeappliedwhendataaugmentationisused.Ingeneral,thiscon-\n",
      "clusionalsoholdsforcaseswhenoneappliesgeneralrst-orderoptimization\n",
      "algorithms,suchasAGD,onsums,asthistypicallyresultsinalinearde-\n",
      "pendenceonn.Secondly,ifagivenoptimizationalgorithmobtainsaniteration\n",
      "complexityofanorderofn+L?kw(0)?w?k2/?forsolvingsmoothandcon-\n",
      "vexsumproblemswithastochasticoracle,thenn+L???n2(??1)=?(n2\n",
      ").Therefore,?=?and??2,indicatingthataniterationcomplexityofan\n",
      "orderofn+Lkw(0)?w?k2/,asobtainedby,e.g.,SVRG++,isnotattainable\n",
      "withastochasticoracle.SimilarreasoningbasedontheLipschitzandstrongly\n",
      "convexcaseinTheorem1showsthattheiterationcomplexityguaranteedby\n",
      "acceleratedSDCAisalsonotattainableinthissetting.5\n",
      "3\n",
      "6\n",
      "\n",
      "ObliviousOptimizationAlgorithms\n",
      "Intheprevioussection,wediscussedtsituationsunderwhichvariance-\n",
      "reductionschemesarenotapplicable.Now,weturntostudyunderwhatcon-\n",
      "ditionscanoneapplyaccelerationschemes.First,weetheframeworkof\n",
      "obliviousCLIalgorithms.Next,weshowthat,forthisfamilyofalgorithms,\n",
      "knowingthestrongconvexityparameteriscrucialforobtainingaccelerated\n",
      "rates.Wethendescribearestartingschemethroughwhichweestablishthat\n",
      "stationaryalgorithms(whoseupdateruleare,onaverage,thesameforevery\n",
      "iteration)forsmoothandconvexfunctionsaresub-optimal.Finally,weusethis\n",
      "reductiontoderiveatightlowerboundforsmoothandconvexsumson\n",
      "theiterationcomplexityofanyobliviousalgorithm(notjuststationary).3.1\n",
      "Framework\n",
      "Inthesequel,following[3],wepresenttheanalyticframeworkthroughwhich\n",
      "wederiveiterationcomplexitybounds.This,perhapspedantic,formulation\n",
      "willallowsustostudysomewhatsubtledistinctionsbetweenoptimizationalgo-\n",
      "rithms.First,wegivearigorousforaclassofoptimizationproblems\n",
      "whichemphasizestheroleofpriorknowledgeinoptimization.1\n",
      "(ClassofOptimizationProblems).Aclassofoptimizationproblemsisanor-\n",
      "deredtriple(F,I,Of),whereFisafamilyoffunctionsoversomedomain\n",
      "designatedbydom(F),Iistheside-informationgivenpriortotheoptimization\n",
      "processandOfisasuitableoracleprocedurewhichuponreceivingw?domF\n",
      "and?insomeparameterset?,returnsOf(w,?)?dom(F)foragivenf?F(we\n",
      "shallomitthesubscriptinOfwhenfisclearfromthecontext).Insum\n",
      "problems,Fcomprisesoffunctionsasin(1);theside-informationmay\n",
      "containthesmoothnessparameterL,thestrongconvexityparameter?andthe\n",
      "numberofindividualfunctionsn;andtheoraclemayallowonetoqueryabouta\n",
      "spindividualfunction(asinthecaseofincrementaloracle,andasopposed\n",
      "tothestochasticoraclediscussedinSection2).WenowturntoCLIop-\n",
      "timizationalgorithms(see[3]foramorecomprehensivediscussion).\n",
      "2(CLI).AnoptimizationalgorithmiscalledaCanonicalLinearIterative(CLI)\n",
      "optimizationalgorithmoveraclassofoptimizationproblems(F,I,Of),ifgiven\n",
      "aninstancef?F(0)andinitializationpoints\n",
      "f\n",
      "wi\n",
      "g\n",
      "i?J?dom(F),whereJis\n",
      "someindexset,itoperatesbyiterativelygeneratingpointssuchthatforanyi\n",
      "?J,\n",
      "X(k+1)(k)(k)wi?Ofwj;?ij,k=0,1,...(12)j?J(k)?ij\n",
      "holds,where??areparameterschosen,stochasticallyordeterministically,\n",
      "bythealgorithm,possiblybasedontheside-information.Iftheparameters\n",
      "donotdependonpreviouslyacquiredoracleanswers,wesaythatthegiven\n",
      "algorithmisoblivious.Fornotationalconvenience,weassume(k)thatthe\n",
      "solutionreturnedbythealgorithmisstoredinw1.Throughouttherestof\n",
      "thepaper,weshallbeinterestedinobliviousCLIalgorithms(forbrevity,we\n",
      "usuallyomitthe?CLI?equippedwiththefollowingtwoincremental\n",
      "oracles:Generalizedoracle:O(w;A,B,c,i):=(w)+Bw+\n",
      "c,Steepestcoordinate-descentoracle:O(w;j,i):=w+t?ej,(13)where\n",
      "A,B?Rd?d,c?Rd,i?[n],j?[d],ejdenotesthej?thd-dimensional\n",
      "unitvectorandt??argmint?Rfj(w1,...,wj?1,wj+t,wj+1,.\n",
      "7\n",
      "\n",
      "..,wd).Werestricttheoracleparameterssuchthatonlyoneindividual\n",
      "functionisallowedtobeaccessedateachiteration.Weremarkthatthefamily\n",
      "ofobliviousalgorithmswithaandacoordinate-descentoracleiswide\n",
      "andsubsumesSAG,SAGA,SDCA,SDCAwithoutduality,SVRG,SVRG++\n",
      "tonameafew.Also,notethatcoordinate-descentstepsw.r.t.partialgradients\n",
      "canbeimplementedusingthegeneralizedoraclebysettingAtobe\n",
      "someprincipalminoroftheunitmatrix(see,e.g.,RDCMin[15]).Further,\n",
      "similarlyto[3],weallowbothandcoordinate-descentoraclestobe\n",
      "usedduringthesameoptimizationprocess.3.2\n",
      "NoStrongConvexityParameter,NoAccelerationforFiniteSumProblems\n",
      "Havingdescribedouranalyticapproach,wenowturntopresentsomecon-\n",
      "creteapplications.Below,weshowthatintheabsenceofagoodestimationfor\n",
      "thestrongconvexityparameter,theoptimal6\n",
      "iterationcomplexityofobliviousalgorithmsis?(n+kln(1/)).Ourproofis\n",
      "basedonthetechniqueusedin[3,4](see[3,Section2.3]forabriefintroduction\n",
      "ofthetechnique).Given0<<L,wethefollowingsetofoptimization\n",
      "problems(overRdwithd>1)\n",
      "n1X1>>wQ?w?qw,where(14)F?(w):=ni=12?L+???L???1\n",
      "22???LL+???1??2?2R?0?????Q?:=??,q:=???.?,??2\n",
      "..?..???.0?parametrizedby??(,L)(notethattheindividualfunctions\n",
      "areidentical.Weelaboratemoreonthisbelow).Itcanbeeasilyvthat\n",
      "theconditionnumberofF??,which?wedenoteby?(F?),isL/?,andthat\n",
      "thecorrespondingminimizersarew?(?)=(R/?2,R/?2,0,...,0)>with\n",
      "norm?R.Ifweareallowedtousetoptimizationalgorithmfort\n",
      "?inthissetting,thenweknowpthattheoptimaliterationcomplexityisof\n",
      "anorderof(n+n?(F?))ln(1/).However,ifweallowedtouseonlyonesingle\n",
      "algorithm,thenweshowthattheoptimaliterationcomplexityisofanorderof\n",
      "n+?(F?)ln(1/).Theproofgoesasfollows.First,notethatinthissetting,the\n",
      "oraclesin(13)takethefollowingform,Generalizedoracle:\n",
      "O(w;A,B,c,i)=A(Q?w?q)+Bw+c,(15)Steepestcoordinate-descent\n",
      "oracle:O(w;j,i)=(I?(1/(Q?)jj)ei(Q?)j,?)w?qj/(Q?)jjej.Now,since\n",
      "theoracleanswersarelinearin?andthek?thiterateisak-foldcompositionof\n",
      "sumsof(k)theoracleanswers,itfollowsthatw1formsad-dimensionalvector\n",
      "ofunivariatepolynomialsin?ofdegree?kwith(possiblyrandom)cots\n",
      "(formally,seeLemma3,AppendixA).Denoting(k)thepolynomialofthe\n",
      "coordinateofEw1(?)bys(?),weseethatforany??(,L),\n",
      "?\n",
      "2s(?)?\n",
      "RR\n",
      "(k)(k)??Ekw1(?)?w(?)k?kEw1(?)?w(?)k?s(?)?????1,\n",
      "2?2LRwheretheinequalityfollowsbyJenseninequalityandthe\n",
      "secondinequalitybyfocusingonthecoordinateofEw(k)(?)andw?(?).\n",
      "Lastly,sincethecotsofs(?)donotdependon?,wehavebyLemma4\n",
      "inAppendixA,thatthereexists?>0,suchthatforany??(L??,L)itholds\n",
      "that?\n",
      "k+1\n",
      "8\n",
      "\n",
      "R1R2s(?)?\n",
      "??1??1?,\n",
      "?(F?)2LR2Lbywhichwederivethefollowing.Theorem2.Theiteration\n",
      "complexityofoblivioussumoptimizationalgorithmsequippedwithast-\n",
      "orderandacoordinate-descentoraclewhoseside-informationdoesnotcontain\n",
      "thestrong?+?ln(1/)).convexityparameteris?(nThenpartofthelower\n",
      "boundholdsforanytypeofsumalgorithmandisprovedin[3,Theorem\n",
      "5].ThelowerboundstatedinTheorem2istightuptologarithmicfactorsand\n",
      "isattainedby,e.g.,SAG[19].Althoughrelyingonasumwithidentical\n",
      "individualfunctionsmayseemsomewhatdisappointing,itsuggeststhatsome\n",
      "variance-reductionschemescanonlygiveoptimaldependenceintermsofn,\n",
      "andthatobtainingoptimaldependenceintermsoftheconditionnumberneed\n",
      "tobedonethroughother(acceleration)mechanisms(e.g.,[13]).Lastly,note\n",
      "that,thisboundholdsforanynumberofiterations(regardlessoftheproblem\n",
      "parameters).3.3\n",
      "StationaryAlgorithmsforSmoothandConvexFiniteSumsareSub-optimal\n",
      "Intheprevioussection,weshowedthatnotknowingthestrongconvexity\n",
      "parameterreducestheoptimalattainableiterationcomplexity.Inthissection,\n",
      "weusethisresulttoshowthatwhereasgeneral7\n",
      "optimizationpalgorithmsforsmoothandconvexsumproblemsobtain\n",
      "iterationcomplexityof?+nL/),theoptimaliterationcomplexityofstationary\n",
      "algorithms(whoseexpectedupdateO(nrulesareis?(n+L/).Theproof\n",
      "(presentedbelow)isbasedonageneralrestartingscheme(seeScheme1)used\n",
      "in[4].TheschemeallowsonetoapplyalgorithmswhicharedesignedforL-\n",
      "smoothandconvexproblemsonsmoothandstronglyconvexsumsby\n",
      "explicitlyincorporatingthestrongconvexityparameter.Thekeyfeatureofthis\n",
      "reductionisitsabilityto?preserve?theexponentoftheiterationcomplexity?\n",
      "fromanorderofC(f)(L/)?inthenon-stronglyconvexcasetoanorderof(C(f\n",
      ")?)ln(1/)inthestronglyconvexcase,whereC(f)denotessomequantitywhich\n",
      "maydependonfbutnotonk,and?issomepositiveconstant.SCHEMEG\n",
      "IVEN\n",
      "1\n",
      "RESTARTINGSCHEMEANOPTIMIZATIONALGORITHMAFOR\n",
      "SMOOTHCONVEXFUNCTIONSWITH\n",
      "f(w(k))?f??\n",
      "2\n",
      "(0)\n",
      "?C(f)w?w??k0\n",
      "FORANYINITIALIZATIONPOINT\n",
      "ITERATE\n",
      "FOR\n",
      "?w\n",
      "t=1,2,...\n",
      "RESTARTTHESTEPSIZESCHEDULEOFA?(0)INITIALIZEA\n",
      "ATwpRUNAFOR?4C(f)/?ITERATIONS?(0)TOBETHEPOINT\n",
      "RETURNEDBYASETwEND\n",
      "9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theproofgoesasfollows.SupposeAisastationaryCLIoptimization\n",
      "algorithmforL-smoothandconvexsumproblemsequippedwithoracles\n",
      "(13).Also,assumethatitsconvergenceratefor2n?L?kw(0)?w?kk?N,N\n",
      "?Nisofanorderof,forsome?,?,?>0.First,observethatink?thiscase\n",
      "wemusthave?=1.Forotherwise,wegetf(w(k))?f?=((?f)(w(k))?\n",
      "(?f)?)/??n?(?L)?/?k?=???1n?L?/k?,implyingthat,simplyby\n",
      "scalingf,onecanoptimizetoanylevelofaccuracyusingatmostNiterations,\n",
      "whichcontradicts[3,Theorem5].Now,by[4,Lemma1],Scheme1producesa\n",
      "newalgorithmwhoseiterationcomplexityforsmoothandstronglyconvex\n",
      "sumswithconditionnumber?is??+n???ln(1/)).O(N+n?(L/))??O(n\n",
      "(16)Finally,stationaryalgorithmsareinvariantunderthisrestartingscheme.\n",
      "Therefore,thenewalgorithmcannotdependon?.Thus,byTheorem2,it\n",
      "mustholdthatthat??1andthatmax\n",
      "f\n",
      "N,n?\n",
      "g\n",
      "=?(n),provingthefollowing.\n",
      "Theorem3.Iftheiterationcomplexityofastationaryoptimizationalgorithm\n",
      "forsmoothandconvexsumproblemsequippedwithaanda\n",
      "coordinate-descentoracleisoftheformofthel.h.s.of(16),thenitmustbeat\n",
      "least?(n+L/).Wenotethat,thislowerboundistightandisattainedby,e.g.,\n",
      "SDCA.3.4\n",
      "ATightLowerBoundforSmoothandConvexFiniteSums\n",
      "Wenowturntoderivealowerboundforsumproblemswithsmooth\n",
      "andconvexindividualfunctionsusingtherestartingschemeshownintheprevi-\n",
      "oussection.Notethat,hereweallowanyobliviousoptimizationalgorithm,not\n",
      "juststationary.ThetechniqueshowninSection3.2ofreducinganoptimiza-\n",
      "tionproblemintoapolynomialapproximationproblemwasusedin[3]toderive\n",
      "lowerboundsforvarioussettings.Thesmoothandconvexcasewasproved\n",
      "onlyforn=1,andageneralizationforn>1seemstoreducetoanon-trivial\n",
      "approximationproblem.Here,usingScheme1,weareabletoavoidthis\n",
      "cultybyreducingthenon-stronglycasetothestronglyconvexcase,forwhich\n",
      "alowerboundforageneralnisknown.Theprooffollowsthesamelinesof\n",
      "theproofofTheorem3.Givenanobliviousoptimizationalgorithmfor\n",
      "sumswithsmoothandconvexindividualsequippedwithoracles(13),weapply\n",
      "againScheme1togetanalgorithmforthesmoothandstronglyconvexcase,\n",
      "whoseiterationcomplexityisasin(16).Now,crucially,obliviousalgorithmare\n",
      "invariantunderScheme1(that8\n",
      "is,whenappliedonagivenobliviousalgorithm,Scheme1producesanother\n",
      "obliviousalgorithm).Therefore,using[3,Theorem2],weobtainthefollowing.\n",
      "Theorem4.Iftheiterationcomplexityofanobliviousoptimizationalgorithm\n",
      "forsmoothandconvexsumproblemsequippedwithaanda\n",
      "coordinate-descentoracleisoftheformofthel.h.s.of(16),thenitmustbeat\n",
      "least!rnL?n+.\n",
      "Thisboundistightandisobtainedby,e.g.,acceleratedSDCA[22].Optimal-\n",
      "ityintermsofLandcanbeobtainedsimplybyapplyingAccelerateGradient\n",
      "Descent[16],oralternatively,byusinganacceleratedversionofSVRGaspre-\n",
      "sentedin[17].Moregenerally,onecanapplyaccelerationschemes,e.g.,[13],\n",
      "togetanoptimaldependenceon.AcknowledgmentsWethankRaananTvizer\n",
      "andMaayanMaliachforseveralhelpfulandinsightfuldiscussions.\n",
      "10\n",
      "\n",
      "2References\n",
      "[1]AlekhAgarwal,MartinJWainwright,PeterLBartlett,andPradeepK\n",
      "Ravikumar.Informationtheoreticlowerboundsontheoraclecomplexityof\n",
      "convexoptimization.InAdvancesinNeuralInformationProcessingSystems,\n",
      "pages1?9,2009.[2]ZeyuanAllen-ZhuandYangYuan.Improvedsvrgfornon-\n",
      "strongly-convexorsum-of-nonconvexobjectives.Technicalreport,Technicalre-\n",
      "port,arXivpreprint,2016.[3]YossiArjevaniandOhadShamir.Dimension-free\n",
      "iterationcomplexityofsumoptimizationproblems.InAdvancesinNeural\n",
      "InformationProcessingSystems,pages3540?3548,2016.[4]YossiArjevaniand\n",
      "OhadShamir.Ontheiterationcomplexityofobliviousoptimization\n",
      "algorithms.InProceedingsofthe33ndInternationalConferenceonMachine\n",
      "Learning,pages908?916,2016.[5]YossiArjevaniandOhadShamir.Oracle\n",
      "complexityofsecond-ordermethodsforproblems.arXivpreprint\n",
      "arXiv:1611.04982,2016.[6]DimitriPBertsekas.Anewclassofincremen-\n",
      "talgradientmethodsforleastsquaresproblems.SIAMJournalonOptimiza-\n",
      "tion,7(4):913?926,1997.[7]AlbertoBiettiandJulienMairal.Stochasticopti-\n",
      "mizationwithvariancereductionfordatasetswithstructure.\n",
      "arXivpreprintarXiv:1610.00970,2016.[8]DoronBlatt,AlfredOHero,and\n",
      "HillelGauchman.Aconvergentincrementalgradientmethodwithaconstant\n",
      "stepsize.SIAMJournalonOptimization,18(1):29?51,2007.[9]ThomasM\n",
      "CoverandJoyAThomas.Elementsofinformationtheory.JohnWiley&Sons,\n",
      "2012.[10]AaronDefazio,FrancisBach,andSimonLacoste-Julien.Saga:A\n",
      "fastincrementalgradientmethodwithsupportfornon-stronglyconvexcompos-\n",
      "iteobjectives.InAdvancesinNeuralInformationProcessingSystems,pages\n",
      "1646?1654,2014.[11]RieJohnsonandTongZhang.Acceleratingstochastic\n",
      "gradientdescentusingpredictivevariancereduction.InAdvancesinNeural\n",
      "InformationProcessingSystems,pages315?323,2013.[12]GuanghuiLan.An\n",
      "optimalrandomizedincrementalgradientmethod.arXiv:1507.02000,2015.\n",
      "arXivpreprint\n",
      "[13]HongzhouLin,JulienMairal,andZaidHarchaoui.Auniversalcata-\n",
      "lystforoptimization.InAdvancesinNeuralInformationProcessing\n",
      "Systems,pages3366?3374,2015.9\n",
      "[14]Ga?lleLoosli,St?phaneCanu,andL?onBottou.Traininginvariant\n",
      "supportvectormachinesusingselectivesampling.Largescalekernelmachines,\n",
      "pages301?320,2007.[15]YuNesterov.ofcoordinatedescentmeth-\n",
      "odsonhuge-scaleoptimizationproblems.SIAMJournalonOptimization,\n",
      "22(2):341?362,2012.[16]YuriiNesterov.Introductorylecturesonconvexop-\n",
      "timization,volume87.SpringerScience&BusinessMedia,2004.[17]Atsushi\n",
      "Nitanda.Acceleratedstochasticgradientdescentforminimizingtesums.In\n",
      "IntelligenceandStatistics,pages195?203,2016.[18]MaximRagin-\n",
      "skyandAlexanderRakhlin.Information-basedcomplexity,feedbackanddy-\n",
      "namicsinconvexprogramming.InformationTheory,IEEETransactionson,\n",
      "57(10):7036?7056,2011.[19]MarkSchmidt,NicolasLeRoux,andFrancis\n",
      "Bach.Minimizingsumswiththestochasticaveragegradient.Mathe-\n",
      "maticalProgramming,pages1?30,2013.[20]ShaiShalev-Shwartz.Sdcawith-\n",
      "11\n",
      "\n",
      "outduality.arXivpreprintarXiv:1502.06177,2015.[21]ShaiShalev-Shwartz\n",
      "andTongZhang.Stochasticdualcoordinateascentmethodsforregularized\n",
      "loss.TheJournalofMachineLearningResearch,14(1):567?599,2013.[22]\n",
      "ShaiShalev-ShwartzandTongZhang.Acceleratedproximalstochasticdual\n",
      "coordinateascentforregularizedlossminimization.MathematicalProgram-\n",
      "ming,155(1-2):105?145,2016.[23]BlakeEWoodworthandNatiSrebro.Tight\n",
      "complexityboundsforoptimizingcompositeobjectives.InAdvancesinNeural\n",
      "InformationProcessingSystems,pages3639?3647,2016.\n",
      "10\n",
      "12\n",
      "\n",
      "PP4798.pdf\n",
      "PP4798.pdf 12\n",
      "Ensembleweightedkernelestimatorsfor\n",
      "multivariateentropyestimation\n",
      "Authoredby:\n",
      "AlfredO.Hero\n",
      "KumarSricharan\n",
      "Abstract\n",
      "Theproblemofestimationofentropyfunctionalsofprobabilityden-\n",
      "sitieshasreceivedmuchattentionintheinformationtheory,machine\n",
      "learningandstatisticscommunities.Kerneldensityplug-inestimators\n",
      "aresimple,easytoimplementandwidelyusedforestimationofentropy.\n",
      "However,kernelplug-inestimatorsfromthecurseofdimensionality,\n",
      "whereintheMSErateofconvergenceisglaciallyslow-oforder$O(T\n",
      "f\n",
      "-\n",
      "f\n",
      "gamma\n",
      "g\n",
      "/\n",
      "f\n",
      "d\n",
      "gg\n",
      ")$,where$T$isthenumberofsamples,and$gamma>0$\n",
      "isarateparameter.Inthispaper,itisshownthatforentlysmooth\n",
      "densities,anensembleofkernelplug-inestimatorscanbecombinedviaa\n",
      "weightedconvexcombination,suchthattheresultingweightedestimator\n",
      "hasasuperiorparametricMSErateofconvergenceoforder$O(T\n",
      "f\n",
      "-1\n",
      "g\n",
      ")$.\n",
      "Furthermore,itisshownthattheseoptimalweightscanbedetermined\n",
      "bysolvingaconvexoptimizationproblemwhichdoesnotrequiretrain-\n",
      "ingdataorknowledgeoftheunderlyingdensity,andthereforecanbe\n",
      "performedThisnovelresultisremarkableinthat,whileeachof\n",
      "theindividualkernelplug-inestimatorsbelongingtotheensemble\n",
      "fromthecurseofdimensionality,byappropriateensembleaveragingwe\n",
      "canachieveparametricconvergencerates.\n",
      "1PaperBody\n",
      "RNon-linearentropyfunctionalsofamultivariatedensityfoftheformg(f(x),\n",
      "x)f(x)dxariseinapplicationsincludingmachinelearning,signalprocessing,\n",
      "mathematicalstatistics,andstatisticalcommunicationtheory.Importantex-\n",
      "amplesofsuchfunctionalsincludeShannonandR?enyientropy.Entropybased\n",
      "applicationsincludeimageregistrationandtextureICA,anomaly\n",
      "detection,dataandimagecompression,testingofstatisticalmodelsandparam-\n",
      "eterestimation.Fordetailsandotherapplications,see,forexample,Beirlant\n",
      "etal.[2]andLeonenkoetal.[18].Intheseapplications,thefunctionalof\n",
      "interestmustbeestimatedempiricallyfromsamplerealizationsoftheunder-\n",
      "lyingdensities.Severalestimatorsofentropymeasureshavebeenproposedfor\n",
      "1\n",
      "\n",
      "generalmultivariatedensitiesf.Theseincludeconsistentestimatorsbasedon\n",
      "histograms[10,2],kerneldensityplug-inestimators,entropicgraphs[5,20],gap\n",
      "estimators[24]andnearestneighbordistances[8,18,19].Kerneldensityplug-in\n",
      "estimators[1,6,11,15,12]aresimple,easytoimplement,computationallyfast\n",
      "andthereforewidelyusedforestimationofentropy[2,23,14,4,13].However,\n",
      "theseestimatorsfrommeansquarederror(MSE)rateswhichtypically\n",
      "growwithfeaturedimensiondasO(T??/d),whereTisthenumberofsamples\n",
      "and?isapositiverateparameter.1\n",
      "Inthispaper,weproposeanovelweightedensemblekerneldensityplug-in\n",
      "estimator?w,thatachievesparametricMSEratesofO(T?1)whenthefeature\n",
      "densofentropyG?w=ityissmooth.Theestimatorisconstructedasaweighted\n",
      "convexcombinationGP??k(l)wrttheweightsl??lw(l)Gk(l)ofindividual\n",
      "kerneldensityplug-inestimatorsGp\n",
      "f\n",
      "w(l);l??l\n",
      "g\n",
      ".Here,?lisavectorofindices\n",
      "f\n",
      "l1,..,lL\n",
      "g\n",
      "andk(l)=lT/2isproportional?k(l).Theindividualkernel\n",
      "estimtothethevolumeofthekernelbinsusedinevaluatingG?k(l)aresimilar\n",
      "tothedata-splitkernelestimatorofandvanderMuelen[11],atorsG\n",
      "andhaveslowMSEratesofconvergenceoforderO(T?1/1+d).Pleaserefer\n",
      "toSection2for?k(l).theexactofGTheprincipalresultpresented\n",
      "inthispaperisasfollows.Itisshownthattheweights\n",
      "f\n",
      "w(l);l??l\n",
      "g\n",
      "canbe\n",
      "chosensoastotlyimprovetherateofMSEconvergence?w.Infact\n",
      "ourensembleaveragingmethodcanimproveMSEoftheweightedestimatorG\n",
      "?convergenceofGwtotheparametricrateO(T?1).Theseoptimalweights\n",
      "canbedeterminedbysolvingaconvexoptimizationproblem.Furthermore,this\n",
      "optimizationproblemdoesnotinvolveanydensity-dependentparametersand\n",
      "canthereforebeperformed1.1\n",
      "Relatedwork\n",
      "Ensemblebasedmethodshavebeenpreviouslyproposedinthecontextof\n",
      "Forexample,inbothboosting[21]andmultiplekernellearning\n",
      "[16]algorithms,lowercomplexityweaklearnersarecombinedtoproduceclassi-\n",
      "withhigheraccuracy.Ourworkfromthesemethodsinseveralways.\n",
      "Firstandforemost,ourproposedmethodperformsestimationratherthanclas-\n",
      "Animportantconsequenceofthisisthattheweightsweusearedata\n",
      "independent,whiletheweightsinboostingandmultiplekernellearningmust\n",
      "beestimatedfromtrainingdatasincetheydependontheunknowndistribu-\n",
      "tion.BirgeandMassart[3]showthatfordensityfinaHoldersmoothnessclass\n",
      "withsderivatives,theminimaxMSErateforestimationofasmoothfunctional\n",
      "isT?2?,where?=min\n",
      "f\n",
      "1/2,4s/(4s+d)\n",
      "g\n",
      ".Thismeansthatfors>4/d,\n",
      "parametricratesareachievable.Thekernelestimatorsproposedinthispaper\n",
      "requirehigherordersmoothnessconditionsonthedensity,i.e.thedensity\n",
      "mustbes>dtimesdrentiable.Whilethereexistotherestimators[17,7]\n",
      "thatachieveparametricMSEratesofO(1/T)whens>4/d,theseestimators\n",
      "aremoretoimplementthankerneldensityestimators,whichareasta-\n",
      "pleofmanytoolboxesinmachinelearning,patternrecognition,andstatistics.\n",
      "Theproposedensembleweightedestimatorisasimpleweightedcombinationof\n",
      "kerneldensityestimators.1.2\n",
      "Organization\n",
      "2\n",
      "\n",
      "Thereminderofthepaperisorganizedasfollows.Weformallydescribe\n",
      "thekernelplug-inentropyestimatorsforentropyestimationinSection2and\n",
      "discusstheMSEconvergencepropertiesoftheseestimators.Inparticular,we\n",
      "establishthattheseestimatorshaveMSEratewhichdecaysasO(T?1/1+d).\n",
      "Next,weproposetheweightedensembleofkernelentropyestimatorsinSection\n",
      "3.Subsequently,weprovideanMSE-optimalsetofweightsasthesolution\n",
      "toaconvexoptimization(3.4)andshowthattheresultantoptimallyweighted\n",
      "estimatorhasaMSEofO(T?1).WepresentsimulationresultsinSection4\n",
      "thatillustratethesuperiorperformanceofthisensembleentropyestimatorin\n",
      "thecontextof(i)estimationofthePanter-Ditedistortion-ratefactor[9]and\n",
      "(ii)testingtheprobabilitydistributionofarandomsample.Weconcludethe\n",
      "paperinSection5.NotationWewilluseboldfacetypetoindicaterandom\n",
      "variablesandrandomvectorsandregulartypefaceforconstants.Wedenote\n",
      "theexpectationoperatorbythesymbolE,thevarianceoperatorasV[X]=E[(X\n",
      "?E[X])2],andthebiasofanestimatorbyB.2\n",
      "2\n",
      "Entropyestimation\n",
      "Thispaperfocusesontheestimationofgeneralnon-linearfunctionalsG(f\n",
      ")ofd-dimensionalmultivariatedensitiesfwithknownsupportS=[a,b]d,\n",
      "whereG(f)hastheformZG(f)=g(f(x),x)f(x)d?(x),(2.1)forsomesmooth\n",
      "functiong(f,x).LetBdenotetheboundaryofS.Here,?denotestheLebesgue\n",
      "measureandEdenotesstatisticalexpectationwithrespecttothedensityf.\n",
      "AssumethatT=N+Mi.i.drealizationsoffeaturevectors\n",
      "f\n",
      "X1,...,XN,\n",
      "XN+1,...,XN+M\n",
      "g\n",
      "areavailablefromthedensityf.Inthesequelfwill\n",
      "becalledthefeaturedensity.2.1\n",
      "Plug-inestimatorsofentropy\n",
      "Atruncatedkerneldensityestimatorwithuniformkernelisbelow.\n",
      "Ourproposedweightedensemblemethodappliestoothertypesofkernelsas\n",
      "wellbutwespecializetouniformkernelsasitmakesthederivationsclearer.\n",
      "Forinteger1?k?M,denethedistancedktobe:dk=(k/M)1/d.\n",
      "thetruncatedkernelbinregionforeachX?StobeSk(X)=\n",
      "f\n",
      "YR?S:||X\n",
      "?Y||1?dk/2\n",
      "g\n",
      ",andthevolumeofthetruncatedkernelbinstobeVk(X)\n",
      "=Sk(X)dz.NotethatwhenthesmallestdistancefromXtoSisgreaterthan\n",
      "dk,Vk(X)=ddk=k/M.Letlk(X)denotesthenumberofpointsfalling\n",
      "inSk(X):Plk(X)=Mi=11\n",
      "f\n",
      "Xi?Sk(X)\n",
      "g\n",
      ".Thetruncatedkerneldensity\n",
      "estimatorisas?fk(X)=\n",
      "lk(X).MVk(X)\n",
      "(2.2)\n",
      "Theplug-inestimatorofthedensityfunctionalisconstructedusingadata\n",
      "splittingapproachasfollows.Thedataisrandomlysubdividedintotwoparts\n",
      "f\n",
      "X1,...,XN\n",
      "g\n",
      "and\n",
      "f\n",
      "XN+1,...,XN+M\n",
      "g\n",
      "ofNandMpoints\n",
      "respectively.Inthestage,weestimatethekerneldensityestimate?fkat\n",
      "theNpoints\n",
      "f\n",
      "X1,...,XN\n",
      "g\n",
      "usingtheMrealizations\n",
      "f\n",
      "XN+1,...,XN\n",
      "+M\n",
      "g\n",
      ".Subsequently,weusetheNsamples\n",
      "f\n",
      "X1,...,XN\n",
      "g\n",
      "toapproximate\n",
      "thefunctionalG(f)andobtaintheplug-inestimator:?kG\n",
      "=\n",
      "3\n",
      "\n",
      "N1X?g(fk(Xi),Xi).Ni=1\n",
      "(2.3)\n",
      "Alsoastandardkerneldensityestimatorwithuniformkernel?fk(X),\n",
      "whichisidenticalto?fk(X)exceptthatthevolumeVk(X)isalwayssettobe\n",
      "Vk(X)=k/M.?kG\n",
      "=\n",
      "N1X?g(fk(Xi),Xi).Ni=1\n",
      "(2.4)\n",
      "?kisidenticaltotheestimatorofandvanderMuelen[11].Observe\n",
      "TheestimatorG?k,unlikeG?k,doesnotrequireknowledgeaboutthe\n",
      "supportthattheimplementationofGofthedensity.2.1.1\n",
      "Assumptions\n",
      "Wemakeanumberoftechnicalassumptionsthatwillallowustoobtain\n",
      "tightMSEconvergenceratesforthekerneldensityestimatorsinabove.\n",
      "Theseassumptionsarecomparabletootherrigoroustreatmentsofentropyes-\n",
      "timation.PleaserefertoSectionII,[2]fordetails.(A.0):Assumethatthe\n",
      "kernelbandwidthk=k0M?foranyrateconstant0<?<1,andassume\n",
      "thatM,NandTarelinearlyrelatedthroughtheproportionalityconstant?f\n",
      "racwith:0<?frac<1,M=?fracTandN=(1??frac)T.(A.1):Letthe\n",
      "featuredensityfbeuniformlyboundedawayfrom0andupperboundedonthe\n",
      "setS,i.e.,thereexistconstants?0,??suchthat0<?0?f(x)???<??x?S.\n",
      "(A.2):Assumethatthedensityfhascontinuouspartialderivativesoforderdin\n",
      "theinteriorofthesetS,andthatthesederivativesareupperbounded.(A.3):\n",
      "Assumethatthe3\n",
      "functiong(f,x)hasmax\n",
      "f\n",
      "?,d\n",
      "g\n",
      "partialderivativesw.r.t.theargumentf,\n",
      "where?theconditions??>1.Denotethen-thpartialderivativeof\n",
      "g(f,x)wrtxbyg(n)(f,x).Also,letg?(f,x):=g(1)(f,x)andg??(f,x)\n",
      ":=g(2)(f,x).(A.4):Assumethattheabsolutevalueofthefunctionalg(f,x)\n",
      "anditspartialderivativesarestrictlyboundedawayfrom?intherange?0<x\n",
      "<??forally.(A.5):Let??(0,1)and??(2/3,1).LetC(M)beapositive\n",
      "functionsatisfyingtheconditionC(M)=O(exp(?M?(1??))).Forsome\n",
      "0<?<1,pl=(1??)?0andpu=(1+?)??.Assumethatthefollowing\n",
      "fourconditionsarebyh(f,x)=g(f,x),g(3)(f,x)andg(?)(f,x):\n",
      "(i)supx|h(0,x)|=G1<?,(ii)supf?(pl,pu),x|h(f,x)|=G2/4<?,(iii)\n",
      "supf?(1/k,pu),x|h(f,x)|C(M)=G3<?,and(iv)E[supf?(pl,2dM/k),x\n",
      "|h(f,x)|]C(M)=G4<?.2.1.2\n",
      "AnalysisofMSE\n",
      "Undertheseassumptions,wehaveshownthefollowing(pleasesee[22]for\n",
      "theproof):?k,G?kisgivenbyTheorem1.Thebiasoftheplug-inestimators\n",
      "G\n",
      "i/dXc2k1k?++o+B(Gk)=c1,iMkkMi?I1/d\n",
      "kc2k1?B(Gk)=c1.++o+MkkM?,G?isgivenbyTheorem2.\n",
      "Thevarianceoftheplug-inestimatorsGkk\n",
      "1111?k)=c4+c5+o+V(GNMMN\n",
      "1111?k)=c4V(G+c5+o.+NMMNIntheaboveexpressions,\n",
      "c1,i,c1,c2,c4andc5areconstantsthatdependonlyong,fandtheirpartial\n",
      "4\n",
      "\n",
      "derivatives,andI=\n",
      "f\n",
      "1,...,d\n",
      "g\n",
      ".Inparticular,theconstantsc1,i,c1,c2,c4\n",
      "andc5areindependentofk,NandM.2.1.3\n",
      "OptimalMSErate\n",
      "?kandG?ktobeunbiased.FromTheorem1,k??andk/M?0forthe\n",
      "estimatorsGLikewisefromTheorem2N??andM??forthevarianceofthe\n",
      "estimatortoconvergeto0.Wecanoptimizethechoiceofbandwidthk,and\n",
      "thedatasplittingproportionsN/(N+M),M/(N+M)forminimumM.S.E.\n",
      "MinimizingtheMSEoverkisequivalenttominimizingthebiasoverk.The\n",
      "optimalchoiceofkisgivenbykopt=O(M1/(1+d)),andthebiasevaluated\n",
      "atkoptisO(M?1/(1+d)).Also?kandG?kisdominatedbythesquared\n",
      "bias(O(M?2/(1+d)))asobservethattheMSEofGcontrastedtothevariance\n",
      "(O(1/N+1/M)).ThisimpliesthattheasymptoticMSErateofconvergence\n",
      "isinvarianttoselectedproportionalityconstant?frac.TheoptimalMSEfor?\n",
      "kandG?kisthereforeachievedforthechoiceofk=O(M1/(1+d)),andis\n",
      "theestimatorsG?2/(1+d)?kandG?khaveidenticaloptimalgivenbyO(T\n",
      ").Inparticular,observethatbothGratesofMSEconvergence.Ourgoalisto\n",
      "reducetheestimatorMSEtoO(T?1).Wedosobyapplyingthemethodof\n",
      "weightedensemblesdescribednextinsection3.\n",
      "3\n",
      "Ensembleestimators\n",
      "ForapositiveintegerL>d,choose?l?=\n",
      "f\n",
      "l1,...,lL\n",
      "g\n",
      "tobeavector\n",
      "ofdistinctpositiverealnumbers.themappingk(l)=lMandletk?=\n",
      "f\n",
      "k(l);l??l\n",
      "g\n",
      ".Observethatanyk?k?correspondstotherateconstant?=\n",
      "0.5,andthatN=?(T)andM=?(T).theweightedensembleestimator\n",
      "X?k(l).?w=w(l)G(3.1)Gl??l\n",
      "4\n",
      "Theorem3.Thereexistsaweightvectorw?suchthat?w??G(f))2]=\n",
      "O(1/T).E[(G\n",
      "Thisweightvectorcanbefoundbysolvingaconvexoptimization.Fur-\n",
      "thermore,thisoptimalweightvectordoesnotdependontheunknownfeature\n",
      "densityforthesamples\n",
      "f\n",
      "X1,..,XN+M\n",
      "g\n",
      ",andhencecanbesolved-line.P\n",
      "Proof.Foreachi?I,?w(i)=l??lw(l)li/d.Thebiasoftheensemble\n",
      "estimatorfollowsfromTheorem1andisgivenby\n",
      "X1?w]=B[Gc1,i?w(i)M?i/2d+O?.(3.2)Ti?I?k(l);l??l\n",
      "g\n",
      "by?L.\n",
      "Let??L=?LT.ObservethatbyDenotethecovariancematrixof\n",
      "f\n",
      "G?(2.5)\n",
      "andtheCauchy-Schwarzinequality,theentriesof?LareO(1).Thevarianceof\n",
      "the?wcanthenbeboundasfollows:weightedestimatorG????2X??\n",
      "k(l)?=w??Lw=w?Lw??max(?L)||w||2.?w]=V?wlGV[G\n",
      "(3.3)TT?l?l\n",
      "Weseekaweightvectorwthat(i)ensuresthatthebiasoftheweighted\n",
      "estimatorisO(T?1/2)and(ii)haslow?2norm||w||2inordertolimit\n",
      "thecontributionofthevarianceoftheweightedestimator.Tothisend,letw?\n",
      "bethesolutiontotheconvexoptimizationproblemminimize||w||2wX\n",
      "w(l)=1,subjectto(3.4)l??l\n",
      "|?w(i)|=0,i?I.Thisproblemisequivalenttominimizing||w||2\n",
      "subjecttoA0w=b,whereA0andbareedbelow.LetfIN:I?\n",
      "f\n",
      "1,..,\n",
      "5\n",
      "\n",
      "I\n",
      "g\n",
      "beabijectivemapping.Leta0bethevectorofi/di/dones:[1,1...,1]1?L\n",
      ";andletafIN(i),fori?IbegivenbyafIN(i)=[l1,..,lL].A0=\n",
      "[a?0,a?1,...,a?I]?,A1=[a?1,...,a?I]andb=[1;0;0;..;0](I+1)?1.\n",
      "Observethattheentries?ofA0andbareO(1),andtherefore?theentriesof\n",
      "thesolutionwareO(1).Consequently,?by(3.2),thebiasB[pGw?]=O(1/\n",
      "T).Furthermore,theoptimalminimum?(d):=||w?||2?w?]isofis\n",
      "givenby?(d)=det(A1A?1)/det(A0A?0).By(6.4),theestimatorvariance\n",
      "V[GorderO(?(d)/T).Thisconcludestheproof.\n",
      "Whilewehaveillustratedtheweightedensemblemethodonlyinthecontext\n",
      "ofkernelestimators,thismethodcanbeappliedtoanygeneralensembleof\n",
      "estimatorsthatsatisfybiasandvarianceconditionsC.1andC.2in[22].\n",
      "4\n",
      "Experiments\n",
      "Weillustratethesuperiorperformanceoftheproposedweightedensemble\n",
      "estimatorfortwoapplications:(i)estimationofthePanter-Diteratedistortion\n",
      "factor,and(ii)estimationofentropytotestforrandomnessofarandomsample.\n",
      "4.1\n",
      "Panter-Ditefactorestimation\n",
      "Forad-dimensionalsourcewithunderlyingdensityf,thePanter-Dite\n",
      "distortion-ratedistortion-ratefunction[9]forRaq-dimensionalvectorquan-\n",
      "tizerwithnlevelsofquantizationisgivenby?(n)=n?2/qfq/(q+2)(x)dx.\n",
      "ThePanter-Ditefactorcorrespondstothe5\n",
      "0\n",
      "10\n",
      "?1\n",
      "Meansquarederror\n",
      "10\n",
      "?2\n",
      "10\n",
      "Standardkernelplug?inestimator[12]Truncatedkernelplug?inestimator\n",
      "(2.3)Histogramplug?inestimator[11]k?nearestneighborestimator[19]En-\n",
      "tropicgraphestimator[6,21]Weightedkernelestimator(3.1)\n",
      "?3\n",
      "10\n",
      "?4\n",
      "10\n",
      "3\n",
      "4\n",
      "10\n",
      "10\n",
      "SamplesizeT\n",
      "(a)VariationofMSEofPanter-Ditefactorestimatesasafunctionofsample\n",
      "sizeT.Fromtheweseethattheproposedweightedestimatorhasthe\n",
      "fastestMSErateofconvergencewrtsamplesizeT.0\n",
      "10\n",
      "?1\n",
      "6\n",
      "\n",
      "Meansquarederror\n",
      "10\n",
      "?2\n",
      "10\n",
      "Standardkernelplug?inestimator[12]Truncatedkernelplug?inestimator\n",
      "(2.3)Histogramplug?inestimator[11]k?nearestneighborestimator[19]En-\n",
      "tropicgraphestimator[6,21]Weightedkernelestimator(3.1)\n",
      "?3\n",
      "10\n",
      "?4\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "56dimensiond\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(b)VariationofMSEofPanter-Ditefactorestimatesasafunctionofdi-\n",
      "mensiond.FromtheweseethattheMSEoftheproposedweighted\n",
      "estimatorhastheslowestrateofgrowthwithincreasingdimensiond.\n",
      "Figure1:VariationofMSEofPanter-Ditefactorestimatesusingstandard\n",
      "kernelplug-inestimator[12],truncatedkernelplug-inestimator(2.3),histogram\n",
      "plug-inestimator[11],k-NNestimator[19],entropicgraphestimator[6,21]and\n",
      "theweightedensembleestimator(3.1).functionalG(f)withg(f,x)=n?2/qf\n",
      "?2/(q+2)I(f>0)+I(f=0),whereI(.)istheindicatorfunction.ThePanter-\n",
      "DitefactorisdirectlyrelatedtotheR?enyi?-entropy,forwhichseveralother\n",
      "estimatorshavebeenproposed.Inoursimulationswecomparesixt\n",
      "choicesoffunctionalestimators-thethree?k,(ii)theestimatorspreviously\n",
      "introduced:(i)thestandardkernelplug-inestimatorG??boundarytruncated\n",
      "plug-inestimatorGkand(iii)theweightedestimatorGwwithoptimalweightw\n",
      "=w?givenby(3.4),andinadditionthefollowingpopularentropyestimators:\n",
      "(iv)histogramplug-inestimator[10],(v)k-nearestneighbor(k-NN)entropy\n",
      "estimator[18]and?kandG?k,weselectthebandwidth(vi)entropick-NN\n",
      "graphestimator[5,20].ForbothGparameterkasafunctionofMaccording\n",
      "totheoptimalproportionalityk=M1/(1+d)andN=M=T/2.Toillustrate\n",
      "theweightedestimatorofthePanter-Ditefactorweassumethatfisthed=\n",
      "6dimensionalmixturedensityf(a,b,p,d)=pf?(a,b,d)+(1?p)fu(d);\n",
      "wheref?(a,b,d)isad-dimensionalBetadensitywithparametersa=6,b=\n",
      "6,fu(d)isad-dimensionaluniformdensityandthemixingratiopis0.8.4.1.1\n",
      "VariationofMSEwithsamplesizeT\n",
      "TheMSEresultsofthesetestimatorsareshowninFig.1(a)asa\n",
      "functionofsample?whastlysizeT.Itisclearfromthethat\n",
      "theproposedensembleestimatorG6\n",
      "7\n",
      "\n",
      "100\n",
      "1\n",
      "0.5\n",
      "HypothesisindexTrueentropyStandardkernelplug?inestimateTruncated\n",
      "kernelplug?inestimateWeightedplug?inestimate\n",
      "50\n",
      "0?1\n",
      "0\n",
      "?0.9\n",
      "?0.8?0.7?0.6?0.5Standardkernelplug?inestimate\n",
      "?0.4\n",
      "?0.3\n",
      "100?0.5\n",
      "Standardkernelplug?inestimate50\n",
      "?1\n",
      "?1.5\n",
      "Truncatedkernelplug?inestimate\n",
      "0?1.4\n",
      "?2\n",
      "?2.50\n",
      "?1.35\n",
      "?1.3\n",
      "?1.25?1.2?1.15?1.1Truncatedkernelplug?inestimate\n",
      "?1.05\n",
      "?1\n",
      "?0.95\n",
      "?1.4\n",
      "?1.3\n",
      "100\n",
      "Weightedplug?inestimate\n",
      "50\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "0?2.3\n",
      "1000\n",
      "?2.2\n",
      "?2.1\n",
      "?2\n",
      "?1.9?1.8?1.7Weightedestimate\n",
      "8\n",
      "\n",
      "?1.6\n",
      "?1.5\n",
      "(a)Entropyestimatesforrandomsamplescor-(b)Histogramenvelopesof\n",
      "entropyestimatesrespondingtohypothesisH0andH1.forrandomsamples\n",
      "correspondingtohypothesisH0(blue)andH1(red).\n",
      "Figure2:Entropyestimatesusingstandardkernelplug-inestimator,trun-\n",
      "catedkernelpluginestimatorandtheweightedestimator,forrandomsamples\n",
      "correspondingtohypothesisH0andH1.Theweightedestimatorprovided\n",
      "betterdiscriminationabilitybysuppressingthebias,atthecostofsomead-\n",
      "ditionalvariance.fasterrateofconvergencewhiletheMSEoftherestofthe\n",
      "estimators,includingthetruncatedkernelplug-inestimator,havesimilar,slow\n",
      "ratesofconvergence.Itisthereforeclearthattheproposedoptimalensemble\n",
      "averagingtlyacceleratestheMSEconvergencerate.4.1.2\n",
      "VariationofMSEwithdimensiond\n",
      "TheMSEresultsofthesederentestimatorsareshowninFig.1(b)asa\n",
      "functionofdimensiond,forsamplesizeT=3000.Forthestandardkernel\n",
      "plug-inestimatorandtruncatedkernelplug-inestimator,theMSEvariesexpo-\n",
      "nentiallywithdasexpected.TheMSEofthehistogramandk-NNestimators\n",
      "increaseatasimilarrate,indicatingthattheseestimatorsfromthecurse\n",
      "ofdimensionalityaswell.TheMSEoftheweightedestimatorontheother\n",
      "handincreasesataslowerrate,whichisinagreementwithourtheorythatthe\n",
      "MSEisO(?(d)/T)andobservingthat?(d)isanincreasingfunctionofd.Also\n",
      "observethattheMSEoftheweightedestimatoristlysmallerthanthe\n",
      "MSEoftheotherestimatorsforalldimensionsd>3.4.2\n",
      "Distributiontesting\n",
      "Inthissection,Shannontialentropyisestimatedusingthefunction\n",
      "g(f,x)=?log(f)I(f>0)+I(f=0)andusedasateststatistictotestfor\n",
      "theunderlyingprobabilitydistributionofarandomsample.Inparticular,we\n",
      "draw500instanceseachofrandomsamplesofsize103fromtheprobability\n",
      "distributionf(a,b,p,d),describedinSec.4.1,withd=6,p=\n",
      "0.75fortwosetsofvaluesofa,bunderthenullandalternatehypothesis,H0\n",
      ":a=a0,b=b0versusH1:a=a1,b=b1.First,wea0=b0\n",
      "=6anda1=b1=5.Wenotethattheunderlyingdensityunderthenull\n",
      "hypothesisf(6,6,0.75,6)hasgreatercurvaturerelativetof(5,5,0.75,6)and\n",
      "therefore?k,G?khassmallerentropy(randomness).Thetrueentropy,and\n",
      "entropyestimatesusingG?wforthecasescorrespondingtoeachofthe500\n",
      "instancesofhypothesisH0andH1andGareshowninFig.2(a).Fromthis\n",
      "itisapparentthattheweightedestimatorprovidesbetterdiscrimination\n",
      "abilitybysuppressingthebias,atthecostofsomeadditionalvariance.To\n",
      "demonstratethattheweightedestimatorprovidesbetterdiscrimination,weplot\n",
      "thehistogramenvelopeoftheentropyestimatesusingstandardkernelplug-in\n",
      "estimator,truncatedkernelplug-inestimatorandtheweightedestimatorforthe\n",
      "casescorrespondingtothehypothesisH0(colorcodedblue)andH1(colorcoded\n",
      "red)inFig.2(b).Furthermore,wequantitativelymeasurethediscriminative\n",
      "abilityofthetestimatorsusingthepstatisticds=|?1??0\n",
      "|/?02+?12,where?0and?0(respectively?1and?1)are7\n",
      "9\n",
      "\n",
      "1\n",
      "1\n",
      "0.95\n",
      "AreaunderROCcurve\n",
      "FalseNegativerate\n",
      "0.90.850.80.750.70.650.6\n",
      "0.5\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.20.250.30.35FalsePositiverate\n",
      "0.4\n",
      "0.45\n",
      "0.8\n",
      "0.7\n",
      "0.6\n",
      "Standardkernelplug?inestimatorTruncatedkernelplug?inestimatorWeighted\n",
      "estimator\n",
      "0.55\n",
      "0.9\n",
      "0.5\n",
      "0.5\n",
      "(a)ROCcurvescorrespondingtoentropyestimatesobtainedusingstan-\n",
      "dardandtruncatedkernelplug-inestimatorandtheweightedestimator.The\n",
      "correspondingAUCaregivenby0.9271,0.9459and0.9619.\n",
      "Neyman?PearsontestStandardkernelplug?inestimateTruncatedkernel\n",
      "plug?inestimateWeightedestimate\n",
      "0.2\n",
      "0.4\n",
      "?\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "(b)VariationofAUCcurvesvs?(=a0?a1,b0?b1)corresponding\n",
      "toNeyman-Pearsonomniscienttest,entropyestimatesusingthestandardand\n",
      "truncatedkernelplug-inestimatorandtheweightedestimator.\n",
      "Figure3:ComparisonofperformanceintermsofROCforthedistribution\n",
      "testingproblem.Theweightedestimatoruniformlyoutperformstheindividual\n",
      "plug-inestimators.thesamplemeanandstandarddeviationoftheentropy\n",
      "estimates.Thestatisticwasfoundtobe1.49,1.60and1.89for\n",
      "thestandardkernelplug-inestimator,truncatedkernelplug-inestimatorand\n",
      "theweightedestimatorrespectively.Thereceiveroperatingcurves(ROC)for\n",
      "thistestusingthesethreedierentestimatorsisshowninFig.3(a).The\n",
      "correspondingareaundertheROCcurves(AUC)aregivenby0.9271,0.9459\n",
      "and0.9619.Inourexperiment,wea0=b0=10andseta1=b1=10?\n",
      "?,draw500instanceseachofrandomsamplesofsize5?103underthenulland\n",
      "10\n",
      "\n",
      "alternatehypothesis,andplottheAUCas?variesfrom0to1inFig.3(b).For\n",
      "comparison,wealsoplottheAUCfortheNeyman-Pearsonlikelihoodratiotest.\n",
      "TheNeyman-Pearsonlikelihoodratiotest,unliketheShannonentropybased\n",
      "tests,isanomniscienttestthatassumesknowledgeofboththeunderlyingbeta-\n",
      "uniformmixtureparametricmodelofthedensityandtheparametervaluesa0\n",
      ",b0anda1,b1underthenullandalternatehypothesisrespectively.Figure4\n",
      "showsthattheweightedestimatoruniformlyandtlyoutperformsthe\n",
      "individualplug-inestimatorsandisclosesttotheperformanceoftheomniscient\n",
      "Neyman-Pearsonlikelihoodtest.Therelativelysuperiorperformanceofthe\n",
      "Neyman-Pearsonlikelihoodtestisduetothefactthattheweightedestimator\n",
      "isanonparametricestimatorthathasmarginallyhighervariance(proportional\n",
      "to||w?||22)comparedtotheunderlyingparametricmodelforwhich\n",
      "theNeyman-Pearsonteststatisticprovidesthemostpowerfultest.\n",
      "5\n",
      "Conclusions\n",
      "Anovelmethodofweightedensembleestimationwasproposedinthispa-\n",
      "per.Thismethodcombinesslowlyconvergingindividualestimatorstoproduce\n",
      "anewestimatorwithfasterMSErateofconvergence.Inthispaper,weapplied\n",
      "weightedensemblestoimprovetheMSEofasetofuniformkerneldensityes-\n",
      "timatorswithtkernelwidthparameters.Weshowedbytheoryandin\n",
      "simulationthatthattheimprovedensembleestimatorachievesparametricMSE\n",
      "convergencerateO(T?1).Theoptimalweightsaredeterminedbysolvinga\n",
      "convexoptimizationproblemwhichdoesnotrequiretrainingdataandcanbe\n",
      "performedine.Thesuperiorperformanceoftheweightedensembleentropy\n",
      "estimatorwasvinthecontextoftwoimportantproblems:(i)estimation\n",
      "ofthePanter-Ditefactorand(ii)non-parametrichypothesistesting.Acknowl-\n",
      "edgmentsThisworkwaspartiallysupportedbyAROgrantW911NF-12-1-0443.\n",
      "8\n",
      "2References\n",
      "[1]I.AhmadandPi-ErhLin.Anonparametricestimationoftheentropyforab-\n",
      "solutelycontinuousdistributions(corresp.).InformationTheory,IEEETrans.\n",
      "on,22(3):372?375,May1976.[2]J.Beirlant,EJDudewicz,L.Gy?and\n",
      "ECVanderMeulen.Nonparametricentropyestimation:Anoverview.Intl.\n",
      "JournalofMathematicalandStatisticalSciences,6:17?40,1997.[3]L.Birge\n",
      "andP.Massart.Estimationofintegralfunctionsofadensity.TheAnnalsof\n",
      "Statistics,23(1):11?29,1995.[4]D.ChauveauandP.Vandekerkhove.Selection\n",
      "ofaMCMCsimulationstrategyviaanentropyconvergencecriterion.ArXiv\n",
      "Mathematicse-prints,May2006.[5]J.A.CostaandA.O.Hero.Geodesicen-\n",
      "tropicgraphsfordimensionandentropyestimationinmanifoldlearning.Signal\n",
      "Processing,IEEETransactionson,52(8):2210?2221,2004.[6]P.B.Eggermont\n",
      "andV.N.LaRiccia.Bestasymptoticnormalityofthekerneldensityentropyes-\n",
      "timatorforsmoothdensities.InformationTheory,IEEETrans.on,45(4):1321\n",
      "?1326,May1999.[7]E.Gin?eandD.M.Mason.Uniforminbandwidthesti-\n",
      "11\n",
      "\n",
      "mationofintegralfunctionalsofthedensityfunction.ScandinavianJournalof\n",
      "Statistics,35:739761,2008.[8]M.Goria,N.Leonenko,V.Mergel,andP.L.\n",
      "NoviInverardi.Anewclassofrandomvectorentropyestimatorsanditsappli-\n",
      "cationsintestingstatisticalhypotheses.NonparametricStatistics,2004.[9]R.\n",
      "Gupta.QuantizationStrategiesforLow-PowerCommunications.PhDthesis,\n",
      "UniversityofMichigan,AnnArbor,2001.[10]L.Gy?andE.C.vander\n",
      "Meulen.Density-freeconvergencepropertiesofvariousestimatorsofentropy.\n",
      "Comput.Statist.DataAnal.,pages425?436,1987.[11]L.Gy?andE.\n",
      "C.vanderMeulen.Anentropyestimatebasedonakerneldensityestimation.\n",
      "LimitTheoremsinProbabilityandStatistics,pages229?240,1989.[12]P.Hall\n",
      "andS.C.Morton.Ontheestimationoftheentropy.Ann.Inst.Statist.Meth.,\n",
      "45:69?88,1993.[13]K.Hlav?a?ckov?a-Schindler,M.Palu?s,M.Vejmelka,\n",
      "andJ.Bhattacharya.Causalitydetectionbasedoninformation-theoreticap-\n",
      "proachesintimeseriesanalysis.PhysicsReports,441(1):1?46,2007.[14]\n",
      "A.T.Ihler,J.W.FisherIII,andA.S.Willsky.Nonparametricestimatorsfor\n",
      "onlinesignatureauthentication.InAcoustics,Speech,andSignalProcessing,\n",
      "2001.Proceedings.(ICASSP?01).2001IEEEInternationalConferenceon,vol-\n",
      "ume6,pages3473?3476.IEEE,2001.[15]H.Joe.Estimationofentropy\n",
      "andotherfunctionalsofamultivariatedensity.AnnalsoftheInstituteofSta-\n",
      "tisticalMathematics,41(4):683?697,1989.[16]G.Lanckriet,N.Cristianini,\n",
      "P.Bartlett,andL.ElGhaoui.Learningthekernelmatrixwith\n",
      "programming.JournalofMachineLearningResearch,5:2004,2002.[17]B.\n",
      "Laurent.testimationofintegralfunctionalsofadensity.TheAnnals\n",
      "ofStatistics,24(2):659?681,1996.[18]N.Leonenko,L.Prozanto,andV.Sa-\n",
      "vani.AclassofR?enyiinformationestimatorsformultidimensionaldensities.\n",
      "AnnalsofStatistics,36:2153?2182,2008.[19]E.Liiti?ainen,A.Lendasse,and\n",
      "F.Corona.Onthestatisticalestimationofr?enyientropies.InProceedings\n",
      "ofIEEE/MLSP2009InternationalWorkshoponMachineLearningforSignal\n",
      "Processing,Grenoble(France),September2-42009.[20]D.Pal,B.Poczos,and\n",
      "C.Szepesvari.EstimationofR?enyientropyandmutualinformationbasedon\n",
      "generalizednearest-neighborgraphs.InProc.AdvancesinNeuralInformation\n",
      "ProcessingSystems(NIPS).MITPress,2010.[21]RobertE.Schapire.The\n",
      "strengthofweaklearnability.MachineLearning,5(2):197?227?227,June1990.\n",
      "[22]K.SricharanandA.O.Hero,III.Ensembleestimatorsformultivariateen-\n",
      "tropyestimation.ArXive-prints,March2012.[23]C.Studholme,C.Drapaca,\n",
      "B.Iordanova,andV.Cardenas.Deformation-basedmappingofvolumechange\n",
      "fromserialbrainmriinthepresenceoflocaltissuecontrastchange.Medical\n",
      "Imaging,IEEETransactionson,25(5):626?639,2006.[24]B.vanEs.Esti-\n",
      "matingfunctionalsrelatedtoadensitybyclassofstatisticsbasedonspacing.\n",
      "ScandinavianJournalofStatistics,1992.\n",
      "9\n",
      "12\n",
      "\n",
      "PP5492.pdf\n",
      "PP5492.pdf 14\n",
      "FromMAPtoMarginals:VariationalInferencein\n",
      "BayesianSubmodularModels\n",
      "Authoredby:\n",
      "AndreasKrause\n",
      "JosipDjolonga\n",
      "Abstract\n",
      "Submodularoptimizationhasfoundmanyapplicationsinmachine\n",
      "learningandbeyond.Wecarryoutthesystematicinvestigationof\n",
      "inferenceinprobabilisticmodelsthroughsubmodularfunctions,\n",
      "generalizingregularpairwiseMRFsandDeterminantalPointProcesses.\n",
      "Inparticular,wepresentL-Field,avariationalapproachtogenerallog-\n",
      "submodularandlog-supermodulardistributionsbasedonsub-andsuper-\n",
      "gradients.Weobtainbothlowerandupperboundsonthelog-partition\n",
      "function,whichenablesustocomputeprobabilityintervalsformarginals,\n",
      "conditionalsandmarginallikelihoods.Wealsoobtainfullyfactorized\n",
      "approximateposteriors,atthesamecomputationalcostasordinarysub-\n",
      "modularoptimization.Ourframeworkresultsinconvexproblemsforop-\n",
      "timizingovertialsofsubmodularfunctions,whichweshowhowto\n",
      "optimallysolve.Weprovidetheoreticalguaranteesoftheapproximation\n",
      "qualitywithrespecttothecurvatureofthefunction.Wefurtherestab-\n",
      "lishnaturalrelationsbetweenourvariationalapproachandtheclassical\n",
      "method.Lastly,weempiricallydemonstratetheaccuracyof\n",
      "ourinferenceschemeonseveralsubmodularmodels.\n",
      "1PaperBody\n",
      "Submodularfunctions[1]arearichclassofsetfunctionsF:2V?R,investi-\n",
      "gatedoriginallyingametheoryandcombinatorialoptimization.Theycapture\n",
      "naturalnotionssuchasdiminishingreturnsandeconomiesofscale.Inre-\n",
      "centyears,submodularoptimizationhasseenmanyimportantapplicationsin\n",
      "machinelearning,includingactivelearning[2],recommendersystems[3],doc-\n",
      "umentsummarization[4],representationlearning[5],clustering[6],thedesign\n",
      "ofstructurednorms[7]etc.Inthiswork,insteadofusingsubmodularfunctions\n",
      "toobtainpointestimatesthroughoptimization,wetakeaBayesianapproach\n",
      "andprobabilisticmodelsoversets(socalledpointprocesses)usingsub-\n",
      "modularfunctions.Manyoftheaforementionedapplicationscanbeunderstood\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asperformingMAPinferenceinsuchmodels.WedevelopL-FIELD,agen-\n",
      "eralvariationalinferenceschemeforreasoningaboutlog-supermodular(P(A)\n",
      "?exp(?F(A)))andlog-submodular(P(A)?exp(F(A)))distributions,whereF\n",
      "isasubmodularsetfunction.Previouswork.Therehasbeenextensiveworkon\n",
      "submodularoptimization(bothapproximateandexactminimizationandmax-\n",
      "imization,see,e.g.,[8,9,10,11]).Incontrast,weareunawareofpreviouswork\n",
      "thataddressesthegeneralproblemofprobabilisticinferenceinBayesiansub-\n",
      "modularmodels.Therearetwoimportantspecialcasesthathavereceivedsig-\n",
      "tinterest.ThemostprominentexamplesareundirectedpairwiseMarkov\n",
      "RandomFields(MRFs)withbinaryvariables,alsocalledtheIsingmodel[12],\n",
      "duetotheirimportanceinstatisticalphysics,andapplications,e.g.,incom-\n",
      "putervision.WhileMAPinferenceisntforregular(log-supermodular)\n",
      "MRFs,computingthepartitionfunctionisknowntobe#P-hard[13],andthe\n",
      "approximationproblemhasbeenalsoshowntobehard[14].Also,thereisno\n",
      "FPRASinthelog-submodularcaseunlessRP=NP[13].Animportantcaseof\n",
      "log-submodulardistributionsistheDeterminantalPointProcess(DPP),used1\n",
      "inmachinelearningasaprincipledwayofmodelingdiversity.Itspartition\n",
      "functioncanbecomputedtly,anda41-approximationschemefor\n",
      "the(NP-hard)MAP[15]isknown.Inthispaper,weproposeavariationalinfer-\n",
      "enceschemeforgeneralBayesiansubmodularmodels,thatencompassesthese\n",
      "twoandmanyotherdistributions,andhasinstance-dependentqualityguar-\n",
      "antees.Ahallmarkofthemodelsisthattheycapturehigh-orderinteractions\n",
      "betweenmanyrandomvariables.Existingvariationalapproaches[16]cannot\n",
      "tlycopewithsuchhigh-orderinteractions?theygenerallyhavetosum\n",
      "overallvariablesinafactor,scalingexponentiallyinthesizeofthefactor.We\n",
      "discussthisprototypicallyforinSec.5.Ourcontributions.Insum-\n",
      "mary,ourmaincontributionsare?Weprovidethegeneraltreatmentof\n",
      "probabilisticinferencewithlog-submodularandlog-supermodulardistributions,\n",
      "thatcancapturehigh-ordervariableinteractions.?WedevelopL-FIELD,a\n",
      "novelvariationalinferenceschemethatoptimizesoversub-andsupergradients\n",
      "ofsubmodularfunctions.Ourschemeyieldsbothupperandlowerboundson\n",
      "thepartitionfunction,whichimplyrigorousprobabilityintervalsformarginals.\n",
      "Wecanalsoobtainfactorialapproximationsofthedistributionatnolarger\n",
      "computationalcostthanperformingMAPinferenceinthemodel(forwhicha\n",
      "plethoraofalgorithmsareavailable).?Weidentifyanaturallinkbetween\n",
      "ourschemeandthewell-knownmethod.?Weestablishtheoretical\n",
      "guaranteesabouttheaccuracyofourbounds,dependentonthecurvatureof\n",
      "theunderlyingsubmodularfunction.?WedemonstratetheaccuracyofL-F\n",
      "IELDonseveralBayesiansubmodularmodels.\n",
      "2\n",
      "Submodularfunctionsandoptimization\n",
      "Submodularfunctionsaresetfunctionssatisfyingadiminishingreturnscon-\n",
      "dition.Formally,letVbesomegroundset,w.l.o.g.V=\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      ",\n",
      "andconsiderasetfunctionF:2V?R.Themarginalgainofaddingitemi?V\n",
      "tothesetA?Vw.r.t.FisdenedasF(i|A)=F(A?\n",
      "f\n",
      "i\n",
      "g\n",
      ")?F(A).Then,a\n",
      "functionF:2V?RissaidtobesubmodularifforallA?B?Vandi?V?\n",
      "2\n",
      "\n",
      "BitholdsthatF(i|A)?F(i|B).AfunctionFiscalledsupermodularif?F\n",
      "issubmodular.Withoutlossofgenerality1,wewillalsomaketheassumption\n",
      "thatFisnormalizedsothatF(?)=0.Theproblemofsubmodularfunctionop-\n",
      "timizationhasreceivedtattention.The(unconstrained)minimization\n",
      "ofsubmodularfunctions,minAF(A),canbedoneinpolynomialtime.While\n",
      "generalpurposealgorithms[8]canbeimpracticalduetotheirhighorder,several\n",
      "classesoffunctionsadmitfaster,specializedalgorithms,e.g.[17,18,19].Many\n",
      "importantproblemscanbecastastheminimizationofasubmodularobjective,\n",
      "rangingfromimagesegmentation[20,12]toclustering[6].Submodularmaxi-\n",
      "mizationhasalsofoundnumerousapplications,e.g.experimentaldesign[21],\n",
      "documentsummarization[4]orrepresentationlearning[5].Whilethisproblem\n",
      "isingeneralNP-hard,econstant-factorapproximationalgorithmsexist\n",
      "(e.g.[22,11]).Inthispaperweliftresultsfromsubmodularoptimizationto\n",
      "probabilisticinference,whichletsusquantifyuncertaintyaboutthesolutions\n",
      "oftheproblem,insteadofbindingustoasingleone.Ourapproachallowsusto\n",
      "obtain(approximate)marginalsatthesamecostastraditionalMAPinference.\n",
      "3\n",
      "ProbabilisticinferenceinBayesiansubmodularmodels\n",
      "WhichBayesianmodelsareassociatedwithsubmodularfunctions?Sup-\n",
      "poseF:2V?Risasubmodularsetfunction.Weconsiderdistributionsover\n",
      "subsets2A?VoftheformP(A)=Z1e+F(A)andP(A)=Z1e?F(A),\n",
      "whichwecalllog-submodularandlog-supermodular,respectively.TheP?F\n",
      "(S)normalizingquantityZ=iscalledthepartitionfunction,and?logZis\n",
      "alsoS?Veknownasfreeenergyinthestatisticalphysicsliterature.Notethat\n",
      "distributionsoversubsetsofVareisomorphictodistributionsof|V|=n\n",
      "binaryrandomvariablesX1,...,Xn?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "?wesimplyidentifyXias\n",
      "theindicatorfunctionoftheeventi?A,orformallyXi=[i?A].Examples\n",
      "oflog-supermodulardistributions.Therearemanydistributionsthatthis\n",
      "framework.Asaprominentexample,considerbinarypairwiseMarkovrandom\n",
      "(MRFs),12\n",
      "ThefunctionsF(A)andF(A)+cencodethesamedistributionsbyvirtue\n",
      "ofnormalization.Intheappendixwealsoconsidercardinalityconstraints,i.e.,\n",
      "distributionsoversetsAthatsatisfy|A|?k.\n",
      "2\n",
      "QP(X1,...,Xn)=Z1i,j?i,j(Xi,Xj).Assumingthepotentials\n",
      "?i,jarepositive,suchMRFsPareequivalenttodistributionsP(A)?exp(?F\n",
      "(A)),whereF(A)=i,jFi,j(A),andFi,j(A)=?log?i,j([i?A],[j?A]).\n",
      "AnMRFiscalledregulareachFi,jissubmodular(andconsequentlyP(A)\n",
      "islog-supermodular).Suchmodelsareextensivelyusedinapplications,e.g.in\n",
      "computervision[12].Moregenerally,arichclassofdistributionscanbe\n",
      "usingdecomposablesubmodularfunctions,whichcanbewrittenassumsof\n",
      "(usuallysimpler)submodularfunctions.Asanexample,letG1,...,Gk?V\n",
      "begroupsofelementsandlet?1,...,?k:[0,?)?RbePkconcave.Then,the\n",
      "functionF(A)=i=1?i(|Gi?A|)issubmodular.Modelsusingthesetypes\n",
      "offunctionsstrictlygeneralizepairwiseMRFs,andcancapturehigher-order\n",
      "variableinteractions,whichcanbecrucialincomputervisionapplicationssuch\n",
      "3\n",
      "\n",
      "assemanticsegmentation(e.g.[23]).Examplesoflog-submodulardistributions.\n",
      "Aprominentexampleoflog-submodulardistributionsareDeterminantalPoint\n",
      "Processes(DPPs)[24].ADPPisadistributionoversetsAoftheformP(A)\n",
      "=Z1exp(F(A)),whereF(A)=log|KA|.Here,K?RV?Visapositive\n",
      "matrix,KAisthesquaresubmatrixindexedbyA,and|?|\n",
      "denotesthedeterminant.BecauseKispositiveF(A)isknownto\n",
      "besubmodular,andhenceDPPsarelog-submodular.Anothernaturalmodel\n",
      "isthatoffacilitylocation.AssumethatwehaveasetoflocationsVwhere\n",
      "wecanopenshops,andasetNofcustomersthatwewouldliketoserve.For\n",
      "eachcustomeri?Nandlocationj?Vwehaveanon-negativePnumberCi,j\n",
      "quantifyinghowmuchserviceigetsfromlocationj.Then,weconsiderF(A)\n",
      "=i?Nmaxj?ACi,j.Wecanalsopenalizethenumberofopenshopsanduse\n",
      "adistributionP(A)?exp(F(A)??|A|)for?>0.Suchobjectiveshave\n",
      "beenusedforoptimizationinmanyapplications,rangingfromclustering[25]\n",
      "torecommendersystems[26].TheInferenceChallenge.Havingintroducedthe\n",
      "modelsthatweconsider,wenowshowhowtodoinferenceinthem3.Let\n",
      "usintroducethefollowingoperationsthatpreservesubmodularity.\n",
      "1.LetF:2V?RbesubmodularandletX,Y?V.thesubmodular\n",
      "functionsFXastherestrictionofFto2X,andFX:2V?X?RasFX(A)=\n",
      "F(A?X)?F(X).First,letusseehowtocomputemarginals.Theprobability\n",
      "thattherandomsubsetSdistributedasP(S=A)?exp(?F(A))isinsome\n",
      "non-emptylattice[X,Y]=\n",
      "f\n",
      "A|X?A?Y\n",
      "g\n",
      "isequalto1X1XZYP(S\n",
      "?[X,Y])=exp(?F(A))=exp(?F(X?A))=e?F(X)X,(1)ZZZX?A?Y\n",
      "A?Y?XPYwhereZX=A?Y?Xe?(F(X?A)?F(X))isthepartitionfunction\n",
      "of(FX)Y.MarginalsP(i?S)ofanyi?Vcanbeobtainedusing[\n",
      "f\n",
      "i\n",
      "g\n",
      ",V].We\n",
      "alsoobtainconditionals?if,forexample,weYifA?[X,Y],conditiononthe\n",
      "eventon(1),wehaveP(S=A|S?[X,Y])=exp(?F(A))/ZX0otherwise.\n",
      "Notethatlog-supermodulardistributionsareconjugatewitheachother:fora\n",
      "logsupermodularpriorP(A)?exp(?F(A))andalikelihoodfunction4P(E|\n",
      "A)?exp(?L(E;A)),forwhichLissubmodularw.r.t.AforeachevidenceE,the\n",
      "posteriorP(A|E)?exp(?(F(A)+L(E;A)))islog-supermodularaswell.\n",
      "Thesameholdsforlog-submodulardistributions.\n",
      "4\n",
      "Thevariationalapproach\n",
      "InSection3wehaveseenthatduetotheclosurepropertiesofsubmodular\n",
      "functions,importantinferencetasks(e.g.,marginals,conditioning)inBayesian\n",
      "submodularmodelsrequirecomputingpartitionfunctionsofsuitably\n",
      "submodularfunctions.Giventhatthegeneralproblemis#Phard,weseek\n",
      "approximatemethods.Themainideaistoexploitthepeculiarpropertyof\n",
      "submodularfunctionsthattheycanbebothlower-andupper-boundedusing\n",
      "simpleadditivePfunctionsoftheforms(A)+c,wherec?Rands:2V?Ris\n",
      "modular,i.e.its(A)=i?As(\n",
      "f\n",
      "i\n",
      "g\n",
      ").Wewillalsotreatmodularfunctions\n",
      "s(?)asvectorss?RVwithcoordinatessi=s(\n",
      "f\n",
      "i\n",
      "g\n",
      ").Becausemodularfunctions\n",
      "havetractablelog-partitionfunctions,weobtainthefollowingbounds.Lemma\n",
      "1.If?A?V:sl(A)+cl?F(A)?su(A)+cuformodularsu,sl,andcl,cu\n",
      "?R,thenPlogZ+(sl,cl)?logPA?Vexp(+F(A))?logZ+(su,cu)and\n",
      "4\n",
      "\n",
      "logZ?(su,cu)?logA?Vexp(?F(A))?logZ?(sl,cl),PPwherelogZ+\n",
      "(s,c)=c+i?Vlog(1+esi)andlogZ?(s,c)=?c+i?Vlog(1+e?si).34\n",
      "Weconsiderlog-supermodulardistributions,asthelog-submodularcaseis\n",
      "analogous.SuchsubmodularlossfunctionsLhavebeenconsidered,e.g.,in\n",
      "documentsummarization[4].\n",
      "3\n",
      "Wecanuseanymodular(upperorlower)bounds(A)+ctoacom-\n",
      "pletelyfactorizeddistributionthatcanbeusedasaproxytoapproximatevalues\n",
      "ofinterestoftheoriginaldistribution.Forexample,themarginalofi?Aunder\n",
      "Q(A)?exp(?s(A)+c)iseasilyseentobe1/(1+esi).Insteadofoptimizing\n",
      "overallpossibleboundsoftheaboveform,weconsiderforeachX?Vtwosets\n",
      "ofmodularfunctions,whichareexactatXandlower-orupper-boundFrespec-\n",
      "tively.Similarlyasforconvexfunctions,we[8][?6.2]thesubrential\n",
      "ofFatXas?F(X)=\n",
      "f\n",
      "s?Rn|?Y?V:F(Y)?F(X)+s(Y)?s(X)\n",
      "g\n",
      ".\n",
      "(2)\n",
      "Thesuperdierential?F(X)isanalogouslybyinvertingthein-\n",
      "equalitysign[27].Foreachsubgradients??F(X),thefunctiongX(Y)=s(Y\n",
      ")+F(X)?s(X)islowerboundingF.Similarly,forasupergradients??F\n",
      "(X),hX(Y)=s(Y)+F(X)?s(X)isanupperboundofF.Notethatboth\n",
      "hXandgXareoftheformthatweconsidered(modularplusconstant)andare\n",
      "tightatX,i.e.hX(X)=gX(X)=F(X).Becausewewillbeoptimizingover\n",
      "tials,wefor+?anyX?VtheshorthandsZX(s)=Z+(s,F\n",
      "(X)?s(X))andZX(s)=Z?(s,F(X)?s(X)).4.1\n",
      "Optimizingoversubgradients\n",
      "?ToanalyzetheproblemofminimizinglogZX(s)subjecttos??F(X),\n",
      "weintroducethebaseVpolyhedronofF,asB(F)=\n",
      "f\n",
      "s?R|s(V)\n",
      "=F(V)and?A?V:s(A)?F(A)\n",
      "g\n",
      ",i.e.thesetofmodularlowerboundsthat\n",
      "areexactatV.Asthefollowinglemmashows,wedonothave?toconsider\n",
      "logZXforallXandwecanrestrictourattentiontothecaseX=?.?Lemma\n",
      "2.ForallX?Vwehavemins??F(?)Z??(s)?mins??F(X)ZX(s).Moreover,\n",
      "theformerproblemisequivalenttoXminimizelog(1+e?si)subjecttos?\n",
      "B(F).(3)s\n",
      "i?V\n",
      "Thus,wehavetooptimizeaconvexfunctionoverB(F),aproblemthat\n",
      "hasbeenalreadyconsidered[8,9].Forexample,wecanusetheFrank-Wolfe\n",
      "algorithm[28,29],whichiseasytoimplementandhasaconvergencerateofO(\n",
      "k1).Itrequirestheoptimizationoflinearfunctionsg(s)=hw,si=wTsover\n",
      "thedomain,which,asshownbyEdmonds[1],canbedonegreedilyinO(|V\n",
      "|log|V|)time.Moreprecisely,tocomputeamaximizers??B(F)of\n",
      "g(s),pickabijection?:\n",
      "f\n",
      "1,...,|V|\n",
      "g\n",
      "?Vthatordersw,i.e.w?(1)\n",
      "?w?(2)?????w?(|V|).Then,sets??(i)=F(?(i)|\n",
      "f\n",
      "?(1),...,\n",
      "?(i?1)\n",
      "g\n",
      ").Alternatively,ifwecantlyminimizethesumofthefunction\n",
      "plusamodularterm,e.g.forthefamilyofgraph-cutrepresentablefunctions\n",
      "[10],wecanapplythedivide-and-conqueralgorithm[9][?9.1],whichneedsthe\n",
      "minimizationofO(|V|)problems.1:procedureFRANK-WOLFE(F,x1\n",
      ",)2:f(x)=log(1+e?x).Elementwise.3:fork?1,2,...,Tdo4:\n",
      "5\n",
      "\n",
      "Picks?argminx?B(F)hx,?f(xk)i5:ifhxk?s,?f(xk)i?then6:returnxk\n",
      ".Smalldualitygap.7:else28:xk+1=(1??k)xk+?ks;?k=k+2\n",
      "1:procedureDIVIDE-CONQUER(F)2:s?F|V(V|)1;A??mini-\n",
      "mizerofF(?)?s(?)3:ifF(A?)=s(A?)then4:returns5:else6:sA?D\n",
      "IVIDE-CONQUER(FA)7:sV?A?DIVIDE-CONQUER(FA)8:return\n",
      "(sA,sV?A)\n",
      "TheentropyviewpointandtheFencheldual.Interestingly,(3)canbeinter-\n",
      "pretedasamaximumentropyproblem.Recallthat,fors?B(F)weusethe\n",
      "distributionP(A)?exp(?s(A)),whoseentropyisexactlythenegativeofourob-\n",
      "jective.Hence,wecanconsiderProblem(3)asthatofmaximizingtheentropy\n",
      "overthesetoffactorizeddistributionswithparametersin?B(F).Wecango\n",
      "backtothestandardrepresentationusingthemarginalspviapi=1/(1+exp(si\n",
      ")).ThisbecomesobviousifweconsidertheFencheldualoftheproblem,which,\n",
      "asdiscussedin?5,allowsustomakeconnectionswiththeclassical\n",
      "approach.Tothisend,weintroducetheLov`aszextension,foranyF:\n",
      "2V?RasthesupportfunctionoverB(F),i.e.f(p)=sups?B(F)sTp[30].V\n",
      "Letusalsodeneforp?[0,1]byH[p]theShannonentropyofavectorof\n",
      "|V|independentBernoullirandomvariableswithsuccessprobabilitiesp.4\n",
      "Lemma3.TheFencheldualproblemofProblem(3)ismaximizeH[p]?f\n",
      "(p).\n",
      "(4)\n",
      "p?[0,1]V\n",
      "Moreover,thereiszerodualitygap,andthepair(s?,p?)isprimal-dual\n",
      "optimalifandonlyif\n",
      "11p?=,...,andf(p?)=p?Ts?.1+exp(s?i)1+exp(s?n)\n",
      "(5)\n",
      "Fromthediscussionabove,itcanbeeasilyseenthattheFencheldualrepa-\n",
      "rameterizestheproblemfromtheparameters?stothemarginalsp.Notethat\n",
      "thedualletsusprovideaofoptimality,astheLov?aszextensioncan\n",
      "becomputedwithEdmonds?greedyalgorithm.4.2\n",
      "Optimizingoversupergradients\n",
      "Tooptimizeoversubgradients,wepickforeachsetX?Varepresentative\n",
      "supergradientandoptimizeoverallX.Asin[27],weconsiderthefollowing\n",
      "supergradients,elementsof?F(X).\n",
      "i?Xi?/X\n",
      "Growsupergradient?sX\n",
      "Shrinksupergradient?sX\n",
      "BarsupergradientsX\n",
      "?sX(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(i|V?\n",
      "f\n",
      "i\n",
      "g\n",
      ")?sX(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(i|X)\n",
      "?sX(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(i|X?\n",
      "f\n",
      "i\n",
      "g\n",
      ")?sX(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(\n",
      "f\n",
      "i\n",
      "g\n",
      ")\n",
      "sX(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(i|V?\n",
      "f\n",
      "i\n",
      "g\n",
      ")sX(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(\n",
      "f\n",
      "i\n",
      "g\n",
      ")\n",
      "Optimizingtheboundoverbarsupergradientsrequirestheminimizationof\n",
      "theoriginalfunctionplusamodularterm.Asalreadymentionedforthedivide-\n",
      "and-conquerstrategyabove,wecandothistlyforseveralproblems.The\n",
      "exactformulationoftheproblemispresentedbelow.Lemma4.the\n",
      "modularfunctionsm1(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=log(1+e?F(i|V?i))?log(1+eF(i)),and\n",
      "6\n",
      "\n",
      "m2(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=log(1+eF(i|V?i))?log(1+e?F(i)).Thefollowingpairsof\n",
      "problemsareequivalent.+XminimizeXlogZX(s)?XmaximizeXlogZX(s\n",
      ")\n",
      "??\n",
      "minimizeXF(X)+m1(X)minimizeXF(X)?m2(X)\n",
      "Eventhoughwecannotoptimizeovergrowandshrinksupergradients,we\n",
      "canevaluateallthreeattheoptimumfortheproblemsaboveandpicktheone\n",
      "thatgivesthebestbound.\n",
      "5\n",
      "methodsandthemulti-linearextension\n",
      "Istherearelationtotraditionalvariationalmethods?IfQ(?)isadistribu-\n",
      "tionoversubsetsofV,thenihhQ(S)iQ(S)0?KL(Q||P)=EQlog\n",
      "=logZ+EQlog=logZ?H[Q]+EQ[F],P(S)exp(?F(S))whichyields\n",
      "theboundlogZ?H[Q]?EQ[F].ThemethodrestrictsQtobe\n",
      "acompletelyfactorizeddistribution,sothatelementsarepickedindependently\n",
      "andQcanbedescribedbyVthevectorofmarginalsq?[0,1],overwhichit\n",
      "isthenoptimized.Comparethiswithourapproach.Mean-FieldObjective\n",
      "OurObjective:L-FIELD\n",
      "maximizeq?[0,1]VH[q]?Eq[F].Non-concave,canbehardtoevaluate.\n",
      "maximizeq?[0,1]VH[q]?f(q).Concave,ttoevaluate.\n",
      "BoththeLov?aszextensionf(q)andthemulti-linearextensionf?(q)=Eq\n",
      "[F]arecontinuousextensionsofF,introducedforsubmodularminimization\n",
      "[30]andmaximization[31],respectively.Theformeragreeswiththeconvex\n",
      "envelopeofFandcanbetlyevaluated(inO(|V|)evaluationsofF\n",
      ")usingEdmonds?greedyalgorithm(cf.,?4.1,[1]).Incontrast,evaluatingP\n",
      "Q[i?A]/f?(q)=Eq[F]=A?Viqi(1?qi)[i?A]F(A)ingeneralrequires\n",
      "summingoverexponentiallymanyterms?aproblempotentiallyashardas\n",
      "theoriginalinferenceproblem!Eveniff?(q)isapproximatedbysampling,\n",
      "itisneitherconvexnorconcave.Moreover,computingthecoordinateascent\n",
      "updatesofcanbeintractableforgeneralF.Hence,ourapproachcan\n",
      "bemotivatedasfollows:insteadofusingthemulti-linearextensionf?,weuse\n",
      "theLov?aszextensionfofF,whichmakestheproblemconvexandtractable.\n",
      "ThisanalogymotivatedthenameL-FIELD(LforLov?asz).5\n",
      "6\n",
      "Curvature-dependentapproximationbounds\n",
      "Howaccuratearetheboundsobtainedviaourvariationalapproach?We\n",
      "nowprovidetheoreticalguaranteesontheapproximationqualityasafunction\n",
      "ofthecurvatureofF,whichquanhowfarthefunctionisfrommodu-\n",
      "larity.Curvatureisforpolymatroidfunctions,whicharenormalized\n",
      "non-decreasingsubmodularfunctions,i.e.,asubmodularfunctionF:2V?R\n",
      "ispolymatroidifforallA?B?VitholdsthatF(A)?F(B).2\n",
      "(From[32]).LetG:2V?Rbeapolymatroidfunction.Thecurvature?ofGis\n",
      "?\n",
      "f\n",
      "i\n",
      "g\n",
      ")as5?=1?mini?V:G(\n",
      "f\n",
      "i\n",
      "g\n",
      ")>0G(i|VG(\n",
      "f\n",
      "i\n",
      "g\n",
      ").Thecurvatureis\n",
      "alwaysbetween0and1andisequalto0ifandonlyifthefunctionismodular.\n",
      "Althoughthecurvatureisanotionforpolymatroidfunctions,wecanstillshow\n",
      "resultsforthegeneralcaseasanysubmodularfunctionFcanbedecomposed\n",
      "7\n",
      "\n",
      "[33]asthesumofamodulartermm(?)asm(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=F(i|V?\n",
      "f\n",
      "i\n",
      "g\n",
      ")and\n",
      "G=F?m,whichisapolymatroidfunction.OurboundsPbelowdependon\n",
      "thecurvatureofGandGMAX=G(V)=F(V)?i?VF(i|V?i).Theorem\n",
      "1.LetF=G+m,whereGispolymatroidwithcurvature?andmismodular\n",
      "asabove.Pickanybijection?:V?\n",
      "f\n",
      "1,2,...,|V|\n",
      "g\n",
      "and\n",
      "setsS0?=?,Si?=\n",
      "f\n",
      "?(1),...,?(i)\n",
      "g\n",
      ".?Ifwees:s?(i)=G(Si?)?\n",
      "G(Si?1),thens+m??F(?)andthefollowinginequalitieshold.XlogZ?(s\n",
      "+m,0)?logexp(?F(A))??GMAX(6)A?V\n",
      "log\n",
      "X\n",
      "exp(+F(A))?logZ+(s+m,0)??GMAX\n",
      "(7)\n",
      "A?V\n",
      "Theorem2.PUnderthesameassumptionsasinTheorem1,ifwethe\n",
      "modularfunctions(?)bys(A)=i?AG(\n",
      "f\n",
      "i\n",
      "g\n",
      "),thens+m??F(?)andthe\n",
      "followinginequalitieshold.log\n",
      "X\n",
      "exp(?F(A))?logZ?(s+m,0)?\n",
      "?(n?1)?GMAX?GMAX1+(n?1)(1??)1??\n",
      "(8)\n",
      "X\n",
      "?(n?1)?GMAX?GMAX1+(n?1)(1??)1??\n",
      "(9)\n",
      "A?V\n",
      "logZ+(s+m,0)?log\n",
      "exp(+F(A))?\n",
      "A?V\n",
      "Notethatweestablishboundsforspsub-/supergradients.Sinceour\n",
      "variationalschemeconsiderstheseintheoptimizationaswell,thesamequality\n",
      "guaranteesholdfortheoptimizedbounds.Further,notethatwegetadepen-\n",
      "denceontherangeofthefunctionviaGMAX.However,ifweconsider?Ffor\n",
      "large?>1,mostofthemasswillbeconcentratedattheMAP(assumingit\n",
      "isunique).Inthiscase,L-FIELDalsoperformswell,asitcanalwayschoose\n",
      "gradientsthataretightattheMAP.Whenweoptimizeoversupergradients,\n",
      "allpossibletightsetsareconsidered.Similarly,thesubgradientsareoptimized\n",
      "overB(F),andforanyX?VthereexistssomesX?B(F)tightatX.\n",
      "7\n",
      "Experiments\n",
      "Ourexperiments6aimtoaddressfourmainquestions:(1)Howlargeisthe\n",
      "gapbetweentheupperandlower-boundsforthelog-partitionfunctionandthe\n",
      "marginals?(2)Howaccuratearethefactorizedapproximationsobtainedfrom\n",
      "asingleMAP-likeoptimizationproblem?(3)Howdoestheaccuracydepend\n",
      "ontheamountofevidence(i.e.,concentrationoftheposterior),thecurvature\n",
      "ofthefunction,andthetypeofBayesiansubmodularmodelconsidered?(4)\n",
      "HowdoesL-FIELDcomparetoonproblemswherethelattercan\n",
      "beapplied?Weconsiderapproximatemarginalsobtainedfromthefollowing\n",
      "8\n",
      "\n",
      "methods:lower/upper:obtainedfromthefactorizeddistributionsassociated\n",
      "withthemodularlower/upperbounds;lower-/upperbound:thelower/upper\n",
      "boundoftheestimatedprobabilityinterval.Allofthefunctionsweconsider\n",
      "aregraph-representable[17],whichallowsustoperformtheoptimizationover\n",
      "suptialsusingasinglegraphcutandusetheexactdivide-and-conquer\n",
      "algorithm.Weusedthemin-cut56\n",
      "Wefromtheconventiontoremovei?Vs.t.G(\n",
      "f\n",
      "i\n",
      "g\n",
      ")=0.Pleaseseethe\n",
      "appendixforadiscussion.Thecodewillbemadeavailableathttp://las.ethz.ch.\n",
      "6\n",
      "implementationfrom[34].Sincetheupdateequationsareeasilycomputable,\n",
      "wehavealsoimplementedfortheexperiment.Fortheothertwo\n",
      "experimentscomputingtheupdatesrequiresexhaustiveenumerationandisin-\n",
      "tractable.TheresultsareshownonFigure1andtheexperimentsareexplained\n",
      "below.Weplottheaveragesofseveralrepetitionsoftheexperiments.Notethat\n",
      "computingintervalsformarginalsrequirestwoMAP-likeoptimizationspervari-\n",
      "able;hencewefocusonsmallproblemswith|V|=100.Wepointoutthat\n",
      "obtainingasinglefactorizedapproximation(asproduced,e.g.,by\n",
      "onlyrequiresasingleMAP-likeoptimization,whichcanbedoneformorethan\n",
      "270,000variables[19].Log-supermodular:Cuts/PairwiseMRFs.Our\n",
      "experimentevaluatesL-FIELDonasequenceofdistributionsthatareincreas-\n",
      "inglymoreconcentrated.Motivatedbyapplicationsinsemisupervisedlearning,\n",
      "wesampleddatafroma2-dimensionalGaussianmixturemodelwith2clusters.\n",
      "ThecentersweresampledfromN([3,3],I)andN([?3,?3],I)respectively.\n",
      "Foreachcluster,wesampledn=50pointsfromabivariatenormal.These2n\n",
      "pointswerethenusedasnodes0tocreateagraphwithweightbetweenpoints\n",
      "xandx0equaltoe?||x?x||.AspriorwechoseP(A)?exp(?F(A)),\n",
      "whereFisthecutfunctioninthisgraph,henceP(A)isaregularMRF.Then,\n",
      "fork=1,...,nweconsidertheconditionaldistributionontheeventthat\n",
      "kpointsfromtheclusterareononesideofthecutandkpointsfromthe\n",
      "otherclusterareontheotherside.Asweprovidemoreevidence,theposterior\n",
      "concentrates,andtheintervalsforboththelog-partitionfunctionandmarginals\n",
      "shrink.Comparedwithgroundtruth,theestimatesofthemarginalprobabili-\n",
      "tiesimproveaswell.Duetonon-convexity,occasionallygetsstuck\n",
      "inlocaloptima,resultinginverypoormarginals.Topreventthis,wechosethe\n",
      "bestrunoutof20randomrestarts.Thesebestrunsproducedslightlybetter\n",
      "marginalsthanL-FIELDforthismodel,atthecostoflessrobustness.Log-\n",
      "supermodular:Decomposablefunctions.Oursecondexperimentassessesthe\n",
      "performanceasafunctionofthecurvatureofF.Itismotivatedbyaproblem\n",
      "inoutbreakdetectiononnetworks.AssumethatwehaveagraphG=(V,E)\n",
      "andsomeofitsnodesE?Vhavebeeninfectedbysomecontagiousprocess.\n",
      "InsteadofE,weobserveanoisysetN?V,corruptedwithafalsepositiverate\n",
      "of0.1andafalsenegativerateof0.2.Weusedalog-supermodularpriorP(A)\n",
      "?P\n",
      "v?A|?exp?v?V|N|N,where??[0,1]andNvistheunionofv\n",
      "anditsneighbors.Thispriorv|preferssmallersetsandsetsthataremore\n",
      "clusteredonthegraph.Notethat?controlsthepreferenceofclusterednodes\n",
      "9\n",
      "\n",
      "andthecurvature.Wesampledrandomgraphswith100nodesfrom\n",
      "aWatts-StrogatzmodelandobtainedEbyrunninganindependentcascade\n",
      "startingfrom2randomnodes.Then,forvarying?,weconsidertheposterior,\n",
      "whichislog-supermodular,asthenoisemodelresultsinamodularlikelihood.\n",
      "Asthecurvatureincreases,theintervalsforboththelog-partitionfunctionand\n",
      "marginalsdecreaseasexpected.Surprisingly,themarginalsareveryaccurate\n",
      "(<0.1averageerror)evenforverylargecurvature.Thissuggeststhatourcur-\n",
      "vaturedependentboundsareveryconservative,andmuchbetterperformance\n",
      "canbeexpectedinpractice.Log-submodular:Facilitylocationmodeling.Our\n",
      "lastexperimentevaluateshowaccurateLFIELDiswhenquantifyinguncer-\n",
      "taintyinsubmodularmaximizationtasks.Concretely,weconsidertheproblem\n",
      "ofsensorplacementinwaterdistributionnetworks,whichcanbemodeledas\n",
      "submodularmaximization[35].Moresp,wehaveawaterdistribution\n",
      "networkandtherearesomejunctionsVwherewecanputsensorsthatcan\n",
      "detectcontaminatedwater.WealsohaveasetIofcontaminationscenarios.\n",
      "Foreachi?Iandj?VwehaveautilityCi,j?[0,1],thatcomesfromreal\n",
      "data[35].Moreover,asthesensorsareexpensive,wewouldliketouseasfew\n",
      "aspossible.WePusethefacility-locationmodel,morepreciselyP(S=A)?\n",
      "exp(F(A)?2|A|),withF(A)=i?Nmaxj?ACi,j.Insteadofoptimizingfor\n",
      "aplacement,hereweconsidertheproblemofsamplingfromPinorder\n",
      "toquantifytheuncertaintyintheoptimizationtask.Weusedthefollowing\n",
      "samplingstrategy.Weconsidernodesv?Vinsomeorder.Wethensamplea\n",
      "BernoulliZwithprobabilityP(Z=1)=qvbasedonthefactorizeddistribution\n",
      "qfromthemodularupperbound.Wethenconditiononv?SifZ=1,orv?\n",
      "/SifZ=0.Inthecomputationofthelowerboundweusedthesubgradientsg\n",
      "computedfromthegreedyorderofV?thei-thelementinthisorderv1,...,\n",
      "vnistheonethatgivesthehighestimprovementwhenaddedtothesetformed\n",
      "bythepreviousi?1elements.Then,sg??F(?):sgi=F(vi|\n",
      "f\n",
      "v0,...,\n",
      "vi?1\n",
      "g\n",
      ").Werepeatedtheexperimentseveraltimesusingrandomlysampled500\n",
      "contaminationscenariosand100locationsfromalargerdataset.Notethatour\n",
      "approximationsgetbetterasweconditiononmoreinformation(i.e.,proceed\n",
      "throughtheiterationsofthesamplingprocedureabove).Alsonotethateven\n",
      "fromtheverybeginning,themarginalsareveryaccurate(<0.1averageerror).\n",
      "7\n",
      "010203040NumberofConditionedPairs\n",
      "0.80.60.40.200\n",
      "50\n",
      "Log-PartitionFunction\n",
      "LowerUpper20\n",
      "10\n",
      "00\n",
      "0.2\n",
      "0.40.61-Curvature\n",
      "0.8\n",
      "0.80.60.40.200\n",
      "80604020020\n",
      "10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4060Iteration\n",
      "80\n",
      "(g)[SP]?Logp.Bounds\n",
      "100\n",
      "AverageGap?Upper-LowerBound\n",
      "Log-PartitionFunction\n",
      "LowerUpper\n",
      "0\n",
      "0.40.61-Curvature\n",
      "0.8\n",
      "0.80.60.40.2020\n",
      "4060Iteration\n",
      "80\n",
      "0\n",
      "100\n",
      "(h)[SP]?Prob.IntervalGap\n",
      "LowerUpperLower-BoundUpper-Bound\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0.2\n",
      "2468NumberofConditionedPairs\n",
      "0\n",
      "(e)[NW]?Prob.IntervalGap\n",
      "(d)[NW]?Logp.Bounds100\n",
      "0.2\n",
      "0.4\n",
      "(c)[CT]?MeanErroronMarginals\n",
      "1\n",
      "1\n",
      "LowerUpperLower-BoundUpper-BoundMean-Field\n",
      "50\n",
      "(b)[CT]?Prob.IntervalGap\n",
      "30\n",
      "AverageGap?Upper-LowerBound\n",
      "(a)[CT]?Logp.Bounds\n",
      "10203040NumberofConditionedPairs\n",
      "MeanAbsoluteErrorofMarginals\n",
      "0\n",
      "MeanAbsoluteErrorofMarginals\n",
      "50\n",
      "0.61\n",
      "11\n",
      "\n",
      "0.2\n",
      "0.40.61-Curvature\n",
      "0.8\n",
      "1\n",
      "(f)[NW]?MeanErroronMarginalsMeanAbsoluteErrorofMarginals\n",
      "Log-PartitionFunction\n",
      "100\n",
      "AverageGap?Upper-LowerBound\n",
      "LowerUpperMean-Field\n",
      "150\n",
      "LowerUpperLower-BoundUpper-Bound\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "00\n",
      "5\n",
      "10Iteration\n",
      "15\n",
      "20\n",
      "(i)[SP]?MeanErroronMarginals\n",
      "Figure1:Experimentson[CT]Cuts(a-c),[NW]networkdetection(d-f),\n",
      "[SP]sensorplacement(g-i).Notethattogenerate(c,f,i)wehadtocompute\n",
      "theexactmarginalsbyexhaustiveenumeration.Hence,thesethreegraphswere\n",
      "createdusingasmallergroundsetofsize20.Theerrorbarscapture3standard\n",
      "errors.\n",
      "8\n",
      "Conclusion\n",
      "WeproposedL-FIELD,thevariationalmethodforapproximateinfer-\n",
      "enceingeneralBayesiansubmodularandsupermodularmodels.Ourapproach\n",
      "hasseveralattractiveproperties:Itproducesrigorousupperandlowerbounds\n",
      "onthelog-partitionfunctionandonmarginalprobabilities.Theseboundscan\n",
      "beoptimizedntlyviaconvexandsubmodularoptimization.Accurate\n",
      "factorialapproximationscanbeobtainedatthesamecomputationalcostas\n",
      "performingMAPinferenceintheunderlyingmodel,aproblemforwhichavast\n",
      "arrayofscalablemethodsareavailable.Furthermore,weidenanatu-\n",
      "ralconnectiontothetraditionalmethodandboundedthequality\n",
      "ofourapproximationswiththecurvatureofthefunction.Ourexperiments\n",
      "demonstratetheaccuracyofourinferenceschemeonseveralnaturalexamples\n",
      "ofBayesiansubmodularmodels.Webelievethatourresultspresenta\n",
      "cantstepinunderstandingtheroleofsubmodularity?sofarmainlyconsidered\n",
      "foroptimization?inapproximateBayesianinference.Furthermore,L-FIELD\n",
      "presentsatadvanceinourabilitytoperformprobabilisticinferencein\n",
      "modelswithcomplex,highorderdependencies,whichpresentamajorchallenge\n",
      "forclassicaltechniques.Acknowledgments.Thisresearchwassupportedin\n",
      "partbySNSFgrant200021137528,ERCStG307036andaMicrosoftResearch\n",
      "FacultyFellowship.\n",
      "12\n",
      "\n",
      "2References\n",
      "[1][2]\n",
      "J.Edmonds.?Submodularfunctions,matroids,andcertainpolyhedra?.In:\n",
      "Combinatorialstructuresandtheirapplications(1970),pp.69?87.D.Golovin\n",
      "andA.Krause.?AdaptiveSubmodularity:TheoryandApplicationsinActive\n",
      "LearningandStochasticOptimization?.In:JournalofIntelligence\n",
      "Research(JAIR)42(2011),pp.427?486.\n",
      "8\n",
      "[3][4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20][21]\n",
      "[22][23][24][25][26][27][28][29][30][31][32][33][34][35]\n",
      "Y.YueandC.Guestrin.?LinearSubmodularBanditsanditsApplication\n",
      "toDivRetrieval?.In:NeuralInformationProcessingSystems(NIPS).\n",
      "2011.H.LinandJ.Bilmes.?Aclassofsubmodularfunctionsfordocument\n",
      "summarization?.In:49thAnnualMeetingoftheAssociationforComputational\n",
      "Linguistics:HLT.2011,pp.510?520.V.CevherandA.Krause.?GreedyDic-\n",
      "tionarySelectionforSparseRepresentation?.In:IEEEJournalofSelected\n",
      "TopicsinSignalProcessing99.5(2011),pp.979?988.M.Narasimhan,N.Jo-\n",
      "jic,andJ.Bilmes.?Q-clustering?.In:NIPS.Vol.5.10.10.2005,p.5.F.\n",
      "Bach.?Structuredsparsity-inducingnormsthroughsubmodularfunctions.?In:\n",
      "NIPS.2010.S.Fujishige.Submodularfunctionsandoptimization.Vol.58.\n",
      "AnnalsofDiscreteMathematics.2005.F.Bach.?Learningwithsubmodular\n",
      "functions:aconvexoptimizationperspective?.In:FoundationsandRinMa-\n",
      "chineLearning6.2-3(2013),pp.145?373.ISSN:1935-8237.TrendsS.Jegelka,\n",
      "H.Lin,andJ.A.Bilmes.?Onfastapproximatesubmodularminimization.?In:\n",
      "NIPS.2011.N.Buchbinder,M.Feldman,J.Naor,andR.Schwartz.?Atight\n",
      "lineartime(1/2)-approximationforunconstrainedsubmodularmaximization?.\n",
      "In:FoundationsofComputerScience(FOCS).2012.Y.Boykov,O.Veksler,\n",
      "andR.Zabih.?Fastapproximateenergyminimizationviagraphcuts?.In:\n",
      "PatternAnalysisandMachineIntelligence,IEEETransactionson23.11(2001),\n",
      "pp.1222?1239.M.JerrumandA.Sinclair.?Polynomial-timeapproximation\n",
      "algorithmsfortheIsingmodel?.In:SIAMJournaloncomputing22.5(1993),\n",
      "pp.1087?1116.L.A.GoldbergandM.Jerrum.?Thecomplexityofferromag-\n",
      "neticIsingwithlocalIn:Combinatorics,ProbabilityandComputing\n",
      "16.01(2007),pp.43?61.J.Gillenwater,A.Kulesza,andB.Taskar.?Near-\n",
      "OptimalMAPInferenceforDeterminantalPointProcesses?.In:Proc.Neural\n",
      "InformationProcessingSystems(NIPS).2012.M.J.WainwrightandM.I.\n",
      "Jordan.?GraphicalModels,ExponentialFamilies,andVariationalInference?.\n",
      "In:Found.TrendsMach.Learn.1.1-2(2008),pp.1?305.V.Kolmogorov\n",
      "andR.Zabin.?Whatenergyfunctionscanbeminimizedviagraphcuts??In:\n",
      "PatternAnalysisandMachineIntelligence,IEEETransactionson26.2(2004),\n",
      "pp.147?159.P.StobbeandA.Krause.tMinimizationofDecompos-\n",
      "ableSubmodularFunctions?.In:Proc.NeuralInformationProcessingSys-\n",
      "tems(NIPS).2010.S.Jegelka,F.Bach,andS.Sra.methodsfor\n",
      "user-friendlysubmodularoptimization?.In:AdvancesinNeuralInformation\n",
      "ProcessingSystems.2013,pp.1313?1321.S.JegelkaandJ.Bilmes.?Sub-\n",
      "13\n",
      "\n",
      "modularitybeyondsubmodularenergies:couplingedgesingraphcuts?.In:\n",
      "ComputerVisionandPatternRecognition(CVPR),2011IEEEConferenceon.\n",
      "2011,pp.1897?1904.A.KrauseandC.Guestrin.?Near-optimalNonmyopic\n",
      "ValueofInformationinGraphicalModels?.In:ConferenceonUncertaintyin\n",
      "Intelligence(UAI).2005.A.KrauseandD.Golovin.?Submodular\n",
      "FunctionMaximization?.In:Tractability:PracticalApproachestoHardProb-\n",
      "lems(toappear).CambridgeUniversityPress,2014.P.Kohli,L.Ladick?y,and\n",
      "P.H.Torr.?Robusthigherorderpotentialsforenforcinglabelconsistency?.In:\n",
      "InternationalJournalofComputerVision82.3(2009),pp.302?324.A.Kulesza\n",
      "andB.Taskar.?DeterminantalPointProcessesforMachineLearning?.In:\n",
      "FoundationsandTrendsinMachineLearning5.2?3(2012).R.GomesandA.\n",
      "Krause.?BudgetedNonparametricLearningfromDataStreams?.In:ICML.\n",
      "2010.K.El-Arini,G.Veda,D.Shahaf,andC.Guestrin.?Turningdownthe\n",
      "noiseintheblogosphere?.In:Proc.ACMSIGKDDInternationalConference\n",
      "onKnowledgeDiscoveryandDatamining.2009.R.Iyer,S.Jegelka,andJ.\n",
      "Bilmes.?FastSemidrential-basedSubmodularFunctionOptimization?.In:\n",
      "ICML(3).2013,pp.855?863.M.FrankandP.Wolfe.?Analgorithmfor\n",
      "quadraticprogramming?.In:NavalResearchLogisticsQuarterly3.1-2(1956),\n",
      "pp.95?110.ISSN:1931-9193.M.Jaggi.?RevisitingFrank-Wolfe:Projection-\n",
      "freesparseconvexoptimization?.In:30thInternationalConferenceonMa-\n",
      "chineLearning(ICML-13).2013,pp.427?435.L.Lov?asz.?Submodular\n",
      "functionsandconvexity?.In:MathematicalProgrammingTheStateofthe\n",
      "Art.Springer,1983,pp.235?257.G.Calinescu,C.Chekuri,M.P?al,andJ.\n",
      "Vondr?ak.?Maximizingasubmodularsetfunctionsubjecttoamatroidcon-\n",
      "straint?.In:Integerprogrammingandcombinatorialoptimization.Springer,\n",
      "2007.M.ConfortiandG.Cornuejols.?Submodularsetfunctions,matroids\n",
      "andthegreedyalgorithm:tightworst-caseboundsandsomegeneralizationsof\n",
      "theRado-Edmondstheorem?.In:Discreteappliedmathematics7.3(1984),pp.\n",
      "251?274.W.H.Cunningham.?Decompositionofsubmodularfunctions?.In:\n",
      "Combinatorica3.1(1983).Y.BoykovandV.Kolmogorov.?Anexperimental\n",
      "comparisonofwalgorithmsforenergyminimizationinvision?.\n",
      "In:PatternAnalysisandMachineIntelligence,IEEETrans.on26.9(2004).\n",
      "A.Krause,J.Leskovec,C.Guestrin,J.VanBriesen,andC.Faloutsos.?Ef-\n",
      "tSensorPlacementOptimizationforSecuringLargeWaterDistribution\n",
      "Networks?.In:JournalofWaterResourcesPlanningandManagement134.6\n",
      "(2008),pp.516?526.\n",
      "9\n",
      "14\n",
      "\n",
      "PP6825.pdf\n",
      "PP6825.pdf 16\n",
      "InhomogeneousHypergraphClusteringwith\n",
      "Applications\n",
      "Authoredby:\n",
      "PanLi\n",
      "OlgicaMilenkovic\n",
      "Abstract\n",
      "Hypergraphpartitioningisanimportantprobleminmachinelearning,\n",
      "computervisionandnetworkanalytics.Awidelyusedmethodforhyper-\n",
      "graphpartitioningreliesonminimizinganormalizedsumofthecostsof\n",
      "partitioninghyperedgesacrossclusters.Algorithmicsolutionsbasedon\n",
      "thisapproachassumethattpartitionsofahyperedgeincurthe\n",
      "samecost.However,thisassumptionfailstoleveragethefactthatdif-\n",
      "ferentsubsetsofverticeswithinthesamehyperedgemayhavet\n",
      "structuralimportance.Wehenceproposeanewhypergraphclustering\n",
      "technique,termedinhomogeneoushypergraphpartitioning,whichassigns\n",
      "tcoststothyperedgecuts.Weprovethatinhomogeneous\n",
      "partitioningproducesaquadraticapproximationtotheoptimalsolution\n",
      "iftheinhomogeneouscostssatisfysubmodularityconstraints.Moreover,\n",
      "wedemonstratethatinhomogenouspartitioningtperfor-\n",
      "manceimprovementsinapplicationssuchasstructurelearningofrank-\n",
      "ings,subspacesegmentationandmotifclustering.\n",
      "1PaperBody\n",
      "Graphpartitioningorclusteringisaubiquitouslearningtaskthathasfound\n",
      "manyapplicationsinstatistics,datamining,socialscienceandsignalprocessing\n",
      "[1,2].Inmostsettings,clusteringisformallycastasanoptimizationproblem\n",
      "thatinvolvesentitieswithtpairwisesimilaritiesandaimstomaximize\n",
      "thetotal?similarity?ofelementswithinclusters[3,4,5],orsimultaneously\n",
      "maximizethetotalsimilaritywithinclusteranddissimilaritybetweenclusters\n",
      "[6,7,8].Graphpartitioningmaybeperformedinanagnosticsetting,where\n",
      "partoftheoptimizationproblemistoautomaticallylearnthenumberofclus-\n",
      "ters[6,7].Althoughsimilarityamongentitiesinaclassmaybecapturedvia\n",
      "pairwiserelations,inmanyrealworldproblemsitisnecessarytocapturejoint,\n",
      "higher-orderrelationsbetweensubsetsofobjects.Fromagraph-theoreticpoint\n",
      "ofview,thesehigher-orderrelationsmaybedescribedviahypergraphs,where\n",
      "1\n",
      "\n",
      "objectscorrespondtoverticesandhigher-orderrelationsamongobjectscorre-\n",
      "spondtohyperedges.Thevertexclusteringproblemaimstominimizethesimi-\n",
      "larityacrossclustersandisreferredtoashypergraphpartitioning.Hypergraph\n",
      "clusteringhasfoundawiderangeofapplicationsinnetworkmotifclustering,\n",
      "semi-supervisedlearning,subspaceclusteringandimagesegmentation.[8,9,10,\n",
      "11,12,13,14,15].Classicalhypergraphpartitioningapproachessharethesame\n",
      "setup:Anonnegativeweightisassignedtoeveryhyperedgeandifthevertices\n",
      "inthehyperedgeareplacedacrossclusters,acostproportionaltotheweightis\n",
      "chargedtotheobjectivefunction[9,11].Werefertothisclusteringprocedure\n",
      "ashomogenoushyperedgeclusteringandrefertothecorrespondingpartitionas\n",
      "ahomogeneouspartition(H-partition).Clearly,thistypeofapproachprohibits\n",
      "theuseofinformationregardinghowtverticesorsubsetsofvertices\n",
      "belongingtoahyperedgecontributetothehigher-orderrelation.Amoreap-\n",
      "propriateformulationentailschargingtcoststotcutsofthe\n",
      "31stConferenceonNeuralInformationProcessingSystems(NIPS2017),Long\n",
      "Beach,CA,USA.\n",
      "InH-??partitionGraph?partition\n",
      "c(M3)\n",
      "H-??partition\n",
      "M3(Product)\n",
      "c(M1)\n",
      "6\n",
      "1\n",
      "2\n",
      "75\n",
      "c(M2)3\n",
      "M1(Reactant)\n",
      "M2(Reactant)\n",
      "84\n",
      "10\n",
      "9\n",
      "Figure1:Clustersobtainedusinghomogenousandinhomogeneoushyper-\n",
      "graphpartitioningandgraphpartitioning(basedonpairwiserelations).Left:\n",
      "Eachreactionisrepresentedbyahyperedge.Threetcutsofahyper-\n",
      "edgearedenotedbyc(M3),c(M1),andc(M2),basedonwhichvertexis\n",
      "?isolated?bythecut.Thegraphpartitiononlytakesintoaccountpairwise\n",
      "relationsbetweenreactants,correspondingtow(c(M3))=0.Thehomogenous\n",
      "partitionenforcesthethreecutstohavethesameweight,w(c(M3))=w(c(M1\n",
      "))=w(c(M2)),whileaninhomogenouspartitionisnotrequiredtosatisfythis\n",
      "constraint.Right:Threetclusteringresultsbasedonoptimallynor-\n",
      "malizedcutsforagraphpartition,ahomogenouspartition(H-partition)and\n",
      "aninhomogenouspartition(InH-partition)with0.01w(c(M1))?w(c(M3))?\n",
      "0.44w(c(M1)).hyperedges,therebyendowinghyperedgeswithvectorweights\n",
      "capturingthesecosts.Toillustratethepoint,considertheexampleofmetabolic\n",
      "networks[16].Inthesenetworks,verticesdescribemetaboliteswhileedgesde-\n",
      "scribetransformative,catalyticorbindingrelations.Metabolicreactionsare\n",
      "2\n",
      "\n",
      "usuallydescribedviaequationsthatinvolvemorethantwometabolites,such\n",
      "asM1+M2?M3.Here,bothmetabolitesM1andM2needtobepresent\n",
      "inordertocompletethereactionthatleadstothecreationoftheproductM3\n",
      ".Thethreemetabolitesplaytroles:M1,M2arereactants,whileM3\n",
      "istheproductmetabolite.Asyntheticmetabolicnetworkinvolvingreactions\n",
      "withthreereagentsasdescribedaboveisdepictedinFigure1,alongwiththree\n",
      "tpartitionsinducedbyahomogeneous,inhomogeneousandclassical\n",
      "graphcut.Asmaybeseen,thehypergraphcutsintermsofhowthey\n",
      "splitorgrouppairsofreagents.Theinhomogeneousclusteringpreservesallbut\n",
      "onepairing,whilethehomogenousclusteringsplitstwopairings.Thegraph\n",
      "partitioncapturesonlypairwiserelationsbetweenreactantsandhence,theop-\n",
      "timalnormalizedcutoverthegraphsplitssixreactiontriples.The\n",
      "betweeninhomogenous,homogenous,andpairwise-relationbasedcutsareeven\n",
      "moreevidentforlargegraphsandtheymayleadtotlytpar-\n",
      "titioningperformanceinanumberofimportantpartitioningapplications.The\n",
      "problemofinhomogeneoushypergraphclusteringhasnotbeenpreviouslystud-\n",
      "iedintheliterature.Themainresultsofthepaperaretalgorithmsfor\n",
      "inhomogenoushypergraphpartitioningwiththeoreticalperformanceguarantees\n",
      "andextensivetestingofinhomogeneouspartitioninginapplicationssuchashier-\n",
      "archicalbiologicalnetworkstudies,structurelearningofrankingsandsubspace\n",
      "clustering1(Allproofsanddiscussionsofsomeapplicationsarerelegatedtothe\n",
      "SupplementaryMaterial).Thealgorithmicmethodsarebasedontransforming\n",
      "hypergraphsintographsandsubsequentlyperformingspectralclusteringbased\n",
      "onthenormalizedLaplacianofthederivedgraph.Asimilarapproachforho-\n",
      "mogenousclusteringhasbeenusedunderthenameofCliqueExpansion[14].\n",
      "However,theprojectionprocedure,whichisthekeystepofCliqueExpansion,\n",
      "tlyfromtheprojectionprocedureusedinourwork,astheinho-\n",
      "mogenousclusteringalgorithmallowsnon-uniformexpansionofonehyperedge\n",
      "whileCliqueExpansiononlyallowsforuniformexpansions.Astraightforward\n",
      "analysisrevealsthatthenormalizedhypergraphcutproblem[11]andthenor-\n",
      "malizedLaplacianhomogeneoushypergraphclusteringalgorithms[9,11]are\n",
      "specialcasesofourproposedalgorithm,wherethecostsassignedtothehyper-\n",
      "edgestakeaveryspecialform.Furthermore,weshowthatwhenthecostsofthe\n",
      "proposedinhomogeneoushyperedgeclusteringaresubmodular,theprojection\n",
      "procedureisguaranteedtoaconstant-approximationsolutionforseveral\n",
      "graph-cutrelatedentities.Hence,theinhomogeneousclusteringprocedurehas\n",
      "thesamequadraticapproximationpropertiesasspectralgraphclustering[17].\n",
      "2\n",
      "PreliminariesandProblemFormulation\n",
      "AhypergraphH=(V,E)isdescribedintermsofavertexsetV=\n",
      "f\n",
      "v1,v2\n",
      ",...,vn\n",
      "g\n",
      "andasetofhyperedgesE.Ahyperedgee?Eisasubsetofvertices\n",
      "inV.ForanarbitrarysetS,welet|S|standforthecardinalityoftheset,\n",
      "anduse?(e)=|e|todenotethesizeofahyperedge.Ifforalle?E,?(e)\n",
      "equalsaconstant?,thehypergraphiscalleda?-uniformhypergraph.1\n",
      "Thecodeforexperimentscanbefoundathttps://github.com/lipan00123/InHclustering.\n",
      "2\n",
      "3\n",
      "\n",
      "Let2edenotethepowersetofe.Aninhomogeneoushyperedge(InH-\n",
      "hyperedge)isahyperedgewithanassociatedweightfunctionwe:2e?R?0\n",
      ".Theweightwe(S)indicatesthecostofcutting/partitioningthehyperedgee\n",
      "intotwosubsets,Sande/S.Aconsistentweightwe(S)thefollowing\n",
      "properties:we(?)=0andwe(S)=we(e/S).Thealsoallowswe(?)\n",
      "tobeenforcedonlyforasubsetof2e.However,forsingletonsetsS=\n",
      "f\n",
      "v\n",
      "g\n",
      "?\n",
      "e,we(\n",
      "f\n",
      "v\n",
      "g\n",
      ")hastobePspeced.Thedegreeofavertexvisasdv=\n",
      "e:v?ewe(\n",
      "f\n",
      "v\n",
      "g\n",
      "),whilethevolumeofasubsetofverticesS?VisasX\n",
      "volH(S)=dv.(1)v?S\n",
      "?beapartitionoftheverticesV.thehyperedgeboundaryofSas\n",
      "?S=\n",
      "f\n",
      "e?Let(S,S)E|e?S6=?,e?S?6=?\n",
      "g\n",
      "andthecorrespondingset\n",
      "volumeasXXvolH(?S)=we(e?S)=we(e?S),(2)e?E\n",
      "e??S\n",
      "wherethesecondequalityholdssincewe(?)=we(e)=0.Thetaskof\n",
      "interestistominimizethenormalizedcutNCutofthehypergraphwithInH-\n",
      "hyperedges,i.e.,tosolvethefollowingoptimizationproblem\n",
      "11argminNCutH(S)=argminvolH(?S)+(3)?.SSvolH(S)volH\n",
      "(S)OnemayalsoextendthenotionofInHhypergraphpartitioningtok-way\n",
      "InH-partition.Forthispurpose,welet(S1,S2,...,Sk)beak-waypartitionof\n",
      "theverticesV,andthek-waynormalizedcutforinH-partitionaccording\n",
      "toNCutH(S1,S2,...,Sk)=\n",
      "kXvolH(?Si)i=1\n",
      "volH(Si)\n",
      ".\n",
      "(4)\n",
      "Similarly,thegoalofak-wayinH-partitionistominimizeNCutH(S1,S2,\n",
      "...,Sk).Notethatif?(e)=2foralle?E,theaboveareconsistent\n",
      "withthoseusedforgraphs[18].\n",
      "3\n",
      "InhomogeneousHypergraphClusteringAlgorithms\n",
      "Motivatedbythehomogeneousclusteringapproachof[14],weproposean\n",
      "inhomogeneousclusteringalgorithmthatusesthreesteps:1)Projectingeach\n",
      "InH-hyperedgeontoasubgraph;2)Mergingthesubgraphsintoagraph;3)\n",
      "PerformingclassicalspectralclusteringbasedonthenormalizedLaplacian(de-\n",
      "scribedintheSupplementaryMaterial,alongwiththecomplexityofallalgo-\n",
      "rithmicsteps).Thenoveltyofourapproachisinintroducingtheinhomogenous\n",
      "clusteringconstraintsviatheprojectionstep,andstatinganoptimizationprob-\n",
      "lemthatprovidestheprovablybestweightsplittingforprojections.Allour\n",
      "theoreticalresultsarestatedfortheNCutproblem,buttheproposedmeth-\n",
      "odsmaybeusedasheuristicsfork-wayNCuts.Supposethatwearegivena\n",
      "hypergraphwithinhomogeneoushyperedgeweights,H=(V,E,w).Foreach\n",
      "InH-hyperedge(e,we),weaimtoacompletesubgraphGe=(V(e),E\n",
      "(e),w(e))that?best?representsthisInH-hyperedge;here,V(e)=e,E(e)\n",
      "=\n",
      "ff\n",
      "v,v?\n",
      "g\n",
      "|v,v??e,v6=v?\n",
      "g\n",
      ",andw(e):E(e)?Rdenotesthehyperedge\n",
      "weightvector.Thegoalistondthegraphedgeweightsthatprovidethebest\n",
      "approximationtothesplithyperedgeweightaccordingto:X(e)min?(e)s.t.\n",
      "4\n",
      "\n",
      "we(S)?wv?v??(e)we(S),forallS?2es.t.we(S)is(5)w(e),?\n",
      "(e)\n",
      "v?S,?v?e/S\n",
      "Uponsolvingfortheweightsw(e),weconstructagraphG=(V,Eo,w),\n",
      "whereVaretheverticesofthehypergraph,Eoisthecompletesetofedges,and\n",
      "wheretheweightswv?v,arecomputedviaX(e)wv?v,wv?v,?\n",
      "f\n",
      "v,v?\n",
      "g\n",
      "?Eo\n",
      ".(6)e?E\n",
      "3\n",
      "Thissteprepresentstheprojectionweightmergingprocedure,whichsimply\n",
      "reducestothesumofweightsofallhyperedgeprojectionsonapairofvertices.\n",
      "Duetothelinearityofthevolumes(1)andboundaries(2)ofsetsSofvertices,\n",
      "foranyS?V,wehaveVolH(?S)?VolG(?S)???VolH(?S),VolH(S)?\n",
      "VolG(S)???VolH(S),\n",
      "(7)\n",
      "where??=maxe?E?(e).ApplyingspectralclusteringonG=(V,Eo,\n",
      "w)producesthedesiredpartition(S?,S??).Thenextresultisaconsequence\n",
      "ofcombiningtheboundsof(7)withtheapproximationguaranteesofspectral\n",
      "graphclustering(Theorem1[17]).Theorem3.1.Iftheoptimizationproblem\n",
      "(5)isfeasibleforallInH-hyperedgesandtheweightswv?vobtainedfrom(6)\n",
      "arenonnegativeforall\n",
      "f\n",
      "v,v?\n",
      "g\n",
      "?Eo,then??=NCutH(S?)\n",
      "(??)2?2?H.88where?Histheoptimalvalueofnormalizedcutofthe\n",
      "hypergraphH.(??)3?H?\n",
      "(8)\n",
      "Therearenoguaranteesthatthewv?vwillbenonnegative:Theoptimization\n",
      "problem(5)mayresultinsolutionsw(e)thatarenegative.Theperformanceof\n",
      "spectralmethodsinthepresenceofnegativeedgeweightsisnotwellunderstood\n",
      "[19,20];hence,itwouldbedesirabletohavetheweightswv?vgeneratedfrom\n",
      "(6)benonnegative.Unfortunately,imposingnonngativityconstraintsinthe\n",
      "optimizationproblemmayrenderitinfeasible.Inpractice,onemayuse(wv?v\n",
      ")+=max\n",
      "f\n",
      "wv?v,0\n",
      "g\n",
      "toP(e)removenegativeweights(otherchoices,suchas\n",
      "(wv?v)+=e(wv?v)+donotappeartoperformwell).Thischangeinvalidates\n",
      "thetheoreticalresultofTheorem3.1,butprovidessolutionswithverygood\n",
      "empiricalperformance.Theissuesdiscussedareillustratedbythenextexample.\n",
      "Example3.1.Lete=\n",
      "f\n",
      "1,2,3\n",
      "g\n",
      ",(we(\n",
      "f\n",
      "1\n",
      "g\n",
      "),we(\n",
      "f\n",
      "2\n",
      "g\n",
      "),we(\n",
      "f\n",
      "3\n",
      "g\n",
      "))=(0,0,1).The\n",
      "solutiontothe(e)(e)(e)weightoptimizationproblemis(?(e),w12,w13\n",
      ",w23)=(1,?1/2,1/2,1/2).Ifallcomponents(e)wareconstrainedtobe\n",
      "nonnegative,theoptimizationproblemisinfeasible.Nevertheless,theabove\n",
      "choiceofweightsisveryunlikelytobeencounteredinpractice,aswe(\n",
      "f\n",
      "1\n",
      "g\n",
      "),we\n",
      "(\n",
      "f\n",
      "2\n",
      "g\n",
      ")=0indicatesthatvertices1and2havenorelevantconnectionswithin\n",
      "thegivenhyperedgee,whilewe(\n",
      "f\n",
      "3\n",
      "g\n",
      ")=1indicatesthatvertex3isstrongly\n",
      "connectedto1and2,whichisacontradiction.Letusassume(e)(e)(e)next\n",
      "thatthenegativeweightissettozero.Then,weadjusttheweights((w12)+,\n",
      "w13,w23)=(0,1/2,1/2),whichproduceclusterings((1,3)(2))or((2,3)(1));\n",
      "bothhavezerocostsbasedonwe.Anotherproblemisthatarbitrarychoices\n",
      "forwemaycausetheoptimizationproblemtobeinfeasible(5)evenifnegative\n",
      "weightsofw(e)areallowed,asillustratedbythefollowingexample.Example\n",
      "5\n",
      "\n",
      "3.2.Lete=\n",
      "f\n",
      "1,2,3,4\n",
      "g\n",
      ",withwe(\n",
      "f\n",
      "1,4\n",
      "g\n",
      ")=we(\n",
      "f\n",
      "2,3\n",
      "g\n",
      ")=1andwe(S)=0\n",
      "forallother(e)choicesofsetsS.Toforcetheweightstozero,werequirewv?v\n",
      "=0forallpairsv?v,whichfailstoworkforwe(\n",
      "f\n",
      "1,4\n",
      "g\n",
      "),we(\n",
      "f\n",
      "2,3\n",
      "g\n",
      ").Fora\n",
      "hyperedgee,thedegreesoffreedomforweare2?(e)?1?1,astwovaluesofwe\n",
      "arewhiletheothervaluesarepairedupbysymmetry.When?(e)>3,we\n",
      "have?(e)<2?(e)?1?1,whichindicatesthattheproblemisoverdeter-\n",
      "mined/infeasible.2Inwhatfollows,weprovidetconditionsforthe\n",
      "optimizationproblemtohaveafeasiblesolutionwithnonnegativevaluesofthe\n",
      "weightsw(e).Also,weprovideconditionsfortheweightswethatresultina\n",
      "smallconstant??andhenceallowforquadraticapproximationsoftheopti-\n",
      "mumsolution.Ourresultsdependontheavailabilityofinformationaboutthe\n",
      "weightswe:Inpractice,theweightshavetobeinferredfromobservabledata,\n",
      "whichmaynottodeterminemorethantheweightofsingletonsorpairs\n",
      "ofelements.Onlythevaluesofwe(\n",
      "f\n",
      "v\n",
      "g\n",
      ")areknown.Inthissetting,weare\n",
      "onlygiveninformationabouthowmucheachnodecontributestoahigher-order\n",
      "relation,i.e.,weareonlygiventhevaluesofwe(\n",
      "f\n",
      "v\n",
      "g\n",
      "),v?V.Hence,wehave\n",
      "?(e)costs(equations)and?(e)?3variables,whichmakestheproblemunder-\n",
      "determinedandeasytosolve.Theoptimal?e=1isattainedbysettingfor\n",
      "alledges\n",
      "f\n",
      "v,v?\n",
      "g\n",
      "X11(e)wv?v=[we(\n",
      "f\n",
      "v\n",
      "g\n",
      ")+we(\n",
      "f\n",
      "?v\n",
      "g\n",
      ")]?we(\n",
      "f\n",
      "v0\n",
      "g\n",
      ").(9)\n",
      "?(e)?2(?(e)?1)(?(e)?2)0v?e\n",
      "Thecomponentsofwe(?)withpositivecotsin(3)areprecisely\n",
      "thoseassociatedwiththeendpointsofedgesv?v.Usingsimplealgebraic\n",
      "manipulations,onecanderivetheconditionsunder(e)whichthevalueswv?v\n",
      "arenonnegative,andthesearepresentedintheSupplementaryMaterial.4\n",
      "Thesolutionto(9)producesaperfectprojectionwith?(e)=1.Unfor-\n",
      "tunately,onecannotguaranteethatthesolutionisnonnegative.Hence,the\n",
      "questionofinterestistodetermineforwhattypesofcutscanonecandeviate\n",
      "fromaperfectprojectionbutensurethattheweightsarenonnegative.The\n",
      "proposedapproachistosettheunspvaluesofwe(?)sothattheweight\n",
      "functionbecomesesubmodular,whichguaranteesnonnegativeweightswv?v\n",
      "thatcanconstantlyapproximatewe(?),althoughwithalargerapproximation\n",
      "constant?.Submodularweightswe(S).Aspreviouslydiscussed,when?(e)\n",
      ">3,theoptimizationproblem(5)maynothaveanyfeasiblesolutionsforar-\n",
      "bitrarychoicesofweights.However,weshownextthatiftheweightsweare\n",
      "submodular,then(5)alwayshasanonnegativesolution.Westartbyrecalling\n",
      "theofasubmodularfunction.3.2.Afunctionwe:2e?\n",
      "R?0thatwe(S1)+we(S2)?we(S1?S2)+we(S1?S2)forall\n",
      "S1,S2?2e,\n",
      "istermedsubmodular.Theorem3.3.Ifweissubmodular,thenXwe(S)\n",
      "?(e)wv?v=1|\n",
      "f\n",
      "v,?v\n",
      "g\n",
      "?S|=12|S|(?(e)?|S|)e\n",
      "(10)\n",
      "S?2/\n",
      "f\n",
      "?,e\n",
      "g\n",
      "we(S)we(S)1|\n",
      "f\n",
      "v,?v\n",
      "g\n",
      "?S|=0?1|\n",
      "f\n",
      "v,?v\n",
      "g\n",
      "?S|=2?2(|S|+1)(?(e)?\n",
      "|S|?1)2(|S|?1)(?(e)?|S|+1)\n",
      "isnonnegative.For2??(e)?7,thefunctionaboveisafeasiblesolutionfor\n",
      "theoptimizationproblem(5)withparameters?(e)listedinTable1.Table1:\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feasiblevaluesof?(e)for?(e)|?(e)|?\n",
      "21\n",
      "31\n",
      "43/2\n",
      "52\n",
      "64\n",
      "76\n",
      "Theorem3.3alsoholdswhensomeweightsinthesetwearenotsp\n",
      "butmaybecompletedtosatisfysubmodularityconstraints(SeeExample3.3).\n",
      "Example3.3.Lete=\n",
      "f\n",
      "1,2,3,4\n",
      "g\n",
      ",(we(\n",
      "f\n",
      "1\n",
      "g\n",
      "),we(\n",
      "f\n",
      "2\n",
      "g\n",
      "),we(\n",
      "f\n",
      "3\n",
      "g\n",
      "),we(\n",
      "f\n",
      "4\n",
      "g\n",
      "))\n",
      "=(1/3,1/3,1,1).Solv(e)ing(9)yieldsw12=?1/9and?(e)=1.By\n",
      "completingthemissingcomponentsinweas(we(\n",
      "f\n",
      "1,2\n",
      "g\n",
      "),we(\n",
      "f\n",
      "1,3\n",
      "g\n",
      "),we(\n",
      "f\n",
      "1,\n",
      "4\n",
      "g\n",
      "))=(2/3,1,1)leadstosubmodularweights(Observethatcom(e)pletionsare\n",
      "notnecessarilyunique).Then,thesolutionof(10)givesw12=0and?(e)?(1,\n",
      "2/3],whichisclearlylargerthanone.Remark3.1.Itisworthpointingoutthat\n",
      "?=1when?(e)=3,whichassertsthathomogeneoustriangleclusteringmay\n",
      "beperformedviaspectralmethodsongraphswithoutanyweightprojection\n",
      "distortion[9].Theaboveresultsextendthisingtotheinhomogeneouscase\n",
      "whenevertheweightsaresubmodular.Inaddition,triangleclusteringbased\n",
      "onrandomwalks[21]maybeextendedtotheinhomogeneouscase.Also,(10)\n",
      "leadtoanoptimalapproximationratio?(e)ifwerestrictw(e)tobealinear\n",
      "mappingofwe,whichisformallystatednext.(e)\n",
      "Theorem3.4.Supposethatforallpairsof\n",
      "f\n",
      "v,v?\n",
      "g\n",
      "?Eo,wv?visalinear\n",
      "functionofwe,denotedby(e)wv?v=fv?v(we),where\n",
      "f\n",
      "fv?v\n",
      "gf\n",
      "v?v?E(e)\n",
      "g\n",
      "dependson?(e)butnotonwe.Then,when?(e)?7,theoptimalvaluesof\n",
      "?forthefollowingoptimizationproblemdependonlyon?(e),andareequalto\n",
      "thoselistedinTable1.min\n",
      "f\n",
      "fvv?\n",
      "gf\n",
      "v,?v\n",
      "g\n",
      "?Eo,?\n",
      "max\n",
      "submodularwe\n",
      "s.t.we(S)?\n",
      "?\n",
      "(11)\n",
      "Xv?S,?v?e/S\n",
      "fv?v(we)??we(S),\n",
      "forallS?2e.\n",
      "Remark3.2.Althoughwewereabletoprovefeasibility(Theorem3.3)and\n",
      "optimalityoflinearsolutions(Theorem3.4)onlyforsmallvaluesof?(e),we\n",
      "conjecturetheresultstobetrueforall?(e).5\n",
      "Thefollowingtheoremshowsthatiftheweightsweofhyperedgesinahy-\n",
      "pergrapharegeneratedfromgraphcutsofalatentweightedgraph,thenthe\n",
      "projectedweightsofhyperedgesareproportionaltothecorrespondingweights\n",
      "inthelatentgraph.Theorem3.5.SupposethatGe=(V(e),E(e),w(e))\n",
      "isalatentgraphthatgenerateshyperedgeP(e)weightsweaccordingtothe\n",
      "followingprocedure:foranyS?e,we(S)=v?S,?v?e/Swv?v.Then,?(e)\n",
      "(e)\n",
      "7\n",
      "\n",
      "equation(10)establishesthatwv?v=?(e)wv?v,forallv?v?E(e),\n",
      "with?(e)=\n",
      "2?(e)?2?(e)(?(e)?1).\n",
      "Theorem3.5establishesconsistencyofthelinearmap(10),andalsoshows\n",
      "thatthemin-maxoptimalapproximationratioforlinearfunctionsequals?(2?(e)\n",
      "/?(e)2).Anindependentlineofwork[22],basedonGomory-Hutrees(non-\n",
      "linear),establishedthatsubmodularfunctionsrepresentnonnegativesolutions\n",
      "oftheoptimizationproblem(5)with?(e)=?e?1.Therefore,anunrestricted\n",
      "solutionoftheoptimizationproblem(5)ensuresthat?(e)??e?1.\n",
      "Aspracticalapplicationsalmostexclusivelyinvolvehypergraphswithsmall,\n",
      "constant?(e),theGomory-Hutreeapproachinthiscaseissuboptimalinap-\n",
      "proximationratiocomparedto(10).Theexpression(10)canberewrittenas\n",
      "w?(e)=Mwe,whereMisamatrixthatonlydependson?(e).Hence,the\n",
      "projectedweightscanbecomputedinaveryntandsimplemanner,as\n",
      "opposedtoconstructingtheGomory-Hutreeorsolving(5)directly.Intherare\n",
      "casethatonehastodealwithhyperedgesforwhich?(e)islarge,theGomory-Hu\n",
      "treeapproachandasolutionof(5)maybepreferred.\n",
      "4\n",
      "RelatedWorkandDiscussion\n",
      "Onecontributionofourworkistointroducethenotionofaninhomogenous\n",
      "partitionofhyperedgesandanewhypergraphprojectionmethodthataccompa-\n",
      "niestheprocedure.Subsequentedgeweightmergingandspectralclusteringare\n",
      "standardlyusedinhypergraphclusteringalgorithms,andinparticularinZhou?s\n",
      "normalizedhypergraphcutapproach[11],CliqueExpansion,StarExpansion\n",
      "andCliqueAveraging[14].TheformulationclosesttooursisZhou?smethod\n",
      "[11].IntheaforementionedhypergraphclusteringmethodforH-hyperedges,\n",
      "eachhyperedgeeisassignedascalarweightweH.Fortheprojectionstep,\n",
      "ZhouusedweH/?(e)fortheweightofeachpairofendpointsofe.Ifweview\n",
      "theH-hyperedgeasanInH-hyperedgewithweightfunctionwe,wherewe(S)\n",
      "=weH|S|(?(e)?|S|)/?(e)forallS?2e,thenourofthevol-\n",
      "ume/costoftheboundary(2)isidenticalto(e)thatofZhou?s.Withthischoice\n",
      "ofwe,theoptimizationproblem(5)outputswv?v=weH/?(e),with(e)?=1,\n",
      "whicharethesamevaluesasthoseobtainedviaZhou?sprojection.Thedegree\n",
      "ofavertexPP?(e)in[11]isasdv=e?Eh(e,v)weH=e?E?(e)?1we\n",
      "(\n",
      "f\n",
      "v\n",
      "g\n",
      "),whichisaweightedsumofthewe(\n",
      "f\n",
      "v\n",
      "g\n",
      ")andthustakesaslightlydif-\n",
      "ferentformwhencomparedtoourAsamatteroffact,foruniform\n",
      "hypergraphs,thetwoformsaresame.Someotherhypergraphclusteringalgo-\n",
      "rithms,suchasCliqueexpansionandStarexpansion,asshownbyAgarwaletal.\n",
      "[23],representspecialcasesofourmethodforuniformhypergraphsaswell.The\n",
      "CliqueAveragingmethodrssubstantiallyfromalltheaforedescribedmeth-\n",
      "ods.Insteadofprojectingeachhyperedgeontoasubgraphandthencombining\n",
      "thesubgraphsintoagraph,thealgorithmperformsaone-shotprojectionofthe\n",
      "wholehypergraphontoagraph.Theprojectionisbasedona`2-minimization\n",
      "rule,whichmaynotallowforconstant-approximationsolutions.Itisunknown\n",
      "iftheresultoftheprocedurecanprovideaquadraticapproximationfortheop-\n",
      "timumsolution.CliqueAveragingalsohaspracticalimplementationproblems\n",
      "8\n",
      "\n",
      "andhighcomputationalcomplexity,asitisnecessarytosolvealinearregression\n",
      "withn2variableandn?(e)observations.Intherecentworkonnetworkmotif\n",
      "clustering[9],thehyperedgesarededucedfromagraphwheretheyrepresent\n",
      "socalledmotifs.Bensonet.al[9]provedthatifthemotifshavethreevertices,\n",
      "resultinginathree-uniformhypergraph,theirproposedalgorithmthe\n",
      "Cheegerinequalityformotifs2.Inthedescribedformulation,whencuttingan\n",
      "H-hyperedgewithweightweH,oneisrequiredtopayweH.Hence,recasting\n",
      "thismodelwithinoursetting,wearriveatinhomogenousweightswe(S)=2\n",
      "(e)weH,forallS?2e,forwhich(5)yieldswv?v=weH/(?(e)?1)and?(e)\n",
      "=b?4(e)c/(?(e)?1),2\n",
      "TheCheegerinequality[17]arisesinthecontextofminimizingtheconduc-\n",
      "tanceofagraph,whichisrelatedtothenormalizedcut.\n",
      "6\n",
      "identicaltothesolutionof[9].Furthermore,giventheresultofourTheorem\n",
      "3.1,onecanprovethatthealgorithmof[9]rsaquadratic-factorapproxima-\n",
      "tionformotifsinvolvingmorethanthreevertices,afactthatwasnotestablished\n",
      "intheoriginalwork[9].Alltheaforementionedalgorithmsessentiallylearnthe\n",
      "spectrumofLaplacianmatricesobtainedthroughhypergraphprojection.The\n",
      "ultimategoalofprojectionsistoavoidsolvingtheNP-hardproblemoflearn-\n",
      "ingthespectrumofcertainhypergraphLaplacians[24].Methodsthatdonot\n",
      "relyonhypergraphprojection,includingoptimizationwiththetotalvarianceof\n",
      "hypergraphs[12,13],tensorspectralmethods[25]andnonlinearLaplacianspec-\n",
      "tralmethods[26],havealsobeenreportedintheliterature.Thesetechniques\n",
      "wereexclusivelyappliedinhomogeneoussettings,andtheytypicallyhavehigher\n",
      "complexityandsmallerspectralgapsthantheprojection-basedmethods.Afu-\n",
      "turelineofworkistoinvestigatewhetherthesemethodscanbeextendedto\n",
      "theinhomogeneouscase.Yetanotherrelevantlineofworkpertainstothesta-\n",
      "tisticalanalysisofhypergraphpartitioningmethodsforgeneralizedstochastic\n",
      "blockmodels[27,28].\n",
      "5\n",
      "Applications\n",
      "Networkmotifclustering.Real-worldnetworksexhibitrichhigher-order\n",
      "connectivitypatternsfrequentlyreferredtoasnetworkmotifs[29].Motifsare\n",
      "specialsubgraphsofthegraphandmaybeviewedashyperedgesofahyper-\n",
      "graphoverthesamesetofvertices.Recentworkhasshownthathypergraph\n",
      "clusteringbasedonmotifsmaybeusedtolearnhiddenhigh-orderorganization\n",
      "patternsinnetworks[9,8,21].However,thisapproachtreatsallverticesand\n",
      "edgeswithinthemotifsinthesamemanner,andhenceignoresthefactthat\n",
      "eachstructuralunitwithinthemotifmayhaveatrelevanceort\n",
      "role.Asaresult,theverticesofthemotifsarepartitionedwithauniformcost.\n",
      "However,thisassumptionishardlyrealisticasinmanyrealnetworks,onlysome\n",
      "verticesofhigher-orderstructuresmayneedtobeclusteredtogether.Hence,\n",
      "inhomogenoushyperedgesareexpectedtoelucidatemoresubtlehigh-orderor-\n",
      "ganizationsofnetwork.WeillustratetheutilityofInH-partitionontheFlorida\n",
      "Bayfoodweb[30]andcompareourtothoseof[9].TheFloridaBay\n",
      "foodwebcomprises128verticescorrespondingtotspeciesororganisms\n",
      "9\n",
      "\n",
      "thatliveintheBay,and2106directededgesindicatingcarbonexchangebe-\n",
      "tweentwospecies.TheFoodwebessentiallyrepresentsalayeredwnetwork,\n",
      "ascarbonwsfromsocalledproducersorganismstohigh-levelpredators.Each\n",
      "layerofthenetworkconsistsof?similar?speciesthatplaythesameroleinthe\n",
      "foodchain.Clusteringofthespeciesmaybeperformedbyleveragingthelay-\n",
      "eredstructureoftheinteractions.Asanetworkmotif,weuseasubgraphof\n",
      "fourspecies,andcorrespondingly,fourverticesdenotedbyvi,fori=1,2,3,\n",
      "4.Themotifcaptures,amongothers,relationsbetweentwoproducersandtwo\n",
      "consumers:Theproducersv1andv2bothtransmitcarbonstov3andv4,and\n",
      "alltypesofcarbonwbetweenv1andv2,v3andv4areallowed(seeFigure\n",
      "2Left).Suchamotifisthesmalleststructuralunitthatcapturesthefactthat\n",
      "carbonexchangeoccursinuni-directionbetweenlayers,whileisallowedfreely\n",
      "withinlayers.Theinhomogeneoushyperedgecostsareassignedaccordingto\n",
      "thefollowingheuristics:First,asv1andv2sharetwocommoncarbonrecipi-\n",
      "ents(predators)whilev3andv4sharetwocommoncarbonsources(preys),we\n",
      "setwe(\n",
      "f\n",
      "vi\n",
      "g\n",
      ")=1fori=1,2,3,4,andwe(\n",
      "f\n",
      "v1,v2\n",
      "g\n",
      ")=0,we(\n",
      "f\n",
      "v1,v3\n",
      "g\n",
      ")=2,andwe(\n",
      "f\n",
      "v1,v4\n",
      "g\n",
      ")=2.Basedonthesolutionoftheoptimization\n",
      "problem(5),onecanconstructaweightedsubgraphwhosecostsofcutsmatch\n",
      "theinhomogeneouscosts,with?(e)=1.ThegraphisdepictedinFigure2\n",
      "(left).Ourapproachistoperformhierarchicalclusteringviaiterativeapplica-\n",
      "tionoftheInH-partitionmethod.Ineachiteration,weconstructahypergraph\n",
      "byreplacingthechosenmotifsubnetworkbyanhyperedge.Theresultisshown\n",
      "inFigure2.Atthelevel,wepartitionedthespeciesintothreeclusters\n",
      "correspondingtoproducers,primaryconsumersandsecondaryconsumers.The\n",
      "producerclusterishomogeneousinsofarthatitcontainsonlyproducers,a\n",
      "totalofnineofthem.Atthesecondlevel,wepartitionedtheobtainedprimary-\n",
      "consumerclusterintotwoclusters,oneofwhichalmostexclusivelycomprises\n",
      "invertebrates(28outof35),whiletheotheralmostexclusivelycomprisesforage\n",
      "Thesecondary-consumerclusterispartitionedintotwoclusters,oneof\n",
      "whichcomprisestop-levelpredators,whiletheotherclustermostlyconsistsof\n",
      "predatoryandbirds.Overall,werecoveredeclustersthatelayers\n",
      "rangingfromproducerstotop-levelconsumers.Itiseasytocheckthatthe\n",
      "producer,invertebrateandtop-levelpredatorclustersexhibithighfunctional\n",
      "similarityofspecies(>80%).Anexactfunctionalofforageand\n",
      "predatoryisnotknown,butourlayerednetworkappearstocapturean\n",
      "overwhelminglylargenumberofprey-predatorrelationsamongthesespecies.\n",
      "Amongthe1714edges,obtainedafterremovingisolatedverticesanddetritus\n",
      "speciesvertices,onlyeedgespointintheoppositedirectionfromahigherto\n",
      "alower-level7\n",
      "v3Projectionv1\n",
      "Motif:v1\n",
      "v2Producers\n",
      "Invertebrates\n",
      "1\n",
      "v2\n",
      "v4Primaryconsumers\n",
      "10\n",
      "\n",
      "Forage\n",
      "0\n",
      "v3\n",
      "0\n",
      "Motif(Benson?16):\n",
      "1\n",
      "0\n",
      "v4\n",
      "0\n",
      "Microfauna\n",
      "ProjectionPelagic\n",
      "Secondaryconsumers\n",
      "Predatory&Birds\n",
      "Top-??levelPredators\n",
      "Crabs&Benthic\n",
      "Macroinvertebrates\n",
      "Figure2:MotifclusteringintheFloridaBayfoodweb.Left:InHomoge-\n",
      "nouscase.Left-top:Hyperedge(networkmotif)&theweightedinducedsub-\n",
      "graph;Left-bottom:HierarchicalclusteringstructureandeclustersviaInH-\n",
      "partition.Theverticesbelongingtotclustersaredistinguishedbythe\n",
      "colorsofvertices.Edgeswithauni-direction(righttoleft)arecoloredblack\n",
      "whileotheredgesarekeptblue.Right:Homogenouspartitioning[9]withfour\n",
      "clusters.Greyverticesarenotconnectedbymotifsandthusclus-\n",
      "ter,twoofwhichgofrompredatorytoforageDetailedinformation\n",
      "aboutthespeciesandclustersisprovidedintheSupplementaryMaterial.In\n",
      "comparison,therelatedworkofBensonetal.[9]whichusedhomogenoushy-\n",
      "pergraphclusteringandtriangularmotifsreportedaverytclustering\n",
      "structure.Thecorrespondingclusterscoveredlessthanhalfofthespecies(62\n",
      "outof128)asmanyverticeswerenotconnectedbythetrianglemotif;incon-\n",
      "trast,127outof128verticeswerecoveredbyourchoiceofmotif.Weattribute\n",
      "thebetweenourresultsandtheresultsof[9]tothechoicesofthe\n",
      "networkmotif.Atrianglemotif,usedin[9]leavesalargenumberofvertices\n",
      "unclusteredandfailstoenforceahierarchicalnetworkstructure.Ontheother\n",
      "hand,ourfanmotifwithhomogeneousweightsproducesagiantclusterasit\n",
      "tiesalltheverticestogether,andthehierarchicaldecompositionisonlyrevealed\n",
      "whenthefanmotifisusedwithinhomogeneousweights.Inordertoidentify\n",
      "hierarchicalnetworkstructures,insteadofhypergraphclustering,onemayuse\n",
      "topologicalsortingtorankspeciesbasedontheircarbonws[31].Unfortu-\n",
      "nately,topologicalsortingcannotusebiologicalsideinformationandhencefails\n",
      "toautomaticallydeterminetheboundariesoftheclusters.Learningthe\n",
      "IndependenceStructureofRankingData.Learningprobabilisticmodelsfor\n",
      "rankingdatahasattractedtinterestinsocialandpoliticalsciencesas\n",
      "wellasinmachinelearning[32,33].Recently,aprobabilisticmodel,termedthe\n",
      "endencemodel,wasshowntoaccuratelydescribemanybenchmark\n",
      "rankeddatasets[34].Intheindependencemodel,onegeneratestwo\n",
      "rankingsovertwodisjointsetsofelementindependently,andthenshs\n",
      "11\n",
      "\n",
      "therankingstoarriveataninterleavedorder.Thestructurelearningproblem\n",
      "inthissettingreducestodistinguishingthetwocategoriesofelementsbased\n",
      "onlimitedrankingdata.Moreprecisely,letQbethesetofcandidatestobe\n",
      "ranked,with|Q|=n.Afullrankingisabijection?:Q?[n],andforan\n",
      "a?Q,?(a)denotesthepositionofcandidateaintheranking?.Weuse?(a)\n",
      "<(>)?(b)toindicatethataisrankedhigher(lower)thanbin?.IfS?Q,we\n",
      "use?S:S?[|S|]todenotetheranking?projectedontothesetS.Wealso\n",
      "useS(?),\n",
      "f\n",
      "?(a)|a?S\n",
      "g\n",
      "todenotethesubsetofpositionsofelementsinS.Let\n",
      "P(E)denotetheprobabilityoftheeventE.independenceassertsthat\n",
      "thereexistsaendentsetS?Q,suchthatforaranking?0\n",
      "over[n],0P(?=?0)=P(?S=?S0)P(?Q/S=?Q/S)P(S(?)=S(?0)).\n",
      "Supposethatwearegivenasetofrankings?=\n",
      "f\n",
      "?(1),?(2),...,?(m)\n",
      "g\n",
      "drawnindependentlyaccordingtosomeprobabilitydistributionP.IfPhasa\n",
      "endentsetS?,thestructurelearningproblemistoS?.In\n",
      "[34],thedescribedproblemwascastasanoptimizationproblemoverallpossible\n",
      "subsetsofQ,withtheobjectiveofminimizingtheKullback-Leiblerdivergence\n",
      "betweentherankingdistributionwithindependenceandtheempirical\n",
      "distributionof?[34].Aversionoftheoptimizationproblemreadsas\n",
      "XXargminF(S),Ii;j,k+Ii;j,k,(12)S?Q\n",
      "(i,j,k)??cross?S,S\n",
      "(i,j,k)??cross?S,S\n",
      "where?crossA,B,\n",
      "f\n",
      "(i,j,k)|i?A,j,k?B\n",
      "g\n",
      ",andwhereIi;j,kdenotesthe\n",
      "estimatedmutualinformationbetweenthepositionofthecandidateiandtwo\n",
      "?comparisoncandidates?j,k.If1?(j)<?(k)8\n",
      "f\n",
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14\n",
      "g\n",
      "FiannaF?ail\n",
      "f\n",
      "1,4,13\n",
      "g\n",
      "f\n",
      "2,3,5,6,7,8,9,10,11,12,14\n",
      "g\n",
      "...\n",
      "FineGael\n",
      "f\n",
      "2,5,6\n",
      "g\n",
      "f\n",
      "3,7,8,9,10,11,12,14\n",
      "g\n",
      "...\n",
      "Independent\n",
      "f\n",
      "7,8,9\n",
      "g\n",
      "f\n",
      "3,10,11,12,14\n",
      "g\n",
      "...\n",
      "1\n",
      "1\n",
      "0.9\n",
      "0.9\n",
      "0.8\n",
      "0.8\n",
      "0.7\n",
      "0.7\n",
      "SuccessRate\n",
      "Candidates1,4,132,5,63,7,8,910,11,12,14\n",
      "12\n",
      "\n",
      "SuccessRate\n",
      "PartyFiannaF?ilFineGaelIndependentOthers\n",
      "0.60.50.40.30.2\n",
      "0.60.50.4\n",
      "InH-Par-F.F.InH-Par-F.G.InH-Par-Ind.InH-Par-AllApar-F.F.Apar-F.G.\n",
      "Apar-Ind.Apar-All\n",
      "0.30.2\n",
      "0.1\n",
      "0.1\n",
      "0101\n",
      "10\n",
      "2\n",
      "10\n",
      "3\n",
      "0\n",
      "SampleComplexitym\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "Triple-SamplingProbabilityr\n",
      "Figure3:Electiondataset.Left-top:partiesandcandidates;Left-bottom:\n",
      "hierarchicalpartitioningstructureofIrishelectiondetectedbyInH-Par;Middle:\n",
      "SuccessratevsSampleComplexity;Right:SuccessratevsTriple-sampling\n",
      "Rate.denotestheindicatorfunctionoftheunderlyingevent,wemaywrite?\n",
      "Ii;j,k,I(?(i);1?(j)<?(k))=\n",
      "X\n",
      "X\n",
      "?(i)1?(j)<?(k)\n",
      "?P(?(i),1?(j)<?(k))?P(?(i),1?(j)<?(k))log,(13)?P(?(i))P(1?(j)<?(k))\n",
      "?denotesanestimateoftheunderlyingprobability.Ifiandj,karein\n",
      "tP?independentsets,theestimatedmutualinformation\n",
      "I(?(i);1?(j)<?(k))convergestozeroasthenumberofsamplesincreases.When\n",
      "thenumberofsamplesissmall,onemayusemutualinformationestimatorsde-\n",
      "scribedin[35,36,37].OnemayrecasttheaboveproblemasanInH-partition\n",
      "problemoverahypergraphwhereeachcandidaterepresentsavertexinthe\n",
      "hypergraph,andIi;j,krepresentstheinhomogeneouscostwe(\n",
      "f\n",
      "i\n",
      "g\n",
      ")?forthe\n",
      "hyperedgee=\n",
      "f\n",
      "i,j,k\n",
      "g\n",
      ".NotethatasmutualinformationI(?(i);1?(j)<?(k))is\n",
      "ingeneralasymmetric,onewouldnothavebeenabletouseH-partitions.The\n",
      "optimizationproblemreducestominSvolH(?S).Thetwooptimizationtasks\n",
      "aret,andweillustratenextthattheInH-partitionoutperformstheorig-\n",
      "inaloptimizationapproachAnchorsPartition(Apar)[34]bothonsyntheticdata\n",
      "andrealdata.Duetospacelimitations,syntheticdataandasubsetofthereal\n",
      "datasetresultsarelistedintheSupplementaryMaterial.Here,weanalyzedthe\n",
      "13\n",
      "\n",
      "IrishHouseofParliamentelectiondataset(2002)[38].Thedatasetconsistsof\n",
      "2490ballotsfullyranking14candidates.Thecandidateswerefromanumberof\n",
      "parties,whereFiannaF?il(F.F.)andFineGael(F.G.)arethetwolargest(and\n",
      "rival)Irishpoliticalparties.UsingInHpartition(InH-Par),onecansplitthe\n",
      "candidatesiterativelyintotwosets(SeeFigure3)whichyieldstomeaningful\n",
      "clustersthatcorrespondtolargeparties:\n",
      "f\n",
      "1,4,13\n",
      "g\n",
      "(F.F.),\n",
      "f\n",
      "2,5,6\n",
      "g\n",
      "(F.G.),\n",
      "f\n",
      "7,\n",
      "8,9\n",
      "g\n",
      "(Ind.).WecomparedInH-partitionwithAparbasedontheirperformance\n",
      "indetectingthesethreeclustersusingasmalltrainingset:Weindependently\n",
      "sampledmrankings100timesandexecutedbothalgorithmstopartitionthe\n",
      "setofcandidatesiteratively.Duringthepartitioningprocedure,?partysuccess?\n",
      "wasdeclaredifoneexactlydetectedoneofthethreepartyclusters(?F.F.?,\n",
      "?F.G.?&?Ind.?).?All?wasusedtodesignatethatallthreepartyclusters\n",
      "weredetectedcompletelycorrectly.InH-partitionoutperformsAparinrecov-\n",
      "eringtheclusterInd.andachievedcomparableperformanceforclusterF.F.,\n",
      "althoughitperformsalittleworsethanAparforclusterF.G.;InH-partition\n",
      "alsoerssuperioroverallperformancecomparedtoApar.Wealsocompared\n",
      "InH-partitionwithAParinthelargesampleregime(m=2490),usingonlya\n",
      "subsetoftriplecomparisons(hyperedges)sampledindependentlywithproba-\n",
      "bilityr(Thisstrategytlyreducesthecomplexityofbothalgorithms).\n",
      "Theaverageiscomputedover100independentruns.Theresultsareshownin\n",
      "Figure3,highlightingtherobustnessofInH-partitionwithrespecttomissing\n",
      "triples.AdditionaltestonrankingdataaredescribedintheSupplementary\n",
      "Material,alongwithnewresultsonsubspaceclustering,motionsegmentation\n",
      "andothers.\n",
      "6\n",
      "Acknowledgement\n",
      "Theauthorsgratefullyacknowledgemanyusefulsuggestionsbythereview-\n",
      "ers.Theyarealsoindebtedtothereviewersforprovidingmanyadditionaland\n",
      "relevantreferences.ThisworkwassupportedinpartbytheNSFgrantCCF\n",
      "1527636.\n",
      "9\n",
      "2References\n",
      "[1]A.K.Jain,M.N.Murty,andP.J.Flynn,?Dataclustering:areview,?ACM\n",
      "computingsurveys(CSUR),vol.31,no.3,pp.264?323,1999.[2]A.Y.Ng,M.\n",
      "I.Jordan,andY.Weiss,?Onspectralclustering:Analysisandanalgorithm,?in\n",
      "AdvancesinNeuralInformationProcessingSystems(NIPS),2002,pp.849?856.\n",
      "[3]S.R.Bul?andM.Pelillo,?Agame-theoreticapproachtohypergraphclus-\n",
      "tering,?inAdvancesinNeuralInformationProcessingSystems(NIPS),2009,\n",
      "pp.1571?1579.[4]M.LeordeanuandC.Sminchisescu,thypergraph\n",
      "clustering,?inInternationalConferenceonIntelligenceandStatistics\n",
      "(AISTATS),2012,pp.676?684.[5]H.Liu,L.J.Latecki,andS.Yan,?Robust\n",
      "clusteringasensemblesofyrelations,?inAdvancesinNeuralInformation\n",
      "ProcessingSystems(NIPS),2010,pp.1414?1422.[6]N.Bansal,A.Blum,and\n",
      "14\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.Chawla,?Correlationclustering,?inThe43rdAnnualIEEESymposiumon\n",
      "FoundationsofComputerScience(FOCS),2002,pp.238?247.[7]N.Ailon,M.\n",
      "Charikar,andA.Newman,?Aggregatinginconsistentinformation:rankingand\n",
      "clustering,?JournaloftheACM(JACM),vol.55,no.5,p.23,2008.[8]P.Li,\n",
      "H.Dau,G.Puleo,andO.Milenkovic,?Motifclusteringandoverlappingcluster-\n",
      "ingforsocialnetworkanalysis,?inIEEEConferenceonComputerCommuni-\n",
      "cations(INFOCOM),2017,pp.109?117.[9]A.R.Benson,D.F.Gleich,andJ.\n",
      "Leskovec,?Higher-orderorganizationofcomplexnetworks,?Science,vol.353,\n",
      "no.6295,pp.163?166,2016.[10]H.Yin,A.R.Benson,J.Leskovec,andD.F.\n",
      "Gleich,?Localhigher-ordergraphclustering,?inProceedingsofthe23rdACM\n",
      "InternationalConferenceonKnowledgeDiscoveryandDataMining(SIGKDD),\n",
      "2017,pp.555?564.[11]D.Zhou,J.Huang,andB.Sch?lkopf,?Learningwith\n",
      "hypergraphs:Clustering,andembedding,?inAdvancesinneural\n",
      "informationprocessingsystems,2007,pp.1601?1608.[12]M.Hein,S.Setzer,\n",
      "L.Jost,andS.S.Rangapuram,?Thetotalvariationonhypergraphs-learning\n",
      "onhypergraphsrevisited,?inAdvancesinNeuralInformationProcessingSys-\n",
      "tems(NIPS),2013,pp.2427?2435.[13]C.Zhang,S.Hu,Z.G.Tang,andT.\n",
      "H.Chan,?Re-revisitinglearningonhypergraphs:intervalandsub-\n",
      "gradientmethod,?inInternationalConferenceonMachineLearning(ICML),\n",
      "2017,pp.4026?4034.[14]S.Agarwal,J.Lim,L.Zelnik-Manor,P.Perona,\n",
      "D.Kriegman,andS.Belongie,?Beyondpairwiseclustering,?inIEEECon-\n",
      "ferenceonComputerVisionandPatternRecognition(CVPR),vol.2,2005,\n",
      "pp.838?845.[15]S.Kim,S.Nowozin,P.Kohli,andC.D.Yoo,?Higher-order\n",
      "correlationclusteringforimagesegmentation,?inAdvancesinNeuralInfor-\n",
      "mationProcessingSystems(NIPS),2011,pp.1530?1538.[16]H.Jeong,B.\n",
      "Tombor,R.Albert,Z.N.Oltvai,andA.-L.Barab?si,?Thelarge-scaleorgani-\n",
      "zationofmetabolicnetworks,?Nature,vol.407,no.6804,pp.651?654,2000.\n",
      "[17]F.R.Chung,?Fourproofsforthecheegerinequalityandgraphpartition\n",
      "algorithms,?inProceedingsofICCM,vol.2,2007,p.378.[18]J.Shiand\n",
      "J.Malik,?Normalizedcutsandimagesegmentation,?IEEETransactionson\n",
      "PatternAnalysisandMachineIntelligence,vol.22,no.8,pp.888?905,2000.\n",
      "[19]J.Kunegis,S.Schmidt,A.Lommatzsch,J.Lerner,E.W.DeLuca,andS.\n",
      "Albayrak,?Spectralanalysisofsignedgraphsforclustering,predictionandvi-\n",
      "sualization,?inSIAMInternationalConferenceonDataMining(ICDM),2010,\n",
      "pp.559?570.[20]A.V.Knyazev,?Signedlaplacianforspectralclusteringrevis-\n",
      "ited,?arXivpreprintarXiv:1701.01394,2017.[21]C.Tsourakakis,J.Pachocki,\n",
      "andM.Mitzenmacher,?Scalablemotif-awaregraphclustering,?arXivpreprint\n",
      "arXiv:1606.06235,2016.10\n",
      "[22]N.R.Devanur,S.Dughmi,R.Schwartz,A.Sharma,andM.Singh,?On\n",
      "theapproximationofsubmodularfunctions,?arXivpreprintarXiv:1304.4948,\n",
      "2013.[23]S.Agarwal,K.Branson,andS.Belongie,?Higherorderlearning\n",
      "withgraphs,?inInternationalConferenceonMachineLearning(ICML).ACM,\n",
      "2006,pp.17?24.[24]G.Li,L.Qi,andG.Yu,?Thez-eigenvaluesofasymmet-\n",
      "rictensoranditsapplicationtospectralhypergraphtheory,?NumericalLinear\n",
      "AlgebrawithApplications,vol.20,no.6,pp.1001?1029,2013.[25]A.R.Ben-\n",
      "son,D.F.Gleich,andJ.Leskovec,?Tensorspectralclusteringforpartitioning\n",
      "15\n",
      "\n",
      "higherordernetworkstructures,?inProceedingsofthe2015SIAMInterna-\n",
      "tionalConferenceonDataMining(ICDM),2015,pp.118?126.[26]A.Louis,\n",
      "?Hypergraphmarkovoperators,eigenvaluesandapproximationalgorithms,?in\n",
      "Proceedingsoftheforty-seventhannualACMsymposiumonTheoryofcom-\n",
      "puting(STOC),2015,pp.713?722.[27]D.GhoshdastidarandA.Dukkipati,\n",
      "?Consistencyofspectralpartitioningofuniformhypergraphsunderplantedpar-\n",
      "titionmodel,?inAdvancesinNeuralInformationProcessingSystems(NIPS),\n",
      "2014,pp.397?405.[28]??,?Consistencyofspectralhypergraphpartitioning\n",
      "underplantedpartitionmodel,?arXivpreprintarXiv:1505.01582,2015.[29]\n",
      "R.Milo,S.Shen-Orr,S.Itzkovitz,N.Kashtan,D.Chklovskii,andU.Alon,\n",
      "?Networkmotifs:simplebuildingblocksofcomplexnetworks,?Science,vol.\n",
      "298,no.5594,pp.824?827,2002.[30]?Floridabaytrophicexchangema-\n",
      "trix,?http://vlado.fmf.uni-lj.si/pub/networks/data/bio/foodweb/Florida.paj.\n",
      "[31]S.Allesina,A.Bodini,andC.Bondavalli,?Ecologicalsubsystemsviagraph\n",
      "theory:theroleofstronglyconnectedcomponents,?Oikos,vol.110,no.1,pp.\n",
      "164?176,2005.[32]P.Awasthi,A.Blum,O.andA.Vijayaraghavan,\n",
      "?Learningmixturesofrankingmodels,?inAdvancesinNeuralInformation\n",
      "ProcessingSystems(NIPS),2014,pp.2609?2617.[33]C.MeekandM.Meila,\n",
      "?Recursiveinversionmodelsforpermutations,?inAdvancesinNeuralInforma-\n",
      "tionProcessingSystems(NIPS),2014,pp.631?639.[34]J.Huang,C.Guestrin\n",
      "etal.,?Uncoveringtheindependencestructureofrankeddata,?Elec-\n",
      "tronicJournalofStatistics,vol.6,pp.199?230,2012.[35]J.Jiao,K.Venkat,\n",
      "Y.Han,andT.Weissman,?Maximumlikelihoodestimationoffunctionalsof\n",
      "discretedistributions,?IEEETransactionsonInformationTheory,vol.63,no.\n",
      "10,pp.6774?6798,2017.[36]Y.Bu,S.Zou,Y.Liang,andV.V.Veer-\n",
      "avalli,?EstimationofKLdivergence:optimalminimaxrate,?arXivpreprint\n",
      "arXiv:1607.02653,2016.[37]W.Gao,S.Oh,andP.Viswanath,?Demystifying\n",
      "k-nearestneighborinformationestimators,?inIEEEInternationalSym-\n",
      "posiumonInformationTheory(ISIT),2017,pp.1267?1271.[38]I.C.Gormley\n",
      "andT.B.Murphy,?Alatentspacemodelforrankdata,?inStatisticalNetwork\n",
      "Analysis:Models,Issues,andNewDirections.Springer,2007,pp.90?102.\n",
      "11\n",
      "16\n",
      "\n",
      "PP4968.pdf\n",
      "PP4968.pdf 14\n",
      "OnlineLearningofNonparametricMixture\n",
      "ModelsviaSequentialVariationalApproximation\n",
      "Authoredby:\n",
      "DahuaLin\n",
      "Abstract\n",
      "Relianceoncomputationallyexpensivealgorithmsforinferencehas\n",
      "beenlimitingtheuseofBayesiannonparametricmodelsinlargescale\n",
      "applications.Totacklethisproblem,weproposeaBayesianlearningal-\n",
      "gorithmforDPmixturemodels.Insteadoffollowingtheconventional\n",
      "paradigm{randominitializationplusiterativeupdate,wetakeanpro-\n",
      "gressiveapproach.Startingwithagivenprior,ourmethodrecursively\n",
      "transformsitintoanapproximateposteriorthroughsequentialvariational\n",
      "approximation.Inthisprocess,newcomponentswillbeincorporatedon\n",
      "thewhenneeded.ThealgorithmcanreliablyestimateaDPmix-\n",
      "turemodelinonepass,makingitparticularlysuitedforapplications\n",
      "withmassivedata.Experimentsonbothsyntheticdataandrealdatasets\n",
      "demonstrateremarkableimprovementon{ordersofmagnitude\n",
      "speed-upcomparedtothestate-of-the-art.\n",
      "1PaperBody\n",
      "Bayesiannonparametricmixturemodels[7]provideanimportantframeworkto\n",
      "describecomplexdata.Inthisfamilyofmodels,Dirichletprocessmixturemod-\n",
      "els(DPMM)[1,15,18]areamongthemostpopularinpractice.Asopposed\n",
      "totraditionalparametricmodels,DPMMallowsthenumberofcomponents\n",
      "tovaryduringinference,thusprovidinggreatyforexplorativeanaly-\n",
      "sis.Nonetheless,theuseofDPMMinpracticalapplications,especiallythose\n",
      "withmassivedata,hasbeenlimitedduetohighcomputationalcost.MCMC\n",
      "sampling[12,14]istheconventionalapproachtoBayesiannonparametricesti-\n",
      "mation.Withheavyrelianceonlocalupdatestoexplorethesolutionspace,they\n",
      "oftenshowslowmixing,especiallyonlargedatasets.Whereastheuseofsplit-\n",
      "mergemovesanddata-drivenproposals[9,17,20]hassubstantiallyimprovedthe\n",
      "mixingperformance,MCMCmethodsstillrequiremanypassesoveradataset\n",
      "toreachtheequilibriumdistribution.Variationalinference[4,11,19,22],anal-\n",
      "ternativeapproachbasedonmeanapproximation,hasbecomeincreasingly\n",
      "popularrecentlyduetobetterrun-timeperformance.Typicalvariationalmeth-\n",
      "odsfornonparametricmixturemodelsrelyonatruncatedapproximationofthe\n",
      "1\n",
      "\n",
      "stickbreakingconstruction[16],whichrequiresanumberofcomponents\n",
      "tobemaintainedanditerativelyupdatedduringinference.Thetruncationlevel\n",
      "areusuallysetconservativelytoensureapproximationaccuracy,incurringcon-\n",
      "siderableamountofunnecessarycomputation.TheeraofBigDatapresents\n",
      "newchallengesformachinelearningresearch.Manyrealworldapplicationsin-\n",
      "volvemassiveamountofdatathatevencannotbeaccommodatedentirelyin\n",
      "thememory.BothMCMCsamplingandvariationalinferencemaintaintheen-\n",
      "tireationandperformiterativeupdatesofmultiplepasses,whichare\n",
      "oftentooexpensiveforlargescaleapplications.Thischallengemotivatedus\n",
      "todevelopanewlearningmethodforBayesiannonparametricmodelsthatcan\n",
      "handlemassivedatatly.Inthispaper,weproposeanonlineBayesian\n",
      "learningalgorithmforgenericDPmixturemodels.Thisalgorithmdoesnot\n",
      "requirerandominitializationofcomponents.Instead,itbeginswiththeprior\n",
      "DP(??)andprogressivelytransformsitintoanapproximateposteriorofthe\n",
      "mixtures,withnewcomponentsintroducedontheasneeded.Basedon\n",
      "anewwayofvariationalapproximation,thealgorithmproceedssequentially,\n",
      "takinginonesampleatatimetomakethe1\n",
      "update.Wealsodevisespstepstopruneredundantcomponentsand\n",
      "mergesimilarones,thusfurtherimprovingtheperformance.Wetestedthe\n",
      "proposedmethodonsyntheticdataaswellastworealapplications:modeling\n",
      "imagepatchesandclusteringdocuments.Resultsshowempiricallythatthe\n",
      "proposedalgorithmcanreliablyestimateaDPmixturemodelinasinglepass\n",
      "overlargedatasets.\n",
      "2\n",
      "RelatedWork\n",
      "Recentyearswitnesslotsofdevotedtodevelopingtlearning\n",
      "algorithmsforBayesiannonparametricmodels.Animportantlineofresearch\n",
      "istoacceleratethemixinginMCMCthroughbetterproposals.JainandNeal\n",
      "[17]proposedtousesplit-mergemovestoavoidbeingtrappedinlocalmodes.\n",
      "Dahl[6]developedthesequentiallyallocatedsampler,wheresplitsarepro-\n",
      "posedbysequentiallyallocatingobservationstooneoftwosplitcomponents\n",
      "throughsequentialimportancesampling.Thismethodwasrecentlyextended\n",
      "forHDP[20]andBP-HMM[9].Therehasalsobeensubstantialadvancement\n",
      "invariationalinference.AtdevelopmentalongislineistheStochas-\n",
      "ticVariationalInference,aframeworkthatincorporatesstochasticoptimization\n",
      "withvariationalinference[8].Wangetal.[23]extendedthisframeworktothe\n",
      "non-parametricrealm,anddevelopedanonlinelearningalgorithmforHDP[18].\n",
      "WangandBlei[21]alsoproposedatruncation-freevariationalinferencemethod\n",
      "forgenericBNPmodels,whereasamplingstepisusedforupdatingatomas-\n",
      "signmentthatallowsnewatomstobecreatedonthe.BryantandSudderth\n",
      "[5]recentlydevelopedanonlinevariationalinferencealgorithmforHDP,using\n",
      "mini-batchtohandlestreamingdataandsplit-mergemovestoadapttruncation\n",
      "levels.TheytriedtotackletheproblemofonlineBNPlearningaswedo,but\n",
      "viaatapproach.First,weproposeagenericmethodwhiletheyfocuses\n",
      "ontopicmodels.Thedesignsarealsot?ourmethodstartsfromscratch\n",
      "andprogressivelyaddsnewcomponents.ItsoverallcomplexityisO(nK),where\n",
      "2\n",
      "\n",
      "nandKarenumberofsamplesandexpectednumberofcomponents.Bryant?s\n",
      "methodbeginswithrandominitializationandreliesonsplitsovermini-batchto\n",
      "createnewtopics,resultinginthecomplexityofO(nKT),whereTisthenum-\n",
      "berofiterationsforeachmini-batch.Thestemfromthetheoretical\n",
      "basis?ourmethodusessequentialapproximationbasedonthepredictivelaw,\n",
      "whiletheirsisanextensionofthestandardtruncation-basedmodel.Nottet\n",
      "al.[13]recentlyproposedamethod,calledVSUGS,forfastestimationofDP\n",
      "mixturemodels.Similartoouralgorithm,theVSUGSmethodproposedtakes\n",
      "asequentialupdatingapproach,butreliesonatapproximation.Partic-\n",
      "ularly,whatweapproximateisajointposterioroverbothdataallocationand\n",
      "modelparameters,whileVSUGSisbasedontheapproximatingtheposterior\n",
      "ofdataallocation.Also,VSUGSrequiresgatruncationlevelTinad-\n",
      "vance,whichmayleadtoinpractice(especiallyforlargedata).Our\n",
      "algorithmprovidesawaytotacklethis,andnolongerrequirestruncation.\n",
      "3\n",
      "NonparametricMixtureModels\n",
      "ThissectionprovideabriefreviewofDirichletProcessMixtureModel?\n",
      "oneofthemostwidelyusednonparametricmixturemodels.ADirichletPro-\n",
      "cess(DP),typicallydenotedbyDP(??)ischaracterizedbyaconcentration\n",
      "parameter?andabasedistribution?.Ithasbeenshownthatsamplepathsof\n",
      "aDParealmostsurelydiscrete[16],andcanbeexpressedasD=\n",
      "?X\n",
      "?k??k,\n",
      "with?k=vk\n",
      "k=1\n",
      "k?1Y\n",
      "vl,vk?Beta(1,?k),?k=1,2,....\n",
      "(1)\n",
      "l=1\n",
      "Thisisoftenreferredtoasthestickbreakingrepresentation,and?kiscalled\n",
      "anatom.SinceanatomcanberepeatedlygeneratedfromDwithpositive\n",
      "probability,thenumberofdistinctatomsisusuallylessthanthenumberof\n",
      "samples.TheDirichletProcessMixtureModel(DPMM)exploitsthisproperty,\n",
      "andusesaDPsampleasthepriorofcomponentparameters.Belowisaformal\n",
      "D?DP(??),\n",
      "?i??,xi?F(?|?i),?i=1,...,n.\n",
      "(2)\n",
      "Considerapartition\n",
      "f\n",
      "C1,...,CK\n",
      "g\n",
      "of\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "suchthat?iare\n",
      "identicalforalli?Ck,whichwedenoteby?k.Insteadofmaintaining?i\n",
      "explicitly,weintroduceanindicatorziforeachiwith2\n",
      "?i=?zi.Usingthisclusteringnotation,thisformulationcanberewritten\n",
      "equivalentlyasfollows:z1:n?CRP(?),?k??,?k=1,2,...Kxi?F\n",
      "(?|?zi),?i=1,2,...,n.(3)Here,CRP(?)denotesaChineseRestaurant\n",
      "Prior,whichisadistributionoverexchangeablepartitions.Itsprobabilitymass\n",
      "functionisgivenbyK?(?)?KYpCRP(z1:n|?)=?(|Ck|).(4)?(?+n)\n",
      "k=1\n",
      "3\n",
      "\n",
      "4\n",
      "VariationalApproximationofPosterior\n",
      "Generally,therearetwoapproachestolearningamixturemodelfromob-\n",
      "serveddata,namelyMaximumlikelihoodestimation(MLE)andBayesianlearn-\n",
      "ing.Sp,maximumlikelihoodestimationseeksanoptimalpointesti-\n",
      "mateof?,whileBayesianlearningaimstoderivetheposteriordistributionover\n",
      "themixtures.Bayesianlearningtakesintoaccounttheuncertaintyabout?,\n",
      "oftenresultinginbettergeneralizationperformancethanMLE.Inthispaper,\n",
      "wefocusonBayesianlearning.Inparticular,forDPMM,thepredictivedis-\n",
      "tributionofcomponentparameters,conditionedonasetofobservedsamples\n",
      "x1:n,isgivenby(5)p(?0|x1:n)=ED|x1:n[p(?0|D)].Here,ED|x1:n\n",
      "takestheexpectationw.r.t.p(D|x1:n).Inthissection,wederiveatractable\n",
      "approximationofthispredictivedistributionbasedonadetailedanalysisofthe\n",
      "posterior.4.1\n",
      "PosteriorAnalysis\n",
      "LetD?DP(??)and?1,...,?nbeiidsamplesfromD,\n",
      "f\n",
      "C1,...,CK\n",
      "g\n",
      "beapartitionof\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "suchthat?iforalli?Ckareidentical,and?k\n",
      "=?i?i?Ck.ThentheposteriordistributionofDremainsaDP,asD|?1:n\n",
      "?DP(????),where??=?+n,andK\n",
      "??=\n",
      "X|Ck|??+??.?+n?+nk\n",
      "(6)\n",
      "k=1\n",
      "Theatomsaregenerallyunobservable,andthereforeitismoreinteresting\n",
      "inpracticetoconsidertheposteriordistributionofDgiventheobservedsam-\n",
      "ples.Forthispurpose,wederivethelemmabelowthatprovidesaconstructive\n",
      "characterizationoftheposteriordistributiongivenboththeobservedsamples\n",
      "x1:nandthepartitionz.Lemma1.ConsidertheDPMMinEq.(3).Draw-\n",
      "ingasamplefromtheposteriordistributionp(D|z1:n,x1:n)isequivalentto\n",
      "constructingarandomprobabilitymeasureasfollows?0D0+\n",
      "KX\n",
      "?k??k,\n",
      "k=1\n",
      "withD0?DP(??),(?0,?1,...,?k)?Dir(?,m1,...,mK),?k?\n",
      "?|Ck.(7)QHere,mk=|Ck|,?|Ckisaposteriordistributiongivenby\n",
      "i.e.?|Ck(d?)??(d?)i?CkF(xi|?).Thislemmaimmediatelyfollowsfrom\n",
      "theTheorem2in[10]asDPisaspecialcaseofthesocalledNormalizedRandom\n",
      "MeasureswithIndependentIncrements(NRMI).Itisworthemphasizingthat\n",
      "p(D|x,z)isnolongeraDirichletprocess,asthelocationsoftheatoms?1,...\n",
      ",?Karenondeterministic,insteadtheyfollowtheposteriordistributions?|Ck\n",
      ".Bymarginalizingoutthepartitionz1:n,weobtaintheposteriordistribution\n",
      "p(D|x1:n):Xp(D|x1:n)=p(z1:n|x1:n)p(D|x1:n,z1:n).\n",
      "(8)\n",
      "z1:n(z)\n",
      "(z)\n",
      "4\n",
      "\n",
      "Let\n",
      "f\n",
      "C1,...,CK\n",
      "g\n",
      "bethepartitioncorrespondingtoz1:n,wehave(z)\n",
      "KYZYp(z1:n|x1:n)?pCRF(z1:n|?)?(d?k)F(xi|?k).k=1\n",
      "3\n",
      "(z)\n",
      "i?Ck\n",
      "(9)\n",
      "4.2\n",
      "VariationalApproximation\n",
      "ComputingthepredictivedistributionbasedonEq.(8)requiresenumerating\n",
      "allpossiblepartitions,whichgrowexponentiallyasnincreases.Totacklethis\n",
      "y,weresorttovariationalapproximation,thatis,tochooseatractable\n",
      "distributiontoapproximatep(D|x1:n,z1:n).Inparticular,weconsidera\n",
      "familyofrandomprobabilitymeasuresthatcanbeexpressedasfollows:nXY\n",
      "q(D|?,?)=?i(zi)q?(z)(D|z1:n).(10)z1:ni=1\n",
      "Here,\n",
      "(z)q?(D|z1:n)d\n",
      "isastochasticprocessconditionedonz1:n,edas\n",
      "q?(z)(D|z1:n)??0D0+\n",
      "KX\n",
      "?k??k,\n",
      "k=1(z)\n",
      "(z)\n",
      "withD0?DP(??),(?0,?1,...,?K)?Dir(?,m1,...,mK),?k??k\n",
      ".(11)d\n",
      "(z)\n",
      "Here,weuse?toindicatethatdrawingasamplefromq?isequivalentto\n",
      "constructingoneaccording(z)(z)totherighthandside.Inaddition,mk=\n",
      "|Ck|isthecardinalityofthek-thclusterw.r.t.z1:n,and?kisadistri-\n",
      "butionovercomponentparametersthatisindependentfromz.Thevariational\n",
      "constructioninEq.(10)and(11)issimilartoEq.(7)andQ(8),exceptfortwo\n",
      "t(1)p(z1:n|x1:n)isreplacedbyaproductdistribution\n",
      "i?i(zi),and(2)?|Ck,whichdependsonz1:n,isreplacedbyanindependent\n",
      "distribution?k.Withthisdesign,zifortiand?kfortkare\n",
      "independentw.r.t.q,thusresultinginatractablepredictivelawbelow:Letq\n",
      "bearandomprobabilitymeasuregivenbyEq.(10)and(11),thenKPnX?0\n",
      "0i=1?i(k)?(?)+?k(?0).(12)Eq(D|?,?)[p(?|D)]=?+n?+nk=1\n",
      "Theapproximateposteriorhastwosetsofparameters:?,(?1,...,?n)\n",
      "and?,(?1,...,?n).Withthisapproximation,thetaskofBayesianlearning\n",
      "reducestotheproblemoftheoptimalsettingoftheseparameterssuch\n",
      "thatq(D|?,?)bestapproximatesthetrueposteriordistribution.4.3\n",
      "SequentialApproximation\n",
      "TheproblemhereistodeterminethevalueofK.Astraightforward\n",
      "approachistoKtoalargenumberasinthetruncatedmethods.Thisway,\n",
      "however,wouldincursubstantialcomputationalcostsonunnecessarycompo-\n",
      "nents.Wetakeatapproachhere.Ratherthanrandomlyinitializing\n",
      "anumberofcomponents,webeginwithanemptymodel(i.e.K=1)\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andprogressivelythemodelassamplescomein,addingnewcomponents\n",
      "onthewhenneeded.Sp,whenthesamplex1isobserved,we\n",
      "introducethecomponentanddenotetheposteriorforthiscomponentby\n",
      "?1.Asthereisonlyonecomponentatthispoint,wehavez1=1,(1)i.e.?1\n",
      "(z1=1)=1,andtheposteriordistributionoverthecomponentparameteris\n",
      "?1(d?)??(d?)F(x1|?).Samplesarebroughtinsequentially.Inparticular,\n",
      "wecompute?i,andupdate?(i?1)to?iuponthearrivalofthei-thsamplexi\n",
      ".(i)\n",
      "(i)\n",
      "Supposewehave?=(?1,...,?i)and?(i)=(?1,...,?K\n",
      ")afterprocessingisamples.Toexplainxi+1,wecanuseeitheroftheK\n",
      "existingcomponentsorintroduceanewcomponent?k+1.Thentheposterior\n",
      "distributionofzi+1,?1,...,?K+1givenx1,...,xn,xn+1isp(zi+1,\n",
      "?1:K+1|x1:i+1)?p(zi+1,?1:K+1|x1:i)p(xi+1|zi+1,?1:K+1).(13)\n",
      "Usingthetractabledistributionq(?|?1:i,?(i))inEq.(10)toapproximate\n",
      "theposteriorp(?|x1:i),wegetp(zi+1,?1:K+1|x1:i+1)?q(zi+1|?1:i,\n",
      "?(i))p(xi+1|zi+1,?1:K+1).(i+1)\n",
      "(14)\n",
      "Then,theoptimalsettingsofqi+1and?thatminimizestheKullback-\n",
      "Leiblerdivergencebetweenq(zi+1,?1:K+1|q1:i+1,?(i+1))andtheap-\n",
      "proximateposteriorinEq.(14)aregivenasfollows:((i)R(i)wk?F(xi+1\n",
      "|?)?k(d?)(k?K),R?i+1?(15)??F(xi+1|?)?(d?)(k=K+1),4\n",
      "Algorithm1SequentialBayesianLearningofDPMM(forconjugatecases).\n",
      "Require:basemeasureparams:?,?0,observedsamples:x1,...,xn,and\n",
      "thresholdLetK=1,?1(1)=1,w1=?1,?1=?(x1),and?10=1.fori=2\n",
      ":ndoTi?T(xi),andbi?b(xi)(B(?k+Ti,?k0+?)?B(?k,?k0)?bi\n",
      "(k=1,...,K)marginallog-likelihood:hi(k)?B(?+Ti,?0+?)?B(?,\n",
      "?0)?bi(k=K+1)Phi(k)hi(l)?i(k)?wke/lwlefork=1,...,K\n",
      "+1withwK+1=?if?i(K+1)>thenwk?wk+?i(k),?k??k+?i(k)Ti\n",
      ",and?k0??k0+?i(k)?,fork=1,...,K0wK+1??i(K+1),?K+1?\n",
      "?i(K+1)Ti,and?K+1??i(K+1)?K?K+1elsePre-normalize?isuch\n",
      "thatKk=1?i(k)=1wk?wk+?i(k),?k??k+?i(k)Ti,and?k0??k0+\n",
      "?i(k)?,fork=1,...,Kendifendfor\n",
      "(i)\n",
      "withwk=\n",
      "Pi\n",
      "j=1\n",
      "?j(k),and(i+1)?k(d?)\n",
      "(Qi+1?(d?)j=1F(xj|?)?j(k)??(d?)F(xi+1|?)?i+1(k)\n",
      "(k?K),(k=K+1).\n",
      "(16)\n",
      "Discussion.Thereisakeydistinctionbetweenthisapproximationscheme\n",
      "andconventionalapproaches:Insteadofseekingtheapproximationofp(D|x1:n\n",
      "),whichisvery(Disandunnecessary(onlyanumberof\n",
      "componentsareuseful),wetrytoapproximatetheposteriorofasubset\n",
      "oflatentvariablesthataretrulyrelevantforprediction,namelyzand?1:K+1\n",
      "6\n",
      "\n",
      ".Thissequentialapproximationschemeintroducesanewcomponentforeach\n",
      "sample,resultinginncomponentsovertheentiredataset.This,however,is\n",
      "unnecessary.Weempiricallythatformostsamples,?i(K+1)isnegligi-\n",
      "ble,indicatingthatthesampleisadequatelyexplainedbyexistingcomponent,\n",
      "andthereisnoneedofnewcomponents.Inpractice,wesetasmallvalueand\n",
      "increaseKonlywhen?i(K+1)>.Thissimplestrategyisveryein\n",
      "controllingthemodelsize.\n",
      "5\n",
      "AlgorithmandImplementation\n",
      "ThissectiondiscussestheimplementationofthesequentialBayesianlearning\n",
      "algorithmundertwotcircumstances:(1)?andFareexponentialfamily\n",
      "distributionsthatformaconjuatepair,and(2)?isnotaconjugatepriorw.r.t.\n",
      "F.ConjugateCase.\n",
      "Ingeneral,when?isconjugatetoF,theycanbewrittenasfollows:\n",
      "?(d?|?,?0)=exp?T?(?)??0A(?)?B(?,?0)h(d?),\n",
      "F(x|?)=exp?(?)TT(x)??A(?)?b(x).\n",
      "(17)(18)\n",
      "0\n",
      "Here,thepriormeasure?hasapairofnaturalparameters:(?,?).Con-\n",
      "ditionedonasetofobservationsPnx1,...,xn,theposteriordistribution\n",
      "remainsinthesamefamilyas?withparameters(?+i=1T(xi),?0+n?).\n",
      "Inaddition,themarginallikelihoodisgivenbyZF(x|?)?(d?|?,?0)=exp\n",
      "(B(?+T(x),?0+?)?B(?,?0)?b(x)).(19)?\n",
      "Insuchcases,boththebasemeasure?andthecomponent-spposterior\n",
      "measures?kcanberepresentedusingthenaturalparameterpairs,whichwe\n",
      "denoteby(?,?0)and(?k,?k0).Withthisnotation,wederiveasequential\n",
      "learningalgorithmforconjugatecases,asshowninAlg1.Non-conjugateCase.\n",
      "Inpracticalmodels,itisnotuncommonthat?andFarenotaconjugatepair.\n",
      "Unlikeintheconjugatecasesdiscussedabove,thereexistnoformulastoupdate\n",
      "posterior5\n",
      "parametersortocomputemarginallikelihoodingeneral.Here,wepropose\n",
      "toaddressthisQnissueusingstochasticoptimization.Consideraposteriordis-\n",
      "tributiongivenbyp(?|x1:n)??(?)i=1F(xi|?).Astochasticoptimization\n",
      "methodtheMAPestimateof?throughupdatestepsasbelow:???+\n",
      "?i(??log?(?)+n??logF(xi|?)).\n",
      "(20)\n",
      "Thebasicideahereistousethegradientcomputedataparticularsample\n",
      "xitoapproximatethetrueprocedureconvergestoa(local)maximum,aslong\n",
      "asthestepsize?isatisfyP?gradient.ThisP?2?=?andi=1ii=1?i<?.\n",
      "Incorporatingthestochasticoptimizationmethodintoouralgorithm,weobtain\n",
      "avariantofAlg1.Thegeneralprocedureissimilar,exceptforthefollowing\n",
      "changes:(1)Itmaintainspointestimatesofthecomponentparametersinstead\n",
      "oftheposterior,whichwedenoteby??1,...,??K.(2)Itcomputesthe\n",
      "log-likelihoodashi(k)=logF(xi|??k).(3)Theestimatesofthecomponent\n",
      "parametersareupdatedusingtheformulabelow:(i)(i?1)??k???k+?i(??\n",
      "log?(?)+n?i(k)??logF(xi|?)).\n",
      "7\n",
      "\n",
      "Followingthecommonpracticeofstochasticoptimization,weset?i=i\n",
      "??\n",
      "(21)\n",
      "/nwith??(0.5,1].\n",
      "PruneandMerge.Asopposedtorandominitialization,componentscreated\n",
      "duringthissequentialconstructionareoftentrulyneeded,asthedecisionsof\n",
      "creatingnewcomponentsarebasedonknowledgeaccumulatedfromprevious\n",
      "samples.However,itisstillpossiblethatsomecomponentsintroducedatearly\n",
      "iterationswouldbecomelessusefulandthatmultiplecomponentsmaybesim-\n",
      "ilar.Wethusintroduceamechanismtoremoveundesirablecomponentsand\n",
      "mergesimilarones.(i)\n",
      "Weidentifyopportunitiestomakesuchadjustmentsbylookingattheweights.\n",
      "Letw?k=Pi(i)P(i)(i)wk/lwl(withwk=?(k))betherelativeweightofa\n",
      "componentatthei-thiteraj=1jtion.Oncetherelativeweightofacomponent\n",
      "dropsbelowasmallthreshold?r,weremoveittosaveunnecessarycomputa-\n",
      "tiononthiscomponentinthefuture.Thesimilaritybetweentwocomponents\n",
      "?kand?k0canbemeasuredintermsofthedistancebePitween?i(k)and?i\n",
      "(k0)overallprocessedsamples,asd?(k,k0)=i?1j=1|?j(k)??j(k0\n",
      ")|.Weincrement?i(k)to?i(k)+?i(k0)when?kand?0karemerged(i.e.\n",
      "d?(k,k0)<?d).Wealsomergetheassociatedtstatistics(forcon-\n",
      "jugatecase)ortakeanweightedaverageoftheparameters(fornon-conjugate\n",
      "case).Generally,thereisnoneedtoperformsuchchecksateveryiteration.\n",
      "SincecomputingthisdistancebetweenapairofcomponentstakesO(n),we\n",
      "proposetoexaminesimilaritiesatanO(i?K)-intervalsothattheamortized\n",
      "complexityismaintainedatO(nK).Discussion.Ascomparedtoexistingmeth-\n",
      "ods,theproposedmethodhasseveralimportantadvantages.First,itbuilds\n",
      "upthemodelonthe,thusavoidingtheneedofrandomlyinitializingaset\n",
      "ofcomponentsasrequiredbytruncation-basedmethods.Themodellearnedin\n",
      "thiswaycanbereadilyextended(e.g.addingmorecomponentsoradapting\n",
      "existingcomponents)whennewdataisavailable.Moreimportantly,thealgo-\n",
      "rithmcanlearnthemodelinonepass,withouttheneedofiterativeupdates\n",
      "overthedataset.ThisdistinguishesitfromMCMCmethodsandconventional\n",
      "variationallearningalgorithms,makingitagreatforlargescaleproblems.\n",
      "6\n",
      "Experiments\n",
      "Totesttheproposedalgorithm,weconductedexperimentsonbothsynthetic\n",
      "dataandrealworldapplications?modelingimagepatchesanddocumentclus-\n",
      "tering.AllalgorithmsareimplementedusingJulia[2],anewlanguageforhigh\n",
      "performancetechnicalcomputing.6.1\n",
      "SyntheticData\n",
      "First,westudythebehavioroftheproposedalgorithmonsyntheticdata.\n",
      "Sp,weconstructedadatasetcomprisedof10000samplesin9Gaussian\n",
      "clustersofunitvariance.Thedistancesbetweentheseclusterswerechosensuch\n",
      "thatthereexistsmoderateoverlapbetweenneighboringclusters.Theestimation\n",
      "oftheseGaussiancomponentsarebasedontheDPMMbelow:\n",
      "D?DP??N(0,?p2I),?i?D,xi?N(?i,?x2I).(22)6\n",
      "8\n",
      "\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "?2\n",
      "?2\n",
      "?4\n",
      "?4\n",
      "?8?8\n",
      "?5.5?6\n",
      "?6\n",
      "?6\n",
      "?4\n",
      "?2\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "?8?8\n",
      "?6\n",
      "?4\n",
      "?2\n",
      "CGS\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "TVF\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "?2\n",
      "9\n",
      "\n",
      "?2\n",
      "?4\n",
      "?4\n",
      "?6\n",
      "?8?8\n",
      "0\n",
      "jointlog?lik\n",
      "?6\n",
      "4\n",
      "x10\n",
      "?6.5?7?7.5?8\n",
      "?6\n",
      "?6\n",
      "?4\n",
      "?2\n",
      "0\n",
      "SVA\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "?8?8\n",
      "?6\n",
      "?4\n",
      "?2\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "SVA-PM\n",
      "?8.50\n",
      "Figure1:Gaussianclustersonsyntheticdataobtainedusingtmeth-\n",
      "ods.BothMC-SMandSVA-PMidenthe9clusterscorrectly.Theresult\n",
      "ofMC-SMisomittedhere,asitlooksthesameasSVA-PM.\n",
      "20\n",
      "40\n",
      "60minute\n",
      "80\n",
      "CGSMC?SMTVFSVASVA?PM100\n",
      "Figure2:Jointlog-likelihoodonsyntheticdataasfunctionsofrun-time.\n",
      "Thelikelihoodvalueswereevaluatedonaheld-outtestingset.(Besttoview\n",
      "withcolor)\n",
      "10\n",
      "\n",
      "Here,weset?=1,?p=100and?x=1.Wetestedthefollowingin-\n",
      "ferencealgorithms:CollapsedGibbssampling(CGS)[12],MCMCwithSplit-\n",
      "Merge(MC-SM)[6],Truncation-FreeVariationalInference(TFV)[21],Sequen-\n",
      "tialVariationalApproximation(SVA),anditsvariantSequentialVariational\n",
      "ApproximationwithPruneandMerge(SVA-PM).ForCGS,MC-SM,andTFV,\n",
      "weruntheupdatingproceduresiterativelyforonehour,whileforSVAandSVA-\n",
      "PM,werunonlyone-pass.Figure1showstheresultingcomponents.CGSand\n",
      "TFVyieldobviouslyredundantcomponents.Thiscorroboratesobservationsin\n",
      "previouswork[9].SuchnuisancesaretlyreducedinSVA,whichonly\n",
      "occasionallybringsinredundantcomponents.Thekeythatleadsto\n",
      "thisimprovementisthatCGSandTFVrelyonrandominitializationtoboot-\n",
      "strapthealgorithm,whichwouldinevitablyintroducesimilarcomponents,while\n",
      "SVAleveragesinformationgainedfromprevioussamplestodecidewhethernew\n",
      "componentsareneeded.BothMC-SMandSVA-PMproducedesiredmixtures,\n",
      "demonstratingtheimportanceofanexplicitmechanismtoremoveredundancy.\n",
      "Figure2plotsthetracesofjointlog-likelihoodsevaluatedonaheld-outsetof\n",
      "samples.WecanseethatSVA-PMquicklyreachestheoptimalsolutionina\n",
      "matterofseconds.SVAalsogetstoareasonablesolutionwithinseconds,and\n",
      "thentheprogressslowsdown.Withouttheprune-and-mergesteps,ittakes\n",
      "muchlongerforredundantcomponentstofadeout.MC-SMeventuallyreaches\n",
      "theoptimalsolutionaftermanyiterations.Methodsrelyingonlocalupdates,\n",
      "includingCGSandTFV,didnotevencomeclosetotheoptimalsolutionwithin\n",
      "onehour.Theseresultsclearlydemonstratethatourprogressivestrategy,which\n",
      "graduallyconstructsthemodelthroughaseriesofinformeddecisions,ismuch\n",
      "morecientthanrandominitializationfollowedbyiterativeupdating.6.2\n",
      "ModelingImagePatches\n",
      "Imagepatches,whichcapturelocalcharacteristicsofimages,playafunda-\n",
      "mentalroleinvariouscomputervisiontasks,suchasimagerecoveryandscene\n",
      "understanding.Manyvisionalgorithmsrelyonapatchdictionarytowork.It\n",
      "hasbeenacommonpracticeincomputervisiontouseparametricmethods(e.g.\n",
      "K-means)tolearnadictionaryofsize.Thisapproachistwhen\n",
      "largedatasetsareused.Itisalsotobeextendedwhennewdatawitha\n",
      "K.Totacklethisproblem,weappliedourmethodtolearnanonparametric\n",
      "dictionaryfromtheSUNdatabase[24],alargedatasetcomprisedofover130K\n",
      "images,whichcaptureabroadvarietyofscenes.Wedividedallimagesintotwo\n",
      "disjointsets:atrainingsetwith120Kimagesandatestingsetwith10K.We\n",
      "extracted2000patchesofsize32?32fromeachimage,andcharacterizeeach\n",
      "patchbya128-dimensionalSIFTfeature.Intotal,thetrainingsetcontains\n",
      "240Mfeaturevectors.WerespectivelyrunTFV,SVA,andSVA-SMtolearna\n",
      "DPMMfromthetrainingset,basedonthe7\n",
      "550\n",
      "?100avg.pred.log?lik\n",
      "avg.pred.log?lik\n",
      "500?120?140?160?180\n",
      "Figure3:ExamplesofimagepatcheclusterslearnedusingSVA-PM.Each\n",
      "rowcorrespondstoacluster.Wecanseesimilarpatchesareinthesamecluster.\n",
      "11\n",
      "\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "TVFSVASVA?PM8\n",
      "4504003503000\n",
      "2\n",
      "hour\n",
      "Figure4:\n",
      "Averageloglikelihoodonimagemodelingasfunctionsofrun-time.\n",
      "4\n",
      "6hour\n",
      "8\n",
      "TVFSVASVA?PM10\n",
      "Figure5:\n",
      "Averageloglikelihoodofdocumentclustersasfunctionsofrun-time.\n",
      "formulationgiveninEq.(22),andevaluatetheaveragepredictivelog-likelihood\n",
      "overthetestingsetasthemeasureofperformance.Figure3showsasmallsub-\n",
      "setofpatchclustersobtainedusingSVA-PM.Figure4comparesthetrajectories\n",
      "oftheaveragelog-likelihoodsobtainedusingtalgorithms.TFVtakes\n",
      "multipleiterationstomovefromarandomgurationtoasub-optimalone\n",
      "andgettrappedinalocaloptima.SVAsteadilyimprovesthepredictiveperfor-\n",
      "manceasitseesmoresamples.Wenoticeinourexperimentsthatevenwithout\n",
      "anexplicitredundancy-removalmechanism,someunnecessarycomponentscan\n",
      "stillgetremovedwhentheirrelativeweightsdecreasesandbecomesnegligible.\n",
      "SVM-PMacceleratesthisprocessbyexplicitlymergingsimilarcomponents.6.3\n",
      "DocumentClustering\n",
      "Next,weapplytheproposedmethodtoexplorecategoriesofdocuments.\n",
      "Unlikestandardtopicmodelingtask,thisisahigherlevelapplicationthatbuilds\n",
      "ontopofthetopicrepresentation.Sp,weobtainacollectionof\n",
      "mtopicsfromasubsetofdocuments,andcharacterizealldocumentsbytopic\n",
      "proportions.Weassumethatthetopicproportionvectorisgeneratedfroma\n",
      "category-spDirichletdistribution,asfollowsD?DP(??Dirsym(?p)),\n",
      "?i?D,xi?Dir(?x?i).\n",
      "(23)\n",
      "Here,thebasemeasureisasymmetricDirichletdistribution.Togeneratea\n",
      "document,wedrawameanprobabilityvector?ifromD,andgeneratesthetopic\n",
      "proportionvectorxifromDir(?x?i).Theparameter?xisadesignparameter\n",
      "thatcontrolshowfarximaydeviatefromthecategoryspcenter?i.Note\n",
      "thatthisisnotaconjugatemodel,andweusestochasticoptimizationinstead\n",
      "ofBayesianupdatesinSVA(seesection5).Weperformedtheexperimentson\n",
      "theNewYorkTimesdatabase,whichcontainsabout1.8Marticlesfromyear\n",
      "1987to2007.Weprunedthevocabularyto5000wordsbyremovingstopwords\n",
      "andthosewithlowTF-IDFscores,andobtained150topicsbyrunningLDA\n",
      "[3]onasubsetof20Kdocuments.Then,eachdocumentisrepresentedbya\n",
      "150-dimensionalvectoroftopicproportions.Weheldout10Kdocumentsfor\n",
      "12\n",
      "\n",
      "testingandusetheremainingtotraintheDPMM.WecomparedSVA,SVA-\n",
      "PM,andTVF.Thetracesoflog-likelihoodvaluesareshowninFigure5.We\n",
      "observesimilartrendsasabove:SVAandSVA-PMattainsbettersolutionmore\n",
      "quickly,whileTVFislesstandisprunetobeingtrappedinlocalmaxima.\n",
      "Also,TVFtendstogeneratemorecomponentsthannecessary,whileSVA-PM\n",
      "maintainsabetterperformanceusingmuchlesscomponents.\n",
      "7\n",
      "Conclusion\n",
      "WepresentedanonlineBayesianlearningalgorithmtoestimateDPmixture\n",
      "models.Theproposedmethoddoesnotrequirerandominitialization.Instead,\n",
      "itcanreliablyandtlylearnaDPMMfromscratchthroughsequential\n",
      "approximationinasinglepass.Thealgorithmtakesindatainastreaming\n",
      "fashion,andthuscanbeeasilyadaptedtonewdata.Experimentsonbothsyn-\n",
      "theticdataandrealapplicationshavedemonstratedthatouralgorithmachieves\n",
      "remarkablespeedup?itcanattainnearlyoptimalwithinseconds\n",
      "orminutes,whilemainstreammethodsmaytakehoursorevenlonger.Itis\n",
      "worthnotingthattheapproximationisderivedbasedonthepredictivelawof\n",
      "DPMM.Itisaninterestingfuturedirectiontoinvestigatehowitcanbegener-\n",
      "alizedtoabroaderfamilyofBNPmodels,suchasHDP,Pitman-Yorprocesses,\n",
      "andNRMIs[10].8\n",
      "2References\n",
      "[1]C.Antoniak.Mixturesofdirichletprocesseswithapplicationstobayesian\n",
      "nonparametricproblems.TheAnnalsofStatistics,2(6):1152?1174,1974.[2]\n",
      "Bezanson,StefanKarpinski,ViralB.Shah,andAlanEdelman.Julia:A\n",
      "fastdynamiclanguagefortechnicalcomputing.CoRR,abs/1209.5145,2012.\n",
      "[3]DavidBlei,NgAndrew,andMichaelJordan.Latentdirichletallocation.\n",
      "JournalofMachineLearningResearch,3:993?1022,2003.[4]DavidM.Blei\n",
      "andMichaelI.Jordan.VariationalmethodsfortheDirichletprocess.InProc.\n",
      "ofICML?04,2004.[5]MichaelBryantandErikSudderth.Trulynonparamet-\n",
      "riconlinevariationalinferenceforhierarchicaldirichletprocesses.InProc.of\n",
      "NIPS?12,2012.[6]DavidB.Dahl.Sequentially-allocatedmerge-splitsampler\n",
      "forconjugateandnonconjugatedirichletprocessmixturemodels,2005.[7]Nils\n",
      "LidHjort,ChrisHolmes,PeterMuller,andStephenG.Walker.BayesianNon-\n",
      "parametrics:PrinciplesandPractice.CambridgeUniversityPress,2010.[8]\n",
      "MattDavidM.Blei,ChongWang,andJohnPaisley.Stochasticvari-\n",
      "ationalinference.arXiveprints,1206.7501,2012.[9]MichaelC.Hughes,Emily\n",
      "B.Fox,andErikB.Sudderth.Eectivesplit-mergemontecarlomethodsfor\n",
      "nonparametricmodelsofsequentialdata.2012.[10]LancelotF.James,Antonio\n",
      "Lijoi,andIgorPr?unster.Posterioranalysisfornormalizedrandommeasures\n",
      "withindependentincrements.ScaninavianJournalofStats,36:76?97,2009.\n",
      "[11]KenichiKurihara,MaxWelling,andYeeWhyeTeh.Collapsedvariational\n",
      "dirichletprocessmixturemodels.InProc.ofIJCAI?07,2007.[12]Radford\n",
      "M.Neal.MarkovChainSamplingMethodsforDirichletProcessMixtureMod-\n",
      "13\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "els.Journalofcomputationalandgraphicalstatistics,9(2):249?265,2000.[13]\n",
      "DavidJ.Nott,XiaoleZhang,ChristopherYau,andAjayJasra.Asequentialal-\n",
      "gorithmforfastofdirichletprocessmixturemodels.InArxiv:1301.2897,\n",
      "2013.[14]IanPorteous,AlexIhler,PadhraicSmyth,andMaxWelling.Gibbs\n",
      "Samplingfor(Coupled)niteMixtureModelsintheStick-breakingRepre-\n",
      "sentation.InProc.ofUAI?06,2006.[15]CarlEdwardRasmussen.The\n",
      "GaussianMixtureModel.InProc.ofNIPS?00,2000.[16]JayaramSethura-\n",
      "man.Aconstructiveofdirichletpriors.StatisticalSinica,4:639?650,\n",
      "1994.[17]S.JainandR.M.Neal.Asplit-mergemarkovchainmontecarlopro-\n",
      "cedureforthedirichletprocessmixturemodel.JournalofComputationaland\n",
      "GraphicalStatistics,13(1):158?182,2004.[18]YeeWhyeTeh,MichaelI.Jordan,\n",
      "MatthewJ.Beal,andDavidM.Blei.HierarchicalDirichletProcesses.Journal\n",
      "oftheAmericanStatisticalAssociation,101(476):1566?1581,2007.[19]Y.W.\n",
      "Teh,K.Kurihara,andMaxWelling.CollapsedVariationalInferenceforHDP.\n",
      "InProc.ofNIPS?07,volume20,2007.[20]ChongWangandDavidBlei.A\n",
      "split-mergemcmcalgorithmforthehierarchicaldirichletprocess.arXiveprints,\n",
      "1201.1657,2012.[21]ChongWangandDavidBlei.Truncation-freestochastic\n",
      "variationalinferenceforbayesiannonparametricmodels.InProc.ofNIPS?12,\n",
      "2012.[22]ChongWangandDavidMBlei.VariationalInferencefortheNested\n",
      "ChineseRestaurantProcess.InProc.ofNIPS?09,2009.[23]ChongWang,\n",
      "JohnPaisley,andDavidBlei.Onlinevariationalinferenceforthehierarchical\n",
      "dirichletprocess.InAISTATS?11,2011.[24]J.Xiao,J.Hays,K.Ehinger,\n",
      "A.Oliva,andA.Torralba.Sundatabase:Large-scalescenerecognitionfrom\n",
      "abbeytozoo.InProc.ofCVPR?10,2010.\n",
      "9\n",
      "14\n",
      "\n",
      "PP7078.pdf\n",
      "PP7078.pdf 12\n",
      "HashEmbeddingsforcientWord\n",
      "Representations\n",
      "Authoredby:\n",
      "OleWinther\n",
      "DanTitoSvenstrup\n",
      "JonasHansen\n",
      "Abstract\n",
      "Wepresenthashembeddings,antmethodforrepresenting\n",
      "wordsinacontinuousvectorform.Ahashembeddingmaybeseenas\n",
      "aninterpolationbetweenastandardwordembeddingandawordembed-\n",
      "dingcreatedusingarandomhashfunction(thehashingtrick).Inhash\n",
      "embeddingseachtokenisrepresentedby$k$$d$-dimensionalembeddings\n",
      "vectorsandone$k$dimensionalweightvector.The$d$dimensional\n",
      "representationofthetokenistheproductofthetwo.Ratherthan\n",
      "theembeddingvectorsforeachtokentheseareselectedbythehashing\n",
      "trickfromasharedpoolof$B$embeddingvectors.Ourexperimentsshow\n",
      "thathashembeddingscaneasilydealwithhugevocabulariesconsistingof\n",
      "millionstokens.Whenusingahashembeddingthereisnoneedtocreate\n",
      "adictionarybeforetrainingnortoperformanykindofvocabularyprun-\n",
      "ingaftertraining.Weshowthatmodelstrainedusinghashembeddings\n",
      "exhibitatleastthesamelevelofperformanceasmodelstrainedusingreg-\n",
      "ularembeddingsacrossawiderangeoftasks.Furthermore,thenumber\n",
      "ofparametersneededbysuchanembeddingisonlyafractionofwhatis\n",
      "requiredbyaregularembedding.Sincestandardembeddingsandembed-\n",
      "dingsconstructedusingthehashingtrickareactuallyjustspecialcasesof\n",
      "ahashembedding,hashembeddingscanbeconsideredanextensionand\n",
      "improvementovertheexistingregularembeddingtypes.\n",
      "1PaperBody\n",
      "Contemporaryneuralnetworksrelyonlossfunctionsthatarecontinuousinthe\n",
      "model?sparametersinordertobeabletocomputegradientsfortraining.For\n",
      "thisreason,anydatathatwewishtofeedthroughthenetwork,evendatathat\n",
      "isofadiscretenatureinitsoriginalformwillbetranslatedintoacontinuous\n",
      "form.Fortextualinputitoftenmakessensetorepresenteachdistinctwordor\n",
      "phrasewithadensereal-valuedvectorinRn.Thesewordvectorsaretrained\n",
      "eitherjointlywiththerestofthemodel,orpre-trainedonalargecorpusbe-\n",
      "1\n",
      "\n",
      "forehand.Forlargedatasetsthesizeofthevocabularycaneasilybeinthe\n",
      "orderofhundredsofthousands,addingmillionsorevenbillionsofparameters\n",
      "tothemodel.Thisproblemcanbeespeciallyseverewhenn-gramsareallowed\n",
      "astokensinthevocabulary.Forexample,thepre-trainedWord2Vecvectors\n",
      "fromGoogle(Mih?ltz,2016)hasavocabularyconsistingof3millionwords\n",
      "andphrases.Thismeansthateventhoughtheembeddingsizeismoderately\n",
      "small(300dimensions),thetotalnumberofparametersisclosetoonebillion.\n",
      "31stConferenceonNeuralInformationProcessingSystems(NIPS2017),Long\n",
      "Beach,CA,USA.\n",
      "Theembeddingsizeproblemcausedbyalargevocabularycanbesolvedin\n",
      "severalways.Eachofthemethodshavesomeadvantagesandsomedrawbacks:\n",
      "1.Ignoreinfrequentwords.Inmanycases,themajorityofatextismadeupofa\n",
      "smallsubsetofthevocabulary,andmostwordswillonlyappearveryfewtimes\n",
      "(Zipf?slaw(Manningetal.,1999)).Byignoringanythingbutmostfrequent\n",
      "words,andsometimesstopwordsaswell,itispossibletopreservemostofthe\n",
      "textwhiledrasticallyreducingthenumberofembeddingvectorsandparame-\n",
      "ters.However,foranygiventask,thereisariskofremovingtoomuchortolittle.\n",
      "Manyfrequentwords(besidesstopwords)areunimportantandsometimeseven\n",
      "stopwordscanbeofvalueforaparticulartask(e.g.atypicalstopwordsuch\n",
      "as?and?whentrainingamodelonacorpusoftextsaboutlogic).Conversely,\n",
      "forsomeproblems(e.g.specializeddomainssuchasmedicalsearch)rarewords\n",
      "mightbeveryimportant.2.Removenon-discriminativetokensaftertraining.\n",
      "Forsomemodelsitispossibletoperformtfeaturepruningbasedone.g.\n",
      "entropy(Stolcke,2000)orbyonlyretainingtheKtokenswithhighestnorm\n",
      "(Joulinetal.,2016a).Thisreductioninvocabularysizecanleadtoadecrease\n",
      "inperformance,butinsomecasesitactuallyavoidssomeovandin-\n",
      "creasesperformance(Stolcke,2000).Formanymodels,however,suchpruningis\n",
      "notpossible(e.g.foron-linetrainingalgorithms).3.Compresstheembedding\n",
      "vectors.Lossycompressiontechniquescanbeemployedtoreducetheamount\n",
      "ofmemoryneededtostoreembeddingvectors.Onesuchmethodisquantiza-\n",
      "tion,whereeachvectorisreplacedbyanapproximationwhichisconstructed\n",
      "asasumofvectorsfromapreviouslydeterminedsetofcentroids(Joulinetal.,\n",
      "2016a;Jegouetal.,2011;Grayand1998).Forsomeproblems,such\n",
      "asonlinelearning,theneedforcreatingadictionarybeforetrainingcanbea\n",
      "nuisance.Thisisoftensolvedwithfeaturehashing,whereahashfunctionis\n",
      "usedtoassigneachtokenw?Ttooneofasetof?buckets?\n",
      "f\n",
      "1,2,...\n",
      "B\n",
      "g\n",
      ",eachofwhichhasitsownembeddingvector.Sincethegoalofhashingisto\n",
      "reducethedimensionalityofthetokenspaceT,wenormallyhavethatB|T\n",
      "|.Thisresultsinmanytokens?colliding?witheachotherbecausetheyareas-\n",
      "signedtothesamebucket.Whenmultipletokenscollide,theywillgetthesame\n",
      "vectorrepresentationwhichpreventsthemodelfromdistinguishingbetweenthe\n",
      "tokens.Eventhoughsomeinformationislostwhentokenscollide,themethod\n",
      "oftenworkssurprisinglywellinpractice(Weinbergeretal.,2009).Oneobvious\n",
      "improvementtothefeaturehashingmethoddescribedabovewouldbetolearn\n",
      "anoptimalhashfunctionwhereimportanttokensdonotcollide.However,since\n",
      "ahashfunctionhasadiscretecodomain,itisnoteasytooptimizeusinge.g.\n",
      "2\n",
      "\n",
      "gradientbasedmethodsusedfortrainingneuralnetworks(KulisandDarrell,\n",
      "2009).Themethodproposedinthisarticleisanextensionoffeaturehashing\n",
      "whereweusekhashfunctionsinsteadofasinglehashfunction,andthenusek\n",
      "trainableparametersforeachwordinordertochoosethe?best?hashfunction\n",
      "forthetokens(oractuallythebestcombinationofhashfunctions).Wecallthe\n",
      "resultingembeddinghashembedding.Asweexplaininsection3,embeddings\n",
      "constructedbybothfeaturehashingandstandardembeddingscanbeconsid-\n",
      "eredspecialcasesofhashembeddings.Ahashembeddingisanthybrid\n",
      "betweenastandardembeddingandanembeddingcreatedusingfeaturehash-\n",
      "ing,i.e.ahashembeddinghasalloftheadvantagesofthemethodsdescribed\n",
      "above,butnoneofthedisadvantages:?Whenusinghashembeddingsthere\n",
      "isnoneedforcreatingadictionarybeforehandandthemethodcanhandlea\n",
      "dynamicallyexpandingvocabulary.?Ahashembeddinghasamechanismca-\n",
      "pableofimplicitvocabularypruning.?Hashembeddingsarebasedonhashing\n",
      "buthasatrainablemechanismthatcanhandleproblematiccollisions.?Hash\n",
      "embeddingsperformsomethingsimilartoproductquantization.Butinsteadof\n",
      "allofthetokenssharingasinglesmallcodebook,eachtokenhasaccesstoafew\n",
      "elementsinaverylargecodebook.Usingahashembeddingtypicallyresultsin\n",
      "areductionofparametersofseveralordersofmagnitude.Sincethebulkofthe\n",
      "modelparametersoftenresidesintheembeddinglayer,thisreductionof2\n",
      "inputtoken\n",
      "hashfunctions\n",
      "componentvectors\n",
      "H1(?horse?)=\n",
      "importanceparameters\n",
      "hashvector\n",
      "e??horse?\n",
      "p1?horse?\n",
      "H2(?horse?)=?horse?\n",
      "p2?horse?\n",
      "P\n",
      "...pk?horse?\n",
      "Hk(?horse?)=\n",
      "Figure1:Illustrationofhowtobuildthehashvectorfortheword?horse?.\n",
      "Theoptionalstepofconcatenatingthevectorofimportanceparametersto\n",
      "e??horse?hasbeenomitted.Thesizeofcomponentvectorsintheillustra-\n",
      "tionisd=4.parametersopensupfore.g.awideruseofe.g.ensemble\n",
      "methodsorlargedimensionalityofwordvectors.\n",
      "2\n",
      "RelatedWork\n",
      "Argerichetal.(2016)proposedatypeofembeddingthatisbasedonhash-\n",
      "ingandwordco-occurrenceanddemonstratesthatcorrelationsbetweenthose\n",
      "embeddingvectorscorrespondtothesubjectivejudgementofwordsimilarity\n",
      "byhumans.Ultimately,itisacleverreductionintheembeddingsizesofword\n",
      "co-occurrencebasedembeddings.ReisingerandMooney(2010)andsincethen\n",
      "Huangetal.(2012)haveusedmultipletwordembeddings(prototypes)\n",
      "3\n",
      "\n",
      "forthesamewordsforrepresentingtpossiblemeaningsofthesame\n",
      "words.Conversely,Baietal.(2009)haveexperimentedwithhashingandtreat-\n",
      "ingwordsthatco-occurfrequentlyasthesamefeatureinordertoreducedimen-\n",
      "sionality.Huangetal.(2013)haveusedbagsofeitherbi-gramsortri-gramsof\n",
      "lettersofinputwordstocreatefeaturevectorsthataresomewhatrobusttonew\n",
      "wordsandminorspellingAnotherapproachemployedbyZhanget\n",
      "al.(2015);XiaoandCho(2016);Conneauetal.(2016)istouseinputsthat\n",
      "representsub-wordunitssuchassyllablesorindividualcharactersratherthan\n",
      "words.Thisgenerallymovesthetaskofmeaningfulrepresentationsof\n",
      "thetextfromtheinputembeddingsintothemodelitselfandincreasesthecom-\n",
      "putationalcostofrunningthemodels(JohnsonandZhang,2016).Johansen\n",
      "etal.(2016)usedahierarchicalencodingtechniquetodomachinetranslation\n",
      "withcharacterinputswhilekeepingcomputationalcostslow.\n",
      "3\n",
      "HashEmbeddings\n",
      "Inthefollowingwewillgothroughthestepbystepconstructionofavector\n",
      "representationforatokenw?Tusinghashembeddings.Thefollowingsteps\n",
      "arealsoillustratedin1:1.UsektfunctionsH1,...,Hkto\n",
      "choosekcomponentvectorsforthetokenwfromapoolofBshared\n",
      "componentvectors2.Combinethechosencomponentvectorsfromstep1asa\n",
      "weightedsum:e?w=Pki1k>?Rkarecalledtheimportanceparameters\n",
      "fori=1pwHi(w).pw=(pw,...,pw)w.3.Optional:Thevectorof\n",
      "importanceparametersforthetokenpwcanbeconcatenatedwithe?winorder\n",
      "toconstructthehashvectorew.3\n",
      "Thefulltranslationofatokentoahashvectorcanbewritteninvector\n",
      "notation(?denotestheconcatenationoperator):cw\n",
      "=\n",
      "(H1(w),H2(w),...,Hk(w))>\n",
      "pw\n",
      "=\n",
      "(p1w,...,pkw)>\n",
      "e?w\n",
      "=p>wcw\n",
      "e>w\n",
      ">=e?>w?pw(optional)\n",
      "ThetokentocomponentvectorfunctionsHiareimplementedbyHi(w)=\n",
      "ED2(D1(w)),where?D1:T?\n",
      "f\n",
      "1,...K\n",
      "g\n",
      "isatokentoidfunction.?\n",
      "D2:\n",
      "f\n",
      "1,...,K\n",
      "g\n",
      "?\n",
      "f\n",
      "1,...B\n",
      "g\n",
      "isanidtobucket(hash)function.?Eis\n",
      "aB?dmatrix.Ifcreatingadictionarybeforehandisnotaproblem,wecan\n",
      "useanenumeration(dictionary)ofthetokensasD1.If,ontheotherhand,\n",
      "itisinconvenient(orimpossible)touseadictionarybecauseofthesizeofT\n",
      ",wecansimplyuseahashfunctionD1:T?\n",
      "f\n",
      "1,...K\n",
      "g\n",
      ".Theimportance\n",
      "parametervectorspwarerepresentedasrowsinaK?kmatrixP,andthe\n",
      "tokento?importancevectormappingisimplementedbyw?PD(w).D(w)\n",
      "canbeeitherequaltoD1,orwe??=D1,andleavethecasecanusea\n",
      "thashfunction.IntherestofthearticlewewilluseD?whereD6=\n",
      "4\n",
      "\n",
      "D1tofuturework.Basedonthedescriptionaboveweseethattheconstruction\n",
      "ofhashembeddingsrequiresthefollowing:1.Atrainableembeddingmatrix\n",
      "EofsizeB?d,whereeachoftheBrowsisacomponentvectoroflengthd.\n",
      "2.AtrainablematrixPofimportanceparametersofsizeK?kwhereeachof\n",
      "theKrowsisavectorofkscalarimportanceparameters.3.kderenthash\n",
      "functionsH1,...,HkthateachuniformlyassignsoneoftheBcomponent\n",
      "vectorstoeachtokenw?T.Thetotalnumberoftrainableparametersina\n",
      "hashembeddingisthusequaltoB?d+K?k,whichshouldbecomparedto\n",
      "astandardembeddingwherethenumberoftrainableparametersisK?d.The\n",
      "numberofhashfunctionskandbucketsBcantypicallybechosenquitesmall\n",
      "withoutdegradingperformance,andthisiswhatcangiveahugereductionin\n",
      "thenumberofparameters(wetypicallyusek=2andchooseKandBs.t.\n",
      "K>10?B).Fromthedescriptionabovewealsoseethatthecomputational\n",
      "overheadofusinghashembeddingsinsteadofstandardembeddingsisjusta\n",
      "matrixmultiplicationofa1?kmatrix(importanceparameters)withak?d\n",
      "matrix(componentvectors).Whenusingsmallvaluesofk,thecomputational\n",
      "overheadisthereforenegligible.Inourexperiments,hashembeddingswere\n",
      "actuallymarginallyfastertotrainthanstandardembeddingtypesforlarge\n",
      "vocabularyproblems1.However,sincetheembeddinglayerisresponsiblefor\n",
      "onlyanegligiblefractionofthecomputationalcomplexityofmostmodels,using\n",
      "hashembeddingsinsteadofregularembeddingsshouldnotmakeany\n",
      "formostmodels.Furthermore,whenusinghashembeddingsitisnotnecessary\n",
      "tocreateadictionarybeforetrainingnortoperformvocabularypruningafter\n",
      "training.Thiscanalsoreducethetotaltrainingtime.Notethatinthespecial\n",
      "casewherethenumberofhashfunctionsisk=1,andallimportanceparameters\n",
      "arexedtop1w=1foralltokensw?T,hashembeddingsareequivalentto\n",
      "usingthehashingtrick.Iffurthermorethenumberofcomponentvectorsis\n",
      "settoB=|T|andthehashfunctionh1(w)istheidentityfunction,hash\n",
      "embeddingsareequivalenttostandardembeddings.1\n",
      "thesmallperformancewasobservedwhenusingKeraswithaTen-\n",
      "wbackendonaGeForceGTXTITANXwith12GBofmemoryanda\n",
      "NvidiaGeForceGTX660with2GBmemory.Theperformancepenaltywhenus-\n",
      "ingstandardembeddingsforlargevocabularyproblemscanpossiblybeavoided\n",
      "byusingacustomembeddinglayer,butwehavenotpursuedthisfurther.\n",
      "4\n",
      "4\n",
      "Hashingtheory\n",
      "Theorem4.1.Leth:T?\n",
      "f\n",
      "0,...,K\n",
      "g\n",
      "beahashfunction.Thenthe\n",
      "probabilitypcolthatw0?Tcollideswithoneormoreothertokensisgivenby\n",
      "pcol=1?(1?1/K)|T|?1.\n",
      "(1)\n",
      "ForlargeKwehavetheapproximationpcol?1?e?\n",
      "|T|K\n",
      ".\n",
      "(2)\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheexpectednumberoftokensincollisionCtotisgivenbyCtot=|T\n",
      "|pcol.\n",
      "(3)\n",
      "Proof.Thisisasimplevariationofthe?birthdayproblem?.\n",
      "Whenusinghashingfordimensionalityreduction,collisionsareunavoidable,\n",
      "whichisthemaindisadvantageforfeaturehashing.Thisiscounteractedbyhash\n",
      "embeddingsintwoways:Firstofall,forchoosingthecomponentvectorsfora\n",
      "tokenw?T,hashembeddingsusekindependentuniformhashfunctionshi:\n",
      "T?\n",
      "f\n",
      "1,...,B\n",
      "g\n",
      "fori=1,...,k.Thecombinationofmultiplehashfunctions\n",
      "approximatesasinglehashfunctionwithmuchlargerrangeh:T?\n",
      "f\n",
      "1,...,\n",
      "Bk\n",
      "g\n",
      ",whichdrasticallyreducestheriskoftotalcollisions.Withavocabulary\n",
      "of|T|=100M,B=1Mtcomponentvectorsandjustk=2instead\n",
      "of1,thechanceofagiventokencolliding\n",
      "withatleastoneothertokeninthevocabularyisreducedfromapproxi-\n",
      "mately1?exp?108/106?1\n",
      "toapproximately1?exp?108/1012?0.0001.Usingmorehashfunctions\n",
      "willfurtherreducethenumberofcollisions.Second,onlyasmallnumberofthe\n",
      "tokensinthevocabularyareusuallyimportantforthetaskathand.Thepur-\n",
      "poseoftheimportanceparametersistoimplicitlypruneunimportantwordsby\n",
      "settingtheirimportanceparameterscloseto0.Thiswouldreducetheexpected\n",
      "numberofcollisionsto\n",
      "|Timp||Timp|?exp?BwhereTimp?Tisthesetofimportant\n",
      "wordsforthegiventask.Theweightingwiththecomponentvectorwillfurther\n",
      "beabletoseparatethecollidingtokensinthekdimensionalsubspacespanned\n",
      "bytheirkddimensionalembeddingvectors.Notethathashembeddingsconsist\n",
      "oftwolayersofhashing.Inthelayereachtokenissimplytranslatedto\n",
      "anintegerin\n",
      "f\n",
      "1,...,K\n",
      "g\n",
      "byadictionaryorahashfunctionD1.IfD1\n",
      "isadictionary,therewillofcoursenotbeanycollisionsinthelayer.If\n",
      "D1isarandomhashfunctionthentheexpectednumberoftokensincollision\n",
      "willbegivenbyequation3.Thesecollisionscannotbeavoided,andtheex-\n",
      "pectednumberofcollisionscanonlybedecreasedbyincreasingK.Increasing\n",
      "thevocabularysizeby1introducesdparametersinstandardembeddingsand\n",
      "onlykinhashembeddings.Thetypicaldrangesfrom10to300,andkisin\n",
      "therange1-3.Thismeansthatevenwhentheembeddingsizeiskeptsmall,\n",
      "theparametersavingscanbehuge.In(Joulinetal.,2016b)forexample,the\n",
      "embeddingsizeischosentobeassmallas10.Inordertogofromabi-gram\n",
      "modeltoageneraln-grammodelthenumberofbucketsisincreasedfromK=\n",
      "107toK=108.Thisincreaseofbucketsrequiresanadditional900million\n",
      "parameterswhenusingstandardembeddings,butlessthan200millionwhen\n",
      "usinghashembeddingswiththedefaultofk=2hashfunctions.I.e.evenwhen\n",
      "theembeddingsizeiskeptextremelysmall,theparametersavingscanbehuge.\n",
      "5\n",
      "Experiments\n",
      "Webenchmarkhashembeddingswithandwithoutdictionariesontextclas-\n",
      "tasks.5.1\n",
      "Dataandpreprocessing\n",
      "6\n",
      "\n",
      "Weevaluatehashembeddingson7tdatasetsintheformintroduced\n",
      "byZhangetal.(2015)forvarioustexttasksincludingtopicclas-\n",
      "sentimentanalysis,andnewscategorization.Allofthedatasetsare\n",
      "balancedsothesamplesaredistributedevenlyamongthe5\n",
      "classes.Anoverviewofthedatasetscanbeseenintable1.t\n",
      "previousresultsarelistedintable2.Weusethesameexperimentalproto-\n",
      "colasin(Zhangetal.,2015).Wedonotperformanypreprocessingbesides\n",
      "removingpunctuation.Themodelsaretrainedonsnippetsoftextthatare\n",
      "createdbyconvertingeachtexttoasequenceofn-grams,andfromthis\n",
      "listatrainingsampleiscreatedbyrandomlyselectingbetween4and100con-\n",
      "secutiven-gramsasinput.Thismaybeseenasinputdrop-outandhelpsthe\n",
      "modelavoidovWhentestingweusetheentiredocumentasinput.\n",
      "Thesnippet/document-levelembeddingisobtainedbysimplyaddingupthe\n",
      "word-levelembeddings.Table1:Datasetsusedintheexperiments,See(Zhang\n",
      "etal.,2015)foracompletedescription.#Train#Test#ClassesTaskAG?s\n",
      "news120k7.6k4EnglishnewscategorizationDBPedia450k70k14Ontology\n",
      "YelpReviewPolarity560k38k2SentimentanalysisYelpReview\n",
      "Full560k50k5SentimentanalysisYahoo!Answers650k60k10Topic\n",
      "cationAmazonReviewFull3000k650k5SentimentanalysisAmazonReview\n",
      "Polarity3600k400k2Sentimentanalysis\n",
      "5.2\n",
      "Training\n",
      "Allthemodelsaretrainedbyminimizingthecrossentropyusingthestochas-\n",
      "ticgradientdescentbasedAdammethod(KingmaandBa,2014)withalearning\n",
      "ratesetto?=0.001.Weuseearlystoppingwithapatienceof10,anduse5%of\n",
      "thetrainingdataasvalidationdata.AllmodelswereimplementedusingKeras\n",
      "withTensorFlowbackend.ThetrainingwasperformedonaNvidiaGeForce\n",
      "GTXTITANXwith12GBofmemory.5.3\n",
      "Hashembeddingswithoutadictionary\n",
      "Inthisexperimentwecomparetheuseofastandardhashingtrickembed-\n",
      "dingwithahashembedding.ThehashembeddingsuseK=10Mt\n",
      "importanceparametervectors,k=2hashfunctions,andB=1Mcomponent\n",
      "vectorsofdimensiond=20.Thisaddsupto40Mparametersforthehash\n",
      "embeddings.Forthestandardhashingtrickembeddings,weuseanarchitec-\n",
      "turealmostidenticaltotheoneusedin(Joulinetal.,2016b).Asin(Joulin\n",
      "etal.,2016b)weonlyconsiderbi-grams.Weuseonelayerofhashingwith\n",
      "10Mbucketsandanembeddingssizeof20.Thisrequires200Mparameters.\n",
      "Thedocument-levelembeddinginputispassedthroughasinglefullyconnected\n",
      "layerwithsoftmaxactivation.Theperformanceofthemodelwhenusingeachof\n",
      "thetwoembeddingtypescanbeseenintheleftsideoftable2.Weseethateven\n",
      "thoughhashembeddingsrequire5timeslessparameterscomparedtostandard\n",
      "embeddings,theyperformatleastaswellasstandardembeddingsacrossallof\n",
      "thedatasets,exceptforDBPediawherestandardembeddingsperformatiny\n",
      "bitbetter.5.4\n",
      "Hashembeddingsusingadictionary\n",
      "Inthisexperimentwelimitthevocabularytothe1Mmostfrequentn-grams\n",
      "7\n",
      "\n",
      "forn<10.Mostofthetokensareuni-gramsandbi-grams,butalsomanyto-\n",
      "kensofhigherorderarepresentinthevocabulary.Weuseembeddingvectors\n",
      "ofsized=200.Thehashembeddingsusek=2hashfunctionsandthebucket\n",
      "sizeBischosenbycross-validationamong[500,10K,50K,100K,150K].The\n",
      "maximumnumberofwordsforthestandardembeddingsischosenbycross-\n",
      "validationamong[10K,25K,50K,300K,500K,1M].Weuseamorecomplex\n",
      "architecturethanintheexperimentabove,consistingofanembeddinglayer\n",
      "(standardorhash)followedbythreedenselayerswith1000hiddenunitsand\n",
      "ReLUactivations,endinginasoftmaxlayer.Weusebatchnormalization\n",
      "andSzegedy,2015)asregularizationbetweenallofthelayers.Theparameter\n",
      "savingsforthisproblemarenotasgreatasintheexperimentwithoutadic-\n",
      "tionary,butthehashembeddingsstilluse3timeslessparametersonaverage\n",
      "comparedtoastandardembedding.6\n",
      "Ascanbeseenintable2themorecomplexmodelsactuallyachieveaworse\n",
      "resultthanthesimplemodeldescribedabove.Thiscouldbecausedbyeitheran\n",
      "tnumberofwordsinthevocabularyorbyovg.Notehowever,\n",
      "thatthetwomodelshaveaccesstothesamevocabulary,andthevocabulary\n",
      "canthereforeonlyexplainthegeneraldropinperformance,nottheperformance\n",
      "betweenthetwotypesofembedding.Thisseemstosuggestthatus-\n",
      "inghashembeddingshavearegularizingectonperformance.Whenusinga\n",
      "dictionaryinthelayerofhashing,eachvectorofimportanceparameters\n",
      "willcorresponddirectlytoauniquephrase.Intable4weseethephrasescor-\n",
      "respondingtothelargest/smallest(absolute)importancevalues.Aswewould\n",
      "expect,largeabsolutevaluesoftheimportanceparameterscorrespondtoim-\n",
      "portantphrases.Alsonotethatsomeofthen-gramscontaininformationthat\n",
      "e.g.thebi-grammodelabovewouldnotbeabletocapture.Forexample,the\n",
      "bi-grammodelwouldnotbeabletotellwhether4or5starshadbeengiven\n",
      "onbehalfofthesentence?Igaveit4starsinsteadof5stars?,butthegeneral\n",
      "n-grammodelwould.5.5\n",
      "Ensembleofhashembeddings\n",
      "Thenumberofbucketsforahashembeddingcanbechosenquitesmall\n",
      "withoutseverelyperformance.B=500?10.000bucketsistypically\n",
      "tinordertoobtainaperformancealmostatparwiththebestresults.\n",
      "Intheexperimentsusingadictionaryonlyabout3Mparametersarerequired\n",
      "inthelayersontopoftheembedding,whilekK+Bd=2M+B?200are\n",
      "requiredintheembeddingitself.Thismeansthatwecanchoosetotrainan\n",
      "ensembleofmodelswithsmallbucketsizesinsteadofalargemodel,whileat\n",
      "thesametimeusethesameamountofparameters(andthesametrainingtime\n",
      "sincemodelscanbetrainedinparallel).Usinganensembleisparticularlyuseful\n",
      "forhashembeddings:eventhoughcollisionsarehandledctivelybytheword\n",
      "importanceparameters,thereisstillapossibilitythatafewoftheimportant\n",
      "wordshavetousesuboptimalembeddingvectors.Whenusingseveralmodels\n",
      "inanensemblethiscanmoreorlessbeavoidedsincethashfunctions\n",
      "canbechosenforeachhashembeddingintheensemble.Weuseanensemble\n",
      "consistingof10modelsandcombinethemodelsusingsoftvoting.Eachmodel\n",
      "useB=50.000andd=200.Thearchitectureisthesameasintheprevious\n",
      "8\n",
      "\n",
      "sectionexceptthatmodelswithonetothreehiddenlayersareusedinsteadof\n",
      "justtenmodelswiththreehiddenlayers.Thiswasdoneinordertodiversify\n",
      "themodels.Thetotalnumberofparametersintheensembleisapproximately\n",
      "150M.Thisshouldbecomparedtoboththestandardembeddingmodelin\n",
      "section5.3andthestandardembeddingmodelinsection5.4(whenusingthe\n",
      "fullvocabulary),bothofwhichrequire?200Mparameters.Table2:Test\n",
      "accuracy(in%)fortheselecteddatasetsWithoutdictionaryWithdictionary\n",
      "Shallownetwork(section5.3)Deepnetwork(section5.4)Hashemb.Stdemb\n",
      "Hashemb.Std.emb.EnsembleAG92.492.091.591.792.0Amazonfull60.0\n",
      "58.359.458.560.5Dbpedia98.598.698.798.698.8Yahoo72.372.371.365.8\n",
      "72.9Yelpfull63.862.662.661.462.9Amazonpol94.494.294.793.694.7Yelp\n",
      "pol95.995.595.895.095.7\n",
      "6\n",
      "FutureWork\n",
      "Hashembeddingsarecomplementarytootherstate-of-the-artmethodsas\n",
      "itaddressestheproblemoflargevocabularies.Anattractivepossibilityisto\n",
      "usehash-embeddingstocreateaword-levelembeddingtobeusedinacontext\n",
      "sensitivemodelsuchaswordCNN.Asnotedinsection3,wehaveusedthesame\n",
      "tokentoidfunctionD1forboththecomponentvectorsandtheimportance\n",
      "parameters.Thismeansthatwordsthathashtothesamebucketinthe\n",
      "layergetbothidenticalcomponentvectorsandimportanceparameters.This\n",
      "elymeansthatthose?forwordsbecomeindistinguishabletothemodel.\n",
      "IfweinsteaduseattokentoidfunctionD7\n",
      "Table3:State-of-the-arttestaccuracyin%.Thetableissplitbetween\n",
      "BOWembeddingapproaches(bottom)andmorecomplexrnn/cnnapproaches\n",
      "(top).Thebestresultineachcategoryforeachdatasetisbolded.char-CNN\n",
      "(Zhangetal.,2015)char-CRNN(XiaoandCho,2016)VDCNN(Conneauet\n",
      "al.,2016)wordCNN(JohnsonandZhang,2016)Discr.LSTM(Yogatamaetal.,\n",
      "2017)Virt.adv.net.(Miyatoetal.,2016)fastText(Joulinetal.,2016b)BoW\n",
      "(Zhangetal.,2015)n-grams(Zhangetal.,2015)n-gramsTFIDF(Zhangetal.,\n",
      "2015)Hashembeddings(nodict.)Hashembeddings(dict.)Hashembeddings\n",
      "(dict.,ensemble)\n",
      "AG87.291.491.393.492.192.588.892.092.492.491.592.0\n",
      "DBP98.398.698.799.298.799.298.696.698.698.798.598.798.8\n",
      "YelpP94.794.595.797.192.6\n",
      "YelpF62.061.864.767.659.6\n",
      "YahA71.271.773.475.273.7\n",
      "AmzF59.559.263.063.8\n",
      "AmzP94.594.195.796.2\n",
      "95.792.295.695.495.995.895.7\n",
      "63.958.056.354.863.862.562.9\n",
      "72.368.968.568.572.371.972.9\n",
      "60.254.654.352.460.059.460.5\n",
      "94.690.492.091.594.494.794.7\n",
      "Table4:Wordsinthevocabularywiththehighest/lowestimportancepa-\n",
      "rameters.ImportanttokensUnimportanttokens\n",
      "9\n",
      "\n",
      "YelppolarityWhat\n",
      "a\n",
      "joke,not\n",
      "a\n",
      "good\n",
      "experience,Great\n",
      "experience,wanted\n",
      "to\n",
      "love,\n",
      "and\n",
      "lacking,Awful,by\n",
      "far\n",
      "the\n",
      "worst,The\n",
      "service\n",
      "was,got\n",
      "a\n",
      "cinnamon,15\n",
      "you\n",
      "can,\n",
      "while\n",
      "touching,and\n",
      "that\n",
      "table,style\n",
      "There\n",
      "is\n",
      "Amazonfullgave\n",
      "it\n",
      "4,it\n",
      "two\n",
      "stars\n",
      "because,4\n",
      "stars\n",
      "instead\n",
      "of\n",
      "5,4\n",
      "stars,four\n",
      "stars,\n",
      "gave\n",
      "it\n",
      "two\n",
      "starsthat\n",
      "my\n",
      "wife\n",
      "and\n",
      "I,the\n",
      "state\n",
      "I,power\n",
      "back\n",
      "on,years\n",
      "and\n",
      "though,\n",
      "you\n",
      "want\n",
      "a\n",
      "real\n",
      "good\n",
      "theimportanceparameters,weseverelyreducethechanceof\"totalcolli-\n",
      "sions\".Ourinitialndingsindicatethatusingathashfunctionforthe\n",
      "indexoftheimportanceparametersgivesasmallbutconsistentimprovement\n",
      "comparedtousingthesamehashfunction.Inthisarticlewehaverepresented\n",
      "wordvectorusingaweighedsumofcomponentvectors.However,otherag-\n",
      "gregationmethodsarepossible.Onesuchmethodissimplytoconcatenate\n",
      "the(weighed)componentvectors.Theresultingkd-dimensionalvectoristhen\n",
      "equivalenttoaweighedsumoforthogonalvectorsinRkd.Finally,itmight\n",
      "beinterestingtoexperimentwithpre-traininglean,high-qualityhashvectors\n",
      "thatcouldbedistributedasanalternativetoword2vecvectors,whichrequire\n",
      "around3.5GBofspaceforalmostabillionparameters.\n",
      "7\n",
      "Conclusion\n",
      "Wehavedescribedanextensionandimprovementtostandardwordem-\n",
      "beddingsandmadeanempiricalcomparisonsbetweenhashembeddingsand\n",
      "standardembeddingsacrossawiderangeofclastasks.Ourexper-\n",
      "imentsshowthattheperformanceofhashembeddingsisalwaysatparwith\n",
      "usingstandardembeddings,andinmostcasesbetter.Wehaveshownthat\n",
      "hashembeddingscaneasilydealwithhugevocabularies,andwehaveshown\n",
      "thathashembeddingscanbeusedbothwithandwithoutadictionary.This\n",
      "isparticularlyusefulforproblemssuchasonlinelearningwhereadictionary\n",
      "cannotbeconstructedbeforetraining.Ourexperimentsalsosuggestthathash\n",
      "embeddingshaveaninherentregularizingonperformance.Whenusing\n",
      "astandardmethodofregularization(suchasL1orL2regularization),westart\n",
      "withthefullparameterspaceandregularizeparametersbypushingsomeof\n",
      "themcloserto0.Thisisincontrasttoregularizationusinghashembeddings\n",
      "wherethenumberofparameters(numberofbuckets)determinesthedegree\n",
      "ofregularization.Thusparametersnotneededbythemodelwillnothaveto\n",
      "beaddedintheplace.Thehashembeddingmodelsusedinthisarticle\n",
      "achieveequalorbetterperformancethanpreviousbag-of-wordsmodelsusing\n",
      "standardembeddings.Furthermore,in5of7datasets,theperformanceofhash\n",
      "embeddingsisintop3ofstate-of-theart.8\n",
      "2References\n",
      "Argerich,L.,J.T.,andCano,M.J.(2016).Hash2vec,featurehashing\n",
      "forwordembeddings.CoRR,abs/1608.08940.Bai,B.,Weston,J.,Grangier,D.,\n",
      "Collobert,R.,Sadamasa,K.,Qi,Y.,Chapelle,O.,andWeinberger,K.(2009).\n",
      "Supervisedsemanticindexing.InProceedingsofthe18thACMconference\n",
      "10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onInformationandknowledgemanagement,pages187?196.ACM.Conneau,\n",
      "A.,Schwenk,H.,Barrault,L.,andLeCun,Y.(2016).Verydeepconvolu-\n",
      "tionalnetworksfornaturallanguageprocessing.CoRR,abs/1606.01781.Gray,\n",
      "R.M.andD.L.(1998).Quantization.IEEETrans.Inf.Theor.,\n",
      "44(6):2325?2383.Huang,E.H.,Socher,R.,Manning,C.D.,andNg,A.Y.\n",
      "(2012).Improvingwordrepresentationsviaglobalcontextandmultipleword\n",
      "prototypes.InProceedingsofthe50thAnnualMeetingoftheAssociationfor\n",
      "ComputationalLinguistics:LongPapers-Volume1,ACL?12,pages873?882,\n",
      "Stroudsburg,PA,USA.AssociationforComputationalLinguistics.Huang,P.-\n",
      "S.,He,X.,Gao,J.,Deng,L.,Acero,A.,andHeck,L.(2013).Learningdeep\n",
      "structuredsemanticmodelsforwebsearchusingclickthroughdata.InProceed-\n",
      "ingsofthe22ndACMInternationalConferenceonInformationandKnowledge\n",
      "Management(CIKM),pages2333?2338.S.andSzegedy,C.(2015).Batch\n",
      "normalization:Acceleratingdeepnetworktrainingbyreducinginternalcovari-\n",
      "ateshift.CoRR,abs/1502.03167.Jegou,H.,Douze,M.,andSchmid,C.(2011).\n",
      "Productquantizationfornearestneighborsearch.IEEETrans.PatternAnal.\n",
      "Mach.Intell.,33(1):117?128.Johansen,A.R.,Hansen,J.M.,Obeid,E.K.,\n",
      "S?nderby,C.K.,andWinther,O.(2016).Neuralmachinetranslationwith\n",
      "charactersandhierarchicalencoding.CoRR,abs/1610.06550.Johnson,R.and\n",
      "Zhang,T.(2016).Convolutionalneuralnetworksfortextcategorization:Shal-\n",
      "lowword-levelvs.deepcharacter-level.CoRR,abs/1609.00718.Joulin,A.,\n",
      "Grave,E.,Bojanowski,P.,Douze,M.,J?gou,H.,andMikolov,T.(2016a).\n",
      "Fasttext.zip:Compressingtextmodels.CoRR,abs/1612.03651.\n",
      "Joulin,A.,Grave,E.,Bojanowski,P.,andMikolov,T.(2016b).Bagoftricks\n",
      "forttextCoRR,abs/1607.01759.Kingma,D.P.andBa,\n",
      "J.(2014).Adam:Amethodforstochasticoptimization.CoRR,abs/1412.6980.\n",
      "Kulis,B.andDarrell,T.(2009).Learningtohashwithbinaryreconstructive\n",
      "embeddings.InBengio,Y.,Schuurmans,D.,y,J.D.,Williams,C.K.\n",
      "I.,andCulotta,A.,editors,AdvancesinNeuralInformationProcessingSys-\n",
      "tems22,pages1042?1050.CurranAssociates,Inc.Manning,C.D.,Sch?tze,\n",
      "H.,etal.(1999).Foundationsofstatisticalnaturallanguageprocessing,vol-\n",
      "ume999.MITPress.Mih?ltz,M.(2016).Google?strainedword2vecmodel\n",
      "inpython.https://github.com/mmihaltz/word2vec-GoogleNews-vectors.Ac-\n",
      "cessed:2017-02-08.Miyato,T.,Dai,A.M.,andGoodfellow,I.(2016).Vir-\n",
      "tualadversarialtrainingforsemi-supervisedtextstat,1050:25.\n",
      "Reisinger,J.andMooney,R.J.(2010).Multi-prototypevector-spacemodels\n",
      "ofwordmeaning.InHumanLanguageTechnologies:The2010AnnualCon-\n",
      "ferenceoftheNorthAmericanChapteroftheAssociationforComputational\n",
      "Linguistics,HLT?10,pages109?117,Stroudsburg,PA,USA.Associationfor\n",
      "ComputationalLinguistics.Stolcke,A.(2000).Entropy-basedpruningofback-\n",
      "languagemodels.CoRR,cs.CL/0006025.Weinberger,K.Q.,Dasgupta,A.,\n",
      "Attenberg,J.,Langford,J.,andSmola,A.J.(2009).Featurehashingforlarge\n",
      "scalemultitasklearning.CoRR,abs/0902.2206.Xiao,Y.andCho,K.(2016).\n",
      "tcharacter-leveldocumentbycombiningconvolutionand\n",
      "recurrentlayers.CoRR,abs/1602.00367.Yogatama,D.,Dyer,C.,Ling,W.,\n",
      "andBlunsom,P.(2017).Generativeanddiscriminativetextwith\n",
      "11\n",
      "\n",
      "recurrentneuralnetworks.arXivpreprintarXiv:1703.01898.Zhang,X.,Zhao,\n",
      "J.J.,andLeCun,Y.(2015).Character-levelconvolutionalnetworksfortext\n",
      "CoRR,abs/1509.01626.\n",
      "9\n",
      "12\n",
      "\n",
      "PP6171.pdf\n",
      "PP6171.pdf 11\n",
      "TheLimitsofLearningwithMissingData\n",
      "Authoredby:\n",
      "EladHazan\n",
      "TomerKoren\n",
      "BrianBullins\n",
      "Abstract\n",
      "Westudyregressionandinasettingwherethelearning\n",
      "algorithmisallowedtoaccessonlyalimitednumberofattributesper\n",
      "example,knownasthelimitedattributeobservationmodel.Inthiswell-\n",
      "studiedmodel,weprovidethelowerboundsgivingalimitonthe\n",
      "precisionattainablebyanyalgorithmforseveralvariantsofregression,\n",
      "notablylinearregressionwiththeabsolutelossandthesquaredloss,as\n",
      "wellasforwiththehingeloss.Wecomplementtheselower\n",
      "boundswithageneralpurposealgorithmthatgivesanupperboundon\n",
      "theachievableprecisionlimitinthesettingoflearningwithmissingdata.\n",
      "1PaperBody\n",
      "Theprimaryobjectiveoflinearregressionistodeterminetherelationshipsbe-\n",
      "tweenmultiplevariablesandhowtheymayacertainoutcome.Astandard\n",
      "exampleisthatofmedicaldiagnosis,wherebythedatagatheredforagivenpa-\n",
      "tientprovidesinformationabouttheirsusceptibilitytocertainillnesses.Amajor\n",
      "drawbacktothisprocessistheworknecessarytocollectthedata,asitrequires\n",
      "runningnumeroustestsforeachperson,someofwhichmaybediscomforting.\n",
      "Insuchcasesitmaybenecessarytoimposelimitationsontheamountofdata\n",
      "availableforeachexample.Formedicaldiagnosis,thismightmeanhavingeach\n",
      "patientonlyundergoasmallsubsetoftests.Aformalsettingforcapturing\n",
      "regressionandlearningwithlimitsonthenumberofattributeobservationsis\n",
      "knownastheLimitedAttributeObservation(LAO)setting,introduced\n",
      "byBen-DavidandDichterman[1].Forexample,inaregressionproblem,the\n",
      "learnerhasaccesstoadistributionDoverdata(x,y)2Rd?R,and\n",
      "thebest(generalized)linearmodelaccordingtoacertainlossfunction,i.e.,it\n",
      "approximatelysolvestheoptimizationproblemmin\n",
      "w:kwkp?B\n",
      "LD(w),\n",
      "fLD(w)=E(x,y)?D`(w>x\n",
      "gy).\n",
      "1\n",
      "\n",
      "IntheLAOsetting,thelearnerdoesnothavecompleteaccesstotheexam-\n",
      "plesx,whichthereadermaythinkofasattributesofacertainpatient.Rather,\n",
      "thelearnercanobserveatmostanumberoftheseattributes,denotedk\n",
      "?d.Ifk=d,thisisthestandardregressionproblemwhichcanbesolvedto\n",
      "arbitraryprecision.Themainquestionweaddress:isitpossibletocompute\n",
      "anarbitrarilyaccuratesolutionifthenumberofobservationsperexample,k,is\n",
      "strictlylessthand?Moreformally,givenany\">0,canonecomputeavector\n",
      "wforwhichLD(w)?\n",
      "min\n",
      "kw?kp?B\n",
      "LD(w?)+\".\n",
      "talgorithmsforregressionwithsquaredlosswhenk<dhavebeen\n",
      "showninpreviouswork[2],andthesamplecomplexityboundshavesincebeen\n",
      "tightened[6,8].However,similarresultsfor30thConferenceonNeuralInfor-\n",
      "mationProcessingSystems(NIPS2016),Barcelona,Spain.\n",
      "othercommonlossfunctionssuchase.g.absolutelosshaveonlybeenshown\n",
      "byrelaxingthehardlimitofkattributesperexample[3,6].Inthispaperwe\n",
      "show,forthetime,thatinfactthisproblemcannotbesolvedingeneral.\n",
      "Ourmainresultshowsthatevenforregressionwiththeabsolutelossfunction,\n",
      "foranyk?d1,thereisaninformation-theoreticlowerboundontheerror\n",
      "attainablebyanyalgorithm.Thatis,thereissome\"0>0forwhichan\"0\n",
      "-optimalsolutioncannotbedetermined,irrespectiveofthenumberofexamples\n",
      "thelearnersees.Formally,withconstantprobability,anyalgorithmreturning\n",
      "avectorw2RdmustsatisfyLD(w)>minLD(w?)+\"0.?kwkp?B\n",
      "Wefurthershowthatthisultimateachievableprecisionparameterisbounded\n",
      "frombelowbyapolynomialinthedimension,i.e.,\"0=?(d3/2).Addition-\n",
      "ally,forthebasicsettingofRidgeregression(withthesquaredloss),wegive\n",
      "atightlowerboundfortheLAOsetting.Cesa-Bianchietal.[2]providedthe\n",
      "talgorithmforthissettingwithsamplecomplexityofO(d2/k\"2\n",
      ")for\"error.HazanandKoren[6]improveduponthisresultandgaveatight\n",
      "samplecomplexityofO(d/k\"2)toachieve\"error.Inbothcases,however,\n",
      "thealgorithmsonlyworkwhenk2.Wecompletethepictureandshowthatk\n",
      "2attributesareinfactnecessarytoobtainarbitrarilylowerror.Thatis,with\n",
      "onlyoneattributeperexample,thereisaninformation-theoreticlimitonthe\n",
      "accuracyattainablebyanyregressionalgorithm.Weremarkthatasimilarim-\n",
      "possibilityresultwasprovenbyCesa-Bianchietal.[3]intherelatedsettingof\n",
      "learningwithnoisyexamples.maybesimilarlycastintheLAO\n",
      "setting.Forwiththehingeloss,namelysoft-marginSVM,wegive\n",
      "arelatedlowerbound,showingthatitisimpossibletoachievearbitrarilylow\n",
      "errorifthenumberofobservedattributesisboundedbyk?d1.However,\n",
      "unlikeourlowerboundforregression,thelowerboundweprovefor\n",
      "tionscalesexponentiallywiththedimension.AlthoughHazanetal.[7]showed\n",
      "howmaybedonewithmissingdata,theirworkincludeslowrank\n",
      "assumptionsandsoitisnotincontradictionwiththelowerboundspresented\n",
      "here.SimilartotheLAOsetting,thesettingoflearningwithmissingdata[9,\n",
      "4,10,11]presentsthelearnerwithexampleswheretheattributesarerandomly\n",
      "2\n",
      "\n",
      "observed.SincethemissingdatasettingisatleastasastheLAOset-\n",
      "ting,ourlowerboundsextendtothiscaseaswell.Wecomplementtheselower\n",
      "boundswithageneralpurposealgorithmforregressionandpwith\n",
      "missingdatathat,givenasucientnumberofsamples,canachieveanerror\n",
      "ofO(1/d).Thisresultleavesonlyasmallpolynomialgapcomparedtothe\n",
      "information-theoreticlowerboundthatweprove.\n",
      "2\n",
      "SetupandStatementofResults\n",
      "Thegeneralframeworkoflinearregressioninvolvesasetofinstances,each\n",
      "oftheform(x,y)wherex2Rdistheattributevectorandy2Risthecor-\n",
      "respondingtargetvalue.Underthetypicalstatisticallearningframework[5],\n",
      "each(x,y)pairisdrawnfromajointdistributionDoverRd?R.Thelearner?s\n",
      "objectiveistodeterminesomelinearpredictorwsuchthatw>xdoeswellin\n",
      "predictingy.Thequalityofpredictionismeasuredaccordingtoalossfunction\n",
      "`:R7!R.Twocommonlyusedlossfunctionsforregressionarethesquared\n",
      "loss`(w>xy)=12(w>xy)2andtheabsoluteloss`(w>xy)=|w>xy|.\n",
      "SinceourexamplesaredrawnfromsomearbitrarydistributionD,itisbestto\n",
      "considertheexpectedloss??LD(w)=E(x,y)?D`(w>xy).Thelearner?s\n",
      "goalthenistodeterminearegressorwthatminimizestheexpectedlossLD\n",
      "(w).Toavoidovaregularizationtermistypicallyadded,whichupto\n",
      "someconstantfactorisequivalenttominLD(w)s.t.kwkp?Bw2Rd\n",
      "forsomeregularizationparameterB>0,wherek?kpisthestandard`p\n",
      "norm,p1.TwocommonvariantsofregressionareRidgeregression(p=2with\n",
      "squaredloss)andLassoregression(p=1withsquaredloss).2\n",
      "Theframeworkforclasisnearlyidenticaltothatoflinearregres-\n",
      "sion.Themaindistinctioncomesfromatmeaningofy2R,namely\n",
      "thatyactsasalabelforthecorrespondingexample.Thelossfunctionalso\n",
      "changeswhenlearningaandinthispaperweareinterestedinthe\n",
      "hingeloss`(y?w>x)=max\n",
      "f\n",
      "0,1y?w>x\n",
      "g\n",
      ".Theoverallgoalofthelearner,\n",
      "however,remainsthesame:namely,todetermineawsuchthatLD\n",
      "(w)isminimized.Throughoutthepaper,weletw?denotetheminimizerofL\n",
      "D(w).2.1\n",
      "MainResults\n",
      "Asastep,forLassoandRidgeregressions,weshowthatonealways\n",
      "needstoobserveatleasttwoattributestobeabletolearnaregressortoarbi-\n",
      "traryprecision.ThisisgivenformallyinTheorem1.1Theorem1.Let0<\"\n",
      "<32andlet`bethesquaredloss.ThenthereexistsadistributionDover\n",
      "f\n",
      "x:\n",
      "||x||1?1\n",
      "g\n",
      "?[1,1]suchthatkw?k1?2,andanyregressionalgorithm\n",
      "thatcanobserveat?suchthatmostoneattributeofeachtrainingexampleof\n",
      "atrainingsetScannotoutputaregressorw?<LD(w?)+\".ES[LD(w)]\n",
      "1Corollary2.Let0<\"<64andlet`bethesquaredloss.Thenthereexistsa\n",
      "distributionDover\n",
      "f\n",
      "x:||x||2?1\n",
      "g\n",
      "?[1,1]suchthatkw?k2?2,and\n",
      "anyregressionalgorithmthatcanobserveat?suchthatmostoneattributeof\n",
      "eachtrainingexampleofatrainingsetScannotoutputaregressorw?<LD\n",
      "(w?)+\".ES[LD(w)]\n",
      "Thelowerboundsaretight?recallthatwithtwoattributes,itisindeedpossi-\n",
      "3\n",
      "\n",
      "bletolearnaregressortowithinarbitraryprecision[2,6].Also,noticetheorder\n",
      "ofquaninthetheorems:itturnsoutthatthereexistsadistribution\n",
      "whichishardforallalgorithms(ratherthanatharddistributionfor\n",
      "anyalgorithm).Forregressionwithabsoluteloss,weconsiderthesettingwhere\n",
      "thelearnerislimitedtoseeingkorfewerattributesofeachtrainingsample.\n",
      "Theorem3belowshowsthatinthecasewherek<dthelearnercannothopeto\n",
      "learnan\"-optimalregressorforsome\">0.3\n",
      "1Theorem3.Letd4,d?0(mod2),0<\"<60d2,andlet`betheabsolute\n",
      "loss.ThenthereexistsadistributionDover\n",
      "f\n",
      "x:||x||1?1\n",
      "g\n",
      "?[1,1]\n",
      "suchthatkw?k1?2,andanyregressionalgorithmthatcanobserveatmostd\n",
      "1attributesofeachtrainingexampleofatrainingsetScannot?suchthatES\n",
      "[LD(w)]?<LD(w?)+\".outputaregressorw\n",
      "1Corollary4.Let0<\"<60d2,andlet`betheabsoluteloss.Thenthere\n",
      "existsadistributionDover\n",
      "f\n",
      "x:||x||2?1\n",
      "g\n",
      "?[1,1]suchthatkw?k2?\n",
      "1,andanyregressionalgorithmthatcanobserveat?suchmostd1attributes\n",
      "ofeachtrainingexampleofatrainingsetScannotoutputaregressorw?<L\n",
      "D(w?)+\".thatES[LD(w)]\n",
      "Wecomplementourforregressionwiththefollowinganalogouslower\n",
      "boundforwiththehingeloss(a.k.a.,softmarginSVM).Theorem\n",
      "5.Letd4,d?0(mod2),andlet`bethehingeloss.Thenthereexistsan\n",
      "\"0>0suchthatthefollowingholds:thereexistsadistributionDover\n",
      "f\n",
      "x:\n",
      "||x||2?1\n",
      "g\n",
      "?[1,1]suchthatkw?k2?1,andanyalgorithm\n",
      "thatcanobserveatmostd1attributesofeachtraining?suchthatES[LD\n",
      "(w)]?<LD(w?)+\"0.exampleofatrainingsetScannotoutputaregressor\n",
      "w\n",
      "3\n",
      "LowerBounds\n",
      "Inthissectionwediscussourlowerboundsforregressionwithmissingat-\n",
      "tributes.Asawarm-up,weproveTheorem1forregressionwiththesquared\n",
      "loss.Whiletheproofisverysimple,itillustratessomeofthemainideasused\n",
      "inallofourlowerbounds.Then,wegiveaproofofTheorem3forregression\n",
      "withtheabsoluteloss.Theproofsoftheremainingboundsaredeferredtothe\n",
      "supplementarymaterial.3.1\n",
      "Lowerboundsforthesquaredloss\n",
      "ProofofTheorem1.Itisenoughtoprovethetheoremfordeterministic\n",
      "learningalgorithms,namely,foralgorithmsthatdonotuseanyexternalran-\n",
      "domization(i.e.,anyrandomizationbesidestherandomsamplesdrawnfrom\n",
      "thedatadistributionitself).Thisisbecauseanyrandomizedalgorithmcan3\n",
      "bethoughtofasadistributionoverdeterministicalgorithms,whichisin-\n",
      "dependentofthedatadistribution.1Now,suppose0<\"<32.LetX1=\n",
      "f\n",
      "(0,0),(1,1)\n",
      "g\n",
      ",X2=\n",
      "f\n",
      "(0,1),(1,0)\n",
      "g\n",
      ",andletD1andD2beuniformdistri-\n",
      "butionsoverX1?\n",
      "f\n",
      "1\n",
      "g\n",
      "andX2?\n",
      "f\n",
      "1\n",
      "g\n",
      ",respectively.Themainobservationis\n",
      "thatanylearnerthatcanobserveatmostoneattributeofeachexamplecannot\n",
      "distinguishbetweenthetwodistributionswithprobabilitygreaterthan12,no\n",
      "matterhowmanysamplesitisgiven.Thisisbecausethemarginaldistributions\n",
      "oftheindividualattributesunderbothD1andD2areexactlythesame.Thus,\n",
      "4\n",
      "\n",
      "toprovethetheoremitisenoughtoshowthatthesetsof\"-optimalsolutions\n",
      "underthedistributionsD1andD2aredisjoint.Indeed,supposethatthereis\n",
      "alearningalgorithmthatemitsa?suchthatE[LD(w)?vectorwLD(w?\n",
      ")]<\"/2(wheretheexpectationisovertherandomsamples?<LD(w?)+\n",
      "\"withfromDusedbythealgorithm).ByMarkov?sinequality,itholdsthat\n",
      "LD(w)probability>1/2.Hence,theoutputofthealgorithmallowsoneto\n",
      "distinguishbetweenthetwodistributionswithprobability>1/2,contradicting\n",
      "theindistinguishabilityproperty.\n",
      "Wesettocharacterizethesetsof\"-optimalsolutionsunderD1andD2.For\n",
      "D1,wehave1X1>11LD1(w)=(wx1)2=+(w1+w21)2,2x2X24\n",
      "41\n",
      "whileforD2,\n",
      "LD2(w)=\n",
      "1X1>(wx2x2X2\n",
      "1)2=\n",
      "2\n",
      "1(w14\n",
      "1)2+\n",
      "1(w24\n",
      "1)2.\n",
      "pNotethatthesetof\"-optimalregressorsforLD1isS1=\n",
      "f\n",
      "w:|w>1\n",
      "p1|?2\"\n",
      "g\n",
      ",whereasforLD2pthesetisS2=\n",
      "f\n",
      "w:kw1k2?2\"\n",
      "g\n",
      ".LetS20=\n",
      "f\n",
      "w:|w>12|?22\"\n",
      "g\n",
      ".ThenS2?S20,soitis0sucienttoshowthatS1\n",
      "andS2aredisjoint.1Since\"<32,foranyw2S1,|w>11|<12,meaning\n",
      "w>1<32.However,foranyw2S20,1>|w12|<2meaningw>1>32,\n",
      "andsowcannotbeamemberofbothS1andS2.Aswearguedearlier,this\n",
      "toprovethetheorem.?\n",
      "3.2\n",
      "Lowerboundsfortheabsoluteloss\n",
      "AsintheproofofTheorem1,themainideaistoshowthatonecandesign\n",
      "twodistributionsthatareindistinguishabletoalearnerwhocanobserveno\n",
      "morethand1attributesofanysamplegivenbythedistribution(i.e.,thattheir\n",
      "marginalsoveranychoiceofd1attributesareidentical),butwhoserespective\n",
      "setsof\"-optimalregressorsaredisjoint.However,incontrasttoTheorem1,\n",
      "bothhandlinggeneraldalongwithswitchingtotheabsolutelossintroduce\n",
      "additionalcomplexitiestotheproofthatrequirettechniques.Westart\n",
      "byconstructingthesetwodistributionsD1andD2.LetX1=\n",
      "f\n",
      "x=(x1,..\n",
      ".,xd):x2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "d,kxk1?0(mod2)\n",
      "g\n",
      "andX2=\n",
      "f\n",
      "x=(x1,...,xd\n",
      "):x2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "d,kxk1?1(mod2)\n",
      "g\n",
      ",andletD1andD2beuniformoverX1\n",
      "?\n",
      "f\n",
      "1\n",
      "g\n",
      "andX2?\n",
      "f\n",
      "1\n",
      "g\n",
      ",respectively.Fromthisconstruction,itisnothardtosee\n",
      "thatforanychoiceofk?d1attributes,themarginalsoverthekattributes\n",
      "ofbothdistributionsareidentical:theyarebothauniformdistributionoverk\n",
      "bits.Thus,thedistributionsD1andD2areindistinguishabletoalearnerthat\n",
      "canonlyobserveatmostd1attributesofeachexample.Let`(w>x\n",
      "y)=|w>x\n",
      "y|,andlet1\n",
      "5\n",
      "\n",
      "LD1(w)=E(x,y)?D1[`(w>x,y)]=\n",
      "2d\n",
      "LD2(w)=E(x,y)?D2[`(w>x,y)]=\n",
      "2d1\n",
      "and\n",
      "1\n",
      "1\n",
      "X\n",
      "|w>x\n",
      "1|,\n",
      "X\n",
      "|w>x\n",
      "1|.\n",
      "x2X1\n",
      "x2X2\n",
      "ItturnsoutthatthesubgradientsofLD1(w)andLD2(w),whichwe\n",
      "denoteby@LD1(w)and@LD2(w)respectively,canbeexpressedprecisely.\n",
      "Infact,thefullsubgradientsetateverypointinthedomainforbothfunctions\n",
      "canbemadeexplicit.Withtheserepresentationsinhand,wecanshowthat\n",
      "2w?1=d21dandw?2=d+21dareminimizersofLD1(w)andLD2(w),\n",
      "respectively.4\n",
      "Figure1:GeometricintuitionforLemmas6and7.Thelowerbounding\n",
      "absolutevaluefunctionactsasarelaxationofthetrueexpectedlossLD(de-\n",
      "pictedhereasacone).Infact,usingthesubgradientsetswecanproveamuch\n",
      "strongerpropertyoftheexpectedlossesLD1andLD2,akintoa?directional\n",
      "strongconvexity?propertyaroundtheirrespectiveminimizers.Thegeometric\n",
      "ideabehindthispropertyisshowninFigure1,wherebyLDislowerbounded\n",
      "byanabsolutevaluefunction.Lemma6.Letw?1=d21d.Foranyw2Rd\n",
      "wehavep2?LD1(w)LD1(w?1)p?1>d(ww?1).e4d2Lemma7.Let\n",
      "w?2=d+21d.Foranyw2Rdwehavep2??LD2(w)LD2(w2)p?1>d\n",
      "(ww?2).e4dGivenLemmas6and7,theproofofTheorem3isimmediate.\n",
      "ProofofTheorem3.AsadirectconsequenceofLemmas6and7,weobtain\n",
      "thatthesetsp89>>2?>?=S1=<>w:e4pd?1d(ww1)?\">:;and\n",
      "p89>>2?>?=S2=<w:?1(ww)?\"p2d>>4ed:;containthe\n",
      "setsof\"-optimalregressorsforLD1(w)andLD2(w),respectively.Allthat\n",
      "isneedednow31istoshowaseparationoftheir\"-optimalsetsfor0<\"<60\n",
      "d2,andthisisdonebyshowinga31separationofthemoremanageablesets\n",
      "S1andS2.Indeed,0<\"<60d2andobservethatforanyw2S1wehave\n",
      "p2?pe4d\n",
      "?1>d(w1>dw\n",
      "w?1)?2\n",
      "160d\n",
      "32\n",
      "1>22d\n",
      "Ontheotherhand,foranyw2S2wehave\n",
      "p2?pe4d\n",
      "6\n",
      "\n",
      "andso,ford\n",
      "4,\n",
      "12d+3=.d+2d+2\n",
      "?1>d(w\n",
      "w?2)?\n",
      "160d\n",
      "32\n",
      ",thus\n",
      "2d12d12d+1+<+=.d+22dd+2d+2d+2Weseethatnowcan\n",
      "existinbothS1andS2,sothesesetsaredisjoint.Theorem3followsbythe\n",
      "samereasoningusedtoconcludetheproofofTheorem1.?1>dw?\n",
      "5\n",
      "ItremainstoproveLemmas6and7.Astheproofsareverysimilar,wewill\n",
      "onlyproveLemma6hereanddefertheproofofLemma7tothesupplementary\n",
      "material.ProofofLemma6.Wewrite1\n",
      "@LD1(w)=Lettingw?1=\n",
      "2d1\n",
      "2d\n",
      "X\n",
      "@`(w>x,1)=\n",
      "x2X1\n",
      "12d1\n",
      "X\n",
      "sign(w>x\n",
      "x2X1\n",
      "1)?x.\n",
      "?1d,wehavethat1X@LD1(w?1)=d1sign(w?>1x1)?x2x2X11\n",
      "?X=d1sign(w?>1x1)?x2x2X,1\n",
      "kxk1=d2\n",
      "+\n",
      "X\n",
      "x2X1,kxk1>d2\n",
      "=\n",
      "1?X\n",
      "2d\n",
      "1\n",
      "sign(w?>1x\n",
      "x2X1,kxk1=d2\n",
      "1)?x+\n",
      "sign(0)?x+\n",
      "X\n",
      "X\n",
      "x2X1,kxk1<d2\n",
      "x\n",
      "x2X1,kxk1>d2\n",
      "sign(w?>1xX\n",
      "7\n",
      "\n",
      "x2X1,kxk1<d2\n",
      "1)?x\n",
      "?\n",
      "?x,\n",
      "wheresign(0)canbeanynumberin[1,1].Next,wecomputeX\n",
      "X\n",
      "x\n",
      "x2X1,kxk1>d2\n",
      "d\n",
      "x=\n",
      "x2X1,kxk1<d2\n",
      "2X\n",
      "i=d4+1\n",
      "d2i\n",
      "d\n",
      "=\n",
      "22X\n",
      "i=0\n",
      "d\n",
      "=\n",
      "d2\n",
      "(1)\n",
      "i\n",
      "!1?1d1d\n",
      "1i\n",
      "!2?1d,2\n",
      "!\n",
      "d\n",
      "41Xd2ii=1\n",
      "!1?1d1\n",
      "?1d\n",
      "????Pwherethelastequalityfollowsfromtheelementaryidentity\n",
      "ki=0(1)ini=(1)knk1,whichweproveinLemma9inthesupplementary\n",
      "material.Now,letX?=\n",
      "f\n",
      "x2X1:kxk1=d2\n",
      "g\n",
      ",letm=|X?|,andletX\n",
      "=[x1,...,xm]2Rd?mbethematrixformedbyallx2X?.Thenwemay\n",
      "expresstheentiresubgradientsetexplicitlyas!?1??d2@LD1(w?1)=d\n",
      "1Xr+d?1dr2[1,1]m.222\n",
      "Thus,anychoiceofr2[1,1]mwillresultinaspsubgradientofLD1\n",
      "(w?1).Considertwosuch?d1?choices:r1=0andr2=1d.NotethatXr1=\n",
      "0andXr2=?1d;toseethelastequality,d21consideranycoordinate\n",
      "iandnoticethatthenumberofelementsinX?withnon-zerovaluesinthe\n",
      "i?thcoordinateisequaltothenumberofwaystochoosetheremainingd21\n",
      "non-zerocoordinatesfromtheotherd1coordinates.Wethenobservethatthe\n",
      "correspondingsubgradientsare!!!1d21d2h+=d1Xr1+d?1d=d1\n",
      "d?1d,222222and\n",
      "8\n",
      "\n",
      "!!!21d2?1=?1d.dd22d12d1d212Notethat,sincethesetof\n",
      "subgradientsofLD1(w?1)isaconvexset,bytakingaconvexcombinationof\n",
      "h+andhitfollowsthat02@LD1(w?1)andsoweseethatw?1isaminimizer\n",
      "ofLD1(w).h=\n",
      "1\n",
      "Xr2+\n",
      "d\n",
      "6\n",
      "Givenahandleonthesubgradientthatthesecotsarepolynomialin\n",
      "d.pset,wenowshowpObservethat,usingthefactthat2?n(ne)n?n!?e\n",
      "n(ne)n,wehave??d2p!+/2?(d2)de21d21*...q/q?ddd/??\n",
      "?d1d12d22222e2d24d2d2e422e,p!d21*2?d2.p??+/d\n",
      "2d1e2dd112,p!d22?+2*p12d2,edp2?p.4edp\n",
      "p?1d.Sinceh?canbewrittenasaconvexcombinationofh+and0,we\n",
      "seethatLeth?=42?ed?h2@LD1(w?1).Similarlywemayseethat?\n",
      "?ppp!d2d2+/1d21*.2?(d2)e2?2???pp.??./=242d\n",
      "1d212d1e2(d1)d2d2ed2ed22e,Again,sinceh?canbewritten\n",
      "asaconvexcombinationofthevectorshand0inthesubgradientset,wemay\n",
      "concludethath?2@LD1(w?1)aswell.\n",
      "Bythesubgradientinequalityitfollowsthat,forallw2Rd,pLD1(w)\n",
      "LD1(w?1)\n",
      "h?>(w\n",
      "w?1)=\n",
      "h?>(w\n",
      "w?1)=\n",
      "andLD1(w)\n",
      "LD1(w?1)\n",
      "whichtakentogetherimplythatLD1(w)\n",
      "p\n",
      "LD1(w?1)\n",
      "e4\n",
      "2?p?1>d(wd\n",
      "asrequired.\n",
      "4\n",
      "2?p?1>d(ww?1)dp2?p?1>d(ww?1),4ed\n",
      "e4\n",
      "w?1)?\n",
      "GeneralAlgorithmforLimitedPrecision\n",
      "Althoughwehaveestablishedlimitsontheattainableprecisionforsome\n",
      "learningproblems,thereisstillthepossibilityofreachingthislimit.Inthis\n",
      "sectionweprovideageneralalgorithm,wherebyaplearnerthatcanobservek\n",
      "<dattributescanalwaysachieveanexpectedlossofO(1k/d).Weprovidethe\n",
      "pseudo-codeinAlgorithm1.AlthoughsimilartotheAERRalgorithmofHazan\n",
      "andKoren[6]?whichisdesignedtoworkonlywiththesquaredloss?Algorithm1\n",
      "avoidsthenecessityofanunbiasedgradientestimatorbyreplacingtheoriginal\n",
      "lossfunctionwithaslightlybiasedone.Aslongasthenewlossfunctionischosen\n",
      "9\n",
      "\n",
      "carefully(andthefunctionsareLipschitzbounded),andgivenenoughsamples,\n",
      "thealgorithmcanreturnaregressoroflimitedprecision.Thisisincontrast\n",
      "toAERRwherebyanarbitrarilypreciseregressorcanalwaysbeachievedwith\n",
      "enoughsamples.Formally,forAlgorithm1weprovethefollowing(proofinthe\n",
      "supplementarymaterial).Theorem8.Let`:R7!RbeanH-Lipschitzfunction\n",
      "over[2B,2B].Assumethe?distributionDissuchthatkxk2?1and\n",
      "|y|?Bwithprobability1.LetB?=max\n",
      "f\n",
      "B,1\n",
      "g\n",
      ",andletw?2Rdwithp.\n",
      "Then,kwk?betheoutputofAlgorithm1,whenrunwith?=G2B?B,and\n",
      "foranyw2mkw?k2?B,r2HBk?2??LD(w)+p+2HB?1E[LD\n",
      "(w)].dm7\n",
      "Algorithm1Generalalgorithmforregreswithmissingat-\n",
      "tributesInput:Lossfunction`,trainingsetS=\n",
      "f\n",
      "(xt,yt)\n",
      "g\n",
      "t2[m],k,B,?>\n",
      "0?withkwk?2?BOutput:Regressorw1:Initializew1,0,kw1k2?B\n",
      "arbitrarily2:fort=1tomdo3:Uniformlychoosesubsetofkindices\n",
      "f\n",
      "it,r\n",
      "g\n",
      "r2[k]from[d]withoutreplacementP4:Setx?t=rk=1x[it,r]?eit,r\n",
      "5:Regressioncase:?tyt)6:Choose?t2@`(w>tx7:case:?t\n",
      ")8:Choose?t2@`(yt?w>tx9:UpdateBwt+1=?(wt?(?t?x?t))\n",
      "max\n",
      "f\n",
      "kwt?(?t?x?t)k2,B\n",
      "g\n",
      "10:endforPm?=m1t=111:ReturnwwtIn\n",
      "particular,form=d/(d\n",
      "k)wehave\n",
      "r2???LD(w)+4HB1E[LD(w)]?\n",
      "andsowhenthelearnerobservesk=doptimum.\n",
      "5\n",
      "k,d\n",
      "p1attributes,theexpectedlossisO(1/d)-awayfrom\n",
      "ConclusionsandFutureWork\n",
      "Inthelimitedattributeobservationsetting,wehaveshowninformation-\n",
      "theoreticlowerboundsforsomevariantsofregression,provingthatadistribution-\n",
      "independentalgorithmforregressionwithabsolutelossthatattains\"errorcan-\n",
      "notexistandclosingthegapforridgeregressionassuggestedbyHazanand\n",
      "Koren[6].Wehavealsoshownthattheprooftechniqueappliedforregression\n",
      "withabsolutelosscanbeextendedtoshowasimilarboundfor\n",
      "withthehingeloss.Inaddition,wehavedescribedageneralpurposealgorithm\n",
      "whichcomplementstheseresultsbyprovidingameansofachievingerroruptoa\n",
      "certainprecisionlimit.Aninterestingpossibilityforfutureworkwouldbetotry\n",
      "tobridgethegapbetweentheupperandlowerboundsoftheprecisionlimits,\n",
      "particularlyinthecaseoftheexponentialgapforwithhingeloss.\n",
      "Anotherdirectionwouldbetodevelopamorecomprehensiveunderstanding\n",
      "oftheselowerboundsintermsofmoregeneralfunctions,oneexamplebeing\n",
      "withlogisticloss.\n",
      "2References\n",
      "[1]S.Ben-DavidandE.Dichterman.Learningwithrestrictedfocusofatten-\n",
      "tion.JournalofComputerandSystemSciences,56(3):277?298,1998.[2]N.\n",
      "10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cesa-Bianchi,S.Shalev-Shwartz,andO.Shamir.Ecientlearningwithpar-\n",
      "tiallyobservedattributes.InProceedingsofthe27thInternationalConference\n",
      "onMachineLearning,2010.[3]N.Cesa-Bianchi,S.Shalev-Shwartz,andO.\n",
      "Shamir.Onlinelearningofnoisydata.IEEETransactionsonInformationThe-\n",
      "ory,57(12):7907?7931,2011.[4]O.Dekel,O.Shamir,andL.Xiao.Learning\n",
      "toclassifywithmissingandcorruptedfeatures.MachineLearningJournal,\n",
      "81(2):149?178,2010.[5]D.Haussler.Decisiontheoreticgeneralizationsofthe\n",
      "PACmodelforneuralnetandotherlearningapplications.Informationand\n",
      "Computation,100(1):78?150,1992.[6]E.HazanandT.Koren.Linearre-\n",
      "gressionwithlimitedobservation.InProceedingsofthe29thInternational\n",
      "ConferenceonMachineLearning(ICML?12),Edinburgh,Scotland,UK,2012.\n",
      "8\n",
      "[7]E.Hazan,R.Livni,andY.Mansour.withlowrankand\n",
      "missingdata.InProceedingsofthe32ndInternationalConferenceonMachine\n",
      "Learning,2015.[8]D.KuklianskyandO.Shamir.Attributetlinear\n",
      "regressionwithdata-dependentsampling.InProceedingsofthe32ndInterna-\n",
      "tionalConferenceonMachineLearning,2015.[9]R.J.A.LittleandD.B.\n",
      "Rubin.StatisticalAnalysiswithMissingData,2ndEdition.WileyInterscience,\n",
      "2002.[10]P.-L.LohandM.J.Wainwright.High-dimensionalregressionwith\n",
      "noisyandmissingdata:Provableguaranteeswithnon-convexity.InAdvancesin\n",
      "NeuralInformationProcessingSystems,2011.[11]A.Rostamizadeh,A.Agar-\n",
      "wal,andP.Bartlett.Learningwithmissingfeatures.InThe27thConference\n",
      "onUncertaintyinIntelligence,2011.[12]R.Tibshirani.Regression\n",
      "shrinkageandselectionviathelasso.JournaloftheRoyalStatisticalSociety,\n",
      "SeriesB,58(1):267?288,1996.[13]M.Zinkevich.Onlineconvexprogramming\n",
      "andgeneralizedgradientascent.InProceedingsofthe20thInter-\n",
      "nationalConferenceonMachineLearning,2003.\n",
      "9\n",
      "11\n",
      "\n",
      "PP5444.pdf\n",
      "PP5444.pdf 16\n",
      "LearningNeuralNetworkPolicieswithGuided\n",
      "PolicySearchunderUnknownDynamics\n",
      "Authoredby:\n",
      "PieterAbbeel\n",
      "SergeyLevine\n",
      "Abstract\n",
      "Wepresentapolicysearchmethodthatusesiterativelylocal\n",
      "linearmodelstooptimizetrajectorydistributionsforlarge,continuous\n",
      "problems.Thesetrajectorydistributionscanbeusedwithintheframe-\n",
      "workofguidedpolicysearchtolearnpolicieswithanarbitraryparame-\n",
      "terization.Ourmethodtime-varyinglineardynamicsmodelstospeed\n",
      "uplearning,butdoesnotrelyonlearningaglobalmodel,whichcanbe\n",
      "whenthedynamicsarecomplexanddiscontinuous.Weshow\n",
      "thatthishybridapproachrequiresmanyfewersamplesthanmodel-free\n",
      "methods,andcanhandlecomplex,nonsmoothdynamicsthatcanposea\n",
      "challengeformodel-basedtechniques.Wepresentexperimentsshowing\n",
      "thatourmethodcanbeusedtolearncomplexneuralnetworkpolicies\n",
      "thatsuccessfullyexecutesimulatedroboticmanipulationtasksinpar-\n",
      "tiallyobservedenvironmentswithnumerouscontactdiscontinuitiesand\n",
      "underactuation.\n",
      "1PaperBody\n",
      "Policysearchmethodscanbedividedintomodel-basedalgorithms,whichuse\n",
      "amodelofthesystemdynamics,andmodel-freetechniques,whichrelyonlyon\n",
      "real-worldexperiencewithoutlearningamodel[10].Althoughmodel-freemeth-\n",
      "odsavoidtheneedtomodelsystemdynamics,theytypicallyrequirepolicies\n",
      "withcarefullydesigned,low-dimensionalparameterizations[4].Ontheother\n",
      "hand,model-basedmethodsrequiretheabilitytolearnanaccuratemodelof\n",
      "thedynamics,whichcanbeveryforcomplexsystems,especiallywhen\n",
      "thealgorithmimposesrestrictionsonthedynamicsrepresentationtomakethe\n",
      "policysearchetandnumericallystable[5].Inthispaper,wepresentahy-\n",
      "bridmethodthatlocal,time-varyinglineardynamicsmodels,whicharenot\n",
      "accurateenoughforstandardmodel-basedpolicysearch.However,wecanuse\n",
      "theselocallinearmodelstotlyoptimizeatime-varyinglinear-Gaussian\n",
      "controller,whichinducesanapproximatelyGaussiandistributionovertrajec-\n",
      "tories.Thekeytothisprocedureistorestrictthechangeinthetrajectory\n",
      "1\n",
      "\n",
      "distributionateachiteration,sothatthetime-varyinglinearmodelremains\n",
      "validunderthenewdistribution.Sincethetrajectorydistributionisapproxi-\n",
      "matelyGaussian,thiscanbedonetly,intermsofbothsamplecountand\n",
      "computationtime.Tothenlearngeneralparameterizedpolicies,wecombine\n",
      "thistrajectoryoptimizationmethodwithguidedpolicysearch.Guidedpolicy\n",
      "searchoptimizespoliciesbyusingtrajectoryoptimizationinaniterativefashion,\n",
      "withthepolicyoptimizedtomatchthetrajectory,andthetrajectoryoptimized\n",
      "tominimizecostandmatchthepolicy.Previousguidedpolicysearchmeth-\n",
      "odsusedmodel-basedtrajectoryoptimizationalgorithmsthatrequiredknown,\n",
      "tiablesystemdynamics[12,13,14].Usingouralgorithm,guidedpolicy\n",
      "searchcanbeperformedunderunknowndynamics.Thishybridguidedpolicy\n",
      "searchmethodhasseveralappealingproperties.First,theparameterizedpolicy\n",
      "neverneedstobeexecutedontherealsystem?allsysteminteractionduring\n",
      "trainingisdone1\n",
      "usingthetime-varyinglinear-Gaussiancontrollers.Stabilizinglinear-Gaussian\n",
      "controllersiseasierthanstabilizingarbitrarypolicies,andthispropertycanbea\n",
      "notablesafetybwhentheinitialparameterizedpolicyisunstable.Second,\n",
      "althoughouralgorithmreliesonatime-varyinglineardynamicsmodel,\n",
      "weshowthatitcanhandlecontact-richtaskswherethetruedynamicsarenot\n",
      "onlynonlinear,butevendiscontinuous.Thisisbecausethelearnedlinearmod-\n",
      "elsaveragethedynamicsfrombothsidesofadiscontinuityinproportiontohow\n",
      "ofteneachsideisvisited,unlikestandardlinearizationmethodsthattiate\n",
      "thedynamics.Thisectivelytransformsadiscontinuousdeterministicproblem\n",
      "intoasmoothstochasticone.Third,ouralgorithmcanlearnpoliciesforpar-\n",
      "tiallyobservedtasksbytrainingaparameterizedpolicythatisonlyallowedto\n",
      "observesomepartsofthestatespace,usingafullyobservedformulationforthe\n",
      "trajectoryoptimizer.Thiscorrespondstofullstateobservationduringtraining\n",
      "(forexampleinaninstrumentedenvironment),butonlypartialobservationat\n",
      "testtime,makingpolicysearchforpartiallyobservedtaskstlyeasier.\n",
      "Inourevaluation,wedemonstratethiscapabilitybytrainingapolicyforinsert-\n",
      "ingapegintoholewhentheprecisepositionoftheholeisunknownattesttime.\n",
      "Thelearnedpolicy,representedbyaneuralnetwork,acquiresastrategythat\n",
      "searchesforandtheholeregardlessofitsposition.Themaincontribution\n",
      "ofourworkisanalgorithmforoptimizingtrajectoriesunderunknowndynamics.\n",
      "Weshowthatthisalgorithmoutperformspriormethodsintermsofbothsample\n",
      "complexityandthequalityofthelearnedtrajectories.Wealsoshowthatour\n",
      "methodcanbeintegratedwithguidedpolicysearch,whichpreviouslyrequired\n",
      "knownmodels,tolearnpolicieswithanarbitraryparameterization,andagain\n",
      "demonstratethattheresultingpolicysearchmethodoutperformspriormethods\n",
      "thatoptimizetheparameterizedpolicydirectly.Ourexperimentalevaluation\n",
      "includessimulatedpeg-in-holeinsertion,high-dimensionaloctopusarmcontrol,\n",
      "swimming,andbipedalwalking.\n",
      "2\n",
      "Preliminaries\n",
      "Policysearchconsistsofoptimizingtheparameters?ofapolicy??(ut\n",
      "|xt),whichisadistributionoveractionsutconditionedonstatesxt,with\n",
      "2\n",
      "\n",
      "respecttotheexpectationofacost`(xt,ut),denotedPTE??[t=1`(xt\n",
      ",ut)].Theexpectationisunderthepolicyandthedynamicsp(xt+1|xt,\n",
      "ut),whichtogetherformadistributionovertrajectories?.WewilluseE??\n",
      "[`(?)]todenotetheexpectedcost.Ouralgorithmoptimizesatime-varying\n",
      "linear-Gaussianpolicyp(ut|xt)=N(Ktxt+kt,Ct),whichallowsfora\n",
      "particularlytoptimizationmethodwhentheinitialstatedistributionis\n",
      "narrowandapproximatelyGaussian.Arbitraryparameterizedpolicies??are\n",
      "optimizedusingtheguidedpolicysearchtechnique,inwhich??istrainedto\n",
      "matchoneormoreGaussianpoliciesp.Inthisway,wecanlearnapolicy\n",
      "thatsucceedsfrommanyinitialstatesbytrainingasinglestationary,nonlin-\n",
      "earpolicy??,whichmightberepresented(forexample)byaneuralnetwork,\n",
      "frommultipleGaussianpolicies.AsweshowinSection5,thisapproachcan\n",
      "outperformmethodsthatsearchforthepolicyparameters?directly,bytak-\n",
      "ingadvantageofthelinear-Gaussianstructureofptoacceleratelearning.For\n",
      "clarity,wewillrefertopasatrajectorydistributionsince,foranarrowCt\n",
      "andwell-behaveddynamics,itinducesanapproximatelyGaussiandistribution\n",
      "overtrajectories,whiletheterm?policy?willbereservedfortheparameterized\n",
      "policy??.Time-varyinglinear-Gaussianpolicieshavepreviouslybeenusedin\n",
      "anumberofmodel-basedandmodel-freemethods[25,16,14]duetotheirclose\n",
      "connectionwithlinearfeedbackcontrollers,whicharefrequentlyusedinclassic\n",
      "deterministictrajectoryoptimization.Thealgorithmwewilldescribebuilds\n",
      "ontheiterativelinear-Gaussianregulator(iLQG),whichoptimizestrajectories\n",
      "byiterativelyconstructinglocallyoptimallinearfeedbackcontrollersundera\n",
      "locallinearizationofthedynamicsandaquadraticexpansionofthecost[15].\n",
      "Underlineardynamicsandquadraticcosts,thevalueorcost-to-gofunctionis\n",
      "quadratic,andcanbecomputedwithdynamicprogramming.TheiLQGal-\n",
      "gorithmalternatesbetweencomputingthequadraticvaluefunctionaroundthe\n",
      "currenttrajectory,andupdatingthetrajectoryusingarolloutofthecorrespond-\n",
      "inglinearfeedbackcontroller.Wewillusesubscriptstodenotederivatives,so\n",
      "that`xutisthederivativeofthecostattimesteptwithrespectto(xt,ut)T\n",
      ",`xu,xutistheHessian,`xtisthederivativewithrespecttoxt,andsoforth.\n",
      "UsingN(fxtxt+futut,Ft)todenotethelocallinear-Gaussianapproximation\n",
      "tothedynamics,iLQGcomputestheandsecondderivativesoftheQand\n",
      "valuefunctionsasfollows:TTQxu,xut=`xu,xut+fxutVx,xt+1fxutQxut\n",
      "=`xut+fxutVxt+1(1)?1Vx,xt=Qx,xt?QTu,xtQu,utQu,x\n",
      "?1Vxt=Qxt?QTu,xtQu,utQut\n",
      "2\n",
      "?t+kt+Kt(xt?x?t)canbeshowntominimizethisquadraticQThe\n",
      "linearcontrollerg(xt)=u??function,wherextandutarethestatesand\n",
      "actionsofthecurrenttrajectory,Kt=?Q?1u,utQu,xt,andkt=?Q?1Q.\n",
      "Wecanalsoconstructalinear-Gaussiancontrollerwiththemeangivenbythe\n",
      "utu,utdeterministicoptimalsolution,andthecovarianceproportionaltothe\n",
      "curvatureoftheQ-function:?t),Q?1p(ut|xt)=N(?ut+kt+Kt(xt\n",
      "?xu,ut)Priorworkhasshownthatthisdistributionoptimizesamaximum\n",
      "entropyobjective[12],givenbyp(?)=arg\n",
      "minp(?)?N(?)\n",
      "3\n",
      "\n",
      "Ep[`(?)]?H(p(?))s.t.p(xt+1|xt,ut)=N(xt+1;fxtxt+futut,\n",
      "Ft),(2)\n",
      "whereHisthetialentropy.Thismeansthatthelinear-Gaussian\n",
      "controllerproducesthewidest,highest-entropydistributionthatalsominimizes\n",
      "theexpectedcost,subjecttothelinearizeddynamicsandquadraticcostfunc-\n",
      "tion.Althoughthisobjectivefromtheexpectedcost,itisusefulasan\n",
      "intermediatestepinalgorithmsthatoptimizesthemorestandardexpectedcost\n",
      "objective[20,12].Ourmethodsimilarlyusesthemaximumentropyobjectiveas\n",
      "anintermediatestep,andconvergestotrajectorydistributionwiththeoptimal\n",
      "expectedcost.However,unlikeiLQG,ourmethodoperatesonsystemswhere\n",
      "thedynamicsareunknown.\n",
      "3\n",
      "TrajectoryOptimizationunderUnknownDynamics\n",
      "WhenthedynamicsN(fxtxt+futut,Ft)areunknown,wecanestimate\n",
      "themusingsamples\n",
      "f\n",
      "(xti,uti)T,xt+1i\n",
      "g\n",
      "fromtherealsystemunderthe\n",
      "previouslinear-Gaussiancontrollerp(ut|xt),where?i=\n",
      "f\n",
      "x1i,u1i,...,\n",
      "xTi,uTi\n",
      "g\n",
      "istheithrollout.Onceweestimatethelinear-Gaussiandynam-\n",
      "icsateachtimestep,wecansimplyrunthedynamicprogrammingalgorithm\n",
      "intheprecedingsectiontoobtainanewlinear-Gaussiancontroller.However,\n",
      "thedynamicsareonlyvalidinalocalregionaroundthesamples,while\n",
      "thenewcontrollergeneratedbyiLQGcanbearbitrarilytfromtheold\n",
      "one.Thefullymodel-basediLQGmethodaddressesthisissuewithalinesearch\n",
      "[23],whichisimpracticalwhentherolloutsmustbestochasticallysampledfrom\n",
      "therealsystem.Withoutthelinesearch,largechangesinthetrajectorywill\n",
      "causethealgorithmtoquicklyfallintounstable,costlypartsofthestatespace,\n",
      "preventingconvergence.Weaddressthisissuebylimitingthechangeinthe\n",
      "trajectorydistributionineachdynamicprogrammingpassbyimposingacon-\n",
      "straintontheKL-divergencebetweentheoldandnewtrajectorydistribution.\n",
      "3.1\n",
      "KL-DivergenceConstraints\n",
      "Underlinear-Gaussiancontrollers,aKL-divergenceconstraintagainstthe\n",
      "previoustrajectorydistributionp?(?)canbeenforcedwithasimplemo\n",
      "cationofthecostfunction.Omittingthedynamicsconstraintforclarity,the\n",
      "constrainedproblemisgivenbyminp(?)?N(?)\n",
      "Ep[`(?)]s.t.DKL(p(?)k?p(?))?.\n",
      "Thistypeofpolicyupdatehaspreviouslybeenproposedbyseveralauthors\n",
      "inthecontextofpolicysearch[1,19,17].Theobjectiveofthisoptimizationis\n",
      "thestandardexpectedcostobjective,andsolvingthisproblemrepeatedly,each\n",
      "timesettingp?(?)tothelastp(?),willminimizeEp(xt,ut)[`(xt,ut)].\n",
      "Using?torepresentthedualvariable,theLagrangianofthisproblemisLtraj\n",
      "(p(?),?)=Ep[`(?)]+?[DKL(p(?)k?p(?))?].Sincep(xt+1|xt,ut)\n",
      "=p?(xt+1|,xt,ut)=N(fxtxt+futut,Ft)duetothelinear-Gaussian\n",
      "dynamicsassumption,theLagrangiancanberewrittenas\"#XLtraj(p(?),\n",
      "?)=Ep(xt,ut)[`(xt,ut)??logp?(ut|xt)]??H(p(?))??.t\n",
      "Dividingbothsidesofthisequationby?givesusanobjectiveofthesame\n",
      "formasEquation(2),whichmeansthatunderlineardynamicswecanminimize\n",
      "4\n",
      "\n",
      "theLagrangianwithrespecttop(?)usingthedynamicprogrammingalgorithm\n",
      "fromtheprecedingsection,withanaugmentedcost?t,ut)=1`(xt,ut)?\n",
      "logp?(ut|xt).Wecanthereforesolvetheoriginalconstrainedfunction`(x?\n",
      "problembyusingdualgradientdescent[2],alternatingbetweenusingdynamic\n",
      "programmingto3\n",
      "minimizetheLagrangianwithrespecttop(?),andadjustthedualvariable\n",
      "accordingtotheamountofconstraintviolation.Usingabracketlinesearchwith\n",
      "quadraticinterpolation[7],thisprocedureusuallyconvergeswithinafewiter-\n",
      "ations,especiallyifweacceptapproximateconstraintsatisfaction,forexample\n",
      "bystoppingwhentheKL-divergenceiswithin10%of.Empirically,wefound\n",
      "thatthelinesearchtendstorequirefeweriterationsinlogspace,treatingthe\n",
      "dualasafunctionof?=log?,whichalsohastheconvenientofenforcing\n",
      "thepositivityof?.Thedynamicprogrammingpassdoesnotguaranteethat\n",
      "Q?1u,ut,whichisthecovarianceofthelinearGaussiancontroller,willalways\n",
      "remainpositivesincenonconvexcostfunctionscanintroducenegative\n",
      "eigenvaluesintoEquation(1)[23].Toaddressthisissue,wecansimplyincrease\n",
      "?untileachQu,utbecomespositivewhichisalwayspossible,since\n",
      "thepositiveprecisionmatrixofp?(ut|xt),multipliedby?,enters\n",
      "additivelyintoQu,ut.ThismightsometimesresultintheKL-divergencebeing\n",
      "lowerthan,thoughthishappensrarelyinpractice.Thestepcanbeadap-\n",
      "tivelyadjustedbasedonthediscrepancybetweentheimprovementintotalcost\n",
      "predictedunderthelineardynamicsandquadraticcostapproximation,andthe\n",
      "actualimprovement,whichcanbeestimatedusingthenewlineardynamicsand\n",
      "quadraticcost.Sincethesequantitiesonlyinvolveexpectationsofquadratics\n",
      "underGaussians,theycanbecomputedanalytically.Theamountofimprove-\n",
      "mentobtainedfromoptimizingp(?)dependsontheaccuracyoftheestimated\n",
      "dynamics.Ingeneral,thesamplecomplexityofthisestimationdependsonthe\n",
      "dimensionalityofthestate.However,thedynamicsatnearbytimestepsand\n",
      "evensuccessiveiterationsarecorrelated,andwecanexploitthiscorrelationto\n",
      "reducetherequirednumberofsamples.3.2\n",
      "BackgroundDynamicsDistribution\n",
      "Whenthedynamics,wecanusepriorstogreatlyreducethenumber\n",
      "ofsamplesrequiredateachiteration.Whilethesepriorscanbeconstructed\n",
      "usingdomainknowledge,amoregeneralapproachistoconstructthepriorfrom\n",
      "samplesatothertimestepsanditerations,byabackgrounddynamics\n",
      "distributionasakindofcrudeglobalmodel.Forphysicalsystemssuchas\n",
      "robots,agoodchoiceforthisdistributionisaGaussianmixturemodel(GMM),\n",
      "whichcorrespondstosoftlypiecewiselineardynamics.Thedynamicsofarobot\n",
      "canbereasonablyapproximatedwithsuchpiecewiselinearfunctions[9],and\n",
      "theyarewellsuitedforcontacts,whichareapproximatelypiecewiselinearwith\n",
      "ahardboundary.IfwebuildaGMMovervectors(xt,ut,xt+1)T,wesee\n",
      "thatwithineachclusterci,theconditionalci(xt+1|xt,ut)representsa\n",
      "linear-Gaussiandynamicsmodel,whilethemarginalci(xt,ut)speesthe\n",
      "regionofthestate-actionspacewherethismodelisvalid.AlthoughtheGMM\n",
      "models(softly)piecewiselineardynamics,itisnotnecessarilyagoodforward\n",
      "model,sincethemarginalsci(xt,ut)willnotalwaysdelineatethecorrect\n",
      "5\n",
      "\n",
      "boundarybetweentwolinearmodes.Inthecaseofcontacts,theboundary\n",
      "mighthaveacomplexshapethatisnotwellmodeledbyaGMM.However,if\n",
      "weusetheGMMtoobtainapriorforlinearregression,itiseasytodetermine\n",
      "thecorrectlinearmodefromthecovarianceof(xti,uti)withxt+1iinthe\n",
      "currentsamplesattimestept.Thetime-varyinglineardynamicscanthen\n",
      "capturetlinearmodesatttimestepsdependingontheactual\n",
      "observedtransitions,evenifthestatesareverysimilar.TousetheGMMto\n",
      "constructapriorforthedynamics,wetheGMMateachiterationtoall\n",
      "ofthesamplesatalltimestepsfromthecurrentiteration,aswellasseveral\n",
      "priorinterations,inordertoensurethattsamplesareavailable.We\n",
      "thenestimatethetime-varyinglineardynamicsbyaGaussiantothe\n",
      "samples\n",
      "f\n",
      "xti,uti,xt+1i\n",
      "g\n",
      "ateachtimestep,whichcanbeconditionedon(xt\n",
      ",ut)Ttoobtainlinear-Gaussiandynamics.TheGMMisusedtoproducea\n",
      "normal-inverseWishartpriorforthemeanandcovarianceofthisGaussianat\n",
      "eachtimestep.Toobtaintheprior,weinfertheclusterweightsforthesamples\n",
      "atthecurrenttimestep,andthenusetheweightedmeanandcovarianceofthese\n",
      "clustersasthepriorparameters.Wefoundthatthebestresultswereproduced\n",
      "bylargemixturesthatmodeledthedynamicsinhighdetail.Inpractice,the\n",
      "GMMallowedustoreducethesamplesateachiterationbyafactorof4to8,\n",
      "wellbelowthedimensionalityofthesystem.\n",
      "4\n",
      "GeneralParameterizedPolicies\n",
      "Thealgorithmintheprecedingsectionoptimizestime-varyinglinear-Gaussian\n",
      "controllers.Tolearnarbitraryparameterizedpolicies,wecombinethisalgorithm\n",
      "withaguidedpolicysearch(GPS)ap4\n",
      "Algorithm1Guidedpolicysearchwithunknowndynamics1:foriteration\n",
      "k=1toKdo2:Generatesamples\n",
      "f\n",
      "?ij\n",
      "g\n",
      "fromeachlinear-Gaussiancontroller\n",
      "pi(?)byperformingrollouts3:Fitthedynamicspi(xt+1|xt,ut)tothe\n",
      "samples\n",
      "f\n",
      "?ij\n",
      "g\n",
      "P4:Minimizei,t?i,tDKL(pi(xt)??(ut|xt)kpi(xt,ut))with\n",
      "respectto?usingsamples\n",
      "f\n",
      "?ij\n",
      "g\n",
      "5:Updatepi(ut|xt)usingthealgorithmin\n",
      "Section3andthesupplementaryappendix6:Incrementdualvariables?i,tby\n",
      "?DKL(pi(xt)??(ut|xt)kpi(xt,ut))7:endfor8:returnoptimizedpolicy\n",
      "parameters?proach.InGPSmethods,theparameterizedpolicyistrained\n",
      "insupervisedfashiontomatchsamplesfromatrajectorydistribution,andthe\n",
      "trajectorydistributionisoptimizedtominimizebothitscostand\n",
      "fromthecurrentpolicy,therebycreatingagoodtrainingsetforthepolicy.By\n",
      "turningpolicyoptimizationintoasupervisedproblem,GPSalgorithmscantrain\n",
      "complexpolicieswiththousandsofparameters[12,14],andsinceourtrajectory\n",
      "optimizationalgorithmexploitsthestructureoflinear-Gaussiancontrollers,it\n",
      "canoptimizetheindividualtrajectorieswithfewersamplesthangeneral-purpose\n",
      "model-freemethods.Asaresult,thecombinedapproachcanlearncomplex\n",
      "policiesthataretotrainwithpriormethods,asshowninourevaluation.\n",
      "WebuildontherecentlyproposedconstrainedGPSalgorithm,whichenforces\n",
      "agreementbetweenthepolicyandtrajectorybymeansofasoftKL-divergence\n",
      "constraint[14].ConstrainedGPSoptimizesthemaximumentropyobjectiveE??\n",
      "[`(?)]?H(??),butourtrajectoryoptimizationmethodallowsustousethe\n",
      "6\n",
      "\n",
      "morestandardexpectedcostobjective,resultinginthefollowingoptimization:\n",
      "minEp(?)[`(?)]s.t.DKL(p(xt)??(ut|xt)kp(xt,ut))=0?t.?,p(?)\n",
      "Iftheconstraintisenforcedexactly,thepolicy??(ut|xt)isidenticalto\n",
      "p(ut|xt),andtheoptimizationminimizesthecostunder??,givenbyE??\n",
      "[`(?)].ConstrainedGPSenforcestheseconstraintssoftly,sothat??andp\n",
      "graduallycomeintoagreementoverthecourseoftheoptimization.Ingeneral,\n",
      "wecanusemultipledistributionspi(?),witheachtrajectorystartingfroma\n",
      "tinitialstateorintconditions,butwewillomitthesubscript\n",
      "forsimplicity,sinceeachpi(?)istreatedidenticallyandindependently.The\n",
      "LagrangianofthisproblemisgivenbyLGPS(?,p,?)=Ep(?)[`(?)]+\n",
      "TX\n",
      "?tDKL(p(xt)??(ut|xt)kp(xt,ut)).\n",
      "t=1\n",
      "TheGPSLagrangianisminimizedwithrespectto?andp(?)inalternating\n",
      "fashion,withthedualvariables?tupdatedtoenforceconstraintsatisfaction.\n",
      "OptimizingLGPSwithrespecttop(?)correspondstotrajectoryoptimiza-\n",
      "tion,whichinourcaseinvolvesdualgradientdescentonLtrajinSection3.1,\n",
      "andoptimizingwithrespect?correspondstosupervisedpolicyoptimizationto\n",
      "minimizetheweightedsumofKL-divergences.TheconstrainedGPSmethod\n",
      "alsousesdualgradientdescenttoupdatethedualvariables,butwefoundthat\n",
      "inpractice,itisunnecessary(and,intheunknownmodelsetting,extremely\n",
      "t)tooptimizeLGPSwithrespecttop(?)and?toconvergenceprior\n",
      "toeachdualvariableupdate.Instead,weincrementthedualvariablesafter\n",
      "eachiterationwithamultiple?oftheKL-divergence(?=10workswell),\n",
      "whichcorrespondstoapenaltymethod.Notethatthedualgradientdescent\n",
      "onLtrajduringtrajectoryoptimizationisunrelatedtothepolicyconstraints,\n",
      "andistreatedasaninnerloopblack-boxoptimizerbyGPS.Pseudocodefor\n",
      "ourmoedconstrainedGPSmethodisprovidedinAlgorithm1.Thepolicy\n",
      "KLdivergencetermsintheobjectivealsonecessitateamodynamicpro-\n",
      "grammingmethod,whichcanbefoundinpriorwork[14],butthestepsize\n",
      "constraintsarestillenforcedasdescribedintheprecedingsection,bymodi-\n",
      "fyingthecost.Thesamesamplesthatareusedtothedynamicsarealso\n",
      "usedtotrainthepolicy,withthepolicytrainedtominimize?tDKL(??(ut\n",
      "|xti)kp(ut|xti))ateachsampledstatexti.Furtherdetailsaboutthis\n",
      "algorithmcanbefoundinthesupplementaryappendix.Althoughthismethod\n",
      "optimizestheexpectedcostofthepolicy,duetothealternatingoptimization,\n",
      "itsentropytendstoremainhigh,sinceboththepolicyandtrajectorymust\n",
      "decreasetheirentropytogethertosatisfytheconstraint,whichrequiresmany\n",
      "alternatingsteps.Tospeedupthisprocess,wefounditusefultoregularize\n",
      "thepolicybypenalizingitsentropydirectly,whichspeedsupconvergenceand\n",
      "producesmoredeterministicpolicies.5\n",
      "2Dinsertion\n",
      "0.4\n",
      "0.2\n",
      "0.2\n",
      "100\n",
      "7\n",
      "\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "samples\n",
      "600\n",
      "700\n",
      "800\n",
      "0\n",
      "octopusarm\n",
      "5\n",
      "targetdistance\n",
      "distancetravelled\n",
      "targetdistance\n",
      "0.6\n",
      "0.4\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "REPSI(100Isamp)\n",
      "700\n",
      "itr2\n",
      "800\n",
      "43210\n",
      "200\n",
      "itr4\n",
      "400\n",
      "itr1\n",
      "600\n",
      "800\n",
      "1000\n",
      "samples\n",
      "itr5\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "itr10\n",
      "REPSI(20I+I500Isamp)CEMI(100Isamp)\n",
      "3\n",
      "CEMI(20Isamp)RWRI(100Isamp)\n",
      "2\n",
      "itr1\n",
      "RWRI(20Isamp)10\n",
      "600\n",
      "itr1\n",
      "8\n",
      "\n",
      "iLQG,ItrueImodel\n",
      "4\n",
      "500\n",
      "samples\n",
      "swimming\n",
      "5\n",
      "0.8\n",
      "0.6\n",
      "0\n",
      "3Dinsertion\n",
      "1\n",
      "targetdistance\n",
      "10.8\n",
      "PILCOI(5Isamp)\n",
      "itr20\n",
      "itr40\n",
      "oursI(20Isamp)100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "samples\n",
      "600\n",
      "700\n",
      "800\n",
      "oursI(withIGMM,I5Isamp)\n",
      "Figure1:Resultsforlearninglinear-Gaussiancontrollersfor2Dand3D\n",
      "insertion,octopusarm,andswimming.Ourapproachusesfewersamplesand\n",
      "bettersolutionsthanpriormethods,andtheGMMfurtherreducesthe\n",
      "requiredsamplecount.Imagesinthelower-rightshowthelasttimestepfor\n",
      "eachsystematseveraliterationsofourmethod,withredlinesindicatingend\n",
      "trajectories.\n",
      "5\n",
      "ExperimentalEvaluation\n",
      "Weevaluatedboththetrajectoryoptimizationmethodandgeneralpolicy\n",
      "searchonsimulatedroboticmanipulationandlocomotiontasks.Thestate\n",
      "consistedofjointanglesandvelocities,andtheactionscorrespondedtojoint\n",
      "torques.Theparameterizedpolicieswereneuralnetworkswithonehiddenlayer\n",
      "andasoftreernonlinearityoftheforma=log(1+exp(z)),withlearned\n",
      "diagonalGaussiannoiseaddedtotheoutputstoproduceastochasticpolicy.\n",
      "Thispolicyclasswaschosenforitsexpressiveness,toallowthepolicytolearn\n",
      "awiderangeofstrategies.However,duetoitshighdimensionalityandnonlin-\n",
      "earity,italsopresentsaseriouschallengeforpolicysearchmethods.Thetasks\n",
      "are2Dand3Dpeginsertion,octopusarmcontrol,andplanarswimmingand\n",
      "walking.Theinsertiontasksrequireapegintoanarrowslot,atask\n",
      "thatcomesup,forexample,wheninsertingakeyintoakeyhole,orassembly\n",
      "9\n",
      "\n",
      "withscrewsornails.Theystemsfromtheneedtoalignthepegwith\n",
      "theslotandthecomplexcontactsbetweenthepegandthewalls,whichresult\n",
      "indiscontinuousdynamics.Controlinthepresenceofcontactsisknownto\n",
      "bechallenging,andthisexperimentisimportantforascertaininghowwellour\n",
      "methodcanhandlesuchdiscontinuities.Octopusarmcontrolinvolvesmoving\n",
      "thetipofaarmtoagoalposition[6].Thechallengeinthistaskstems\n",
      "fromitshighdimensionality:thearmhas25degreesoffreedom,corresponding\n",
      "to50statedimensions.Theswimmingtaskrequirescontrollingathree-link\n",
      "snake,andthewalkingtaskrequiresaseven-linkbipedtomaintainatarget\n",
      "velocity.Thechallengeinthesetaskscomesfromunderactuation.Detailsof\n",
      "thesimulationandcostforeachtaskareinthesupplementaryappendix.5.1\n",
      "TrajectoryOptimization\n",
      "Figure1comparesourmethodwithpriorworkonlearninglinear-Gaussian\n",
      "controllersforpeginsertion,octopusarm,andswimming(walkingisdiscussed\n",
      "inthenextsection).Thehorizontalaxisshowsthetotalnumberofsamples,\n",
      "andtheverticalaxisshowstheminimumdistancebetweentheendofthepeg\n",
      "andthebottomoftheslot,thedistancetothetargetfortheoctopusarm,or\n",
      "thetotaldistancetravelledbytheswimmer.Sincethepegis0.5unitslong,\n",
      "distancesabovethisamountcorrespondtocontrollersthatcannotperforman\n",
      "insertion.WecomparetoREPS[17],reward-weightedregression(RWR)[18,\n",
      "11],thecross-entropymethod(CEM)[21],andPILCO[5].WealsouseiLQG\n",
      "[15]withaknownmodelasabaseline,shownasablackhorizontalline.REPSis\n",
      "amodel-freemethodthat,likeourapproach,enforcesaKLdivergenceconstraint\n",
      "betweenthenewandoldpolicy.WecomparetoavariantofREPSthatalso\n",
      "lineardynamicstogenerate500pseudo-samples[16],whichwelabel?REPS\n",
      "(20+500).?RWRisanEMalgorithmthatthepolicytoprevioussamples\n",
      "weightedbytheexponentialoftheirreward,andCEMthepolicytothe\n",
      "bestsamplesineachbatch.WithGaussiantrajectories,CEMandRWRonly\n",
      "intheweights.ThesemethodsrepresentaclassofRLalgorithmsthat\n",
      "thepolicy6\n",
      "2Dinsertionpolicy\n",
      "distancetravelled\n",
      "targetdistance\n",
      "0.6\n",
      "0.4\n",
      "0.4\n",
      "0.2\n",
      "0.2\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "samples\n",
      "600\n",
      "10\n",
      "\n",
      "700\n",
      "800\n",
      "walkingpolicy\n",
      "20\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "samples\n",
      "CEM(100samp)\n",
      "600\n",
      "swimmingpolicy\n",
      "5\n",
      "0.8\n",
      "0.6\n",
      "distancetravelled\n",
      "3Dinsertionpolicy\n",
      "1\n",
      "targetdistance\n",
      "10.8\n",
      "700\n",
      "800\n",
      "43210\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "samples\n",
      "1200\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "#1\n",
      "#2\n",
      "#3\n",
      "#4\n",
      "1400\n",
      "1600\n",
      "CEM(20samp)\n",
      "15\n",
      "RWR(100samp)\n",
      "10\n",
      "11\n",
      "\n",
      "RWR(20samp)5\n",
      "ours(20samp)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "samples\n",
      "600\n",
      "700\n",
      "800\n",
      "ours(withGMM,5samp)\n",
      "Figure2:Comparisononneuralnetworkpolicies.Forinsertion,thepolicy\n",
      "wastrainedtosearchforanunknownslotpositiononfourslotpositions(shown\n",
      "above),andgeneralizationtonewpositionsisgraphedwithdashedlines.Note\n",
      "howtheendtor(inred)followsthesurfacetotheslot,andhowthe\n",
      "swimminggaitissmootherduetothestationarypolicy(alsoseesupplementary\n",
      "video).toweightedsamples,includingPoWERandPI2[11,24,22].PILCOis\n",
      "amodel-basedmethodthatusesaGaussianprocesstolearnaglobaldynamics\n",
      "modelthatisusedtooptimizethepolicy.REPSandPILCOrequiresolving\n",
      "largenonlinearoptimizationsateachiteration,whileourmethoddoesnot.Our\n",
      "methodused5rolloutswiththeGMM,and20without.Duetoitscomputa-\n",
      "tionalcost,PILCOwasprovidedwith5rolloutsperiteration,whileotherprior\n",
      "methodsused20and100.Ourmethodlearnedmuchmoreecontrollers\n",
      "withfewersamples,especiallywhenusingtheGMM.On3Dinsertion,itoutper-\n",
      "formedtheiLQGbaseline,whichusedaknownmodel.Contactdiscontinuities\n",
      "causeproblemsforderivative-basedmethodslikeiLQG,aswellasmethodslike\n",
      "PILCOthatlearnasmoothglobaldynamicsmodel.Weuseatime-varying\n",
      "localmodel,whichpreservesmoredetail,andthemodeltosampleshas\n",
      "asmoothingthatmitigatesdiscontinuityissues.Priorpolicysearchmeth-\n",
      "odscouldservotothehole,butwereunabletoinsertthepeg.Ontheoctopus\n",
      "arm,ourmethodsucceededdespitethehighdimensionalityofthestateand\n",
      "actionspaces.1Priorworkusedsimp?macro-actions?tosolvethistask,\n",
      "whileourmethoddirectlycontrolledeachdegreeoffreedom[6].Ourmethod\n",
      "alsosuccessfullylearnedaswimminggait,whilepriormodel-freemethodscould\n",
      "notinitiateforwardmotion.2PILCOalsolearnedanegaitduetothe\n",
      "smoothdynamicsofthistask,butitsGP-basedoptimizationrequiredordersof\n",
      "magnitudemorecomputationtimethanourmethod,takingabout50minutes\n",
      "periteration.Theseresultssuggestthatourmethodcombinesthesampleef-\n",
      "ofmodel-basedmethodswiththeversatilityofmodel-freetechniques.\n",
      "However,thismethodisdesignedspforlinearGaussiancontrollers.In\n",
      "thenextsection,wepresentresultsforlearningmoregeneralpolicieswithour\n",
      "method,usingthelinear-Gaussiancontrollerswithintheframeworkofguided\n",
      "policysearch.5.2\n",
      "NeuralNetworkPolicyLearningwithGuidedPolicySearch\n",
      "12\n",
      "\n",
      "Byusingourmethodwithguidedpolicysearch,wecanlearnarbitrarypa-\n",
      "rameterizedpolicies.Figure2showsresultsfortrainingneuralnetworkpolicies\n",
      "foreachtask,withcomparisonstopriormethodsthatoptimizethepolicypa-\n",
      "rametersdirectly.3Onswimming,ourmethodachievedsimilarperformanceto\n",
      "thelinear-Gaussiancase,butsincetheneuralnetworkpolicywasstationary,\n",
      "theresultinggaitwasmuchsmoother.Previousmethodscouldonlysolvethis\n",
      "taskwith100samplesperiteration,withRWReventuallyobtainingadistance\n",
      "of0.5mafter4000samples,andCEMreaching2.1mafter3000.Ourmethod\n",
      "wasabletoreachsuchdistanceswithmanyfewersamples.1\n",
      "ThehighdimensionalityoftheoctopusarmmadeittorunPILCO,\n",
      "thoughinprinciple,suchmethodsshouldperformwellonthistaskgiventhe\n",
      "arm?ssmoothdynamics.2EveniLQGrequiresmanyiterationstoinitiate\n",
      "anyforwardmotion,butthenmakesrapidprogress.Thissuggeststhatprior\n",
      "methodsweresimplyunabletogetovertheinitialthresholdofinitiatingforward\n",
      "movement.3PILCOcannotoptimizeneuralnetworkcontrollers,andwecould\n",
      "notobtainreasonableresultswithREPS.PriorapplicationsofREPSgenerally\n",
      "focusonsimpler,lower-dimensionalpolicyclasses[17,16].\n",
      "7\n",
      "Generatingwalkingfromscratchisextremelychallengingevenwithaknown\n",
      "model.Wethereforeinitializethegaitfromdemonstration,asinpriorwork[12].\n",
      "Thesupplementarywebsitealsoshowssomegaitsgeneratedfromscratch.To\n",
      "generatetheinitialsamples,weassumethatthedemonstrationcanbestabilized\n",
      "withalinearfeedbackcontroller.Buildingsuchcontrollersaroundexampleshas\n",
      "beenaddressedinpriorwork[3].TheRWRandCEMpolicieswereinitialized\n",
      "withsamplesfromthiscontrollertoprovideafaircomparison.Thewalkerused\n",
      "5samplesperiterationwiththeGMM,and40withoutit.Thegraphshows\n",
      "theaveragedistancetravelledonrolloutsthatdidnotfall,andshowsthatonly\n",
      "ourmethodwasabletolearnwalkingpoliciesthatsucceededconsistently.On\n",
      "theinsertiontasks,theneuralnetworkwastrainedtoinsertthepegwithout\n",
      "preciseknowledgeofthepositionofthehole,makingthisapartiallyobserved\n",
      "problem.Theholeswereplacedinaregionofradius0.2unitsin2Dand0.1\n",
      "unitsin3D.Thepoliciesweretrainedonfourtholepositions,andthen\n",
      "testedonfournewholepositionstoevaluategeneralization.Thegeneralization\n",
      "resultsareshownwithdashedlinesinFigure2.Thepositionoftheholewas\n",
      "notprovidedtotheneuralnetwork,andthepoliciesthereforehadtothe\n",
      "holeby?feeling?forit,withonlyjointanglesandvelocitiesasinput.Only\n",
      "ourmethodcouldacquireasuccessfulstrategytolocateboththetrainingand\n",
      "testholes,althoughRWRwaseventuallyabletoinsertthepegintooneof\n",
      "thefourholesin2D.Thistaskillustratesoneoftheadvantagesoflearning\n",
      "expressiveneuralnetworkpolicies,sincenosingletrajectory-basedpolicycan\n",
      "representsuchasearchstrategy.Videosofthelearnedpoliciescanbeviewed\n",
      "athttp://rll.berkeley.edu/nips2014gps/.\n",
      "6\n",
      "Discussion\n",
      "Wepresentedanalgorithmthatcanoptimizelinear-Gaussiancontrollers\n",
      "underunknowndynamicsbyiterativelylocallineardynamicsmodels,\n",
      "13\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withabackgrounddynamicsdistributionactingasapriortoreducethesam-\n",
      "plecomplexity.Weshowedthatthisapproachcanbeusedtotrainarbitrary\n",
      "parameterizedpolicieswithintheframeworkofguidedpolicysearch,wherethe\n",
      "parameterizedpolicyisoptimizedtomatchthelinear-Gaussiancontrollers.In\n",
      "ourevaluation,weshowthatthismethodcantraincomplexneuralnetwork\n",
      "policiesthatactintelligentlyinpartiallyobservedenvironments,evenfortasks\n",
      "thatcannotbesolvedwithdirectmodel-freepolicysearch.Byusinglocallinear\n",
      "models,ourmethodisabletooutperformmodel-freepolicysearchmethods.On\n",
      "theotherhand,thelearnedmodelsarehighlylocalandtime-varying,incon-\n",
      "trasttomodel-basedmethodsthatrelyonlearninganeglobalmodel\n",
      "[4].Thisallowsourmethodtohandleeventhecomplicatedanddiscontinu-\n",
      "ousdynamicsencounteredinthepeginsertiontask,whichweshowpresenta\n",
      "challengeformodel-basedmethodsthatusesmoothdynamicsmodels[5].Our\n",
      "approachoccupiesamiddlegroupbetweenmodel-basedandmodel-freetech-\n",
      "niques,allowingittolearnrapidly,whilestillsucceedingindomainswherethe\n",
      "truemodelistolearn.OuruseofaKL-divergenceconstraintduringtra-\n",
      "jectoryoptimizationparallelsseveralpriormodelfreemethods[1,19,17,20,16].\n",
      "Trajectory-centricpolicylearninghasalsobeenexploredindetailinrobotics,\n",
      "withafocusondynamicmovementprimitives(DMPs)[8,24].Time-varying\n",
      "linearGaussiancontrollersareingeneralmoreexpressive,thoughtheyincorpo-\n",
      "ratelesspriorinformation.DMPsconstrainthestatetoagoalstate,and\n",
      "onlyencodetargetstates,relyingonanexistingcontrollertotrackthosestates\n",
      "withsuitablecontrols.Theimprovedperformanceofourmethodisdueinpart\n",
      "totheuseofstrongerassumptionsaboutthetask,comparedtogeneralpolicy\n",
      "searchmethods.Forinstance,weassumethattime-varyinglinearGaussians\n",
      "areareasonablelocalapproximationforthedynamics.Whilethisassumption\n",
      "issensibleforphysicalsystems,itwouldrequireadditionalworktoextendto\n",
      "hybriddiscrete-continuoustasks.Ourmethodalsosuggestssomepromisingfu-\n",
      "turedirections.Sincetheparameterizedpolicyistraineddirectlyonsamples\n",
      "fromtherealworld,itcanincorporatesensoryinformationthatisto\n",
      "simulatebutusefulinpartiallyobserveddomains,suchasforcesensorsona\n",
      "roboticgripper,orevencameraimages,whilethelinear-Gaussiancontrollers\n",
      "aretraineddirectlyonthetruestateunderknown,controlledconditions,asin\n",
      "ourpeginsertionexperiments.Thiscouldprovideforsuperiorgeneralization\n",
      "forpartiallyobservedtasksthatareotherwiseextremelychallengingtolearn.\n",
      "AcknowledgmentsThisresearchwaspartlyfundedbyaDARPAYoungFaculty\n",
      "Award#D13AP0046.8\n",
      "2References\n",
      "[1]J.A.BagnellandJ.Schneider.Covariantpolicysearch.InInternational\n",
      "JointConferenceonIntelligence(IJCAI),2003.[2]S.BoydandL.\n",
      "Vandenberghe.ConvexOptimization.CambridgeUniversityPress,NewYork,\n",
      "NY,2004.[3]A.Coates,P.Abbeel,andA.Ng.Learningforcontrolfrom\n",
      "multipledemonstrations.InInternationalConferenceonMachineLearning\n",
      "14\n",
      "\n",
      "(ICML),2008.[4]M.Deisenroth,G.Neumann,andJ.Peters.Asurveyon\n",
      "policysearchforrobotics.FoundationsandTrendsinRobotics,2(1-2):1?142,\n",
      "2013.[5]M.DeisenrothandC.Rasmussen.PILCO:amodel-basedanddata-\n",
      "tapproachtopolicysearch.InInternationalConferenceonMachine\n",
      "Learning(ICML),2011.[6]Y.Engel,P.Szab?o,andD.Volkinshtein.Learning\n",
      "tocontrolanoctopusarmwithGaussianprocesstemporalmethods.\n",
      "InAdvancesinNeuralInformationProcessingSystems(NIPS),2005.[7]R.\n",
      "Fletcher.PracticalMethodsofOptimization.Wiley-Interscience,NewYork,\n",
      "NY,1987.[8]A.Ijspeert,J.Nakanishi,andS.Schaal.Learningattractor\n",
      "landscapesforlearningmotorprimitives.InAdvancesinNeuralInformation\n",
      "ProcessingSystems(NIPS),2003.[9]S.M.Khansari-ZadehandA.Billard.\n",
      "BM:Aniterativealgorithmtolearnstablenon-lineardynamicalsystemswith\n",
      "gaussianmixturemodels.InInternationalConferenceonRoboticsandAu-\n",
      "tomation(ICRA),2010.[10]J.Kober,J.A.Bagnell,andJ.Peters.Reinforce-\n",
      "mentlearninginrobotics:Asurvey.InternationalJournalofRoboticResearch,\n",
      "32(11):1238?1274,2013.[11]J.KoberandJ.Peters.Learningmotorprimitives\n",
      "forrobotics.InInternationalConferenceonRoboticsandAutomation(ICRA),\n",
      "2009.[12]S.LevineandV.Koltun.Guidedpolicysearch.InInternational\n",
      "ConferenceonMachineLearning(ICML),2013.[13]S.LevineandV.Koltun.\n",
      "Variationalpolicysearchviatrajectoryoptimization.InAdvancesinNeural\n",
      "InformationProcessingSystems(NIPS),2013.[14]S.LevineandV.Koltun.\n",
      "Learningcomplexneuralnetworkpolicieswithtrajectoryoptimization.InIn-\n",
      "ternationalConferenceonMachineLearning(ICML),2014.[15]W.Liand\n",
      "E.Todorov.Iterativelinearquadraticregulatordesignfornonlinearbiological\n",
      "movementsystems.InICINCO(1),pages222?229,2004.[16]R.Lioutikov,\n",
      "A.Paraschos,G.Neumann,andJ.Peters.Sample-basedinformation-theoretic\n",
      "stochasticoptimalcontrol.InInternationalConferenceonRoboticsandAu-\n",
      "tomation,2014.[17]J.Peters,K.M?ulling,andY.Alt?un.Relativeentropy\n",
      "policysearch.InAAAIConferenceonIntelligence,2010.[18]J.Pe-\n",
      "tersandS.Schaal.Applyingtheepisodicnaturalactor-criticarchitectureto\n",
      "motorprimitivelearning.InEuropeanSymposiumonNeuralNet-\n",
      "works(ESANN),2007.[19]J.PetersandS.Schaal.Reinforcementlearningof\n",
      "motorskillswithpolicygradients.NeuralNetworks,21(4):682?697,2008.[20]\n",
      "K.Rawlik,M.Toussaint,andS.Vijayakumar.Onstochasticoptimalcontrol\n",
      "andreinforcementlearningbyapproximateinference.InRobotics:Scienceand\n",
      "Systems,2012.[21]R.RubinsteinandD.Kroese.TheCross-EntropyMethod:\n",
      "AApproachtoCombinatorialOptimization,Monte-CarloSimulation\n",
      "andMachineLearning.Springer,2004.[22]F.StulpandO.Sigaud.Pathin-\n",
      "tegralpolicyimprovementwithcovariancematrixadaptation.InInternational\n",
      "ConferenceonMachineLearning(ICML),2012.[23]Y.Tassa,T.Erez,and\n",
      "E.Todorov.Synthesisandstabilizationofcomplexbehaviorsthroughonline\n",
      "trajectoryoptimization.InIEEE/RSJInternationalConferenceonIntelligent\n",
      "RobotsandSystems,2012.[24]E.Theodorou,J.Buchli,andS.Schaal.Re-\n",
      "inforcementlearningofmotorskillsinhighdimensions.InInternationalCon-\n",
      "ferenceonRoboticsandAutomation(ICRA),2010.[25]M.Toussaint.Robot\n",
      "trajectoryoptimizationusingapproximateinference.InInternationalConfer-\n",
      "15\n",
      "\n",
      "enceonMachineLearning(ICML),2009.9\n",
      "16\n",
      "\n",
      "PP5283.pdf\n",
      "PP5283.pdf 10\n",
      "MultiscaleFieldsofPatterns\n",
      "Authoredby:\n",
      "PedroFelzenszwalb\n",
      "JohnG.Oberlin\n",
      "Abstract\n",
      "Wedescribeaframeworkforhigh-orderimagemodelsthat\n",
      "canbeusedinavarietyofapplications.Theapproachinvolvesmodeling\n",
      "localpatternsinamultiscalerepresentationofanimage.Localproperties\n",
      "ofacoarsenedimagerenon-localpropertiesoftheoriginalimage.\n",
      "Inthecaseofbinaryimageslocalpropertiesarebythebinary\n",
      "patternsobservedoversmallneighborhoodsaroundeachpixel.Withthe\n",
      "multiscalerepresentationwecapturethefrequencyofpatternsobserved\n",
      "attscalesofresolution.Thisframeworkleadstoexpressivepriors\n",
      "thatdependonarelativelysmallnumberofparameters.Forinference\n",
      "andlearningweuseanMCMCmethodforblocksamplingwithvery\n",
      "largeblocks.Weevaluatetheapproachwithtwoexampleapplications.\n",
      "Oneinvolvescontourdetection.Theotherinvolvesbinarysegmentation.\n",
      "1PaperBody\n",
      "Markovrandomarewidelyusedaspriorsforsolvingavarietyofvision\n",
      "problemssuchasimagerestorationandstereo[5,8].Mostoftheworkinthe\n",
      "areahasconcentratedonlow-ordermodelsinvolvingpairsofneighboringpix-\n",
      "els.However,itisclearthatrealisticimagepriorsneedtocapturehigher-order\n",
      "propertiesofimages.Inthispaperwedescribeageneralframeworkfor\n",
      "high-orderimagemodelsthatcanbeusedinavarietyofapplications.The\n",
      "approachinvolvesmodelinglocalpropertiesinamultiscalerepresentationofan\n",
      "image.Thisleadstoanaturallow-dimensionalrepresentationofahigh-order\n",
      "model.Weconcentrateontheproblemofestimatingbinaryimages.Inthis\n",
      "caselocalimagepropertiescanbecapturedbythebinarypatternsinsmall\n",
      "neighborhoodsaroundeachpixel.WeaFieldofPatterns(FoP)model\n",
      "usinganenergyfunctionthatassignsacosttoeach3x3patternobservedinan\n",
      "imagepyramid.Thecostofapatterndependsonthescalewhereitappears.\n",
      "Figure1showsabinaryimagecorrespondingtoacontourmapfromtheBerke-\n",
      "leysegmentationdataset(BSD)[12,2]andapyramidrepresentationobtained\n",
      "byrepeatedcoarsening.The3x3patternsweobserveafterrepeatedcoarsening\n",
      "dependonlargeneighborhoodsoftheoriginalimage.Thesecoarse3x3pat-\n",
      "1\n",
      "\n",
      "ternscapturenon-localimageproperties.Wetrainmodelsusingamaximum-\n",
      "likelihoodcriteria.Thisinvolvesselectingpatterncostsmakingtheexpected\n",
      "frequencyofpatternsinarandomsamplefromthemodelmatchtheaverage\n",
      "frequencyofpatternsinthetrainingimages.Usingthepyramidrepresentation\n",
      "themodelmatchesfrequenciesofpatternsateachresolution.Inpracticeweuse\n",
      "MCMCmethodsforinferenceandlearning.InSection3wedescribeanMCMC\n",
      "samplingalgorithmthatcanupdateaverylargeareaofanimage(ahorizontal\n",
      "orverticalbandofpixels)inasinglestep,bycombiningtheforward-backward\n",
      "algorithmforone-dimensionalMarkovmodelswithaMetropolis-Hastingspro-\n",
      "cedure.Weevaluatedourmodelsandalgorithmsontwodrentapplications.\n",
      "Oneinvolvescontourdetection.Theotherinvolvesbinarysegmentation.These\n",
      "twoapplicationsrequireverytimagepriors.Forcontourdetectionthe\n",
      "priorshouldencourageanetworkofthincontours,whileforbi1\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "Figure1:(a)Multiscale/pyramidrepresentationofacontourmap.(b)\n",
      "Coarsestimagescaledupforbettervisualization,witha3x3patternhighlighted.\n",
      "Theleftmostobjectintheoriginalimageappearsasa3x3?circle?patterninthe\n",
      "coarseimage.(c)Patchesofcontourmaps(top)thatcoarsentoaparticular\n",
      "3x3pattern(bottom)afterreducingtheirresolutionbyafactorof8.nary\n",
      "segmentationthepriorshouldencouragespatiallycoherentmasks.Inboth\n",
      "caseswecandesignemodelsusingmaximum-likelihoodestimation.1.1\n",
      "RelatedWork\n",
      "FRAMEmodels[24]andmorerecentlyFieldsofExperts(FoE)[15]dened\n",
      "high-orderenergymodelsusingtheresponseoflinearFoPmodelsare\n",
      "closelyrelated.Thedetectionof3x3patternsattresolutionscorre-\n",
      "spondstousingnon-linearofincreasingsize.InFoPwehaveaset\n",
      "ofnon-linearthatdetectcommonpatternsattreso-\n",
      "lutions.Thisavoidslearning,whichleadstoanon-convexoptimization\n",
      "probleminFoE.Arestrictedsetof3x3binarypatternswasconsideredin[6]\n",
      "topriorsforimagerestoration.Binarypatternswerealsousedin[17]to\n",
      "modelcurvatureofabinaryshape.Therehasbeenrecentworkoninference\n",
      "algorithmsforCRFsbybinarypatterns[19]anditmaybepossible\n",
      "todeveloptinferencealgorithmsforFoPmodelsusingthosetechniques.\n",
      "Theworkin[23]edavarietyofmultiresolutionmodelsforimagesbasedon\n",
      "aquad-treerepresentation.Thequad-treeleadstomodelsthatsupportcient\n",
      "learningandinferenceviadynamicprogramming,butsuchmodelsalso\n",
      "fromartifactsduetotheunderlyingtree-structure.Theworkin[7]bi-\n",
      "naryimagepriorsusingdeepBoltzmannmachines.Thosemodelsarebasedon\n",
      "ahierarchyofhiddenvariablesthatisrelatedtoourmultiscalerepresentation.\n",
      "Howeverinourcasethemultiscalerepresentationisadeterministicfunctionof\n",
      "theimageanddoesnotinvolveextrahiddenvariablesas[7].Theapproachwe\n",
      "taketoamultiscalemodelissimilarto[9]wherelocalpropertiesofsub-\n",
      "sampledsignalswhereusedtomodelcurves.Oneofourmotivatingapplications\n",
      "involvesdetectingcontoursinnoisyimages.Thisproblemhasalonghistoryin\n",
      "2\n",
      "\n",
      "computervision,goingbackatleastto[16],whousedatypeofMarkovmodel\n",
      "fordetectingsalientcontours.Relatedapproachesincludethestochasticcom-\n",
      "pletionin[22,21],spectralmethods[11],thecurveindicatorrandom\n",
      "[3],andthemorerecentworkin[1].\n",
      "2\n",
      "FieldsofPatterns(FoP)\n",
      "LetG=[n]?[m]bethegridofpixelsinannbymimage.Letx=\n",
      "f\n",
      "x(i,j)\n",
      "|(i,j)?G\n",
      "g\n",
      "beahiddenbinaryimageandy=\n",
      "f\n",
      "y(i,j)|(i,j)?G\n",
      "g\n",
      "beaset\n",
      "ofobservations(suchasagrayscaleorcolorimage).Ourgoalistoestimatex\n",
      "fromy.Wep(x|y)usinganenergyfunctionthatisasumoftwoterms,\n",
      "1exp(?E(x,y))E(x,y)=EFoP(x)+Edata(x,y)p(x|y)=Z(y)2\n",
      "(1)\n",
      "ItissometimesusefultothinkofEFoP(x)asamodelforbinaryimagesand\n",
      "Edata(x,y)asadatamodeleventhoughtechnicallythereisnosuchdistinction\n",
      "inaconditionalmodel.2.1\n",
      "SinglescaleFoPModel\n",
      "ThesinglescaleFoPmodelisoneofthesimplestenergymodelsthatcan\n",
      "capturethebasicpropertiesofcontourmapsorotherimagesthatcontainthin\n",
      "objects.Weusex[i,j]todenotethebinarypatternbyxinthe3x3\n",
      "windowcenteredatpixel(i,j),treatingvaluesoutsideoftheimageas0.A\n",
      "singlescaleFoPmodelisbythelocalpatternsinx,XEFoP(x)=V\n",
      "(x[i,j]).(2)(i,j)?G\n",
      "HereVisapotentialfunctionassigningcosts(orenergies)tobinarypatterns.\n",
      "Notethatthereare512possiblebinarypatternsina3x3window.Wecanmake\n",
      "themodelinvarianttorotationsandmirrorsymmetriesbytyingparameters\n",
      "together.Theresultingmodelhas102parameters(somepatternshavemore\n",
      "symmetriesthanothers)andcanbelearnedfromsmallerdatasets.Weused\n",
      "invariantmodelsforalloftheexperimentsreportedinthispaper.2.2\n",
      "MultiscaleFoPModel\n",
      "Tocapturenon-localstatisticswelookatlocalpatternsinamultiscalerep-\n",
      "resentationofx.ForamodelwithKscaleslet?(x)=x0,...,xK?1be\n",
      "animagepyramidwherex0=xandxk+1isacoarseningofxk.Herexkisa\n",
      "binaryimageoveragridGk=[n/2k]?[m/2k].Thecoarseningweuse\n",
      "inpracticeisbyalogicalORoperation,xk+1(i,j)=xk(2i,2j)?xk(2i\n",
      "+1,2j)?xk(2i,2j+1)k?xk(2i+1,2j+1)(3)Thisparticularcoarsening\n",
      "mapsconnectedobjectsatonescaleofresolutiontoconnectedobjectsatthe\n",
      "nextscale,butothercoarseningsmaybeappropriateintapplications.\n",
      "AmultiscaleFoPmodelisbythelocalpatternsin?(x),EFoP(x)=\n",
      "K?1X\n",
      "X\n",
      "Vk(xk[i,j]).\n",
      "(4)\n",
      "k=0(i,j)?Gk\n",
      "ThismodelisparameterizedbyKpotentialfunctionsVk.,oneforeach\n",
      "scaleinthepyramid?(x).Inmanyapplicationsweexpectthefrequenciesofa\n",
      "3\n",
      "\n",
      "3x3patterntobetateachscale.Thepotentialfunctionscanencour-\n",
      "ageordiscouragesppatternstooccuratspscales.Notethat?(x)\n",
      "isadeterministicfunctionandthepyramidrepresentationdoesnotintroduce\n",
      "newrandomvariables.Thepyramidsimplyaconvenientwaytospecify\n",
      "potentialfunctionsoverlargeregionsofx.Asinglepotentialfunctioninamul-\n",
      "tiscalemodelcandependonalargeareaofxduetothecoarsenings.Forlarge\n",
      "enoughK(proportionaltologoftheimagesize)theMarkovblanketofapixel\n",
      "canbethewholeimage.WhiletheexperimentsinSection5usetheconditional\n",
      "modelingapproachspbyEquation(1),wecanalsouseEFoPto\n",
      "priorsoverbinaryimages.Samplesfromthesepriorsillustratetheinformation\n",
      "thatiscapturedbyaFoPmodel,speciallytheaddedbofthemultiscale\n",
      "representation.Figure2showssamplesfromFoPpriorstrainedoncontour\n",
      "mapsofnaturalimages.Theempiricalstudiesin[14]suggestthatlow-order\n",
      "Markovmodelscannotcapturetheempiricallengthdistributionofcontours\n",
      "innaturalimages.AmultiscaleFoPmodelcancontrolthesizedistributionof\n",
      "objectsmuchbetterthanalow-orderMRF.Aftercoarseningthediameterofan\n",
      "objectgoesdownbyafactorofapproximatelytwo,andeventuallytheobject\n",
      "ismappedtoasinglepixel.Thescaleatwhichthishappenscanbecaptured\n",
      "bya3x3patternwithan?on?pixelsurroundedby?pixels(thisassumes\n",
      "therearenootherobjectsnearby).Sincethecostofapatterndependsonthe\n",
      "scaleatwhichitappearswecanassignacosttoanobjectthatisbasedloosely\n",
      "uponitssize.2.3\n",
      "DataModel\n",
      "Letybeaninputimageand?(y)beanimagepyramidcomputedfromy.\n",
      "Ourdatamodelsarebysumsoverpixelsinthetwopyramids?(x)and\n",
      "?(y).Inourexperimentsyisagraylevel3\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "Figure2:(a)ExamplesoftrainingimagesTextractedfromtheBSD.(b)\n",
      "SamplesfromasinglescaleFoPpriortrainedonT.(c)Samplesfromamultiscale\n",
      "FoPpriortrainedonT.Themultiscalemodelisbetteratcapturingthelengths\n",
      "ofcontoursandrelationshipsbetweenthem.imagewithvaluesin\n",
      "f\n",
      "0,...,M\n",
      "?1\n",
      "g\n",
      ".Thepyramid?(y)isinanalogyto?(x)exceptthatweusealocal\n",
      "averageforcoarseninginsteadofthelogicalOR,yk+1(i,j)=b(yk(2i,2j)+\n",
      "yk(2i+1,2j)+yk(2i,2j+1)+yk(2i+1,2j+1))/4c\n",
      "(5)\n",
      "ThedatamodelisparameterizedbyKvectorsD0,...,DK?1?RM\n",
      "Edata(x,y)=\n",
      "K?1X\n",
      "X\n",
      "xk(i,j)Dk(yk(i,j))\n",
      "(6)\n",
      "k=0(i,j)?Gk\n",
      "HereDk(yk(i,j))isanobservationcostincurredwhenxk(i,j)=1.There\n",
      "isnoneedtoincludeanobservationcostwhenxk(i,j)=0becauseonlyenergy\n",
      "4\n",
      "\n",
      "theposteriorp(x|y).Wenotethatitwouldbeinterestingto\n",
      "considerdatamodelsthatcapturecomplexrelationshipsbetweenlocalpatterns\n",
      "in?(x)and?(y).Forexamplealocalmaximuminyk(i,j)mightgiveevidence\n",
      "forxk(i,j)=1,oraparticular3x3patterninxk[i,j].2.4\n",
      "Log-LinearRepresentation\n",
      "TheenergyfunctionE(x,y)ofaFoPmodelcanbeexpressedbyadot\n",
      "productbetweenavectorofmodelparameterswandafeaturevector?(x,y).\n",
      "Thevector?(x,y)hasoneblockforeachscale.Inthek-thblockwehave:(1)\n",
      "512(or102forinvariantmodels)entriescountingthenumberoftimeseach3x3\n",
      "patternoccursinxk;and(2)Mentriescountingthenumberoftimeseach\n",
      "possiblevaluefory(i,j)occurswherexk(i,j)=1.Thevectorwspthe\n",
      "costforeachpatternineachscale(Vk)andtheparametersofthedatamodel\n",
      "(Dk).WethenhavethatE(x,y)=w??(x,y).Thislog-linearformisuseful\n",
      "forlearningthemodelparametersasdescribedinSection4.\n",
      "3\n",
      "InferencewithaBandSampler\n",
      "Ininferencewehaveasetofobservationsyandwanttoestimatex.Weuse\n",
      "MCMCmethods[13]todrawsamplesfromp(x|y)andestimatetheposterior\n",
      "marginalprobabilitiesp(x(i,j)=1|y).Samplingisalsousedforlearningmodel\n",
      "parametersasdescribedinSection4.InablockGibbssamplerwerepeatedly\n",
      "updatexbypickingablockofpixelsBandsamplingnewvaluesforxBfrom\n",
      "p(xB|y,xB).IftheblocksareselectedappropriatelythisaMarkov\n",
      "chainwithstationarydistributionp(x|y).WecanimplementablockGibbs\n",
      "samplerforamultiscaleFoPmodelbykeepingtrackoftheimagepyramid?(x)\n",
      "asweupdatex.Tosamplefromp(xB|y,xB)weconsidereachpossible\n",
      "4\n",
      "forxB.Wecantlyupdate?(x)toapossiblefor\n",
      "xBandevaluatethetermsinE(x,y)thatdependonxB.ThistakesO(K|B|)\n",
      "timeforeachforxB.ThisinturnleadstoanO(K|B|2|B|\n",
      ")timealgorithmforsamplingfromp(xB|y,xB?).Therunningtimecan\n",
      "bereducedtoO(K2|B|)usingGraycodestoiterateoverfor\n",
      "xB.Hereweabandsamplerthatupdatesallpixelsinahorizontalor\n",
      "verticalbandofxinasinglestep.ConsiderannbymimagexandletBbe\n",
      "ahorizontalbandofpixelswithhrows.Since|B|=mhastraightforward\n",
      "implementationofblocksamplingforBiscompletelyimpractical.However,\n",
      "foranIsingmodelwecangeneratesamplesfromp(xB|y,xB)inO(m22h\n",
      ")timeusingtheforward-backwardalgorithmforMarkovmodels.Wesimply\n",
      "treateachcolumnofBasasinglevariablewith2hpossiblestates.Asimilar\n",
      "ideacanbeusedforFoPmodels.LetSbeastatespacewhereastatesp\n",
      "ajointofbinaryvaluesforthepixelsinacolumnofB.Notethat\n",
      "|S|=2h.Letz1,...,zmbearepresentationofxBintermsofthestate\n",
      "ofeachcolumn.ForasinglescaleFoPmodelthedistributionp(z1,...,zn\n",
      "|y,xB?)isa2nd-orderMarkovmodel.Thisallowsfortsamplingusing\n",
      "forwardweightscomputedviadynamicprogramming.Suchanalgorithmtakes\n",
      "O(m23h)timetogenerateasamplefromp(xB|y,xB),whichist\n",
      "formoderatevaluesofh.InamultiscaleFoPmodelthe3x3patternsinthe\n",
      "5\n",
      "\n",
      "upperlevelsof?(x)dependonmanycolumnsofB.Thismeansp(z1,...,zn\n",
      "|xB?)isnolonger2nd-order.ThereforeinsteadofsamplingxBdirectlywe\n",
      "useaMetropolis-Hastingsapproach.LetpbeamultiscaleFoPmodelwewould\n",
      "liketosamplefrom.LetqbeasinglescaleFoPmodelthatapproximatesp.\n",
      "LetxbethecurrentstateoftheMarkovchainandx0beaproposalgenerated\n",
      "bythesinglescalebandsamplerforq.Weacceptx0withprobabilitymin(1,\n",
      "((p(x0|y)q(x|y))/(p(x|y)q(x0|y)))).ntcomputationofacceptance\n",
      "probabilitiescanbedoneusingthepyramidrepresentationsofxandy.Foreach\n",
      "proposalweupdate?(x)to?(x0)andcomputetheinenergydueto\n",
      "thechangeunderbothpandq.OneproblemwiththeMetropolis-Hastings\n",
      "approachisthatifproposalsarerejectedveryoftentheresultingMarkovchain\n",
      "mixesslowly.Wecanavoidthisproblembynotingthatmostofthework\n",
      "requiredtogenerateasamplefromtheproposaldistributioninvolvescomputing\n",
      "forwardweightsthatcanbere-usedtogenerateothersamples.Eachstepofour\n",
      "bandsamplerforamultiscaleFoPmodelpicksabandB(horizontalorvertical)\n",
      "andgeneratesmanyproposalsforxB,acceptingeachonewiththeappropriate\n",
      "acceptanceprobability.Aslongasoneoftheproposalsisacceptedthework\n",
      "doneincomputingforwardweightsisnotwasted.\n",
      "4\n",
      "Learning\n",
      "Wecanlearnmodelsusingmaximum-likelihoodandstochasticgradientde-\n",
      "scent.Thisissimilartowhatwasdonein[24,15,20].Butinourcasewehave\n",
      "aconditionalmodelsowemaximizetheconditionallikelihoodofthetraining\n",
      "examples.LetT=\n",
      "f\n",
      "(x1,yi),...,(xN,yN)\n",
      "g\n",
      "beatrainingsetwithN\n",
      "examples.Wethetrainingobjectiveusingthenegativelog-likelihoodof\n",
      "thedataplusaregularizationterm.Theregularizationensuresnopatternis\n",
      "toocostly.ThishelpstheMarkovchainsusedduringlearningandinferenceto\n",
      "mixreasonablyfast.LetL(xi,yi)=?logp(xi|yi).Thetrainingobjective\n",
      "isgivenbyNX?O(w)=||w||2+L(xi,yi).(7)2i=1Thisobjectiveis\n",
      "convexand?O(w)=?w+\n",
      "NX\n",
      "?(xi,yi)?Ep(x|yi)[?(x,yi)].\n",
      "(8)\n",
      "i=1\n",
      "HereEp(x|yi)[?(x,yi)]istheexpectationof?(x,yi)undertheposterior\n",
      "p(x|yi)edbythecurrentmodelparametersw.Astochasticapproxima-\n",
      "tiontothegradient?O(w)canbeobtainedbysamplingx0ifromp(x|yi).Let\n",
      "?bealearningrate.Ineachstochasticgradientdescentstepwesamplex0i\n",
      "fromp(x|yi)andupdatewasfollowsNXw:=w??(?w+?(xi,yi)??(x0i\n",
      ",yi)).(9)i=1\n",
      "5\n",
      "Tosamplethex0iwerunNMarkovchains,oneforeachtrainingexample,\n",
      "usingthebandsamplerfromSection3.Aftereachmodelupdateweadvance\n",
      "eachMarkovchainforasmallnumberofstepsusingthelatestmodelparameters\n",
      "toobtainnewsamplesx0i.\n",
      "5\n",
      "6\n",
      "\n",
      "Applications\n",
      "ToevaluatetheabilityofFoPtoadapttotproblemsweconsidertwo\n",
      "tapplications.Inbothcasesweestimatehiddenbinaryimagesxfrom\n",
      "grayscaleinputimagesy.Weusedgroundtruthbinaryimagesobtainedfrom\n",
      "standarddatasetsandsyntheticobservations.Fortheexperimentsdescribed\n",
      "herewegenerateybysamplingavaluey(i,j)foreachpixelindependentlyfrom\n",
      "anormaldistributionwithstandarddeviation?yandmean?0or?1,depending\n",
      "onx(i,j),y(i,j)?N(?x(i,j),?y2).\n",
      "(10)\n",
      "Wehavealsodoneexperimentswithmorecomplexdatamodelsbutthe\n",
      "resultsweobtainedweresimilartotheresultsdescribedhere.5.1\n",
      "ContourDetection\n",
      "TheBSD[12,2]containsimagesofnaturalscenesandmanualsegmentations\n",
      "ofthemostsalientobjectsinthoseimages.Weusedonemanualsegmentation\n",
      "foreachimageintheBSD500.Fromeachimagewegeneratedacontourmapx\n",
      "indicatingthelocationofboundaryesbetweensegmentsintheimage.Togener-\n",
      "atetheobservationsyweused?0=150,?1=100and?y=40inEquation(10).\n",
      "Ourtrainingandtestsetseachhave200examples.Wetraineda1-scale\n",
      "FoPmodel.Wethentraineda4-levelFoPmodelusingthe1-levelmodelasa\n",
      "proposaldistributionforthebandsampler(seeSection3).Trainingeachmodel\n",
      "took2daysona20-coremachine.Duringtrainingandtestingweusedthe\n",
      "bandsamplerwithh=3rows.Inferenceinvolvesestimatingposteriormarginal\n",
      "probabilitiesforeachpixelbysamplingfromp(x|y).Inferenceoneachimage\n",
      "took20minutesonan8-coremachine.Forcomparisonweimplementedabase-\n",
      "linetechniqueusinglinearFollowing[10]weusedthesecondderivative\n",
      "ofanelongatedGaussiantogetherwithitsHilberttransform.The\n",
      "hadanelongationfactorof4andweexperimentedwithtvaluesfor\n",
      "thebasestandarddeviation?boftheGaussian.Thesumofsquaredresponses\n",
      "ofbothesanorientedenergymap.Weevaluatedtheat16\n",
      "orientationsandtookthemaximumresponseateachpixel.Weperformednon-\n",
      "maximumsuppressionalongthedominantorientationstoobtainathincontour\n",
      "map.Figure3illustratesourresultson3examplesfromthetestset.Resultson\n",
      "moreexamplesareavailableinthesupplementalmaterial.FortheFoPmodels\n",
      "weshowtheposteriormarginalprobabilitiesp(x(i,j)=1|y).Thedarkness\n",
      "ofapixelisproportionaltothemarginalprobability.TheFoPmodelsdoa\n",
      "goodjobsuppressingnoiseandlocalizingthecontours.ThemultiscaleFoP\n",
      "modelinparticulargivesfairlycleanresultsdespitethehighlynoisyinputs.\n",
      "Thebaselineresultsatlower?bvaluesfromtnoise,detecting\n",
      "manyspuriousedges.Thebaselineathigher?bvaluessuppressesnoiseatthe\n",
      "expenseofhavingpoorlocalizationandmissinghigh-curvatureboundaries.For\n",
      "aquantitativeevaluationwecomputeprecision-recallcurvesforthet\n",
      "modelsbythresholdingtheestimatedcontourmapsattvalues.Figure\n",
      "4showstheprecision-recallcurves.Theaverageprecision(AP)wasfoundby\n",
      "calculatingtheareaundertheprecision-recallcurves.The1-levelFoPmodel\n",
      "APwas0.73.The4-levelFoPmodelAPwas0.78.ThebestbaselineAPwas\n",
      "0.18obtainedwith?b=1.Wehavealsodoneexperimentsusinglowerobser-\n",
      "7\n",
      "\n",
      "vationnoiselevels?y.Withlowobservationnoisethe1-leveland4-levelFoP\n",
      "resultsbecomesimilarandbaselineresultsimprovecantlyapproaching\n",
      "theFoPresults.5.2\n",
      "BinarySegmentation\n",
      "ForthisexperimentweobtainedbinaryimagesfromtheSwedishLeafDataset\n",
      "[18].WefocusedontheclassofRowanleavesbecausetheyhavecomplexshapes.\n",
      "Eachimageasegmentationmaskx.Togeneratetheobservationsywe\n",
      "used?0=150,?1=100and?y=100inEquation(10).Weusedahigher?y\n",
      "comparedtothepreviousexperimentbecausethe2Dnatureofmasksmakesit\n",
      "possibletorecoverthemunderhighernoise.Weused50examplesfortraining\n",
      "and256\n",
      "ContourmapxObservationyBaseline?b=1Baseline?b=4FoP1FoP\n",
      "4Figure3:Contourdetectionresults.Top-to-bottom:Hiddencontourmapx,\n",
      "inputimagey,outputoforientedbaselinewith?b=1and?b=4,output\n",
      "of1-leveland4-levelFoPmodel.\n",
      "examplesfortesting.WetrainedFoPmodelswiththesameprocedureand\n",
      "parametersusedforthecontourdetectionexperiment.Forabaseline,weused\n",
      "graph-cuts[5,4]toperformMAPinferencewithanIsingmodel.Wesetthe\n",
      "datatermusingourknowledgeoftheobservationmodelandpickedthepairwise\n",
      "discontinuitycostminimizingtheper-pixelerrorrateinthetestset.Figure\n",
      "5illustratestheresultsofthetmethods.Resultsonotherimagesare\n",
      "availableinthesupplementalmaterial.Theprecision-recallcurvesareinFigure\n",
      "4.Graph-cutsyieldsaprecisionrecallpoint,withprecision0.893andrecall\n",
      "0.916.The1-levelFoPmodelhasahigherprecisionof0.915atthesamerecall.\n",
      "The4-levelFoPmodelraisestheprecisionto0.929atthesamerecall.The7\n",
      "(a)Contourdetection\n",
      "(b)Binarysegmentation\n",
      "Figure4:(a)Precision-recallcurvesforthecontourdetectionexperiment.\n",
      "(b)Precision-recallcurvesforthesegmentationexperiment(thegraph-cuts\n",
      "baselineyieldsasingleprecision-recallpoint).Maskx\n",
      "Observationy\n",
      "Graph-cuts\n",
      "FoP1\n",
      "FoP4\n",
      "Figure5:Binarysegmentationexamples.The4-levelFoPmodeldoesa\n",
      "betterjobrecoveringpixelsneartheobjectboundaryandthestemoftheleaves.\n",
      "inprecisionaresmallbecausetheyareduetopixelsnearthe\n",
      "objectboundarybutthosearethehardestpixelstogetright.Thereareclear\n",
      "thatcanbeseenbyvisualinspection.\n",
      "6\n",
      "Conclusion\n",
      "Wedescribedageneralframeworkforhigh-orderimagemodels.\n",
      "Theideainvolvesmodelinglocalpropertiesinamultiscalerepresentationof\n",
      "animage.Thisleadstoanaturallowdimensionalparameterizationforhigh-\n",
      "ordermodelsthatexploitsstandardpyramidrepresentationsofimages.Our\n",
      "experimentsdemonstratetheapproachyieldsgoodresultsontwoapplications\n",
      "8\n",
      "\n",
      "thatrequireverytimagepriors,illustratingthebroadapplicabilityof\n",
      "ourmodels.AninterestingdirectionforfutureworkistoconsiderFoPmodels\n",
      "fornon-binaryimages.\n",
      "AcknowledgementsWewouldliketothankAlexandraShapiroforhelpful\n",
      "discussionsandinitialexperimentsrelatedtothisproject.Thismaterialis\n",
      "baseduponworksupportedbytheNationalScienceFoundationunderGrant\n",
      "No.1161282.8\n",
      "2References\n",
      "[1]S.Alpert,M.Galun,B.Nadler,andR.Basri.Detectingfaintcurvededges\n",
      "innoisyimages.InECCV,2010.[2]PabloArbelaez,MichaelMaire,Charless\n",
      "Fowlkes,andJitendraMalik.Contourdetectionandhierarchicalimageseg-\n",
      "mentation.PAMI,33(5):898?916,May2011.[3]J.AugustandS.W.Zucker.\n",
      "Sketcheswithcurvature:Thecurveindicatorrandomandmarkovpro-\n",
      "cesses.PAMI,25(4):387?400,April2003.[4]Y.BoykovandV.Kolmogorov.\n",
      "Anexperimentalcomparisonofwalgorithmsforenergymini-\n",
      "mizationinvision.PAMI,26(9):1124?1137,Sep2004.[5]Y.Boykov,O.Veksler,\n",
      "andR.Zabih.tapproximateenergyminimizationviagraphcuts.PAMI,\n",
      "20(12):1222?1239,Nov2001.[6]X.Descombes,J.F.Mangin,E.Pechersky,and\n",
      "M.Sigelle.Finestructurespreservingmarkovmodelforimageprocessing.In\n",
      "SCIA,1995.[7]S.M.Eslami,N.Heess,andJ.Winn.Theshapeboltzmann\n",
      "machine:astrongmodelofobjectshape.CVPR,2012.[8]P.F.Felzenszwalb\n",
      "andD.P.Huttenlocher.Ecientbeliefpropagationforearlyvision.IJCV,\n",
      "70(1),2006.[9]P.F.FelzenszwalbandJ.Schwartz.Hierarchicalmatching\n",
      "ofdeformableshapes.CVPR,2007.[10]T.LeungandJ.Malik.Contour\n",
      "continuityinregion-basedimagesegmentation.ECCV,pages544?559,1998.\n",
      "[11]ShyjanMahamud,LanceR.Williams,KarvelK.Thornber,andKanglin\n",
      "Xu.Segmentationofmultiplesalientclosedcontoursfromrealimages.PAMI,\n",
      "25(4):433?444,2003.[12]DavidR.Martin,CharlessC.Fowlkes,andJiten-\n",
      "draMalik.Learningtodetectnaturalimageboundariesusinglocalbrightness,\n",
      "color,andtexturecues.PAMI,26(5):530?549,2004.[13]R.Neal.Probabilistic\n",
      "inferenceusingmarkovchainmontecarlomethods.TechnicalReportCRG-\n",
      "TR93-1,ComputerScience,UniversityofToronto,1993.[14]XiaofengRen,\n",
      "CharlessFowlkes,andJitendraMalik.Learningprobabilisticmodelsforcon-\n",
      "tourcompletioninnaturalimages.IJCV,77(1-3):47?63,2008.[15]StefanRoth\n",
      "andMichaelJ.Black.Fieldsofexperts.IJCV,82(2):205?229,2009.[16]A.\n",
      "ShashuaandS.Ullman.Structuralsaliency:Thedetectionofgloballysalient\n",
      "structuresusingalocallyconnectednetwork.InICCV,pages321?327,1988.\n",
      "[17]A.Shekhovtsov,P.Kohli,andC.Rother.Curvaturepriorformrf-based\n",
      "segmentationandshapeinpainting.InDAGM,2012.[18]O.J.O.S?oderkvist.\n",
      "Computervisionofleavesfromswedishtrees.Master?sthesis,\n",
      "Link?opingUniversity,September2001.[19]RustemTakhanovandVladimir\n",
      "Kolmogorov.Inferencealgorithmsforpattern-basedcrfsonsequencedata.In\n",
      "ICML,2013.[20]T.Tieleman.Trainingrestrictedboltzmannmachinesus-\n",
      "9\n",
      "\n",
      "ingapproximationstothelikelihoodgradient.InICML,2008.[21]LanceR.\n",
      "WilliamsandDavidW.Jacobs.Localparallelcomputationofstochasticcom-\n",
      "pletionNeuralComputation,9(4):859?881,1997.[22]LanceR.Williams\n",
      "andDavidW.Jacobs.StochasticcompletionAneuralmodelofillu-\n",
      "sorycontourshapeandsalience.NeuralComputation,9(4):837?858,1997.[23]\n",
      "A.S.Willsky.Multiresolutionmarkovmodelsforsignalandimageprocessing.\n",
      "ProceedingsoftheIEEE,90(8):1396?1458,2002.[24]S.C.Zhu,Y.N.Wu,\n",
      "andD.B.Mumford.Filters,randomsandmaximumentropy(FRAME):\n",
      "Towardsatheoryfortexturemodeling.IJCV,27(2):1?20,1998.\n",
      "9\n",
      "10\n",
      "\n",
      "PP5122.pdf\n",
      "PP5122.pdf 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SolvinginverseproblemofMarkovchainwith\n",
      "partialobservations\n",
      "Authoredby:\n",
      "TetsuroMorimura\n",
      "TakayukiOsogami\n",
      "TsuyoshiIde\n",
      "Abstract\n",
      "TheMarkovchainisaconvenienttooltorepresentthedynamicsof\n",
      "complexsystemssuchasandsocialsystems,whereprobabilistic\n",
      "transitiontakesplacebetweeninternalstates.AMarkovchainischar-\n",
      "acterizedbyinitial-stateprobabilitiesandastate-transitionprobability\n",
      "matrix.Inthetraditionalsetting,amajorgoalistooutproperties\n",
      "ofaMarkovchainwhenthoseprobabilitiesareknown.Thispapertackles\n",
      "aninverseversionoftheproblem:wethoseprobabilitiesfrompartial\n",
      "observationsatalimitednumberofstates.Theobservationsincludethe\n",
      "frequencyofvisitingastateandtherateofreachingastatefromanother.\n",
      "Practicalexamplesofthistaskincludemonitoringsystemsincities,\n",
      "whereweneedtoinferthetvolumeoneverysinglelinkonaroad\n",
      "networkfromaverylimitednumberofobservationpoints.Weformulate\n",
      "thistaskasaregularizedoptimizationproblemforprobabilityfunctions,\n",
      "whichistlysolvedusingthenotionofnaturalgradient.Usingsyn-\n",
      "theticandreal-worlddatasetsincludingcitymonitoringdata,we\n",
      "demonstratetheenessofourmethod.\n",
      "1PaperBody\n",
      "TheMarkovchainisastandardmodelforanalyzingthedynamicsofstochastic\n",
      "systems,includingeconomicsystems[29],systems[11],socialsystems\n",
      "[12],andecosystems[6].Thereisalargebodyoftheliteratureontheproblem\n",
      "ofanalyzingthepropertiesaMarkovchaingivenitsinitialdistributionand\n",
      "amatrixoftransitionprobabilities[21,26].Forexample,thereexistestab-\n",
      "lishedmethodsforanalyzingthestationarydistributionandthemixingtime\n",
      "ofaMarkovchain[23,16].Inthesetraditionalsettings,theinitialdistribution\n",
      "andthetransition-probabilitymatrixaregivenaprioriordirectlyestimated.\n",
      "Unfortunately,itisoftenimpracticaltodirectlymeasureorestimatethepa-\n",
      "rameters(i.e.,theinitialdistributionandthetransition-probabilitymatrix)of\n",
      "theMarkovchainthatmodelsaparticularsystemunderconsideration.For\n",
      "1\n",
      "\n",
      "example,onecananalyzeasystem[27,24],includinghowthevehicles\n",
      "aredistributedacrossacity,bymodelingthedynamicsofvehiclesasaMarkov\n",
      "chain[11].Itis,however,todirectlymeasurethefractionofthevehicles\n",
      "thatturnsrightorleftateveryintersection.TheinverseproblemofaMarkov\n",
      "chainthatweaddressinthispaperisaninverseversionofthetraditionalprob-\n",
      "lemofanalyzingaMarkovchainwithgiveninputparameters.Namely,our\n",
      "goalistoestimatetheparametersofaMarkovchainfrompartialobservations\n",
      "ofthecorrespondingsystem.Inthecontextofthesystem,forexample,\n",
      "weseektotheparametersofaMarkovchain,giventhevolumesat\n",
      "stationaryobservationpointsand/ortherateofvehiclesmovingbetween1\n",
      "Figure1:AninverseMarkovchainproblem.Thevolumeonev-\n",
      "eryroadisinferredfromvolumesatlimitedobservationpointsand/or\n",
      "theratesofvehiclestransitioningbetweenthesepoints.thesepoints.Such\n",
      "statisticscanbereliablyestimatedfromobservationswithweb-cameras[27],\n",
      "automaticnumberplaterecognitiondevices[10],orradio-frequencyiden\n",
      "tion(RFID)[25],whoseavailabilityishoweverlimitedtoasmallnumberof\n",
      "observationpointsingeneral(seeFigure1).Byestimatingtheparametersofa\n",
      "Markovchainandanalyzingitsstationaryprobability,onecaninferthe\n",
      "volumesatunobservedpoints.Theprimarycontributionofthispaperisthe\n",
      "methodologyforsolvingtheinverseproblemofaMarkovchainwhenonly\n",
      "theobservationatalimitednumberofstationaryobservationpointsaregiven.\n",
      "Sp,weassumethatthefrequencyofvisitingastateand/ortherate\n",
      "ofreachingastatefromanotheraregivenforasmallnumberofstates.We\n",
      "formulatetheinverseproblemofaMarkovchainasaregularizedoptimization\n",
      "problem.Thenwecantlyasolutiontotheinverseproblemofa\n",
      "Markovchainbasedonthenotionofnaturalgradient[3].Theinverseprob-\n",
      "lemofaMarkovchainhasbeenaddressedintheliterature[9,28,31],butthe\n",
      "existingmethodsassumethatsamplepathsoftheMarkovchainareavailable.\n",
      "Relatedworkofinversereinforcementlearning[20,1,32]alsoassumesthat\n",
      "samplepathsareavailable.Inthecontextofthesystem,thesample\n",
      "pathscorrespondstoprobe-cardata(i.e.,sequenceofGPSpoints).However,\n",
      "theprobe-cardataisexpensiveandrarelyavailableinpublic.Evenwhenitis\n",
      "available,itisoftenlimitedtovehiclesofaparticulartypesuchastaxisorina\n",
      "particularregion.Ontheotherhand,stationaryobservationdataisoftenless\n",
      "expensiveandmoreobtainable.Forinstance,web-cameraimagesareavailable\n",
      "evenindevelopingcountriessuchasKenya[2].Therestofthispaperisorga-\n",
      "nizedasfollows.InSection2,preliminariesareintroduced.InSection3,we\n",
      "formulateaninverseproblemofaMarkovchainasaregularizedoptimization\n",
      "problem.AmethodfortlysolvingtheinverseproblemofaMarkovchain\n",
      "isproposedinSection4.AnexampleofimplementationisprovidedinSection\n",
      "5.Section6evaluatestheproposedmethodwithbothandreal-world\n",
      "datasetsincludingtheonefrommonitoringinacity.\n",
      "2\n",
      "Preliminaries\n",
      "Adiscrete-timeMarkovchain[26,21]isastochasticprocess,X=(X0,X1\n",
      ",...),whereXtisarandomvariablerepresentingthestateattimet?Z?0.\n",
      "2\n",
      "\n",
      "AMarkovchainisbythetriplet\n",
      "f\n",
      "X,pI,pT\n",
      "g\n",
      ",whereX=\n",
      "f\n",
      "1,...,\n",
      "|X|\n",
      "g\n",
      "isasetofstates,where|X|?2isthenumberofstates.The\n",
      "function,pI:X?[0,1],sptheinitial-stateprobability,i.e.,pI(x)?Pr(X0\n",
      "=x),andpT:X?X?[0,1]spthestatetransitionprobabilityfromx\n",
      "tox?,i.e.,pT(x?|x)?Pr(Xt+1=x?|Xt=x),?t?Z?0.Notethe\n",
      "statetransitionisconditionallyindependentofthepaststatesgiventhecurrent\n",
      "state,whichiscalledtheMarkovproperty.AnyMarkovchaincanbeconverted\n",
      "intoanotherMarkovchain,calledaMarkovchainwithrestart,bymodifying\n",
      "thetransitionprobability.There,theinitial-stateprobabilitystaysunchanged,\n",
      "butthestatetransitionprobabilityismointopsuchthatp(x?|x)?\n",
      "?pT(x?|x)+(1??)pI(x?),\n",
      "(1)\n",
      "where??[0,1)isacontinuationrateoftheMarkovchain1.Inthelimitof\n",
      "??1,thisMarkovchainwithrestartisequivalenttotheoriginalMarkovchain.\n",
      "Inthefollowing,werefertopasthe(total)transitionprobability,whilepTas\n",
      "apartialtransition(orp-transition)probability.1Therate?candependon\n",
      "thecurrentstatexsothat?canbereplacedwith?(x)throughoutthepaper.\n",
      "Forreadability,weassume?isaconstant.\n",
      "2\n",
      "Ourmaintargetedapplicationsare(massive)multi-agentsystemssuchas\n",
      "systems.So,restartingachainmeansthatanagent?soriginofatrip\n",
      "isdecidedbytheinitialdistribution,andthetripendsateachtime-stepwith\n",
      "probability1??.Wemodeltheinitialprobabilityandp-transitionprobability\n",
      "withparameters??Rd1and??Rd2,respectively,whered1andd2are\n",
      "thenumbersofthoseparameters.SowewilldenotethoseaspI?andpT?,\n",
      "respectively,andthetotaltransitionprobabilityasp?,where?isthetotal\n",
      "modelparameter,???Rdwhered=d1+d2+1and?????1(?)withthe\n",
      "inverseofsigmoidfunction??[??,??,?]??1.Thatis,Eq.(1)isrewritten\n",
      "asp?(x?|x)??pT?(x?|x)+(1??)pI?(x?).\n",
      "(2)\n",
      "TheMarkovchainwithrestartcanberepresentedasM(?)?\n",
      "f\n",
      "X,pI?,pT?\n",
      ",?\n",
      "g\n",
      ".Alsowemakethefollowingassumptionsthatarestandardforthestudyof\n",
      "Markovchainsandtheirvariants[26,7].Assumption1TheMarkovchainM(?)\n",
      "forany??Rdisergodic(irreducibleandaperiodic).Assumption2Theinitial\n",
      "probabilitypI?andp-transitionprobabilitypT?aretiableeverywhere\n",
      "withrespectto??Rd.2UnderAssumption1,thereexistsauniquestationary\n",
      "probability,??(?),whichthebalanceequation:???(x?)=x?Xp(x?\n",
      "|x)??(x),?x??X,(3)Thisstationaryprobabilityisequaltothelimiting\n",
      "distributionandindependentoftheinitialstate:??(x?)=limt??Pr(Xt\n",
      "=x?|X0=x,M(?)),?x?X.Assumption2indicatesthatthetransition\n",
      "probabilityp?isalsotiableforanystatepair(x,x?)?X?Xwith\n",
      "respecttoany??Rd.FinallywehittingprobabilitiesforaMarkov\n",
      "chainofTheMarkovchain?isrepresentedasM(?)=\n",
      "f\n",
      "X,\n",
      "pT?,?\n",
      "g\n",
      ",whichevolvesaccordingtothep-transitionprobabilitypT?,nottop?\n",
      ",andterminateswithaprobability1??ateverystep.Thehittingprobability\n",
      "ofastatex?givenxisas?|X0=x,M(?)),?h?(x?|x)?Pr(x?\n",
      "3\n",
      "\n",
      "?X(4)?=(X?0,...,X?T)isasamplepathofM(?)?whereXuntilthe\n",
      "stoppingtime,T.\n",
      "3InverseMarkovChainProblemHereweformulateaninverseproblemof\n",
      "theMarkovchainM(?).Intheinverseproblem,themodelfamilyM?\n",
      "f\n",
      "M(?)\n",
      "|??Rd\n",
      "g\n",
      ",whichmaybesubjecttoatransitionstructureasintheroad\n",
      "network,isknownorgivenapriori,butthemodelparameter?isunknown.In\n",
      "Section3.1,weinputsoftheproblem,whichareassociatedwithfunctions\n",
      "oftheMarkovchain.Objectivefunctionsfortheinverseproblemarediscussed\n",
      "inSection3.2.3.1\n",
      "Problemsetting\n",
      "TheinputandoutputofourinverseproblemoftheMarkovchainisas\n",
      "follows.?Inputsarethevaluesmeasuredataportionofstatesx?Xo,where\n",
      "Xo?Xandusually|Xo|?|X|.Themeasuredvaluesincludethe\n",
      "frequencyofvisitingastate,f(x),x?Xo.Inaddition,therateofreaching\n",
      "astatefromanother,g(x,x?),mightalsobegivenfor(x,x?)?Xo?Xo,\n",
      "whereg(x,x)isequalto1.Inthecontextofmonitoring,f(x)denotesthe\n",
      "numberofvehiclesthatwentthroughanobservationpoint,x;g(x,x?)denotes\n",
      "thenumberofvehiclesthatwentthroughxandx?inthisorderdividedbyf\n",
      "(x).?Outputistheestimatedparameter?oftheMarkovchainM(?),which\n",
      "spthetotaltransitionprobabilityfunctionp?inEq.(2).2\n",
      "Weassume\n",
      "???i\n",
      "logpI?(x)=0whenpI?(x)=0,andananalogousassumptionappliesto\n",
      "pT?.\n",
      "3\n",
      "ThestepofourformulationistorelatefandgtotheMarkovchain.\n",
      "Sp,weassumethattheobservedfisproportionaltothetruestationary\n",
      "probabilityoftheMarkovchain:??(x)=cf(x),x?Xo,(5)wherecisan\n",
      "unknownconstanttosatisfythenormalizationcondition.Wefurtherassume\n",
      "thattheobservedreachingrateisequaltothetruehittingprobabilityofthe\n",
      "Markovchain:h?(x?|x)=g(x,x?),(x,x?)?Xo?Xo.(6)3.2\n",
      "Objectivefunction\n",
      "Ourobjectiveistotheparameter??suchthat???andh??well\n",
      "approximate??andh?inEqs.(5)and(6).Weusethefollowingobjective\n",
      "functiontobeminimized,L(?)??Ld(?)+(1??)Lh(?)+?R(?),(7)where\n",
      "LdandLharecostfunctionswithrespecttothequalityoftheapproximationof\n",
      "??andh?,respectively.Thesearespinthefollowingsubsections.The\n",
      "functionR(?)istheregularizationtermof?,suchas||?||22or||?||1\n",
      ".Theparameters??[0,1]and??0balancethesecostfunctionsandthe\n",
      "regularizationterm,whichwillbeoptimizedbycross-validation.Altogether,\n",
      "ourproblemistotheparameter,??=argmin??RdL(?).3.2.1\n",
      "Costfunctionforstationaryprobabilityfunction\n",
      "Because?theconstantcinEq.(5)isunknown,forexample,wecannot\n",
      "minimizeasquarederrorsuchasx?Xo(??(x)???(x))2.Thus,weneedto\n",
      "deriveanalternativecostfunctionof??thatisindependentofc.ForLd(?),\n",
      "4\n",
      "\n",
      "onenaturalchoicemightbeaKullback-Leibler(KL)divergence,????(x)\n",
      "LKL??(x)log=?cf(x)log??(x)+o,d(?)???(x)x?Xo\n",
      "x?Xo\n",
      "whereoisatermindependentof?.TheminimizerofLKLd(?)isindepen-\n",
      "dentofc.However,KLminimizationofLwillleadtoabiasedestimate.This\n",
      "isbecauseLKLwillbedecreasedbydd??increasingx?Xo??(x)whenthe\n",
      "ratios??(x)/??(x),?x,x??Xoareunchanged.Thisimplies??hasan\n",
      "unwantedsidethat,becauseofx?Xo??(x)+x?(XXo)??(x)=1,minimizing\n",
      "LKLd??ofovervaluingx?Xo??(x)andundervaluingx?(XXo)??\n",
      "(x).HereweproposeanalternativeformofLdthatcanavoidthis\n",
      "Itusesalogarithmicratioofthestationaryprobabilitiessuchthat()2()21?\n",
      "???(i)??(i)1??f(i)??(i)Ld(?)?log??log=log?log(8)2?(j)??\n",
      "(j)2f(j)??(j)i?Xoj?Xo\n",
      "i?Xoj?Xo\n",
      "Thelog-ratioofprobabilitiesrepresentsofinformationcontents\n",
      "betweentheseprobabilitiesinthesenseofinformationtheory[17].Thusthis\n",
      "functioncanberegardedasasumofsquarederrorbetween??(x)and??(x)\n",
      "overx?Xowithrespecttorelativeinformationcontents.Inadierentpointof\n",
      "view,Eq.(8)followsfrommaximizingthelikelihoodof?undertheassumption\n",
      "thattheobservation?logf(i)?logf(j)?hasaGaussianwhite?noiseN(0,\n",
      "?2).Thisassumptioniswhenf(i)hasalog-normaldistribution,LN\n",
      "(?i,(?/2)2),independentlyforeachi,where?iisthetruelocationparameter,\n",
      "andthemedianoff(i)isequaltoe?i.3.2.2\n",
      "Costfunctionforhittingprobabilityfunction\n",
      "UnlikeLd(?),thereareseveraloptionsforLh(?).Examplesofthiscost\n",
      "functionincludeameansquarederrorandmeanabsoluteerror.Hereweuse\n",
      "thefollowingstandardsquarederrorsinthelogspace,basedonEq.(6),)21?\n",
      "?(Lh(?)?logg(i,j)?logh?(j|i).(9)2i?Xoj?Xo\n",
      "Eq.(9)followsfrommaximizingthelikelihoodof?undertheassumption\n",
      "thattheobservationlogg(i,j)hasaGaussianwhitenoise,aswiththecaseof\n",
      "Ld(?).4\n",
      "4\n",
      "Gradient-basedApproach\n",
      "Letusconsider(local)minimizationoftheobjectivefunctionL(?)inEq.\n",
      "(7).Weadoptagradientdescentapproachfortheproblem,wheretheparameter\n",
      "?isoptimizedbythefollowingiteration,withthenotation??L(?)?[?L(?)/??1\n",
      ",...,?L(?)/??d]?,?t+1=?t??tG?1?t\n",
      "f\n",
      "???Ld(?t)+(1??)??Lh(?t\n",
      ")+???R(?t)\n",
      "g\n",
      ",\n",
      "(10)\n",
      "where?t>0isanupdatingrate.ThematrixG?t?Rd?d,calledthemetric\n",
      "oftheparameter?,isanarbitraryboundedpositivematrix.When\n",
      "G?tissettotheidentitymatrixofsized,Id,theupdateformulainEq.(10)\n",
      "becomesanordinarygradientdescent.However,sincethetangentspaceata\n",
      "pointofamanifoldrepresentingM(?)isgenerallytfromanorthonormal\n",
      "spacewithrespectto?[4],onecanapplytheideaofnaturalgradient[3]tothe\n",
      "metricG?,expectingtomaketheproceduremoret.Thisisdescribed\n",
      "5\n",
      "\n",
      "inSection4.1.ThegradientsofLdandLhinEq.(10)aregivenas)()??(f\n",
      "(i)??(i)??Ld(?)=log?log??log??(j)???log??(i),f(j)??(j)i?Xo\n",
      "j?Xo??()??Lh(?)=logg(i,j)?logh?(j|i)??logh?(j|i).i?Xo\n",
      "j?Xo\n",
      "InordertoimplementtheupdateruleofEq.(10),weneedtocompute\n",
      "thegradientofthelogarithmicstationaryprobability??log??,thehitting\n",
      "probabilityh?,anditsgradient??h?.InSections4.2,wewilldescribehow\n",
      "tocomputethem,whichwillturnouttobequitenon-trivial.4.1\n",
      "Naturalgradient\n",
      "Usually,aparametricfamilyofMarkovchains,M??\n",
      "f\n",
      "M(?)|??Rd\n",
      "g\n",
      ",\n",
      "formsamanifoldstructurewithrespecttotheparameter?underinformation\n",
      "divergencessuchasaKLdivergence,insteadoftheEuclideanstructure.Thus\n",
      "theordinarygradient,Eq.(10)withG?=Id,doesnotproperlythe\n",
      "inthesensitivitiesandthecorrelationsbetweentheelementsof?.\n",
      "Accordingly,theordinarygradientisgenerallyntfromthesteepestdirec-\n",
      "tiononthemanifold,andtheoptimizationprocesswiththeordinarygradient\n",
      "oftenbecomesunstableorfallsintoalearningplateau[5].Fortlearning,\n",
      "weconsideranappropriateG?basedonthenotionofthenaturalgradient(NG)\n",
      "[5].TheNGrepresentsthesteepestdescentdirectionofafunctionb(?)ina\n",
      "Riemannianspace3by?R??1??b(?)whentheRiemannianspaceis\n",
      "bythemetricmatrixR?.AnappropriateRiemannianmetriconastatistical\n",
      "model,Y,havingparameters,?,isknowntobeitsFisherinformationmatrix\n",
      "(FIM):4??yPr(Y=y|?)??logPr(Y=y|?)??logPr(Y=y|?).In\n",
      "ourcase,thejointprobability,p?(x?|x)??(x)forx,x??X,fullysp\n",
      "M(?)atthesteadystate,duetotheMarkovianproperty.Thusweproposeto\n",
      "usethefollowingG?intheupdateruleofEq.(10),G?=F?+?Id,\n",
      "(11)\n",
      "?\n",
      "whereF?istheFIMofp?(x|x)??(x),()??F????(x)??log??\n",
      "(x)??log??(x)?+p?(x?|x)??logp?(x?|x)??logp?(x?|x)?.x?X\n",
      "x??X\n",
      "Thesecondtermwith??0inEq.(11)willbeneededtomakeG?\n",
      "positive3AparameterspaceisaRiemannianspaceiftheparameter\n",
      "??RdisonaRiemannianmanifoldbyapositivematrix\n",
      "calledaRiemannianmetricmatrixR??Rd?d.Thesquaredlengthofasmall\n",
      "incrementalvector??connecting?to?+??inaRiemannianspaceisgiven\n",
      "by????2R?=???R???.4TheFIMistheuniquemetricmatrixofthesecond-\n",
      "orderTaylorexpansionoftheKLdivergence,thatis,?Pr(Y=y|?)21yPr(Y\n",
      "=y|?)logPr(Y=y|?+??)?2????F?.\n",
      "5\n",
      "4.2\n",
      "Computingthegradient\n",
      "Toderiveanexpressionforcomputing??log??,weusethefollowing\n",
      "notationsforavectorandamatrix:???[??(1),...,??(|X|)]?and\n",
      "(P?)x,x??p?(x?|x).Thenthelogarithmicstationaryprobabilitygradients\n",
      "withrespectto?iisgivenby?log?????ilog??=Diag(??)?1(Id?P??\n",
      "6\n",
      "\n",
      "+??1?d)?1(??iP??)??,(12)??iwhereDiag(a)isadiagonalmatrixwhose\n",
      "diagonalelementsconsistofavectora,logaistheelement-wiselogarithmof\n",
      "a,and1ddenotesacolumn-vectorofsized,whoseelementsareall1.Inthe\n",
      "remainderofthissection,weproveEq.(12)byusingthefollowingproposition.\n",
      "Proposition1([7])IfA?Rd?dlimK??AK=0,thentheinverseof(I\n",
      "?A)exists,?Kand(I?A)?1=limK??k=0Ak.Equation(3)isrewrittenas\n",
      "??=P????.Notethat??isequaltoanormalizedeigenvectorofP??whose\n",
      "eigenvalueis1.BytakingapartialrentialofEq.(3)withrespectto?i,\n",
      "Diag(??)??ilog??=(??iP??)??+P??Diag(??)??ilog??isobtained.\n",
      "Thoughwegetthefollowinglinearsimultaneousequationof??ilog??,(13)\n",
      "(Id?P??)Diag(??)??ilog??=(??iP??)??,?theinverseof(Id?P?\n",
      ")Diag(??)doesnotexist.Itcomesfromthefact(Id?P??)Diag(??)1d=0.\n",
      "Soweaddatermincluding1?dDiag(??)??ilog??=1?d??i??=??i\n",
      "f\n",
      "1?d??\n",
      "g\n",
      "=0toEq.(13),suchthat(Id?P??+??1?d)Diag(??)??ilog??=(??i\n",
      "P??)??.Theinverseof(Id?P??+??1?d)exists,becauseofProposition\n",
      "1andthefactlimk??(P?????1?d)k=limk??P??k???1?d=0.The\n",
      "inverseofDiag(??)alsoexists,because??(x)ispositiveforanyx?Xunder\n",
      "Assumption1.HencewegetEq.(12).Toderiveexpressionsforcomputingh?\n",
      "and??logh?,weusethefollowingnotations:h?(x)?[h?(x|1),...,\n",
      "h?(x||X|)]?forthehittingprobabilitiesinEq.(4)and(PT?)x,x??\n",
      "pT?(x?|x)forp-transitionprobabilitiesinEq.(1).Thehittingprobabilities\n",
      "andthosegradientswithrespectto?icanbecomputedasthefollowingclosed\n",
      "forms,x\n",
      "h?(x)=(I|X|??PT?)?1ex|X|,??ilogh?(x)=?Diag(h?(x))?1\n",
      "(I|X|?whereex|X|\n",
      "(14)xx?PT?)?1(??iP?)h?(x),\n",
      "(15)\n",
      "denotesacolumn-vectorofsize|X|,wherex?thelementis1andallof\n",
      "theotherelementsx\n",
      "arezero.ThematrixPT?isas(I|X|?ex|X|ex|X?|)PT?\n",
      ".WewillderiveEqs.(14)and(15)asfollows.Thehittingprobabilities\n",
      "f\n",
      "in\n",
      "Eq.(4)canberepresentedasthefollowingrecursiveform,h?(x?|x)=\n",
      "1??y?XpT?(y|x)h?(x?|y)\n",
      "ifx?=xotherwise.\n",
      "x\n",
      "Thisequationcanberepresentedwiththematrixnotationash?(x)=\n",
      "ex|X|+?PT?h?(x).Becausex\n",
      "x\n",
      "theinverseof(I|X|??PT?)existsbyProposition1andlimk??(?PT?\n",
      ")k=0,wegetEq.(14).Inasimilarway,onecanproveEq.(15).\n",
      "5\n",
      "Implementation\n",
      "Forimplementingtheproposedmethod,parametricmodelsoftheinitial\n",
      "probabilitypI?andtheptransitionprobabilitypT?inEq.(1)needtobespec-\n",
      "Weprovideintuitivemodelsbasedonthelogitfunction[8].Theinitial\n",
      "probabilityismodeledasexp(sI(x;?))pI?(x)??,y?Xexp(sI(y;?))\n",
      "7\n",
      "\n",
      "(16)\n",
      "wheresI(x;?)isastatescorefunctionwithitsparameter??[?loc?,?\n",
      "glo?]??Rd1consistingofalocalparameter?loc?R|X|andaglobal\n",
      "parameter?glo?Rd1?|X|.ItisassI(x;?)??xloc+?I(x)??\n",
      "glo,6\n",
      "(17)\n",
      "where?I(x)?Rd1?|X|isafeaturevectorofastatex.Inthecase\n",
      "oftheroadnetwork,astatecorrespondstoaroadsegment.Then?I(x)may,\n",
      "forexample[18],bewiththeindicatorsofwhetherthereareparticular\n",
      "typesofbuildingsneartheroadsegment,x.Werefertothersttermandthe\n",
      "secondtermoftheright-handsideinEq.(17)asalocalpreferenceandaglobal\n",
      "preference,respectively.Ifasimplermodelispreferred,eitherofthemwould\n",
      "beomitted.Similarly,ap-transitionprobabilitymodelwiththeparameter??\n",
      "[?loc?,?1glo?,?2glo?]?isgivenas\n",
      "f\n",
      "/??exp(sT(x,x?;?))?y?Xxexp(sT\n",
      "(x,y;?)),if(x,x)?X?Xx,pT?(x|x)?(18)0otherwise,whereXxisaset\n",
      "ofstatesconnectedfromx,andsT(x,x?;?)isastate-to-statescorefunction.\n",
      "Itisasloc??glosT(x,x?;?)??(x,x+?(x,x?)??2glo,(x,x?)\n",
      "?X?Xx,?)+?T(x)?1?\n",
      "loclocwhere?(x,x(?Rx?X|Xx|)correspondingtotransitionfromx\n",
      "tox?,and?)istheelementof???T(x)and?(x,x)arefeaturevectors.\n",
      "Fortheroadnetwork,?T(x)maybebasedonthetypeoftheroad\n",
      "segment,x,and?(x,x?)maybebasedontheanglebetweenxandx?\n",
      ".Thoselinearcombinationswiththeglobalparameters,?1gloand?2glo,can\n",
      "representdrivers?preferencessuchashowmuchthedriversprefermajorroads\n",
      "orstraightroutestoothers.\n",
      "NotethatthepI?(x)andpT?(x?|x)presentedinthissectioncanbe\n",
      "tiatedanalytically.Hence,F?inEq.(11),??ilog??inEq.(12),and\n",
      "??ih?inEq.(15)canbecomputedtly.\n",
      "66.1\n",
      "ExperimentsExperimentonsyntheticdata\n",
      "Tostudythesensitivitiesoftheperformanceofouralgorithmtotheratio\n",
      "ofobservablestates,weappliedittorandomlysynthesizedinverseproblemsof\n",
      "100-stateMarkovchainswithavaryingnumberofobservablestates,|Xo|?\n",
      "f\n",
      "5,10,20,35,50,70,90\n",
      "g\n",
      ".Thelinkagesbetweenstateswererandomlygenerated\n",
      "inthesamewayas[19].ThevaluesofpIandpTaredeterminedintwostages.\n",
      "First,thebasicinitialprobabilities,pI?,andthebasictransitionprobabilities,\n",
      "pT?,weredeterminedbasedonEqs.(16)and(18),whereeveryelementof?,\n",
      "?,?I(x),?T(x),and?T(x,x?)wasdrawnindependentlyfromthenormal\n",
      "distributionN(0,12).ThenweaddednoisestopI?andpT?,whichareideal\n",
      "forouralgorithm,byusingtheDirichletdistributionDir,suchthatpI=0.7pI?\n",
      "+0.3?with??Dir(0.3?1|X|).Thenwesampledthevisitingfrequencies\n",
      "f(x)andthehittingratesg(x,x?)foreveryx,x??Xofromthissynthesized\n",
      "Markovchain.WeusedEqs.(16)and(18)forthemodelsandEq.(7)for\n",
      "theobjectiveofourmethod.InEq.(7),weset?=0.1andR(?)=???22,\n",
      "and?wasdeterminedwithacross-validation.Weevaluatedthequalityofour\n",
      "solutionwiththerelativemeanabsoluteerror(RMAE),RMAE=??|f(x)??\n",
      "8\n",
      "\n",
      "c??(x)|1?isascalingvaluegivenbyc?=1/|Xo|x?Xof(x).Asx?XXo\n",
      "max\n",
      "f\n",
      "f(x),1\n",
      "g\n",
      ",wherec|XXo|abaselinemethod,weuseNadaraya-Watson\n",
      "kernelregression(NWKR)[8]whosekerneliscomputedbasedonthenumberof\n",
      "hopsintheminimumpathbetweentwostates.NotethattheNWKRcouldnot\n",
      "useg(x,x?)asaninput,becausethisisaregressionproblemoff(x).Hence,\n",
      "forafaircomparison,wealsoappliedavariantofourmethodthatdoesnotuse\n",
      "g(x,x?).Figure2(A)showsthemeanandstandarddeviationoftheRMAEs.\n",
      "TheproposedmethodgivesclearlybetterperformancethantheNWKR.This\n",
      "ismainlyduetothefactthattheNWKRassumesthatallpropagationsof\n",
      "theobservationfromalinktoanotherconnectedlinkareequallyweighted.In\n",
      "contrast,ourmethodincorporatessuchweightinthetransitionprobabilities.\n",
      "6.2\n",
      "Experimentonreal-worlddata\n",
      "Wetestedourmethodthroughacity-widetaskasshown\n",
      "inFig.1.Thegoalistoestimatethevolumealonganarbitraryroad\n",
      "segment(orlinkofanetwork),givenobservedvolumesonalimited\n",
      "numberofthelinks,wherealinkcorrespondstothestatexofM(?),andthe\n",
      "volumealongxcorrespondstof(x)ofEq.(5).Thevolumesalong\n",
      "theobservablelinkswerereliablyestimatedfromreal-worldweb-cameraimages\n",
      "capturedinNairobi,Kenya[2,7\n",
      "(B)\n",
      "2.5\n",
      "2\n",
      "ProposedmethodProposedmethodwithnouseofgNadaraya?Watsonker-\n",
      "nelregression\n",
      "?1.26?1.265\n",
      "(C)\n",
      "I\n",
      "1\n",
      "10\n",
      "?1.275?1.28?1.285\n",
      "0\n",
      "10\n",
      "?1.295?1.3?1.305\n",
      "1\n",
      "0.5\n",
      "36.8\n",
      "36.81\n",
      "36.82\n",
      "36.83\n",
      "36.84\n",
      "10?110\n",
      "36.85\n",
      "0\n",
      "1\n",
      "1010Observation\n",
      "9\n",
      "\n",
      "?1.26?1.265\n",
      "00\n",
      "(RMAE:1.01?0.917)\n",
      "?1\n",
      "?1.3136.79\n",
      "Proposedmethod\n",
      "II1\n",
      "?1.27\n",
      "3060#ofobservationstates\n",
      "90\n",
      "10\n",
      "?1.275\n",
      "Estimation\n",
      "RMAE\n",
      "?1.29\n",
      "1.5\n",
      "NWKR\n",
      "?1.27\n",
      "Estimation\n",
      "(A)\n",
      "?1.28?1.285?1.29\n",
      "0\n",
      "10\n",
      "?1.295?1.3\n",
      "?1\n",
      "?1.305?1.3136.79\n",
      "36.8\n",
      "36.81\n",
      "36.82\n",
      "36.83\n",
      "36.84\n",
      "36.85\n",
      "10?110\n",
      "(RMAE:0.517?0.669)0\n",
      "1\n",
      "1010Observation\n",
      "Figure2:(A)ComparisonofRMAEforthesynthetictaskbetweenour\n",
      "methodsandtheNWKR(baselinemethod).(B)Tvolumesforacitycenter\n",
      "mapinNairobi,Kenya,I:Web-cameraobservations(colored),II:Estimated\n",
      "volumesbyourmethod.(C)ComparisonbetweentheNWKRandour\n",
      "methodfortherealvolumepredictionproblem.15],whilewedidnot\n",
      "usethehittingrateg(x,x?)herebecauseofitsunavailability.Notethatthis\n",
      "taskissimilartonetworktomography[27,30]orlink-costprediction[32,14].\n",
      "However,unlikenetworktomography,weneedtoinferallofthelink\n",
      "insteadofsource-destinationdemands.Unlikelink-costprediction,ourinputs\n",
      "arestationaryobservationsinsteadoftrajectories.Again,weusetheNMKRas\n",
      "10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thebaselinemethod.Theroadnetworkandtheweb-cameraobservationsare\n",
      "showninFig.2(B)-I.Whilethetotalnumberoflinkswas1,497,thenumber\n",
      "oflinkswithobservationswasonly52(about3.5%).Weusedtheparametric\n",
      "modelsinSection5,where?T(x)?[?1,1]wassetbasedontheroadcategory\n",
      "ofxsuchthatprimaryroadshaveahighervaluethansecondaryroads[22],and\n",
      "?(x,x?)?[?1,1]wasthecosineoftheanglebetweenxandx?.However,\n",
      "weomittedthetermsof?I(x)inEq.(17).Figure2(B)-IIshowsanexample\n",
      "ofourresults,wheretheredandyellowroadsaremostcongestedwhilethe\n",
      "ontheblueroadsiswingsmoothly.Thecongestedroadsfromour\n",
      "analysisareconsistentwiththosefromalocalsurveyreport[13].Figure\n",
      "2(C)showscomparisonbetweenpredictedandobservedtravelvolumes.Inthe\n",
      "the45olinecorrespondstoperfectagreementbetweentheactualand\n",
      "predictedvalues.Toevaluateaccuracy,weemployedtheleaveone-outcross-\n",
      "validation.Wecanseethattheproposedmethodgivesagoodperformance.\n",
      "Thisisrathersurprising,becausetherateofobservationlinksisverylimitedto\n",
      "only3.5percent.\n",
      "7\n",
      "Conclusion\n",
      "WehaveanovelinverseproblemofaMarkovchain,whereweinfer\n",
      "theprobabilitiesabouttheinitialstatesandthetransitions,usingalimited\n",
      "amountofinformationthatwecanobtainbyobservingtheMarkovchainata\n",
      "smallnumberofstates.Wehaveproposedaneobjectivefunctionfor\n",
      "thisproblemaswellasanalgorithmbasedonnaturalgradient.Usingreal-world\n",
      "data,wehavedemonstratedthatourapproachisusefulforamonitor-\n",
      "ingsystemthatmonitorsthevolumeatlimitednumberoflocations.\n",
      "FromthisobservationtheMarkovchainmodelisinferred,whichinturncan\n",
      "beusedtodeducethevolumeatanylocation.Surprisingly,evenwhen\n",
      "theobservationsaremadeatonlyseveralpercentofthelocations,thepro-\n",
      "posedmethodcansuccessfullyinferthevolumeatunobservedlocations.\n",
      "Furtheranalysisoftheproposedmethodisnecessarytobetterunderstandits\n",
      "propertyandeness.Inparticular,ourfutureworkincludesananalysis\n",
      "ofmodelidenyandempiricalstudieswithotherapplications,suchas\n",
      "logisticsandeconomicsystemmodeling.AcknowledgmentsTheauthorsthank\n",
      "Dr.R.Morris,Dr.R.Raymond,andMr.T.Katsukiforfruitfuldiscussion.8\n",
      "2References\n",
      "[1]P.AbbeelandA.Y.Ng.Apprenticeshiplearningviainversereinforcement\n",
      "learning.InProc.ofInternationalConferenceonMachinelearning,2004.[2]\n",
      "AccessKenya.com.hkenya.com/.[3]S.Amari.Naturalgra-\n",
      "dientworkstlyinlearning.NeuralComputation,10(2):251?276,1998.\n",
      "[4]S.AmariandH.Nagaoka.MethodofInformationGeometry.OxfordUniver-\n",
      "sityPress,2000.[5]S.Amari,H.Park,andK.Fukumizu.Adaptivemethodof\n",
      "realizingnaturalgradientlearningformultilayerperceptrons.NeuralComputa-\n",
      "tion,12(6):1399?1409,2000.[6]H.Balzter.Markovchainmodelsforvegetation\n",
      "11\n",
      "\n",
      "dynamics.EcologicalModelling,126(2-3):139?154,2000.[7]J.BaxterandP.L.\n",
      "Bartlett.Inpolicy-gradientestimation.JournalofArtiIntel-\n",
      "ligenceResearch,15:319?350,2001.[8]C.M.Bishop.PatternRecognitionand\n",
      "MachineLearning.Springer,2006.[9]H.H.Bui,S.Venkatesh,andG.West.\n",
      "OntherecognitionofabstractMarkovpolicies.InProc.ofAAAIConferenceon\n",
      "Intelligence,pages524?530,2000.[10]S.L.Chang,L.S.Chen,Y.C.\n",
      "Chung,andS.W.Chen.Automaticlicenseplaterecognition.InProc.ofIEEE\n",
      "TransactionsonIntelligentTransportationSystems,pages42?53,2004.[11]E.\n",
      "Crisostomi,S.Kirkland,andR.Shorten.AGoogle-likemodelofroadnetwork\n",
      "dynamicsanditsapplicationtoregulationandcontrol.InternationalJournal\n",
      "ofControl,84(3):633?651,1995.[12]M.GamonandA.C.K?onig.Navigation\n",
      "patternsfromandtosocialmedia.InProc.ofAAAIConferenceonWeblogs\n",
      "andSocialMedia,2009.[13]J.E.Gonzales,C.C.Chavis,Y.Li,andC.F.Da-\n",
      "ganzo.MultimodaltransportinNairobi,Kenya:Insightsandrecommendations\n",
      "withamacroscopicevidence-basedmodel.InProc.ofTransportationResearch\n",
      "Board90thAnnualMeeting,2011.[14]T.Id?eandM.Sugiyama.Trajectory\n",
      "regressiononroadnetworks.InProc.ofAAAIConferenceonIn-\n",
      "telligence,pages203?208,2011.[15]T.Katasuki,T.Morimura,andT.Id?e.\n",
      "Bayesianunsupervisedvehiclecounting.InTechnicalReport.IBMResearch,\n",
      "RT0951,2013.[16]D.Levin,Y.Peres,andE.Wilmer.MarkovChainsandMix-\n",
      "ingTimes.AmericanMathematicalSociety,2008.[17]D.MacKay.Information\n",
      "theory,inference,andlearningalgorithms.CambridgeUniversityPress,2003.\n",
      "[18]T.MorimuraandS.Kato.Statisticalorigin-destinationgenerationwith\n",
      "multiplesources.InProc.ofInternationalConferenceonPatternRecognition,\n",
      "pages283?290,2012.[19]T.Morimura,E.Uchibe,J.Yoshimoto,andK.Doya.\n",
      "Ageneralizednaturalactor-criticalgorithm.InProc.ofAdvancesinNeural\n",
      "InformationProcessingSystems,volume22,2009.[20]A.Y.NgandS.Russell.\n",
      "Algorithmsforinversereinforcementlearning.InProc.ofInternationalConfer-\n",
      "enceonMachineLearning,2000.[21]J.R.Norris.MarkovChains.Cambridge\n",
      "UniversityPress,1998.[22]OpenStreetMap.http://wiki.openstreetmap.org/.\n",
      "[23]C.C.PegelsandA.E.Jelmert.Anevaluationofblood-inventorypolicies:\n",
      "AMarkovchainapplication.OperationsResearch,18(6):1087?1098,1970.[24]\n",
      "J.A.QuinnandR.Nakibuule.Tcwmonitoringincrowdedcities.In\n",
      "Proc.ofAAAISpringSymposiumonIntelligenceforDevelopment,\n",
      "2010.[25]C.M.Roberts.Radiofrequencyiden(RFID).Computers\n",
      "&Security,25(1):18?26,2006.[26]S.M.Ross.Stochasticprocesses.John\n",
      "Wiley&SonsInc,1996.[27]S.Santini.Analysisofwinurbanareas\n",
      "usingwebcameras.InProc.ofIEEEWorkshoponApplicationsofComputer\n",
      "Vision,pages140?145,2000.[28]R.R.Sarukkai.Linkpredictionandpath\n",
      "analysisusingMarkovchains.ComputerNetworks,33(16):377?386,2000.[29]\n",
      "G.Tauchen.FinitestateMarkov-chainapproximationstounivariateandvec-\n",
      "torautoregressions.EconomicsLetters,20(2):177?181,1986.[30]Y.Zhang,\n",
      "M.Roughan,C.Lund,andD.Donoho.Aninformation-theoreticapproachto\n",
      "matrixestimation.InProc.ofConferenceonApplications,technolo-\n",
      "gies,architectures,andprotocolsforcomputercommunications,pages301?312.\n",
      "ACM,2003.[31]J.Zhu,J.Hong,andJ.G.Hughes.UsingMarkovchainsfor\n",
      "12\n",
      "\n",
      "linkpredictioninadaptiveWebsites.InProc.ofSoft-Ware2002:Computing\n",
      "inanImperfectWorld,volume2311,pages60?73.Springer,2002.[32]B.D.\n",
      "Ziebart,A.L.Maas,andA.K.DeyJ.A.Bagnell.Maximumentropyinverse\n",
      "reinforcementlearning.InProc.ofAAAIConferenceonIntelligence,\n",
      "pages1433?1438,2008.\n",
      "9\n",
      "13\n",
      "\n",
      "PP5447.pdf\n",
      "PP5447.pdf 12\n",
      "RAAM:TheofRobustnessin\n",
      "ApproximatingAggregatedMDPsin\n",
      "ReinforcementLearning\n",
      "Authoredby:\n",
      "MarekPetrik\n",
      "DharmashankarSubramanian\n",
      "Abstract\n",
      "WedescribehowtouserobustMarkovdecisionprocessesforvalue\n",
      "functionapproximationwithstateaggregation.Therobustnessservesto\n",
      "reducethesensitivitytotheapproximationerrorofsub-optimalpolicies\n",
      "incomparisontoclassicalmethodssuchasvalueiteration.This\n",
      "resultsinreducingtheboundsonthegamma-discountedhorizon\n",
      "performancelossbyafactorof1/(1-gamma)whilepreservingpolynomial-\n",
      "timecomputationalcomplexity.Ourexperimentalresultsshowthatusing\n",
      "therobustrepresentationcantlyimprovethesolutionquality\n",
      "withminimaladditionalcomputationalcost.\n",
      "1PaperBody\n",
      "Stateaggregationisoneofthesimplestapproximatemethodsforreinforcement\n",
      "learningwithverylargestatespaces;itisaspecialcaseoflinearvaluefunction\n",
      "approximationwithbinaryfeatures.Themainadvantagesofusingaggregation\n",
      "incomparisonwithothervaluefunctionapproximationmethodsareitssim-\n",
      "plicity,y,andtheeaseofinterpretability(Beanetal.,1987;Bertsekas\n",
      "andCastanon,1989;VanRoy,2005).Informally,valuefunctionapproxima-\n",
      "tionmethodscomputeanapproximately-optimalpolicy??bycomputingan\n",
      "approximatevaluefunctionv?asanintermediatestep.Thequalityoftheso-\n",
      "lutioncanbemeasuredbyitsperformanceloss:?(??)??(??)where?\n",
      "?istheoptimalpolicy,and?(?)isthe?-discountedreturnof\n",
      "thepolicy,averagedover(any)giveninitialstatedistribution.Thetightupper\n",
      "boundguaranteesontheperformanceloss?tighterforstate-aggregationthan\n",
      "forgenerallinearvaluefunctionapproximation?are(VanRoy,2005),?(??)?\n",
      "?(??)?4?(v?)/(1??)2\n",
      "(1.1)\n",
      "where(v?formallyinSection4?isthesmallestapproximation\n",
      "errorfortheoptimalvaluefunctionv?.Itisimportantthattheerroriswith\n",
      "1\n",
      "\n",
      "respecttotheoptimalvaluefunctionwhichcanhavespecialstructuralprop-\n",
      "erties,suchasconvexityininventorymanagementproblems(Porteus,2002).\n",
      "Becausetheboundin(1.1)istight,theperformancelossmaygrowwiththedis-\n",
      "countfactorasfastas?/(1??)2whilethetotalreturnforanypolicyonlygrows\n",
      "as1/(1??).Therefore,for?tlycloseto1,thepolicy??computed\n",
      "throughstateaggregationmaybenobetterthanarandompolicyevenwhen\n",
      "theapproximationerroroftheoptimalpolicyissmall.Thislargeperformance\n",
      "lossiscausedbylargeerrorsinapproximatingsub-optimalvaluefunctions(Van\n",
      "Roy,2005).Inthispaper,weshowthatitispossibletoguaranteemuchsmaller\n",
      "performancelossbyusingarobustmodeloftheapproximationerrorsthrough\n",
      "anewalgorithmwecallRAAM(robustapproximationforaggregatedMDPs).\n",
      "Informally,weuserobustnesstoreducetheapproximatedreturnofpolicies\n",
      "withlargeapproximationerrorstomakeitlesslikelythatsuchpolicieswillbe\n",
      "selected.1\n",
      "TheperformancelossoftheRAAMcanbeboundedas:?(??)??(??)\n",
      "?2(v?)/(1??).\n",
      "(1.2)\n",
      "Asthemaincontributionofthepaper?describedinSection3?weincorpo-\n",
      "ratethedesiredrobustnessintotheaggregationmodelbyassumingbounded\n",
      "worst-casestateimportanceweights.Thestateimportanceweightsdetermine\n",
      "therelativeimportanceoftheapproximationerrorsamongthestates.RAAM\n",
      "formulatestherobustoptimizationovertheimportanceweightsasarobust\n",
      "Markovdecisionprocess(RMDP).RMDPsextendMDPstoallowuncertain\n",
      "transitionprobabilitiesandrewardsandpreservemostofthefavorableMDP\n",
      "properties(Iyengar,2005;NilimandGhaoui,2005;LeTallec,2007;Wiese-\n",
      "mannetal.,2013).RMDPscanbesolvedinpolynomialtimeandthesolution\n",
      "methodsarepractical(KaufmanandSchaefer,2013;Hansenetal.,2013).To\n",
      "minimizetheoverheadofRAAMincomparisonwithstandardaggregation,we\n",
      "describeanewlinear-timealgorithmfortheBellmanupdateinSection3.1for\n",
      "RMDPswithrobustsetsconstrainedbytheL1norm.Anothercontributionof\n",
      "thispaper?describedinSection4?istheanalysisofRAAMperformancelossand\n",
      "theimpactofthechoiceofrobustuncertaintysets.Wefocusonconstructing\n",
      "aggregateRMPDswithrectangularuncertaintysets(Iyengar,2005;Wiesemann\n",
      "etal.,2013)andshowthatitispossibletouseMDPstructuralpropertiestore-\n",
      "duceRAAMperformancelossguaranteescomparedto(1.2).Theexperimental\n",
      "resultsinSection5empiricallyillustratesettingsinwhichRAAMoutperforms\n",
      "standardstateaggregationmethods.Inparticular,RAAMismorerobustto\n",
      "sub-optimalpolicieswithalargeapproximationerror.Theresultsalsoshow\n",
      "thatthecomputationaloverheadofusingtherobustformulationisverysmall.\n",
      "2\n",
      "Preliminaries\n",
      "Inthissection,weoverviewrobustMarkovdecisionprocesses(RMDPs).\n",
      "RMDPsgeneralizeMDPstoallowforuncertaintransitionprobabilitiesandre-\n",
      "wards.OurtionofRMDPsisinspiredbystochasticzero-sumgamesto\n",
      "generalizepreviousresultstoallowforuncertaintyinboththerewardsandtran-\n",
      "sitionprobabilities(FilarandVrieze,1997;Iyengar,2005).Formally,anRMDP\n",
      "2\n",
      "\n",
      "isatuple(S,A,B,P,r,?),whereSisasetofstates,??4Sistheinitial\n",
      "distribution,Asisasetofactionsthatcanbetakeninstates?S,andBsis\n",
      "asetofrobustoutcomesfors?Sthatrepresenttheuncertaintyintransitions\n",
      "andrewards.Fromagame-theoreticperspective,Bscanbeseenastheactions\n",
      "oftheadversary.Foranya?As,b?Bs,thetransitionprobabilitiesare\n",
      "Pa,b:S?4Sandtherewardisra,b:S?R.Therewardsdependonlyon\n",
      "thestartingstateandareindependentofthetargetstate1.Thebasicsolution\n",
      "conceptsofRMDPsareverysimilartoregularMDPswiththeexceptionthat\n",
      "thesolutionalsoincludesthepolicyoftheadversary.Weconsiderthesetof\n",
      "randomizedstationarypolicies?R=\n",
      "f\n",
      "?s?4As\n",
      "g\n",
      "s?Sascandidatesolutionsand\n",
      "use?Dfordeterministicpolicies.Twomainpracticalmodelsoftheuncertainty\n",
      "inBshavebeenconsidered:s-rectangularands,arectangularsets(LeTallec,\n",
      "2007;Wiesemannetal.,2013).Ins-rectangularuncertaintymodels,thereal-\n",
      "izationoftheuncertaintydependsonlyonthestateandisindependentonthe\n",
      "action;thecorrespondingsetofnature?spoliciesis:?S=\n",
      "f\n",
      "?s?4Bs\n",
      "g\n",
      "s?S.Ins,\n",
      "a-rectangularmodels,therealizationoftheuncertaintycanalsodependonthe\n",
      "action:?SA=\n",
      "f\n",
      "?s,a?4Bs\n",
      "g\n",
      "s?S,a?As.WeQwillalsoconsiderrestrictedsetson\n",
      "theadversary?spolicies:?QS=\n",
      "f\n",
      "?s?Qs\n",
      "g\n",
      "s?Sand?SA=\n",
      "f\n",
      "?s,a?Qs\n",
      "g\n",
      "s,a?S?As\n",
      ",forsomeQs?4Bs.Next,weoverviewthebasicpropertiesofrobust\n",
      "MDPs;pleasereferto(Iyengar,2005;NilimandGhaoui,2005;LeTallec,2007;\n",
      "Wiesemannetal.,2013)formoredetails.Thetransitionsandrewardsforany\n",
      "stationarypolicies?and?aredenedas:XXP?,?(s,s0)=Pa,b(s,s0)?s,a\n",
      "?s,b,r?,?(s)=ra,b(s)?s,a?s,b.a,b?As?Bs\n",
      "a,b?As?Bs\n",
      "1Rewardsthatdependonthetargetstatecanbereadilyreducedtoinde-\n",
      "pendentonesbytakingtheappropriateexpectation.\n",
      "2\n",
      "ItwillbeconvenienttouseP?,?todenotethetransitionmatrixandr?,?and\n",
      "?asvectorsoverstates.WewillalsouseItodenoteanidentitymatrixand1,\n",
      "0todenotevectorsofonesandzerosrespectivelywithappropriatedimensions.\n",
      "Usingthisnotation,withas,a-rectangularmodel,theobjectiveintheRMDP\n",
      "istomaximizethe?-discountedhorizonrobustreturn?as:??=sup\n",
      "??(?)=sup???R\n",
      "inf?(?,?)=sup\n",
      "???R???SA\n",
      "inf\n",
      "?X\n",
      "?T(?P?,?)tr?,?.\n",
      "(RBST)\n",
      "???R???SAt=0\n",
      "Thenegativesuperscriptdenotesthefactthatthisistherobustreturn.The\n",
      "valuefunctionforapolicy?pair?and?isdenotedbyv?,?andtheoptimal\n",
      "robustvaluefunctionisv??.SimilarlytoregularMDPs,theoptimalrobust\n",
      "valuefunctionmustsatisfytherobustBellmanoptimalityequation:\n",
      "XXv??(s)=maxmin?s,a?s,a,bra,b(s)+?Pa,b(s,s0)v??(s0).\n",
      "(2.1)???R???QSA\n",
      "3\n",
      "\n",
      "3\n",
      "s0?S\n",
      "a,b?As?Bs\n",
      "RAAM:RobustApproximationforAggregatedMDPs\n",
      "ThissectiondescribeshowRAAMusestransitionsamplestocomputean\n",
      "approximatelyoptimalpolicy.Wealsodescribealinear-timealgorithmfor\n",
      "computingvaluefunctionupdatesfortherobustMDPsconstructedbyRAAM.\n",
      "Algorithm1:RAAM:RobustApproximationforAggregatedMDPs//?-\n",
      "samples,w-weights,?-aggregation,?-robustnessInput:?,w,?,?Output:\n",
      "???approximatelyoptimalpolicy//ComputeRMDPparameters1S?\n",
      "f\n",
      "?(?\n",
      "s):(?s,s?0,a?,r)??\n",
      "g\n",
      "?\n",
      "f\n",
      "?(?s0):(?s,s?0,a?,r?)??\n",
      "g\n",
      ";//States2\n",
      "forallthes?Sdo3As?\n",
      "f\n",
      "?a:(?s,s?0,a?,r)??,s=?(?s)\n",
      "g\n",
      ";//Actions4\n",
      "Bs?\n",
      "f\n",
      "?s:(?s,s?0,a?,r)??,s=?(?s)\n",
      "g\n",
      ";//Outcomes5end//Compute\n",
      "RMDPtransitionprobabilitiesandrewards06forallthes,s?S?Sdo7forall\n",
      "thea,b?As?Bsdo8?0?\n",
      "f\n",
      "(?s0,r?):(?s,s?0,a?,r?)??,?(?s)=s,\n",
      "a=a?,b=s?\n",
      "g\n",
      ";P109Pa,b(s,s)?|?0|s?0,???01s0=?(?s0);P10\n",
      "ra,b(s)??,?r??0r?/|?0|;11end12end//Constructrobustsetsbasedon\n",
      "stateweightsandL1boundswsBk1??\n",
      "g\n",
      ";13Qs?\n",
      "f\n",
      "??4s:k??T1w|Bs\n",
      "14\n",
      "1516\n",
      "?QSA?\n",
      "f\n",
      "?s,a?Qs\n",
      "g\n",
      "s,a?S?As;//SolveRMDP?Solve(2.1)toget??\n",
      "?theoptimalRMDPpolicy?andlet??s?,a=??(?s),a;return??;\n",
      "Algorithm1depictsasimplimplementationofRAAM.Ingeneral,we\n",
      "uses?todistinguishtheun-aggregatedMDPstatesfromthestatesintheag-\n",
      "gregatedRMDP.Themaininputtothealgorithmconsistsoftransitionsamples\n",
      "?=\n",
      "f\n",
      "(?si,s?0i,a?i,ri)\n",
      "g\n",
      "i?Iwhichrepresenttransitionsfromastates?i0to\n",
      "thestates?igivenrewardriandtakinganactionai;thetransitionsneedtobe\n",
      "sampledaccordingtothetransitionprobabilitiesconditionedonthestateand\n",
      "anaction.Theaggregationfunction?:S??S,whichmapseveryMDPstate\n",
      "fromS?toanaggregateRMDPstate,isalsoassumedtobegiven.Finally,the\n",
      "stateweightsw?4Sandtherobustness?aretunableparameters.Weusethe\n",
      "L1normtoboundtheuncertainty.Therepresentationuses?tocontinuously\n",
      "tradebetweenimportanceweightsfor?=0andcompleterobustness\n",
      "?=2.Weanalyze3\n",
      "1\n",
      "a1\n",
      "a1\n",
      "s?1\n",
      "0\n",
      "s?2\n",
      "0s?1\n",
      "0\n",
      "s?2\n",
      "s1\n",
      "s?3\n",
      "s1\n",
      "4\n",
      "\n",
      "s2\n",
      "1a2\n",
      "s?1\n",
      "Figure1:AnexampleMDP.\n",
      "0\n",
      "0\n",
      "a2\n",
      "s2\n",
      "s?2\n",
      "Figure2:AggregatedRMDP.\n",
      "theofthisparameterinSection4.However,simplysettingwtobe\n",
      "uniformand?=2willprovidetlystrongtheoreticalguaranteesand\n",
      "generallyworkswellinpractice.Finally,weassumes,a-rectangularuncertainty\n",
      "setsforthesakeofreducingthecomputationalcomplexity;betterapproxima-\n",
      "tionscouldbeobtainedbyusings-rectangularsets,butthismakesno\n",
      "fordeterministicpolicies.Next,weshowanexamplethatdemonstrateshow\n",
      "therobustMDPisconstructedfromtheaggregation.Wewillalsousethis\n",
      "exampletoshowthetightnessofourboundsontheperformanceloss.Ex-\n",
      "ample3.1.TheoriginalMDPproblemisshowninFig.1.Theroundwhite\n",
      "nodesrepresentthestates,whiletheblacknodesrepresentstate-actionpairs.\n",
      "Alltransitionsaredeterministic,withthenumbernexttothetransitionrepre-\n",
      "sentingthecorrespondingreward.Twoshadedregionsmarkedwiths1ands2\n",
      "denotetheaggregatestates.Fig.2depictsthecorrespondingaggregatedrobust\n",
      "MDPconstructedbyRAAM.Therectangularnodesinthispicturerepresent\n",
      "therobustoutcome.3.1\n",
      "ReducingComputationalComplexity\n",
      "SolvinganRMDPisingeneralmorethansolvingaregularMDP.\n",
      "MostRMDPalgorithmsarebasedonvalueorpolicyiteration,butingeneral\n",
      "involverepeatedsolutionsoflinearorconvexprograms(KaufmanandSchaefer,\n",
      "2013).Eventhoughtheworst-casetimecomplexityofthesealgorithmsispoly-\n",
      "nomial,theymaybeimpracticalbecausetheyrequirerepeatedlysolving(2.1)\n",
      "foreverystate,action,anditeration.Eachofthesecomputationsmayrequire\n",
      "solvingalinearprogram.Theoptimizationover?SAwhencomputingthevalue\n",
      "functionupdateforsolvingLine15ofAlgorithm1requiressolvingthefollowing\n",
      "linearprogramforeachsanda.min\n",
      "?s,a?4Bs\n",
      "s.t.\n",
      "T?s,azs=\n",
      "X\n",
      "X?s,a,bra,b(s)+?Pa,b(s,s0)v(s0)s0?S\n",
      "b?Bs\n",
      "(3.1)\n",
      "k?s,a?qsk1??.\n",
      "Hereqs=ws/1Tw(Bs).Whilethisproblemcanbesolveddirectlyusing\n",
      "alinearprogramsolver,wedescribeatlymoretmethodin\n",
      "Algorithm2.Theorem3.2.Algorithm2correctlysolves(3.1)inO(|Bs|)\n",
      "5\n",
      "\n",
      "timewhenthefullsortisreplacedbyaquickselectquantileselectionalgorithm\n",
      "inLine4.TheproofistechnicalandisdeferredtoAppendixB.1.Themain\n",
      "ideaistodualizethenormconstraintandexaminethestructureoftheoptimal\n",
      "solutionasafunctionofthedualvariable.\n",
      "4\n",
      "PerformanceLossBounds\n",
      "Thissectiondescribesnewboundsontheperformancelosswhichisthe\n",
      "betweenthereturnoftheoptimalandapproximatepolicy.Theper-\n",
      "formancelossisamorereliablemeasureoftheerrorthantheerrorinthevalue\n",
      "function(VanRoy,2005).Wealsoanalyzetheofthestateweightsw\n",
      "andtherobustnessparameter?onperformanceloss.Itwillbeconvenient,for\n",
      "thepurposeofderivingtheerrorbounds,totreataggregationasalinearvalue\n",
      "functionapproximation(VanRoy,2005).Forthatpurpose,amatrix?(?\n",
      "s,s)=1s=?(?s)4\n",
      "Algorithm2:Solve(3.1)inLine15ofAlgorithm1Input:zs,qs?sorted\n",
      "suchthatzsisnon-decreasing,indexedas1...n?Output:?s,a?optimal\n",
      "solutionof(3.1)1o?copy(qs);i?n;?2?min\n",
      "f\n",
      "1?q1,2\n",
      "g\n",
      ";3o1?+q1\n",
      ";4while>0;//Determinethethreshold5do6oi?oi?min\n",
      "f\n",
      ",oi\n",
      "g\n",
      ";7??\n",
      "min\n",
      "f\n",
      ",oi\n",
      "g\n",
      ";8i?i?1;9end10returno;\n",
      "?and1representstheindicatorfunction.Thatis,eachcolumncorresponds\n",
      "towheres?S,s??S,asingleaggregatestatewitheachrowentrybeingeither\n",
      "1or0dependingonwhethertheoriginalstatebelongsintotheaggregatestate.\n",
      "Inordertosimplifythederivationofthebounds,westartbyassumingthatthe\n",
      "RMDPinRAAMisconstructedfromthefullsampleoftheoriginalMDP;we\n",
      "discussboundslater.?A,?P?,r?,?Therefore,assumethat\n",
      "thefullregularMDPisM=(S,?);weareusingbarsingeneral?todenote\n",
      "MDPvalues,butassumethatA=A.Wealsouse??todenotethereturnofa\n",
      "policyintheMDP.Therobustoutcomescorrespondtotheoriginalstatesthat\n",
      "composeanys:Bs=??1(s).TheRMDPtransitionsandrewardsforsome?\n",
      "and?arecomputedas:\n",
      "r?,?=?Tdiag??r???T=??T?.(4.1)P?,?=?Tdiag??P???P\n",
      "Here,??s?=a?As??s,a?s,a,?ssuchthat?(?s)=sarestateweightsinduced\n",
      "by?.Therearetwotypesofoptimalpolicies:???and??;???isthetruly\n",
      "optimalpolicy,while??istheoptimalpolicygivenaggregationconstraints\n",
      "requiringthesameactionforallaggregatedstates.Foranycomputedpolicy??\n",
      ",wefocusprimarily??(??)???(??).Thetotallosscanon?theperformance\n",
      "loss???beeasilydecomposedas??(??)???(??)=??(??)???(?)+\n",
      "??(?)???(??).Theerror?(???)???(??)isindependentofhowthe\n",
      "valueoftheaggregationiscomputed.Thefollowingtheoremstatesthemain\n",
      "resultofthepaper.ApartoftheresultsusestheconcentrationcocientC\n",
      "foragivendistribution?oftheMDP(Munos,2005)whichareas:P?a\n",
      "(s,s0)??a?A.?C?(s0)foralls,s0?S,Theorem4.1.Let??bethe\n",
      "solutionofAlgorithm1basedonthefullsamplefor?=2.Then:??(??)?\n",
      "??(??)?\n",
      "2(v?),1??\n",
      "where(v?)=minv?RSkv???vk?andthisboundistight.Inaddition,\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whentheconcentrationcotoftheoriginalMDPisCwithdistribution?,\n",
      "then(v?)=minv?RSke(v)k1,?where?=?T(??+(1??)?)ande(v)s=\n",
      "maxs????1(s)|(I??P???)(?v???v)|s?.BeforeprovingTheorem4.1,it\n",
      "isinstrumentaltocompareitwiththeperformancelossofrelatedreinforcement\n",
      "learningalgorithms.Whentheaggregationisconstructedusingconstantand\n",
      "uniformaggregationweights(aswhenAlgorithm1isusedwith?=0),the\n",
      "performancelossofthecomputedpolicy??isboundedas(TsitsiklisandVan\n",
      "Roy,1996;Gordon,1995):??(??)???(??)?\n",
      "4?(v?).(1??)2\n",
      "Thisboundholdsspforaggregation(andapproximatorsthatare\n",
      "averagers)andistight;theperformancelossformoregeneralalgorithmscanbe\n",
      "evenlarger.Notethattheinthe1/(1??)factorisveryt\n",
      "when??1.VanRoy(2005)showssimilarboundsasRAAM,buttheyare\n",
      "weakerandrequiretheinvariantdistribution?.Inaddition,similarperformance\n",
      "lossboundsasTheorem4.1canbeguaranteedbyDRADP,butthisapproach\n",
      "resultsingeneraltoNPhardcomputationalproblems(Petrik,2012).Infact,\n",
      "therobustaggregationcanbeseenasaspecialcaseofDRADPwithrectangular\n",
      "uncertaintysets(Iyengar,2005).5\n",
      "ToproveTheorem4.1weneedthefollowingresultshowingthatforproperly\n",
      "chosenrobustuncertaintysets,therobustreturnisalowerboundonthetrue\n",
      "return.Wewillused??torepresentthenormalizedoccupancyfrequencyfor\n",
      "theMDPMandpolicy?.Q?Lemma4.2.Assumetheuncertaintysettobe\n",
      "?QSor?SAasconstructedin(4.1).Then?(?)????(?)aslongasforeach\n",
      "???wehavethatd?|Bs??s?Qsforeachs?Sandsome?s.\n",
      "When?=2,theinequalityinthetheoremalsoholdsforvaluefunctions\n",
      "asPropositionB.1intheappendixshows.Proof.Weprovetheresultfors-\n",
      "rectangularuncertaintysets;theprooffors,a-rectangularsetsisanalogous.\n",
      "Whenthepolicy?issolvingforthenature?spolicyrepresentsamini-\n",
      "mizationMDPwithcontinuousactionconstraintsthathasthefollowingdual\n",
      "linearprogramformulation(Mareckietal.,2013):??(?)=\n",
      "min\n",
      "d?\n",
      "f\n",
      "RBs\n",
      "g\n",
      "s?S\n",
      "dTr??/(1??)?T(I??P??T)d=(1??)?T??Xds,b/ds,b0?Qs\n",
      ",?s?S,?b?Bs.\n",
      "s.t.\n",
      "(4.2)\n",
      "b0?Bs\n",
      "Notethattheleft-handsideofthelastconstraintcorrespondsto?a,b.Now,\n",
      "settingd=d??showsthedesiredinequalityfor?;thisvalueisfeasibleinP(4.2)\n",
      "from(B.3)andtheobjectivevalueiscorrectfrom(B.4).Thenormalization\n",
      "constantis?s=b0?Bsds,b0.ProofofTheorem4.1.UsingLemma4.2,the\n",
      "performancelossfor?=2canbeboundedas:0???(??)???(??)???(?\n",
      "?)???(??)=min(??(??)????(?))???(??)???(??)???\n",
      "?\n",
      "Forapolicy?,solving?(?)correspondstoanMDPwiththefollowingLP\n",
      "formulation:??(??)???(??)?min\n",
      "f\n",
      "?T(v???v):?v??P????v+\n",
      "7\n",
      "\n",
      "r??\n",
      "g\n",
      ".v\n",
      "(4.3)\n",
      "1+?Now,lettheminimum=minvkv???vk?beattainedatv0.Then,\n",
      "toshowthatv1=v0?1??1isfeasiblein(4.3),foranyk:\n",
      "?1?v???v0?1(k?1)1?v???v0+k1?(1+k)1(k?1)?1??\n",
      "P???(v???v0+k1)?(1+k)?1\n",
      "(4.4)(4.5)\n",
      "ThederivationaboveusesthemonotonicityofP???in(4.5).Then,after\n",
      "multiplyingby(I??P???),whichismonotone,andrearrangingtheterms:(I?\n",
      "?P???)?(v0?k1)?(1+??(1??)k)1+r??,where(I??P???)v?=r??\n",
      ".Lettingk=(1+?)/(1??)provestheneededfeasibilityand(4.4)establishes\n",
      "thebound.ThetightnessoftheboundfollowsfromExample3.1with?0.The\n",
      "boundonthesecondinequalityfollowsfromboundingthedualgapbetweenthe\n",
      "primalfeasiblesolutionv1andanupperboundonadualoptimalsolution.To\n",
      "upper-boundthedualsolution,aconcentrationcotforanRMDP\n",
      "similarlytoanMDP:P?a,b(s,s0)?C?(s0)foralls,s0?S,a?As,b?Bs.\n",
      "Byalgebraicmanipulation,iftheoriginalMDPhasaconcentrationcot\n",
      "Cwithadistribution?thentheaggregatedRMDPhasthesameconcentration\n",
      "cotwithadistribution?T?.Then,usingLemma4.3in(Petrik,2012),\n",
      "theoccupancyfrequency(andthereforeCthedualvalue)oftheRMDPforany\n",
      "policyisboundedasu?1???((1??)?T?+??T?).Thelinearprogram\n",
      "(4.3)canbeformulatedasthefollowingpenalizedoptimizationproblem:\n",
      "maxmin?T(v???v)+uT(I??P???)?v?r??+,u\n",
      "v\n",
      "Notethat:?T(v???v)=?TI??P???\n",
      "?1\n",
      "??(I??P???)(v???v)=d?T??(I??P??)(v??v).\n",
      "6\n",
      "Thepenalizedoptimizationproblemcanberewritten,usingthefactthat\n",
      "r??=(I??P???)v?andthefeasibilityofv1as:maxu\n",
      "s.t.\n",
      "2uT|(I??P???)(?v1?v?)|1??Cu??((1??)?T?+??T?)\n",
      "1??\n",
      "Thetheoremthenfollowsbysimplealgebraicmanipulationfromtheupper\n",
      "boundonu.4.1\n",
      "StateImportanceWeights\n",
      "Inthissection,wediscusshowtoselectthestateimportanceweightswand\n",
      "therobustnessparameter?.NotethatLemma4.2showsthatanychoiceofw\n",
      "and?suchthatthenormalizedoccupancyfrequencyiswithin?ofwinterms\n",
      "oftheL1norm,providesthetheoreticalguaranteesofTheorem4.1.Smaller\n",
      "uncertaintysetsunderthisconditiononlyimprovetheguarantees.Inpractice,\n",
      "thevalueswand?canbetreatedasregularizationparameters.Weshow\n",
      "tconditionsunderwhichtherightchoiceofwand?cantly\n",
      "reducetheperformanceloss,buttheseconditionshaveamoreexplanatorythan\n",
      "predictivecharacter.AsitcanbeseeneasilyfromtheproofofLemma4.2and\n",
      "AppendixB.2,theoptimalchoicefortheRAAMweightswtoapproximate\n",
      "8\n",
      "\n",
      "thereturnofapolicy?istouseitsstateoccupancyfrequency.Whilethe\n",
      "occupancyfrequencyisrarelyknown,thereexiststructuralproperties,suchas\n",
      "theconcentrationcocient(Munos,2005),thatcanleadtoupperboundson\n",
      "thepossibleoccupancyfrequencies.However,thefollowingexampleshowsthat\n",
      "simplyusinganupperboundontheoccupancyfrequencyisnottto\n",
      "reducetheperformanceloss.Example4.3.ConsideranMDPwith4states:s1\n",
      ",...,s4andtheaggregationwithtwostatesthatcorrespondto\n",
      "f\n",
      "s1,s2\n",
      "g\n",
      "and\n",
      "f\n",
      "s3,s4\n",
      "g\n",
      ".Letthesetofadmissibleoccupancyfrequenciesbe:Q=\n",
      "f\n",
      "d?44:1/4\n",
      "?d(s1)+d(s4)?1/2,d?1/8\n",
      "g\n",
      ".Thesetofuncertaintiesforthisboundedsetis\n",
      "4fori=1,3,andj=2,4asfollows:?QS=\n",
      "f\n",
      "d?R+:1/6?d(si)?4/5,1/5?\n",
      "d(sj)?5/6,d(si)+d(sj)=1\n",
      "g\n",
      ",whichissmallerthan?S.However,Qwithout\n",
      "theconstraintd?1/8resultsin?QS=?S.AsExample4.3demonstrates,\n",
      "theconcentrationcotalonedoesnotguaranteeanimprovementinthe\n",
      "policyloss.Onepossibleadditionalstructuralassumptionisthattheoccupancy\n",
      "frequenciesfortheindividualstatesineachaggregatestatetobe?correlated?\n",
      "acrosspolicies.Moreformally,theaggregationcorrelationcotD?R+\n",
      "mustsatisfy:??(?s)?d?(?s)??D?(?s),\n",
      "(4.6)\n",
      "?and?asinTheorem4.1.Usingthisassumption,wecanderive\n",
      "forsome??0,eachs??S,thefollowingtheorem.Considertheuncertainty\n",
      "setQs=\n",
      "f\n",
      "q:q?C(?|Bs)/(1T?(Bs))\n",
      "g\n",
      "thenwecanshowthefollowing\n",
      "theorem.Theorem4.4.GivenanMDPwithaconcentrationcoetCfor?\n",
      "andacorrelationcotTD,thenforuncertaintyset?QSandfor?=?\n",
      "(??+(1??)?)wehave:??(??)???(??)?\n",
      "2CDmink(I??P???)(?v???v)k1,?.1??v?RS\n",
      "TheproofisbasedonaminormoofTheorem4.1andisdeferred\n",
      "untiltheappendix.Theorem4.4improvesonTheorem4.1byentirelyreplacing\n",
      "theL?normbyaweightedL1norm.Whilethecorrelationcotmay\n",
      "notbeeasytodetermineinpractice,itmayapropertytoanalyzetoexplain\n",
      "afailureofthemethod.Finite-sampleboundsarebeyondthescopeofthis\n",
      "paper.However,thesamplingerrorisadditiveandcanbebasedforexample\n",
      "oncoverageassumptionsmadeforapproximatelinearprograms.Inparticular,\n",
      "(4.2)representsanapproximatelinearprogramandcanbeboundedassuch,as\n",
      "forexampledonebyPetriketal.(2010).\n",
      "5\n",
      "ExperimentalResults\n",
      "Inthissection,weexperimentallyvalidatetheapproximationpropertiesof\n",
      "RAAMwithrespecttothequalityofthesolutionsandthecomputationaltime\n",
      "required.Forthepurposeoftheempirical7\n",
      "40RobustAggregation,jj?jj1?1:5\n",
      "10?1\n",
      "ApproximateLinearProgramming\n",
      "0\n",
      "Time(s)\n",
      "MeanReturn\n",
      "20\n",
      "9\n",
      "\n",
      "100\n",
      "MeanAggregation/LSPIRobustAggregation,jj?jj1?0:5\n",
      "?20\n",
      "?40\n",
      "?600.0\n",
      "CPLEXTotalCPLEXSolverCustomPythonCustomC++\n",
      "10?2\n",
      "10?3\n",
      "10?4\n",
      "0.5\n",
      "1.0ExtraRewardrq\n",
      "1.5\n",
      "10?5110\n",
      "2.0\n",
      "102\n",
      "103\n",
      "104\n",
      "Variables\n",
      "Figure3:Sensitivitytotherewardperturbationforregularaggregationand\n",
      "RAAM.\n",
      "Figure4:Timetocompute(3.1)forAlgorithm2versusaCPLEXLPsolver.\n",
      "evaluationweuseamoinvertedpendulumproblemwithadiscount\n",
      "factorof0.99,asdescribedforexamplein(LagoudakisandParr,2003).Forthe\n",
      "aggregation,weuseauniformgridofdimension40?40anduniformsampling\n",
      "ofdimensions120?120.Theordinarysettingissolvedeasilyandreliably\n",
      "byboththestandardaggregationandRAAM.Tostudytherobustnesswith\n",
      "respecttotheapproximationerrorofsuboptimalpoliciesweaddanadditional\n",
      "rewardraforthependulumunderatiltedangle(?/2?0.12????/2and???\n",
      "0where?istheangleand??istheaction).Thisrewardcanbeonlyachieved\n",
      "byasuboptimalpolicy.Fig.3showsthereturnoftheapproximatepolicyasthe\n",
      "functionofthemagnitudeoftheadditionalrewardforthestandardaggregation\n",
      "andRAAMwithvariousvalueson?.Weomittheranges,whichare\n",
      "small,toenhanceimageclarity.Notethatweassumethatoncethependulum\n",
      "goesover?/2,thereward-1isaccrueduntiltheendofthehorizon.Thisresult\n",
      "clearlydemonstratesthegreaterstabilityandrobustnessofRAAMforthan\n",
      "standardaggregation.TheresultsalsoillustratethelackofstabilityofALP,\n",
      "whichiscanbeseenasanoptimisticversionofRAAM.Weobservedthesame\n",
      "behaviorforotherparameterchoices.ThemaincostofusingRAAMcompared\n",
      "toordinaryaggregationistheincreasedcomputationalcomplexity.Ourresults\n",
      "show,however,thatthecomputationaloverheadofRAAMisminimal.Section\n",
      "5showsthatAlgorithm2isseveralordersofmagnitudefasterthanCPLEX\n",
      "12.3.Thevaluefunctionupdatefortheaggregatedinvertedpendulumwith\n",
      "1600states,3actions,andabout9robustoutcomestakes8.7msforordinary\n",
      "aggregation,8.8msforRAAMwith?=2,and9.7msforRAAMwith?=\n",
      "1.Theguaranteesontheimprovementforoneiterationarethesameforboth\n",
      "algorithmsandallimplementationsareinC++.\n",
      "10\n",
      "\n",
      "6\n",
      "Conclusion\n",
      "RAAMisnovelapproachtostateaggregationwhichleveragesRMDPs.\n",
      "RAAMtlyreducesperformancelossguaranteesincomparisonwith\n",
      "standardaggregationwhileintroducingnegligiblecomputationaloverhead.The\n",
      "robustapproachhassomedistinctadvantagesincomparisonwithprevious\n",
      "methodswithimprovedperformancelossguarantees.Ourexperimentalresults\n",
      "areencouragingandshowthataddingrobustnesscantlyimprovethe\n",
      "solutionquality.Clearly,notallproblemswillbfromthisapproach.How-\n",
      "ever,giventhesmallcomputationaloverheadandthereisnoreasontonottry.\n",
      "Whilewedoprovidesometheoreticalforchoosingwand?,itis\n",
      "mostlikelythatinpracticethesecanbebesttreatedasregularizationparam-\n",
      "eters.ManyimprovementsonthebasicRAAMalgorithmarepossible.Most\n",
      "notably,theRMDPactionsetcouldbebasedon?meta-actions?or?options?.\n",
      "TheL1maybereplacedbyotherpolynomialnormsorKLdivergence.RAAM\n",
      "couldbealsoextendedtochooseadaptivelythemostappropriateaggregation\n",
      "forthegivensamples(BernsteinandShikim,2008).Finally,usings-rectangular\n",
      "uncertaintysetsmayleadtobetterresults.AcknowledgmentsWethankBan\n",
      "Kawasforextensivediscussionsonthistopicandtheanonymousreviewersfor\n",
      "theircommentsthathelpedtotlyimprovethepaper.\n",
      "8\n",
      "2References\n",
      "Bean,J.J.C.,Birge,J.R.J.,andSmith,R.R.L.(1987).Aggregationin\n",
      "dynamicprogramming.OperationsResearch,35(2),215?220.Bernstein,A.\n",
      "andShikim,N.(2008).Adaptiveaggregationforreinforcementlearningwith\n",
      "texploration:Deterministicdomains.InConferenceonLearningTheory\n",
      "(COLT).Bertsekas,D.P.D.andCastanon,D.A.(1989).Adaptiveaggrega-\n",
      "tionmethodsforhorizondynamicprogramming.IEEETransationson\n",
      "AutomaticControl,34,589?598.deFarias,D.P.andVanRoy,B.(2003).The\n",
      "linearprogrammingapproachtoapproximatedynamicprogramming.Opera-\n",
      "tionsResearch,51(6),850?865.Desai,V.V.,Farias,V.F.,andMoallemi,C.\n",
      "C.(2012).Approximatedynamicprogrammingviaasmoothedlinearprogram.\n",
      "OperationsResearch,60(3),655?674.Filar,J.andVrieze,K.(1997).Com-\n",
      "petitiveMarkovDecisionProcesses.Springer.Gordon,G.J.(1995).Stable\n",
      "functionapproximationindynamicprogramming.InInternationalConference\n",
      "onMachineLearning,pages261?268.CarnegieMellonUniversity.Hansen,\n",
      "T.,Miltersen,P.,andZwick,U.(2013).Strategyiterationisstronglypolyno-\n",
      "mialfor2playerturn-basedstochasticgameswithaconstantdiscountfactor.\n",
      "JournaloftheACM(JACM),60(1),1?16.Iyengar,G.N.(2005).Robust\n",
      "dynamicprogramming.MathematicsofOperationsResearch,30(2),257?280.\n",
      "Kaufman,D.L.andSchaefer,A.J.(2013).Robustmopolicyiteration.\n",
      "INFORMSJournalonComputing,25(3),396?410.Lagoudakis,M.G.and\n",
      "Parr,R.(2003).Least-squarespolicyiteration.JournalofMachineLearning\n",
      "11\n",
      "\n",
      "Research,4,1107?1149.LeTallec,Y.(2007).Robust,Risk-Sensitive,andData-\n",
      "drivenControlofMarkovDecisionProcesses.Ph.D.thesis,MIT.Mannor,S.,\n",
      "Mebel,O.,andXu,H.(2012).Lightningdoesnotstriketwice:RobustMDPs\n",
      "withcoupleduncertainty.InInternationalConferenceonMachineLearning.\n",
      "Marecki,J.,Petrik,M.,andSubramanian,D.(2013).Solutionmethodsfor\n",
      "constrainedMarkovdecisionprocesswithcontinuousprobabilitymodulation.\n",
      "InUncertaintyinIntelligence(UAI).Munos,R.(2005).Performance\n",
      "boundsinLpnormforapproximatevalueiteration.InNationalConference\n",
      "onIntelligence(AAAI).Nilim,A.andGhaoui,L.E.(2005).Robust\n",
      "controlofMarkovdecisionprocesseswithuncertaintransitionmatrices.Op-\n",
      "erationsResearch,53(5),780?798.Petrik,M.(2012).Approximatedynamic\n",
      "programmingbyminimizingdistributionallyrobustbounds.InInternational\n",
      "ConferenceofMachineLearning.Petrik,M.andZilberstein,S.(2009).Con-\n",
      "straintrelaxationinapproximatelinearprograms.InInternationalConference\n",
      "onMachineLearning,NewYork,NewYork,USA.ACMPress.Petrik,M.,\n",
      "Taylor,G.,Parr,R.,andZilberstein,S.(2010).Featureselectionusingregular-\n",
      "izationinapproximatelinearprogramsforMarkovdecisionprocesses.InInter-\n",
      "nationalConferenceonMachineLearning.Porteus,E.L.(2002).Foundations\n",
      "ofStochasticInventoryTheory.StanfordBusinessBooks.Puterman,M.L.\n",
      "(2005).Markovdecisionprocesses:Discretestochasticdynamicprogramming.\n",
      "JohnWiley&Sons,Inc.Tsitsiklis,J.N.andVanRoy,B.(1996).Ananalysisof\n",
      "templearningwithfunctionapproximation.VanRoy,B.(2005).\n",
      "Performancelossboundsforapproximatevalueiterationwithstateaggregation.\n",
      "MathematicsofOperationsResearch,31(2),234?244.Wiesemann,W.,Kuhn,\n",
      "D.,andRustem,B.(2013).RobustMarkovdecisionprocesses.Mathematicsof\n",
      "OperationsResearch,38(1),153?183.9\n",
      "12\n",
      "\n",
      "PP3988.pdf\n",
      "PP3988.pdf 13\n",
      "tandRobustFeatureSelectionviaJoint\n",
      "?2,1-NormsMinimization\n",
      "Authoredby:\n",
      "ChrisH.Ding\n",
      "FeipingNie\n",
      "HengHuang\n",
      "XiaoCai\n",
      "Abstract\n",
      "Featureselectionisanimportantcomponentofmanymachinelearning\n",
      "applications.Especiallyinmanybioinformaticstasks,tandrobust\n",
      "featureselectionmethodsaredesiredtoextractmeaningfulfeaturesand\n",
      "eliminatenoisyones.Inthispaper,weproposeanewrobustfeature\n",
      "selectionmethodwithemphasizingjoint?2,1-normminimizationonboth\n",
      "lossfunctionandregularization.The?2,1-normbasedlossfunctionis\n",
      "robusttooutliersindatapointsandthe?2,1-normregularizationselects\n",
      "featuresacrossalldatapointswithjointsparsity.Antalgorithm\n",
      "isintroducedwithprovedconvergence.Ourregressionbasedobjective\n",
      "makesthefeatureselectionprocessmoret.Ourmethodhasbeen\n",
      "appliedintobothgenomicandproteomicbiomarkersdiscovery.Extensive\n",
      "empiricalstudieswereperformedonsixdatasetstodemonstratethe\n",
      "enessofourfeatureselectionmethod.\n",
      "1PaperBody\n",
      "Featureselection,theprocessofselectingasubsetofrelevantfeatures,isakey\n",
      "componentinbuildingrobustmachinelearningmodelsforclasscation,clus-\n",
      "tering,andothertasks.Featuresectionhasbeenplayinganimportantrolein\n",
      "manyapplicationssinceitcanspeedupthelearningprocess,improvethemode\n",
      "generalizationcapability,andalleviatetheofthecurseofdimensionality\n",
      "[15].Alargenumberofdevelopmentsonfeatureselectionhavebeenmadein\n",
      "theliteratureandtherearemanyrecentreviewsandworkshopsdevotedtothis\n",
      "topic,e.g.,NIPSConference[7].Inpasttenyears,featureselectionhasseen\n",
      "muchactivitiesprimarilyduetotheadvancesinbioinformaticswherealarge\n",
      "amountofgenomicandproteomicdataareproducedforbiologicalandbiomed-\n",
      "icalstudies.Forexample,ingenomics,DNAmicroarraydatameasurethe\n",
      "expressionlevelsofthousandsofgenesinasingleexperiment.Geneexpression\n",
      "1\n",
      "\n",
      "datausuallycontainalargenumberofgenes,butasmallnumberofsamples.A\n",
      "givendiseaseorabiologicalfunctionisusuallyassociatedwithafewgenes[19].\n",
      "Outofseveralthousandsofgenestoselectafewofrelevantgenesthusbecomes\n",
      "akeyprobleminbioinformaticsresearch[22].Inproteomics,high-throughput\n",
      "massspectrometry(MS)screeningmeasuresthemolecularweightsofindividual\n",
      "biomolecules(suchasproteinsandnucleicacids)andhaspotentialtodiscover\n",
      "putativeproteomicbiomarkers.Eachspectrumiscomposedofpeakamplitude\n",
      "measurementsatapproximately15,500featuresrepresentedbyacorresponding\n",
      "mass-to-chargevalue.Theidenofmeaningfulproteomicfeaturesfrom\n",
      "MSiscrucialfordiseasediagnosisandprotein-basedbiomarkerp[22].1\n",
      "Ingeneral,therearethreemodelsoffeatureselectionmethodsintheliter-\n",
      "ature:(1)methods[14]wheretheselectionisindependentof\n",
      "(2)wrappermethods[12]wherethepredictionmethodisusedasablackbox\n",
      "toscoresubsetsoffeatures,and(3)embeddedmethodswheretheprocedure\n",
      "offeatureselectionisembeddeddirectlyinthetrainingprocess.Inbioinfor-\n",
      "maticsapplications,manyfeatureselectionmethodsfromthesecategorieshave\n",
      "beenproposedandapplied.Widelyusedypefeatureselectionmethods\n",
      "includeF-statistic[4],reliefF[11,13],mRMR[19],t-test,andinformation\n",
      "gain[21]whichcomputethesensitivity(correlationorrelevance)ofafeature\n",
      "withrespectto(w.r.t)theclasslabeldistributionofthedata.Thesemeth-\n",
      "odscanbecharacterizedbyusingglobalstatisticalinformation.Wrapper-type\n",
      "featureselectionmethodsistightlycoupledwithaspecsuchas\n",
      "correlation-basedfeatureselection(CFS)[9],supportvectormachinerecursive\n",
      "featureelimination(SVM-RFE)[8].Theyoftenhavegoodperformance,but\n",
      "theircomputationalcostisveryexpensive.Recentlysparsityregularizationin\n",
      "dimensionalityreductionhasbeenwidelyinvestigatedandalsoappliedintofea-\n",
      "tureselectionstudies.`1-SVMwasproposedtoperformfeatureselectionusing\n",
      "the`1-normregularizationthattendstogivesparsesolution[3].Becausethe\n",
      "numberofselectedfeaturesusing`1-SVMisupperboundedbythesamplesize,\n",
      "aHybridHuberizedSVM(HHSVM)wasproposedcombiningboth`1-norm\n",
      "and`2-normtoformamorestructuredregularization[26].Butitwasdesigned\n",
      "onlyforbinaryInmulti-tasklearning,inparallelworks,Obozin-\n",
      "skyet.al.[18]andArgyriouet.al.[1]havedevelopedasimilarmodelfor\n",
      "`2,1-normregularizationtocouplefeatureselectionacrosstasks.Suchregu-\n",
      "larizationhascloseconnectionstogrouplasso[28].Inthispaper,wepropose\n",
      "anovelientandrobustfeatureselectionmethodtoemployjoint`2,1norm\n",
      "minimizationonbothlossfunctionandregularization.Insteadofusing`2-norm\n",
      "basedlossfunctionthatissensitivetooutliers,a`2,1-normbasedlossfunction\n",
      "isadoptedinourworktoremoveoutliers.Motivatedbypreviousresearch[1,\n",
      "18],a`2,1-normregularizationisperformedtoselectfeaturesacrossalldata\n",
      "pointswithjointsparsity,i.e.eachfeature(geneexpressionormass-to-charge\n",
      "valueinMS)eitherhassmallscoresforalldatapointsorhaslargescoresover\n",
      "alldatapoints.Tosolvethisnewrobustfeatureselectionobjective,wepropose\n",
      "antalgorithmtosolvesuchjoint`2,1-normminimizationproblem.We\n",
      "alsoprovidethealgorithmanalysisandprovetheconvergenceofouralgorithm.\n",
      "Extensiveexperimentshavebeenperformedonsixbioinformaticsdatasetsand\n",
      "2\n",
      "\n",
      "ourmethodoutperformseothercommonlyusedfeatureselectionmethodsin\n",
      "statisticallearningandbioinformatics.\n",
      "2NotationsandWesummarizethenotationsandthe\n",
      "ofnormsusedinthispaper.Matricesarewrittenasboldfaceuppercaseletters.\n",
      "Vectorsarewrittenasboldfacelowercaseletters.FormatrixM=(mij),its\n",
      "i-throw,j-thcolumnaredenotedbymi,mjrespectively.?n?p1PpnThe\n",
      "`p-normofthevectorv?Risaskvkp=|vi|.The`0-normofthe\n",
      "vectorn\n",
      "v?Risdenedaskvk0=\n",
      "nPi=1\n",
      "i=1\n",
      "0\n",
      "|vi|.TheFrobeniusnormofthematrixM?Rn?misas\n",
      "vvunuXmuXunX22tkMkF=kmik2.mij=ti=1j=1\n",
      "(1)\n",
      "i=1\n",
      "The`2,1-normofamatrixwasintroducedin[5]asrotationalinvariant\n",
      "`1normandalsousedformulti-tasklearning[1,18]andtensorfactorization\n",
      "[10].Itisas\n",
      "kMk2,1\n",
      "vnnuXXX?i?um2?m?,t=mij=2i=1\n",
      "j=1\n",
      "2\n",
      "i=1\n",
      "(2)\n",
      "whichisrotationalinvariantforrows:kMRk2,1=kMk2,1foranyrotational\n",
      "matrixR.The`2,1-normcanbegeneralizedto`r,p-norm???pr?p1?n!1\n",
      "mnXXX??pp??r?mi??kMkr,p=?|mij|??=.(3)rj=1\n",
      "i=1\n",
      "i=1\n",
      "Notethat`r,p-normisavalidnormbecauseitthethreenorm\n",
      "conditions,includingthetriangleinequalitykAkr,p+kBkr,p?kA+Bkr,p.\n",
      "Thiscanbeprovedasfollows.Startingfrom111PPPthetriangleinequality\n",
      "(i|ui|p)p+(i|vi|p)p?(i|ui+vi|p)pandsettingui=kai\n",
      "krandvi=kbikr,weobtain?!p1?!p1?!p1?!p1XXXXipipiip\n",
      "iipkakr+kbkr?|kakr+kbkr|?|ka+bkr|,(4)i\n",
      "i\n",
      "i\n",
      "i\n",
      "wherethesecondinequalityfollowsthetriangleinequalityfor`rnorm:kai\n",
      "kr+kbikr?kai+bikr.Eq.(4)isjustkAkr,p+kBkr,p?kA+Bkr,p\n",
      ".However,the`0-normisnotavalidnormbecauseitdoesnotsatisfythe\n",
      "positivescalability:k?vk0=|?|kvk0forscalar?.Theterm?norm?hereis\n",
      "forconvenience.\n",
      "3\n",
      "RobustFeatureSelectionBasedon`2,1-Norms\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leastsquareregressionisoneofthepopularmethodsfor\n",
      "Giventrainingdata\n",
      "f\n",
      "x1,x2,???,xn\n",
      "g\n",
      "?Rdandtheassociatedclass\n",
      "labels\n",
      "f\n",
      "y1,y2,???,yn\n",
      "g\n",
      "?Rc,traditionalleastsquareregressionsolves\n",
      "thefollowingoptimizationproblemtoobtaintheprojectionmatrixW?Rd?c\n",
      "andthebiasb?Rc:nX?T??Wxi+b?yi?2.min2\n",
      "W,b\n",
      "(5)\n",
      "i=1\n",
      "Forsimplicity,thebiasbcanbeabsorbedintoWwhentheconstantvalue\n",
      "1isaddedasanadditionaldimensionforeachdataxi(1?i?n).Thusthe\n",
      "problembecomes:minW\n",
      "nX?T??Wxi?yi?2.2\n",
      "(6)\n",
      "i=1\n",
      "Inthispaper,weusetherobustlossfunction:minW\n",
      "nX?T??Wxi?yi?,2\n",
      "(7)\n",
      "i=1\n",
      "wheretheresidualkWTxi?yikisnotsquaredandthusoutliershaveless\n",
      "importancethanthesquaredresidualkWTxi?yik2.Thislossfunctionhas\n",
      "arotationalinvariantpropertywhilethepure`1-normlossfunctiondoesnot\n",
      "hassuchdesirableproperty[5].WenowaddaregularizationtermR(W)with\n",
      "parameter?.Theproblembecomes:minW\n",
      "nX?T??Wxi?yi?+?R(W).2\n",
      "(8)\n",
      "i=1\n",
      "Severalregularizationsarepossible:R1(W)=kWk2,R2(W)=\n",
      "cX\n",
      "kwjk1,R3(W)=\n",
      "j=1\n",
      "ddXX?i?0?i??w?,R4(W)=?w?.22i=1\n",
      "(9)\n",
      "i=1\n",
      "R1(W)istheridgeregularization.R2(W)istheLASSOregularization.\n",
      "R3(W)andR4(W)penalizesallcregressioncotscorrespondingtoa\n",
      "singlefeatureasawhole.Thishasthe3\n",
      "offeatureselection.Althoughthe`0-normofR3(W)isthemost\n",
      "desirable[16],inthispaper,weuseR4(W)instead.Thereasonsare:(A)the`1\n",
      "-normofR4(W)isconvexandcanbeeasilyoptimized(themaincontribution\n",
      "ofthispaper);(B)itwasshownthatresultsof`0-normisidenticalorapproxi-\n",
      "matelyidenticaltothe`1-normresultsunderpracticalconditions.Denotedata\n",
      "matrixX=[x1,x2,???,xn]?Rd?nandlabelmatrixY=[y1,y2,??\n",
      "?,yn]T?Rn?c.Inthispaper,weoptimizeminJ(W)=W\n",
      "nX?T????Wxi?yi?+?R4(W)=?XTW?Y?+?kWk.2,122,1\n",
      "(10)\n",
      "i=1\n",
      "4\n",
      "\n",
      "Itseemsthatsolvingthisjoint`2,1-normproblemisasbothofthe\n",
      "termsarenon-smooth.Surprisingly,wewillshowinthenextsectionthatthe\n",
      "problemcanbesolvedusingasimpleyettalgorithm.\n",
      "44.1\n",
      "AntAlgorithmReformulationasAConstrainedProblem\n",
      "First,theprobleminEq.(10)isequivalentto?1?min?XTW?Y?2,1+\n",
      "kWk2,1,W?whichisfurtherequivalenttominkEk2,1+kWk2,1\n",
      "W,E\n",
      "Rewritingtheaboveproblemas?????W???minE?W,E?\n",
      "XTW+?E=Y.\n",
      "s.t.\n",
      "?\n",
      "s.t.\n",
      "(11)\n",
      "X\n",
      "T\n",
      "?I\n",
      "?\n",
      "?\n",
      "2,1\n",
      "WE\n",
      "where?I?R?n?nisanidentitymatrix.Denotem=n+d.LetA=WU=\n",
      "?Rm?c,thentheprobleminEq.(13)canbewrittenas:EminkUk2,1U\n",
      "s.t.\n",
      "AU=Y\n",
      "(12)\n",
      "?=Y,?\n",
      "XT\n",
      "(13)?I\n",
      "?\n",
      "?Rn?mand\n",
      "(14)\n",
      "ThisoptimizationproblemEq.(14)hasbeenwidelyusedintheMultiple\n",
      "MeasurementVector(MMV)modelinsignalprocessingcommunity.Itwas\n",
      "generallyfeltthatthe`2,1-normminimizationproblemismuchmore\n",
      "tosolvethanthe`1-normminimizationproblem.Existingalgorithmsusually\n",
      "reformulateitasasecond-orderconeprogramming(SOCP)orpro-\n",
      "gramming(SDP)problem,whichcanbesolvedbyinteriorpointmethodorthe\n",
      "bundlemethod.However,solvingSOCPorSDPiscomputationallyveryex-\n",
      "pensive,whichlimitstheiruseinpractice.Recently,antalgorithmwas\n",
      "proposedtosolvethespproblemEq.(14)bycomplicatedlyreformulating\n",
      "theproblemasamin-maxproblemandthenapplyingtheproximalmethod\n",
      "tosolveit[25].Thereportedresultsshowthatthealgorithmismoret\n",
      "thanexistingalgorithms.However,thealgorithmisagradientdescenttype\n",
      "methodandconvergesveryslow.Moreover,thealgorithmisderivedtosolve\n",
      "thespproblem,andcannotbeapplieddirectlytosolveothergeneral`2,1\n",
      "5\n",
      "\n",
      "-normminimizationproblem.Inthenextsubsection,wewillproposeavery\n",
      "simplebutatthesametimemuchmoretmethodtosolvethisproblem.\n",
      "Theoreticalanalysisguaranteesthattheproposedmethodwillconvergetothe\n",
      "globaloptimum.Moreimportantly,thismethodisveryeasytoimplementand\n",
      "canbereadilyusedtosolveothergeneral`2,1-normminimizationproblem.4.2\n",
      "AntAlgorithmtoSolvetheConstrainedProblem\n",
      "TheLagrangianfunctionoftheprobleminEq.(14)isL(U)=kUk2,1?T\n",
      "r(?T(AU?Y)).4\n",
      "(15)\n",
      "TakingthederivativeofL(U)w.r.tU,andsettingthederivativetozero,we\n",
      "have:?L(U)=2DU?AT?=0,?UwhereDisadiagonalmatrixwiththei-th\n",
      "diagonalelementas11dii=.2kuik2\n",
      "(16)\n",
      "(17)\n",
      "LeftmultiplyingthetwosidesofEq.(16)byAD?1,andusingtheconstraint\n",
      "AU=Y,wehave:2AU?AD?1AT?=0?2Y?AD?1AT?=0??=2(AD?1\n",
      "AT)?1YSubstituteEq.(18)intoEq.(16),wearriveat:\n",
      "(18)\n",
      "U=D?1AT(AD?1AT)?1Y.\n",
      "(19)\n",
      "SincetheprobleminEq.(14)isaconvexproblem,Uisaglobaloptimum\n",
      "solutiontotheproblemifandonlyiftheEq.(19)isNotethatDis\n",
      "dependenttoUandthusisalsoaunknownvariable.Weproposeaniterative\n",
      "algorithminthispapertoobtainthesolutionUsuchthatEq.(19)is\n",
      "andproveinthenextsubsectionthattheproposediterativealgorithmwill\n",
      "convergetotheglobaloptimum.ThealgorithmisdescribedinAlgorithm1.\n",
      "Ineachiteration,UiscalculatedwiththecurrentD,andthenDisupdated\n",
      "basedonthecurrentcalculatedU.Theiterationprocedureisrepeateduntilthe\n",
      "algorithmconverges.Data:A?Rn?m,Y?Rn?cResult:U?Rm?cSett=0.\n",
      "InitializeDt?Rm?masanidentitymatrixrepeat?1T?1TCalculateUt+1\n",
      "=D?1Y.tA(ADtA)CalculatethediagonalmatrixDt+1,wherethei-th\n",
      "diagonalelementis\n",
      "12kuit+1k\n",
      ".\n",
      "2\n",
      "t=t+1.untilConvergesAlgorithm1:Antiterativealgorithmto\n",
      "solvetheoptimizationprobleminEq.(14).4.3\n",
      "AlgorithmAnalysis\n",
      "TheAlgorithm1monotonicallydecreasestheobjectiveoftheproblemin\n",
      "Eq.(14)ineachiteration.Toproveit,weneedthefollowinglemma:Lemma\n",
      "1.Foranynonzerovectorsu,ut?Rc,thefollowinginequalityholds:2\n",
      "kuk2?\n",
      "2\n",
      "kuk2kutk2?kutk2?.2kutk22kutk2\n",
      "(20)\n",
      "6\n",
      "\n",
      "??Proof.Beginningwithanobviousinequality(v?vt)2?0,wehave?\n",
      "???v(v?vt)2?0?v?2vvt+vt?0?v???2vt\n",
      "?\n",
      "??vtvvt?v???vt??(21)22vt2vt\n",
      "2\n",
      "2\n",
      "SubstitutethevandvtinEq.(21)bykuk2andkutk2respectively,we\n",
      "arriveattheEq.(20).1\n",
      "Whenui=0,thendii=0isasubgradientofkUk2,1w.r.t.ui.However,\n",
      "wecannotsetdii=0whenu=0,otherwisethederivedalgorithmcannotbe\n",
      "guaranteedtoconverge.Twomethodscanbeusedtosolvethisproblem.?First,\n",
      "D?1,sowecanletthei-thelement?wewillseefromEq.(19)thatweonly\n",
      "needtocalculate?1i?1?ofDas2u2.Second,wecanregularizediiasdii=\n",
      "?iTi,andthederivedalgorithmcanbe2(u)u+?npPprovedtominimize\n",
      "theregularized`2,1-normsofUas(ui)Tui+?)insteadofthe`2,1\n",
      "-normsi\n",
      "i=1\n",
      "ofU.Itiseasytoseethattheregularized`2,1-normsofUapproximatesthe\n",
      "`2,1-normsofUwhen??0.\n",
      "5\n",
      "TheconvergenceoftheAlgorithm1issummarizedinthefollowingtheorem:\n",
      "Theorem1.TheAlgorithm1willmonotonicallydecreasetheobjectiveofthe\n",
      "probleminEq.(14)ineachiteration,andconvergetotheglobaloptimumof\n",
      "theproblem.Proof.ItcaneasilyvthatEq.(19)isthesolutiontothe\n",
      "followingproblem:minTr(UTDU)s.t.AU=YU\n",
      "Thusinthetiteration,\n",
      "Ut+1=argminTrUTDtU,\n",
      "(23)\n",
      "Tr(UTt+1DtUt+1)?Tr(UTtDtUt).\n",
      "(24)\n",
      "??2??m?im?i?2XXut+1?2u????t?2,i???2ut2uit?\n",
      "(25)\n",
      "UAU=Y\n",
      "whichindicatesthatThatistosay,\n",
      "(22)\n",
      "i=1\n",
      "2\n",
      "i=1\n",
      "2\n",
      "wherevectorsuitanduit+1denotethei-throwofmatricesUtandUt+1,\n",
      "respectively.Ontheotherhand,accordingtoLemma1,foreachiwehave?i\n",
      "?2?i?2?ut+1??u??i??i?2?ut+1??????ut???t?2.i22??\n",
      "2ut22?uit?2Thusthefollowinginequalityholds:???i?2!?i?2!mm\n",
      "?ut+1??u?XX?i??i?2?ut+1?????ut???t?2.?i222?ut?2\n",
      "?uit?2\n",
      "i=1\n",
      "7\n",
      "\n",
      "i=1\n",
      "(26)\n",
      "(27)\n",
      "2\n",
      "CombiningEq.(25)andEq.(27),wearriveatmmXX?i??i??ut+1\n",
      "???ut?.22i=1\n",
      "(28)\n",
      "i=1\n",
      "Thatistosay,kUt+1k2,1?kUtk2,1.(29)ThustheAlgorithm1will\n",
      "monotonicallydecreasetheobjectiveoftheprobleminEq.(14)ineachiteration\n",
      "t.Intheconvergence,UtandDtwillsatisfytheEq.(19).Astheproblemin\n",
      "Eq.(14)isaconvexproblem,satisfyingtheEq.(19)indicatesthatUisa\n",
      "globaloptimumsolutiontotheprobleminEq.(14).Therefore,theAlgorithm\n",
      "1willconvergetotheglobaloptimumoftheproblem(14).Notethatineach\n",
      "iteration,theEq.(19)canbesolvedtly.First,D?is?adiagonalmatrix\n",
      "and?i?thusD?1isalsodiagonalwiththei-thdiagonalelementasd?1ii=2\n",
      "u2.Second,theterm?1T?1Z=(ADA)YinEq.(19)canbetly\n",
      "obtainedbysolvingthelinearequation:(AD?1AT)Z=Y.(30)Empirical\n",
      "resultsshowthattheconvergenceisfastandonlyafewiterationsareneeded\n",
      "toconverge.Therefore,theproposedmethodcanbeappliedtolargescale\n",
      "probleminpractice.Itisworthtopointoutthattheproposedmethodcanbe\n",
      "easilyextendedtosolveother`2,1-normminimizationproblem.Forexample,\n",
      "consideringageneral`2,1-normminimizationproblemasfollows:Xminf(U)\n",
      "+kAkU+Bkk2,1s.t.U?C(31)U\n",
      "k\n",
      "Theproblemcanbesolvedbysolvethefollowingproblemiteratively:Xmin\n",
      "f(U)+Tr((AkU+Bk)TDk(AkU+Bk))s.t.U\n",
      "U?C\n",
      "(32)\n",
      "k\n",
      "1.SimilartheoreticalwhereDkisadiagonalmatrixwiththei-thdiagonal\n",
      "elementas2k(AkU+Bik)k2analysiscanbeusedtoprovethattheiterative\n",
      "methodwillconvergetoalocalminimum.IftheproblemEq.(31)isaconvex\n",
      "problem,i.e.,f(U)isaconvexfunctionandCisaconvexset,thentheiterative\n",
      "methodwillconvergetotheglobalminimum.\n",
      "6\n",
      "100\n",
      "8075\n",
      "95\n",
      "95\n",
      "85\n",
      "80\n",
      "ReliefFFscoreRankT?testInformationgainmRMRRFS\n",
      "75\n",
      "70\n",
      "0\n",
      "8\n",
      "\n",
      "10\n",
      "20\n",
      "30405060thenumberoffeaturesselected\n",
      "70\n",
      "65605550ReliefFFscoreRankT?testInformationgainmRMRRFS\n",
      "45403530\n",
      "80\n",
      "theaccuracy\n",
      "theaccuracy\n",
      "theaccuracy\n",
      "70\n",
      "90\n",
      "0\n",
      "10\n",
      "(a)ALLAML\n",
      "20\n",
      "30405060thenumberoffeaturesselected\n",
      "70\n",
      "90\n",
      "85ReliefFFscoreRankT?testInformationgainmRMRRFS\n",
      "80\n",
      "75\n",
      "80\n",
      "0\n",
      "10\n",
      "20\n",
      "(b)GLIOMA\n",
      "100\n",
      "98\n",
      "90\n",
      "96\n",
      "80\n",
      "94\n",
      "30405060thenumberoffeaturesselected\n",
      "70\n",
      "80\n",
      "(c)LUNG100\n",
      "605040\n",
      "ReliefFFscoreRankT?testInformationgainmRMRRFS\n",
      "302010\n",
      "0\n",
      "10\n",
      "20\n",
      "30405060thenumberoffeaturesselected\n",
      "70\n",
      "92908886\n",
      "9\n",
      "\n",
      "ReliefFFscoreRankT?testInformationgainmRMRRFS\n",
      "848280\n",
      "(d)Carcinomas\n",
      "theaccuracy\n",
      "theaccuracy\n",
      "theaccuracy\n",
      "95\n",
      "70\n",
      "80\n",
      "0\n",
      "10\n",
      "20\n",
      "30405060thenumberoffeaturesselected\n",
      "(e)PROSTATE-GE\n",
      "70\n",
      "90\n",
      "85\n",
      "80\n",
      "ReliefFFscoreRankT?testInformationgainmRMRRFS\n",
      "75\n",
      "80\n",
      "70\n",
      "0\n",
      "10\n",
      "20\n",
      "30405060thenumberoffeaturesselected\n",
      "70\n",
      "80\n",
      "(f)PROSTATE-MS\n",
      "Figure1:accuracycomparisonsofsixfeatureselectionalgo-\n",
      "rithmson6datasets.SVMwith5-foldcrossvalidationisusedfor\n",
      "RFSisourmethod.\n",
      "5\n",
      "ExperimentalResults\n",
      "Inordertovalidatetheperformanceofourfeatureselectionmethod,we\n",
      "appliedourmethodintotwobioinformaticsapplications,geneexpressionand\n",
      "massspectrometryInourexperiments,weusedvepublicly\n",
      "availablemicroarraydatasetsandoneMassSpectrometry(MS)datasets:AL-\n",
      "LAMLdataset[6],themalignantglioma(GLIOMA)dataset[17],thehuman\n",
      "lungcarcinomas(LUNG)dataset[2],HumanCarcinomas(Carcinomas)data\n",
      "set[24,27],ProstateCancergeneexpression(Prostate-GE)dataset[23]for\n",
      "microarraydata;andProstateCancer(Prostate-MS)[20]forMSdata.The\n",
      "SupportVectorMachine(SVM)isemployedtothesedatasets,using\n",
      "5-foldcross-validation.5.1\n",
      "DataSetsDescriptions\n",
      "10\n",
      "\n",
      "Wegiveabriefdescriptiononalldatasetsusedinourexperimentsasfol-\n",
      "lows.ALLAMLdatasetcontainsintotal72samplesintwoclasses,ALLand\n",
      "AML,whichcontain47and25samples,respectively.Everysamplecontains\n",
      "7,129geneexpressionvalues.GLIOMAdatasetcontainsintotal50samplesin\n",
      "fourclasses,cancerglioblastomas(CG),noncancerglioblastomas(NG),cancer\n",
      "oligodendrogliomas(CO)andnon-canceroligodendrogliomas(NO),whichhave\n",
      "14,14,7,15samples,respectively.Eachsamplehas12625genes.Geneswith\n",
      "minimalvariationsacrossthesampleswereremoved.Forthisdataset,inten-\n",
      "sitythresholdsweresetat20and16,000units.Geneswhoseexpressionlevels\n",
      "varied<100unitsbetweensamples,orvaried<3foldbetweenanytwosamples,\n",
      "wereexcluded.Afterpreprocessing,weobtainedadatasetwith50samplesand\n",
      "4433genes.LUNGdatasetcontainsintotal203samplesineclasses,which\n",
      "have139,21,20,6,17samples,respectively.Eachsamplehas12600genes.The\n",
      "geneswithstandarddeviationssmallerthan50expressionunitswereremoved\n",
      "andweobtainedadatasetwith203samplesand3312genes.Carcinomasdata\n",
      "setcomposedoftotal174samplesinelevenclasses,prostate,bladder/ureter,\n",
      "breast,colorectal,gastroesophagus,kidney,liver,ovary,pancreas,lungadeno-\n",
      "carcinomas,andlungsquamouscellcarcinoma,whichhave26,8,26,23,12,\n",
      "11,7,27,6,14,14samples,respectively.Intheoriginaldata[24],eachsample\n",
      "contains12533genes.Inthepreprocesseddataset[27],thereare174samples\n",
      "and9182genes.7\n",
      "Table1:AccuracyofSVMusing5-foldcrossvalidation.Six\n",
      "featureselectionmethodsarecompared.RF:ReliefF,F-s:F-score,IG:Infor-\n",
      "mationGain,andRFS:ourmethod.Averageaccuracyoftop20features(%)\n",
      "RFF-sT-testIGmRMRALLAML90.3689.1192.8693.2193.21GLIOMA50\n",
      "50566062LUNG91.6887.789.2293.192.61Carcinom.79.8865.4849.985.09\n",
      "78.22Pro-GE92.1895.0992.1892.1893.18Pro-MS76.4198.8995.5698.89\n",
      "95.42Average80.0981.0479.2987.0985.78\n",
      "RFS95.897493.6391.3895.0998.8991.48\n",
      "Averageaccuracyoftop80features(%)RFF-sT-testIGmRMR95.89\n",
      "96.0794.2995.7194.46546058666693.6391.6390.6695.194.1290.2483.33\n",
      "68.9189.6587.9291.1893.1893.1889.2786.3689.9398.8994.4498.8993.14\n",
      "85.8187.1883.2589.1087\n",
      "RFS97.327096.0793.6695.0910092.02\n",
      "Prostate-GEdatasethasintotal102samplesintwoclassestumorand\n",
      "normal,whichhave52and50samples,respectively.Theoriginaldataset\n",
      "contains12600genes.Inourexperiment,intensitythresholdsweresetat100\n",
      "C16000units.Thenweoutthegeneswithmax/min?5or(max-\n",
      "min)?50.Afterpreprocessing,weobtainedadatasetwith102samplesand\n",
      "5966genes.Prostate-MSdatacanbeobtainedfromtheFDA-NCIClinical\n",
      "ProteomicsProgramDatabank[20].ThisMSdatasetconsistsof190samples\n",
      "diagnosedasbenignprostatehyperplasia,63samplesconsideredasnoevidence\n",
      "ofdisease,and69samplesdiagnosedasprostatecancer.Thesamplesdiagnosed\n",
      "asbenignprostatehyperplasiaaswellassampleshavingnoevidenceofprostate\n",
      "cancerwerepooledintoonesetmaking253controlsamples,whereastheother\n",
      "69samplesarethecancersamples.5.2\n",
      "11\n",
      "\n",
      "AccuracyComparisons\n",
      "Alldatasetsarestandardizedtobezero-meanandnormalizedbystandard\n",
      "deviation.SVMhasbeenindividuallyperformedonalldatasetsusing\n",
      "5-foldcross-validation.WeutilizethelinearkernelwiththeparameterC=1.\n",
      "Wecompareourfeatureselectionmethod(calledasRFS)toseveralpopularly\n",
      "usedfeatureselectionmethodsinbioinformatics,suchasF-statistic[4],reliefF\n",
      "[11,13],mRMR[19],t-test,andinformationgain[21].Becausetheabove\n",
      "datasetsareformulticlassproblem,wedon?tcompareto`1-\n",
      "SVM,HHSVMandothermethodsthatweredesignedforbinary\n",
      "Fig.1showstheaccuracycomparisonsofallefeatureselection\n",
      "methodsonsixdatasets.Table1showsthedetailedexperimentalresultsusing\n",
      "SVM.Wecomputetheaverageaccuracyusingthetop20andtop80features\n",
      "forallfeatureselectionapproaches.Obviouslyourapproachesoutperformother\n",
      "methodstly.Withtop20features,ourmethodisaround5%-12%\n",
      "betterthanothermethodsallsixdatasets.\n",
      "6\n",
      "Conclusions\n",
      "Inthispaper,weproposedanewcientandrobustfeatureselection\n",
      "methodwithemphasizingjoint`2,1-normminimizationonbothlossfunction\n",
      "andregularization.The`2,1-normbasedregressionlossfunctionisrobustto\n",
      "outliersindatapointsandalsotincalculation.Motivatedbyprevious\n",
      "work,the`2,1-normregularizationisusedtoselectfeaturesacrossalldatapoints\n",
      "withjointsparsity.Weprovidedantalgorithmwithprovedconvergence.\n",
      "Ourmethodhasbeenappliedintobothgenomicandproteomicbiomarkersdis-\n",
      "covery.Extensiveempiricalstudieshavebeenperformedontwobioinformatics\n",
      "tasks,sixdatasets,todemonstratetheperformanceofourmethod.\n",
      "7\n",
      "Acknowledgements\n",
      "ThisresearchwasfundedbyUSNSF-CCF-0830780,0939187,0917274,NSF\n",
      "DMS-0915228,NSFCNS-0923494,1035913.8\n",
      "2References\n",
      "[1]A.Argyriou,T.Evgeniou,andM.Pontil.Multi-taskfeaturelearning.NIPS,\n",
      "pages41?48,2007.[2]A.Bhattacharjee,W.G.Richards,andet.al.\n",
      "tionofhumanlungcarcinomasbymRNAexpressionrevealsdistinct\n",
      "adenocarcinomasubclasses.ProceedingsoftheNationalAcademyofSciences,\n",
      "98(24):13790?13795,2001.[3]P.BradleyandO.Mangasarian.Featureselec-\n",
      "tionviaconcaveminimizationandsupportvectormachines.ICML,1998.[4]C.\n",
      "DingandH.Peng.Minimumredundancyfeatureselectionfrommicroarraygene\n",
      "expressiondata.ProceedingsoftheComputationalSystemsBioinformatics,\n",
      "2003.[5]C.Ding,D.Zhou,X.He,andH.Zha.R1-PCA:Rotationalinvariant\n",
      "L1-normprincipalcomponentanalysisforrobustsubspacefactorization.Proc.\n",
      "Int?lConf.MachineLearning(ICML),June2006.[6]S.P.Fodor.DNASE-\n",
      "QUENCING:MassivelyParallelGenomics.Science,277(5324):393?395,1997.\n",
      "12\n",
      "\n",
      "[7]I.GuyonandA.ElisseeAnintroductiontovariableandfeatureselection.\n",
      "J.MachineLearningResearch,2003.[8]I.Guyon,J.Weston,S.Barnhill,andV.\n",
      "Vapnik.Geneselectionforcancerusingsupportvectormachines.\n",
      "MachineLearning,46(1):389,2002.[9]M.A.HallandL.A.Smith.Feature\n",
      "selectionformachinelearning:Comparingacorrelation-basedapproach\n",
      "tothewrapper.1999.[10]H.HuangandC.Ding.Robusttensorfactorization\n",
      "usingr1norm.CVPR2008,pages1?8,2008.[11]K.KiraandL.A.Rendell.\n",
      "Apracticalapproachtofeatureselection.InAPracticalApproachtoFeature\n",
      "Selection,pages249?256,1992.[12]R.KohaviandG.H.John.Wrappersfor\n",
      "featuresubsetselection.Intelligence,97(1-2):273?324,1997.[13]I.\n",
      "Kononenko.Estimatingattributes:AnalysisandextensionsofRELIEF.InEu-\n",
      "ropeanConferenceonMachineLearning,pages171?182,1994.[14]P.Langley.\n",
      "Selectionofrelevantfeaturesinmachinelearning.InAAAIFallSymposiumon\n",
      "Relevance,pages140?144,1994.[15]H.LiuandH.Motoda.FeatureSelection\n",
      "forKnowledgeDiscoveryandDataMining.Springer,1998.[16]D.Luo,C.\n",
      "Ding,andH.Huang.Towardsstructuralsparsity:Anexplicit`2/`0approach.\n",
      "ICDM,2010.[17]C.L.Nutt,D.R.Mani,R.A.Betensky,P.Tamayo,J.\n",
      "G.Cairncross,C.Ladd,U.Pohl,C.Hartmann,andM.E.Mclaughlin.Gene\n",
      "expression-basedofmalignantgliomascorrelatesbetterwithsur-\n",
      "vivalthanhistologicalCancerRes.,63:1602?1607,2003.[18]G.\n",
      "Obozinski,B.Taskar,andM.Jordan.Multi-taskfeatureselection.Technical\n",
      "report,DepartmentofStatistics,UniversityofCalifornia,Berkeley,2006.[19]\n",
      "H.Peng,F.Long,andC.Ding.Featureselectionbasedonmutualinformation:\n",
      "Criteriaofmax-dependency,max-relevance,andmin-redundancy.IEEETrans.\n",
      "PatternAnalysisandMachineIntelligence,27,2005.[20]P.C.PetricoinEF,\n",
      "OrnsteinDK.Serumproteomicpatternsfordetectionofprostatecancer.JNatl\n",
      "CancerInst.,94(20):1576?8,2002.[21]L.E.RaileanuandK.Theoreti-\n",
      "calcomparisonbetweentheginiindexandinformationgaincriteria.Univeristy\n",
      "ofNeuchatel,2000.[22]Y.Saeys,I.Inza,andP.Larranaga.Areviewoffeature\n",
      "selectiontechniquesinbioinformatics.Bioinformatics,23(19):2507?2517,2007.\n",
      "[23]D.Singh,P.Febbo,K.Ross,andetal.Geneexpressioncorrelatesofclinical\n",
      "prostatecancerbehavior.CancerCell,pages203?209,2002.[24]A.I.Su,J.B.\n",
      "Welsh,L.M.Sapinoso,andetal.Molecularofhumancarcinomas\n",
      "byuseofgeneexpressionsignatures.CancerResearch,61:7388?7393,2001.[25]\n",
      "L.Sun,J.Liu,J.Chen,andJ.Ye.trecoveryofjointlysparsevectors.\n",
      "InNeuralInformationProcessingSystems,2009.[26]L.Wang,J.Zhu,andH.\n",
      "Zou.Hybridhuberizedsupportvectormachinesformicroarray\n",
      "ICML,2007.[27]K.Yang,Z.Cai,J.Li,andG.Lin.Astablegeneselectionin\n",
      "microarraydataanalysis.BMCBioinformatics,7:228,2006.[28]M.Yuanand\n",
      "Y.Lin.Modelselectionandestimationinregressionwithgroupedvariables.\n",
      "JournaloftheRoyalStatisticalSociety:SeriesB,68:49?67,2005.\n",
      "9\n",
      "13\n",
      "\n",
      "PP4177.pdf\n",
      "PP4177.pdf 15\n",
      "Multi-labelMultipleKernelLearningby\n",
      "StochasticApproximation:ApplicationtoVisual\n",
      "ObjectRecognition\n",
      "Authoredby:\n",
      "AnilK.Jain\n",
      "RongJin\n",
      "SerhatBucak\n",
      "Abstract\n",
      "Recentstudieshaveshownthatmultiplekernellearningisvery\n",
      "tiveforobjectrecognition,leadingtothepopularityofkernellearning\n",
      "incomputervisionproblems.Inthiswork,wedevelopantal-\n",
      "gorithmformulti-labelmultiplekernellearning(ML-MKL).Weassume\n",
      "thatalltheclassesunderconsiderationsharethesamecombinationof\n",
      "kernelfunctions,andtheobjectiveistotheoptimalkernelcombina-\n",
      "tionthatballtheclasses.Althoughseveralalgorithmshavebeen\n",
      "developedforML-MKL,theircomputationalcostislinearinthenumber\n",
      "ofclasses,makingthemunscalablewhenthenumberofclassesislarge,a\n",
      "challengefrequentlyencounteredinvisualobjectrecognition.Weaddress\n",
      "thiscomputationalchallengebydevelopingaframeworkforML-MKL\n",
      "thatcombinestheworst-caseanalysiswithstochasticapproximation.Our\n",
      "analysisshowsthatthecomplexityofouralgorithmis$O(m\n",
      "f\n",
      "1/3\n",
      "g\n",
      "sqrt\n",
      "f\n",
      "ln\n",
      "m\n",
      "g\n",
      ")$,where$m$isthenumberofclasses.Empiricalstudieswithobject\n",
      "recognitionshowthatwhileachievingsimilaraccuracy,the\n",
      "proposedmethodistlymoretthanthestate-of-the-art\n",
      "algorithmsforML-MKL.\n",
      "1PaperBody\n",
      "Recentstudieshaveshownpromisingperformanceofkernelmethodsforob-\n",
      "jectrecognitionandlocalization[1].Sincethechoiceofkernel\n",
      "functionscantlytheperformanceofkernelmethods,kernel\n",
      "learning,ormorespMultipleKernelLearning(MKL)[2,3,4,5,6,\n",
      "7],hasattractedconsiderableamountofinterestincomputervisioncommu-\n",
      "nity.Inthiswork,wefocussonkernellearningforobjectrecognitionbecause\n",
      "thevisualcontentofanimagecanberepresentedinmanyways,depending\n",
      "onthemethodsusedforkeypointdetection,descriptor/featureextraction,and\n",
      "1\n",
      "\n",
      "keypointquantization.Sinceeachrepresentationleadstoatsimilarity\n",
      "measurebetweenimages(i.e.,kernelfunction),therelatedfusionproblemcan\n",
      "becastintoaMKLproblem.Anumberofalgorithmshavebeendeveloped\n",
      "forMKL.In[2],MKLisformulatedasaquadraticallyconstraintquadratic\n",
      "program(QCQP).[8]suggestsanalgorithmbasedonsequentialminimization\n",
      "optimization(SMO)toimprovetheof[2].[9]showsthatMKLcanbe\n",
      "formulatedasalinearprogram(SILP)andcanbesolvediently\n",
      "byusingSVMimplementations.Inordertoimprovethescalability\n",
      "ofMKL,severalorderoptimizationmethodshavebeenproposed,includ-\n",
      "ingthesubgradientmethod[10],thelevelmethod[11],themethodbasedon\n",
      "equivalencebetweengrouplassoandMKL[12,13,14].BesidesL1-norm[15]\n",
      "andL2-norm[16],Lp-norm[17]hasalsobeenproposedtoregularizetheweights\n",
      "forkernelcombination.Otherthentheframeworkbasedonmaximummargin\n",
      "MKLcanalsobeformulatedbyusingkernelalignment[18]and\n",
      "Fisherdiscriminativeanalysisframeworks[19].1\n",
      "AlthoughmostinMKLfocusonbinaryproblems,sev-\n",
      "eralrecentstudieshaveattemptedtoextendMKLtomulti-classandmulti-label\n",
      "learning[3,20,21,22,23].Mostofthesestudiesassumethateitherthesame\n",
      "orsimilarkernelfunctionsareusedbytbutrelatedtasks.\n",
      "EventhoughstudiesshowthatMKLformulti-classandmulti-labellearningcan\n",
      "resultintimprovementinaccuracy,thecomputational\n",
      "costisoftenlinearinthenumberofclasses,makingitcomputationallyexpen-\n",
      "sivewhendealingwithalargenumberofclasses.Sincemostobjectrecognition\n",
      "problemsinvolvemanyobjectclasses,whosenumbermightgouptohundreds\n",
      "orsometimeseventothousands,itisimportanttodevelopantlearning\n",
      "algorithmformulti-classandmultilabelMKLthatissublinearinthenumber\n",
      "ofclasses.Inthiswork,wedevelopantalgorithmforMulti-LabelMKL\n",
      "(ML-MKL)thatassumesallthesharethesamecombinationofker-\n",
      "nels.Wenotethatalthoughthisassumptiontlyconstrainsthechoice\n",
      "ofkernelfunctionsfortclasses,ourempiricalstudieswithobjectrecog-\n",
      "nitionshowthatitdoesnottheperformance.Asimilar\n",
      "phenomenonwasalsoobservedin[21].AnaiveimplementationofML-MKL\n",
      "withsharedkernelcombinationwillleadtoacomputationalcostlinearinthe\n",
      "numberofclasses.Wealleviatethiscomputationalchallengebyexploringthe\n",
      "ideaofcombiningworstcaseanalysis?withstochasticapproximation.Ouranal-\n",
      "ysisrevealsthattheconvergencerateoftheproposedalgorithmisO(m1/3ln\n",
      "m),whichistlybetterthanalineardependenceonm,wheremisthe\n",
      "numberofclasses.OurempiricalstudiesshowthattheproposedMKLalgo-\n",
      "rithmyieldssimilarperformanceasthestate-of-the-artalgorithmsforML-MKL,\n",
      "butwithatlyshorterrunningtime,makingitsuitableformulti-label\n",
      "learningwithalargenumberofclasses.Therestofthispaperisorganizedas\n",
      "follows.Section2presentstheproposedalgorithmforMulti-LabelMKL,along\n",
      "withitsconvergenceanalysis.Section3summarizestheexperimentalresults\n",
      "forobjectrecognition.Section4concludesthiswork.\n",
      "2\n",
      "Multi-labelMultipleKernelLearning(ML-MKL)\n",
      "2\n",
      "\n",
      "WedenotebyD=\n",
      "f\n",
      "x1,...,xn\n",
      "g\n",
      "thecollectionofntraininginstances,\n",
      "andbymthenumberofclasses.Weintroduceyk=(y1k,...,ynk)>?\n",
      "f\n",
      "?1,\n",
      "+1\n",
      "g\n",
      "n,theassignmentofthekthclasstoallthetraininginstances:yik=+1\n",
      "ifxiisassignedtothek-thclassandyik=?1otherwise.Weintroduce?a(x,\n",
      "x0):Rd?Rd7?R,a=1,...,s,theskernelfunctionstobecombined.\n",
      "Wedenoteby\n",
      "f\n",
      "Ka?Rn?n,a=1,...,s\n",
      "g\n",
      "thecollectionofskernelmatrices\n",
      "forthedataapointsinD,i.e.,Ki,j=?a(xi,xj).PsWeintroducep=(p1\n",
      ",...,ps),aprobabilitydistribution,forcombiningkernels.Wedenoteby\n",
      "K(p)=a=1paKathecombinedkernelmatrices.WeintroducethedomainP\n",
      "fortheprobabilitydistributionp,i.e.,P=\n",
      "f\n",
      "p?Rs+:p>1=1\n",
      "g\n",
      ".Ourgoal\n",
      "istolearnfromthetrainingexamplestheoptimalkernelcombinationpforall\n",
      "themclasses.Thesimplestapproachformulti-labelmultiplekernellearning\n",
      "withsharedkernelcombinationistotheoptimalkernelcombinationpby\n",
      "minimizingthesumofregularizedlossfunctionsofallmclasses,leadingtothe\n",
      "followingoptimizationproblem:))(m(nmXXX\n",
      "1k2,(1)`yifk(xi)|fk|H(p)+minminHk=p?P\n",
      "f\n",
      "fk?H(p)\n",
      "g\n",
      "m2\n",
      "k=1i=1k=1\n",
      "k=1\n",
      "where`(z)=max(0,1?z)andH(p)isaReproducingKernelHilbertSpace\n",
      "endowedwithkernel?(x,x0;p)=Psa0a=1p?a(x,x).Hkistheregularized\n",
      "lossfunctionforthekthclass.Itisstraightforwardtoverifythefollowingdual\n",
      "problemof(1):()mX1kk>k>kk[?]1?(??y)K(p)(??y)minmax\n",
      "L(p,?)=,(2)p?P??Q12k=1\n",
      "whereQ1=?=(?1,...,?m):?k?[0,C]n,k=1,...,m.\n",
      "TosolvetheoptimizationprobleminEq.(2),wecanviewitasaminimization\n",
      "problem,i.e.,minp?PA(p),whereA(p)=max??Q1L(p,?).Wethenfollow\n",
      "thesubgradientdescentapproachin[10]andcomputethegradientofA(p)as\n",
      "m\n",
      "?piA(p)=?\n",
      "1Xk(?(p)?yk)>Ki(?k(p)?yk),2k=1\n",
      "2\n",
      "where?k(p)=argmax??[0,C]n[?k]>1?(?k?yk)>K(p)(?k?yk).\n",
      "WerefertothisapproachasMulti-labelMultipleKernelLearningbySum,or\n",
      "ML-MKL-Sum.Notethatthisapproachissimilartotheoneproposedin[21].\n",
      "ThemaincomputationalproblemwithML-MKL-Sumisthatbytreatingevery\n",
      "classequally,ineachiterationofsubgradientdescent,itrequiressolvingmkernel\n",
      "SVMs,makingitunscalabletoaverylargenumberofclasses.Belowwepresent\n",
      "aformulationformulti-labelMKLwhosecomputationalcostissublinearinthe\n",
      "numberofclasses.2.1\n",
      "AMinimaxFrameworkforMulti-labelMKL\n",
      "Inordertoalleviatethecomputationalyarisingfromalargenumber\n",
      "ofclasses,wesearchforthecombinedkernelmatrixK(p)thatminimizesthe\n",
      "worsterroramongmclasses,i.e.,min\n",
      "maxHk\n",
      "min\n",
      "(3)\n",
      "3\n",
      "\n",
      "p?P\n",
      "f\n",
      "fk?H(p)\n",
      "g\n",
      "m1?k?mk=1\n",
      "PmEq.(3)fromEq.(1)inPthatitreplacesk=1Hkwithmax1?k?m\n",
      "Hk.ThemaincomputationaladvantageofusingmaxkHkinsteadofkHkis\n",
      "thatbyusinganappropriatelydesignedmethod,wemaybeabletoout\n",
      "themostclassinafewiterations,andspendmostofthecomputational\n",
      "cyclesonlearningtheoptimalkernelcombinationforthemostclass.In\n",
      "thisway,weareabletoachievearunningtimethatissublinearinthenumber\n",
      "ofclasses.Below,wepresentanoptimizationstrategyforEq.(3)basedonthe\n",
      "ideaofstochasticapproximation.Adirectapproachistosolvetheoptimization\n",
      "probleminEq.(3)byitsdualform.Itisstraightforwardtoderivethedual\n",
      "problemofEq.(3)asfollows(moredetailscanbefoundinthesupplementary\n",
      "documents)\n",
      "minmaxp?P??B\n",
      "whereB=\n",
      "(\n",
      "???\n",
      "L(p,?)=\n",
      "1\n",
      "m\n",
      "(\n",
      "mX\n",
      "k=1\n",
      "k\n",
      "(?,...,?):??\n",
      "1[?k]>1?(?k?yk)>K(p)(?k?yk)2\n",
      "Rn+,k\n",
      "k\n",
      "n\n",
      "=1,...,m,??[0,C?k]s.t.\n",
      "?21)2?\n",
      "mX\n",
      "?\n",
      ".\n",
      "(4))\n",
      "?k=1.\n",
      "k=1\n",
      "ThechallengeinsolvingEq.(4)isthatthesolutions\n",
      "f\n",
      "?1,...,?m\n",
      "g\n",
      "indomainBarecorrelatedwitheachother,makingitimpossibletosolveeach\n",
      "?kindependentlybyanSVMsolver.Althoughagradientdescent\n",
      "approachcanbedevelopedforoptimizingEq.(4),itisunabletoexplorethe\n",
      "sparsestructurein?kmakingitlesstthanstate-of-the-artSVMsolvers.\n",
      "InordertoelyexplorethepowerofSVMsolvers,werewrite\n",
      "(3)asfollows(\n",
      ")mX1kk>kk>kk??1?(??y)K(p)(??y)minmaxL(p,?)=\n",
      "max,(5)??Q1p?P???2k=1\n",
      "4\n",
      "\n",
      ">where?=\n",
      "f\n",
      "(?1,...,?m)?Rm+:?1=1\n",
      "g\n",
      ".InEq.(5),wereplace\n",
      "max1?k?mwithmax???.TheadvantageofusingEq.(5)isthatwecanresort\n",
      "toaSVMsolvertotlynd?kforagivencombinationofkernelsK(p).\n",
      "GivenEq.(5),wedevelopasubgradientdescentapproachforsolvingthe\n",
      "optimizationproblem.Inparticular,ineachiterationofsubgradientdescent,\n",
      "wecomputethegradientL(p,?)withrespecttopand?asfollowsm\n",
      "?paL(p,?)=?\n",
      "1Xkk1?(??yk)>Ka(?k?yk),??kL(p,?)=[?k]>1?(?k?yk)>\n",
      "K(p)(?k?yk),22\n",
      "(6)\n",
      "k=1\n",
      "where?k=argmax??[0,C]n?>1?(??yk)>K(p)(??yk)/2,i.e.,aSVM\n",
      "solutiontothecombinedkernelK(p).?PsFollowingthemirrorproxdescent\n",
      "method[24],wepotentialfunctions?p=??pa=1palnpaforpandPm\n",
      "??=i=1?iln?ifor?,andhavethefollowingequationsforupdatingptand\n",
      "?tpat+1=\n",
      "?tkpatkexp(?????kL(pt,?t)),pexp(??p?paL(pt,?t)),?t+1=Zt\n",
      "Zt?3\n",
      "(7)\n",
      ">whereZtpandZt?arenormalizationfactorsthatensurep>t1=?t1=\n",
      "1.?p>0and??>0arethestepsizesforoptimizingpand?,respectively.\n",
      "Unfortunately,thealgorithmdescribedabovesharesthesameshortcom-\n",
      "ingastheotherapproachesformultiplelabelmultiplekernellearning,i.e.,it\n",
      "requiressolvingmSVMproblemsineachiteration,andthereforeitscomputa-\n",
      "tionalcomplexityislinearinthenumberofclasses.Toalleviatethisproblem,\n",
      "wemodifytheabovealgorithmbyintroducingthestochasticapproximation\n",
      "method.Inparticular,ineachiterationt,insteadofcomputingthefullgradi-\n",
      "entsthatrequirssolvingmSVMs,wesampleonetaskaccording\n",
      "tothemultinomialdistributionMulti(?t1,...,?tm).Letjtbetheindex\n",
      "ofthesampledtask.Usingthesampledtaskjt,weestimatethe\n",
      "gradientofL(p,?)withrespecttopaand?k,denotedbygbap(pt,?t)and\n",
      "gbk?(pt,?t),asfollows1(8)gbap(pt,?t)=?(?jt?yjt)>Ka(?jt?yjt),\n",
      "2\n",
      "0k6=jt.(9)gbk?(pt,?t)=11>kk>kk?1?(??y)K(p)(??y)\n",
      "k=jtk?k2\n",
      "Thecomputationofgbap(pt,?t)andgbi?(pt,?t)onlyrequires?jtand\n",
      "thereforeonlyneedstosolveoneSVMproblem,insteadofmSVMs.Thekey\n",
      "propertyoftheestimatedgradientsinEqs.(8)and(9)isthattheirexpectations\n",
      "equaltothetruegradients,assummarizedbyProposition1.Thispropertyis\n",
      "thekeytothecorrectnessofthisalgorithm.Proposition1.Wehavegi?(pt,\n",
      "?t)]=??iL(pt,?t),Et[bgap(pt,?t)]=?paL(pt,?t),Et[bwhereEt[?]\n",
      "standsfortheexpectationovertherandomlysampledtaskjt.\n",
      "Giventheestimatedgradients,wewillfollowEq.(7)forupdatingpand?\n",
      "ineachiteration.Sincegbi?(pt,?t)isproportionalto1/?t,toensurethe\n",
      "normofgbi?(pt,?t)tobebounded,weneedtosmooth?t+1.Inorderto\n",
      "havethe0smoothingwithoutmodifying?t+1,wewillsampledirectly\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from?t+1,?0kk????,??0??0,s.t.?t+1??t+1(1??)+,k=1,...\n",
      ",m,mwhere?>0isasmallprobabilitymassusedforsmoothingand\n",
      "??0=?0>1=1,?k0?,k=1,...,m.mWerefertothisalgorithm\n",
      "asMulti-labelMultipleKernelLearningbyStochasticApproximation,orML-\n",
      "MKLSAforshort.Algorithm1givesthedetaileddescription.2.2\n",
      "ConvergenceAnalysis\n",
      "SinceEq.(5)isaconvex-concaveoptimizationproblem,weintroducethe\n",
      "followingcitationformeasuringthequalityofasolution(p,?)?(p,?)=max\n",
      "L(p,?0)?minL(p0,?).(11)00???\n",
      "p?P\n",
      "Wedenoteby(p?,??)theoptimalsolutiontoEq.(5).Proposition2.\n",
      "Wehavethefollowingpropertiesfor?(p,?)1.?(p,?)?0foranysolutionp\n",
      "?Pand???2.?(p?,??)=03.?(p,?)isjointlyconvexinbothp\n",
      "and?WehavethefollowingtheoremfortheconvergencerateforAlgorithm1.\n",
      "Thedetailedproofcanbefoundinthesupplementarydocument.band?b\n",
      "Theorem1.AfterrunningAlgorithm1overTiterations,wehavethefollowing\n",
      "inequalityforthesolutionpobtainedbyAlgorithm1\n",
      "1m2b)]?E[?(bp,?(lnm+lns)+??d2?20n2C4+n2C2,\n",
      "??T2?wheredisaconstantterm,E[?]standsfortheexpectationoverthe\n",
      "sampledtaskindicesofalliterations,and?0=max?max(Ka),where?max\n",
      "(Z)standsforthemaximumeigenvalueofmatrixZ.1?a?s\n",
      "4\n",
      "Algorithm1Multi-labelMultipleKernelLearning:ML-MKL-SA1:Input?\n",
      "?p,??:stepsizes?K1,...,Ks:skernelmatrices?y1,...,ym\n",
      ":theassignmentsofmtclassestontraininginstances?T:number\n",
      "ofiterations??:smoothingparameter2:Initialization??1=1/mandp1=\n",
      "1/s3:fort=1,...,Tdo4:Sampleataskjtaccordingtothe\n",
      "distributionMulti(?t1,...,?tm).5:Compute?jt=argmax??[0,C]n?>1\n",
      "?(??yjt)>K(p)(??yjt)/2usinganshelfSVMsolver.6:Computethe\n",
      "estimatedgradientsgbap(pt,?t)andgbi?(pt,?t)usingEq.(8)and(9).0\n",
      "7:Updatept+1,?t+1and?t+1asfollowspat+1\n",
      "=\n",
      "k\n",
      "=\n",
      "[?t+1]\n",
      "patexp(???gbap(pt,?t)),a=1,...,s.Ztp?tk?0exp(??gbk?(pt,\n",
      "?t)),k=1,...,m;?t+1=(1??)?t+1+1.Zt?m\n",
      "8:endforband?bas9:Computethesolutionp\n",
      "?b=\n",
      "T1X?t,Tt=1\n",
      "b=p\n",
      "T1Xpt.Tt=1\n",
      "(10)\n",
      "21pCorollary1.With?=m3and??=n1m?3(lnm)/T,afterrunning\n",
      "Algorithm1(ontheoriginalpaper)overTpiterations,wehaveE[?(bp,?b)]\n",
      "?O(nm1/3(lnm)/T)intermsofm,nandT.\n",
      "6\n",
      "\n",
      "SinceweonlyneedtosolveonekernelpSVMateachiteration,wehavethe\n",
      "computationalcomplexityfortheproposedalgorithmontheorderofO(m1/3\n",
      "(lnm)/T),sublinearinthenumberofclassesm.\n",
      "3\n",
      "Experiments\n",
      "Inthissection,weempiricallyevaluatetheproposedmultiplekernellearning\n",
      "algorithm2bydemonstratingitsandenessonthevisualobject\n",
      "recognitiontask.3.1\n",
      "Datasets\n",
      "Weusethreebenchmarkdatasetsforvisualobjectrecognition:Caltech-101,\n",
      "PascalVOC2006andPascalVOC2007.Caltech-101contains101derent\n",
      "objectclassesinadditiontoa?background?class.Weusethesamesettingsas\n",
      "[25]inwhich30instancesofeachclassareusedfortrainingand15instances\n",
      "fortesting.PascalVOC2006dataset[26]consistsof5,303imagesdistributed\n",
      "over10classes,ofwhich2,618areusedfortraining.PascalVOC2007[27]\n",
      "consistsof5,011trainingimagesand4,932testimagesthataredistributed\n",
      "over20classes.Forbothdatasets,weusedthedefaulttrain-testpartition\n",
      "providedbyVOCChallenge.UnlikeCaltech-101dataset,whereeachimage\n",
      "isassignedtooneclass,imagesinVOCdatasetscanbeassignedtomultiple\n",
      "classessimultaneously,makingitmoresuitableformulti-labellearning.2\n",
      "Codescanbedownloadedfromhttp://www.cse.msu.edu/?bucakser/ML-\n",
      "MKL-SA.rar\n",
      "5\n",
      "Table1:Clasaccuracy(AUC)andrunningtimes(second)ofall\n",
      "ML-MKLalgorithmsonthreedatasets.AbbreviationsSA,GMKL,Sum,Sim-\n",
      "ple,VSKL,AVGstandforML-MKL-SA,GeneralizedMKL,ML-MKL-Sum,\n",
      "SimpleMKL,variablesparsitykernellearningandaveragekernel,respectively\n",
      "SA0.800.750.50\n",
      "GMKL0.790.750.49\n",
      "Accuracy(AUC)SumSimple0.800.780.740.740.470.42\n",
      "VSKL0.770.740.46\n",
      "AVG0.770.720.45\n",
      "SA191.17245.101329.40\n",
      "1\n",
      "1\n",
      "1\n",
      "0.8\n",
      "0.8\n",
      "0.40.20\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "time(sec)\n",
      "ML-MKL-SA\n",
      "7\n",
      "\n",
      "kernelcoients\n",
      "0.6\n",
      "TrainingTime(sec)SumSimple1814.509869.40890.6511549.001372.60\n",
      "18536.37\n",
      "0.8\n",
      "0.8\n",
      "kernelcoients\n",
      "kernelcoients\n",
      "1\n",
      "GMKL18292.002586.9030333.14\n",
      "0.60.40.20\n",
      "0\n",
      "0.5\n",
      "1\n",
      "time(sec)\n",
      "1.5\n",
      "0.60.40.20\n",
      "2\n",
      "kernelcoients\n",
      "datasetCALTECH-101VOC2006VOC2007\n",
      "0\n",
      "500\n",
      "1000\n",
      "time(sec)\n",
      "4\n",
      "x10\n",
      "GMKL\n",
      "ML-MKL-Sum\n",
      "1500\n",
      "VSKL21266.057368.2711370.48\n",
      "AVGN/AN/AN/A\n",
      "0.60.40.20\n",
      "0\n",
      "0.5\n",
      "1\n",
      "time(sec)\n",
      "1.5\n",
      "24\n",
      "x10\n",
      "VSKL\n",
      "Figure1:TheevolutionofkernelweightsovertimeforCALTECH-101data\n",
      "set.ForGMKLandVSKL,thecurvesdisplaythekernelweightsthatare\n",
      "averagedoveralltheclassessinceatkernelcombinationislearntfor\n",
      "eachclass.3.2\n",
      "Kernels\n",
      "8\n",
      "\n",
      "Weextracted9kernelsforCaltech-101datasetbyusingthesoftwarepro-\n",
      "videdin[28].Threetfeatureextractionmethodsareusedforkernel\n",
      "construction:(i)GB:geometricblurdescriptorsareappliedtothedetected\n",
      "keypoints[29];RBFkernelisusedinwhichthedistancebetweentwoimages\n",
      "iscomputedbyaveragingthedistanceofthenearestdescriptorpairsforthe\n",
      "imagepair.(ii)PHOWgray/color:keypointsbasedondensesampling;SIFT\n",
      "descriptorsarequantizedto300wordsandspatialhistogramswith2x2and\n",
      "4x4subdivisionsarebuilttogeneratechi-squaredkernels[30].(iii)SSIM:self-\n",
      "similarityfeaturestakenfrom[31]areusedandspatialhistogramsbasedon\n",
      "300visualwordsareusedtoformthechi-squaredkernel.ForVOCdatasets,\n",
      "atprocedure,basedonthereportsofVOCchallenges[1],isusedto\n",
      "constructmultiplevisualdictionaries,andeachdictionaryresultsinat\n",
      "kernel.Toobtainmultiplevisualdictionaries,wedeploy(i)threekeypointde-\n",
      "tectors,i.e.,densesampling,HARHES[32]andHESLAP[33],(ii)twokeypoint\n",
      "descriptors,i.e.,SIFT[33]andSPIN[34]),(iii)twodierentnumbersofvisual\n",
      "words,i.e.,500and1,000visualwords,(iv)twodierentkernelfunctions,i.e.,\n",
      "linearkernelandchi-squaredkernel.Thebandwidthofthechi-squaredkernelsis\n",
      "calculatedusingtheprocedurein[25].Usingtheabovevariantsinvisualdictio-\n",
      "naryconstruction,weconstructed22kernelsforbothVOC2007andVOC2006\n",
      "datasets.InadditiontotheK-meansimplementationin[28],wealsoapplieda\n",
      "hierarchicalclusteringalgorithm[35]todescriptorquantizationforVOC2007\n",
      "dataset,leadingtofourmorekernelsforVOC2007dataset.3.3\n",
      "BaselineMethods\n",
      "WecomparetheproposedalgorithmML-MKL-SAtothefollowingMKL\n",
      "algorithmsthatlearnatkernelcombinationforeachclass:(i)Gener-\n",
      "alizedmultiplekernellearningmethod(GMKL)[25],whichreportspromising\n",
      "resultsforobjectrecognition,(ii)SimpleMKL[10],whichlearnsthekernelcom-\n",
      "binationbyasubgradientapproachand(iii)VariableSparsityKernelLearning\n",
      "(VSKL),amiror-proxdescentbasedalgorithmforMKL[36].Wealsocompare\n",
      "ML-MKL-SAtoML-MKL-Sum,whichlearnsakernelcombinationsharedby\n",
      "allclassesasdescribedinSection2usingtheoptimizationmethodin[21].In\n",
      "allimplementationsofMLmultiplekernellearningalgorithms,weuseLIBSVM\n",
      "implementationofone-versus-allSVMwhereneeded.3.4\n",
      "ExperimentalResults\n",
      "Toevaluatethetivenessoftalgorithmsformulti-labelmultiple\n",
      "kernellearning,wecomputetheareaunderprecision-recallcurve(AUC)\n",
      "foreachclass,andreportthevalueofAUCaveragedoveralltheclasses.We6\n",
      "0.8\n",
      "0.50.750.48\n",
      "0.740.73\n",
      "AUC\n",
      "0.76\n",
      "AUC\n",
      "AUC\n",
      "0.78\n",
      "0.72\n",
      "9\n",
      "\n",
      "0.740.72500\n",
      "1000time(sec)\n",
      "1500\n",
      "0.44\n",
      "0.71\n",
      "ML?MKL?SAML?MKL?SUM\n",
      "0\n",
      "0.42\n",
      "ML?MKL?SAML?MKL?SUM\n",
      "0.7\n",
      "2000\n",
      "0.46\n",
      "0\n",
      "200\n",
      "CALTECH-101\n",
      "400600time(sec)\n",
      "800\n",
      "ML?MKL?SAML?MKL?SUM200\n",
      "1000\n",
      "VOC-2006\n",
      "400\n",
      "600800time(sec)\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "VOC-2007\n",
      "Figure2:TheevolutionofaccuracyovertimeforML-MKL-SA\n",
      "andML-MKL-Sumonthreedatasets0.81\n",
      "0.84?=0.01?=0.001?=0.0001\n",
      "0.8050.82\n",
      "AUC\n",
      "AUC\n",
      "0.80.795\n",
      "0.8\n",
      "0.79?=0?=0.2?=0.6?=1\n",
      "0.7850.780.775\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "numberofiterations\n",
      "300\n",
      "350\n",
      "0.78\n",
      "0.76\n",
      "10\n",
      "\n",
      "400\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "numberofiterations\n",
      "Figure3:accuracy(AUC)oftheproposedalgorithmMl-MKL-\n",
      "SAonCALTECH-101usingtvaluesof?(for?p=??=0.01).\n",
      "Figure4:accuracy(AUC)oftheproposedalgorithmMl-MKL-\n",
      "SAonCALTECH-101usingtvaluesof?p=??=?for(?=0).\n",
      "evaluatetheofalgorithmsbytheirrunningtimesfortraining.All\n",
      "methodsarecodedinMATLABandareimplementedonmachineswith2dual-\n",
      "coreAMDOpteronsrunningat2.2GHz,8GBRAMandlinuxoperatingsystem.\n",
      "pt?1Fortheproposedmethod,itarationsstopwhenpt?bissmallerthan0.01.\n",
      "Unlessstated,thesmoothingparameterbtp?issettobe0.2.Forsimplicity\n",
      "wetake?=?p=??inallthefollowingexperiments.Stepsize?ischosen\n",
      "as0.0001forCALTECH-101datasetand0.001forVOCdatasetsinorderto\n",
      "achievethebestcomputational.b\n",
      "Table1summarizesthecaccuracies(AUC)andtherunning\n",
      "timesofallthealgorithmsoverthethreedatasets.Wenotethatthepro-\n",
      "posedMKLmethodformulti-labeleddata,i.e.,ML-MKL-SA,yieldsthebest\n",
      "performanceamongthemethodsincomparison,whichtheassumption\n",
      "ofusingthesamekernelcombinationforalltheclasses.Notethatasimple\n",
      "approachthatusestheaverageofallkernelsyieldsreasonableperformance,\n",
      "althoughitsaccuracyistlyworsethantheproposedap-\n",
      "proachML-MKL-SA.Second,weobservethatexceptfortheaveragekernel\n",
      "methodthatdoesnotrequirelearningthekernelcombinationweights,MLMKL-\n",
      "SAandML-MKL-Sumaretlymoretthantheotherbaseline\n",
      "approaches.ThisisnotsurprisingasML-MKL-SAandML-MKL-Sumcompute\n",
      "asinglekernelcombinationforallclasses.Third,comparedtoMLMKL-Sum,\n",
      "weobservethatML-MKL-SAisoverallmorecient,andtlymore\n",
      "tforCALTECH101dataset.Thisisbecausethenumberofclassesin\n",
      "CALTECH-101istlylargerthanthatofthetwoVOCchallengedata\n",
      "sets.Thisresultfurtherthattheproposedalgorithmisscalabletothe\n",
      "datasetswithalargenumberofclasses.Fig.1showsthechangeintheker-\n",
      "nelweightsovertimefortheproposedmethodandthethreebaselinemethods\n",
      "(i.e.,ML-MKL-Sum,GMKL,andVSKL)onCALTECH-101dataset.Weob-\n",
      "servethat,overall,ML-MKL-SAsharesasimilarpatternasGMKLandVSKL\n",
      "intheevolutioncurvesofkernelweights,butistentimesfasterthanthetwo\n",
      "baselinemethods.AlthoughML-MKL-Sumistlymoretthan\n",
      "GMKLandVSKL,thekernelweightslearnedbyML-MKL-Sumvary\n",
      "cantly,particularlyatthebeginningofthelearningprocess,makingitaless\n",
      "stablealgorithmthantheproposedalgorithmML-MKL-SA.Tofurthercompare\n",
      "ML-MKL-SAwithML-MKL-Sum,inFig.2,weshowhowtheac-\n",
      "11\n",
      "\n",
      "curacyischangedovertimeforbothmethodsforallthreedatasets.Weagain\n",
      "observetheunstablebehaviorofML-MKL-Sum:theclasaccuracyof\n",
      "ML-MKL-Sumcouldvarysigntlyoverarelativelyshortperiodoftime,\n",
      "makingitlessdesirablemethodforMKL.7\n",
      "Toevaluatethesensitivityoftheproposedmethodtoparameters?and?,we\n",
      "conductedexperimentswithvariedvaluesforthetwoparameters.Fig.3shows\n",
      "howtheaccuracy(AUC)oftheproposedalgorithmchangesover\n",
      "iterationsonCALTECH-101usingfourtvaluesof?.Weobservethatthe\n",
      "accuracyiscomparablefortvaluesof?,demonstrating\n",
      "therobustnessoftheproposedmethodtothechoiceof?.Wealsonotethat\n",
      "thetwoextremecases,i.e,?=0and?=1,givetheworstperformance,\n",
      "indicatingtheimportanceofchoosinganoptimalvaluefor?.Fig.4showsthe\n",
      "accuracyforthreetvaluesof?onCALTECH101dataset.\n",
      "Weobservethattheproposedalgorithmachievessimilaraccuracy\n",
      "when?issettobearelativelysmallvalue(i.e.,?=0.001and?=0.0001).\n",
      "Thisresultdemonstratesthattheproposedalgorithmisingeneralinsensitive\n",
      "tothechoiceofstepsize(?).\n",
      "4\n",
      "ConclusionandFutureWork\n",
      "Inthispaper,wepresentanetoptimizationframeworkformulti-label\n",
      "multiplekernellearningthatcombinesworst-caseanalysiswithstochasticap-\n",
      "proximation.ComparedtotheotheralgorithmsforML-MKL,thekeyadvan-\n",
      "tageoftheproposedalgorithmisthatitscomputationalcostissublinearinthe\n",
      "numberofclasses,makingitsuitableforhandlingalargenumberofclasses.\n",
      "Weverifytheenessoftheproposedalgorithmbyexperimentsinobject\n",
      "recognitiononseveralbenchmarkdatasets.Therearetwodirectionsthatwe\n",
      "plantoexploreinthefuture.First,weaimtofurtherimprovetheof\n",
      "ML-MKLbyreducingitsdependenceonthenumberoftrainingexamplesand\n",
      "speedinguptheconvergencerate.Second,weplantoimprovetheeness\n",
      "andofmulti-labellearningbyexploringthecorrelationandstructure\n",
      "amongtheclasses.\n",
      "5\n",
      "Acknowledgements\n",
      "ThisworkwassupportedinpartbyNationalScienceFoundation(IIS-\n",
      "0643494),USArmyResearch(AROAwardW911NF-08-010403)andOceof\n",
      "NavalResearch(ONRN00014-09-1-0663).Anyopinions,andconclu-\n",
      "sionsorrecommendationsexpressedinthismaterialarethoseoftheauthorsand\n",
      "donotnecessarilytheviewsofNFS,ARO,andONR.PartofAnilJain?s\n",
      "researchwassupportedbyWCU(WorldClassUniversity)programthroughthe\n",
      "NationalResearchFoundationofKoreafundedbytheMinistryofEducation,\n",
      "ScienceandTechnology(R31-2008-000-10008-0).\n",
      "12\n",
      "\n",
      "2References\n",
      "[1]M.Everingham,L.VanGool,C.K.I.Williams,J.Winn,andA.Zisser-\n",
      "man,?ThePASCALVisualObjectClassesChallenge2009(VOC2009)Results.?\n",
      "http://www.pascal-network.org/challenges/VOC/voc2009/workshop/index.html.\n",
      "[2]G.Lanckriet,T.DeBie,N.Cristianini,M.Jordan,andW.Noble,?Astatisti-\n",
      "calframeworkforgenomicdatafusion,?Bioinformatics,vol.20,pp.2626?2635,\n",
      "2004.[3]S.Ji,L.Sun,R.Jin,andJ.Ye,?Multi-labelmultiplekernellearn-\n",
      "ing,?inProceedingsofNeuralInformationProcessingsSystems,2008.[4]G.\n",
      "Lanckriet,N.Cristianini,P.Bartlett,L.Ghaoui,andM.Jordan,?Learningthe\n",
      "kernelmatrixwithprogramming,?JournalofMachineLearning\n",
      "Research,vol.5,pp.27?72,2004.[5]O.ChapelleandA.Rakotomamonjy,\n",
      "?Secondorderoptimizationofkernelparameters,?inNIPSWorkshoponKer-\n",
      "nelLearning:AutomaticSelectionofOptimalKernels,2008.[6]P.Gehlerand\n",
      "S.Nowozin,?Onfeaturecombinationformulticlassobjectin\n",
      "ProceedingsoftheIEEEInternationalConferenceonComputerVision,2009.\n",
      "[7]P.GehlerandS.Nowozin,?Letthekernelitout:Principledlearningof\n",
      "pre-processingforkernelinProceedingsoftheIEEEConferenceon\n",
      "ComputerVisionandPatternRecognition,2009.[8]F.Bach,G.Lanckriet,and\n",
      "M.Jordan,?Multiplekernellearning,conicduality,andthesmoalgorithm,?in\n",
      "Proceedingsofthe21stInternationalConferenceonMachineLearning,2004.\n",
      "[9]S.Sonnenburg,G.Ratsch,andC.Schafer,?Ageneralandetmultiple\n",
      "kernellearningalgorithm,?inProceedingsofNeuralInformationProcessings\n",
      "Systems,pp.1273?1280,2006.[10]A.Rakotomamonjy,F.Bach,Y.Grand-\n",
      "valet,andS.Canu,?SimpleMKL,?JournalofMachineLearningResearch,vol.\n",
      "9,pp.2491?2521,2008.\n",
      "8\n",
      "[11]Z.Xu,R.Jin,I.King,andM.R.Lyu,?Anextendedlevelmethodfor\n",
      "tmultiplekernellearning,?inProceedingsofNeuralInformationPro-\n",
      "cessingsSystems,pp.1825?1832,2008.[12]Z.Xu,R.Jin,H.Yang,I.King,and\n",
      "M.R.Lyu,?Simpleandtmultiplekernellearningbygrouplasso,?inPro-\n",
      "ceedingsofthe27thInternationalConferenceonMachineLearning,2010.[13]\n",
      "F.Bach,?Consistencyofthegrouplassoandmultiplekernellearning,?Journal\n",
      "ofMachineLearningResearch,vol.9,pp.1179?1225,2008.[14]Z.Xu,R.Jin,\n",
      "S.Zhu,M.R.Lyu,andI.King,?Smoothoptimizationforemultipleker-\n",
      "nellearning,?inProceedingsoftheAAAIConferenceonIntelligence,\n",
      "2010.[15]A.Rakotomamonjy,F.Bach,S.Canu,andY.Grandvalet,?More\n",
      "inmultiplekernellearning,?inProceedingsofthe24thInternational\n",
      "ConferenceonMachineLearning,2007.[16]M.Kloft,U.Brefeld,A.Sonnen-\n",
      "burg,andA.Zien,?Comparingsparseandnon-sparsemultiplekernellearning,?\n",
      "inNIPSWorkshoponUnderstandingMultipleKernelLearningMethods,2009.\n",
      "[17]M.Kloft,U.Brefeld,A.Sonnenburg,P.Laskov,K.-R.Muller,andA.\n",
      "Zien,tandaccuratelp-normmultiplekernellearning,?inProceedings\n",
      "ofNeuralInformationProcessingsSystems,2009.[18]S.Hoi,M.Lyu,andE.\n",
      "Chang,?LearningthekernelmachinesforinProceedings\n",
      "oftheConferenceonKnowledgeDiscoveryandDataMining,p.187196,2006.\n",
      "13\n",
      "\n",
      "[19]J.Ye,J.Chen,andJ.S.,?Discriminantkernelandregularizationparame-\n",
      "terlearningviaprogramming,?inProceedingsoftheInternational\n",
      "ConferenceonMachineLearning,p.10951102,2007.[20]A.ZienandS.Cheng,\n",
      "?Multiclassmultiplekernellearning,?inProceedingsofthe24thInternational\n",
      "ConferenceonMachineLearning,2007.[21]L.Tang,J.Chen,andJ.Ye,?On\n",
      "multiplekernellearningwithmultiplelabels,?inProceedingsofthe21stIn-\n",
      "ternationalJontConferenceonIntelligence,2009.[22]J.Yang,Y.Li,\n",
      "Y.Tian,L.Duan,andW.Gao,?Group-sensitivemultiplekernellearningfor\n",
      "objectcategorization,?inProceedingsoftheIEEEInternationalConferenceon\n",
      "ComputerVision,2009.[23]F.Orabona,L.Jie,andB.Caputo,?Online-batch\n",
      "stronglyconvexmultikernellearning,?inProceedingsoftheIEEEConference\n",
      "onComputerVisionandPatternRecognition,2010.[24]A.Nemirovski,?Prox-\n",
      "methodwithrateofconvergenceo(1/t)forvariationalinequalitieswithlips-\n",
      "chitzcontinuousmonotoneoperatorsandsmoothconvex-concavesaddlepoint\n",
      "problems,?SIAMJournalonOptimization,vol.15,pp.229?251,2004.[25]M.\n",
      "VarmaandD.Ray,?Learningthediscriminativepower-invariancetradein\n",
      "ProceedingsoftheIEEEInternationalConferenceonComputerVision,October\n",
      "2007.[26]M.Everingham,A.Zisserman,C.K.I.Williams,andL.VanGool,\n",
      "?ThePASCALVisualObjectClassesChallenge2006(VOC2006)Results.?\n",
      "http://www.pascal-network.org/challenges/VOC/voc2006/results.pdf.[27]M.\n",
      "Everingham,L.VanGool,C.K.I.Williams,J.Winn,andA.Zisserman,\n",
      "?ThePASCALVisualObjectClassesChallenge2007(VOC2007)Results.?\n",
      "http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html.\n",
      "[28]A.VedaldiandB.Fulkerson,?VLFeat:Anopenandportablelibraryof\n",
      "computervisionalgorithms.?http://www.vlfeat.org/,2008.[29]A.Berg,T.\n",
      "Berg,andJ.Malik,?Shapematchingandobjectrecognitionusinglowdistortion\n",
      "correspondences,?inProceedingsoftheIEEEConferenceonComputerVision\n",
      "andPatternRecognition,2005.[30]S.Lazebnik,C.Schmid,andP.Ponce,?Be-\n",
      "yondbagoffeatures:Spatialpyramidmatchingforrecognizingnaturalscene\n",
      "categories,?inProceedingsoftheIEEEConferenceonComputerVisionand\n",
      "PatternRecognition,2006.[31]E.ShechtmanandI.M.,?Matchinglocalself-\n",
      "similaritiesacrossimagesandvideos,?inProceedingsoftheIEEEConference\n",
      "onComputerVisionandPatternRecognition,2007.[32]K.Mikolajczykand\n",
      "C.Schmid,?Distinctiveimagefeaturesfromscale-invariantkeypoints,?IEEE\n",
      "TransactionsonPatternAnalysisandMachineIntelligence,vol.27,no.10,\n",
      "pp.1615?1630,2005.[33]D.Lowe,?Distinctiveimagefeaturesfromscale-\n",
      "invariantkeypoints,?InternationalJournalofComputerVision,vol.2,no.\n",
      "60,pp.91?110,2004.[34]S.Lazebnik,C.Schmid,andP.Ponce,?Sparse\n",
      "texturerepresentationusingvariantneighborhoods,?inProceedingsof\n",
      "theIEEEConferenceonComputerVisionandPatternRecognition,2003.[35]\n",
      "M.MujaandD.G.Lowe,?Fastapproximatenearestneighborswithautomatic\n",
      "algorithminProceedingsoftheInternationalConferenceon\n",
      "ComputerVisionTheoryandApplication,pp.331?340,INSTICCPress,2009.\n",
      "[36]J.SakethaNath,G.Dinesh,S.Raman,C.Bhattacharyya,A.Ben-Tal,and\n",
      "K.Ramakrishan,?Onthealgorithmicsandapplicationsofamixed-normbased\n",
      "kernellearningformulation,?inProceedingsofNeuralInformationProcessings\n",
      "14\n",
      "\n",
      "Systems,2009.\n",
      "9\n",
      "15\n",
      "\n",
      "PP5043.pdf\n",
      "PP5043.pdf 13\n",
      "AnalyzingHogwildParallelGaussianGibbs\n",
      "Sampling\n",
      "Authoredby:\n",
      "AlanWillsky\n",
      "MatthewJohnson\n",
      "JamesSaunderson\n",
      "Abstract\n",
      "Samplinginferencemethodsarecomputationallytoscalefor\n",
      "manymodelsinpartbecauseglobaldependenciescanreduceopportu-\n",
      "nitiesforparallelcomputation.Withoutstrictconditionalindependence\n",
      "structureamongvariables,standardGibbssamplingtheoryrequiressam-\n",
      "pleupdatestobeperformedsequentially,evenifdependencebetween\n",
      "mostvariablesisnotstrong.Empiricalworkhasshownthatsomemodels\n",
      "canbesampledelybygoingHogwild\"andsimplyrunningGibbs\n",
      "updatesinparallelwithonlyperiodicglobalcommunication,butthesuc-\n",
      "cessesandlimitationsofsuchastrategyarenotwellunderstood.Asa\n",
      "steptowardssuchanunderstanding,westudytheHogwildGibbssam-\n",
      "plingstrategyinthecontextofGaussiandistributions.Wedevelopa\n",
      "frameworkwhichprovidesconvergenceconditionsanderrorboundsalong\n",
      "withsimpleproofsandconnectionstomethodsinnumericallinearal-\n",
      "gebra.Inparticular,weshowthatiftheGaussianprecisionmatrixis\n",
      "generalizeddiagonallydominant,thenanyHogwildGibbssampler,with\n",
      "anyupdatescheduleorallocationofvariablestoprocessors,yieldsastable\n",
      "samplingprocesswiththecorrectsamplemean.\"\n",
      "1PaperBody\n",
      "Scalingprobabilisticinferencealgorithmstolargedatasetsandparallelcom-\n",
      "putingarchitecturesisachallengeofgreatimportanceandconsiderablecurrent\n",
      "researchinterest,andgreatstrideshavebeenmadeindesigningparallelizeable\n",
      "algorithms.Alongwiththepowerfulandsometimescomplexnewalgorithms,\n",
      "averysimplestrategyhasproventobesurprisinglysuccessfulinsomesitua-\n",
      "tions:runningGibbssamplingupdates,derivedonlyforthesequentialsetting,\n",
      "inparallelwithoutgloballysynchronizingthesamplerstateaftereachupdate.\n",
      "Concretely,thestrategyistoapplyanalgorithmlikeAlgorithm1.Werefer\n",
      "tothisstrategyas?HogwildGibbssampling?inreferencetorecentwork[1]\n",
      "inwhichsequentialcomputationsforcomputinggradientstepswereapplied\n",
      "1\n",
      "\n",
      "inparallel(withoutglobalcoordination)togreatbThisHog-\n",
      "wildGibbssamplingstrategyhaslongbeenconsideredausefulhack,perhaps\n",
      "forpreparingdecentinitialstatesforaproperserialGibbssampler,butex-\n",
      "tensiveempiricalworkonApproximateDistributedLatentDirichletAllocation\n",
      "(AD-LDA)[2,3,4,5,6],whichappliesthestrategytogeneratesamplesfrom\n",
      "acollapsedLDAmodel,hasdemonstrateditsenessinsamplingLDA\n",
      "modelswiththesamepredictiveperformanceasthosegeneratedbystandard\n",
      "serialGibbs[2,Figure3].However,theresultsarelargelyempiricalandsoitis\n",
      "tounderstandhowmodelpropertiesandalgorithmparametersmight\n",
      "performance,orwhethersimilarsuccesscanbeexpectedforanyother\n",
      "models.Therehavebeenrecentadvancesinunderstandingsomeofthepartic-\n",
      "ularstructureofAD-LDA[6],butathoroughtheoreticalexplanationforthe\n",
      "enessandlimitationsofHogwildGibbssamplingisfarfromcomplete.\n",
      "SamplinginferencealgorithmsforcomplexBayesianmodelshavenotoriously\n",
      "resistedtheoreticalanalysis,sotobeginananalysisofHogwildGibbssampling\n",
      "weconsiderarestrictedclassofmodelsthatisespeciallytractableforanalysis:\n",
      "Gaussians.Gaussiandistributionsandalgorithmsaretractablebecauseoftheir\n",
      "deepconnectionwithlinearalgebra.Further,Gaussiansamplingisof1\n",
      "Algorithm1HogwildGibbsSamplingRequire:SamplersGi(?x?i)which\n",
      "samplep(xi|x?i=x??i),apartition\n",
      "f\n",
      "I1,I2,...,IK\n",
      "g\n",
      "of\n",
      "f\n",
      "1,2,...,n\n",
      "g\n",
      ",\n",
      "andaninneriterationscheduleq(k,`)?01:Initializex?(1)2:for`=1,2,.\n",
      "..untilconvergencedo.globaliterations/synchronizations3:fork=1,2,..\n",
      ".,Kinparalleldo.foreachofKparallelprocessors(1)`4:y?Ik?x?Ik5:\n",
      "forj=1,2,...,q(k,`)do.runlocalGibbsstepswithold6:fori?Ikdo.\n",
      "statisticsfromotherprocessors(j)(`)(j)(`)7:y?i?Gi(?xI1,...,y?Ik\n",
      "f\n",
      "i\n",
      "g\n",
      ",...,x?IK)8:\n",
      "(q(1,`))\n",
      "x?(`+1)?(?yI1\n",
      "(q(K,`))\n",
      "???y?IK\n",
      ")\n",
      ".globallysynchronizestatistics\n",
      "greatinterestinitsownright,andthereisactiveresearchindevelopingpow-\n",
      "erfulGaussiansamplers[7,8,9,10].GaussianHogwildGibbssamplingcould\n",
      "beusedinconjunctionwiththosemethodstoallowgreaterparallelizationand\n",
      "scalability,givenanunderstandingofitsapplicabilityandToward\n",
      "thegoalofunderstandingGaussianHogwildGibbssampling,themaincontri-\n",
      "butionofthispaperisalinearalgebraicframeworkforanalyzingthestability\n",
      "anderrorsinGaussianHogwildGibbssampling.Ourframeworkyieldssev-\n",
      "eralresults,includingasimpleproofforatconditionforallGaussian\n",
      "HogwildGibbssamplingprocessestobestableandyieldthecorrectasymp-\n",
      "toticmeannomattertheallocationofvariablestoprocessorsornumberof\n",
      "sub-iterations(Proposition1,Theorem1),aswellasananalysisoferrorsin-\n",
      "troducedintheprocessvariance.Codetoregenerateourplotsisavailableat\n",
      "https://github.com/mattjj/gaussian-hogwild-gibbs.\n",
      "2\n",
      "2\n",
      "\n",
      "RelatedWork\n",
      "TherehasbeentworkonconstructingparallelGibbssampling\n",
      "algorithms,andthecontributionsaretoonumeroustolisthere.Onerecent\n",
      "bodyofwork[11]providesexactparallelGibbssamplerswhichexploitgraphical\n",
      "modelstructureforparallelism.Thealgorithmsaresupportedbythestandard\n",
      "Gibbssamplinganalysis,andtheauthorspointoutthatwhileheuristicparallel\n",
      "samplerssuchastheAD-LDAsamplereasierimplementationandoften\n",
      "greaterparallelism,theyarecurrentlynotsupportedbymuchtheoreticalanal-\n",
      "ysis.TheparallelsamplingworkthatismostrelevanttotheproposedHogwild\n",
      "GibbssamplinganalysisisthethoroughempiricaldemonstrationofAD-LDA\n",
      "[2,3,4,5,6]anditsextensions.TheAD-LDAsamplingalgorithmisanin-\n",
      "stanceofthestrategywehavenamedHogwildGibbs,andBekkermanetal.\n",
      "[5,Chapter11]suggestsapplyingthestrategytootherlatentvariablemodels.\n",
      "TheworkofIhleretal.[6]providessomeunderstandingoftheenessof\n",
      "avariantofAD-LDAbyboundingintermsofrun-timequantitiestheone-step\n",
      "errorprobabilityinducedbyproceedingwithsamplingstepsinparallel,thereby\n",
      "allowinganAD-LDAusertoinspectthecomputederrorboundafterinference\n",
      "[6,Section4.2].Inexperiments,theauthorsempiricallydemonstrateverysmall\n",
      "upperboundsontheseone-steperrorprobabilities,e.g.avalueoftheirparame-\n",
      "ter?=10?4meaningthatatleast99.99%ofsamplesareexpectedtobedrawn\n",
      "justasiftheyweresampledsequentially.However,thisper-sampleerrordoes\n",
      "notnecessarilyprovideadirectunderstandingoftheeenessoftheoverall\n",
      "algorithmbecauseerrorsmightaccumulateoversamplingsteps;indeed,under-\n",
      "standingthispotentialerroraccumulationisofcriticalimportanceiniterative\n",
      "systems.Furthermore,theboundisintermsofempiricalrun-timequantities,\n",
      "andthusitdoesnotprovideguidanceregardingonwhichothermodelsthe\n",
      "Hogwildstrategymaybee.Ihleretal.[6,Section4.3]alsoprovides\n",
      "approximatescalinganalysisbyestimatingtheorderoftheone-stepboundin\n",
      "termsofaGaussianapproximationandsomedistributionalassumptions.Fi-\n",
      "nally,Niuetal.[1]providesbothamotivationforHogwildGibbssamplingas\n",
      "wellastheHogwildname.Theauthorspresent?alock-freeapproachtopar-\n",
      "allelizingstochasticgradientdescent?(SGD)byprovidinganalysisthatshows,\n",
      "forcertaincommonproblemstructures,thatthelocking2\n",
      "andsynchronizationneededtorunastochasticgradientdescentalgorithm\n",
      "?correctly?onamulticorearchitectureareunnecessary,andinfactthero-\n",
      "bustnessoftheSGDalgorithmcompensatesfortheuncertaintyintroducedby\n",
      "allowingprocessorstoperformupdateswithoutlockingtheirsharedmemory.\n",
      "3\n",
      "Background\n",
      "InthissectionwenotationforGaussiandistributionsanddescribeknown\n",
      "connectionsbetweenGaussiansamplingandaclassofstationaryiterativelinear\n",
      "systemsolverswhichareusefulinanalyzingthebehaviorofHogwildGibbs\n",
      "sampling.ThedensityofaGaussiandistributiononnvariableswithmean\n",
      "vector?andpositivecovariancematrix?0hastheformno\n",
      "Tp(x)?exp?12(x??)??1(x??)?exp?21xTJx+hTx\n",
      "(1)wherewehavewrittentheinformationparametersJ:=??1andh:=J?.\n",
      "3\n",
      "\n",
      "ThematrixJisoftencalledtheprecisionmatrixorinformationmatrix,andit\n",
      "hasanaturalinterpretationinthecontextofGaussiangraphicalmodels:its\n",
      "entriesarethecontsonpairwiselogpotentialsanditssparsitypatternis\n",
      "exactlythesparsitypatternofagraphicalmodel.Similarlyh,alsocalledthe\n",
      "potentialvector,encodesnodepotentialsandevidence.Inmanyproblems[12]\n",
      "onehasaccesstothepair(J,h)andmustcomputeorestimatethemoment\n",
      "parameters?and?(orjustthediagonal)orgeneratesamplesfromN(?,?).\n",
      "Samplingprovidesbothameansforestimatingthemomentparametersand\n",
      "asubroutineforotheralgorithms.Computing?from(J,h)isequivalentto\n",
      "solvingthelinearsystemJ?=hfor?.Onewaytogeneratesamplesisvia\n",
      "Gibbssampling,inwhichoneiteratessamplingeachxiconditionedonallother\n",
      "variablestoconstructaMarkovchainforwhichtheinvariantdistributionisthe\n",
      "targetN(?,?).TheconditionaldistributionsforGibbssamplingstepsarep(xi\n",
      "|x?i=x??i)?\n",
      "??i)+viexp?21Jiix2i+(hi?Ji?ix??i)xi.Thatis,weupdateeach\n",
      "xiviaxi?J1ii(hi?Ji?ixiid\n",
      "wherevi?N(0,J1ii).\n",
      "Sinceeachvariableupdateisalinearfunctionofothervariableswithadded\n",
      "Gaussiannoise,wecancollectonescanfori=1,2,...,nintoamatrix\n",
      "equationrelatingthesamplerstateattandt+1:iid\n",
      "1\n",
      "x(t+1)=?D?1Lx(t+1)?D?1LTx(t)+D?1h+D?2v?(t),v?(t)?N\n",
      "(0,I).wherewehavesplitJ=L+D+LTintoitsstrictlylower-triangular,\n",
      "diagonal,andstrictlyuppertriangularparts,respectively.Notethatx(t+1)\n",
      "appearsonbothsidesoftheequation,andthatthesparsitypatternsofLand\n",
      "LTensurethateachentryofx(t+1)dependsontheappropriateentriesofx(t)\n",
      "andx(t+1).Wecanre-arrangetheequationintoanupdateexpression:?1\n",
      "x(t+1)=?(D+L)\n",
      "?1\n",
      "LTx(t)+(D+L)\n",
      "?1(t)\n",
      "iid\n",
      "v?,v?(t)?N(0,D).\n",
      "h+(D+L)\n",
      "TheexpectationofthisupdateisexactlytheGauss-Seideliterativelinear\n",
      "systemsolverupdate[13,?1?1Section7.3]appliedtoJ?=h,i.e.x(t+1)=\n",
      "?(D+L)LTx(t)+(D+L)h.ThereforeaGaussianGibbssamplingpro-\n",
      "cesscanbeinterpretedasGauss-SeideliteratesonthesystemJ?=hwith\n",
      "appropriately-shapednoiseinjectedateachiteration.Gauss-Seidelisonein-\n",
      "stanceofastationaryiterativelinearsolverbasedonamatrixsplitting.In\n",
      "general,onecanconstructastationaryiterativelinearsolverforanysplitting\n",
      "J=M?NwhereMisinvertible,andsimilarlyonecanconstructiterative\n",
      "Gaussiansamplersviaiid\n",
      "x(t+1)=(M?1N)x(t)+M?1h+M?1v(t),v(t)?N(0,MT+N)\n",
      "(2)\n",
      "4\n",
      "\n",
      "withtheconstraintthatMT+N0(i.e.thatthesplittingisP-regular[14]).\n",
      "Foraniterativeprocesslike(2)tobestableorconvergentforanyinitialization\n",
      "werequiretheeigenvaluesofits1\n",
      "Assumemodelsarenon-degenerate:matrixparametersareoffullrankand\n",
      "densitiesareeverywhere.\n",
      "3\n",
      "updatemaptolieintheinteriorofthecomplexunitdisk,i.e.?(M?1N):=\n",
      "maxi|?i(M?1N)|<1[13,Lemma7.3.6].TheGauss-Seidelsolver(andGibbs\n",
      "sampling)correspondtochoosingMtobethelower-triangularpartofJandN\n",
      "tobethenegativeofthestrictupper-triangleofJ.J0isatconditionfor\n",
      "Gauss-Seideltobeconvergent[13,Theorem7.5.41][15],andtheconnectionto\n",
      "Gibbssamplingprovidesanindependentproof.Forsolvinglinearsystemswith\n",
      "splitting-basedalgorithms,thecomplexityofsolvinglinearsystemsinMdirectly\n",
      "thecomputationalcostperiteration.FortheGauss-Seidelsplitting\n",
      "(andhenceGibbssampling),Mischosentobelower-triangularsothatthe\n",
      "correspondinglinearsystemcanbesolvedtlyviabacksubstitution.Inthe\n",
      "samplingcontext,theper-iterationcomputationalcomplexityisalsodetermined\n",
      "bythecovarianceoftheinjectednoiseprocessv(t),becauseateachiteration\n",
      "onemustsamplefromaGaussiandistributionwithcovarianceMT+N.We\n",
      "highlightoneotherstandardstationaryiterativelinearsolverthatisrelevant\n",
      "toanalyzingGaussianHogwildGibbssampling:Jacobiiterations,inwhichone\n",
      "splitsJ=D?AwhereDisthediagonalpartofJandAisthenegativeofthe\n",
      "part.DuetothechoiceofadiagonalM,eachcoordinateupdate\n",
      "dependsonlyontheprevioussweep?soutput,andthustheJacobiupdatesweep\n",
      "canbeperformedinparallel.AtconditionfortheconvergenceofJacobi\n",
      "iteratesisforJtobeageneralizeddiagonallydominantmatrix(i.e.anH-\n",
      "matrix)[13,5.13].Asimpleproof2duetoRuozzietal.[16],isto\n",
      "considerGauss-Seideliterationsonalifted2n?2nsystem:\n",
      "0D?1AD?AG-SupdateD?100A(3)???????=2.?AD00D?1AD?1\n",
      "D?10(D?1A)ThereforeoneiterationofGauss-Seidelontheliftedsystemis\n",
      "exactlytwoapplicationsoftheJacobiupdateD?1Atothesecondhalfofthe\n",
      "statevector,soJacobiiterationsconvergeifGauss-Seidelontheliftedsystem\n",
      "converges.Furthermore,atconditionforGauss-Seideltoconvergeon\n",
      "theliftedsystemisforittobepositiveandbytakingSchur\n",
      "complementswe1111requireD?AD?1A0orI?(D?2AD?2)(D?2\n",
      "AD?2)0,whichisequivalenttorequiringgeneralizeddiagonaldominance[13,\n",
      "Theorem5.14].\n",
      "4\n",
      "GaussianHogwildAnalysis\n",
      "GiventhatGibbssamplingiterationsandJacobisolveriterations,whichcan\n",
      "becomputedinparallel,caneachbewrittenasiterationsofastochasticlinear\n",
      "dynamicalsystem(LDS),itisnotsurprisingthatGaussianHogwildGibbssam-\n",
      "plingcanalsobeexpressedasanLDSbyappropriatelycomposingtheseideas.\n",
      "InthissectionwedescribetheLDScorrespondingtoGaussianHogwildGibbs\n",
      "samplingandprovideconvergenceanderroranalysis,alongwithaconnection\n",
      "toaclassoflinearsolvers.Forthemajorityofthissection,weassumethat\n",
      "5\n",
      "\n",
      "thenumberofinneriterationsperformedoneachprocessorisconstantacross\n",
      "timeandprocessorindex;thatis,wehaveasinglenumberq=q(k,`)ofsub-\n",
      "iterationsperprocessorforeachouteriteration.Wedescribehowtorelaxthe\n",
      "assumptionattheendofthissubsection.GivenajointGaussiandistribution\n",
      "ofdimensionnrepresentedbyapair(J,h)asin(1),werepresentanallocation\n",
      "ofthenscalarvariablestolocalprocessorsbyapartitionof\n",
      "f\n",
      "1,2,...,\n",
      "n\n",
      "g\n",
      ",whereweassumepartitionelementsarecontiguouswithoutlossofgener-\n",
      "ality.Considerablock-JacobisplittingofJintoitsblockdiagonalandblock\n",
      "components,J=Dblock?A,accordingtothepartition.Ain-\n",
      "cludesthecross-processorpotentials,andthisblock-Jacobisplittingwillmodel\n",
      "theouteriterationsinAlgorithm1.WefurtherperformaGauss-Seidelsplitting\n",
      "onDblockinto(block-diagonal)lower-triangularandstrictlyupper-triangular\n",
      "parts,Dblock=B?C;theseprocessor-localGauss-Seidelsplittingsmodelthe\n",
      "innerGibbssamplingstepsinAlgorithm1.WerefertothissplittingJ=B?C\n",
      "?AastheHogwildsplitting;seeFigure1aforanexample.Foreachouteriter-\n",
      "ationoftheHogwildGibbssamplerweperformqprocessor-localGibbssteps,\n",
      "elyapplyingtheblock-diagonalupdateB?1CrepeatedlyusingAx(t)+\n",
      "hasapotential2WhenJissymmetriconecanarriveatthesameconditionby\n",
      "applyingasimilaritytransformasinProposition5.Weusetheliftingargument\n",
      "herebecauseweextendtheideainourotherproofs.\n",
      "4\n",
      "vectorthatincludesout-of-datestatisticsfromtheotherprocessors.The\n",
      "resultingupdateoperatorforoneouteriterationoftheHogwildGibbssampling\n",
      "processcanbewrittenasq?1\n",
      "Xq(t)jiid(t+1)?1x=(BC)x+(B?1C)B?1Ax(t)+h+v(t,j),v\n",
      "(t,j)?N(0,D)(4)j=0\n",
      "whereDisthediagonalofJ.Notethatweshapethenoisediagonallybecause\n",
      "inHogwildGibbssamplingwesimplyapplystandardGibbsupdatesintheinner\n",
      "loop.Asmentionedpreviously,theupdatein(4)iswrittensothatthenumber\n",
      "ofsub-iterationsishomogeneous,buttheexpressioncaneasilybeadaptedto\n",
      "modelanynumbersofsub-iterationsbywritingaseparatesumoverjforeach\n",
      "blockrowoftheoutputandaseparatematrixpowerforeachblockinthe\n",
      "B?1Cterm.Theproofsandargumentsinthefollowingsubsectionscanalso\n",
      "beextendedwithextrabookkeeping,sowefocusonthehomogeneousqcase\n",
      "forconvenience.4.1\n",
      "ConvergenceandCorrectnessofMeans\n",
      "BecausetheGaussianHogwildGibbssamplingiteratesformaGaussian\n",
      "lineardynamicalsystem,theprocessisstable(i.e.itsiteratesconvergeindis-\n",
      "tribution)ifandonlyif[13,Lemma7.3.6]thedeterministicpartoftheupdate\n",
      "map(4)hasspectralradiuslessthanunity,i.e.q\n",
      "T:=(B?1C)+\n",
      "q?1Xj=0\n",
      "j\n",
      "q\n",
      "q\n",
      "?1\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(B?1C)B?1A=(B?1C)+(I?(B?1C))(B?C)\n",
      "A\n",
      "(5)\n",
      "qq?(T)<1.WecanwriteT=Tind+(I?Tind)Tblockwhere\n",
      "TindisthepurelyGaussSeidelupdatewhenA=0andTblockfortheblock\n",
      "Jacobiupdate,whichcorrespondstosolvingtheprocessor-locallinearsystems\n",
      "exactlyateachouteriteration.Theupdate(5)fallsintotheclassoftwo-stage\n",
      "splittingmethods[14,17,18],andthenextpropositionisequivalenttosuch\n",
      "two-stagesolvershavingthecorrectpoint.Proposition1.IfaGaussian\n",
      "HogwildGibbsprocessisstable,theasymptoticmeaniscorrect.\n",
      "Proof.Iftheprocessisstablethemeanprocesshasauniquepoint,\n",
      "andfrom(4)and(5)wecanwritethexed-pointequationfortheprocessmean\n",
      "?hogas(I?T)?hog=(I?Tind)(I?Tblock)?hog=(I?Tind)(B?C)?1h,hence\n",
      "(I?(B?C)?1A)?hog=(B?C)?1hand?hog=(B?C?A)?1h.Thebehaviorof\n",
      "thespectralradiusoftheupdatemapcanbeverycomplicated,evengenerically\n",
      "oversimpleensembles.InFigure1b,wecompare?(T)forq=1andq=?\n",
      "(correspondingtoT=Tblock)withmodelssampledfromanaturalrandom\n",
      "ensemble;weseethatthereisnogeneralrelationshipbetweenstabilityatq\n",
      "=1andatq=?.Despitethecomplexityoftheupdatemap?sstability,in\n",
      "thenextsubsectionwegiveasimpleargumentthatidenitsconvergence\n",
      "withtheconvergenceofGauss-Seideliteratesonalarger,non-symmetriclinear\n",
      "system.GiventhatrelationshipwethenproveaconditionontheentriesofJ\n",
      "thatensurestheconvergenceoftheGaussianHogwildGibbssamplingprocess\n",
      "foranychoiceofpartitionorsub-iterationcount.4.1.1\n",
      "Aliftingargumentandtcondition\n",
      "FirstobservethatwecanwritemultiplestepsofGauss-Seidelasasingle\n",
      "stepofGauss-Seidelonalargersystem:givenJ=L?UwhereLislower-\n",
      "triangular(includingthediagonal,unlikethenotationofSection3)andUis\n",
      "strictlyupper-triangular,considerapplyingGauss-Seideltoalargerblockk?\n",
      "ksystem:????!L?1L?U\n",
      "?1?\n",
      "?UL......?U\n",
      "L\n",
      "G-S?????\n",
      "L?1UL?1...\n",
      "(L?1U)\n",
      "k?1\n",
      "L?1\n",
      "L?1???\n",
      "L\n",
      "U\n",
      "..\n",
      ".L?1UL?1L?1\n",
      "?\n",
      "=\n",
      "U\n",
      "7\n",
      "\n",
      "...\n",
      "(6)\n",
      "(L?1U)k\n",
      "ThereforeonestepofGauss-Seidelonthelargersystemcorrespondstok\n",
      "applicationsoftheGaussSeidelupdateL?1Ufromtheoriginalsystemtothe\n",
      "lastblockelementoftheliftedstatevector.Nowweprovidealiftingonwhich\n",
      "Gauss-SeidelcorrespondstoGaussianHogwildGibbsiterations.5\n",
      "1.2\n",
      "?(T),q=?\n",
      "1.11.0\n",
      "A\n",
      "B\n",
      "0.9\n",
      "C\n",
      "0.8\n",
      "(a)Supportpattern(inblack)oftheHogwildsplittingJ=B?C?Awith\n",
      "n=9andtheprocessorpartition\n",
      "ff\n",
      "1,2,3\n",
      "g\n",
      ",\n",
      "f\n",
      "4,5,6\n",
      "g\n",
      ",\n",
      "f\n",
      "7,8,9\n",
      "gg\n",
      "0.8\n",
      "0.9\n",
      "1.0\n",
      "1.1\n",
      "1.2\n",
      "?(T),q=1\n",
      "(b)?(T)forq=1versusforq=?A=0\n",
      "A=0\n",
      "?(B?1C)q=0.670\n",
      "0.0010\n",
      "ck-diagonalerror\n",
      "blockdiagonalerror\n",
      "0.0012\n",
      "?(B?1C)q=0.448?(B?1C)q=0.300\n",
      "0.0008\n",
      "?(B?1C)q=0.201\n",
      "0.00060.00040.00020.00000.00\n",
      "0.05\n",
      "0.10\n",
      "0.15\n",
      "?(B?1C)q=0.670\n",
      "0.015\n",
      "?(B?1C)q=0.448?(B?1C)q=0.300?(B?1C)q=0.201\n",
      "0.010\n",
      "0.005\n",
      "0.0000.00\n",
      "0.20\n",
      "t\n",
      "0.05\n",
      "8\n",
      "\n",
      "0.10\n",
      "0.15\n",
      "0.20\n",
      "t\n",
      "(c)?projectstotheblockdiagonal\n",
      "(d)?projectstotheck-diagonal\n",
      "Figure1:(a)visualizationoftheHogwildsplitting;(b)Hogwildstabilityfor\n",
      "genericmodels;(c)and(d)typicalplotsof||?(???hog)||Fro.In(b)\n",
      "eachpointcorrespondstoasampledmodeliid\n",
      "iid\n",
      "J=QQT+nrIwithQij?N(0,1),r?Uniform[0.5,1],n=24withan\n",
      "evenpartitionofsize4.In(c)and(d),modelsareJ=B?C?tAwhereB\n",
      "?C?A=QQT,n=150withanevenpartitionofsize3.Theplotscanbe\n",
      "generatedwithpythony-seed=0.\n",
      "Proposition2.TwoapplicationsoftheHogwildupdateTof(5)areequiv-\n",
      "alenttotheupdatetothelastblockelementofthestatevectorinoneGauss-\n",
      "Seideliterationonthe(2qn)?(2qn)system!!\n",
      "hBA+C?CBAE?F.F=.(7)x?=..withE=......?FE...h\n",
      "?CB\n",
      "A\n",
      "Proof.Bycomparingtotheblockupdatein(3),itsucestoconsiderE\n",
      "?1F.Furthermore,sincetheclaimconcernsthelastblockentry,weneedonly\n",
      "considerthelastblockrowofE?1F.Eisblocklower-bidiagonalasthematrix\n",
      "thatisinvertedin(6),soE?1hasthesamelower-triangularformasin(6)\n",
      "andtheproductofthelastblockrowofE?1withthelastblockcolumnofF\n",
      "yieldsPq?1qj(B?1C)+j=0(B?1C)B?1A=T.Proposition3.Gaus-\n",
      "sianHogwildGibbssamplingisconvergentifGauss-Seidelconvergeson(7).\n",
      "Unfortunatelytheliftingisnotsymmetricandsowecannotimposepositive\n",
      "ontheliftedsystem;however,anothertconditionfor\n",
      "Gauss-Seidelstabilitycanbeapplied:Theorem1.IfJisgeneralizeddiagonally\n",
      "dominant(i.e.anH-matrix,seeBermanetal.[13,5.13,Theorem\n",
      "5.14])thenHogwildGibbssamplingisconvergentforanyvariablepartitionand\n",
      "anynumberofsub-iterations.Proof.IfJisgeneralizeddiagonallydominant\n",
      "thenthereexistsadiagonalscalingmatrixRsuchPethatJe:=JRisrow\n",
      "diagonallydominant,i.e.Jeii?j6=i|Jij|.Sinceeachscalarrowofthe\n",
      "cotmatrixin(7)containsonlyentriesfromonerowofJandzeros,itis\n",
      "generalizeddiagonallydominantwithascalingmatrixthatconsistsof2qcopies\n",
      "ofRalongthediagonal.Finally,Gauss-Seideliterationsongeneralizeddiago-\n",
      "nallydominantsystemsareconvergent[13,Theorem5.14],sobyProposition3\n",
      "thecorrespondingHogwildGibbsiterationsareconvergent.6\n",
      "IntermsofGaussiangraphicalmodels,generalizeddiagonallydominant\n",
      "modelsincludetreemodelsandlatenttreemodels(sinceH-matricesareclosed\n",
      "underSchurcomplements),inwhichthedensityofthedistributioncanbe\n",
      "writtenasatree-structuredsetofpairwisepotentialsoverthemodelvariables\n",
      "andasetoflatentvariables.Latenttreemodelsareusefulinmodelingdata\n",
      "withhierarchicalormulti-scaledrelationships,andthisconnectiontolatent\n",
      "9\n",
      "\n",
      "treestructureisevocativeofmanyhierarchicalBayesianmodels.Morebroadly,\n",
      "diagonallydominantsystemsarewell-knownfortheirtractabilityandapplica-\n",
      "bilityinmanyothersettings[19],andGaussianHogwildGibbsprovidesanother\n",
      "exampleoftheirutility.Becauseoftheconnectiontolinearsystemsolversbased\n",
      "ontwo-stagemultisplittings,thisresultcanbeidenwith[18,Theorem2.3],\n",
      "whichshowsthatifthecoetmatrixisanH-matrixthenthetwo-stageit-\n",
      "erativesolverisconvergent.Indeed,bytheconnectionbetweensolversand\n",
      "samplersonecanproveourTheorem1asacorollaryto[18,Theorem2.3](or\n",
      "vice-versa),thoughourprooftechniqueismuchsimpler.Theotherresultson\n",
      "two-stagemultisplittings[18,14],canalsobeappliedimmediatelyforresults\n",
      "ontheconvergenceofGaussianHogwildGibbssampling.Thetcondi-\n",
      "tionprovidedbyTheorem1iscoarseinthatitprovidesconvergenceforany\n",
      "partitionorupdateschedule.However,giventhecomplexityoftheprocesses,\n",
      "asexhibitedinFigure1b,itistoprovidegeneralconditionswithout\n",
      "takingintoaccountsomemodelstructure.4.1.2\n",
      "Exactlocalblocksamples\n",
      "Convergenceanalysisgreatlyinthecasewhereexactblocksamples\n",
      "aredrawnateachprocessorbecauseqistlylargeorbecauseanother\n",
      "exactsampler[9,10]isusedoneachprocessor.ThisregimeofHogwildGibbs\n",
      "samplingisparticularlyinterestingbecauseitminimizescommunicationbe-\n",
      "tweenprocessors.In(4),weseethatasq??wehaveT?Tblock;thatis,the\n",
      "deterministicpartoftheupdatebecomestheblockJacobiupdatemap,which\n",
      "admitsanaturaltconditionforconvergence:1\n",
      "1\n",
      "Proposition4.If((B?C)?2A(B?C)?2)2?I,thenblockHogwild\n",
      "Gibbssamplingconverges.11Proof.Sincesimilaritytransformationspreserve\n",
      "eigenvalues,withA?:=(B?C)?2A(B?C)?211?andsinceA?issymmetric\n",
      "wehave?(Tblock)=?((B?C)2(B?C)?1A(B?C)?2)=?(A)2??A?I\n",
      "??(A)<1??(Tblock)<1.\n",
      "4.2\n",
      "Variances\n",
      "SincewecananalyzeGaussianHogwildGibbssamplingasalineardynamical\n",
      "system,wecanwriteanexpressionforthesteady-statecovariance?hogofthe\n",
      "processwhenitisstable.ForageneralstableLDSoftheformx(t+1)=T\n",
      "x(t)+v(t)withv(t)?N(0,?inj)thesteady-statecovarianceP?isgivenby\n",
      "theseriest=0Tt?injTtT,whichisthesolutiontothelineardiscrete-time\n",
      "Lyapunovequation??T?TT=?injin?.Theinjectednoisefortheouter\n",
      "loopoftheHogwilditerationsisgeneratedbytheinnerloop,whichitselfhas\n",
      "injectednoisewithcovarianceD,thediagonalofJ,soforHogwildsamplingwe\n",
      "havePq?1?inj=j=0(B?1C)jB?1DB?T(B?1C)jT.Thetargetcovariance\n",
      "isJ?1=(B?C?A)?1.ComposingtheseexpressionsweseethattheHogwild\n",
      "covarianceiscomplicated,butwecananalyzesomesalientpropertiesinat\n",
      "leasttworegimes:whenAissmallandwhenlocalprocessorsdrawexactblock\n",
      "samples(e.g.whenq??).4.2.1\n",
      "First-orderinA\n",
      "Intuitively,theHogwildstrategyworksbestwhencross-processorinterac-\n",
      "10\n",
      "\n",
      "tionsaresmall,andsoitisnaturaltoanalyzethecasewhenAissmallandwe\n",
      "candiscardtermsthatincludepowersofAbeyondorder.WhenA=0,\n",
      "themodelisindependentacrossprocessorsandboththeexactcovarianceand\n",
      "theHogwildsteady-statecovarianceforanyqis(B?C)?1.Forsmallnonzero\n",
      "A,weconsider?hog(A)7\n",
      "tobeafunctionofAandlinearizearoundA=0towrite?hog(A)?(B?\n",
      "C)?1+[D0?hog](A),wherethederivative[D0?hog](A)isamatrixdetermined\n",
      "bythelinearequatione?SASeT?(I?S)A(Ie?S)T[D0?hog](A)?S[D0\n",
      "?hog](A)ST=A\n",
      "e:=(B?C)?1A(B?C)?1andS:=(B?1C)q.Seethesupplementary\n",
      "materials.WewhereAcancomparethislinearapproximationtothelinear\n",
      "approximationfortheexactcovariance:eJ?1=[I+(B?C)?1A+((B?\n",
      "C)?1A)2+???](B?C)?1?(B?C)?1+A.(8)ehaszeroblock-diagonal\n",
      "andSisblock-diagonal,weseethattoorderAhasnoonSinceA\n",
      "theblock-diagonalofeithertheexactcovarianceortheHogwildcovariance.As\n",
      "showninFigure1c,innumericalexperimentshigher-ordertermsimprovethe\n",
      "HogwildcovarianceontheblockdiagonalrelativetotheA=0approximation,\n",
      "andtheimprovementsincreasewithlocalmixingrates.Theck-diagonal\n",
      "termintheHogwildcovarianceisnonzeroanditdependsonthe\n",
      "localmixingperformedbyS.Inparticular,ifglobalsynchronizationhappens\n",
      "infrequentlyrelativetothespeedoflocalsamplermixing(e.g.ifqislarge),S?\n",
      "0andD0?hog?0,so?hog?(B?C)?1(tostorderinA)andcross-processor\n",
      "interactionsareignored(thoughtheyarestillusedtocomputethecorrectmean,\n",
      "asperProposition1).However,whentherearedirectionsinewhichSisslow\n",
      "tomix,D0?hogpicksupsomepartsofthecorrectcovariance?s\n",
      "term,A.Figure1dshowstheck-diagonalerrorincreasingwithfaster\n",
      "localmixingforsmallA.Intuitively,morelocalmixing,andhencerelatively\n",
      "lessfrequentglobalsynchronization,degradestheHogwildapproximationofthe\n",
      "cross-processorcovariances.Suchanctmaybeundesirablebecauseincreased\n",
      "localmixinggreaterparallelism(oranapplicationofmorepowerfullocal\n",
      "samplers[9,10]).Inthenextsubsectionweshowthatthiscaseadmitsaspecial\n",
      "analysisandevenaninexpensivecorrectiontorecoverasymptoticallyunbiased\n",
      "estimatesforthefullcovariancematrix.4.2.2\n",
      "Exactlocalblocksamples\n",
      "Aslocalmixingincreases,e.g.asq??orifweuseanexactblocklocal\n",
      "samplerbetweenglobalsynchronizations,wearetivelysamplinginthelifted\n",
      "modelofEq.(3)andthereforewecanusetheliftingconstructiontoanalyze\n",
      "theerrorinvariances:Proposition5.Whenlocalblocksamplesareexact,\n",
      "theHogwildsampledcovariance?Hog?=(I+(B?C)?1A)?Hog\n",
      "and||???Hog||?||(B?C)?1A||||?Hog||where?=\n",
      "J?1istheexacttargetcovarianceand||?||isanysubmultiplicative\n",
      "matrixnorm.Proof.Usingtheliftingin(3),theHogwildprocesssteady-state\n",
      "covarianceisthemarginalcovarianceofhalfoftheliftedstatevector,sousing\n",
      "Schurcomplementswecanwrite?Hog=((B?C)?A(B?C)?1A)?1=[I\n",
      "+((B?C)?1A)2+???](B?C)?1.Wecancomparethisseriestotheexact\n",
      "expansionin(8)toseethat?Hogincludesexactlytheevenpowers(duetothe\n",
      "11\n",
      "\n",
      "block-bipartitelifting),sotherefore???Hog=[(B?C)?1A+((B?C)?1A)3+?\n",
      "??](B?C)?1=(B?C)?1A?Hog.\n",
      "5\n",
      "Conclusion\n",
      "WehaveintroducedaframeworkforunderstandingGaussianHogwildGibbs\n",
      "samplingandshownsomeresultsonthestabilityanderrorsofthealgorithm,\n",
      "including(1)quantitativedescriptionsforwhenaGaussianmodelisnot?too\n",
      "dependent?tocauseHogwildsamplingtobeunstable(Proposition2,Theorem\n",
      "1,Proposition4);(2)givenstability,theasymptoticHogwildmeanisalways\n",
      "correct(Proposition1);(3)inthelinearizedregimewithsmallcross-processor\n",
      "interactions,thereisatradebetweenlocalmixinganderrorinHogwildcross-\n",
      "processorcovariances(Section4.2.1);and(4)whenlocalsamplersarerunto\n",
      "convergencewecanboundtheerrorintheHogwildvariancesandevently\n",
      "correctestimatesofthefullcovariance(Proposition5).Wehopetheseideas\n",
      "maybeextendedtoprovidefurtherinsightintoHogwildGibbssampling,inthe\n",
      "Gaussiancaseandbeyond.\n",
      "6\n",
      "Acknowledgements\n",
      "ThisresearchwassupportedinpartunderAFOSRGrantFA9550-12-1-0287.\n",
      "8\n",
      "2References\n",
      "[1][2]\n",
      "[3][4]\n",
      "[5][6]\n",
      "[7][8][9][10]\n",
      "[11]\n",
      "[12][13][14]\n",
      "[15]\n",
      "[16]\n",
      "[17][18][19]\n",
      "F.Niu,B.Recht,C.R?,andS.J.Wright.?Hogwild!:Alock-freeapproach\n",
      "toparallelizingstochasticgradientdescent?.In:AdvancesinNeuralInforma-\n",
      "tionProcessingSystems(2011).D.Newman,A.Asuncion,P.Smyth,andM.\n",
      "Welling.?Distributedinferenceforlatentdirichletallocation?.In:Advances\n",
      "inNeuralInformationProcessingSystems20.1081-1088(2007),pp.17?24.D.\n",
      "Newman,A.Asuncion,P.Smyth,andM.Welling.?Distributedalgorithmsfor\n",
      "topicmodels?.In:TheJournalofMachineLearningResearch10(2009),pp.\n",
      "1801?1828.Z.Liu,Y.Zhang,E.Y.Chang,andM.Sun.?PLDA+:Parallel\n",
      "latentdirichletallocationwithdataplacementandpipelineprocessing?.In:\n",
      "ACMTransactionsonIntelligentSystemsandTechnology(TIST)2.3(2011),\n",
      "p.26.R.Bekkerman,M.Bilenko,andJ.Langford.Scalingupmachine\n",
      "learning:Parallelanddistributedapproaches.CambridgeUniversityPress,\n",
      "12\n",
      "\n",
      "2012.A.IhlerandD.Newman.?UnderstandingErrorsinApproximateDis-\n",
      "tributedLatentDirichletAllocation?.In:KnowledgeandDataEngineering,\n",
      "IEEETransactionson24.5(2012),pp.952?960.Y.Liu,O.Kosut,andA.S.\n",
      "Willsky.?SamplingGMRFsbySubgraphCorrection?.In:NIPS2012Work-\n",
      "shop:Perturbations,Optimization,andStatistics(2012).G.Papandreouand\n",
      "A.Yuille.?Gaussiansamplingbylocalperturbations?.In:NeuralInformation\n",
      "ProcessingSystems(NIPS).2010.A.ParkerandC.Fox.?SamplingGaus-\n",
      "siandistributionsinKrylovspaceswithconjugategradients?.In:SIAMJour-\n",
      "nalonScienComputing34.3(2012),pp.312?334.ColinFoxandAlbert\n",
      "Parker.?ConvergenceinVarianceofFirst-OrderandSecond-OrderCheby-\n",
      "shevAcceleratedGibbsSamplers?.2013.URL:http://www.physics.otago.\n",
      "ac.nz/data/fox/publications/SIAM\n",
      "CS\n",
      "2012-11-30.pdf.J.Gonzalez,Y.Low,\n",
      "A.Gretton,andC.Guestrin.?ParallelGibbsSampling:FromColoredFields\n",
      "toThinJunctionTrees?.In:InIntelligenceandStatistics(AISTATS).\n",
      "Ft.Lauderdale,FL,May2011.M.J.WainwrightandM.I.Jordan.?Graph-\n",
      "icalmodels,exponentialfamilies,andvariationalRinMachineLearning1.1-2\n",
      "(2008),pp.1?305.inference?.In:FoundationsandTrendsA.Bermanand\n",
      "R.J.Plemmons.?NonnegativeMatricesintheMathematicalSciences?.In:\n",
      "ClassicsinAppliedMathematics,9(1979).M.J.CastelV.Migall?nandJ.Pe-\n",
      "nad?s.?OnParalleltwo-stagemethodsforHermitianpositivematrices\n",
      "withapplicationstopreconditioning?.In:ElectronicTransactionsonNumer-\n",
      "icalAnalysis12(2001),pp.88?112.D.Serre.Nov.2011.URL:http://\n",
      "mathoverw.net/questions/80793/is-gauss-seidel-guaranteed-to-con-\n",
      "verge-on-semi-positiveNicholasRuozziand\n",
      "SekharTatikonda.?Message-PassingAlgorithmsforQuadraticMinimization?.\n",
      "In:JournalofMachineLearningResearch14(2013),pp.2287?2314.URL:\n",
      "http://jmlr.org/papers/v14/ruozzi13a.html.A.FrommerandD.B.Szyld.?On\n",
      "asynchronousiterations?.In:Journalofcomputationalandappliedmathemat-\n",
      "ics123.1(2000),pp.201?216.A.FrommerandD.B.Szyld.?Asynchronous\n",
      "two-stageiterativemethods?.In:NumerischeMathematik69.2(1994),pp.\n",
      "141?153.J.A.Kelner,L.Orecchia,A.Sidford,andZ.A.Zhu.ASimple,Com-\n",
      "binatorialAlgorithmforSolvingSDDSystemsinNearly-LinearTime.2013.\n",
      "arXiv:1301.6628[cs.DS].\n",
      "9\n",
      "13\n",
      "\n",
      "PP5721.pdf\n",
      "PP5721.pdf 12\n",
      "Black-boxoptimizationofnoisyfunctionswith\n",
      "unknownsmoothness\n",
      "Authoredby:\n",
      "RemiMunos\n",
      "RemiMunos\n",
      "MichalValko\n",
      "Jean-BastienGrill\n",
      "Abstract\n",
      "Westudytheproblemofblack-boxoptimizationofafunction$f$of\n",
      "anydimension,givenfunctionevaluationsperturbedbynoise.Thefunc-\n",
      "tionisassumedtobelocallysmootharoundoneofitsglobaloptima,but\n",
      "thissmoothnessisunknown.Ourcontributionisanadaptiveoptimiza-\n",
      "tionalgorithm,POOorparalleloptimisticoptimization,thatisableto\n",
      "dealwiththissetting.POOperformsalmostaswellasthebestknownal-\n",
      "gorithmsrequiringtheknowledgeofthesmoothness.Furthermore,POO\n",
      "worksforalargerclassoffunctionsthanwhatwaspreviouslyconsidered,\n",
      "especiallyforfunctionsthatareculttooptimize,inaveryprecise\n",
      "sense.WeprovideaanalysisofPOO'sperformance,which\n",
      "showsthatitserrorafter$n$evaluationsisatmostafactorof$sqrt\n",
      "f\n",
      "ln\n",
      "n\n",
      "g\n",
      "$awayfromtheerrorofthebestknownoptimizationalgorithmsusing\n",
      "theknowledgeofthesmoothness.\n",
      "1PaperBody\n",
      "Wetreattheproblemofoptimizingafunctionf:X?Rgivenabudgetofn\n",
      "noisyevaluations.Weconsiderthatthecostofanyofthesefunctionevaluations\n",
      "ishigh.Thatmeans,wecareaboutassessingtheoptimizationperformancein\n",
      "termsofthesamplecomplexity,i.e.,thenumberofnfunctionevaluations.\n",
      "Thisistypicallythecasewhenoneneedstotuneparametersforacomplex\n",
      "systemseenasablack-box,whichperformancecanonlybeevaluatedbya\n",
      "costlysimulation.Onesuchexample,isthehyper-parametertuningwherethe\n",
      "sensitivitytoperturbationsislargeandthederivativesoftheobjectivefunction\n",
      "withrespecttotheseparametersdonotexistorareunknown.Suchsetting\n",
      "thesequentialdecision-makingsettingunderbanditfeedback.Inthissetting,\n",
      "theactionsarethepointsthatlieinadomainX.Ateachstept,analgorithm\n",
      "selectsanactionxt?Xandreceivesarewardrt,whichisanoisyfunction\n",
      "1\n",
      "\n",
      "evaluationsuchthatrt=f(xt)+?t,where?tisaboundednoisewithE[?t\n",
      "|xt]=0.Afternevaluations,thealgorithmoutputsitsbestguessx(n),which\n",
      "canbetfromxn.Theperformancemeasurewewanttominimizeis\n",
      "thevalueofthefunctionatthereturnedpointcomparedtotheoptimum,also\n",
      "referredtoassimpleregret,def\n",
      "Rn=supf(x)?f(x(n)).x?X\n",
      "Weassumethereexistsatleastonepointx??Xsuchthatf(x?)=\n",
      "supx?Xf(x).TherelationshipwithbanditsettingsmotivatedUCT[10,8],\n",
      "anempiricallysuccessfulheuristicthathierarchicallypartitionsdomainXand\n",
      "selectsthenextpointxt?Xusingupperbounds[1].Theempirical\n",
      "successofUCTononesidebuttheabsenceofperformanceguaranteesforit\n",
      "ontheother,incitedresearchonsimilarbuttheoreticallyfoundedalgorithms\n",
      "[4,9,12,2,6].Astheglobaloptimizationoftheunknownfunctionwithout\n",
      "absolutelyanyassumptionswouldbeadauntingneedle-in-a-haystackproblem,\n",
      "mostofthealgorithmsassumeatleastaveryweak?\n",
      "ontheleavefromSequeLteam,INRIALille-NordEurope,France\n",
      "1\n",
      "assumptionthatthefunctiondoesnotdecreasefasterthanaknownrate\n",
      "aroundoneofitsglobaloptima.Inotherwords,theyassumeacertainlocal\n",
      "smoothnesspropertyoff.Thissmoothnessisoftenexpressedintheformofa\n",
      "semi-metric`thatquanthisregularity[4].Naturally,thisregularityalso\n",
      "theguaranteesthatthesealgorithmsareabletofurnish.Manyof\n",
      "themanear-optimalitydimensiondorazoomingdimension.Theseare\n",
      "`-dependentquantitiesusedtoboundthesimpleregretRnorarelatednotion\n",
      "calledcumulativeregret.Ourworkfocusesonanotionofsuchnear-optimality\n",
      "dimensiondthatdoesnotdirectlyrelatethesmoothnesspropertyofftoa\n",
      "spmetric`butdirectlytothehierarchicalpartitioningP=\n",
      "f\n",
      "Ph,i\n",
      "g\n",
      ",atree-\n",
      "basedrepresentationofthespaceusedbythealgorithm.Indeed,aninteresting\n",
      "fundamentalquestionistodetermineagoodcharacterizationofthey\n",
      "oftheoptimizationforanalgorithmthatusesagivenhierarchicalpartitioning\n",
      "ofthespaceXasitsinput.Thekindofhierarchicalpartitioning\n",
      "f\n",
      "Ph,i\n",
      "g\n",
      "we\n",
      "considerissimilartotheonesintroducedinpriorwork:foranydepthh?0\n",
      "inthetreerepresentation,thesetofcells\n",
      "f\n",
      "Ph,i\n",
      "g\n",
      "1?i?IhformapartitionofX\n",
      ",whereIhisthenumberofcellsatdepthh.Atdepth0,therootofthetree,\n",
      "thereisasinglecellP0,1=X.AcellPh,iofdepthhissplitintoseveralchildren\n",
      "subcells\n",
      "f\n",
      "Ph+1,j\n",
      "g\n",
      "jofdepthh+1.Werefertothestandardpartitioningasto\n",
      "onewhereeachcellissplitintoregularsame-sizedsubcells[13].Animportant\n",
      "insight,detailedinSection2,isthatanear-optimalitydimensiondthatis\n",
      "independentfromthepartitioningusedbyanalgorithm(asinprior\n",
      "work[4,9,2])doesnotembodytheoptimizationyperfectly.Thisis\n",
      "easytosee,asforanyfwecouldapartitioning,perfectlysuitedforf.\n",
      "Anexampleisapartitioning,thatattherootsplitsXinto\n",
      "f\n",
      "x?\n",
      "g\n",
      "andXx?,\n",
      "whichmakestheoptimizationtrivial,whateverdis.Thisinsightwasalready\n",
      "observedbySlivkins[14]andBull[6],whosezoomingdimensiondependsboth\n",
      "onthefunctionandthepartitioning.Inthispaper,weanotionof\n",
      "near-optimalitydimensiondwhichmeasuresthecomplexityoftheoptimization\n",
      "2\n",
      "\n",
      "problemdirectlyintermsofthepartitioningusedbyanalgorithm.First,we\n",
      "makethefollowinglocalsmoothnessassumptionaboutthefunction,expressed\n",
      "intermsofthepartitioningandnotanymetric:ForagivenpartitioningP,we\n",
      "assumethatthereexist?>0and??(0,1),s.t.,f(x)?f(x?)???h\n",
      "?h?0,?x?Ph,i?h,\n",
      "where(h,i?h)isthe(unique)cellofdepthhcontainingx?.Then,we\n",
      "thenear-optimalitydimensiond(?,?)asno0defd(?,?)=infd0?R+\n",
      ":?C>0,?h?0,Nh(2??h)?C??dh,whereforall?>0,Nh(?)isthe\n",
      "numberofcellsPh,iofdepthhs.t.supx?Ph,if(x)?f(x?)??.Intuitively,\n",
      "functionswithsmallerdareeasiertooptimizeandwedenote(?,?),forwhich\n",
      "d(?,?)isthesmallest,as(??,??).Obviously,d(?,?)dependsonPandf,but\n",
      "doesnotdependonanychoiceofaspmetric.InSection2,wearguethat\n",
      "thisofd1encompassestheoptimizationcomplexitybetter.Westress\n",
      "thisisnotanartifactofouranalysisandpreviousalgorithms,suchasHOO[4],\n",
      "TaxonomyZoom[14],orHCT[2],canbeshowntoscalewiththisnewnotionof\n",
      "d.Mostofthepriorbandit-basedalgorithmsproposedforfunctionoptimization,\n",
      "foreitherdeterministicorstochasticsetting,assumethatthesmoothnessofthe\n",
      "optimizedfunctionisknown.Thisisthecaseofknownsemi-metric[4,2]and\n",
      "pseudo-metric[9].Thisassumptionlimitstheapplicationofthesealgorithms\n",
      "andopenedaverycompellingquestionofwhetherthisknowledgeisnecessary.\n",
      "Priorworkrespondedwithalgorithmsnotrequiringthisknowledge.Bubecket\n",
      "al.[5]providedanalgorithmforoptimizationofLipschitzfunctionswithout\n",
      "theknowledgeoftheLipschitzconstant.However,theyhavetoassumethat\n",
      "fistwicetiableandaboundonthesecondorderderivativeisknown.\n",
      "CombesandProuti`ere[7]treatunimodalfrestrictedtodimensionone.Slivkins\n",
      "[14]consideredageneraloptimizationproblemembeddedinataxonomy2and\n",
      "providedguaranteesasafunctionofthequalityofthetaxonomy.Thequality\n",
      "referstotheprobabilityofreachingtwocellsbelongingtothesamebranch\n",
      "thatcanhavevaluesthatbymorethathalfofthediameter(expressed\n",
      "bythetruemetric)ofthebranch.Theproblemisthatthealgorithmneedsa\n",
      "lowerboundonthisquality(whichcanbetiny)andtheperformancedepends\n",
      "inverselyonthisquantity.Alsoitassumesthatthequalityisstrictlypositive.\n",
      "Inthispaper,wedonotrelyontheknowledgeofqualityandalsoconsidera\n",
      "moregeneralclassoffunctionsforwhichthequalitycanbe0(AppendixE).1\n",
      "2\n",
      "weusethenotationdinsteadofd(?,?)forclaritywhenno\n",
      "confusionispossiblewhichissimilartothehierarchicalpartitioningpreviously\n",
      "\n",
      "2\n",
      "0.09\n",
      "simpleregretafter5000evaluations\n",
      "0.0\n",
      "f(x)\n",
      "?0.2?0.4?0.6?0.8?1.00.0\n",
      "0.2\n",
      "0.4\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.8\n",
      "0.080.070.060.050.040.030.020.010.0\n",
      "1.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "?\n",
      "x\n",
      "pp2Figure1:functionf:x?s(log2|x?0.5|)?(|x?0.5|\n",
      "?(x?0.5))?|x?0.5|where,s(x)=1ifthefractionalpartofx,thatis,\n",
      "x?bxc,isin[0,0.5]ands(x)=0,ifitisin(0.5,1).Left:Oscillationbetween\n",
      "twoenvelopesoftsmoothnessleadingtoanonzerodforastandard\n",
      "partitioning.Right:RegretofHOOafter5000evaluationsfortvaluesof\n",
      "?.AnotherdirectionhasbeenfollowedbyMunos[11],whereinthedeterministic\n",
      "case(thefunctionevaluationsarenotperturbedbynoise),theirSOOalgorithm\n",
      "performsalmostaswellasthebestknownalgorithmswithouttheknowledge\n",
      "ofthefunctionsmoothness.SOOwaslaterextendedtoStoSOO[15]forthe\n",
      "stochasticcase.HoweverStoSOOonlyextendsSOOforalimitedcaseofeasy\n",
      "instancesoffunctionsforwhichthereexistsasemi-metricunderwhichd=0.\n",
      "Also,Bull[6]providedasimilarregretboundfortheATBalgorithmforaclass\n",
      "offunctions,calledzoomingcontinuousfunctions,whichisrelatedtotheclassof\n",
      "functionsforwhichthereexistsasemi-metricunderwhichthenear-optimality\n",
      "dimensionisd=0.Butnoneofthepriorworkconsidersamoregeneralclass\n",
      "offunctionswherethereisnosemi-metricadaptedtothestandardpartitioning\n",
      "forwhichd=0.Togiveanexampleofafunction,considerthefunction\n",
      "inFigure1.It?possessesalowerandupperenvelopearounditsglobaloptimum\n",
      "thatareequivalenttox2andx;andthereforehavetsmoothness.Thus,\n",
      "forastandardpartitioning,thereisnosemi-metricoftheform`(x,y)=||x?\n",
      "y||?forwhichthenear-optimalitydimensionisd=0,asshownbyValkoet\n",
      "al.[15].Otherexamplesofnonzeronear-optimalitydimensionarethefunctions\n",
      "thatforastandardpartitioningbehavetlydependingonthedirection,\n",
      "forinstancef:(x,y)7?1?|x|?y2.Usingabadvalueforthe?\n",
      "parametercanhavedramaticconsequencesonthesimpleregret.InFigure1,\n",
      "weshowthesimpleregretafter5000functionevaluationsfortvalues\n",
      "of?.Forthevaluesof?thataretoolow,thealgorithmdoesnotexplore\n",
      "enoughandisstuckinalocalmaximumwhileforvaluesof?toohighthe\n",
      "algorithmwastesevaluationsbyexploringtoomuch.Inthispaper,weprovide\n",
      "anewalgorithm,POO,paralleloptimisticoptimization,whichcompeteswith\n",
      "thebestalgorithmsthatassumetheknowledgeofthefunctionsmoothness,for\n",
      "alargerclassoffunctionsthanwaspreviouslydone.Indeed,POOhandlesa\n",
      "panoplyoffunctions,includinghardinstances,i.e.,suchthatd>0,likethe\n",
      "functionillustratedabove.WealsorecovertheresultofStoSOOandATBfor\n",
      "functionswithd=0.Inparticular,weboundthePOO?ssimpleregretas\n",
      "4\n",
      "\n",
      "1/(2+d(??,??))E[Rn]?Oln2n/n.Thisresultshouldbecomparedto\n",
      "thesimpleregretofthebestknownalgorithmthatusestheknowledgeofthe\n",
      "metricunderwhichthefunctionissmooth,orequivalently(?,?),whichisofthe\n",
      "orderofO((lnn/n)1/(2+d)).ThusPOO?sperformanceisatmostafactorof\n",
      "(lnn)1/(2+d)awayfromthatofthebestknownoptimizationalgorithmsthat\n",
      "requiretheknowledgeofthefunctionsmoothness.Interestingly,thisfactor\n",
      "decreaseswiththecomplexitymeasured:theharderthefunctiontooptimize,\n",
      "thelessimportantitistoknowitsprecisesmoothness.\n",
      "22.1\n",
      "BackgroundandassumptionsHierarchicaloptimisticoptimization\n",
      "POOoptimizesfunctionswithouttheknowledgeoftheirsmoothnessusinga\n",
      "subroutine,ananytimealgorithmoptimizingfunctionsusingtheknowledgeof\n",
      "theirsmoothness.Inthispaper,weuseamoversionofHOO[4]assuch\n",
      "subroutine.Therefore,weembarkwithaquickreviewofHOO.HOOfollowsan\n",
      "optimisticstrategyclosetoUCT[10],butunlikeUCT,itusesproper\n",
      "boundstoprovidetheoreticalguarantees.HOOapartitionofthespace\n",
      "basedonahierarchicalpartitioning,whereateachstep,ayetunexploredcell\n",
      "(aleafofthecorrespondingtree)isselected,3\n",
      "andthefunctionisevaluatedatapointwithinthiscell.Theselectedpath\n",
      "(fromtheroottotheleaf)istheonethatmaximizestheminimumvalueUh,i\n",
      "(t)amongallcellsofeachdepth,wherethevalueUh,i(t)ofanycellPh,iis\n",
      "ass2ln(t)Uh,i(t)=?bh,i(t)++??h,Nh,i(t)wheretisthenumber\n",
      "ofevaluationsdonesofar,?bh,i(t)istheempiricalaverageofallevaluations\n",
      "donewithinPh,i,andNh,i(t)isthenumberofthem.Thesecondterminthe\n",
      "ofUh,i(t)isaengtypeinterval,measuring\n",
      "theestimationerrorinducedbythenoise.Thethirdterm,??hwith??(0,1)\n",
      "is,byassumption,aboundonthencef(x?)?f(x)foranyx?Ph,i?h\n",
      ",acellcontainingx?.Isitthisbound,whereHOOreliesontheknowledgeof\n",
      "thesmoothness,becausethealgorithmrequiresthevaluesof?and?.Inthe\n",
      "nextsections,weclarifytheassumptionsmadebyHOOvs.relatedalgorithms\n",
      "andpointoutthewithPOO.2.2\n",
      "Assumptionsmadeinpriorwork\n",
      "Mostofpreviousworkreliesontheknowledgeofasemi-metriconXsuch\n",
      "thatthefunctioniseitherlocallysmoothneartooneofitsmaximawithrespect\n",
      "tothismetric[11,15,2]orrequireastronger,weakly-Lipschitzassumption[4,\n",
      "12,2].Furthermore,Kleinbergetal.[9]assumethefullmetric.Note,that\n",
      "thesemi-metricdoesnotrequirethetriangularinequalitytohold.Forinstance,\n",
      "considerthesemi-metric`(x,y)=||x?y||?onRpwith||?||\n",
      "beingtheeuclideanmetric.When?<1thenthissemi-metricdoesnotsatisfy\n",
      "thetriangularinequality.However,itisametricfor??1.Therefore,using\n",
      "onlysemi-metricallowsustoconsideralargerclassoffunctions.Priorwork\n",
      "typicallyrequirestwoassumptions.Theoneisonsemi-metric`andthe\n",
      "function.Anexampleistheweakly-LipschitzassumptionneededbyBubecket\n",
      "al.[4]whichrequiresthat?x,y?X,\n",
      "f(x?)?f(y)?f(x?)?f(x)+max\n",
      "f\n",
      "f(x?)?f(x),`(x,y)\n",
      "g\n",
      ".\n",
      "ItisaweakversionofaLipschitzcondition,restrictingfinparticularfor\n",
      "5\n",
      "\n",
      "thevaluesclosetof(x?).Morerecentresults[11,15,2]assumeonlyalocal\n",
      "smoothnessaroundoneofthefunctionmaxima,x?X\n",
      "f(x?)?f(x)?`(x?,x).\n",
      "Thesecondcommonassumptionlinksthehierarchicalpartitioningwiththe\n",
      "semi-metric.Itrequiresthepartitioningtobeadaptedtothe(semi)metric.\n",
      "Morepreciselythewell-shapedassumptionstatesthatthereexist?<1and\n",
      "?1??2>0,suchthatforanydepthh?0andindexi=1,...,Ih,\n",
      "thesubsetPh,iiscontainedbyandcontainstwoopenballsofradius?1?h\n",
      "and?2?hrespectively,wheretheballsarew.r.t.thesamesemi-metricusedin\n",
      "theofthefunctionsmoothness.?Localsmoothness?isweakerthan\n",
      "?weaklyLipschitz?andthereforepreferable.Algorithmsrequiringthelocal-\n",
      "smoothnessassumptionalwayssampleacellPh,iinaspecialrepresentative\n",
      "pointand,inthestochasticcase,collectseveralfunctionevaluationsfromthe\n",
      "samepointbeforesplittingthecell.ThisisnotthecaseofHOO,whichallows\n",
      "tosampleanypointinsidetheselectedcellandtoexpandeachcellafterone\n",
      "sample.Thisadditionalycomesatthepriceofrequiringthestronger\n",
      "weakly-Lipschitznessassumption.Nevertheless,althoughHOOdoesnotwait\n",
      "beforeexpandingacell,itdoessomethingsimilarbyselectingapathfromthe\n",
      "roottothisleafthatmaximizestheminimumoftheU-valueoverthecellsof\n",
      "thepath,asmentionedinSection2.1.ThefactthatHOOfollowsanoptimistic\n",
      "strategyevenafterreachingthecellthatpossessestheminimalU-valuealong\n",
      "thepathisnotusedintheanalysisoftheHOOalgorithm.Furthermore,a\n",
      "reasonforbetterdependencyonthesmoothnessinotheralgorithms,e.g.,HCT\n",
      "[2],isnotonlyalgorithmic:HCTneedstoassumeaslightlystrongercondition\n",
      "onthecell,i.e.,thatthesinglecenterofthetwoballs(onethatcoversand\n",
      "theotheronethatcontainsthecell)isactuallythesamepointthatHCTuses\n",
      "forsampling.Thisisstrongerthanjustassumingthattheresimplyexistsuch\n",
      "centersofthetwoballs,whicharenotnecessarilythesamepointswherewe\n",
      "sample(whichistheHOOassumption).Therefore,thisisincontrastwithHOO\n",
      "thatsamplesanypointfromthecell.Infact,itisstraightforwardtomodify\n",
      "HOOtoonlysampleatarepresentativepointineachcellandonlyrequirethe\n",
      "local-smoothnessassumption.Inouranalysisandthealgorithm,weusethis\n",
      "moversionofHOO,therebyfromthisweakerassumption.4\n",
      "Priorwork[9,4,11,2,12]oftendenedsome?dimension?dofthenear-\n",
      "optimalspaceoffmeasuredaccordingtothe(semi-)metric`.Forexample,the\n",
      "so-callednear-optimalitydimension[4]measuresthesizeofthenear-optimal\n",
      "spaceX?=\n",
      "f\n",
      "x?X:f(x)>f(x?)??\n",
      "g\n",
      "intermsofpackingnumbers:Forany\n",
      "c>0,?0>0,the(c,?0)-near-optimalitydimensiondoffwithrespectto`is\n",
      "as\n",
      "infd?[0,?):?Cs.t.????0,N(Xc?,`,?)?C??d,(1)wherefor\n",
      "anysubsetA?X,thepackingnumberN(A,`,?)isthemaximumnumberof\n",
      "disjointballsofradius?containedinA.2.3\n",
      "Ourassumption\n",
      "Contrarytothepreviousapproaches,weneedonlyasingleassumption.We\n",
      "donotintroduceany(semi)-metricandinsteaddirectlyrelateftothehierar-\n",
      "chicalpartitioningP,inSection1.LetKbethemaximumnumberof\n",
      "6\n",
      "\n",
      "childrencells(Ph+1,jk)1?k?KpercellPh,i.Weremindthereaderthatgiven\n",
      "aglobalmaximumx?off,i?hdenotestheindexoftheuniquecellofdepth\n",
      "hcontainingx?,i.e.,suchthatx??Ph,i?h.Withthisnotationwecan\n",
      "stateoursoleassumptiononboththepartitioning(Ph,i)andthefunctionf.\n",
      "Assumption1.Thereexists?>0and??(0,1)suchthat?h?0,?x?Ph,i?h,\n",
      "f(x)?f(x?)???h.\n",
      "Thevalues(?,?)alowerboundonthepossibledropoffnearthe\n",
      "optimumx?accordingtothepartitioning.Thechoiceoftheexponentialrate\n",
      "??hismadetocoveraverylargeclassoffunctions,aswellastorelatetoresults\n",
      "frompriorwork.Inparticular,forastandardpartitioningonRpandany?,?>\n",
      "0,anyfunctionfsuchthatf(x)?x?x??||x?x?||?thisassumption.\n",
      "Thisisalsothecaseformorecomplicatedfunctionssuchastheoneillustrated\n",
      "inFigure1.Anexampleofafunctionandapartitioningthatdoesnotsatisfy\n",
      "thisassumptionisthefunctionf:x7?1/lnxandastandardpartitioningof[0,\n",
      "1)becausethefunctiondecreasestoofastaroundx?=0.AsobservedbyValko\n",
      "[15],thisassumptioncanbeweakentoholdonlyforvaluesoffthatare?-closeto\n",
      "f(x?)uptoan?-dependentconstantintheregret.Letusnotethatthesetof\n",
      "assumptionsmadebypriorwork(Section2.2)canbereformulatedusingsolely\n",
      "Assumption1.Forexample,foranyf(x)?x?x??||x?x?||?,onecould\n",
      "considerthesemimetric`(x,y)=?||x?y||?forwhichthecorresponding\n",
      "near-optimalitydimensionbyEquation1forastandardpartitioningis\n",
      "d=0.Yetwearguethatoursettingprovidesamorenaturalwaytodescribe\n",
      "thecomplexityoftheoptimizationproblemforagivenhierarchicalpartitioning.\n",
      "Indeed,existingalgorithms,thatuseahierarchicalpartitioningofX,likeHOO,\n",
      "donotusethefullmetricinformationbutinsteadonlyusethevalues?and\n",
      "?,pairedupwiththepartitioning.Hence,theprecisevalueofthemetricdoes\n",
      "notimpactthealgorithms?tdecisions,neithertheirperformance.Whatreally\n",
      "matters,ishowthehierarchicalpartitioningofXf.Indeed,thisiswhat\n",
      "wemeasure.Toreinforcethisargument,noticeagainthatanyfunctioncanbe\n",
      "triviallyoptimizedgivenaperfectlyadaptedpartitioning,forinstancetheone\n",
      "thatassociatesx?toonechildoftheroot.Also,thepreviousanalysestried\n",
      "toprovideperformanceguarantiesbasedonlyonthemetricandf.However,\n",
      "sincethemetricisassumedtobesuchthatthecellsofthepartitioningarewell\n",
      "shaped,thelargediversityofpossiblemetricsvanishes.Choosingsuchmetric\n",
      "thencomesdowntochoosingonly?,?,andahierarchicaldecompositionofX.\n",
      "Anotherwayofseeingthisistoremarkthatpreviousworksmakeanassumption\n",
      "onboththefunctionandthemetric,andanotheronboththemetricandthe\n",
      "partitioning.Weunderlinethatthemetricisactuallytherejusttocreatealink\n",
      "betweenthefunctionandthepartitioning.Bydiscardingthemetric,wemerge\n",
      "thetwoassumptionsintoasingleoneandconvertatopologicalprobleminto\n",
      "acombinatorialone,leadingtoeasieranalysis.Toproceed,weanew\n",
      "near-optimalitydimension.Forany?>0and??(0,1),thenearoptimality\n",
      "dimensiond(?,?)offwithrespecttothepartitioningPisasfollows.\n",
      "1.Near-optimalitydimensionoffisno0defd(?)=infd0?R+:\n",
      "?C>0,?h?0,Nh(2??h)?C??dhwhereNh(?)isthenumberofcellsPh,i\n",
      "ofdepthhsuchthatsupx?Ph,if(x)?f(x?)??.5\n",
      "7\n",
      "\n",
      "ThehierarchicaldecompositionofthespaceXistheonlypriorinformation\n",
      "availabletothealgorithm.The(new)near-optimalitydimensionisameasure\n",
      "ofhowwellisthispartitioningadaptedtof.Moreprecisely,itisameasure\n",
      "ofthesizeofthenear-optimalset,i.e.,thecellswhicharesuchthatsupx?Ph,i\n",
      "f(x)?f(x?)??.Intuitively,thiscorrespondstothesetofcellsthat\n",
      "anyalgorithmwouldhavetosampleinordertodiscovertheoptimum.Asan\n",
      "example,anyfsuchthatf(x)?x?x?||x?x?||?,forany?>0,has\n",
      "azeronear-optimalitydimensionwithrespecttothestandardpartitioningand\n",
      "anappropriatechoiceof?.AsdiscussedbyValkoetal.[15],anyfunctionsuch\n",
      "thattheupperandlowerenvelopesoffnearitsmaximumareofthesameorder\n",
      "hasanear-optimalitydimensionofzeroforastandardpartitioningof[0,1].An\n",
      "exampleofafunctionwithd>0forthestandardpartitioningisinFigure1.\n",
      "Functionsthatbehavetlyintdimensionshavealsod>0forthe\n",
      "standardpartitioning.Nonetheless,forasomehandcraftedpartitioning,itis\n",
      "possibletohaved=0evenforthosetroublesomefunctions.Underournew\n",
      "assumptionandournewofnear-optimalitydimension,onecanprove\n",
      "thesameregretboundforHOOasBubecketal.[4]andthesamecanbedone\n",
      "forotherrelatedalgorithms.\n",
      "3\n",
      "ThePOOalgorithm\n",
      "3.1\n",
      "DescriptionofPOO\n",
      "ThePOOalgorithmuses,asasubroutine,anoptimizingalgorithmthat\n",
      "requirestheknowledgeofthefunctionsmoothness.WeuseHOO[4]asthe\n",
      "basealgorithm,butotheralgorithms,suchasHCT[2],couldbeusedaswell.\n",
      "POO,withpseudocodeinAlgorithm1,runsseveralHOOinstancesinparallel,\n",
      "hencethenameparalleloptimisticoptimization.ThenumberofbaseHOO\n",
      "instancesandotherparametersareadaptedtothebudgetofevaluationsand\n",
      "areautomaticallydecidedonthe.EachinstanceofHOOrequirestworeal\n",
      "numbers?and?.RunningHOOparametrizedwith(?,?)thatarefarfromthe\n",
      "optimalone(??,??)3wouldcauseHOOtounderperform.Surprisingly,our\n",
      "analysisofthissuboptimalitygaprevealsthatitdoesnotdecreasetoofastas\n",
      "westrayawayfrom(??,??).Thismotivatesthefollowingobservation.Ifwe\n",
      "simultaneouslyrunaslewofHOOswitht(?,?)s,oneofthemisgoing\n",
      "toperformdecentlywell.Infact,weshowthattoachievegoodperformance,we\n",
      "onlyrequire(lnn)HOOinstances,wherenisthecurrentnumberoffunction\n",
      "evaluations.Notice,thatwedonotrequiretoknowthetotalnumberofrounds\n",
      "inadvancewhichhintsthatwecanhopeforanaturallyanytimealgorithm.\n",
      "Algorithm1POOParameters:K,P=\n",
      "f\n",
      "Ph,i\n",
      "g\n",
      "Optionalparameters:?max\n",
      ",?maxInitialization:Dmax?lnK/ln(1/?max)n?0\n",
      "f\n",
      "numberofevaluation\n",
      "performed\n",
      "g\n",
      "N?1\n",
      "f\n",
      "numberofHOOinstances\n",
      "g\n",
      "S?\n",
      "f\n",
      "(?max,?max)\n",
      "gf\n",
      "setof\n",
      "HOOinstances\n",
      "g\n",
      "whilecomputationalbudgetisavailabledowhileN?12Dmax\n",
      "ln(n/(lnn))dofori?1,...,Ndo\n",
      "f\n",
      "startnewHOOs\n",
      "g\n",
      "s??max,?max\n",
      "2N/(2i+1)S?S?\n",
      "f\n",
      "s\n",
      "g\n",
      "nPerformNfunctionevaluationwithHOO(s)Update\n",
      "theaveragereward?b[s]ofHOO(s)endforn?2nN?2Nendwhile\n",
      "f\n",
      "ensure\n",
      "thereisenoughHOOs\n",
      "g\n",
      "fors?SdoPerformafunctionevaluationwithHOO(s)\n",
      "8\n",
      "\n",
      "Updatetheaveragereward?b[s]ofHOO(s)endforn?n+Nendwhiles??\n",
      "argmaxs?S?b[s]Output:ArandompointevaluatedbyHOO(s?)\n",
      "ThestrategyofPOOisquitesimple:ItconsistsofrunningNinstancesof\n",
      "HOOinparallel,thatarealllaunchedwitht(?,?)s.Attheendof\n",
      "thewholeprocess,POOselectstheinstances?whichperformedthebestand\n",
      "returnsoneofthepointsselectedbythisinstance,chosenuniformlyatrandom.\n",
      "NotethatjustusingadoublingtrickinHOOwithincreasingvaluesof?and\n",
      "?isnotenoughtoguaranteeagoodperformance.Indeed,itisimportantto\n",
      "keeptrackofallHOOinstances.Otherwise,theregretratewouldway\n",
      "toomuchfromusingthevalueof?thatistoofarfromtheoptimalone.3\n",
      "theparameters(?,?)satisfyingAssumption1forwhichd(?,?)isthe\n",
      "smallest\n",
      "6\n",
      "Forclarity,thepseudo-codeofAlgorithm1takes?maxand?maxaspa-\n",
      "rametersbutinAppendixCweshowhowtoset?maxand?maxautomatically\n",
      "asfunctionsofthenumberofevaluations,i.e.,?max(n),?max(n).Further-\n",
      "more,inAppendixD,weexplainhowtoshareinformationbetweentheHOO\n",
      "instanceswhichmakestheempiricalperformancelight-yearsbetter.SincePOO\n",
      "isanytime,thenumberofinstancesN(n)istime-dependentanddoesnotneed\n",
      "tobeknowninadvance.Infact,N(n)isincreasedalongsidetheexecutionof\n",
      "thealgorithm.Moreprecisely,wewanttoensurethatN(n)?21Dmaxln(n/\n",
      "lnn),\n",
      "where\n",
      "def\n",
      "Dmax=(lnK)/ln(1/?max)?\n",
      "Tokeepthesetoft(?,?)swelldistributed,thenumberofHOOsis\n",
      "notincreasedonebyonebutinsteadisdoubledwhenneeded.Moreover,we\n",
      "alsorequirethatHOOsruninparallel,performthesamenumberoffunction\n",
      "evaluations.Consequently,whenwestartrunningnewinstances,weensure\n",
      "tomaketheseinstancesonparwithalreadyexistingonesintermsofnumberof\n",
      "evaluations.Finally,asouranalysisreveals,agoodchoiceofparameters(?i)\n",
      "isnotauniformgridon[0,1].Instead,assuggestedbyouranalysis,werequire\n",
      "that1/ln(1/?i)isauniformgridon[0,1/(ln1/?max)].Asaconsequence,we\n",
      "addHOOinstancesinbatchessuchthat?i=?maxN/i.3.2\n",
      "UpperboundonPOO?sregret\n",
      "POOdoesnotrequiretheknowledgeofa(?,?)verifyingAssumption1\n",
      "and4yetweprovethatitachievesaperformanceclose5totheoneobtainedby\n",
      "HOOusingthebestparameters(??,??).Thisresultsolvestheopenquestion\n",
      "ofValkoetal.[15],whetherthestochasticoptimizationoffwithunknown\n",
      "parameters(?,?)whend>0forthestandardpartitioningispossible.Theorem\n",
      "1.LetRnbethesimpleregretofPOOatstepn.Forany(?,?)verifying\n",
      "Assumption1suchthat???maxand???maxthereexists?suchthatfor\n",
      "allnE[Rn]???Dmax\n",
      "Moreover,?=??Dmax(?max/??)\n",
      "1/(d(?,?)+2)ln2n/n\n",
      ",where?isaconstantindependentof?maxand?max.\n",
      "9\n",
      "\n",
      "WeproveTheorem1intheAppendixAandB.NoticethatTheorem1holds\n",
      "forany???maxand???maxandinparticularfortheparameters(??,\n",
      "??)forwhichd(?,?)isminimalaslongas????maxand????max.\n",
      "InAppendixC,weshowhowtomake?maxand?maxoptional.Togivesome\n",
      "intuitiononDmax,itiseasytoprovethatitistheattainableupperbound\n",
      "onthenearoptimalitydimensionoffunctionsverifyingAssumption1with??\n",
      "?max.Moreover,anyfunctionof[0,1]p,LipschitzfortheEuclideanmetric,\n",
      "has(lnK)/ln(1/?)=pforastandardpartitioning.ThePOO?sperformance\n",
      "shouldbecomparedtothesimpleregretofHOOrunwiththebestparameters\n",
      "??and??,whichisoforder\n",
      "1/(d(??,??)+2).O((lnn)/n)1/(d(?,?)+2)\n",
      "??ThusPOO?sperformanceisonlyafactorofO((lnn))awayfromthe\n",
      "optimallyHOO.Furthermore,weourregretboundforPOOisslightly\n",
      "betterthantheknownregretbound?forStoSOO[15]inthecasewhend(?,?)\n",
      "=0forthesamepartitioning,i.e.,E[Rn]=O(lnn/n).Withouralgorithm\n",
      "andanalysis,wegeneralizethisboundforanyvalueofd?0.\n",
      "NotethatweonlygiveasimpleregretboundforPOOwhereasHOOensures\n",
      "aboundonboththecumulativeandsimpleregret.6NoticethatsincePOOruns\n",
      "severalHOOswithnon-optimalvaluesofthe(?,?)parameters,thisalgorithm\n",
      "exploresmuchmorethanoptimallyHOO,whichdramaticallyimpacts\n",
      "thecumulativeregret.Asaconsequence,ourresultappliestothesimpleregret\n",
      "only.4\n",
      "notethatseveralpossible?valuesofthoseparametersarepossibleforthe\n",
      "samefunctionuptoalogarithmictermlnninthesimpleregret6infact,\n",
      "theboundonthesimpleregretisadirectconsequenceoftheboundonthe\n",
      "cumulativeregret[3]5\n",
      "7\n",
      "simpleregret\n",
      "0.160.14\n",
      "simpleregret(log-scaled)\n",
      "HOO,?=0.0HOO,?=0.3HOO,?=0.66HOO,?=0.9POO\n",
      "0.18\n",
      "0.120.100.08\n",
      "?2.0?2.5?3.0\n",
      "HOO,?=0.0HOO,?=0.3HOO,?=0.66HOO,?=0.9POO\n",
      "?3.5\n",
      "0.06100\n",
      "200\n",
      "300\n",
      "numberofevaluations\n",
      "400\n",
      "?4.0\n",
      "500\n",
      "4\n",
      "5\n",
      "6\n",
      "10\n",
      "\n",
      "7\n",
      "numberofevaluation(log-scaled)\n",
      "8\n",
      "Figure2:RegretofPOOandHOOrunfortvaluesof?.\n",
      "4\n",
      "Experiments\n",
      "WeranexperimentsonthefunctionplottedinFigure1forHOOalgorithms\n",
      "withrentvaluesof?andthePOO7algorithmfor?max=0.9.This\n",
      "function,asdescribedinSection1,hasanupperandlowerenvelopethatare\n",
      "notofthesameorderandthereforehasd>0forastandardpartitioning.In\n",
      "Figure2,weshowthesimpleregretofthealgorithmsasfunctionofthenumber\n",
      "ofevaluations.Intheontheleft,weplotthesimpleregretafter500\n",
      "evaluations.Intherightone,weplottheregretafter5000evaluationsinthe\n",
      "log-logscale,inordertoseethetrendbetter.TheHOOalgorithmsreturna\n",
      "randompointchosenuniformlyamongthoseevaluated.POOdoesthesamefor\n",
      "thebestempiricalinstanceofHOO.Wecomparethealgorithmsaccordingto\n",
      "theexpectedsimpleregret,whichisthebetweentheoptimumandthe\n",
      "expectedvalueoffunctionvalueatthepointtheyreturn.Wecomputeitasthe\n",
      "averageofthevalueofthefunctionforallevaluatedpoints.Whilewedidnot\n",
      "investigatepossiblytheuristics,webelievethatreturningthedeepest\n",
      "evaluatedpointwouldgiveabetterempiricalperformance.Asexpected,the\n",
      "HOOalgorithmsusingvaluesof?thataretoolow,donotexploreenough\n",
      "andbecomequicklystuckinalocaloptimum.ThisisthecaseforbothUCT\n",
      "(HOOrunfor?=0)andHOOrunfor?=0.3.TheHOOalgorithmusing\n",
      "?thatistoohighwastetheirbudgetonexploringtoomuch.Thisway,we\n",
      "empiricallythattheperformanceoftheHOOalgorithmisgreatly\n",
      "impactedbythechoiceofthis?parameterforthefunctionweconsidered.In\n",
      "particular,atT=500,theempiricalregretofHOOwith?=0.66wasahalf\n",
      "oftheregretofUCT.Inourexperiments,HOOwith??=0.66performedthe\n",
      "bestwhichisabitlowerthanwhatthetheorywouldsuggest,since??=1/2?\n",
      "0.7.TheperformanceofHOOusingthisparameterisalmostmatchedbyPOO.\n",
      "Thisissurprising,consideringthefactthePOOwassimultaneouslyrunning\n",
      "100tHOOs.Itshowsthatcarefullysharinginformationbetweenthe\n",
      "instancesofHOO,asdescribedandinAppendixD,hasamajorimpact\n",
      "onempiricalperformance.Indeed,amongthe100HOOinstances,onlytwo(on\n",
      "average)actuallyneededafreshfunctionevaluation,the98couldreusetheones\n",
      "performedbyanotherHOOinstance.\n",
      "5\n",
      "Conclusion\n",
      "WeintroducedPOOforglobaloptimizationofstochasticfunctionswithun-\n",
      "knownsmoothnessandshowedthatitcompeteswiththebestknownoptimiza-\n",
      "tionalgorithmsthatknowthissmoothness.Thisresultsextendstheprevious\n",
      "workofValkoetal.[15],whichisonlyabletodealwithanearoptimalitydi-\n",
      "mensiond=0.POOisprovableabletodealwithatroveoffunctionsforwhich\n",
      "d?0forastandardpartitioning.Furthermore,wegaveanewinsightonsev-\n",
      "eralassumptionsrequiredbypriorworkandprovidedamorenaturalmeasure\n",
      "11\n",
      "\n",
      "ofthecomplexityofoptimizingafunctiongivenahierarchicalpartitioningof\n",
      "thespace,withoutrelyingonany(semi-)metric.AcknowledgementsThere-\n",
      "searchpresentedinthispaperwassupportedbyFrenchMinistryofHigherEd-\n",
      "ucationandResearch,Nord-Pas-de-CalaisRegionalCouncil,adoctoralgrant\n",
      "of?EcoleNormaleSup?erieureinParis,InriaandCarnegieMellonUniver-\n",
      "sityassociated-teamprojectEduBand,andFrenchNationalResearchAgency\n",
      "projectExTra-Learn(n.ANR-14-CE24-0010-01).7\n",
      "codeavailableathttps://sequel.lille.inria.fr/Software/POO\n",
      "8\n",
      "2References\n",
      "[1]PeterAuer,Nicol`oCesa-Bianchi,andPaulFischer.Finite-timeAnalysisof\n",
      "theMultiarmedBanditProblem.MachineLearning,47(2-3):235?256,2002.[2]\n",
      "MohammadGheshlaghiAzar,AlessandroLazaric,andEmmaBrunskill.Online\n",
      "StochasticOptimizationunderCorrelatedBanditFeedback.InInternational\n",
      "ConferenceonMachineLearning,2014.[3]S?ebastienBubeck,R?emiMunos,\n",
      "andGillesStoltz.PureExplorationinFinitely-ArmedandContinuously-Armed\n",
      "Bandits.TheoreticalComputerScience,412:1832?1852,2011.[4]S?ebastien\n",
      "Bubeck,R?emiMunos,GillesStoltz,andCsabaSzepesv?ari.X-armedBan-\n",
      "dits.JournalofMachineLearningResearch,12:1587?1627,2011.[5]S?ebastien\n",
      "Bubeck,GillesStoltz,andJiaYuanYu.LipschitzBanditswithouttheLip-\n",
      "schitzConstant.InAlgorithmicLearningTheory,2011.[6]AdamD.Bull.\n",
      "Adaptive-treedbandits.Bernoulli,21(4):2289?2307,2015.[7]RichardCombes\n",
      "andAlexandreProuti`ere.UnimodalBanditswithoutSmoothness.ArXive-\n",
      "prints:http://arxiv.org/abs/1406.7447,2015.[8]Pierre-ArnaudCoquelinand\n",
      "R?emiMunos.BanditAlgorithmsforTreeSearch.InUncertaintyin\n",
      "cialIntelligence,2007.[9]RobertKleinberg,AlexanderSlivkins,andEliUpfal.\n",
      "Multi-armedBanditProblemsinMetricSpaces.InSymposiumonTheoryOf\n",
      "Computing,2008.[10]LeventeKocsisandCsabaSzepesv?ari.Banditbased\n",
      "Monte-CarloPlanning.InEuropeanConferenceonMachineLearning,2006.\n",
      "[11]R?emiMunos.OptimisticOptimizationofDeterministicFunctionswith-\n",
      "outtheKnowledgeofitsSmoothness.InNeuralInformationProcessingSys-\n",
      "tems,2011.[12]R?emiMunos.FromBanditstoMonte-CarloTreeSearch:\n",
      "TheOptimisticPrincipleAppliedtoOptimizationandPlanning.Foundations\n",
      "andTrendsinMachineLearning,7(1):1?130,2014.[13]PhilippePreux,R?emi\n",
      "Munos,andMichalValko.BanditsAttackFunctionOptimization.InCongress\n",
      "onEvolutionaryComputation,2014.[14]AleksandrsSlivkins.Multi-armed\n",
      "BanditsonImplicitMetricSpaces.InNeuralInformationProcessingSystems,\n",
      "2011.[15]MichalValko,AlexandraCarpentier,andR?emiMunos.Stochastic\n",
      "SimultaneousOptimisticOptimization.InInternationalConferenceonMachine\n",
      "Learning,2013.\n",
      "9\n",
      "12\n",
      "\n",
      "PP7122.pdf\n",
      "PP7122.pdf 12\n",
      "ImprovingtheExpectedImprovementAlgorithm\n",
      "Authoredby:\n",
      "DanielRusso\n",
      "ChaoQin\n",
      "DiegoKlabjan\n",
      "Abstract\n",
      "Theexpectedimprovement(EI)algorithmisapopularstrategyfor\n",
      "informationcollectioninoptimizationunderuncertainty.Thealgorithm\n",
      "iswidelyknowntobetoogreedy,butneverthelessenjoyswideusedue\n",
      "toitssimplicityandabilitytohandleuncertaintyandnoiseinacoher-\n",
      "entdecisiontheoreticframework.ToproviderigorousinsightintoEI,we\n",
      "studyitspropertiesinasimplesettingofBayesianoptimizationwherethe\n",
      "domainconsistsofagridofpoints.Thisistheso-calledbest-arm\n",
      "idenproblem,wherethegoalistoallocatemeasurement\n",
      "wiselytotlyidentifythebestarmusingasmallnumberofmea-\n",
      "surements.Inthisframework,onecanshowformallythatEIisfarfrom\n",
      "optimal.Toovercomethisshortcoming,weintroduceasimplemo\n",
      "cationoftheexpectedimprovementalgorithm.Surprisingly,thissimple\n",
      "changeresultsinanalgorithmthatisasymptoticallyoptimalforGaussian\n",
      "best-armidenproblems,andprovablyoutperformsstandardEI\n",
      "byanorderofmagnitude.\n",
      "1PaperBody\n",
      "RecentlyBayesianoptimizationhasreceivedmuchattentioninthemachine\n",
      "learningcommunity[21].Thisliteraturestudiestheproblemofmaximizing\n",
      "anunknownblack-boxobjectivefunctionbycollectingnoisymeasurementsof\n",
      "thefunctionatcarefullychosensamplepoints.Atapriorbeliefoverthe\n",
      "objectivefunctionisprescribed,andthenthestatisticalmodelisse-\n",
      "quentiallyasdataareobserved.Expectedimprovement(EI)[13]isoneofthe\n",
      "mostwidely-usedBayesianoptimizationalgorithms.Itisagreedyimprovement-\n",
      "basedheuristicthatsamplesthepointgreatestexpectedimprovement\n",
      "overthecurrentbestsampledpoint.EIissimpleandreadilyimplementable,\n",
      "anditreasonableperformanceinpractice.AlthoughEIisreasonablyef-\n",
      "fective,itistoogreedy,focusingnearlyallsamplingneartheestimated\n",
      "optimumandgatheringtoolittleinformationaboutotherregionsinthedo-\n",
      "main.ThisphenomenonismosttransparentinthesimplestsettingofBayesian\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizationwherethefunction?sdomainisaitegridofpoints.Thisisthe\n",
      "problemofbest-armidencation(BAI)[1]inamultiarmedbandit.Theplayer\n",
      "sequentiallyselectsarmstomeasureandobservesnoisyrewardsampleswiththe\n",
      "hopethatasmallnumberofmeasurementsenableatidenof\n",
      "thebestarm.RecentlyRyzhov[20]studiedtheperformanceofEIinthisset-\n",
      "ting.HisworkfocusesonalinkbetweenEIandanotheralgorithmknownasthe\n",
      "optimalcomputingbudgetallocation[3],buthisanalysisrevealsEIallocates\n",
      "avanishingproportionofsamplestosuboptimalarmsasthetotalnumberof\n",
      "samplesgrows.AnymethodwiththispropertywillbefarfromoptimalinBAI\n",
      "problems[1].31stConferenceonNeuralInformationProcessingSystems(NIPS\n",
      "2017),LongBeach,CA,USA.\n",
      "Inthispaper,weimprovetheEIalgorithmdramaticallythroughasimple\n",
      "moTheresultingalgorithm,whichwecalltop-twoexpectedimprove-\n",
      "ment(TTEI),combinesthetop-twosamplingideaofRusso[19]withacareful\n",
      "changetotheimprovement-measureusedbyEI.Weshowthatthissimplevari-\n",
      "antofEIachievesstrongasymptoticoptimalitypropertiesintheBAIproblem,\n",
      "andbenchmarkthealgorithminsimulationexperiments.Ourmaintheoreti-\n",
      "calcontributionisacompletecharacterizationoftheasymptoticproportionof\n",
      "samplesTTEIallocatestoeacharmasafunctionofthetrue(unknown)arm\n",
      "means.Theseparticularsamplingproportionshavebeenshowntobeoptimal\n",
      "fromseveralperspectives[4,12,9,19,8],andthisenablesustoestablishtwo\n",
      "toptimalityresultsforTTEI.Theconcernstherateatwhichthe\n",
      "algorithmgainsabouttheidentityoftheoptimalarmasthetotal\n",
      "numberofsamplescollectedgrows.Nextwestudytheso-called\n",
      "dencesetting,wherethealgorithmisabletostopatanypointandreturnan\n",
      "estimateoftheoptimalarm.Weshowthatwhenappliedwiththestoppingrule\n",
      "ofGarivierandKaufmann[8],TTEIessentiallyminimizestheexpectednumber\n",
      "ofsamplesrequiredamongallrulesobeyingaconstraintontheprobabilityof\n",
      "incorrectselection.Oneundesirablefeatureofouralgorithmisitsdependence\n",
      "onatuningparameter.Ourtheoreticalresultspreciselyshowtheimpactof\n",
      "thisparameter,andrevealasurprisingdegreeofrobustnesstoitsvalue.Itis\n",
      "alsoeasytodesignmethodsthatadaptthisparameterovertimetotheoptimal\n",
      "value,andweexploreonesuchmethodinsimulation.Still,removingthistuning\n",
      "parameterisaninterestingdirectionforfutureresearch.Furtherrelatedlitera-\n",
      "ture.DespitethepopularityofEI,itstheoreticalpropertiesarenotwellstudied.\n",
      "AnotableexceptionistheworkofBull[2],whostudiesaglobaloptimization\n",
      "problemandprovidesaconvergencerateforEI?sexpectedloss.However,itis\n",
      "assumedthattheobservationsarenoiseless.Ourworkalsorelatestoalarge\n",
      "numberofrecentmachinelearningpapersthattrytocharacterizethesample\n",
      "complexityofthebest-armidenproblem[5,18,1,7,14,10,11,15?\n",
      "17].Despitesubstantialprogress,matchingasymptoticupperandlowerbounds\n",
      "remainedelusiveinthislineofwork.Buildingonolderworkinstatistics[4,\n",
      "12]andsimulationoptimization[9],recentworkofGarivierandKaufmann[8]\n",
      "andRusso[19]characterizedtheoptimalsamplingproportions.Twonotionsof\n",
      "asymptoticoptimalityareestablished:samplecomplexityinthe\n",
      "settingandrateofposteriorconvergence.GarivierandKaufmann[8]developed\n",
      "2\n",
      "\n",
      "twosamplingrulesdesignedtocloselytracktheasymptoticoptimalproportions\n",
      "andshowedthat,whencombinedwithastoppingrulemotivatedby\n",
      "[4],thissamplingruleminimizestheexpectednumberofsamplesrequiredto\n",
      "guaranteeavanishingthresholdontheprobabilityofincorrectselectionissatis-\n",
      "Russo[19]independentlyproposedthreesimpleBayesianalgorithms,and\n",
      "provedthateachalgorithmattainstheoptimalrateofposteriorconvergence.\n",
      "TTEIproposedinthispaperisconceptuallymostsimilartothetop-twovalue\n",
      "samplingofRusso[19],butitismorecomputationallyt.1.1\n",
      "MainContributions\n",
      "Asdiscussedbelow,ourworkmakesboththeoreticalandalgorithmiccon-\n",
      "tributions.Theoretical:OurmaintheoreticalcontributionisTheorem1,which\n",
      "establishesthatTTEI?asimplemotoapopularBayesianheuris-\n",
      "tic?convergestotheknownoptimalasymptoticsamplingproportions.Itis\n",
      "worthemphasizingthat,unlikerecentresultsforothertop-twosamplingalgo-\n",
      "rithms[19],thistheoremestablishesthattheexpectedtimetoconvergetothe\n",
      "optimalproportionsiswhichweneedtoestablishoptimalityinthe\n",
      "setting.Provingthisresultrequiredsubstantialtechnicalinnova-\n",
      "tions.Theorems2and3areadditionaltheoreticalcontributions.Thesemirror\n",
      "resultsin[19]and[8],butweextractminimalconditionsonsamplingrulesthat\n",
      "areienttoguaranteethetwonotionsofoptimalitystudiedinthesepapers.\n",
      "Algorithmic:Onthealgorithmicside,wesubstantiallyimproveawidelyused\n",
      "algorithm.TTEIcanbeeasilyimplementedbymodifyingexistingEIcode,\n",
      "but,asshowninourexperiments,cananorderofmagnitudeimprove-\n",
      "ment.AmoresubtlepointinvolvestheadvantagesofTTEIoveralgorithms\n",
      "thataredesignedtodirectlytargetconvergenceontheasymptoticallyoptimal\n",
      "proportions.Intheexperiments,weshowthatTTEIsubstantiallyoutperforms\n",
      "anoraclesamplingrulewhosesamplingproportionsdirectlytracktheasymp-\n",
      "toticallyoptimalproportions.Thisphenomenonshouldbeexploredfurtherin\n",
      "futurework,butsuggeststhat2\n",
      "bycarefullyreasoningaboutthevalueofinformationTTEIaccountsfor\n",
      "importantfactorsthatarewashedoutinasymptoticanalysis.Finally?asdis-\n",
      "cussedintheconclusion?althoughwefocusonuncorrelatedpriorswebelieve\n",
      "ourmethodcanbeeasilyextendedtomorecomplicatedproblemslikethatof\n",
      "best-armideninlinearbandits[22].\n",
      "2\n",
      "ProblemFormulation\n",
      "LetA=\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      "bethesetofarms.Ateachtimen?N=\n",
      "f\n",
      "0,1,2,\n",
      "...\n",
      "g\n",
      ",anarmIn?Aismeasured,andanindependentnoisyrewardYn,Inis\n",
      "observed.TherewardYn,i?Rofarmiattimenfollowsanormaldistribution\n",
      "N(?i,?2)withcommonknownvariance?2,butunknownmean?i.\n",
      "Theobjectiveistoallocatemeasurementwiselyinordertotly\n",
      "identifythearmwithhighestmeanusingasmallnumberofmeasurements.We\n",
      "assumethat?1>?2>...>?k.Ouranalysistakesplaceinafrequentist\n",
      "setting,inwhichthetruemeans(?1,...,?k)arebutunknown.The\n",
      "algorithmswestudy,however,areBayesianinthesensethattheybeginwith\n",
      "prioroverthearmmeansandupdatethebelieftoformaposteriordistribution\n",
      "3\n",
      "\n",
      "asevidenceisgathered.PriorandPosteriorDistributions.Thesamplingrules\n",
      "studiedinthispaperbeginwithanormally2distributedprioroverthetrue\n",
      "meanofeacharmi?AdenotedbyN(?0,i,?0,i),andupdatethistoforma\n",
      "posteriordistributionasobservationsaregathered.Byconjugacy,theposterior\n",
      "distributionafterobservingthesequence(I0,Y0,I0,...,In?1,Yn?1,In?1)\n",
      "isalsoanormaldistributiondenoted2byN(?n,i,?n,i).Theposteriormean\n",
      "andvariancecanbecalculatedusingthefollowingrecursiveequations:?2?2\n",
      "(?n,i?n,i+??2Yn,i)/(?n,i+??2)ifIn=i,?n+1,i=?n,i,ifIn6=i,and\n",
      "2?n+1,i\n",
      "=\n",
      "?21/(?n,i+??2)ifIn=i,.2?n,i,ifIn6=i.\n",
      "Wedenotetheposteriordistributionoverthevectorofarmmeansby222\n",
      "?n=N(?n,1,?n,1)?N(?n,2,?n,2)?????N(?n,k,?n,k)\n",
      "andlet?=(?1,...,?k).Forexample,withthisnotation\"#XX\n",
      "E???n?i=?n,i.i?A\n",
      "i?A\n",
      "Theposteriorprobabilityassignedtotheeventthatarmiisoptimalis\n",
      "?n,i,P???n?i>max?j.j6=i\n",
      "(1)\n",
      "Toavoidconfusion,wealwaysuse?=(?1,...,?k)todenotea\n",
      "randomvectorofarmmeansdrawnfromthealgorithm?sposterior?n,and\n",
      "?=(?1,...,?k)todenotethevectoroftruearmmeans.Twonotions\n",
      "ofasymptoticoptimality.Ournotionofoptimalityrelatestotherateof\n",
      "posteriorconvergence.Asthenumberofobservationsgrows,onehopesthat\n",
      "theposteriordistributionelyidenthetruebestarm,inthesense\n",
      "thattheposteriorprobability1??n,1assignedbytheeventthatat\n",
      "armisoptimaltendstozero.Bysamplingthearmsintelligently,wehopethis\n",
      "probabilitycanbedriventozeroasrapidlyaspossible.FollowingRusso[19],\n",
      "weaimtomaximizetheexponentgoverningtherateofdecay,liminf?n??\n",
      "1log(1??n,1),n\n",
      "amongallsamplingrules.Thesecondsettingweconsiderisoftencalled\n",
      "thesetting.Here,theagentisallowedatanypointtostop\n",
      "gatheringsamplesandreturnanestimateoftheidentityoftheoptimal.In\n",
      "additiontoasamplingrule,werequireastoppingrulethatselectsatime?at\n",
      "whichtostop,and3\n",
      "adecisionrulethatreturnsanestimateI??oftheoptimalarmbasedonthe\n",
      "?observations.Weconsiderminimizingtheaveragenumberofobservations\n",
      "E[??]requiredbyanalgorithm(thatconsistsofasamplingrule,astopping\n",
      "ruleandadecisionrule)guaranteeingavanishingprobability?ofincorrect\n",
      "ideni.e.,P(I???6=1)??.FollowingGarivierandKaufmann[8],the\n",
      "numberofsamplesrequiredscaleswithlog(1/?),andsoweaimtominimizelim\n",
      "sup??0\n",
      "E[??]log(1/?)\n",
      "amongallalgorithmswithprobabilityoferrornomorethan?.Inthis\n",
      "setting,westudytheperformanceofsamplingruleswhencombinedwiththe\n",
      "stoppingrulestudiedby[4]andGarivierandKaufmann[8].\n",
      "4\n",
      "\n",
      "3\n",
      "SamplingRules\n",
      "Inthissection,weintroducetheexpectedimprovementalgorithm,and\n",
      "pointoutitsweakness.Thenasimplevariantoftheexpectedimprovement\n",
      "algorithmisproposed.Bothalgorithmsmakecalculationsusingfunctionf(x)\n",
      "=x?(x)+?(x)where?(?)and?(?)aretheCDFandPDFofthestandard\n",
      "normaldistribution.Onecanshowthatasx??,logf(?x)??x2/2,andso2f\n",
      "(?x)?e?x/2forverylargex.Onecanalsoshowthatfisanincreasingfunction.\n",
      "ExpectedImprovement.Expectedimprovement[13]isasimpleimprovement-\n",
      "basedsamplingrule.TheEIalgorithmfavorsthearmthatthelargest\n",
      "amountofimprovementuponatarget.TheEIalgorithmmeasuresthearmIn\n",
      "=argmaxi?Avn,iwherevn,iistheEIvalueofarmiattimen.LetIn?=\n",
      "argmaxi?A?n,idenotethearmwithlargestposteriormeanattimen.TheEI\n",
      "valueofarmiattimenisash+ivn,i,E???n?i??n,In?.wherex+\n",
      "=max\n",
      "f\n",
      "x,0\n",
      "g\n",
      ".Theaboveexpectationcanbecomputedanalyticallyasfollows,\n",
      "?n,i??n,In??n,i??n,In??n,i??n,In?+?n,i?=?n,if.vn,i=\n",
      "?n,i??n,In???n,i?n,i?n,iTheEIvaluevn,imeasuresthepotentialofarm\n",
      "itoimproveuponthelargestposteriormean?n,In?attimen.Becausefis\n",
      "anincreasingfunction,vn,iisincreasinginboththeposteriormean?n,iand\n",
      "posteriorstandarddeviation?n,i.Top-TwoExpectedImprovement.TheEI\n",
      "algorithmcanhaveverypoorperformanceforselectingthebestarm.Oncethe\n",
      "posteriorindicatesaparticulararmisthebestwithreasonablyhighprobability,\n",
      "EIallocatesnearlyallfuturesamplestothisarmattheexpenseofmeasuring\n",
      "otherarms.RecentlyRyzhov[20]showedthatEIonlyallocatesO(logn)sam-\n",
      "plestosuboptimalarmsasymptotically.Thisisasevereshortcoming,asit\n",
      "meansnmustbeextremelylargebeforethealgorithmhasenoughsamplesfrom\n",
      "suboptimalarmstoreachatconclusion.ToimprovetheEIalgorithm,\n",
      "webuildonthetop-twosamplingideainRusso[19].Theideaistoidentifyin\n",
      "eachperiodthetwo?mostpromising?armsbasedoncurrentobservations,and\n",
      "randomizetochoosewhichtosample.Atuningparameter??(0,1)controls\n",
      "theprobabilityassignedtothe?top?arm.Anaivetop-twovariantofEIwould\n",
      "identifythetwoarmswithlargestEIvalue,anda??weightedcointodecide\n",
      "whichtomeasure.However,onecanprovethatthisalgorithmisnotoptimal\n",
      "foranychoiceof?.Instead,whatwecallthetop-twoexpectedimprovement\n",
      "algorithmusesanovelmoEIcriterionwhichmorecarefullyaccountsfor\n",
      "thedecision-maker?suncertaintywhendecidingwhicharmtosample.Fori,j\n",
      "?A,vn,i,j,E???n[(?i??j)+].Thismeasurestheexpectedmagnitude\n",
      "ofimprovementarmioverarmj,butunlikethetypicalEIcriterion,this\n",
      "expectationintegratesovertheuncertainqualityofbotharms.Thismeasure\n",
      "canbecomputedanalyticallyas??q?n,i??n,j?2+?2f?qvn,i,j=?n,i.\n",
      "n,j2+?2?n,in,j4\n",
      "TTEIdependsonatuningparameter?>0,setto1/2bydefault.With\n",
      "probability?,TTEImeasures(1)(2)thearmInbyoptimizingtheEIcriterion,\n",
      "andotherwiseitmeasuresanalternativeInthat(1)thelargestexpected\n",
      "improvementonthearmIn.Formally,TTEImeasuresthearm((1)In=arg\n",
      "maxi?Avn,i,withprobability?,In=(2)In=argmaxi?Avn,i,I(1),with\n",
      "5\n",
      "\n",
      "probability1??.n\n",
      "Notethatvn,i,i=0,whichimplies\n",
      "(2)In\n",
      "6=\n",
      "(1)In.\n",
      "WenoticethatTTEIwith?=1isthestandardEIalgorithm.Comparingto\n",
      "theEIalgorithm,TTEIwith??(0,1)allocatesmuchmoremeasurement\n",
      "tosuboptimalarms.WewillseethatTTEIallocates?proportionofsamples\n",
      "tothebestarmasymptotically,anditusestheremaining1??fractionof\n",
      "samplesforgatheringevidenceagainsteachsuboptimalarm.\n",
      "4\n",
      "ConvergencetoAsymptoticallyOptimalProportions\n",
      "Pn?1Foralli?Aandn?N,weTn,i,`=01\n",
      "f\n",
      "I`=i\n",
      "g\n",
      "tobethe\n",
      "numberofsamplesofarmibeforetimen.WewillshowthatunderTTEI\n",
      "withparameter?,limn??Tn,1/n=?.Thatis,thealgorithmasymptotically\n",
      "allocates?proportionofthesamplestotruebestarm.Droppingforthe\n",
      "momentquestionsregardingtheimpactofthistuningparameter,letusconsider\n",
      "theoptimalasymptoticproportionoftoallocatetoeachofthek?1\n",
      "remainingarms.ItisknownthatthePkoptimalproportionsaregivenbythe\n",
      "uniquevector(w2?,???,wk?)satisfyingi=2wi?=1??and(?1??2)2\n",
      "1/?+\n",
      "1/w2?\n",
      "=...=\n",
      "(?1??k)21/?+1/wk?\n",
      ".\n",
      "(2)\n",
      "Wesetw1?=?,sow?=w1?,...,wk?encodesthesamplingproportions\n",
      "ofeacharm.Tounderstandthesourceofequation(2),imaginethatoverthe\n",
      "nperiodseacharmiissampled2exactlywi?ntimes,andlet??n,i?N\n",
      "?i,w??ndenotetheempiricalmeanofarmi.Theni!\n",
      "1?2122+?.??n,1???n,i?N?1??i,??iwhere??i=n\n",
      "?wiTheprobability??n,1???n,i?0?leadingtoanincorrectestimateof\n",
      "whicharmhashighestmean?is?((?i??1)/??i)where?istheCDFof\n",
      "thestandardnormaldistribution.Equation(2)isequivalenttorequiring(?1\n",
      "??i)/??iisequalforallarmsi,sotheprobabilityoffalselydeclaring?i?\n",
      "?1isequalforalli6=1.Inasense,thesesamplingfrequenciesequalizethe\n",
      "evidenceagainsteachsuboptimalarm.Theseproportionsappearedinthe\n",
      "machinelearningliteraturein[19,8],butappearedmuchearlierinthestatistics\n",
      "literaturein[12],andseparatelyinthesimulationoptimizationliteraturein[9].\n",
      "Aswewillseeinthenextsection,convergencetothisallocationisanecessary\n",
      "conditionforbothnotionsofoptimalityconsideredinthispaper.Ourmain\n",
      "theoreticalcontributionisthefollowingtheorem,whichestablishesthatunder\n",
      "TTEIsamplingproportionsconvergetotheproportionsw?derivedabove.\n",
      "Therefore,whilethesamplingproportionoftheoptimalarmiscontrolledbythe\n",
      "tuningparameter?,theremaining1??fractionofmeasurementisoptimally\n",
      "distributedamongtheremainingk?1arms.Sucharesultwasestablished\n",
      "6\n",
      "\n",
      "forothertop-twosamplingalgorithmsin[19].Thesecondnotionofoptimality\n",
      "requiresnotjustconvergencetow?withprobability1,butalsoasenseinwhich\n",
      "theexpectedtimeuntilconvergenceisThefollowingtheorempresents\n",
      "suchastrongerresultforTTEI.Tomakethisprecise,weintroduceatime\n",
      "afterwhichforeacharm,theempiricalproportionallocatedtoitisaccurate.\n",
      "Sp,given??(0,1)and>0,we\n",
      "M?,infN?N:max|Tn,i/n?wi?|??n?N.(3)i?A\n",
      "ItisclearthatP(M?<?)=1forall>0ifandonlyifTn,i/n?wi?with\n",
      "probability1foreacharmi?A.Toestablishoptimalityinthe\n",
      "setting?,weneedtoproveinadditionthatE[M?]<?forall>0,whichrequires\n",
      "substantialnewtechnicalinnovations.5\n",
      "Theorem1.UnderTTEIwithparameter??(0,1),E[M?]<?forany>0.\n",
      "ThisresultimpliesthatunderTTEI,P(M?<?)=1forall>0,orequivalently\n",
      "lim\n",
      "n??\n",
      "4.1\n",
      "Tn,i=wi?n\n",
      "?i?A.\n",
      "ProblemComplexityMeasure\n",
      "Given??(0,1),theproblemcomplexitymeasure???,\n",
      "(???k)2(???2)2=...=11,2?21/?+1/w2?2?21/?+1/wk?\n",
      "whichisafunctionofthetruearmmeansandvariances.Thiswillbethe\n",
      "exponentgoverningtherateofposteriorconvergence,andalsocharacterizing\n",
      "theaveragenumberofsamplesinthestetting.Theoptimal\n",
      "exponentcomesfrommaximizingover?.Letus??=max??(0,1)???\n",
      "and??=argmax??(0,1)???andset\n",
      "???w?=w?=??,w2?,...,wk?.n?o?Russo[19]hasproved\n",
      "thatfor??(0,1),??????/max??,1??,andtherefore??1/2???/2.1??\n",
      "Thisdemonstratesasurprisingdegreeofrobustnessto?.Inparticular,??is\n",
      "closeto??if?isadjustedtobecloseto??,andthechoiceof?=1/2always\n",
      "yieldsa2-approximationto??.\n",
      "5\n",
      "ImpliedOptimalityResults\n",
      "ThissectionestablishesformaloptimalityguaranteesforTTEI.Bothresults,\n",
      "infact,holdforanyalgorithmsatisfyingtheconclusionsofTheorem1,andare\n",
      "thereforeofbroaderinterest.5.1\n",
      "OptimalRateofPosteriorConvergence\n",
      "Weprovideupperandlowerboundsontheexponentgoverningtherate\n",
      "ofposteriorconvergence.ThesameresulthasbeenhasbeenprovedinRusso\n",
      "[19]forboundedcorrelatedpriors.Weusetprooftechniquestoprove\n",
      "thefollowingresultforuncorrelatedGaussianpriors.?\n",
      "Thistheoremshowsthatnoalgorithmcanattainarateofposteriorconver-\n",
      "gencefasterthane??nandthatthisisattainedbyanyalgorithmthat,like\n",
      "TTEIwithoptimaltuningparameter??,hasasymptoticsamplingratios(w1?\n",
      ",...,wk?).ThesecondpartimpliesTTEIwithparameter?attains?con-\n",
      "vergenceratee?n??andthatitisoptimalamongsamplingrulesthatallocation\n",
      "7\n",
      "\n",
      "??fractionofsamplestotheoptimalarm.Recallthat,withoutlossofgenerality,\n",
      "wehaveassumedarm1isthearmwithtruehighestmean?1=maxi?A?i.We\n",
      "willstudytheposteriormass1??n,1assignedtotheeventthatsomeotherhas\n",
      "thehighestmean.Theorem2(PosteriorConvergence-tConditionfor\n",
      "Optimality).Thefollowingpropertiesholdwithprobability1:1.Underany\n",
      "samplingrulethatTn,i/n?wi?foreachi?A,lim?\n",
      "n??\n",
      "1log(1??n,1)=??.n\n",
      "Underanysamplingrule,limsup?n??\n",
      "1log(1??n,1)???.n\n",
      "2.Let??(0,1).UnderanysamplingrulethatTn,i/n?wi?for\n",
      "eachi?A,lim?\n",
      "n??\n",
      "1log(1??n,1)=???.n6\n",
      "UnderanysamplingrulethatTn,1/n??,limsup?n??\n",
      "1log(1??n,1)????.n\n",
      "Thisresultrevealsthatwhenthetuningparameter?issetoptimallyto??\n",
      ",TTEIattainstheoptimalrateofposteriorconvergence.Since??1/2???/2,\n",
      "when?issettothedefaultvalue1/2,theexponentgoverningtheconvergence\n",
      "rateofTTEIisatleasthalfoftheoptimalone.5.2\n",
      "OptimalAverageSampleSize\n",
      "?sStoppingRule.Inthesetting,besidesant\n",
      "samplingrule,aplayeralsoneedstodesignanintelligentstoppingrule.This\n",
      "sectionintroducesastoppingruleproposedby[4]andstudiedrecently\n",
      "byGarivierandKaufmann[8].ThisstoppingrulemakesuseoftheGeneralized\n",
      "LikelihoodRatiostatistic,whichdependsonthecurrentmaximumlikelihood\n",
      "estimatesofallunknownmeans.Foreacharmi?A,themaximumlikelihood\n",
      "estimate?1Pn?1ofitsunknownmean?iattimenisitsempiricalmean??n,i\n",
      "=Tn,i1\n",
      "f\n",
      "I`=i\n",
      "g\n",
      "Y`,I`where`=0Pn?1Tn,i=`=01\n",
      "f\n",
      "I`=i\n",
      "g\n",
      ".Nextwea\n",
      "weightedaverageofempiricalmeansofarmsi,j?A:??n,i,j,\n",
      "Tn,iTn,j??n,i+??n,j.Tn,i+Tn,jTn,i+Tn,j\n",
      "Thenif??n,i???n,j,theGeneralizedLikelihoodRatiostatisticZn,i,j\n",
      "hasthefollowingexplicitexpression:Zn,i,j,Tn,id(??n,i,??n,i,j)+Tn,j\n",
      "d(??n,j,??n,i,j)whered(x,y)=(x?y)2/(2?2)istheKullback-Leibler\n",
      "(KL)divergencebetweenGaussiandistributionsN(x,?2)andN(y,?2).\n",
      "Similarly,if??n,i<??n,j,Zn,i,j=?Zn,j,i?0whereZn,j,iiswellas\n",
      "above.Ifeitherarmhasneverbeensampledbefore,thesequantitiesarenot\n",
      "wellandwetaketheconventionthatZn,i,j=Zn,j,i=0.Givenatarget\n",
      "??(0,1),toensurethatonearmisbetterthantheotherswith\n",
      "probabilityatleast1??,weusethestoppingtime\n",
      "??,infn?N:Zn,maxminZn,i,j>?n,?i?Aj?A\n",
      "f\n",
      "i\n",
      "g\n",
      "where?n,?>0isanappropriatethreshold.Byminj?A\n",
      "f\n",
      "i\n",
      "g\n",
      "Zn,i,j\n",
      "isnonnegativeif?n,iisunique,andonlyif??n,i???n,jforallj?A\n",
      "f\n",
      "i\n",
      "g\n",
      ".\n",
      "Hence,wheneverI?n?,argmaxi?A?Zn=minj?A\n",
      "f\n",
      "I??\n",
      "g\n",
      "Zn,I??,j.n\n",
      "n\n",
      "8\n",
      "\n",
      "Nextweintroducetheexplorationratefornormalbanditmodelsthatcan\n",
      "ensuretoidentifythebestarmwithprobabilityatleast1??.Weusethe\n",
      "followingresultgiveninGarivierandKaufmann[8].Proposition1(Garivier\n",
      "andKaufmann[8]Proposition12).Let??(0,1)and?>1.Thereexistsa\n",
      "constantC=C(?,k)suchthatunderanysamplingrule,usingtheChern?s\n",
      "stoppingrulewith?thethreshold?n,?=log(Cn?/?)guarantees\n",
      "P??<?,argmax????,i6=1??.i?A\n",
      "SampleComplexity.GarivierandKaufmann[8]recentlyprovidedageneral\n",
      "lowerboundonthenumberofsamplesrequiredinthesetting.\n",
      "Inparticular,theyshowthatforanynormalbanditmodel,underanysampling\n",
      "ruleandstoppingtime??thatguaranteesaprobabilityoferrornomorethan\n",
      "?,E[??]1liminf??.??0log(1/?)?RecallthatM?,in(3),isthe\n",
      "timeafterwhichtheempiricalproportionsarewithinoftheirasymptotic\n",
      "limits.ThenextresultprovidesaconditionintermsofM?thatistto\n",
      "guaranteeoptimalityinthesetting.7\n",
      "Theorem3(Fixed-tConditionforOptimality).Let\n",
      "?,??(0,1)and?>1.Underanysamplingrulewhich,ifappliedwithno\n",
      "stoppingrule,E[M?]<?forall>0,?=log(Cn?/?)(whereC=\n",
      "C(?,k))usingthe?sstoppingrulewiththethreshold?n,?guarantees\n",
      "E[??]1limsup??.log(1/?)????0When?=??thegenerallowerbound\n",
      "onsamplecomplexityof1/??isessentiallymatched.Inaddition,when?is\n",
      "settothedefaultvalue1/2,thesamplecomplexityofTTEIcombinedwiththe\n",
      "?sstoppingruleisatmosttwicetheoptimalsamplecomplexitysince\n",
      "1/??1/2?2/??.\n",
      "6\n",
      "NumericalExperiments\n",
      "TotesttheempiricalperformanceofTTEI,weconductseveralnumerical\n",
      "experiments.TheexperimentcomparestheperformanceofTTEIwith?\n",
      "=1/2andEI.Thesecondexperimentcomparestheperformanceoft\n",
      "versionsofTTEI,top-twoThompsonsampling(TTTS)[19],knowledgegradient\n",
      "(KG)[6]andoraclealgorithmsthatknowtheoptimalproportionsapriori.Each\n",
      "algorithmplaysarmi=1,...,kexactlyonceatthebeginning,andthen\n",
      "prescribeapriorN(Yi,i,?2)forunknownarm-mean?iwhereYi,iisthe\n",
      "observationfromN(?i,?2).Inbothexperiments,wexthecommonknown\n",
      "variance?2=1andthenumberofarmsk=5.Weconsiderthreeinstances[?1\n",
      ",...,?5]=[5,4,1,1,1],[5,4,3,2,1]and[2,0.8,0.6,0.4,0.2].Theoptimal\n",
      "parameter??equals0.48,0.45and0.35,respectively.Recallthat?n,i,\n",
      "in(1),denotestheposteriorprobabilitythatarmiisoptimal.Tables1and\n",
      "2showtheaveragenumberofmeasurementsrequiredforthelargestposterior\n",
      "probabilityassignedtosomearmbeingthebesttoreachagiven\n",
      "levelc,i.e.,maxi?n,i?c.InaBayesiansetting,theprobabilityofcorrect\n",
      "selectionunderthisruleisexactlyc.TheresultsinTable1areaveragedover\n",
      "100trials.WeseethatTTEIwith?=1/2outperformsstandardEIbyanorder\n",
      "ofmagnitude.Table1:Averagenumberofmeasurementsrequiredtoreachthe\n",
      "levelc=0.95[5,4,1,1,1][5,4,3,2,1][2,.8,.6,.4,.2]\n",
      "TTEI-1/214.6016.7224.39\n",
      "9\n",
      "\n",
      "EI238.50384.731525.42\n",
      "Thesecondexperimentcomparestheperformanceoftversionsof\n",
      "TTEI,TTTS,KG,arandomsamplingoracle(RSO)andatrackingoracle(TO).\n",
      "Therandomsamplingoracledrawsarandomarmineachroundfromthedis-\n",
      "tributionw?encodingtheasymptoticallyoptimalproportions.Thetracking\n",
      "oracletrackstheoptimalproportionsateachround.Sp,thetracking\n",
      "oraclesamplesthearmwiththelargestratioitsoptimalandempiricalpro-\n",
      "portions.TwotrackingalgorithmsproposedbyGarivierandKaufmann[8]are\n",
      "similartothistrackingoracle.TTEIwithadaptive?(aTTEI)worksasfol-\n",
      "lows:itstartswith?=1/2andupdates?=???every10roundswhere???\n",
      "isthemaximizerofequation(2)basedonplug-inestimatorsfortheunknown\n",
      "arm-means.Table2showstheaveragenumberofmeasurementsrequiredfor\n",
      "thelargestposteriorprobabilitybeingthebesttoreachthelevelc\n",
      "=0.9999.TheresultsinTable2areaveragedover200trials.Weseethatthe\n",
      "performancesofTTEIwithadaptive?andTTEIwith??arebetterthan\n",
      "theperformancesofallotheralgorithms.WenotethatTTEIwithadaptive\n",
      "?substantiallyoutperformsthetrackingoracle.Table2:Averagenumberof\n",
      "measurementsrequiredtoreachthelevelc=0.9999[5,4,1,1,1][5,\n",
      "4,3,2,1][2,.8,.6,.4,.2]\n",
      "TTEI-1/261.9766.5676.21\n",
      "aTTEI61.9865.5472.94\n",
      "TTEI-??61.5965.5571.62\n",
      "TTTS-??62.8666.5373.02\n",
      "RSO97.04103.43101.97\n",
      "TO77.7688.0296.90\n",
      "KG75.5581.4986.98\n",
      "InadditiontotheBayesianstoppingruletestedabove,wehaverunsomeex-\n",
      "perimentswiththestoppingrulediscussedinSection5.2.Asymptotic\n",
      "analysisshowsthesetworulesare8\n",
      "similarwhenthelevelcisveryhigh.However,the\n",
      "stoppingruleappearstobetooconservativeinpractice;ittypicallyyieldsa\n",
      "probabilityofcorrectselectionmuchlargerthanthespdencelevelc\n",
      "attheexpenseofusingmoresamples.Sinceourcurrentfocusisonallocation\n",
      "rules,wefocusonthisBayesianstoppingrule,whichappearstoamore\n",
      "fundamentalcomparisonthanonebasedonadhocchoiceoftuningparameters.\n",
      "Developingimprovedstoppingrulesisanimportantareaforfutureresearch.\n",
      "7\n",
      "ConclusionandExtensionstoCorrelatedArms\n",
      "WeconcludebynotingthatwhilethispaperthoroughlystudiesTTEIin\n",
      "thecaseofuncorrelatedpriors,webelievethealgorithmisalsoideallysuited\n",
      "toproblemswithcomplexcorrelatedpriorsandlargesetsofarms.Infact,the\n",
      "moinformationmeasurevn,i,jwasdesignedwithaneyetowarddealing\n",
      "withcorrelationinasophisticatedway.Inthecaseofacorrelatednormaldis-\n",
      "tributionN(?,?),onehas!p?n,i??n,j+vn,i,j=E??N(?,?)[(?i??j)]=?ii\n",
      "+?jj?2?ijfp.?ii+?jj?2?ijThisclosedformaccommodatestcom-\n",
      "putation.Heretheterm?i,jaccountsforthecorrelationorsimilaritybetween\n",
      "10\n",
      "\n",
      "armsiandj.Thereforevn,i,I(1)islargeforarmsithatlargepotentialn\n",
      "(1)\n",
      "improvementoverIn,i.e.thosethat(1)havelargeposteriormean,(2)have\n",
      "largeposteriorvariance,(1)(1)and(3)arenothighlycorrelatedwitharmIn.\n",
      "AsInconcentratesneartheestimatedoptimum,weexpectthethirdfactorwill\n",
      "forcethealgorithmtoexperimentinpromisingregionsofthedomainthatare\n",
      "?far?awayfromthecurrent-estimatedoptimum,andareunder-exploredunder\n",
      "standardEI.\n",
      "9\n",
      "2References\n",
      "[1]Jean-YvesAudibert,S?bastienBubeck,andR?miMunos.Bestarmiden-\n",
      "inmultiarmedbandits.InCOLT2010-The23rdConferenceon\n",
      "LearningTheory,Haifa,Israel,June27-29,2010,pages41?53,2010.[2]Adam\n",
      "D.Bull.Convergenceratesoftglobaloptimizationalgorithms.Jour-\n",
      "nalofMachineLearningResearch,12:2879?2904,2011.URLhttp://dblp.uni-\n",
      "trier.de/db/journals/jmlr/jmlr12.html#Bull11.[3]Chun-HungChen,Jianwu\n",
      "Lin,EnverY?cesan,andStephenEChick.Simulationbudgetallocationfor\n",
      "furtherenhancingtheofordinaloptimization.DiscreteEventDy-\n",
      "namicSystems,10(3):251?270,2000.[4]HermanSequentialde-\n",
      "signofexperiments.Ann.Math.Statist.,30(3):755?770,091959.doi:\n",
      "10.1214/aoms/1177706205.URLhttp://dx.doi.org/10.1214/aoms/1177706205.\n",
      "[5]EyalEven-dar,ShieMannor,andYishayMansour.Pacboundsformulti-\n",
      "armedbanditandmarkovdecisionprocesses.InInFifteenthAnnualConference\n",
      "onComputationalLearningTheory(COLT),pages255?270,2002.[6]PeterI\n",
      "Frazier,WarrenBPowell,andSavasDayanik.Aknowledge-gradientpolicy\n",
      "forsequentialinformationcollection.SIAMJournalonControlandOptimiza-\n",
      "tion,47(5):2410?2439,2008.[7]VictorGabillon,MohammadGhavamzadeh,\n",
      "andAlessandroLazaric.BestarmidenAapproachto\n",
      "budgetandInF.Pereira,C.J.C.Burges,L.Bottou,and\n",
      "K.Q.Weinberger,editors,AdvancesinNeuralInformationProcessingSystems\n",
      "25,pages3212?3220.CurranAssociates,Inc.,2012.[8]Aur?lienGarivierand\n",
      "EmilieKaufmann.OptimalbestarmidenwithIn\n",
      "Proceedingsofthe29thConferenceonLearningTheory,COLT2016,NewYork,\n",
      "USA,June23-26,2016,pages998?1027,2016.[9]P.GlynnandS.Juneja.A\n",
      "largedeviationsperspectiveonordinaloptimization.InSimulationConference,\n",
      "2004.Proceedingsofthe2004Winter,volume1.IEEE,2004.[10]Kevin\n",
      "Jamieson,MatthewMalloy,RobertNowak,andS?bastienBubeck.lil?ucb\n",
      ":Anoptimalexplorationalgorithmformulti-armedbandits.InMariaFlo-\n",
      "rinaBalcan,VitalyFeldman,andCsabaSzepesv?ri,editors,Proceedingsof\n",
      "The27thConferenceonLearningTheory,volume35ofProceedingsofMa-\n",
      "chineLearningResearch,pages423?439,Barcelona,Spain,13?15Jun2014.\n",
      "PMLR.URLhttp://proceedings.mlr.press/v35/jamieson14.html.[11]Kevin\n",
      "G.JamiesonandRobertD.Nowak.Best-armidenalgorithmsfor\n",
      "11\n",
      "\n",
      "multi-armedbanditsinthesetting.In48thAnnualConfer-\n",
      "enceonInformationSciencesandSystems,CISS2014,Princeton,NJ,USA,\n",
      "March19-21,2014,pages1?6,2014.[12]C.Jennison,I.M.Johnstone,and\n",
      "B.W.Turnbull.Asymptoticallyoptimalproceduresforsequentialadaptive\n",
      "selectionofthebestofseveralnormalmeans.Statisticaldecisiontheoryand\n",
      "relatedtopicsIII,2:55?86,1982.[13]DonaldR.Jones,MatthiasSchonlau,and\n",
      "WilliamJ.Welch.tglobaloptimizationofexpensiveblack-boxfunc-\n",
      "tions.JournalofGlobalOptimization,13(4):455?492,1998.ISSN1573-2916.\n",
      "doi:10.1023/A:1008306431147.URLhttp://dx.doi.org/10.1023/A:1008306431147.\n",
      "[14]ZoharKarnin,TomerKoren,andOrenSomekh.Almostoptimalexplo-\n",
      "rationinmulti-armedbandits.InSanjoyDasguptaandDavidMcAllester,ed-\n",
      "itors,Proceedingsofthe30thInternationalConferenceonMachineLearning,\n",
      "volume28ofProceedingsofMachineLearningResearch,pages1238?1246,At-\n",
      "lanta,Georgia,USA,17?19Jun2013.PMLR.URLhttp://proceedings.mlr.press/v28/karnin13.html.\n",
      "10\n",
      "[15]EmilieKaufmannandShivaramKalyanakrishnan.Informationcom-\n",
      "plexityinbanditsubsetselection.InShaiShalev-ShwartzandIngoSteinwart,\n",
      "editors,Proceedingsofthe26thAnnualConferenceonLearningTheory,volume\n",
      "30ofProceedingsofMachineLearningResearch,pages228?251,Princeton,NJ,\n",
      "USA,12?14Jun2013.PMLR.URLhttp://proceedings.mlr.press/v30/Kaufmann13.html.\n",
      "[16]EmilieKaufmann,OlivierCapp?,andAur?lienGarivier.Onthecomplexity\n",
      "ofa/btesting.InMariaFlorinaBalcan,VitalyFeldman,andCsabaSzepesv?ri,\n",
      "editors,ProceedingsofThe27thConferenceonLearningTheory,volume35of\n",
      "ProceedingsofMachineLearningResearch,pages461?481,Barcelona,Spain,\n",
      "13?15Jun2014.PMLR.URLhttp://proceedings.mlr.press/v35/kaufmann14.html.\n",
      "[17]EmilieKaufmann,OlivierCapp?,andAur?lienGarivier.Onthecomplex-\n",
      "ityofbest-armideninmulti-armedbanditmodels.JournalofMachine\n",
      "LearningResearch,17(1):1?42,2016.URLhttp://jmlr.org/papers/v17/kaufman16a.html.\n",
      "[18]ShieMannor,JohnN.Tsitsiklis,KristinBennett,andNicol?Cesa-bianchi.\n",
      "Thesamplecomplexityofexplorationinthemulti-armedbanditproblem.Jour-\n",
      "nalofMachineLearningResearch,5:2004,2004.[19]DanielRusso.Simple\n",
      "bayesianalgorithmsforbestarmidenIn29thAnnualConference\n",
      "onLearningTheory,pages1417?1418,2016.[20]IlyaO.Ryzhov.Onthe\n",
      "convergenceratesofexpectedimprovementmethods.OperationsResearch,\n",
      "64(6):1515?1528,2016.doi:10.1287/opre.2016.1494.URLhttp://dx.doi.org/\n",
      "10.1287/opre.2016.1494.[21]BobakShahriari,KevinSwersky,ZiyuWang,\n",
      "RyanP.Adams,andNandodeFreitas.Takingthehumanoutoftheloop:A\n",
      "reviewofBayesianoptimization.ProceedingsoftheIEEE,104(1):148?175,\n",
      "2016.doi:10.1109/JPROC.2015.2494218.URLhttp://dx.doi.org/10.1109/\n",
      "JPROC.2015.2494218.[22]MartaSoare,AlessandroLazaric,andR?miMunos.\n",
      "Best-armideninlinearbandits.InAdvancesinNeuralInformation\n",
      "ProcessingSystems,pages828?836,2014.\n",
      "11\n",
      "12\n",
      "\n",
      "PP3807.pdf\n",
      "PP3807.pdf 14\n",
      "TrackingDynamicSourcesofMaliciousActivity\n",
      "atInternetScale\n",
      "Authoredby:\n",
      "AvrimBlum\n",
      "ShobhaVenkataraman\n",
      "DawnSong\n",
      "SubhabrataSen\n",
      "OliverSpatscheck\n",
      "Abstract\n",
      "Weformulateandaddresstheproblemofdiscoveringdynamicmali-\n",
      "ciousregionsontheInternet.Wemodelthisproblemasoneofadaptively\n",
      "pruningaknowndecisiontree,butwithadditionalchallenges:(1)severe\n",
      "spacerequirements,sincetheunderlyingdecisiontreehasover4billion\n",
      "leaves,and(2)achangingtargetfunction,sincemaliciousactivityonthe\n",
      "Internetisdynamic.Wepresentanovelalgorithmthataddressesthis\n",
      "problem,byputtingtogetheranumberoft\\expertsalgorithms\n",
      "andonlinepagingalgorithms.Weproveguaranteesonouralgorithms\n",
      "performanceasafunctionofthebestpossiblepruningofasimilarsize,\n",
      "andourexperimentsshowthatouralgorithmachieveshighaccuracyon\n",
      "largereal-worlddatasets,withtimprovementsoverexistingap-\n",
      "proaches.\n",
      "1PaperBody\n",
      "Itiswidelyacknowledgedthatidentifyingtheregionsthatoriginatemalicious\n",
      "ontheInternetisvitaltonetworksecurityandmanagement,e.g.,in\n",
      "throttlingattackforfastmitigation,isolatinginfectedsub-networks,and\n",
      "predictingfutureattacks[6,18,19,24,26].Inthispaper,weshowhowthis\n",
      "problemcanbemodeledasaversionofaquestionstudiedbyHelmboldand\n",
      "Schapire[11]ofadaptivelylearningagoodpruningofaknowndecisiontree,\n",
      "butwithanumberofadditionalchallengesanddculties.Theseincludea\n",
      "changingtargetfunctionandseverespacerequirementsduetotheenormity\n",
      "oftheunderlyingIPaddress-spacetree.Wedevelopnewalgorithmsableto\n",
      "addressthesethatcombinetheunderlyingapproachof[11]with\n",
      "thesleepingexpertsframeworkof[4,10]andtheonlinepagingproblemof\n",
      "[20].Weshowhowtodealwithanumberofpracticalissuesthatariseand\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demonstrateempiricallyonreal-worlddatasetsthatthismethodsubstantially\n",
      "improvesoverexistingapproachesof/24andnetwork-awareclusters\n",
      "[6,19,24]incorrectlyidentifyingmaliciousOurexperimentsondatasets\n",
      "of126millionIPaddressesdemonstratethatouralgorithmisabletoachievea\n",
      "clusteringthatisbothhighlyaccurateandmeaningful.1.1BackgroundMultiple\n",
      "measurementstudieshaveindicatedthatmalicioustendstoclusterina\n",
      "waythatalignswiththestructureoftheIPaddressspace,andthatthisis\n",
      "trueformanytkindsofmalicious?spam,scanning,botnets,\n",
      "andphishing[6,18,19,24].Suchclusteredbehaviourcanbeeasilyexplained:\n",
      "mostmaliciousoriginatesfromhostsinpoorly-managednetworks,and\n",
      "networksaretypicallyassignedcontiguousblocksoftheIPaddressspace.Thus,\n",
      "itisnaturalthatmaliciousisclusteredinpartsoftheIPaddressspace\n",
      "thatbelongtopoorly-managednetworks.Fromamachinelearningperspective,\n",
      "theproblemofidentifyingregionsofmaliciousactivitycanbeviewedasone\n",
      "ofagoodpruningofaknowndecisiontree?theIPaddressspace\n",
      "maybenaturallyinterpretedasabinarytree(seeFig.1(a)),andthegoalisto\n",
      "learnapruningofthistreethatisnottoolargeandhaslowerrorinclassifying\n",
      "IPaddressesasmaliciousornon-malicious.ThestructureoftheIPaddress\n",
      "spacesuggeststhattheremaywellbeapruningwithonlyamodestnumberof\n",
      "leavesthatcanclassifymostoftheaccurately.Thus,identifyingregionsof\n",
      "maliciousactivityfromanonlinestreamoflabeleddataismuchliketheproblem\n",
      "consideredbyHelmboldandSchapire[11]ofadaptivelylearningagoodpruning\n",
      "ofaknowndecisiontree.However,therearea1\n",
      "numberofreal-worldchallenges,bothconceptualandpractical,thatmust\n",
      "beaddressedinordertomakethissuccessful.Onemajorchallengeinourappli-\n",
      "cationcomesfromthescaleofthedataandsizeofacompletedecisiontreeover\n",
      "theIPaddressspace.AfulldecisiontreeovertheIPv4addressspacewould\n",
      "have232leaves,andovertheIPv6addressspace(whichisslowlybeingrolled\n",
      "out),2128leaves.Withsuchlargedecisiontrees,itiscriticaltohavealgorithms\n",
      "thatdonotbuildthecompletetree,butinsteadoperateinspacecomparableto\n",
      "thesizeofagoodpruning.Thesespaceconstraintsarealsoimportantbecause\n",
      "ofthevolumeofthatmayneedtobeanalyzed?ISPsoftencollectter-\n",
      "abytesofdatadailyandanalgorithmthatneedstostoreallitsdatainmemory\n",
      "simultaneouslywouldbeinfeasible.Asecondchallengecomesfromthefactthat\n",
      "theregionsofmaliciousactivitymayshiftlongitudinallyovertime[25].This\n",
      "mayhappenformanyreasons,e.g.,administratorsmayeventuallydiscoverand\n",
      "cleanupalreadyinfectedbots,andattackersmaytargetnewvulnerabilitiesand\n",
      "attacknewhostselsewhere.Suchdynamicbehaviourisaprimaryreasonwhy\n",
      "individualIPaddressestendtobesuchpoorindicatorsoffuturemalicious\n",
      "[15,26].Thus,wecannotassumethatthedatacomesfromaxeddistribution\n",
      "overtheIPaddressspace;thealgorithmneedstoadapttodynamicnatureof\n",
      "themaliciousactivity,andtrackthesechangesaccuratelyandquickly.Thatis,\n",
      "wemustconsidernotonlyanonlinesequenceofexamplesbutalsoachanging\n",
      "targetfunction.Whiletherehavebeenanumberofmeasurementstudies[6,18,\n",
      "19,24]thathaveexaminedtheoriginofmaliciousfromIPaddressblocks\n",
      "thatarekeptapriori,noneofthesehavefocusedondevelopingonline\n",
      "2\n",
      "\n",
      "algorithmsthatthebestpredictiveIPaddresstree.Ourchallengeistode-\n",
      "velopanthigh-accuracyonlinealgorithmthathandlestheseverespace\n",
      "constraintsinherentinthisproblemandaccountsforthedynamicallychang-\n",
      "ingnatureofmaliciousbehavior.Weshowthatwecanindeeddothis,both\n",
      "provingtheoreticalguaranteesonadaptiveregretanddemonstratingsuccessful\n",
      "performanceonreal-worlddata.1.2ContributionsInthispaper,weformulate\n",
      "andaddresstheproblemofdiscoveringandtrackingmaliciousregionsofthe\n",
      "IPaddressspacefromanonlinestreamofdata.Wepresentanalgorithmthat\n",
      "adaptivelyprunestheIPaddresstreeinawaythatmaintainsatmostmleaves\n",
      "andperformsnearlyaswellastheoptimumadaptivepruningoftheIPaddress\n",
      "treewithacomparablesize.Intuitively,weachievetherequiredadaptivityand\n",
      "thespaceconstraintsbycombiningseveral?experts?algorithmstogetherwith\n",
      "atree-basedversionofpaging.Ourtheoreticalresultsprovethatouralgorithm\n",
      "canpredictnearlyaswellasthebestadaptivedecisiontreewithkleaveswhen\n",
      "usingO(klogk)leaves.Ourexperimentalresultsdemonstratethatouralgo-\n",
      "rithmidenmaliciousregionsoftheIPaddressspaceaccurately,withorders\n",
      "ofmagnitudeimprovementoverpreviousapproaches.Ourexperimentsfocuson\n",
      "classifyingspammersandlegitimatesendersontwomaildatasets,onewith126\n",
      "millionmessagescollectedover38daysfromthemailserversofatier-1ISP,and\n",
      "asecondwith28millionmessagescollectedover6monthsfromanenterprise\n",
      "mailserver.OurexperimentsalsohighlighttheimportanceofallowingtheIP\n",
      "addresstreetobedynamic,andtheresultingviewoftheIPaddressspacethat\n",
      "wegetisbothcompellingandmeaningful.\n",
      "2andPreliminariesWenowpresentsomebasicaswell\n",
      "asourformalproblemstatement.TheIPaddresshierarchycanbenaturally\n",
      "interpretedasafullbinarytree,asinFig.1:theleavesofthetreecorrespond\n",
      "toindividualIPaddresses,andthenon-leafnodescorrespondtotheremaining\n",
      "IPLetPdenotethesetofallIPandIdenotethesetofall\n",
      "IPaddresses.WealsousetermclusterstodenotetheIPWean\n",
      "IPTreeTPtobeapruningofthefullIPaddresstree:atreewhosenodesareIP\n",
      "P?P,andwhoseleavesareeachassociatedwithalabel,i.e.,malicious\n",
      "ornon-malicious.AnIPtreecanthusbeinterpretedasacfunction\n",
      "fortheIPaddressesI:anIPaddressigetsthelabelassociatedwithitslongest\n",
      "matchinginP.Fig.1showsanexampleofanIPtree.Wethesize\n",
      "ofanIPtreetobethenumberofleavesithas.Forexample,inFig.1(a),the\n",
      "sizeoftheIPtreeis6.AsdescribedinSec.1,wefocusononlinelearningin\n",
      "thispaper.Atypicalpointofcomparisonusedintheonlinelearningmodelis\n",
      "theerroroftheoptimalalgorithm.Inthiscase,theoptimal\n",
      "algorithmistheIPtreeofagivensizeki.e.,thetreeofsizekthatmakes\n",
      "2\n",
      "0.0.0.0/0128.0.0.0/1\n",
      "0.0.0.0/10.0.0.0/2\n",
      "192.0.0.0/2\n",
      "+\n",
      "+\n",
      "+\n",
      "3\n",
      "\n",
      "128.0.0.0/4\n",
      "+\n",
      "-\n",
      "160.0.0.0/3\n",
      "152.0.0.0/4\n",
      "(a)AnexampleIPTree\n",
      "(b)ArealIPTree(ColorcodingexplainedinSec.5)\n",
      "Figure1:IPTrees:exampleandreal.RecallthatanIPaddressisinterpreted\n",
      "asa32-bitstring,readfromlefttoright.Thisesapathonthebinary\n",
      "tree,goingleftfor0andrightfor1.AnIPprexisdenotedbyIP/n,where\n",
      "nindicatesthenumberofbitsrelevanttothethefewestmistakeson\n",
      "theentiresequence.However,ifthetrueunderlyingIPtreemaychangeover\n",
      "time,abetterpointofcomparisonwouldallowthetreetoalsochange\n",
      "overtime.Tomakesuchacomparisonmeaningful,thetreemustpayan\n",
      "additionalpenaltyeachtimeitchanges(otherwisethetreewouldnotbe\n",
      "ameaningfulpointofcomparison?itcouldchangeforeachIPaddressinthe\n",
      "sequence,andthusmakenomistakes).Wethereforelimitthekindsofchanges\n",
      "thetreecanmake,andcomparetheperformanceofouralgorithmto\n",
      "everyIPtreewithkleaves,asafunctionoftheerrorsitmakesandthechanges\n",
      "itmakes.WeanadaptiveIPtreeofsizektobeanadaptivetreethatcan\n",
      "(a)grownodesovertimesolongasitneverhasmorethankleaves,(b)change\n",
      "thelabelsofitsleafnodes,and(c)occasionallyitselfcompletely.\n",
      "OurgoalistodevelopanonlinealgorithmTsuchthatforanysequenceofIP\n",
      "addresses,(1)foreveryadaptivetreeT?ofsizek,thenumberofmistakesmade\n",
      "byTisboundedbya(small)functionofthemistakesandthechangesoftypes\n",
      "(a),(b),and(c)madeby?T?,and(2)TusesnomorethanO(k)space.In\n",
      "thenextsection,wedescribeanalgorithmmeetingtheserequirements.\n",
      "3AlgorithmsandAnalysisInthissection,wedescribeourmainalgorithm\n",
      "TrackIPTree,andpresenttheoreticalguaranteesonitsperformance.Atahigh-\n",
      "level,ourapproachkeepsanumberofexpertsineachpoftheIPtree,and\n",
      "combinestheirpredictionstoclassifyeveryIPaddress.Theinherentstruc-\n",
      "tureintheIPtreeallowsustodecomposetheproblemintoanumberofexpert\n",
      "problems,andprovidelowermemoryboundsandbetterguaranteesthanear-\n",
      "lierapproaches.Webeginwithanoverview.thepath-nodesofanIP\n",
      "addresstobethesetofallofiinT,anddenotethissetbyPi,T.\n",
      "TopredictthelabelofanIPi,thealgorithmlooksupallthepathnodesin\n",
      "Pi,T,considerstheirpredictions,andcombinesthesepredictionstoproducea\n",
      "labelfori.Toupdatethetree,thealgorithmrewardsthepath-nodesthat\n",
      "predictedcorrectly,penalizestheincorrectones,andmothetreestructure\n",
      "ifnecessary.Tolloutthisoverview,therearefourtechnicalquestionsthat\n",
      "weneedtoaddress:(1)Ofallthepath-nodesinPi,T,howdowelearnthe\n",
      "onesthatarethemostimportant?(2)Howdowelearnthecorrectlabelto\n",
      "predictataparticularpath-nodeinPi,T(i.e.,positiveornegative)?(3)Howdo\n",
      "wegrowtheIPtreeappropriately,ensuringthatitgrowsprimarilythe\n",
      "neededtoimprovetheaccuracy?(4)Howdoweensurethatthe\n",
      "sizeoftheIPtreestaysboundedbym?Weaddressthesequestionsbytreating\n",
      "4\n",
      "\n",
      "themasseparatesubproblems,andweshowhowtheytogethertobecome\n",
      "thecompletealgorithminFigure3.1.3.1SubproblemsofTrackIPTreeWenow\n",
      "describeouralgorithmindetail.Sinceouralgorithmdecomposesnaturallyinto\n",
      "thefoursubproblemsmentionedabove,wefocusoneachsubproblemseparately\n",
      "tosimplifythepresentation.Weusethefollowingnotationinourdescriptions:\n",
      "RecallfromSec.2thatmisthemaximumnumberofleavesallowedtoour\n",
      "algorithm,kisthesizeoftheoptimaltree,andPi,Tdenotesthesetof\n",
      "path-nodes,i.e.,theofIPiinthecurrentIPtreeT.RelativeImpor-\n",
      "tanceofthePathNodesFirst,weconsidertheproblemofdecidingwhichof\n",
      "thenodesinthepathPi,Tismostimportant.Weformulatethisasa\n",
      "sleepingexpertsproblem[4,10].Wesetanexpertineachnode,andcallthem\n",
      "thepath-nodeexperts,andforanIPi,weconsiderthesetofpath-nodeexperts\n",
      "inPi,Ttobethe?awake?experts,andtheresttobe?asleep?.The3\n",
      "x0x1x2x3x4\n",
      "y+\n",
      "x5\n",
      "y-\n",
      "x6\n",
      "(a)SleepingExperts:RelativeImportanceofPath-Nodes\n",
      "(b)ShiftingExperts:DeterminingNodeLabels\n",
      "Figure2:DecomposingtheTrackIPTreeAlgorithmsleepingexpertsalgo-\n",
      "rithmmakespredictionsusingtheawakeexperts,andintuitively,hasthegoal\n",
      "ofpredictingnearlyaswellasthebestawakeexpertontheinstancei1.Inour\n",
      "context,thebestawakeexpertontheIPicorrespondstothepofiinthe\n",
      "optimalIPtree,whichremainssleepinguntiltheIPtreegrowsthatFig.\n",
      "2(a)illustratesthesleepingexpertsframeworkinourcontext:theshadednodes\n",
      "are?awake?andtherestare?asleep?.PSp,letxtdenotetheweight\n",
      "ofthepath-nodeexpertatnodet,andletSi,T=t?Pi,Txt.TopredictonIP\n",
      "addressi,thealgorithmchoosestheexpertatnodetwithprobabilityxt/Si,T.\n",
      "Toupdate,thealgorithmpenalizesallincorrectexpertsinPi,T,reducingtheir\n",
      "weightxtto?xt.(e.g.,?=0.8).Itthenrenormalizestheweightsofallthe\n",
      "expertsinPi,TsothattheirsumSi,Tdoesnotchange.(Inourproof,weusea\n",
      "slightlyrentversionofthesleepingexpertsalgorithm[4]).DecidingLabels\n",
      "ofIndividualNodesNext,weneedtodecidewhetherthepath-nodeexpertata\n",
      "nodenshouldpredictpositiveornegative.Weuseatexpertsalgorithm\n",
      "toaddressthissubproblem?theshiftingexpertsalgorithm[12].Sp,\n",
      "wealloweachnodentohavetwoadditionalexperts?apositiveexpert,which\n",
      "alwayspredictspositive,andanegativeexpert,whichalwayspredictsnegative.\n",
      "Wecalltheseexpertsnode-labelexperts.Letyn,+andyn,?denotetheweights\n",
      "ofthepositiveandnegativenode-labelexpertsrespectively,withyn,?+yn,+\n",
      "=1.Thealgorithmoperatesasfollows:topredict,thenodepredictspositive\n",
      "withprobabilityyn,+andnegativewithprobabilityyn,?.Toupdate,when\n",
      "thenodereceivesalabel,itincreasestheweightofthecorrectnode-labelexpert\n",
      "by?,anddecreasestheweightoftheincorrectnode-labelexpertby?(uptoa\n",
      "maximumof1andaminimumof0).Notethatthisalgorithmnaturallyadapts\n",
      "whenaleafoftheoptimalIPtreeswitcheslabels?therelevantnodeinour\n",
      "5\n",
      "\n",
      "IPtreewillslowlyshiftweightsfromtheincorrectnode-labelexperttothecor-\n",
      "rectone,makinganexpected1?mistakesintheprocess.Fig.2(b)illustrates\n",
      "theshiftingexpertssettingonanIPtree:eachnodehastwoexperts,apositive\n",
      "andanegative.Fig.3showshowittsinwiththesleepingexpertsalgorithm.\n",
      "BuildingTreeStructureWenextaddressthesubproblemofbuildingtheappro-\n",
      "priatestructurefortheIPtree.Theintuitionhereis:whenanodeintheIPtree\n",
      "makesmanymistakes,theneitherthatnodehasasubtreeintheoptimalIPtree\n",
      "thatseparatesthepositiveandnegativeinstances,ortheoptimalIPtreemust\n",
      "alsomakethesamemistakes.SinceTrackIPTreecannotdistinguishbetween\n",
      "thesetwosituations,itsimplysplitsanynodethatmakestmistakes.\n",
      "Inparticular,TrackIPTreestartswithonlytherootnode,andtracksthenum-\n",
      "berofmistakesmadeateverynode.Everytimealeafmakes1?mistakes,\n",
      "TrackIPTreesplitsthatleafintoitschildren,andinstantiatesandinitializesthe\n",
      "relevantpath-nodeexpertsandnode-labelexpertsofthechildren.Ineit\n",
      "isasifthepath-nodeexpertsofthechildrenhadbeenasleeptillthispoint,but\n",
      "willnowbe?awake?fortheappropriateIPaddresses.TrackIPTreewaitsfor1?\n",
      "mistakesateachnodebeforegrowingit,sothatthereisalittleresilencewith\n",
      "noisydata?otherwise,itwouldsplitanodeeverytimetheoptimaltreemade\n",
      "amistake,andtheIPtreewouldgrowveryquickly.Notealsothatitnaturally\n",
      "incorporatestheoptimalIPtreegrowingaleaf;ourtreewillgrowtheappro-\n",
      "priatenodeswhenthatleafhasmade1?mistakes.BoundingSizeofIPtree\n",
      "SinceTrackIPTreesplitsanynodeafteritmakes1?mistakes,itislikelythat\n",
      "theIPtreeitbuildsissplitmuchfartherthantheoptimalIPtree?TrackIPTree\n",
      "doesnotknowwhentostopgrowingasubtree,anditsplitsevenifthesame\n",
      "mistakesaremadebytheoptimalIPtree.Whilethisexcessivesplittingdoes\n",
      "notimpactthepredictionsofthepath-nodeexpertsorthenode-labelexperts\n",
      "tly,westillneedtoensurethattheIPtreebuiltbyouralgorithmdoes\n",
      "notbecometoolarge.1\n",
      "Weleavetheexactstatementoftheguaranteetotheproofin[23]\n",
      "4\n",
      "TRACKIPTREEInput:treesizem,learningrate?,penaltyfactor?\n",
      "Initialize:SetT:=rootInitializeNode(root)\n",
      "UpdateRule(Contd.)://UpdatePpath-nodeexpertss:=n?Pxnt,Tfor\n",
      "n?Pi,Tifpredict[n]6=r,penalizexn:=?xnmistakes[xn]++ifmistakes[xn\n",
      "]>1/?andnisleaf,GrowTree(n)Renormalizexn:=xnPs\n",
      "PredictionRule:GivenIPi//Selectanode-labelexpertforn?Pi,Tcoin\n",
      "ofbiasyn,+ifheads,predict[n]:=+elsepredict[n]:=?//Selectapath-node\n",
      "expertrval:=Ppredict[n]withweightxn/t?PxtReturnrval\n",
      "j?Pi,T\n",
      "xj\n",
      "subINITIALIZENODEInput:nodetxt:=1;yt,+:=yt,?:=0.5\n",
      "mistakes[t]:=0subGROWTREEInput:leaflifsize(T)?mSelectnodesNto\n",
      "discardwithpagingalgorithmSplitleaflintochildrenlc,rc.InitializeNode(lc),\n",
      "InitializeNode(rc)\n",
      "UpdateRule:GivenIPi,labelr//Updatenode-labelexpertsforn?Pi,T\n",
      "forlabelz?\n",
      "f\n",
      "+,?\n",
      "g\n",
      "ifz=r,yn,z:=yn,z+?elseyn,z:=yn,z??\n",
      "6\n",
      "\n",
      "Figure3:TheCompleteTrackIPTreeAlgorithmWedothisbyframingitas\n",
      "apagingproblem[20]:considereachnodeintheIPtreetobeapage,andthe\n",
      "maximumallowednodesintheIPtreetobethesizeofthecache.The\n",
      "IPtree,whichhaskleaves,needsacacheofsize2k.TheIPtreebuiltbyour\n",
      "algorithmmayhaveatmostmleaves(andthus,2mnodes,sinceitisabinary\n",
      "tree),andsothesizeofitscacheis2mandthecacheis2k.Wemaythen\n",
      "selectnodestobediscardedasiftheywerepagesinthecacheoncetheIPtree\n",
      "growsbeyond2mnodes;so,forexample,wemaychoosetheleastrecentlyused\n",
      "nodesintheIPtree,withLRUasthepagingalgorithm.Ouranalysisshows\n",
      "thatsettingm=O(?k2logk?)whenTrackIPTreeusesFLUSH-W\n",
      "HEN-FULL(FWF)asitspagingalgorithm?thisisasimplepagingalgorithm\n",
      "thatdiscardsallthepagesinthecachewhenthecacheisfull,andrestartswith\n",
      "anemptycache.WeuseFWFhereforacleananalysis,andespeciallysincein\n",
      "simplepagingmodels,manyalgorithmsachievenobetterguarantees[20].For\n",
      "ourexperiments,weimplementLRU,andourresultsshowthatthisapproach,\n",
      "whileperhapsnotsophisticated,stillmaintainsanaccuratepredictiveIPtree.\n",
      "3.2AnalysisInthissection,wepresenttheoreticalguaranteesonTrackIPTree?s\n",
      "performance.Weshowouralgorithmperformsnearlyaswellasbestadaptive\n",
      "k-IPtree,boundingthenumberofmistakesmadebyouralgorithmasafunction\n",
      "ofthenumberofmistakes,numberoflabelschangesandnumberofcomplete\n",
      "oftheoptimalsuchtreeinhindsight.Theorem3.1Fixk.Set\n",
      "themaximumnumberofleavesallowedtotheTrackIPTreealgorithmmtok\n",
      "be10k?2log?.LetTbeanadaptivek-IPtree.Let?T,zdenotethenumber\n",
      "oftimesTchangeslabelsontheitsleavesoverthesequencez,andRT,zdenote\n",
      "thenumberoftimestimesThascompletelyitselfoverz.The\n",
      "algorithmTrackIPTreeensuresthatonanysequenceofinstancesz,foreachT\n",
      ",thenumberofkmistakesmadebyTrackIPTreeisatmost(1+3?)MT,z+(\n",
      "1?+3)?T,z+10k?3log?(RT,z+1)withk\n",
      "probabilityatleast1?k12?2.Inotherwords,ifthereisanadaptive\n",
      "k-IPtree,thatmakesfewchangesandfewmistakesontheinputsequenceofIP\n",
      "addresses,thenTrackIPTreewillalsomakeonlyasmallnumberofmistakes.\n",
      "Duetospaceconstraints,wepresenttheproofinthetechnicalreport[23].\n",
      "4EvaluationSetupWenowdescribeourevaluationset-up:data,practical\n",
      "changestothealgorithm,andbaselineschemesthatcompareagainst.While\n",
      "therearemanyissuesthatgointoconvertingthealgorithminSec.3forpractical\n",
      "use,wedescribeherethosemostimportanttoourexperiments,anddeferthe\n",
      "resttothetechnicalreport[23].5\n",
      "DataWefocusonIPaddressesderivedfrommaildata,sincespammers\n",
      "representatfractionofthemaliciousactivityandcompromisedhosts\n",
      "ontheInternet[6],andlabelsarerelativelyeasytoobtainfrom\n",
      "runbythemailservers.Forourevaluation,weconsiderlabelsfromthemail\n",
      "servers?tobegroundtruth.Anyerrorsinthewill\n",
      "thetreethatweconstructandourexperimentalresultsarelimited\n",
      "bythisassumption.Onedatasetconsistsoflogextractscollectedatthemail\n",
      "serversofatier-1ISPwith1millionactivemailboxes.Theextractscontain\n",
      "theIPaddressesofthemailserversthatsendmailtotheISP,thenumberof\n",
      "7\n",
      "\n",
      "messagestheysent,andthefractionofthosemessagesthatareas\n",
      "spam,aggregatedover10minuteintervals.Themailserver?s\n",
      "softwareconsistsofacombinationofhand-craftedrules,DNSblacklists,and\n",
      "Brightmail[1],andwetaketheirresultsaslabelsforourexperiments.The\n",
      "logextractswerecollectedover38daysfromDecember2008toJanuary2009,\n",
      "andcontain126millionIPaddresses,ofwhich105millionarespamand21\n",
      "millionarelegitimate.Theseconddatasetconsistsoflogextractsfromthe\n",
      "enterprisemailserverofalargecorporationwith1300activemailboxes.These\n",
      "extractsalsocontaintheIPaddressesofmailserversthatattemptedtosend\n",
      "mail,alongwiththenumberofmessagestheysentandthefractionofthese\n",
      "messagesthatwerespambySpamAssassin[2],aggregatedover10\n",
      "minuteintervals.Theextractscontain28millionIPaddresses,ofwhicharound\n",
      "1.2millionarelegitimateandtherestarespammers.Notethatinbothcases,\n",
      "ourdataonlycontainsaggregateinformationabouttheIPaddressesofthemail\n",
      "serverssendingmailtotheISPandenterprisemailservers,andsowedonot\n",
      "havetheabilitytomapanyinformationbacktoindividualusersoftheISP\n",
      "orenterprisemailservers.TrackIPTreeFortheexperimentalresults,weuse\n",
      "LRUasthepagingalgorithmwhennodesneedtobediscardedfromtheIPtree\n",
      "(Sec.3.1).Inourimplementation,wesetTrackIPTreetodiscard1%ofm,\n",
      "themaximumleavesallowed,everytimeitneedstoexpirenodes.Thelearning\n",
      "rate?issetto0.05andthepenaltyfactor?forsleepingexpertsissetto0.1\n",
      "respectively.Ourresultsarenotectediftheseparametersarechangedbya\n",
      "factorof2-3.Whilewehavepresentedanonlinelearningalgorithm,inpractice,\n",
      "itwilloftenneedtopredictondatawithoutreceivinglabelsoftheinstances\n",
      "rightaway.Therefore,westudyTrackIPTree?saccuracyonthefollowingday?s\n",
      "data,i.e.,tocomputepredictionaccuracyofdayi,TrackIPTreeisallowedto\n",
      "updateuntildayi?1.Wechooseintervalsofaday?slengthtoallowthetree?s\n",
      "predictionstobeupdatedatleasteveryday.AprioriFixedClustersWecompare\n",
      "TrackIPTreetotwosetsofaprioriclusters:(1)networkawareclusters,\n",
      "whichareasetofuniquederivedfromBGProutingtablesnapshots\n",
      "[17],and(2)/24Wechoosetheseclustersasabaseline,astheyhave\n",
      "beenthebasisofmeasurementstudiesdiscussedearlier(Sec.1),priorworkin\n",
      "IP-based[19,24],andareevenusedbypopularDNSblacklists[3].\n",
      "WeusetheedclusterstopredictthelabelofanIPintheusualmanner:we\n",
      "simplyassignanIPthelabelofitslongestmatchingprexamongtheclusters.Of\n",
      "course,weneedtoassigntheseclusterstheirownlabels.Toensurethat\n",
      "theyclassifyaswellaspossible,weassignthemtheoptimallabelingoverthe\n",
      "datatheyneedtoclassify;wedothisbyallowingthemtomakemultiplepasses\n",
      "overthedata.Thatis,foreachday,weassignlabelssothattheclusters\n",
      "maximizetheiraccuracyonspamforagivenrequiredaccuracyonlegitimate\n",
      "mail2.Itisclearthatthisexperimentalset-upisfavourabletotheapriori\n",
      "clusters.Wedonotdirectlycompareagainstthealgorithmin[11],asit\n",
      "requireseveryuniqueIPaddressinthedatasettobeinstantiatedinthetree.\n",
      "Inourexperiments(e.g.,withtheISPlogs),thismeansthatitrequiresover90\n",
      "millionleavesinthetree.Weinsteadfocusonpracticalpriorapproacheswith\n",
      "moreclustersizesinourexperiments.\n",
      "8\n",
      "\n",
      "5ResultsWereportthreesetsofexperimentalresultsregardingthepredic-\n",
      "tionaccuracyofTrackIPTreeusingtheexperimentalset-upofSection4.While\n",
      "wedonotprovideanextensiveevaluationofouralgorithm?scomputational\n",
      ",wenotethatour(unoptimized)implementationofTrackIPTreetakes\n",
      "underaminutetolearnoveramillionIPaddresses,ona2.4GHzSparc64-VI\n",
      "core.2\n",
      "Forspacereasons,wedeferthedetailsofhowweassignthislabelingtothe\n",
      "technicalreport[23]\n",
      "6\n",
      "0.80.6\n",
      "0.20\n",
      "0.5CoverageonLegitIPs\n",
      "ErroronLegitIPs\n",
      "AccuracyonSpamIPs\n",
      "0.5CoverageonLegitIPs\n",
      "0.9\n",
      "0.850\n",
      "1\n",
      "50k10k5k1k\n",
      "0.2\n",
      "DynamicStatic:5DaysStatic:10Days\n",
      "0.150.1\n",
      "200k100k50k20k0.5CoverageonLegitIPs\n",
      "1\n",
      "(c)Expt2:ISPlogs\n",
      "0.25\n",
      "0.98\n",
      "0.920\n",
      "0.4\n",
      "TrackIPTreeNetwork?Aware/24\n",
      "0.95\n",
      "(b)Expt1:Enterpriselogs\n",
      "1\n",
      "0.94\n",
      "0.6\n",
      "0.20\n",
      "1\n",
      "(a)Expt1:ISPlogs\n",
      "0.96\n",
      "0.8\n",
      "ErroronSpamIPs\n",
      "0.4\n",
      "TrackIPTreeNetwork?Aware/24\n",
      "1AccuracyonSpamIPs\n",
      "1AccuracyonSpamIPs\n",
      "AccuracyonSpamIPs\n",
      "9\n",
      "\n",
      "1\n",
      "0.15\n",
      "DynamicStatic:5DaysStatic:10Days\n",
      "0.1\n",
      "0.05\n",
      "0.5CoverageonLegitIPs\n",
      "1\n",
      "(d)Expt2:Enterpriselogs\n",
      "0.05\n",
      "10\n",
      "20Timeindays\n",
      "30\n",
      "(e)Expt3:LegitimateIPs\n",
      "10\n",
      "20Timeindays\n",
      "30\n",
      "(f)Expt3:SpamIPs\n",
      "Figure4:ResultsforExperiments1,2,and3Ourresultscomparethe\n",
      "fractionofspammingIPsthattheclustersclassifycorrectly,subjecttothecon-\n",
      "straintthattheyclassifyatleastx%legitimatemailIPscorrectly(wetermthis\n",
      "tobethecoverageofthelegitimateIPsrequired).Thus,weelyplotthe\n",
      "truepositiverateagainstthetruenegativerate.(ThisisjusttheROCcurve\n",
      "withthex-axisreversed,sinceweplotthetruepositiveagainstthetruenegative,\n",
      "insteadofplottingthetruepositiveagainstthefalsepositive.)Experiment1:\n",
      "ComparisonswithAprioriFixedClustersOursetofexperimentscompares\n",
      "theperformanceofouralgorithmwithnetwork-awareclustersand/24IPpre-\n",
      "Figs.4(a)&4(b)illustratetheaccuracyofthethreesetsofclus-\n",
      "tersonthetwodatasets.Clearly,theaccuracyofTrackIPTreeisatremendous\n",
      "improvementonbothsetsofaprioriclusters?foranychoiceofcoverage\n",
      "onlegitimateIPs,theaccuracyofspamIPsbyTrackIPTreeisfarhigherthan\n",
      "theaprioriclusters,evenbyasmuchasafactorof2.5.Inparticular,note\n",
      "thatwhenthecoveragerequiredonlegitimateIPsis95%,TrackIPTreeachieves\n",
      "95%accuracyinclassifyingspamonbothdatasets,comparedtothe35?45%\n",
      "achievedbytheotherclusters.Inaddition,TrackIPTreegainsthis\n",
      "accuracyusingafarsmallertree.Table1showsthemediannumberofleaves\n",
      "instantiatedbythetreeattheendofeachday.(Tobefairtotheclus-\n",
      "ters,weonlyinstantiatetherequiredtoclassifytheday?sdata,rather\n",
      "thanallpossibleintheclusteringscheme.)Table1showsthatthetree\n",
      "producedbyTrackIPTreeisafactorof2.5-17smallerwiththeISPlogs,anda\n",
      "factorof20-100smallerwiththeenterpriselogs.Thesenumbershighlightthat\n",
      "theaprioriclustersareperhapstoocoarsetoclassifyaccuratelyinparts\n",
      "oftheIPaddressspace,andalsoaretlyaggregatedinotherparts\n",
      "oftheaddressspace.Experiment2:ChangingtheMaximumLeavesAllowed\n",
      "Next,weexploretheofchangingm,themaximumnumberofleavesal-\n",
      "lowedtoTrackIPTree.Fig.4(c)&4(d)showtheaccuracycoveragefor\n",
      "TrackIPTreewhenmrangesbetween20,000-200,000leavesfortheISPlogs,and\n",
      "10\n",
      "\n",
      "1,000-50,000leavesfortheenterpriselogs.Clearly,inbothcases,thepredictive\n",
      "accuracyincreaseswithmonlyuntilmistlylarge??oncemislarge\n",
      "enoughtocaptureallthedistinctsubtreesintheunderlyingoptimalIPtree,the\n",
      "predictiveaccuracywillnotincrease.Whiletheactualvaluesofmaresp\n",
      "toourdatasets,theresultshighlighttheimportanceofhavingat\n",
      "andalgorithm?both10,000and100,000areverymodestsizescom-\n",
      "paredtothenumberofpossibleaprioriclusters,orthesizeoftheIPv4\n",
      "addressspace,andthissuggeststhattheunderlyingdecisiontreerequiredis\n",
      "indeedofamodestsize.Experiment3:DoesaDynamicTreeHelp?Inthis\n",
      "experiment,wedemonstrateempiricallythatouralgorithm?sdynamicaspects\n",
      "doindeedtlyenhanceitsaccuracyoverstaticclusteringschemes.The\n",
      "staticclusteringthatwecomparetoisatreegeneratedbyouralgorithm,but\n",
      "onethatlearnsoverthezdays,andthenstaysunchanged.Foreaseof\n",
      "reference,wecallsuchatreeaz-statictree;inourexperiments,wesetz=5\n",
      "andz=10.Wecomparethesetreesbyexaminingseparatelytheerrorsincurred\n",
      "onlegitimateandspamIPs.7\n",
      "TrackIPTree/24Network-aware\n",
      "ISP999421732441260132\n",
      "Enterprise99631426445223025\n",
      "wt?0.2[0,0.2)(?0.2,0)??0.2\n",
      "ImplicationStronglyLegitWeaklyLegitWeaklyMaliciousStronglyMali-\n",
      "cious\n",
      "ColourDarkGreenLightGreenBlueWhite\n",
      "Table1:SizesofClusteringSchemesTable2:ColourcodingforIPtreeinFig\n",
      "1(b)Fig.4(e)&4(f)comparetheerrorsofthez-statictreesandthedynamic\n",
      "treeonlegitimateandspamIPsrespectively,usingtheISPlogs.Clearly,both\n",
      "z-statictreesdegradeinaccuracyovertime,andtheydosoonbothlegitimate\n",
      "andspamIPs.Ontheotherhand,theaccuracyofthedynamictreedoes\n",
      "notdegradeoverthisperiod.Further,theinerrorgrowswithtime;after28\n",
      "days,the10-statictreehasalmostafactorof2highererroronbothspamIPs\n",
      "andlegitimateIPs.DiscussionandImplicationsOurexperimentsdemonstrate\n",
      "thatouralgorithmisabletoachievehighaccuracyinpredictinglegitimateand\n",
      "spamIPs,e.g.,itcanpredict95%ofthespamIPscorrectly,whenmisclassifying\n",
      "only5%ofthelegitimateIPs.However,itdoesnotclassifytheIPsperfectly.\n",
      "Thisisunsurprising?achievingzeroerrorintheseapplicationsis\n",
      "practicallyinfeasible,givenIPaddressdynamics[25].Nevertheless,ourIPtree\n",
      "stillprovidesinsightintothemaliciousactivityontheInternet.Asanexample,\n",
      "weexamineahigh-levelviewoftheInternetobtainedfromourtree,andits\n",
      "implications.Fig.1(b)visualizesanIPtreeontheISPlogswith50,000leaves.\n",
      "Itislaidoutsothattherootisnearthecenter,andthegrow\n",
      "theirchildrenoutwards.PThenodesarecoloureddependingontheirweights,\n",
      "asshowninTable2:fornodet,wt=j?Qxj(yj,+?yj,?),whereQisthe\n",
      "setofofnodet(includingnodetitself.Thus,thebluecentralnodesare\n",
      "thelarge(e.g.,/8andthetheyoutputisslightly\n",
      "malicious;thismeansthatanIPaddresswithoutalongermatching\n",
      "inthetreeistypicallytobemalicious.Thissuggests,forexample,\n",
      "11\n",
      "\n",
      "thatanunseenIPaddressistypicallyasaspammerbyourIPtree,\n",
      "whichisconsistentwiththeobservationsofnetworkadministrators.Asecond\n",
      "observationwecanmakeisthatthetreehasmanyshortbranchesaswellas\n",
      "longbranches,suggestingthatsomeIParegrowntomuchgreater\n",
      "depththanothers.Thismighthappen,forinstance,ifactiveIPaddressesfor\n",
      "thisapplicationarenotdistributeduniformlyintheaddressspace(andsoall\n",
      "donotneedtobegrownatuniformrates),whichisalsowhatwemight\n",
      "expecttoseebasedonpriorwork[16].Ofcourse,theseobservationsareonly\n",
      "examples;acompleteanalysisofourIPtree?simplicationsispartofourfuture\n",
      "work.Nevertheless,theseobservationssuggestthatourtreedoesindeedcapture\n",
      "anappropriatepictureofthemaliciousactivityontheInternet.\n",
      "6OtherRelatedWorkInthenetworkinganddatabasesliterature,therehas\n",
      "beenmuchinterestindesigningstreamingalgorithmstoidentifyIP\n",
      "withtnetwork[7,9,27],butthesealgorithmsdonotexplore\n",
      "howtopredictmaliciousactivity.PreviousIP-basedapproachestoreducespam\n",
      "[22,24],asmentionedearlier,havealsoexploredindividualIPaddresses,\n",
      "whicharenotparticularlyusefulsincetheyaresodynamic[15,19,25].Zhanget\n",
      "al[26]alsoexaminehowtopredictwhetherknownmaliciousIPaddressesmay\n",
      "appearatagivennetwork,byanalyzingtheco-occurenceofallknownmalicious\n",
      "IPaddressesatanumberoftnetworks.Morecloselyrelatedis[21],who\n",
      "presentalgorithmstoextractrulesforIPaddressesthat\n",
      "maybeusedininesettings.Therehasalsobeenworkoncomputingdecision\n",
      "treesoverstreamingdata[8,13],butthisworkassumesthatdatacomesfrom\n",
      "adistribution.\n",
      "7ConclusionWehaveaddressedtheproblemofdiscoveringdynamicma-\n",
      "liciousregionsontheInternet.Wemodelthisproblemasoneofadaptively\n",
      "pruningaknowndecisiontree,butwiththeadditionalchallengescomingfrom\n",
      "real-worldsettings?severespacerequirementsandachangingtargetfunction.\n",
      "Wedevelopednewalgorithmstoaddressthisproblem,bycombining?experts?\n",
      "algorithmsandonlinepagingalgorithms.Weshowedguaranteesonouralgo-\n",
      "rithm?sperformanceasafunctionofthebestpossiblepruningofasimilarsize,\n",
      "andourexperimentalresultsonreal-worlddatasetsareordersofmagnitude\n",
      "betterthancurrentapproaches.AcknowledgementsWearegratefultoAlan\n",
      "GlasserandGangYaofortheirhelpwiththedataanalysis8\n",
      "2References\n",
      "[1][2][3][4][5][6]\n",
      "[7]\n",
      "[8][9][10]\n",
      "[11][12][13][14]\n",
      "[15][16][17][18]\n",
      "[19][20][21][22][23][24][25][26][27]\n",
      "Brightmail.http://www.brightmail.com.SpamAssassin.http://www.spamassassin.apache.org.\n",
      "SpamHaus.http://www.spamhaus.net.BLUM,A.,ANDMANSOUR,Y.\n",
      "12\n",
      "\n",
      "Fromexternaltointernalregret.InInProceedingsof18thAnnualConference\n",
      "onComputationalLearningTheory(COLT2005)(2005).CESA-BIANCHI,\n",
      "N.,FREUND,Y.,HAUSSLER,D.,HELMBOLD,D.P.,SCHAPIRE,R.\n",
      "E.,ANDWARMUTH,M.K.Howtouseexpertadvice.J.ACM44,3(1997),\n",
      "427?485.COLLINS,M.P.,SHIMEALL,T.J.,FABER,S.,NAIES,J.,W\n",
      "EAVER,R.,ANDSHON,M.D.Usinguncleanlinesstopredictfuturebotnet\n",
      "addresses.InProceedingsoftheInternetMeasurementConference(2007).C\n",
      "ORMODE,G.,KORN,F.,MUTHUKRISHNAN,S.,ANDSRIVASTAVA,D.\n",
      "Diamondintherough:Findinghierarchicalheavyhittersinmulti-dimensional\n",
      "data.InSIGMOD?04:Proceedingsofthe2004ACMSIGMODinternational\n",
      "conferenceonManagementofdata(2004).DOMINGOS,P.,ANDHULTEN\n",
      ",G.Mininghigh-speeddatastreams.InProceedingsofACMSIGKDD(2000),\n",
      "pp.71?80.ESTAN,C.,SAVAGE,S.,ANDVARGHESE,G.Automatically\n",
      "inferringpatternsofresourceconsumptioninnetworkInProceedingsof\n",
      "SIGCOMM?03(2003).FREUND,Y.,SCHAPIRE,R.E.,SINGER,Y.,\n",
      "ANDWARMUTH,M.K.Usingandcombiningpredictorsthatspecialize.In\n",
      "ProceedingsoftheTwenty-NinthAnnualSymposiumontheTheoryofCom-\n",
      "puting(STOC)(1997),pp.334?343.HELMBOLD,D.P.,ANDSCHAPIRE\n",
      ",R.E.Predictingnearlyaswellasthebestpruningofadecisiontree.Ma-\n",
      "chineLearning27,1(1997),51?68.HERBSTER,M.,ANDWARMUTH,\n",
      "M.Trackingthebestexpert.MachineLearning32,2(August1998).JIN\n",
      ",R.,ANDAGARWAL,G.tandedecisiontreeconstruction\n",
      "onstreamingdata.InProceedingsofACMSIGKDD(2003).JUNG,J.,K\n",
      "RISHNAMURTHY,B.,ANDRABINOVICH,M.Flashcrowdsanddenialof\n",
      "serviceattacks:Characterizationandimplicationsforcdnsandwebsites.In\n",
      "ProceedingsoftheInternationalWorldWideWebConference(May2002).J\n",
      "UNG,J.,ANDSIT,E.AnempiricalstudyofspamandtheuseofDNS\n",
      "blacklists.InProceedingsofInternetMeasurementConference(IMC)(2004).\n",
      "KOHLER,E.,LI,J.,PAXSON,V.,ANDSHENKER,S.Observedstructure\n",
      "ofaddressesinIPIEEE/ACMTransactionsinNetworking14,6(2006).\n",
      "KRISHNAMURTHY,B.,ANDWANG,J.Onnetwork-awareclusteringofweb\n",
      "clients.InProceedingsofACMSIGCOMM(2000).MAO,Z.M.,SEKAR,\n",
      "V.,SPATSCHECK,O.,VANDERMERWE,J.,ANDVASUDEVAN,R.\n",
      "Analyzinglargeddosattacksusingmultipledatasources.InACMSIGCOMM\n",
      "WorkshoponLargeScaleAttackDefense(2006).RAMACHANDRAN,A.,\n",
      "ANDFEAMSTER,N.Understandingthenetwork-levelbehaviorofspammers.\n",
      "InProceedingsofACMSIGCOMM(2006).SLEATOR,D.D.,ANDTARJAN\n",
      ",R.E.Amortizedoflistupdateandpagingrules.InCommunications\n",
      "oftheACM(1985),vol.28,pp.202?208.SOLDO,F.,MARKOPOULO,A.,\n",
      "ANDARGYRAKI,K.Optimalofsourceaddress:Modelsand\n",
      "algorithms.InProceedingsofIEEEInfocom2009(2009).TWINING,D.,W\n",
      "ILLIAMSON,M.M.,MOWBRAY,M.,ANDRAHMOUNI,M.Emailprior-\n",
      "itization:Reducingdelaysonlegitimatemailcausedbyjunkmail.InUSENIX\n",
      "AnnualTechnicalConference(2004).VENKATARAMAN,S.,BLUM,A.,\n",
      "SONG,D.,SEN,S.,ANDSPATSCHECK,O.Trackingdynamicsources\n",
      "ofmaliciousactivityatinternet-scale.Tech.Rep.TD-7NZS8K,AT&TLabs,\n",
      "13\n",
      "\n",
      "2009.VENKATARAMAN,S.,SEN,S.,SPATSCHECK,O.,HAFFNER,\n",
      "P.,ANDSONG,D.Exploitingnetworkstructureforproactivespammitiga-\n",
      "tion.InProceedingsofUsenixSecurity?07(2007).XIE,Y.,YU,F.,ACHAN\n",
      ",K.,GILLUM,E.,,GOLDSZMIDT,M.,ANDWOBBER,T.Howdynamic\n",
      "areIPaddresses?InProceedingsofACMSIGCOMM(2007).ZHANG,J.,P\n",
      "ORRAS,P.,ANDULRICH,J.Highlypredictiveblacklists.InProceedingsof\n",
      "UsenixSecurity?08(2008).ZHANG,Y.,SINGH,S.,SEN,S.,DUFFIELD\n",
      ",N.,ANDLUND,C.Onlineidenofhierarchicalheavyhitters:algo-\n",
      "rithms,evaluation,andapplications.InIMC?04:Proceedingsofthe4thACM\n",
      "SIGCOMMconferenceonInternetmeasurement(NewYork,NY,USA,2004),\n",
      "ACM,pp.101?114.\n",
      "9\n",
      "14\n",
      "\n",
      "PP4946.pdf\n",
      "PP4946.pdf 11\n",
      "LeastInformativeDimensions\n",
      "Authoredby:\n",
      "FabianSinz\n",
      "AnnaStockl\n",
      "JanGrewe\n",
      "JanBenda\n",
      "Abstract\n",
      "Wepresentanovelnon-parametricmethodforasubspaceof\n",
      "stimulusfeaturesthatcontainsallinformationabouttheresponseofa\n",
      "system.Ourmethodgeneralizessimilarapproachestothisproblemsuch\n",
      "asspiketriggeredaverage,spiketriggeredcovariance,ormaximallyin-\n",
      "formativedimensions.Insteadofmaximizingthemutualinformationbe-\n",
      "tweenfeaturesandresponsesdirectly,weuseintegralprobabilitymetrics\n",
      "inkernelHilbertspacestominimizetheinformationbetweenuninforma-\n",
      "tivefeaturesandthecombinationofinformativefeaturesandresponses.\n",
      "Sinceestimatorsofthesemetricsaccessthedataviakernels,areeasyto\n",
      "compute,andexhibitgoodtheoreticalconvergenceproperties,ourmethod\n",
      "caneasilybegeneralizedtopopulationsofneuronsorspikepatterns.By\n",
      "usingaparticularexpansionofthemutualinformation,wecanshowthat\n",
      "theinformativefeaturesmustcontainallinformationifwecanmakethe\n",
      "uninformativefeaturesindependentoftherest.\n",
      "1PaperBody\n",
      "Animportantaspectofdecipheringtheneuralcodeistodeterminethosestim-\n",
      "ulusfeaturespopulationsofsensoryneuronsaremostsensitiveto.Approaches\n",
      "tothatproblemincludewhitenoiseanalysis[2,14],inparticularspike-triggered\n",
      "average[4]orspike-triggeredcovariance[3,19],canonicalcorrelationanalysisor\n",
      "populationreceptive[12],generalizedlinearmodels[18,15],ormaximally\n",
      "informativedimensions[22].Allthesetechniqueshaveincommonthattheyop-\n",
      "timizeastatisticaldependencymeasurebetweenstimuliandspikeresponsesover\n",
      "thechoiceofalinearsubspace.Theparticularalgorithmsinthedimen-\n",
      "sionalityofthesubspacetheyextract(one-vs.multi-dimensional),thestatisti-\n",
      "calmeasuretheyuse(correlation,likelihood,relativeentropy),andwhetheran\n",
      "extensiontopopulationresponsesisfeasibleornot.Whilespike-triggeredaver-\n",
      "ageusescorrelationandisrestrictedtoasinglesubspace,spike-triggeredcovari-\n",
      "anceandcanonicalcorrelationanalysiscanalreadyextractmulti-dimensional\n",
      "1\n",
      "\n",
      "subspacesbutarestillrestrictedtosecond-orderstatistics.Maximallyinfor-\n",
      "mativedimensionsistheonlytechniqueoftheabovethatcanextractmultiple\n",
      "dimensionsthatareinformativealsowithrespecttohigher-orderstatistics.\n",
      "However,anextensiontospikepatternsorpopulationresponsesisnotstraight-\n",
      "forwardbecauseofthecurseofdimensionality.Hereweapproachtheproblem\n",
      "fromantperspectiveandproposeanalgorithmthatcanextractamulti-\n",
      "dimensionalsubspacecontainingallrelevantinformationabouttheneuralre-\n",
      "sponsesYintermsofShannon?smutualinformation(ifsuchasubspaceexists).\n",
      "Ourmethoddoesnotcommittoaparticularparametricmodel,andcaneasily\n",
      "beextendedtospikepatternsorpopulationresponses.1\n",
      "Ingeneral,theproblemofthemostinformativesubspaceofthestim-\n",
      "uliXabouttheresponsesYcanbedescribedasanorthogonalmatrix\n",
      "Q(abasisforRn)thatseparatesX>intoinformativeandnon-informative\n",
      "features(U,V)=QX.SinceQisorthogonal,themutualinformationI[X:Y\n",
      "]betweenXandYcanbedecomposedas[5]\n",
      "p(U,V,Y)I[Y:X]=I[Y:U,V]=EX,Ylogp(U,V)p(Y)\n",
      "p(Y,V|U)=I[Y:U]+EY,Vlogp(Y|U)p(V|U)=I[Y:U\n",
      "]+EU[I[Y|U:V|U]].(1)Sincethetwotermsontherighthandsideof\n",
      "equation(1)arealwayspositiveandsumuptothemutualinformationbetween\n",
      "YandX,twowaystoobtainmaximallyinformativefeaturesUaboutYwould\n",
      "betoeithermaximizeI[Y:U]ortominimizeEU[I[Y|U:V|U]]via\n",
      "thechoiceofQ.Thepossibilityisalongthelinesofmaximallyinformative\n",
      "dimensions[22]andinvolvesdirectestimationofthemutualinformation.The\n",
      "secondpossibilitywhichavoidsdirectestimationhasbeenproposedbyFuku-\n",
      "mizuandcolleagues[5,6](wediscussbothinSection3).Here,weexplore\n",
      "athirdpossibility,whichtradespracticaladvantagesagainstaslightlymore\n",
      "restrictiveobjective.TheideaistoobtainmaximallyinformativefeaturesU\n",
      "bymakingVasindependentaspossiblefromthecombinationofUandY.\n",
      "Forthisreason,wenameourapproachleastinformativedimensions(LID).For-\n",
      "mally,leastinformativedimensionstriestominimizethemutualinformation\n",
      "betweenthepairY,UandV.Usingthechainruleformultiinformationwe\n",
      "canwriteitas(seesupplementarymaterial)I[Y,U:V]\n",
      "=I[Y:X]+I[U:V]?I[Y:U].\n",
      "(2)\n",
      "ThismeansthatminimizingI[Y,U:V]isequivalenttomaximizingI[Y:U\n",
      "]whilesimultaneouslyminimizingI[U:V].NotethatI[Y,U:V]=0implies\n",
      "I[U:V]=0.Therefore,ifQcanbechosensuchthatI[Y,U:V]=0equation\n",
      "(2)reducestoI[Y:X]=I[Y:U],pushingallinformationaboutYintoU.\n",
      "SinceeachnewchoiceofQrequirestheestimationofthemutualinformation\n",
      "between(potentiallyhigh-dimensional)variables,directoptimizationishardor\n",
      "unfeasible.Forthisreason,weresorttoanotherdependencymeasurewhichis\n",
      "easiertoestimatebutsharesitsminimumwithmutualinformation,thatis,itis\n",
      "zeroifandonlyifthemutualinformationiszero.TheobjectiveistochooseQ\n",
      "suchthat(Y,U)andVareindependentinthatdependencymeasure.Ifwecan\n",
      "suchaQ,thenweknowthatI[Y,U:V]iszeroaswell,whichmeansthatU\n",
      "arethemostinformativefeaturesintermsoftheShannonmutualinformation.\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thiswillallowustoobtainmaximallyinformativefeatureswithouteverhaving\n",
      "toestimateamutualinformation.Theeasierestimationprocedurecomesat\n",
      "thecostofonlybeingabletolinkthealternativedependencymeasuretothe\n",
      "mutualinformationifbothofthemarezero.IfthereisnoQthatachievesthis,\n",
      "wewillstillgetinformativefeaturesinthealternativemeasure,butitisnot\n",
      "clearhowinformativetheyareintermsofmutualinformation.\n",
      "2\n",
      "Leastinformativedimensions\n",
      "ThissectiondescribeshowtotlyaQsuchthatI[Y,U:V]=0\n",
      "(ifsuchaQexists).>Unlessnotedotherwise,(U,V)=QXwhereUdenotes\n",
      "theinformativeandVtheuninformativefeatures.Themutualinformationisa\n",
      "specialcaseoftherelativeentropy\n",
      "logp(X)DKL[p||q]=EX?plogq(X)betweentwodistributionpand\n",
      "q.WhilebeinglinkedtotherichtheoreticalbackgroundofShannoninformation\n",
      "theory,therelativeentropyisknowntobehardtoestimate[25].Alternatives\n",
      "torelativeentropyofincreasingpracticalinterestaretheintegralprobability\n",
      "metrics(IPM),as[25,17]?F(X:Z)\n",
      "=\n",
      "sup|EX[f(X)]?EZ[f(Z)]|.\n",
      "(3)\n",
      "f?F\n",
      "Intuitively,themetricinequation(3)searchesforafunctionf,whichcan\n",
      "detectainthedistributionsoftworandomvariablesXandZ.Ifno\n",
      "suchwitnessfunctioncanbefound,the2\n",
      "distributionsmustbeequal.IfFischosentobeatlyrichrepro-\n",
      "ducingkernelHilbertspaceH[21],thenthesupremuminequation(3)canbe\n",
      "computedexplicitlyandthedivergencecanbecomputedinclosedform[7].\n",
      "ThisparticulartypeofIPMiscalledmaximummeandiscrepancy(MMD)[9,\n",
      "7,10].Akernelk:X?X?Risasymmetricfunctionsuchthatthematrix\n",
      "Kij=k(xi,xj)ispositiveforeveryselectionofpointsx1,...,\n",
      "xm?X[21].Inthatcase,thefunctionsk(?,x)areelementsofareproducing\n",
      "kernelHilbertspace(RKHS)offunctionsH.Thisspaceisendowedwithadot\n",
      "producth?,?iHwiththesocalledreproducingpropertyhk(?,x),fiH=f(x)\n",
      "forf?H.Inparticular,hk(?,x),k(?,x0)iH=k(x,x0).WhensettingFin\n",
      "equation(3)tobetheunitballinH,thentheIPMcanbecomputedinclosed\n",
      "formasthenormofthedrencebetweenthemeanfunctionsinH[7,10,8,\n",
      "26]:?H(X:Z)\n",
      "==\n",
      "kEX[k(?,X)]?EZ[k(?,Z)]kH\n",
      "12EX,X0kX,X0?2EX,Z[k(X,Z)]+EZ,Z0kZ,Z0,\n",
      "(4)\n",
      "wheretheequalityisderivedin[7],andsecondequalityusesthebi-\n",
      "linearityofthedotproductandthereproducingpropertyofk.Furthermore,\n",
      "(X,X0)?PX?PXand(Z,Z0)?PZ?PZaretwoindependentrandom\n",
      "variablesdrawnfromthemarginaldistributionsofXandZ,respectively.The\n",
      "functionEX[k(?,X)]isanembeddingofthedistributionofXintotheRKHS\n",
      "3\n",
      "\n",
      "HviaX7?EX[k(?,X)].Ifthismapisinjective,thatis,ifituniquelyrep-\n",
      "resentstheprobabilitydistributionofX,thenequation(4)iszeroifandonly\n",
      "iftheprobabilitydistributionsofXandX0arethesame.Kernelswiththat\n",
      "propertyarecalledcharacteristicinanalogytothecharacteristicfunction?X\n",
      "(t)7?EXexpit>X[26,27].ThismeansthatforcharacteristickernelsMMDis\n",
      "zeroexactlyiftherelativeentropyDKL[pkq]iszeroaswell.Sincethemutual\n",
      "informationistherelativeentropybetweenthejointdistributionandtheprod-\n",
      "uctsofthemarginals,wecanuseMMDtosearchforaQsuchthat?H(PY,U\n",
      ",V:PY,U?PV)iszero1,whichthenimpliesthatI[Y,U:V]=0aswell.\n",
      "Thesampleversionof(4)issimplygivenbyreplacingtheexpectations\n",
      "withtheempiricalmean(andpossiblysomebiascorrection)[7,10,8].The\n",
      "estimationof?Hthereforeonlyinvolvessummationoverthreekernelmatrices\n",
      "andcanbedoneinafewlinesofcode.Unlikefortherelativeentropy,theem-\n",
      "piricalestimationofMMDisthereforemuchmorefeasible.Further?more,the\n",
      "residualerroroftheempiricalestimatorcanbeshowntodecreaseontheorder\n",
      "of1/mwheremisthenumberofdatapoints[25].Noteinparticular,thatthis\n",
      "ratedoesnotdependonthedimensionalityofthedata.ObjectivefunctionThe\n",
      "objectivefunctionforouroptimizationproblemnowhasthefollowingform:We\n",
      "transforminputexamplesxiintofeaturesuiandvivia(ui,vi)=Qxi.Then\n",
      "weuseakernelk(ui,vi,yi),uj,vj,yjtocomputeandminimizeMMD\n",
      "withrespecttothechoiceofQ.Inordertodothattly,afewadaptations\n",
      "arerequired.First,withoutlossofgenerality,weminimizethesquaredMMD\n",
      "insteadofMMDitself\n",
      "2?H(Z1,Z2)=EZ1,Z01kZ1,Z01?2EZ1,Z2[k(Z1,Z2)]+\n",
      "EZ2,Z02kZ2,Z02,(5)whereZ1=(Y,U,V)?PY,U,VandZ2=\n",
      "(Y,U,V)?PY,U?PV.Second,inordertogetsamplesfromPY,U?PV\n",
      ",weassumethatourkerneltakestheform\n",
      "k(ui,vi,yi),uj,vj,yj=k1(ui,yi),uj,yj?k2(vi,vj).For\n",
      "thisspecialcase,onecanincorporatetheindependenceassumptionbetweenU\n",
      ",YandVdirectlybyusingthefactthatforindependentrandomvariables,the\n",
      "expectationoftheproductisequaltotheproductofexpectations,thatis,\n",
      "Ek1(ui,yi),uj,yj?k2(vi,vj)=Ek1(ui,yi),uj,yjE[k2\n",
      "(vi,vj)].ThisspecialcaseofMMDisequivalenttotheHilbert-Schmidt\n",
      "IndependenceCriterion(HSIC)[9,23]andcanbecomputedas12??hs(6)=\n",
      "2tr(K1HK2H),(m?1)m\n",
      "whereK1andK2denotethematricesofpairwisekernelvaluesbetweenthe\n",
      "datasets\n",
      "f\n",
      "(ui,yi)\n",
      "g\n",
      "i=1mand\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,respectively,andHij=?ij?m?1.\n",
      "1\n",
      "Withsomeabuseofnotation,wewroteMMDasafunctionoftheprobability\n",
      "measures.\n",
      "3\n",
      "Note,however,thatonecouldinprinciplealsooptimize(5)foranon-\n",
      "factorizingkernelbysimplyshthe(ui,yi)andviacrossexamples.\n",
      "Wecanalsouseshtoassesswhetherthe2optimalvalue??hsfounddur-\n",
      "ingtheoptimizationistlytfromzerobycomparing2thevalue\n",
      "toanulldistributionover??hsobtainedfromdatasetswherethe(ui,yi)and\n",
      "4\n",
      "\n",
      "vihavebeenpermutedacrossexamples.Minimizationprocedureandgradients\n",
      "Foroptimizing(6)withrespecttoQweusegradientdescentovertheorthogonal\n",
      "groupSO(n).Theoptimizationcanbecarriedoutbycomputingtheuncon-\n",
      "strainedgradient?Q?oftheobjectivefunctionwithrespecttoQ(treatingQ\n",
      "asanordinarymatrix),projectingthatgradientontothetangentspaceofSO\n",
      "(n),andperformingalinesearchalongthegradientdirection.Wenowpresent\n",
      "thenecessaryformulaetoimplementtheoptimizationinamodularfashion.We\n",
      "showhowtocomputethegradient?Q?intermsofthegradients22?ui\n",
      ",vi??hs,thenweshowhowtocomputethe?ui,vi??hsintermsofderivatives\n",
      "ofkernelfunctions,anddemonstratehowtheformulaechangewhenap-\n",
      "proximatingthekernelmatriceswithanincompleteCholeskydecomposition.\n",
      "Giventheunconstrainedgradient?Q?theprojectionontothetangentspaceis\n",
      "givenby?=Q?Q?>Q??Q?[13,eq.(22)].Thefunctionisthenminimized\n",
      "byperformingaline-searchalong?(Q+t?),where?istheprojectiononto\n",
      "SO(n)whichcaneasilybecomputedviasingularvaluedecompositionofQ+\n",
      "t?andsettingthesingularvaluestoone[13,prop.7].Thismeansthatall\n",
      "weneedforthegradientdescentonSO(n)istheunconstrainedgradient?Q?.\n",
      "Thisgradienttakestheformofasumofouterproducts[16,eq.(20)]\n",
      "m22X???hs???hs2>?Q??hs=?x>,=J?,J=i?(ui,vi)?(ui,\n",
      "vi)ii=1wherethematrix?containsthestimulixiinitsrows.(u)\n",
      "ThekcolumnsJ?correspondingtothedimensionofthefeaturesuiand\n",
      "thelastn?kcolumnsJ(v)correspondingtothedimensionofthefeaturesvi\n",
      "aregivenby\n",
      "22(u)>(v)(v)>J?(u)=diagHKHDandJ=diagHKHD,21???22\n",
      "(m?1)(m?1)where\n",
      "D?(u)\n",
      "=ij\n",
      "?k(ui,vi,yi),uj,vj,yj?ui?\n",
      "ij\n",
      "th\n",
      "containsthepartialderivativesofthekernelwithrespecttothe?dimension\n",
      "ofu(andanalogouslyforv)intheargument(seesupplementarymaterialfor\n",
      "thederivation).ntimplementationwithincompleteCholeskydecomposi-\n",
      "tionofthekernelmatrixSofar,theevaluationofHSICrequiresthecomputation\n",
      "oftwom?mkernelmatricesineachstep.Forlargerdatasetsthiscanquickly\n",
      "becomecomputationallyprohibitive.Inordertospeedupcomputationtime,\n",
      "weapproximatethekernelmatricesbyanincompleteCholeskydecomposition\n",
      "K=LL>,whereL?Rm>isa?tall?matrix[1].Inthatcase,HSICcanbe\n",
      "computedmuchfasterasthetraceofaproductoftwo`?`matricesbecause\n",
      "2>2tr(K1HK2H)=trL>1HL2L2HL1,whereHLkcanbetly\n",
      "computedbycenteringLkonitsrowmean.Alsointhiscase,thematrixJ\n",
      "canbecomputedtlyintermsofderivativesofsub-matricesofthekernel\n",
      "matrix(seesupplementarymaterialfortheexactformulae).\n",
      "3\n",
      "Relatedwork\n",
      "5\n",
      "\n",
      "Kerneldimensionreductioninregression[5,6]Fukumizuandcolleagues\n",
      "maximallyinformativefeaturesUbyminimizingEU[I[V|U:Y|U]]in\n",
      "equation(1)viaconditionalkernel4\n",
      "covarianceoperators.Theyshowthatthecovarianceoperatorequalszeroif\n",
      "andonlyifYisconditionallyindependentofVgivenU,thatis,Y??V|U\n",
      ".Inthatcase,UcarriesallinformationaboutY.Althoughtheirapproachis\n",
      "closesttoours,itinafewkeyaspects:Incontrasttoourapproach,their\n",
      "objectiveinvolvestheinversionofa?potentiallylarge?kernelmatrixwhichneeds\n",
      "additionalregularizationinordertobeinvertible.Aconceptualisthat\n",
      "weareoptimizingaslightlymorerestrictiveproblembecausetheirobjective\n",
      "doesnotattempttomakeUindependentofVaswell.However,thiswillnot\n",
      "makeainmanypracticalcases,sincemanystimulusdistributions\n",
      "areGaussianforwhichthedependenciesbetweenUandVcanberemovedby\n",
      "prewhiteningthestimulusdatabeforetrainingLID.InthatcaseI[U:V]=\n",
      "0foreverychoiceofQandequation(2)becomesequivalenttomaximizingthe\n",
      "mutualinformationbetweenUandY.Theadvantageofourformulationofthe\n",
      "problemisthatitallowsustodetectandquantifyindependencebycomparing\n",
      "thecurrent??hstoitsnulldistributionobtainedbyshthe(yi,ui)\n",
      "againstviacrossexamples.Thisishardlypossibleintheconditionalcase.\n",
      "AlsonotethatforsphericallysymmetricdataI[U:V]=const.forevery\n",
      "choiceofQ.Inthatcaseequation(2)becomesequivalenttomaximizingI[Y\n",
      ":U].However,aresidualredundancyremainswhichwouldshowupwhen2\n",
      "comparing??hstoitsnulldistribution.Finally,theuseofkernelcovariance\n",
      "operatorsisboundtokernelsthatfactorize.Inprinciple,ourmethodisalso\n",
      "applicabletonon-factorizingkernelsifweuse?Hinsteadof?hsandobtainthe\n",
      "samplesfromtheproductdistributionofPY,U?PVviashg.Maximally\n",
      "informativedimensions[22]\n",
      "SharpeeandcolleaguesmaximizetherelativeentropyIspike=DKLpv>\n",
      "s|spike||pv>sbetweenthedistributionofstimuliprojectedontoinfor-\n",
      "mativedimensionsgivenaspike,tothemarginaldistributionoftheprojection.\n",
      "Thisrelativeentropyisthepartofthemutualinformationwhichiscarriedby\n",
      "thearrivalofasinglespike,since\n",
      "Iv>s:\n",
      "f\n",
      "spike,nospike\n",
      "g\n",
      "=p(spike)?Ispike+p(nospike)Inospike\n",
      ".Theirmethodisalsocompletelynon-parametricandcaptureshigherorder\n",
      "dependenciesbetweenastimulusandasinglespike.However,byfocusingon\n",
      "singlespikesandthespiketriggereddensityonly,itneglectsthedependencies\n",
      "betweenspikesandtheinformationcarriedbythesilenceoftheneuron[28].\n",
      "Additionally,thegeneralizationtospikepatternsorpopulationresponsesis\n",
      "non-trivialbetweentheprojectedstimuliandspikepatterns$1,...,$`be\n",
      "becausetheinformationPcomesIv>s:$=p($)?I$i.Thisrequiresthe\n",
      "estimationofaconditionaldistributionii\n",
      ">pvs|$iforeachpattern$iwhichcanquicklybecomeprohibitivewhen\n",
      "thenumberofpatternsgrowsexponentially.\n",
      "4\n",
      "Experiments\n",
      "Inalltheexperimentsbelow,wedemonstratethevalidityofourmethods\n",
      "6\n",
      "\n",
      "oncontrolledexamplesandonP-unitrecordingsfromelectricWe\n",
      "useanRBFkernelontheviandatensorRBFkernelonthe(ui,yi):!\n",
      ">2\n",
      "kuiy>kvi?vjk2i?ujyjkk(vi,vj)=exp?andk(ui,yi)\n",
      ",uj,yj=exp?.?2?2Thederivativesofthekernelscanbefoundinthe\n",
      "supplementarymaterial.Unlessnotedotherwisethe?werechosentobethe\n",
      "medianofpairwiseEuclideandistancesbetweendatapoints.Inall\n",
      "experiments,Qwaschosenrandomly.LinearNon-LinearPoissonModel(LNP)\n",
      "Inthisexperiment,wetrainedLIDonasimplelinearnonlinearPoisson(LNP)\n",
      "neuronyi?Poissonbhw,xii??c+withanexponentiallydecayingand\n",
      "arectifyingnon-linearity(seeFigure1,left).Weusedm=5000datapointsxi\n",
      "froma20-dimensionalstandardnormaldistributionN(0,I)asinput.The\n",
      "waschosensuchthatapproximately35%non-zerospikecountsintheyiwere\n",
      "obtained.Weusedoneinformativeand19non-informativedimensions,andset\n",
      "?=1forthetensorkernel.Afteroptimization,thehdimensionq1ofQ\n",
      "convergeditothew(Figure1).WecomparedtheHSICvalues??hs\n",
      "f\n",
      "(yi\n",
      ",ui)\n",
      "g\n",
      "i=1,...,m:\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,...,mbeforeandaftertheoptimizationtotheirnull\n",
      "distributionobtainedbyshBeforetheoptimization,thedependenceof\n",
      "(Y,U)andV5\n",
      "Figure1:Left:LNPModel.Theinformativedimension(grayduringopti-\n",
      "mization,blackafteroptimization)convergestothetrueofanLNPmodel\n",
      "(blueline).Beforeoptimization(Y,U)andVaredependentasshownby\n",
      "theleftinset(nulldistributionobtainedviashingray,dashedlineshows\n",
      "actualHSICvalue).Aftertheoptimization(rightinset)theHSICvalueiseven\n",
      "belowthenulldistribution.Right:Twostateneuron.LIDcorrectlyiden\n",
      "thesubspace(bluedashed)inwhichthetwotrue(solidblack)reside\n",
      "sinceprojectionsoftheonthesubspace(reddashed)closelyresemble\n",
      "theoriginaliscorrectlydetected(Figure1,left,insets).Afterconver-\n",
      "gencetheactualHSICvaluelieslefttothenulldistribution?sdomain.Since\n",
      "theappropriatetestforindependencewouldbeone-sided,thenullhypothesis\n",
      "?(Y,U)isindependentofV?wouldnotberejectedinthiscase.Twostate\n",
      "neuronInthisexperiment,wesimulatedaneuronwithtwostatesthatwere\n",
      "bothattainedin50%ofthetrials(seeFigure1,right).Thistime,theoutput\n",
      "consistedoffour?bins?whosestatisticsvarieddependingonthestate.Inthe\n",
      "rate?state,thefourbinscontainedspikecountsdrawnfromanLNP\n",
      "neuronwithexponentiallydecayingasabove.Inthesecond?burst?state,\n",
      "thetwobinsweredrawnfromPoissondistributionwithabaserate\n",
      "independentofthestimulus.ThesecondtwobinsweredrawnfromanLNP\n",
      "neuronwithamodulatedexponentialandhighergain.Weusedm=8000\n",
      "inputstimulifroma20-dimensionalstandardnormaldistribution.Weusetwo\n",
      "informativedimensionsandset?ofthetensorkerneltotwotimesthemedian\n",
      "ofthepairwisedistances.LIDcorrectlyidenthesubspaceassociatedwith\n",
      "thetwoalsointhiscase(Figure1,right).complexcellIna\n",
      "secondexperiment,weestimatedthetwo-dimensionalsubspaceassociatedwith\n",
      "acomplexcell.Wegeneratedaquadraturepairw1andw2oftwo\n",
      "10dimensional(seeFigure2,left).Weusedm=8000inputpointsfrom\n",
      "7\n",
      "\n",
      "astandardnormaldistribution.ResponsesweregeneratedfromaPoissondis-\n",
      "tributionwiththerategivenby22?i=hw1,xii+hw2,xii.Thisledto\n",
      "about34%non-zeroneuralresponses.Whenusingtwoinformativesubspaces,\n",
      "LIDwasabletoidentifythesubspacecorrectly(Figure2,left).Whencompar-\n",
      "ingtheHSICvalueagainstthenulldistributionfoundviashthe\n",
      "valueindicatednofurtherdependencies.Whenonlyaone-dimensionalsubspace\n",
      "wasused(Figure2,right),LIDdidnotconvergetothecorrectsubspace.Im-\n",
      "portantly,theHSICvalueafteroptimizationwasclearlyoutsidethesupportof\n",
      "thenulldistribution,therebycorrectlyindicatingresidualdependencies.P-Unit\n",
      "recordingsfromweaklyelectricFinally,weappliedourmethodtoP-unit\n",
      "recordingsfromtheweaklyelectricEigenmanniavirescens.Theseweakly\n",
      "electricgenerateadipolelikeelectricwhichchangespolaritywitha\n",
      "frequencyatabout300Hz.Sensorsintheskinofthearetunedtothis\n",
      "carrierfrequencyandrespondtoamplitudechangescausedbyclose-byobjects\n",
      "withtconductivepropertiesthanwater[20].Inthepresentrecordings,\n",
      "theimmobilizedwasstimulatedwith10sof300?600Hzlow-pass\n",
      "fullfrozenGaussianwhitenoiseamplitudemodulationsofitsown\n",
      "Neuralactivitywasrecordedintra-cellularlyfromtheP-unitts.Spikes\n",
      "werebinnedwith1msprecision.Weselectedm=8400randomtimepoints\n",
      "inthespikeresponseandthecorrespondingpreceding20msoftheinput(20\n",
      "dimensions).Weusedthesame6\n",
      "Figure2:ComplexCell.Left:Theoriginalare90?phase\n",
      "shiftedGaborwhichformanorthogonalbasisforatwo-dimensionalsub-\n",
      "space.Afteroptimization,thetwoinformativedimensionsofLIDtwo\n",
      "rowsofQ)convergetothatsubspaceandalsoformapairof90?phaseshifted\n",
      "(notethatevenifthearenotthesame,theyspanthesamesub-\n",
      "space).ComparingtheHSICvaluesbeforeandafteroptimizationshowsthat\n",
      "thissubspacecontainstherelevantinformation(leftandrightinset).Right:\n",
      "Ifonlyaone-dimensionalinformativesubspaceisused,theonlyslightly\n",
      "convergestothesubspace.Afteroptimization,acomparisonoftheHSICvalue\n",
      "tothenulldistributionobtainedviashindicatesresidualdependencies\n",
      "whicharenotexplainedbytheone-dimensionalsubspace(leftandrightinset).\n",
      "Figure3:MostinformativefeatureforaweaklyelectricP-Unit:A\n",
      "random(bluetrace)exhibitsHSICvaluesthatareclearlyoutsidethe\n",
      "domainofthenulldistribution(leftinset).Usingthespiketriggeredaverage\n",
      "(redtrace)movestheHSICvaluesofthefeatureofQalreadyinsidethenull\n",
      "distribution(middleinset).FurtheroptimizationwithLIDthefeature\n",
      "(blacktrace)andbringstheHSICvaluesclosertozero(rightinset).After\n",
      "optimization,theinformativefeatureUisindependentofthefeaturesVbecause\n",
      "therowandcolumnofthecovariancematrixofthetransformedGaussian\n",
      "inputshownocorrelations.Thefactthatoneinformativefeatureissucient\n",
      "tobringtheHSICvaluesinsidethenulldistributionindicatesthatasingle\n",
      "subspacecapturesallinformationconveyedbythesesensoryneurons.\n",
      "kernelsasintheexperimentontheLNPmodel.Weinitializedthe\n",
      "rowinQwiththenormalizedspiketriggeredaverage(STA;Figure3,left,red\n",
      "trace).Weneitherpre-whitenedthedataforcomputingtheSTAnorforthe\n",
      "8\n",
      "\n",
      "optimizationofLID.Unlikearandomfeature(Figure3,left,bluetrace),the\n",
      "spiketriggeredaveragealreadyachievesHSICvalueswithinthenulldistribution\n",
      "(Figure3,leftandmiddleinset).Themostinformativefeaturecorresponding\n",
      "toUlooksverysimilartotheSTAbutshiftstheHSICvaluedeeperintothe\n",
      "domainofthenulldistribution(Figure3,rightinset).7\n",
      "Thisindicatesthatonesinglesubspaceintheinputisttocarryall\n",
      "informationbetweentheinputandtheneuralresponse.\n",
      "5\n",
      "Discussion\n",
      "Herewepresentedanon-parametricmethodtoestimateasubspaceofthe\n",
      "stimulusspacethatcontainsallinformationaboutaresponsevariableY.Even\n",
      "thoughourmethodiscompletelygenericandapplicabletoarbitraryinput-\n",
      "outputpairsofdata,wefocusedontheapplicationinthecontextofsensory\n",
      "neuroscience.TheadvantageofthegenericapproachisthatYcaninprinciple\n",
      "beanythingfromspikecounts,tospikepatternsorpopulationresponses.Since\n",
      "ourmethodthemostinformativedimensionsbymakingthecomplement\n",
      "ofthosedimensionsasindependentfromthedataaspossible,wetermedit\n",
      "leastinformativedimensions(LID).WeusetheHilbert-Schmidtindependence\n",
      "criteriontominimizethedependenciesbetweentheuninformativefeaturesand\n",
      "thecombinationofinformativefeaturesandoutputs.Thismeasureiseasyto\n",
      "implement,avoidstheneedtoestimatemutualinformation,anditsestimator\n",
      "hasgoodconvergencepropertiesindependentofthedimensionalityofthedata.\n",
      "Eventhoughourapproachonlyestimatestheinformativefeaturesandnotmu-\n",
      "tualinformationitself,itcanhelptoestimatemutualinformationbyreducing\n",
      "thenumberofdimensions.AsintheapproachbyFukumizuandcolleagues,it\n",
      "mightbethatnoQexistssuchthatI[Y,U:V]=0.Inthatsituation,the\n",
      "pricetopayforaneasiermeasureisthatitishardtomakeitestatements\n",
      "abouttheinformativenessofthefeaturesUintermsoftheShannoninforma-\n",
      "tion,since?H=I[Y,U:V]=0isthepointthatconnects?Htothemutual\n",
      "information.Asdemonstratedintheexperiments,wecandetectthiscaseby\n",
      "comparingtheactualvalueof??Htoanempiricalnulldistributionof??Hval-\n",
      "uesobtainedbyshtheviagainsttheui,yipairs.However,if?H6=\n",
      "0,theoreticalupperboundsonthemutualinformationareunfortunatelynot\n",
      "available.2Infact,usingresultsfrom[25]andPinsker?sinequalityonecan\n",
      "showthat?Hboundsthemutualinformationfrombelow.Onemightnowbe\n",
      "temptedtothinkthatmaximizing?H[Y,U]mightbeabetterwayto\n",
      "informativefeatures.Whilethismightbeawaytogetsomeinformativefea-\n",
      "tures[24],itisnotpossibletolinkthefeaturestoinformativenessintermsof\n",
      "Shannonmutualinformation,becausethepointthatbuildsthebridgebetween\n",
      "thetwodependencymeasuresiswherebothofthemarezero.Anywhereelse\n",
      "theboundmaynotbetightsothemaximallyinformativefeaturesintermsof\n",
      "?Handintermsofmutualinformationcanbet.Anotherproblemour\n",
      "approachshareswithmanyalgorithmsthatdetecthigher-orderdependenciesis\n",
      "thenon-convexityoftheobjectivefunction.Inpractice,wefoundthatthede-\n",
      "greetowhichthisposesaproblemverymuchdependsontheproblemathand.\n",
      "Forinstance,whilethesubspacesoftheLNPorthetwostateneuronwerede-\n",
      "9\n",
      "\n",
      "tectedreliably,thetwodimensionalsubspaceofthecomplexcellseems\n",
      "toposeaharderproblem.Itislikelythatthechoiceofkernelhasan\n",
      "onthelandscapeoftheobjectivefunction.Weplantoexplorethisrelationship\n",
      "inmoredetailinthefuture.Ingeneral,agoodinitializationofQhelpstoget\n",
      "closetotheglobaloptimum.Beyondthat,however,integralprobabilitymetric\n",
      "approachestomaximallyinformativedimensionseragreatchancetoavoid\n",
      "manyproblemsassociatedwithdirectestimationofmutualinformation,andto\n",
      "extendittomuchmoreinterestingoutputstructuresthansinglespikes.\n",
      "AcknowledgementsFabianSinzwouldliketothankLucasTheisandSe-\n",
      "bastianGerwinnforhelpfuldiscussionsandcommentsonthemanuscript.This\n",
      "studyispartoftheresearchprogramoftheBernsteinCenterforComputational\n",
      "Neuroscience,T?ubingen,fundedbytheGermanFederalMinistryofEducation\n",
      "andResearch(BMBF;FKZ:01GQ1002).\n",
      "2References\n",
      "[1]F.R.BachandM.I.Jordan.Predictivelow-rankdecompositionforker-\n",
      "nelmethods.InProceedingsofthe22ndinternationalconferenceonMachine\n",
      "learning-ICML?05,pages33?40,NewYork,NewYork,USA,2005.ACM\n",
      "Press.[2]E.D.BoerandP.Kuyper.TriggeredCorrelation,1968.\n",
      "8\n",
      "[3]N.Brenner,W.Bialek,andR.DeRuyterVanSteveninck.Adaptive\n",
      "rescalingmaximizesinformationtransmission.Neuron,26(3):695?702,2000.\n",
      "[4]E.J.Chichilnisky.Asimplewhitenoiseanalysisofneuronallightresponses.\n",
      "Network:Comput.NeuralSyst,12:199?213,2001.[5]K.Fukumizu,F.R.\n",
      "Bach,andM.I.Jordan.DimensionalityReductionforSupervisedLearning\n",
      "withReproducingKernelHilbertSpaces.JournalofMachineLearningRe-\n",
      "search,5(1):73?99,2004.[6]K.Fukumizu,F.R.Bach,andM.I.Jordan.Kernel\n",
      "dimensionreductioninregression.AnnalsofStatistics,37(4):1871?1905,2009.\n",
      "[7]A.Gretton,K.M.Borgwardt,M.Rasch,B.Sch?olkopf,andA.Smola.A\n",
      "kernelmethodforthetwosampleproblem.InB.Sch?olkopf,J.Platt,and\n",
      "T.editors,AdvancesinNeuralInformationProcessingSystems19,\n",
      "pages513?-520,Cambridge,MA,2007.MITPress.[8]A.Gretton,K.M.\n",
      "Borgwardt,M.J.Rasch,B.Sch?olkopf,andA.Smola.AKernelTwo-Sample\n",
      "Test.JournalofMachineLearningResearch,13:723?773,2012.[9]A.Gretton,\n",
      "O.Bousquet,A.Smola,andB.Sch?olkopf.MeasuringStatisticalDependence\n",
      "withHilbertSchmidtNorms.InS.Jain,H.U.Simon,andE.Tomita,editors,\n",
      "AdvancesinNeuralInformationProcessingSystems,pages63?77.Springer\n",
      "Berlin/Heidelberg,2005.[10]A.Gretton,K.Fukumizu,Z.Harchaoui,and\n",
      "B.K.Sriperumbudur.AFast,ConsistentKernelTwo-SampleTest.InYBen-\n",
      "gio,DSchuurmans,Jy,CKIWilliams,andACulotta,editors,Ad-\n",
      "vancesinNeuralInformationProcessingSystems,pages673?681.Curran,Red\n",
      "Hook,NY,USA,2009.[11]J.D.Hunter.Matplotlib:A2Dgraphicsenviron-\n",
      "ment.ComputingInScience&Engineering,9(3):90?95,2007.[12]J.Macke,\n",
      "G.Zeck,andM.Bethge.ReceptiveFieldswithoutSpike-Triggering.Advances\n",
      "10\n",
      "\n",
      "inNeuralInformationProcessingSystems20,pages1?8,2007.[13]J.H.Man-\n",
      "ton.Optimizationalgorithmsexploitingunitaryconstraints.SignalProcessing,\n",
      "IEEETransactionson,50(3):635?650,2002.[14]P.Z.MarmarelisandK.Naka.\n",
      "White-noiseanalysisofaneuronchain:anapplicationoftheWienertheory.\n",
      "Science,175(27):1276?1278,1972.[15]PMcCullaghandJANelder.General-\n",
      "izedLinearModels,SecondEdition.ChapmanandHall,1989.[16]T.P.Minka.\n",
      "OldandNewMatrixAlgebraUsefulforStatistics.MITMediaLabNote,pages\n",
      "1?19,2000.[17]A.M?uller.IntegralProbabilityMetricsandTheirGenerating\n",
      "ClassesofFunctions.AdvancesinAppliedProbability,29(2):429?443,1997.\n",
      "[18]L.Paninski.Maximumlikelihoodestimationofcascadepoint-processneu-\n",
      "ralencodingmodels.Network:ComputationinNeuralSystems,15(4):243?262,\n",
      "2004.[19]J.W.PillowandE.P.Simoncelli.Dimensionalityreductioninneural\n",
      "models:aninformation-theoreticgeneralizationofspike-triggeredaverageand\n",
      "covarianceanalysis.JournalofVision,6(4):414?428,2006.[20]H.Scheich,T.\n",
      "H.Bullock,andR.HHamstra.Codingpropertiesoftwoclassesoftnerve\n",
      "ers:high-frequencyelectroreceptorsintheelectricEigenmannia.Jour-\n",
      "nalofNeurophysiology,36(1):39?60,1973.[21]B.Sch?olkopfandA.J.Smola.\n",
      "LearningwithKernels:SupportVectorMachines,Regularization,Optimiza-\n",
      "tion,andBeyond,volume98ofAdaptivecomputationandmachinelearning.\n",
      "MITPress,2001.[22]T.Sharpee,N.C.Rust,andW.Bialek.Analyzing\n",
      "neuralresponsestonaturalsignals:maximallyinformativedimensions.Neural\n",
      "Computation,16(2):223?250,2004.[23]A.Smola,A.Gretton,L.Song,and\n",
      "B.Sch?olkopf.AHilbertSpaceEmbeddingforDistributions.InAlgorithmic\n",
      "LearningTheory:18thInternationalConference,pages13?31.Springer-Verlag,\n",
      "Berlin/Heidelberg,2007.[24]L.Song,A.Smola,A.Gretton,J.Bedo,andK.\n",
      "Borgwardt.Featureselectionviadependencemaximization.JournalofMa-\n",
      "chineLearningResearch,13(May):1393?1434,2012.[25]B.K.Sriperumbudur,\n",
      "K.Fukumizu,A.Gretton,andG.R.G.Lanckriet.OnIntegralProbability\n",
      "Metrics,phi-divergencesandbinaryTechnicalReport1,arXiv,\n",
      "2009.[26]B.K.Sriperumbudur,A.Gretton,K.Fukumizu,G.Lanckriet,and\n",
      "B.Sch?olkopf.InjectiveHilbertSpaceEmbeddingsofProbabilityMeasures.\n",
      "InProceedingsofthe21stAnnualConferenceonLearningTheory,numberi,\n",
      "pages111?122.Omnipress,2008.[27]B.K.Sriperumbudur,A.Gretton,K.\n",
      "Fukumizu,B.Sch?olkopf,andG.R.G.Lanckriet.HilbertSpaceEmbeddings\n",
      "andMetricsonProbabilityMeasures.JournalofMachineLearningResearch,\n",
      "11(1):48,2010.[28]R.S.Williamson,M.Sahani,andJ.W.Pillow.Equating\n",
      "information-theoreticandlikelihood-basedmethodsforneuraldimensionality\n",
      "reduction.TechnicalReport1,arXiv,2013.\n",
      "9\n",
      "11\n",
      "\n",
      "PP5319.pdf\n",
      "PP5319.pdf 10\n",
      "StructurelearningofantiferromagneticIsing\n",
      "models\n",
      "Authoredby:\n",
      "DevavratShah\n",
      "GuyBresler\n",
      "DavidGamarnik\n",
      "Abstract\n",
      "Inthispaperweinvestigatethecomputationalcomplexityoflearning\n",
      "thegraphstructureunderlyingadiscreteundirectedgraphicalmodelfrom\n",
      "i.i.d.samples.Ourresultisanunconditionalcomputationallower\n",
      "boundof$Omega(p\n",
      "f\n",
      "d/2\n",
      "g\n",
      ")$forlearninggeneralgraphicalmodelson$p$\n",
      "nodesofmaximumdegree$d$,fortheclassofstatisticalalgorithmsre-\n",
      "centlyintroducedbyFeldmanetal.Theconstructionisrelatedtothe\n",
      "notoriouslylearningparitieswithnoiseproblemincomputational\n",
      "learningtheory.Ourlowerboundshowsthatthe$widetildeO(p\n",
      "f\n",
      "d+2\n",
      "g\n",
      ")$\n",
      "runtimerequiredbyBresler,Mossel,andSly'sexhaustive-searchalgo-\n",
      "rithmcannotbetlyimprovedwithoutrestrictingtheclassof\n",
      "models.Asidefromstructuralassumptionsonthegraphsuchasitbeing\n",
      "atree,hypertree,tree-like,etc.,mostrecentpapersonstructurelearning\n",
      "assumethatthemodelhasthecorrelationdecayproperty.Indeed,fo-\n",
      "cusingonferromagneticIsingmodels,BentoandMontanarishowedthat\n",
      "allknownlow-complexityalgorithmsfailtolearnsimplegraphswhenthe\n",
      "interactionstrengthexceedsanumberrelatedtothecorrelationdecay\n",
      "threshold.Oursecondsetofresultsgivesaclassofrepelling(antiferro-\n",
      "magnetic)modelsthathavetheemph\n",
      "f\n",
      "opposite\n",
      "g\n",
      "behavior:verystrong\n",
      "repellingallowstlearningintime$widetildeO(p2)$.Weprovide\n",
      "analgorithmwhoseperformanceinterpolatesbetween$widetildeO(p2)$\n",
      "and$widetildeO(p\n",
      "f\n",
      "d+2\n",
      "g\n",
      ")$dependingonthestrengthoftherepulsion.\n",
      "1PaperBody\n",
      "Graphicalmodelshavehadtremendousimpactinavarietyofapplicationdo-\n",
      "mains.Forunstructuredhigh-dimensionaldistributions,suchasinsocialnet-\n",
      "works,biology,andanimportantstepistodeterminewhichgraph-\n",
      "icalmodeltouse.Inthispaperwefocusontheproblemofstructurelearning:\n",
      "Givenaccesstonindependentandidenticallydistributedsamples?(1),...?\n",
      "(n)fromanundirectedgraphicalmodelrepresentingadiscreterandomvector\n",
      "1\n",
      "\n",
      "?=(?1,...,?p),thegoalistothegraphGunderlyingthemodel.\n",
      "Twobasicquestionsare1)Howmanysamplesarerequired?and2)Whatis\n",
      "thecomputationalcomplexity?Inthispaperwearemostlyinterestedinthe\n",
      "computationalcomplexityofstructurelearning.Weconsidertheproblem\n",
      "oflearningageneraldiscreteundirectedgraphicalmodelofboundeddegree.1\n",
      "1.1\n",
      "Learninggeneralgraphicalmodels\n",
      "Severalalgorithmsbasedonexhaustivelysearchingoverpossiblenodeneigh-\n",
      "borhoodshaveappearedinthelastdecade[4,2,5].Abbeel,Koller,andNg\n",
      "[4]gavealgorithmsforlearninggeneralgraphicalmodelsclosetothetruedis-\n",
      "tributioninKullback-Leiblerdistance.Bresler,Mossel,andSly[2]presented\n",
      "algorithmsguaranteedtolearnthetrueunderlyinggraph.Thealgorithmsin\n",
      "both[4]and[2]performasearchovercandidateneighborhoods,andforagraph\n",
      "ofmaximumdegreed,thecomputationalcomplexityforrecoveringagraphon\n",
      "p?d+2)(wheretheO?notationhideslogarithmicfactors).nodesscalesas\n",
      "O(pWhilethealgorithmsin[2]areguaranteedtoreconstructgeneralmodels\n",
      "underbasicnondegeneracyconditionsusinganoptimalnumberofsamplesn=\n",
      "O(dlogp)(samplecomplexitylowerboundswereprovedbySanthanamand\n",
      "Wainwright[6]aswellas[2]),the?d+2)run-timeisimpracticallyhigheven\n",
      "forconstantbutlargegraphexponentdintheO(pdegrees.Thishasmotivated\n",
      "agreatdealofworkonstructurelearningforspecialclassesofgraphicalmodels.\n",
      "Butbeforegivingupongeneralmodels,weaskthefollowingquestion:Question\n",
      "1:Isitpossibletolearnthestructureofgeneralgraphicalmodelsonpnodes\n",
      "withmaximumdegreedusingsubstantiallylesscomputationthanpd?Our\n",
      "resultsuggeststhattheanswertoQuestion1isnegative.Weshowanuncond\n",
      "ditionalcomputationallowerboundofp2fortheclassofstatisticalalgorithms\n",
      "introducedbyFeldmanetal.[1].Thisclassofalgorithmswasintroducedin\n",
      "ordertounderstandtheapparentyofthePlantedCliqueproblem,and\n",
      "isbasedonKearns?statisticalquerymodel[7].Kearnsshowedinhislandmark\n",
      "paperthatstatisticalqueryalgorithmsrequireexponentialcomputationtolearn\n",
      "parityfunctionssubjecttonoise,andourhardnessconstructionis\n",
      "relatedtothisproblem.Mostknownalgorithmicapproaches(includingMarkov\n",
      "chainMonteCarlo,programming,andmanyothers)canbeimple-\n",
      "mentedasstatisticalalgorithms,sothelowerboundisfairlyconvincing.We\n",
      "givebackgroundandprovethefollowingtheoreminSection4.Theorem1.1.\n",
      "Statisticalalgorithmsrequireatleast(p2)computationstepsinordertolearn\n",
      "thestructureofageneralgraphicalmodelsofdegreed.d\n",
      "Ifcomplexitypdistobeconsideredintractable,whatshallweconsider\n",
      "astractable?Writingalgorithmcomplexityintheformc(d)pf(d),forhigh-\n",
      "dimensional(largep)problemstheexponentf(d)isofprimaryimportance,\n",
      "andwewillthinkoftractablealgorithmsashavinganf(d)thatisboundedby\n",
      "aconstantindependentofd.Thefactorc(d)isalsoimportant,andwewilluse\n",
      "ittocomparealgorithmswiththesameexponentf(d).InlightofTheorem1.1,\n",
      "reducingcomputationbelowp(d)requiresrestrictingtheclassofmodels.One\n",
      "caneitherrestrictthegraphstructureorthenatureoftheinteractionsbetween\n",
      "variables.TheseminalpaperofChowandLiu[8]makesamodelrestriction\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ofthetype,assumingthatthegraphisatree;generalizationsincludeto\n",
      "polytrees[9],hypertrees[10],andothers.Amongthemanypossibleassumptions\n",
      "ofthesecondtype,thecorrelationdecaypropertyisdistinguished:tothebest\n",
      "ofourknowledgeallexistinglow-complexityalgorithmsrequirethecorrelation\n",
      "decayproperty[3].1.2\n",
      "Correlationdecayproperty\n",
      "Informally,agraphicalmodelissaidtohavethecorrelationdecayprop-\n",
      "erty(CDP)ifanytwovariables?sand?tareasymptoticallyindependentas\n",
      "thegraphdistancebetweensandtincreases.Exponentialdecayofcorrelations\n",
      "holdswhenthedistancefromindependencedecreasesexponentiallyfastingraph\n",
      "distance,andwewillmeanthisstrongerformwhenreferringtocorrelationde-\n",
      "cay.Correlationdecayisknowntoholdforanumberofpairwisegraphical\n",
      "modelsintheso-calledhigh-temperatureregime,includingIsing,hard-corelat-\n",
      "ticegas,Potts(multinomial)model,andothers(see,e.g.,[11,12,13,14,15,\n",
      "16]).2\n",
      "Bresler,Mossel,andSly[2]observedthatitispossibletotlylearn\n",
      "modelswith(exponential)decayofcorrelations,undertheadditionalassump-\n",
      "tionthatneighboringvariableshavecorrelationboundedawayfromzero(asis\n",
      "true,e.g.,fortheferromagneticIsingmodelinthehightemperatureregime).\n",
      "Thealgorithmtheyproposedforthissettingprunedthecandidatesetofneigh-\n",
      "borsforeachnodetoroughlysizeO(d)byretainingonlythosevariableswith\n",
      "tlyhighcorrelations,andthenwithinthissetperformedtheexhaustive\n",
      "search?2).Theoverneighborhoodsmentionedbefore,resultinginacompu-\n",
      "tationalcostofdO(d)O(pgreedyalgorithmsofNetrapalietal.[17]andRayet\n",
      "al.[18]alsorequirethecorrelationdecaypropertyandperformasimilarprun-\n",
      "ingstepbyretainingonlynodeswithhighpairwisecorrelation;theythenusea\n",
      "tmethodtoselectthetrueneighborhood.Anumberofpapersconsider\n",
      "theproblemofreconstructingIsingmodelsongraphswithfewshortcycles,\n",
      "beginningwithAnandkumaretal.[19].TheirresultsapplytothecaseofIsing\n",
      "modelsonsparselyconnectedgraphssuchastheErd?os-Renyirandomgraph\n",
      "G(p,dp).Theyadditionallyrequiretheinteractionparameterstobeeither\n",
      "genericorferromagnetic.Ferromagneticmodelshavethebthatneigh-\n",
      "borsalwayshaveanon-negligiblecorrelationbecausethedependenciescannot\n",
      "cancel,butineithercasetheresultsstillrequiretheCDPtohold.Wuetal.\n",
      "[20]removetheassumptionofgenericparametersin[19],butagainrequirethe\n",
      "CDP.Otheralgorithmsforstructurelearningarebasedonconvexoptimization,\n",
      "suchasRavikumaretal.?s[21]approachusingregularizednode-wiselogisticre-\n",
      "gression.WhilethisalgorithmdoesnotexplicitlyrequiretheCDP,Bentoand\n",
      "Montanari[3]foundthatthelogisticregressionalgorithmof[21]provablyfails\n",
      "tolearncertainferromagneticIsingmodelonsimplegraphswithoutcorrelation\n",
      "decay.Otherconvexoptimization-basedalgorithmssuchas[22,23,24]require\n",
      "similarincoherenceorrestrictedisometry-typeconditionsthatareto\n",
      "verify,butlikelyalsorequirecorrelationdecay.Sinceallknownalgorithmsfor\n",
      "structurelearningrequiretheCDP,weaskthefollowingquestion(paraphras-\n",
      "ingBentoandMontanari):Question2:Islow-complexitystructurelearning\n",
      "possibleformodelswhichdonotexhibittheCDP,ongeneralboundeddegree\n",
      "3\n",
      "\n",
      "graphs?Oursecondmainresultanswersthisquestionelybyshowing\n",
      "thatabroadclassofrepellingmodelsongeneralgraphscanbelearnedusing\n",
      "simplealgorithms,evenwhentheunderlyingmodeldoesnotexhibittheCDP.\n",
      "1.3\n",
      "Repellingmodels\n",
      "TheantiferromagneticIsingmodelhasanegativeinteractionparameter,\n",
      "wherebyneighboringnodesprefertobeinoppositestates.Otherpopularan-\n",
      "tiferromagneticmodelsincludethePottsorcoloringmodel,andthehard-core\n",
      "model.Antiferromagneticmodelshavetheinterestingpropertythatcorrelations\n",
      "betweenneighborscanbezeroduetocancellations.Thusalgorithmsbasedon\n",
      "pruningneighborhoodsusingpairwisecorrelations,suchasthealgorithmin[2]\n",
      "formodelswithcorrelationdecay,doesnotworkforanti-ferromagneticmodels.\n",
      "Toourknowledgetherearenopreviousresultsthatimproveonthepdcomputa-\n",
      "tionalcomplexityforstructurelearningofantiferromagneticmodelsongeneral\n",
      "graphsofmaximumdegreed.Ourlearningalgorithm,describedinSection\n",
      "2,isforthehard-coremodel.Theorem1.2(Informal).Itispossibletolearn\n",
      "stronglyrepellingmodels,suchasthehard?2).coremodel,withrun-timeO(p\n",
      "Weextendthisresulttoweaklyrepellingmodels(equivalenttotheantiferro-\n",
      "magneticIsingmodelparameterizedinanonstandardway,seeSection3).Here\n",
      "?isarepellingstrengthandhisanexternalTheorem1.3(Informal).\n",
      "Suppose??(d??)(h+ln2)foraninteger0??<d.Then?2+?).itis\n",
      "possibletolearnarepellingmodelwithinteraction?,withrun-timeO(p3\n",
      "?2),achievableforThecomputationalcomplexityofthealgorithminter-\n",
      "polatesbetweenO(pd+2?stronglyrepellingmodels,andO(p),achievable\n",
      "forgeneralmodelsusingexhaustivesearch.Thecomplexitydependsonthere-\n",
      "pellingstrengthofthemodel,ratherthanstructuralassumptionsonthegraph\n",
      "asin[19,20].Weremarkthatthestronglyrepellingmodelsexhibitlong-range\n",
      "correlations,yetthealgorithmictaskofgraphstructurelearningispossibleus-\n",
      "ingalocalprocedure.Thefocusofthispaperisonstructurelearning,but\n",
      "theproblemofparameterestimationisequallyimportant.Itturnsoutthat\n",
      "thestructurelearningproblemisstrictlymorechallengingforthemodelswe\n",
      "consider:oncethegraphisknown,itisnottoestimatetheparameters\n",
      "withlowcomputationalcomplexity(see,e.g.,[4]).\n",
      "2\n",
      "Learningthegraphofahard-coremodel\n",
      "Wewarmupbyconsideringthehard-coremodel.Theanalysisinthissection\n",
      "isstraightforward,butservesasanexampletohighlightthefactthatcorrelation\n",
      "decayisnotanecessaryconditionforstructurelearning.GivenagraphG=\n",
      "(V,E)on|V|=pnodes,denotebyI(G)?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "pthesetofindependentset\n",
      "indicatorvectors?,forwhichatleastoneof?ior?jiszeroforeachedge\n",
      "f\n",
      "i,j\n",
      "g\n",
      "?\n",
      "E(G).Thehardcoremodelwithfugacity?>0assignsnonzeroprobabilityonly\n",
      "tovectorsinI(G),with?|?|P(?)=,??I(G).(2.1)Zq|?|Here|?|\n",
      "isthenumberofentriesof?equaltooneandZ=??I(G)?isthenormalizing\n",
      "constantcalledthepartitionfunction.If?>1thenmoremassisassignedto\n",
      "largerindependentsets.(Weuseindicatorvectorstodenethemodelinorder\n",
      "tobeconsistentwiththeantiferromagneticIsingmodelinthenextsection.)\n",
      "4\n",
      "\n",
      "OurgoalistolearnthegraphG=(V,E)underlyingthemodel(2.1)given\n",
      "accesstoindependentsamples?(1),...,?(n).Thefollowingsimple\n",
      "algorithmreconstructsGtly.Algorithm1simpleHC(?(1),...,?(n)\n",
      ")1:FOReachi,j,k:(k)(k)2:IF?i=?j=1,THENS=S?\n",
      "f\n",
      "i,j\n",
      "g\n",
      "?=Sc3:\n",
      "OUTPUTETheideabehindthealgorithmisverysimple.If\n",
      "f\n",
      "i,j\n",
      "g\n",
      "belongsto\n",
      "theedgesetE(G),then(k)(k)foreverysample?(k)either?i=0or?j=0\n",
      "(orboth).Thusforeveryi,jandksuch(k)\n",
      "(k)\n",
      "that?i=?j=1wecansafelydeclare\n",
      "f\n",
      "i,j\n",
      "g\n",
      "nottobeanedge.Toshow\n",
      "correctnessofthealgorithmitisthereforeienttoarguethatforeverynon-\n",
      "edge\n",
      "f\n",
      "i,j\n",
      "g\n",
      "thereisahighlikelihoodthatsuchanindependentset?(k)willbe\n",
      "sampled.\n",
      "Beforedoingthis,weobservethatsimpleHCactuallycomputesthemaximum-\n",
      "likelihood(k)(k)estimateforthegraphG.Toseethis,notethatanedgee=\n",
      "f\n",
      "i,j\n",
      "g\n",
      "forwhich?i=?j=1?sinceP(?(k)|G+e)??ThustheMLestimate\n",
      "containsforsomekcannotbeinG,=0foranyG.asubsetofthoseedgese\n",
      "whichhavenotbeenruledoutby?(1),...,?(n).Butaddinganysuchedge\n",
      "etothegraphdecreasesthevalueofthepartitionfunctionin(2.1)(thesum\n",
      "isoverfewerindependentsets),therebyincreasingthelikelihoodofeachofthe\n",
      "samples.ThesamplecomplexityandcomputationalcomplexityofsimpleHCis\n",
      "asfollows,withproofintheSupplement.Theorem2.1.Considerthehard-core\n",
      "model(2.1)onagraphG=(V,E)on|V|=pnodesandwithmaximum\n",
      "degreed.ThesamplecomplexityofsimpleHCisn=O((2?)2d?2logp),4\n",
      "(2.2)\n",
      "i.e.withthismanysamplesthealgorithmsimpleHCcorrectlyreconstructs\n",
      "thegraphwithprobability1?o(1).ThecomputationalcomplexityisO(np2)\n",
      "=O((2?)2d?2p2logp).\n",
      "(2.3)\n",
      "WenextshowthatthesamplecomplexityboundinTheorem2.1isbasically\n",
      "tight:Theorem2.2(Samplecomplexitylowerbound).Considerthehard-core\n",
      "model(2.1).Thereisafamilyofgraphsonpnodeswithmaximumdegreed\n",
      "suchthatfortheprobabilityofsuccessfulreconstructiontoapproachone,the\n",
      "numberofsamplesmustscaleas1p2n=(2?)2dlog.dLemma2.3.Suppose\n",
      "edgee=(i,j)?/G,andletIbeanindependentsetchosenaccordingtothe\n",
      "Gibbsdistribution(2.1).ThenP(\n",
      "f\n",
      "i,j\n",
      "g\n",
      "?I)?(9?max\n",
      "f\n",
      "1,(2?)2d?2\n",
      "g\n",
      ")?1,?.\n",
      "TheSupplementaryMaterialcontainsproofsforTheorem2.2andLemma2.3.\n",
      "3\n",
      "Learninganti-ferromagneticIsingmodels\n",
      "Inthissectionweconsidertheanti-ferromagneticIsingmodelonagraphG\n",
      "=(V,E).Weparametrizethemodelinsuchawaythateachhas\n",
      "probability)*1P(?)=expH(?),??\n",
      "f\n",
      "0,1\n",
      "g\n",
      "p,(3.1)Zwhere??H(?)=??\n",
      "?i?j+hi?i.(3.2)(i,j)?E\n",
      "i?V\n",
      "Here?>0and\n",
      "f\n",
      "hi\n",
      "g\n",
      "i?Varereal-valuedparameters,andweassumethat\n",
      "|hi|?hforalli.Workingwithcgurationsin\n",
      "f\n",
      "0,1\n",
      "g\n",
      "pratherthanthe\n",
      "moretypical\n",
      "f\n",
      "?1,+1\n",
      "g\n",
      "pamountstoareparametrization(whichiswithoutloss\n",
      "5\n",
      "\n",
      "ofgeneralityasshownforexampleinAppendix1of[25]).Settinghi=h=ln\n",
      "?foralli,werecoverthehard-coremodelwithfugacity?inthelimit???,so\n",
      "wethinkof(3.2)asa?soft?independentsetmodel.3.1\n",
      "Stronglyantiferromagneticmodels\n",
      "Westartbyconsideringthesituationinwhichtherepellingstrength?is\n",
      "tlylargethatwecanmodifytheapproachusedforthehard-coremodel.\n",
      "Werequiresomenotationtoworkwithconditionalprobabilities:foreachvertex\n",
      "b?V,let(i)\n",
      "and\n",
      "Bb=\n",
      "f\n",
      "?(i):?b=1\n",
      "g\n",
      ",\n",
      "?a=1|?b=1):=1|\n",
      "f\n",
      "i?B:?(i)=1\n",
      "g\n",
      "|.P(?a|B|!\"?a=\n",
      "1|?b=1)=P(?a=1|?b=1).Thealgorithm,describednext,Ofcourse,E\n",
      "P(??toathreshold.determineswhethereachedge\n",
      "f\n",
      "a,b\n",
      "g\n",
      "ispresentbasedon\n",
      "comparingPAlgorithm2StrongRepelling\n",
      "?Input:?,h,d,andnsamples?(1),...,?(n)?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "p.Output:\n",
      "edgesetE.dh(d?1)?21:Let?=(1+2e)!\"2:FOReachpossibleedge\n",
      "f\n",
      "a,\n",
      "b\n",
      "g\n",
      "?V2:?3:IFP?(?a=1|?b=1)?(1+e??h)?1+?THENaddedge\n",
      "(a,b)toE?4:OUTPUTEAlgorithmStrongRepellingobtainsthefollowing\n",
      "performance.TheproofofProposition3.1issimilartothatofTheorem2.1,\n",
      "replacingLemma2.3byLemma3.2below.5\n",
      "Proposition3.1.ConsidertheantiferromagneticIsingmodel(3.2)onagraph\n",
      "G=(V,E)onpnodesandwithmaximumdegreed.If??d(h+ln2),\n",
      "thenalgorithmStrongRepellinghassamplecomplexity12n=O22d\n",
      "e2h(d+1)logp,\n",
      "i.e.thismanysamplesarettoreconstructthegraphwithprobability\n",
      "1?o(1).ThecomputationalcomplexityofStrongRepellingis12O(np2)=\n",
      "O22de2h(d+1)p2logp.Whentheinteractionparameter??d(h+ln2)it\n",
      "ispossibletoidentifyedgesusingpairwisestatistics.Thenextlemma,proved\n",
      "intheSupplement,showsthedesiredseparation.Lemma3.2.Wehavethe\n",
      "followingestimates:(i)If(a,b)?/E(G),thenP(?a=1|?b=1)?\n",
      "11+2deg(a)eh(deg(a)+1)\n",
      "(ii)Conversely,if(a,b)?E(G),thenP(?a=1|?b=1)?(ii)Foranyb?\n",
      "V,P(?b=1)?3.2\n",
      "11+2deg(b)eh(deg(b)+1)\n",
      ".\n",
      "11+e??h\n",
      ".\n",
      ".\n",
      "Weaklyantiferromagneticmodels\n",
      "Inthissectionwefocusonlearningweaklyrepellingmodelsandshowatrade-\n",
      "betweencomputationalcomplexityandstrengthoftherepulsion.Recallthat\n",
      "forstronglyrepellingmodelsouralgorithmhasrun-timeO(p2logp),thesame\n",
      "asforthehard-coremodelrepulsion).ForasubsetofnodesU?V,\n",
      "letGUdenotethegraphobtainedfromGbyremovingnodesinU(aswellas\n",
      "anyedgesincidenttonodesinU).Thefollowingcorollaryisimmediatefrom\n",
      "Lemma3.2.Corollary3.3.Wehavetheconditionalprobabilityestimatesfor\n",
      "6\n",
      "\n",
      "deletingsubsetsofnodes:(i)If(a,b)?/E(G),thenforanysubsetofnodesU\n",
      "?V\n",
      "f\n",
      "a,b\n",
      "g\n",
      ",PGU(?a=1|?b=1)?\n",
      "1\n",
      "1+2\n",
      "degGU(a)h(degGU(a)+1)\n",
      "e\n",
      ".\n",
      "(ii)Conversely,if(a,b)?E(G),thenforanysubsetofnodesU?V\n",
      "f\n",
      "a,b\n",
      "g\n",
      "PGU(?a=1|?b=1)?\n",
      "1.1+e??h\n",
      "Wecanelyremovenodesfromthegraphbyconditioning:Thefamily\n",
      "ofmodels(3.2)hasthepropertythatconditioningon?i=0amountstoremoving\n",
      "nodeifromthegraph.Fact3.4(Self-reducibility).LetG=(V,E),andconsider\n",
      "themodel3.2.ThenforanysubsetofnodesU?V,theprobabilitylawPG(?\n",
      "??|?U=0)isequaltoPGU(?VU??).Theingredientistoshow\n",
      "thatwecanconditionbyrestrictingattentiontoasubsetoftheobserveddata,\n",
      "?(1),...,?(n),withoutthrowingawaytoomanysamples.Lemma3.5.Let\n",
      "U?Vbeasubsetofnodesanddenotethesubsetofsampleswithvariables(i)\n",
      "?UequaltozerobyAU=\n",
      "f\n",
      "?(i):?u=0forallu?U\n",
      "g\n",
      ".Thenwithprobability\n",
      "atleasth2|U|1?exp(n/2(1+e))thenumber|AU|ofsuchsamples\n",
      "isatleastn2?(1+eh)?|U|.\n",
      "Wenowpresentthealgorithm.ely,itreducesnodedegreebyremov-\n",
      "ingnodes(whichcanbedonebyconditioningonvaluezero),andthenapplies\n",
      "thestrongrepellingalgorithmtotheresidualgraph.6\n",
      "Algorithm3WeakRepelling\n",
      "?Input:?,h,d,andnsamples?(1),...,?(n)?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "p.Output:\n",
      "edgesetE.1:Let?=(1+2deh(d?1))?2!\"2:FOReachpossibleedge(a,\n",
      "b)?V2:3:FOReachU?V\n",
      "f\n",
      "a,b\n",
      "g\n",
      "ofsize|U|??d??/(h+ln2)?4:\n",
      "ComputeP?GU(?a=1|?b=1)?5:IFminU:|U|=P?GU(?a=1|?b\n",
      "=1)?(1+e??h)+?THENaddedge(a,b)toE?6:OUTPUTETheorem\n",
      "3.6.Let?beanonnegativeintegerstrictlysmallerthand,andconsiderthe\n",
      "antiferromagneticIsingmodel3.2with??(d??)(h+ln2)onagraphG.\n",
      "AlgorithmWeakRepellingreconstructsthegraphwithprobability1?o(1)as\n",
      "p??using12n=O(1+eh)?22de2h(d+1)logpi.i.d.samples,with\n",
      "run-time\n",
      "4\n",
      "!\"?h,d(p2+?).Onp2+?=O\n",
      "StatisticalalgorithmsandproofofTheorem1.1\n",
      "Westartbydescribingthestatisticalalgorithmframeworkintroducedby\n",
      "[1].Inthissectionitisconvenienttoworkwithvariablestakingvaluesin\n",
      "f\n",
      "?1,\n",
      "+1\n",
      "g\n",
      "ratherthan\n",
      "f\n",
      "0,1\n",
      "g\n",
      ".4.1\n",
      "Backgroundonstatisticalalgorithms\n",
      "LetX=\n",
      "f\n",
      "?1,+1\n",
      "g\n",
      "pdenotethespaceofandletDbeaset\n",
      "ofdistributionsoverX.LetFbeasetofsolutions(inourcase,graphs)and\n",
      "Z:D?2FbeamaptakingeachdistributionD?Dtoasubsetofsolutions\n",
      "Z(D)?FthataretobevalidsolutionsforD.Inoursetting,sinceeach\n",
      "7\n",
      "\n",
      "graphicalmodelisidenthereisasinglegraphZ(D)correspondingto\n",
      "eachdistributionD.Forn>0,thedistributionalsearchproblemZoverDand\n",
      "Fusingnsamplesistoavalidsolutionf?Z(D)givenaccesstonrandom\n",
      "samplesfromanunknownD?D.\n",
      "Theclassofalgorithmsweareinterestedinarecalledunbiasedstatistical\n",
      "algorithms,byaccesstoanunbiasedoracle.Otherrelatedclassesof\n",
      "algorithmsarein[1],andsimilarlowerboundscanbederivedforthose\n",
      "aswell.4.1(UnbiasedOracle).LetDbethetruedistribution.The\n",
      "algorithmisgivenaccesstoanoracle,whichwhengivenanyfunctionh:X?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",takesanindependentrandomsamplexfromDandreturnsh(x).These\n",
      "algorithmsaccessthesampleddataonlythroughtheoracle:unbiasedstatistical\n",
      "algorithmsoutsourcethecomputation.Becausethedataisaccessedthrough\n",
      "theoracle,itispossibletoproveunconditionallowerboundsusinginformation-\n",
      "theoreticmethods.Asnotedintheintroduction,manyalgorithmicapproaches\n",
      "canbeimplementedasstatisticalalgorithms.Wenowakeyquantity\n",
      "calledaveragecorrelation.Theaveragecorrelationofasubsetofdistributions\n",
      "D??DrelativetoadistributionDisdenoted?(D?,D),>?-=D11D2??(D\n",
      ",D):=?2(4.1)-D?1,D?1-,|D|D1,D2?D?\n",
      "D\n",
      "where?f,g?D:=Ex?D[f(x)g(x)]andtheratioD1/Drepresentstheratio\n",
      "ofprobabilitymassfunctions,so(D1/D)(x)=D1(x)/D(x).\n",
      "Wequotethetionofstatisticaldimensionwithaveragecorrelation\n",
      "from[1],andthenstatealowerboundonthenumberofqueriesneededbyany\n",
      "statisticalalgorithm.7\n",
      "4.2(Statisticaldimension).Fix?>0,?>0,andsearchproblem\n",
      "ZoversetofsolutionsFandclassofdistributionsDoverX.Weconsiderpairs\n",
      "(D,DD)consistingofa?referencedistribution?DoverXandasetof\n",
      "distributionsDD?Dwiththefollowingproperty:foranysolutionf?F,the\n",
      "setDf=DDZ?1(f)hassizeatleast(1??)?|DD|.Let?(D,DD)bethe\n",
      "largestinteger?sothatforanysubsetD??Dfwith|D?|?|Df|/?,the\n",
      "averagecorrelationis|?(D?,D)|<?(ifthereisnosuch?onecantake?=\n",
      "0).Thestatisticaldimensionwithaveragecorrelation?andsolutionsetbound\n",
      "?istobethelargest?(D,DD)forvalidpairs(D,DD)asdescribed,\n",
      "andisdenotedbySDA(Z,?,?).Theorem4.3([1]).LetXbeadomainandZ\n",
      "asearchproblemoverasetofsolutionsFandaclassofdistributionsDoverX\n",
      ".For?>0and??(0,1),let?=SDA(Z,?,?).Any(possiblyrandomized)\n",
      "unbiasedstatisticalalgorithmthatsolvesZwithprobability?requiresatleast\n",
      "mcallstotheUnbiasedOraclefor;<?(???)(???)2m=min,.2(1??)\n",
      "12?Inparticular,if??1/6,thenanyalgorithmwithsuccessprobabilityat\n",
      "least2/3requiresatleastmin\n",
      "f\n",
      "?/4,1/48?\n",
      "g\n",
      "samplesfromtheUnbiasedOracle.\n",
      "Inordertoshowthatagraphicalmodelonpnodesofmaximumdegreed\n",
      "requirescomputationp(d)inthiscomputationalmodel,wethereforewouldlike\n",
      "toshowthatSDA(Z,?,?)=p(d)with?=p?(d).4.2\n",
      "Softparities\n",
      "rForanysubsetS?[p]ofcardinality|S|=d,let?S(x)=i?Sxibethe\n",
      "parityofvariablesinS.Deneaprobabilitydistributionbyassigningmassto\n",
      "8\n",
      "\n",
      "x?\n",
      "f\n",
      "?1,+1\n",
      "g\n",
      "paccordingto1pS(x)=exp(c??S(x)).(4.2)ZHerecisa\n",
      "constant,andthepartitionfunctionis?Z=exp(c??S(x))=2p?1(ec+e?c\n",
      ").(4.3)x\n",
      "Our!p\"familyofdistributionsDisgivenbythesesoftparitiesoversubsets\n",
      "S?[p],and|D|=d.Thefollowinglemma,provedinthesupplementary\n",
      "material,computescorrelationsbetweendistributions.Lemma4.4.LetUde-\n",
      "notetheuniformdistributionon\n",
      "f\n",
      "?1,+1\n",
      "g\n",
      "p.ForS?=T,thecorrelation?\n",
      "pUS?1,pUT?1?isexactlyequaltozeroforanyvalueofc.IfS=T,the\n",
      "correlation?pUS?1,pUS?1?=1?(ec+e4?c)2?1.Lemma4.5.Forany\n",
      "setD??Dofsizeatleast|D|/pd/2,theaveragecorrelation?(D?\n",
      ",U)?ddp?d/2.\n",
      "Proof.Bytheprecedinglemma,theonlycontributionstothesum(4.1)\n",
      "comesfromchoosing?thesamesetSinthesum,ofwhichthereareafraction\n",
      "1/|Dsuchcorrelationisat!\"|.Each?d/2d/2pmostone!by\"Lemma4.4,\n",
      "so??1/|D|?p/|D|=p/d?dd/pd/2.Hereweusedtheestimate\n",
      "nk?(nk)k.ProofofTheorem1.1.Let?=1/6and?=ddp?d/2,and\n",
      "considerthesetofdistributionsDgivenbysoftparitiesasabove.With\n",
      "referencedistributionD=U,theuniformdistribution,Lemma4.5impliesthat\n",
      "SDA(Z,?,?)ofthestructurelearningproblemoverdistribution(4.2)isatleast\n",
      "?=pd/2/dd.TheresultfollowsfromTheorem4.3.AcknowledgmentsThis\n",
      "workwassupportedinpartbyNSFgrantsCMMI-1335155andCNS-1161964,\n",
      "andbyArmyResearchMURIAwardW911NF-11-1-0036.8\n",
      "2References\n",
      "[1]V.Feldman,E.Grigorescu,L.Reyzin,S.Vempala,andY.Xiao,?Statistical\n",
      "algorithmsandalowerboundfordetectingplantedcliques,?inSTOC,pp.\n",
      "655?664,ACM,2013.[2]G.Bresler,E.Mossel,andA.Sly,?Reconstruction\n",
      "ofMarkovrandomfromsamples:Someobservationsandalgorithms,?\n",
      "Approximation,RandomizationandCombinatorialOptimization,pp.343?356,\n",
      "2008.[3]J.BentoandA.Montanari,?Whichgraphicalmodelsareto\n",
      "learn?,?inNIPS,2009.[4]P.Abbeel,D.Koller,andA.Y.Ng,?Learningfac-\n",
      "torgraphsinpolynomialtimeandsamplecomplexity,?TheJournalofMachine\n",
      "LearningResearch,vol.7,pp.1743?1788,2006.[5]I.Csisz?arandZ.Talata,\n",
      "?Consistentestimationofthebasicneighborhoodofmarkovrandom\n",
      "TheAnnalsofStatistics,pp.123?145,2006.[6]N.P.SanthanamandM.J.\n",
      "Wainwright,?Information-theoreticlimitsofselectingbinarygraphicalmodels\n",
      "inhighdimensions,?Info.Theory,IEEETrans.on,vol.58,no.7,pp.4117?\n",
      "4134,2012.[7]M.Kearns,tnoise-tolerantlearningfromstatistical\n",
      "queries,?JournaloftheACM(JACM),vol.45,no.6,pp.983?1006,1998.[8]\n",
      "C.ChowandC.Liu,?Approximatingdiscreteprobabilitydistributionswithde-\n",
      "pendencetrees,?InformationTheory,IEEETransactionson,vol.14,no.3,pp.\n",
      "462?467,1968.[9]S.Dasgupta,?Learningpolytrees,?inProceedingsoftheFif-\n",
      "teenthconferenceonUncertaintyinintelligence,pp.134?141,Morgan\n",
      "KaufmannPublishersInc.,1999.[10]N.Srebro,?Maximumlikelihoodbounded\n",
      "9\n",
      "\n",
      "tree-widthmarkovnetworks,?inProceedingsoftheSeventeenthconferenceon\n",
      "Uncertaintyinintelligence,pp.504?511,MorganKaufmannPublish-\n",
      "ersInc.,2001.[11]R.L.Dobrushin,?Prescribingasystemofrandomvariables\n",
      "byconditionaldistributions,?TheoryofProbability&amp;ItsApplications,\n",
      "vol.15,no.3,pp.458?486,1970.[12]R.L.DobrushinandS.B.Shlosman,\n",
      "?ConstructivecriterionfortheuniquenessofgibbsinStatisticalphysics\n",
      "anddynamicalsystems,pp.347?370,Springer,1985.[13]J.SalasandA.D.\n",
      "Sokal,?Absenceofphasetransitionforantiferromagneticpottsmodelsviathe\n",
      "dobrushinuniquenesstheorem,?JournalofStatisticalPhysics,vol.86,no.3-4,\n",
      "pp.551?579,1997.[14]D.Gamarnik,D.A.Goldberg,andT.Weber,?Correla-\n",
      "tiondecayinrandomdecisionnetworks,?MathematicsofOperationsResearch,\n",
      "vol.39,no.2,pp.229?261,2013.[15]D.GamarnikandD.Katz,?Corre-\n",
      "lationdecayanddeterministicfptasforcountinglistcoloringsofagraph,?in\n",
      "ProceedingsoftheeighteenthannualACM-SIAMsymposiumonDiscretealgo-\n",
      "rithms,pp.1245?1254,SocietyforIndustrialandAppliedMathematics,2007.\n",
      "[16]D.Weitz,?Countingindependentsetsuptothetreethreshold,?inPro-\n",
      "ceedingsofthethirtyeighthannualACMsymposiumonTheoryofcomputing,\n",
      "pp.140?149,ACM,2006.[17]P.Netrapalli,S.Banerjee,S.Sanghavi,andS.\n",
      "Shakkottai,?Greedylearningofmarkovnetworkstructure,?in48thAllerton\n",
      "Conference,pp.1295?1302,2010.[18]A.Ray,S.Sanghavi,andS.Shakkottai,\n",
      "?Greedylearningofgraphicalmodelswithsmallgirth,?in50thAllertonCon-\n",
      "ference,2012.[19]A.Anandkumar,V.Tan,F.Huang,andA.Willsky,?High-\n",
      "dimensionalstructureestimationinIsingmodels:Localseparationcriterion,?\n",
      "Ann.ofStat.,vol.40,no.3,pp.1346?1375,2012.[20]R.Wu,R.Srikant,\n",
      "andJ.Ni,?LearninglooselyconnectedMarkovrandomStochasticSys-\n",
      "tems,vol.3,no.2,pp.362?404,2013.[21]P.Ravikumar,M.Wainwright,\n",
      "andJ.y,?High-dimensionalIsingmodelselectionusing?1-regularized\n",
      "logisticregression,?TheAnnalsofStatistics,vol.38,no.3,pp.1287?1319,\n",
      "2010.[22]S.-I.Lee,V.Ganapathi,andD.Koller,tstructurelearning\n",
      "ofmarkovnetworksusingl1-regularization,?inAdvancesinneuralInformation\n",
      "processingsystems,pp.817?824,2006.[23]A.Jalali,C.C.Johnson,andP.D.\n",
      "Ravikumar,?Onlearningdiscretegraphicalmodelsusinggreedymethods.,?in\n",
      "NIPS,pp.1935?1943,2011.[24]A.Jalali,P.Ravikumar,V.Vasuki,S.Sang-\n",
      "havi,andU.ECE,?Onlearningdiscretegraphicalmodelsusinggroup-sparse\n",
      "regularization,?inInter.Conf.onAIandStatistics(AISTATS),vol.14,2011.\n",
      "[25]A.Sinclair,P.Srivastava,andM.Thurley,?Approximationalgorithmsfor\n",
      "two-stateantiferromagneticspinsystemsonboundeddegreegraphs,?Journal\n",
      "ofStatisticalPhysics,vol.155,no.4,pp.666?686,2014.\n",
      "9\n",
      "10\n",
      "\n",
      "PP6017.pdf\n",
      "PP6017.pdf 13\n",
      "SparseandLow-RankTensorDecomposition\n",
      "Authoredby:\n",
      "NikhilRao\n",
      "ParikshitShah\n",
      "GongguoTang\n",
      "Abstract\n",
      "Motivatedbytheproblemofrobustfactorizationofalow-ranktensor,\n",
      "westudythequestionofsparseandlow-ranktensordecomposition.We\n",
      "presentantcomputationalalgorithmthatmoesLeurgans'al-\n",
      "goirthmfortensorfactorization.Ourmethodreliesonareductionofthe\n",
      "problemtosparseandlow-rankmatrixdecompositionviathenotionof\n",
      "tensorcontraction.Weusewell-understoodconvextechniquesforsolving\n",
      "thereducedmatrixsub-problemwhichthenallowsustoperformthefull\n",
      "decompositionofthetensor.Wedelineatesituationswheretheproblem\n",
      "isrecoverableandprovidetheoreticalguaranteesforouralgorithm.We\n",
      "validateouralgorithmwithnumericalexperiments.\n",
      "1PaperBody\n",
      "Tensorsareusefulrepresentationalobjectstomodelavarietyofproblemssuch\n",
      "asgraphicalmodelswithlatentvariables[1],audio[20],psycho-\n",
      "metrics[8],andneuroscience[3].Oneconcreteexampleproposedin[1]involves\n",
      "topicmodelinginanexchangeablebag-of-wordsmodelwhereingivenacorpus\n",
      "ofdocumentsonewishestoestimateparametersrelatedtotherenttopics\n",
      "ofthetdocuments(eachdocumenthasauniquetopicassociatedtoit).\n",
      "Bycomputingtheempiricalmomentsassociatedto(exchangeable)bi-grams\n",
      "andtri-gramsofwordsinthedocuments,[1]showsthatthisproblemreducesto\n",
      "thatofa(lowrank)tensordecomposition.Anumberofothermachinelearning\n",
      "tasks,suchasIndependentComponentAnalysis[11],andlearningGaussian\n",
      "mixtures[2]arereducibletothatoftensordecomposition.Whilemosttensor\n",
      "problemsarecomputationallyintractable[12]therehasbeenrenewedinterest\n",
      "indevelopingtractableandprincipledapproachesforthesame[4,5,12,15,\n",
      "19,21,24?27].Inthispaperweconsidertheproblemofperformingtensorde-\n",
      "compositionswhenasubsetoftheentriesofalow-ranktensorXarecorrupted\n",
      "adversarially,sothatthetensorobservedisZ=X+YwhereYisthecorrup-\n",
      "tion.Onemayviewthisproblemasthetensorversionofasparseandlow-rank\n",
      "matrixdecompositionproblemasstudiedin[6,9,10,13].Wedevelopanalgo-\n",
      "1\n",
      "\n",
      "rithmforperformingsuchadecomopsitionandprovidetheoreticalguarantees\n",
      "astowhensuchdecompositionispossible.Ourworkdrawsontwosetsoftools:\n",
      "(a)ThelineofworkaddressingtheRobustPCAprobleminthematrixcase[6,\n",
      "9],and(b)ApplicationofLeaurgans?algorithmfortensordecompositionand\n",
      "tensorinverseproblems[4,17,24].Ouralgorithmiscomputationallyt\n",
      "andscalable,itreliesonthekeynotionoftensorcontractionwhichely\n",
      "reducesatensorproblemofdimensionn?n?ntofourdecompostionproblems\n",
      "formatricesofsizen?n.Onecanthenapplyconvexmethodsforsparseand\n",
      "low-rankmatrixdecompositionfollowedbycertainlinearalgebraicoperations\n",
      "torecovertheconstituenttensors.Ouralgorithmnotonlyproducesthecorrect\n",
      "decompositionofZintoXandY,butalsoproducesthelowrankfactorization\n",
      "ofX.Weareabletoavoidtensorunfoldingbasedapproaches[14,21,26]which\n",
      "areexpensiveandwouldleadtosolvingconvexproblemsthatarelargerby\n",
      "ordersofmagnitude;inthe3rdordercasetheunfoldedmatrixwouldben2?\n",
      "n.Furthermore,ourmethodis1\n",
      "conceptuallysimple,toimpelementaswellastoanalyzetheoretically.Fi-\n",
      "nallyourmethodisalsomodular?itcanbeextendedtothehigherorder\n",
      "caseaswellastosettingswherethecorruptedtensorZhasmissingentries,as\n",
      "describedinSection5.1.1\n",
      "ProblemSetup\n",
      "Inthispaper,vectorsaredenotedusinglowercasecharacters(e.g.x,y,\n",
      "a,b,etc.),matricesbyuppercasecharacters(e.g.X,Y,etc,)andtensorsby\n",
      "upper-caseboldcharacters(e.g.X,T,Aetc.).Wewillworkwithtensorsof\n",
      "thirdorder(representationallytobethoughtofasthree-wayarrays),andthe\n",
      "termmodereferstooneoftheaxesofthetensor.Asliceofatensorreferstoa\n",
      "twodimensionalmatrixgeneratedfromthetensorbyvaryingindicesalongtwo\n",
      "modeswhilekeepingthethirdmodexed.ForatensorXwewillrefertothe\n",
      "indicesoftheithmode-1slice(i.e.,theslicecorresponding(1)totheindices\n",
      "f\n",
      "i\n",
      "g\n",
      "?[n2]?[n3])bySi,where[n2]=\n",
      "f\n",
      "1,2,...,n2\n",
      "g\n",
      "and[n3]is\n",
      "similarly.(1)WedenotethematrixcorrespondingtoSibyXi1.Similarlythe\n",
      "indicesofthekthmode-3slice(3)willbedenotedbySkandthematrixby\n",
      "Xk3.GivenatensorofinterestX,consideritsdecompositionintorankone\n",
      "tensorsrX?iui?vi?wi,X=\n",
      "(1)\n",
      "i=1\n",
      "where\n",
      "f\n",
      "ui\n",
      "g\n",
      "i=1,...,r?Rn1,\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,...,r?Rn2,and\n",
      "f\n",
      "wi\n",
      "g\n",
      "i=1,...,r?Rn3\n",
      "areunitvectors.Here?denotesthetensorproduct,sothatX?Rn1?n2?n3\n",
      "isatensoroforder3anddimensionn1?n2?n3.Withoutlossofgenerality,\n",
      "throughoutthispaperweassumethatn1?n2?n3.Wewillpresentour\n",
      "resultsforthirdordertensors,andanalogousresultsforhigherordersfollow\n",
      "inatransparentmanner.Wewillbedealingwithlow-ranktensors,i.e.those\n",
      "tensorswithr?n1.Tensorscanhaveranklargerthanthedimension,indeedr?\n",
      "n3isaninterestingregime,butfarmorechallengingandisatopicleftforfuture\n",
      "work.Kruskal?sTheorem[16]guaranteesthattensorssatisfyingAssumption\n",
      "1.1belowhaveauniqueminimaldecompositionintorankonetermsoftheform\n",
      "(1).Thenumberoftermsiscalledthe(Kruskal)rank.Assumption1.1.\n",
      "f\n",
      "ui\n",
      "2\n",
      "\n",
      "g\n",
      "i=1,...,r?Rn1,\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,...,r?Rn2,and\n",
      "f\n",
      "wi\n",
      "g\n",
      "i=1,...,r?Rn3aresetsof\n",
      "linearlyindependentvectors.Whilerankdecompositionoftensorsintheworst\n",
      "caseisknowntobecomputationallyintractable[12],itisknownthatthe(mild)\n",
      "assumptionstatedinAssumption1.1aboveforanalgorithmknownas\n",
      "Leurgans?algorithm[4,18]tocorrectlyidentifythefactorsinthisunique\n",
      "decomposition.Inthispaper,wewillmakethisassumptionaboutourtensorX\n",
      "throughout.Thisassumptionmaybeviewedasa?genericity?or?smoothness?\n",
      "assumption[4].In(1),ristherank,?i?Rarescalars,andui?Rn1,vi?\n",
      "Rn2,wi?Rn3arethetensorfactors.LetU?Rn1?rdenotethematrixwhose\n",
      "columnsareui,andcorrespondinglyV?Rn2?randW?Rn3?r.LetY\n",
      "?Rn1?n2?n3beasparsetensortobeviewedasa?corruption?oradversarial\n",
      "noiseaddedtoX,sothatoneobserves:Z=X+Y.Theproblemofinterestis\n",
      "thatofdecomposition,i.e.recoveringXandYfromZ.ForatensorX,we\n",
      "itsmode-3contractionwithrespecttoacontractionvectora?Rn3,denoted\n",
      "byXa3?Rn1?n2,asthefollowingmatrix:n3X3Xaij=Xijkak,(2)k=1\n",
      "sothattheresultingn1?n2matrixisaweightedsumofthemode-3slicesof\n",
      "thetensorX.Underthisnotation,thekthmode-3slicematrixXk3isamode-3\n",
      "contractionwithrespecttothekthcanonicalbasisvector.Wesimilarlydene\n",
      "themode-1contractionwithrespecttoavectorc?Rn1asn1X1Xcjk=Xijk\n",
      "ci.(3)i=1\n",
      "2\n",
      "InthesubsequentdiscussionwewillalsousethefollowingPnotation.For\n",
      "amatrixM,kMkreferstothespectralnorm,kMk?thenuclearnorm,kM\n",
      "k1:=i,j|Mij|theelementwise`1norm,andkMk?:=maxi,j|Mi,j|the\n",
      "elementwise`?norm.1.2\n",
      "Incoherence\n",
      "Theproblemofsparseandlow-rankdecompositionformatriceshasbeen\n",
      "studiedin[6,9,13,22],anditiswellunderstoodthatexactdecompositionis\n",
      "notalwayspossible.Inorderfortheproblemtobeidenable,twosituations\n",
      "mustbeavoided:(a)thelow-rankcomponentXmustnotbesparse,and(b)\n",
      "thesparsecomponentYmustnotbelow-rank.Infact,somethingstrongeris\n",
      "bothnecessaryandt:thetangentspacesofthelow-rankmatrix(with\n",
      "respecttotherankvariety)andthesparsematrix(withrespecttothevariety\n",
      "ofsparsematrices)musthaveatransverseintersection[9].Fortheproblem\n",
      "tobeamenabletorecoveryusingcomptationallytractable(convex)methods,\n",
      "somewhatstronger,incoherenceassumptionsarestandardinthematrixcase\n",
      "[6,7,9].Wewillmakesimilarassumptionsforthetensorcase,whichwenow\n",
      "describe.Giventhedecomposition(1)ofXwethefollowingsubspaces\n",
      "ofmatrices:\n",
      "TU,V=UAT+BVT:A?Rn2?r,B?Rn1?r\n",
      "TV,W=VCT+DWT:C?Rn3?r,D?Rn2?r.\n",
      "(4)\n",
      "ThusTU,Visthesetofrankrmatriceswhosecolumnspacesarecontained\n",
      "inspan(U)orrowspacesarecontainedinspan(V)respectively,andasimilar\n",
      "holdsforTV,WandmatricesV,W.IfQisarankrmatrixwith\n",
      "columnspacespan(U)androwspacespan(V),TU,Visthetangentspaceat\n",
      "3\n",
      "\n",
      "Qwithrespecttothevarietyofrankrmatrices.ForatensorY,thesupport\n",
      "ofYreferstotheindicescorrespondingtothenon-zeroentriesofY.(3)Let?\n",
      "?[n1]?[n2]?[n3]denotethesupportofY.Further,forasliceYi3,let\n",
      "?i?[n1]?[n2](k)denotethecorrespondingsparsitypatternofthesliceYi3\n",
      "(moregenerally?icanbeasththesparsityofthematrixresultingfrom\n",
      "theimodekslice).WhenatensorcontractionofYiscomputedalongmodek,\n",
      "thesparsityoftheresultingmatrixistheunionofthesparsitypatternsof\n",
      "Snk(k)each(matrix)slice,i.e.?(k)=i=1?i.LetS?(k)denotetheset\n",
      "of(sparse)matriceswithsupport?(k).Wethefollowingincoherence\n",
      "parameters:?(U,V):=\n",
      "max\n",
      "kMk?\n",
      "?(V,W):=\n",
      "M?TU,V:kMk?1\n",
      "??(k):=\n",
      "max\n",
      "max\n",
      "kMk?\n",
      "M?TV,W:kMk?1\n",
      "kNk.\n",
      "N?S(?(k)):kNk??1\n",
      "Thequantities?(U,V)and?(V,W)beingsmallimpliesthatforcon-\n",
      "tractionsofthetensorZ,allmatricesinthetangentspaceofthosecontractions\n",
      "withrespecttothevarietyofrankrmatricesarei.e.donothave\n",
      "sparseelements[9].Similarly,??(k)beingsmallimpliesthatallmatriceswith\n",
      "thecontractedsparsitypattern?(k)aresuchthattheirspectrumis\n",
      "i.e.theydonothavelowrank.Wewillseespeccsettingswheretheseforms\n",
      "ofincoherenceholdfortensorsinSection3.\n",
      "2\n",
      "AlgorithmforSparseandLowRankTensorDecomposition\n",
      "Wenowintroduceouralgorithmtoperformsparseandlowranktensor\n",
      "decompositions.WebeginwithaLemma:Lemma2.1.LetX?Rn1?n2?n3,\n",
      "withn1?n2?n3beatensorofrankr?n1.ThentherankofXa3isatmost\n",
      "r.SimilarlytherankofXc1isatmostr.PrProof.ConsideratensorX=i=1\n",
      "?iui?vi?wi.ThereadermayverifyinastraightforwardmannerthatXa3\n",
      "enjoysthedecomposition:Xa3=\n",
      "rX\n",
      "?ihwi,aiuiviT.\n",
      "i=1\n",
      "3\n",
      "(5)\n",
      "TheprooffortherankofXc1isanalogous.Notethatwhile(5)isamatrix\n",
      "decompositionofthecontraction,itisnotasingularvaluedecomposition(the\n",
      "componentsneednotbeorthogonal,forinstance).Recoveringthefactorsneeds\n",
      "anapplicationofsimultaneousdiagonalization,whichwedescribenext.Pr\n",
      "Lemma2.2.[4,18]Supposewearegivenanorder3tensorX=i=1?iui?vi\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?wiofsizen1?n2?n3satisfyingtheconditionsofAssumption1.1.Suppose\n",
      "thecontractionsXa3andXb3arecomputedwithrespecttounitvectorsa,b\n",
      "?Rn3distributedindependentlyanduniformlyontheunitsphereSn3?1and\n",
      "considerthematricesM1andM2formedas:M1=Xa3(Xb3)?\n",
      "M2=(Xb3)?Xa3.\n",
      "ThentheeigenvectorsofM1(correspondingtothenon-zeroeigenvalues)\n",
      "are\n",
      "f\n",
      "ui\n",
      "g\n",
      "i=1,...,r,andtheeigenvectorsofM2Tare\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,...,r.Remark\n",
      "Notethatwhiletheeigenvectors\n",
      "f\n",
      "ui\n",
      "g\n",
      ",\n",
      "f\n",
      "vj\n",
      "g\n",
      "arethusdetermined,asourceof\n",
      "ambiguityremains.Foraorderingof\n",
      "f\n",
      "ui\n",
      "g\n",
      "oneneedstodeterminethe\n",
      "orderinwhich\n",
      "f\n",
      "vj\n",
      "g\n",
      "aretobearranged.Thiscanbe(generically)achievedby\n",
      "usingthe(common)eigenvaluesofM1andM2forpairingi(fthecontractions\n",
      "Xa3,Xb3arecomputedwithrespecttorandomvectorsa,btheeigenvaluesare\n",
      "distinctalmostsurely).SincetheeigenvaluesofM1,M2aredistincttheycanbe\n",
      "usedtopairthecolumnsofUandV.Lemma2.2isessentiallyasimultaneous\n",
      "diagonalizationresult[17]thatfacilitatestensordecomposition[4].Givena\n",
      "tensorT,onecancomputetwocontractionsformode1andapplysimultaneous\n",
      "diagonalizationasdescribedinLemma2.2-thiswouldyieldthefactorsvi,wi\n",
      "(uptosignandreordering).Onecanthenrepeatthesameprocesswithmode3\n",
      "contractionstoobtainui,vi.Inthesteponecanthenobtain?ibysolving\n",
      "asystemoflinearequations.ThefullalgorithmisdescribedinAlgorithm2in\n",
      "thesupplementarymaterial.ForacontractionZvkofatensorZwithrespect\n",
      "toavectorvalongmodek,considersolvingtheconvexproblem:minimizeX\n",
      ",Y\n",
      "kXk?+?kkYk1\n",
      "subjectto\n",
      "Zvk=X+Y.\n",
      "(6)\n",
      "Ouralgorithm,statedinAlgorithm1,proceedsasfollows:Givenatensor\n",
      "Z=X+Y,weperform(3)(3)tworandomcontractions(w.r.t.vectorsa,b)\n",
      "ofthetensoralongmode3toobtainmatricesZa,Zb(3)(3).SinceZisa\n",
      "sumofsparseandlow-rankcomponents,byLemma2.1soarethematricesZa\n",
      ",Zb.Wethususe(6)todecomposethemintoconstituentsparseandlow-rank\n",
      "components,whicharethe(3)(3)(3)(3)(3)(3)contractionsofthematricesXa\n",
      ",Xb,Ya,Yb.WethenuseXa,XbandLemma2.2toobtainthefactorsU,V.\n",
      "Weperformthesameoperationsalongmode1toobtainfactorsV,W.Inthelast\n",
      "step,wesolveforthescalefactors?i(asystemoflinearequations).Algorithm2\n",
      "inthesupplementarymaterial,whichweadoptforourdecompositionproblem\n",
      "inAlgorithm1,essentiallyreliesontheideaofsimultaneousdiagonalizationof\n",
      "matricessharingcommonrowandcolumnspaces[17].Inthispaperwedonot\n",
      "analyzethesituationwhererandomnoiseisaddedtoalltheentries,butonly\n",
      "thesparseadversarialnoisesetting.Wenote,however,thatthekeyalgorithmic\n",
      "insightofusingcontractionstoperformtensorrecoveryisnumericallystableand\n",
      "robustwithrespecttonoise,ashasbeenstudiedin[4,11,17].Parametersthat\n",
      "needtobepickedtoimplementouralgorithmaretheregularizationcots\n",
      "?1,?3.Inthetheoreticalguaranteeswewillseethatthiscanbepickedina\n",
      "stablemanner,andthatarangeofvaluesguaranteeexactdecompositionwhen\n",
      "5\n",
      "\n",
      "thesuitableincoherenceconditionshold.Inpracticethesecoentswould\n",
      "needtobedeterminedbyacross-validationmethod.Notealsothatunder\n",
      "suitablerandomsparsityassumptions[6],theregularizationcotmaybe\n",
      "pickedtobetheinverseofthesquare-rootofthedimension.2.1\n",
      "ComputationalComplexity\n",
      "Thecomputationalcomplexityofouralgorithmisdominatedbythecom-\n",
      "plexityofperfomingthesparseandlow-rankmatrixdecompositionofthecon-\n",
      "tractionsvia(6).Forsimplicity,letusconsider4\n",
      "Algorithm1Algorithmforsparseandlowranktensordecomposition1:2:\n",
      "3:4:5:6:\n",
      "7:8:9:10:\n",
      "11:\n",
      "12:\n",
      "Input:TensorZ,parameters?1,?3.Generatecontractionvectorsa,b?\n",
      "Rn3independentlyanduniformlydistributedonunitsphere.Computemode\n",
      "3contractionsZa3andZb3respectively.Solvetheconvexproblem(6)withv\n",
      "=a,k=3.CalltheresultingsolutionmatricesXa3,Ya3,andregularization\n",
      "parameter?1.Solvetheconvexproblem(6)withv=b,k=3.Calltheresulting\n",
      "solutionmatricesXb3,Yb3andregularizationparameter?3.Computeeigen-\n",
      "decompositionofM1:=Xa3(Xb3)?andM2:=(Xb3)?Xa3.LetUand\n",
      "VdenotethematriceswhosecolumnsaretheeigenvectorsofM1andM2T\n",
      "respectivelycorrespondingtothenon-zeroeigenvalues,insortedorder.(Letr\n",
      "bethe(common)rankofM1andM2.)Theeigenvectors,thusarrangedare\n",
      "denotedas\n",
      "f\n",
      "ui\n",
      "g\n",
      "i=1,...,rand\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,...,r.Generatecontractionvectorsc,d?\n",
      "Rn1independentlyanduniformlydistributedonunitsphere.Solvetheconvex\n",
      "problem(6)withv=c,k=1.CalltheresultingsolutionmatricesXc1,Yc1\n",
      "andregularizationparameter?3.Solvetheconvexproblem(6)withv=d,k=\n",
      "1.CalltheresultingsolutionmatricesXd1,Yd1andregularizationparameter\n",
      "?4.?denoteComputeeigen-decompositionofM3:=Xc1(Xd1)?andM4:=\n",
      "(Xc1)?Xd1.LetV?andWTthematriceswhosecolumnsaretheeigenvectors\n",
      "ofM3andM4respectivelycorrespondingtothenon-zeroeigenvalues,insorted\n",
      "order.(Letrbethe(common)rankofM3andM4.)?,alsoperforming\n",
      "simultaneoussignreversalsasSimultaneouslyreorderthecolumnsofV?,W?\n",
      "necessarysothatthecolumnsofVandVareequal,calltheresultingmatrix\n",
      "Wwithcolumns\n",
      "f\n",
      "wi\n",
      "g\n",
      "i=1,...,r.Solvefor?iinthelinearsystemXa3=\n",
      "rX\n",
      "?iuiviThwi,ai.\n",
      "i=1\n",
      "?:=13:Output:DecompositionX\n",
      "Pr\n",
      "i=1\n",
      "??iui?vi?wi,Y?:=Z?X.\n",
      "thecasewherethetargettensorZ?Rn?n?nhasequaldimensionsinderent\n",
      "modes.Using3astandardordermethod,thesolutionof(6)hasaper\n",
      "iterationcomplexityofO(n),andto1achieveanaccuracyof,Oiterations\n",
      "arerequired[22].Sinceonlyfoursuchstepsneedbe\n",
      "6\n",
      "\n",
      "3\n",
      "performed,thecomplexityofthemethodisOnwhereistheaccuracyto\n",
      "which(6)issolved.Anotheralternativeistoreformulate(6)suchthatitis\n",
      "amenabletogreedyatomicapproaches[23],whichyieldsanorderofmagnitude\n",
      "improvement.Wenotethatincontrast,atensorunfoldingforthisproblem[14,\n",
      "21,26]resultsintheneedtosolvemuchlargerconvexprograms.Forinstance,\n",
      "forZ?Rn?n?n,theresultingmatrixbeofsizen2?nandtheresulting\n",
      "convexprob4wouldlemwouldthenhaveacomplexityofOn.Forhigherorder\n",
      "tensors,thegapincomputationalcomplexitywouldincreasebyfurtherorders\n",
      "ofn.2.2\n",
      "NumericalExperiments\n",
      "Wenowpresentnumericalresultstovalidateourapproach.Weperform\n",
      "experimentsfortensorsofsize50?50?50(non-symmetric).AtensorZis\n",
      "generatedasthesumofalowranktensorXandasparsetensorY.Thelow-\n",
      "rankcomponentisgeneratedasfollows:Threesetsofrunitvecotsui,vi,wi\n",
      "?R50aregeneratedrandomly,independentlyanduniformlydistributedonthe\n",
      "unitsphere.PAlsoarandompositivescalefactor(uniformlydistributedon[0,\n",
      "1]ischosenandthertensorX=i=1?iui?vi?wi.ThetensorYisgenerated\n",
      "by(Bernoulli)randomlysamplingitsentrieswithprobabilityp.Foreachsuch\n",
      "p,weperform10trialsandapplyouralgorithm.Inallourexperiments,the\n",
      "regularizationparameterwaspickedtobe?=?1n.Theoptimizationproblem\n",
      "(6)issolvedusingCVXinMATLAB.WereportsuccessiftheMSEissmaller\n",
      "than10?5,separatelyforboththeXandYcomponents.Weplottheempirical\n",
      "probabilityofsuccessasafunctionofpinFig.1(a),(b),formultiplevaluesof\n",
      "thetruerankr.InFig.1(c),(d)wetestthescalability5\n",
      "0.80.6\n",
      "P(recovery)\n",
      "0.60.4\n",
      "0.4\n",
      "0.200\n",
      "r=1r=2r=3r=4\n",
      "0.2\n",
      "0.5\n",
      "1sparsityx100\n",
      "1.5\n",
      "2\n",
      "00\n",
      "0.5\n",
      "1sparsityx100\n",
      "1.5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "7\n",
      "\n",
      "1\n",
      "00\n",
      "2\n",
      "#InexactRecoveries\n",
      "0.8P(recovery)\n",
      "1\n",
      "r=1r=2r=3r=4\n",
      "#InexactRecoveries\n",
      "1\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "3\n",
      "2\n",
      "1\n",
      "00\n",
      "0.05\n",
      "CorruptionSparsity\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "CorruptionSparsity\n",
      "(a)LowRankCompo-(b)SparseComponent(c)LowRankCompo-(d)\n",
      "SparseComponentnentnent\n",
      "Figure1:Recoveryofthelowrankandsparsecomponentsfromourproposed\n",
      "methods.In(a)and(b)weseethattheprobabilityofrecoveryishigh\n",
      "whenboththerankandsparsityarelow.In(c)and(d)westudythe\n",
      "recoveryerrorforatensorofdimensions300?300?300andrank50.of\n",
      "ourmethod,bygeneratingarandom300?300?300tensorofrank50,and\n",
      "corruptingitwithasparsetensorofvaryingsparsitylevel.Werun5independent\n",
      "trialsandseethatforlowlevelsofcorruption,boththelowrankandsparse\n",
      "componentsareaccuratelyrecoveredbyourmethod.\n",
      "3\n",
      "MainResults\n",
      "Wenowpresentthemainrigorousguaranteesrelatedtotheperformanceof\n",
      "ouralgorithm.Duetospaceconstraints,theproofsaredeferredtothesupple-\n",
      "mentarymaterials.PrTheorem3.1.SupposeZ=X+Y,whereX=i=1?i\n",
      "ui?vi?wi,hasrankr?n1andsuchthatthefactorssatisfyAssumption1.1.\n",
      "SupposeYhassupport?andthefollowingconditionis\n",
      "11??(1)?(V,W)<.??(3)?(U,V)?66ThenAlgoritm1succeedsin\n",
      "exactlyrecoveringthecomponenttensors,i.e.(X,Y)=\n",
      "1?3?(U,V)?(?(3))?(U,V)?Y?)whenever?karepickedsothat?3?,(X,\n",
      "and1?4?(U,V)?(?(3))?(?(3))\n",
      "1?3?(V,W)?(?(1))?(V,W)))p,?1?.Sp,choiceof?3=(3?(U,V\n",
      "1?pand(3)1?4?(V,W)?(?(1))?(?(1))(?(?))p))?1=(3?(V,W1?pforany\n",
      "8\n",
      "\n",
      "p?[0,1]intheserespectiveintervalsguaranteesexactrecovery.(?(?(1)))For\n",
      "amatrixM,thedegreeofM,denotedbydeg(M),isthemaximumnumber\n",
      "ofnon-zerosinanyroworcolumnofM.ForatensorY,wethedegree\n",
      "alongmodek,denotedbydegk(Y)tobethemaximumnumberofnon-zero\n",
      "entriesinanyroworcolumnofamatrixsupportedon?(k)inSection\n",
      "1.2).ThedegreeofYisdenotedbydeg(Y):=maxk?\n",
      "f\n",
      "1,2,3\n",
      "g\n",
      "degk(Y).Lemma\n",
      "3.2.Wehave:\n",
      "??(k)?deg(Y),forallk.ForasubspaceS?Rn,letusthe\n",
      "incoherenceofthesubspaceas:?(S):=maxkPSeik2,i\n",
      "wherePSdenotestheprojectionoperatorontoS,eiisastandardunitvector\n",
      "andk?k2istheEuclideannormofavector.Letusinc(X):=max\n",
      "f\n",
      "?\n",
      "(span(U)),?(span(V)),?(span(W))\n",
      "g\n",
      "inc3(X):=max\n",
      "f\n",
      "?(span(U)),?\n",
      "(span(V))\n",
      "g\n",
      "inc1(X):=max\n",
      "f\n",
      "?(span(V)),?(span(W))\n",
      "g\n",
      ".6\n",
      "Notethatinc(X)<1,always.Formanyrandomensemblesqofinterest,we\n",
      "havethattheincoherencescalesgracefullywiththedimensionn,i.e.:inc(X)?\n",
      "K\n",
      "max\n",
      "f\n",
      "r,logn\n",
      "g\n",
      ".n\n",
      "Lemma3.3.Wehave?(U,V)?2inc(X)\n",
      "?(V,W)?2inc(X).Pr\n",
      "Corollary3.4.LetZ=X+Y,withX=i=1?iui?vi?wiandrankr\n",
      "?n1,thefactorssatisfyAssumption1.1andincoherenceinc(X).SupposeY\n",
      "issparseandhasdegreedeg(Y).Ifthecondition1inc(X)deg(Y)<12?Y?)\n",
      "whentheholdsthenAlgorithm1successfullyrecoversthetruesolution,i.e..\n",
      "(X,Y)=(X,parameters\n",
      "2inc3(X)1?6deg3(Y)inc3(X)?3?,1?8deg3(Y)inc3(X)deg3(Y)\n",
      "2inc1(X)1?6deg1(Y)inc1(X)?1?,.1?8deg1(Y)inc1(X)deg1(Y)\n",
      "p\n",
      "(6inc3(X))Sp,achoiceof?3=(2deg1?p,?1=3(Y))that\n",
      "guaranteesexactrecovery.\n",
      "(6inc1(X))p(2deg1(Y))1?p\n",
      "foranyp?[0,1]isavalidchoice\n",
      "RemarkNotethatCorollary3.4presentsadeterministicguaranteeonthe\n",
      "recoverabilityofasparsecorruptionofalowranktensor,andcanbeviewedasa\n",
      "tensorextensionof[9,Corollary3].Wenowconsider,forthesakeofsimplicity,\n",
      "tensorsofuniformdimension,i.e.X,Y,Z?Rn?n?n.Weshowthatwhenthe\n",
      "low-rankandsparsecomponentsaresuitablyrandom,theapproachoutlinedin\n",
      "Algorithm1achievesexactrecovery.Wetherandomsparsitymodelto\n",
      "beonewhereeachentryofthetensorYisnon-zeroindependentlyandwith\n",
      "identicalprobability?.Wemakenoassumptionaboutthemangitudeofthe\n",
      "entriesofY,onlythatitsnon-zeroentriesarethussampled.PrnLemma3.5.\n",
      "LetX=i=1?iui?vi?wi,whereui,vi,wi?Rareuniformlyrandomly\n",
      "n?1distributedontheunitsphereS.ThentheincoherenceofthetensorX\n",
      "rmax\n",
      "f\n",
      "r,logn\n",
      "g\n",
      "inc(X)?c1nwithprobabilityexceeding1?c2\n",
      "n?3lognforsomeconstantsc1,c2.Lemma3.6.SupposetheentriesofYare\n",
      "sampledaccordingtotherandomsparsitymodel,and?13?n.Thenthe\n",
      "tensorYdeg(Y)?12c1max(log?=On2max(logn,r)n,r)with\n",
      "9\n",
      "\n",
      "?nprobabilityexceeding1?exp?c3max(logn,r)forsomeconstantc3\n",
      ">0.Corollary3.7.LetZ=X+YwhereXislowrankwithrandomfactors\n",
      "aspertheconditionsofLemma13.5andYissparsewithrandomsupport\n",
      "aspertheconditionsinLemma3.6.Provided?Y?)=(X,Y)2r?o\n",
      "n,Algorithm1successfullyrecoversthecorrectdecomposition,i.e.(X,with\n",
      "probabilityexceeding1?n??forsome?>0.Remarks1)Underthissampling\n",
      "model,thecardinalityofthesupportofYisallowedtobeaslarge3asm=\n",
      "O(n2log?1n)whentherankrisconstant(independentofn).2)Wecould\n",
      "equivalentlyhavelookedatauniformlyrandomsamplingmodel,i.e.onewhere\n",
      "asupportsetofsizemischosenuniformlyrandomlyfromthesetofallpossible\n",
      "supportsetsofcardinalityatmostm,andourresultsforexactrecoverywould\n",
      "havegonethrough.Thisfollowsfromtheequivalenceprincipleforsuccessful\n",
      "recoverybetweenBernoullisamplinganduniformsampling,see[6,Appendix\n",
      "7.1].3)Notethatfortherandomsparsityensemble,[6]showsthatachoiceof?\n",
      "=?1nensuresexactrecovery(anadditionalconditionregardingthemagnitudes\n",
      "ofthefactorsisneeded,however).Byextension,thesamechoicecanbeshown\n",
      "toworkforoursetting.7\n",
      "4\n",
      "Extensions\n",
      "TheapproachdescribedinAlgorithm1andtheanalysisisquitemodularand\n",
      "canbeadaptedtovarioussettingstoaccountfortformsofmeasurements\n",
      "androbustnessmodels.Wedonotpresentananalysisofthesesituationsdue\n",
      "tospaceconstraints,butoutlinehowtheseextensionsfollowfromthecurrent\n",
      "developmentinastraightforwardmanner.1)HigherOrderTensors:Algorithm\n",
      "1canbeextendednaturallytothehigherordersetting.Recallthatinthe\n",
      "thirdordercase,oneneedstorecovertwocontractionsalongthethirdmodeto\n",
      "discoverfactorsU,Vandthentwocontractionsalongtherstmodetodiscover\n",
      "factorsV,W.ForanorderKtensoroftheformZ?Rn1?...?nKwhichis\n",
      "thesumofalowrankcomponentPrNK(l)X=i=1?il=1uiandasparse\n",
      "componentY,oneneedstocomputehigherordercontractionsofZalongK?1\n",
      "tmodes.ForeachoftheseK?1modestheresultingcontractionisthe\n",
      "sumofasparseandlow-rankmatrix,andthuspairsofmatrixproblemsofthe\n",
      "form(6)revealthesparseandlow-rankcomponentsofthecontractions.The\n",
      "low-rankfactorscanthenberecoveredviaapplicationofLemma2.2andthefull\n",
      "decompositioncanthusberecovered.ThesameguaranteesasinTheorem3.1\n",
      "andCorollary3.4holdverbatim(thenotionsofincoherenceinc(X)anddegree\n",
      "deg(Y)oftensorsneedtobeextendedtothehigherordercaseinthenatural\n",
      "way)2)Blocksparsity:Situationswhereentireslicesofthetensorarecorrupted\n",
      "mayhappeninrecommendersystemswithadversarialratings[10].Anatural\n",
      "approachinthiscaseistouseaconvexrelaxationoftheformminimizeM1,M2\n",
      "?kkM1k?+kM2k1,2\n",
      "Zvk=M1+M2Pinplaceof(6)inAlgorithm1.Intheabove,kMk1,2\n",
      ":=ikMik2,whereMiistheithcolumnofM.Sinceexactrecoveryofthe\n",
      "block-sparseandlow-rankcomponentsofthecontractionsareguaranteedvia\n",
      "thisrelaxationundersuitableassumptions[10],thealgorithmwouldinherit\n",
      "associatedprovableguarantees.subjectto\n",
      "10\n",
      "\n",
      "3)Tensorcompletion:Inapplicationssuchasrecommendationsystems,it\n",
      "maybedesirabletoperformtensorcompletioninthepresenceofsparsecor-\n",
      "ruptions.In[24],anadaptationofLeurgans?algorithmwaspresentedfor\n",
      "performingcompletionfrommeasurementsrestrictedtoonlyfourslicesofthe\n",
      "tensorwithnear-optimalsamplecomplexity(undersuitablegenericityassump-\n",
      "tionsaboutthetensor).WenotethatitisstraightforwardtoblendAlgorithm\n",
      "1withthismethodtoachievecompletionwithsparsecorruptions.Recalling\n",
      "thatZ=X+YandthereforeZk3=Xk3+Yk3(i.e.thekthmode3sliceofZ\n",
      "isasumofsparseandlowrankslicesofXandY),ifonlyasubsetofelements\n",
      "ofZk3(sayP?Zk3)isobservedforsomeindexset?,wecanreplace(6)in\n",
      "Algorithm1with\n",
      "minimize?kkM1k?+kM2k1subjecttoP?Zvk=P?(M1+M2).M1\n",
      ",M2\n",
      "Undersuitableincoherenceassumptions[6,Theorem1.2],theabovewill\n",
      "achieveexactrecoveryoftheslices.Oncefourslicesareaccuratelyrecovered,\n",
      "onecanthenuseLeurgans?algorithmtorecoverthefulltensor[24,Theorem\n",
      "3.6].Indeedtheaboveideacanbeextendedmoregenerallytotheconceptofde-\n",
      "convolvingasumofsparseandlow-ranktensorsfromseparablemeasurements\n",
      "[24].4)Non-convexapproaches:Abasicprimitiveforsparseandlow-rank\n",
      "tensordecompositionusedinthispaperisthatofusing(6)formatrixdecom-\n",
      "position.Moretnon-convexapproachessuchastheonesdescribedin\n",
      "[22]maybeusedinsteadtospeedupAlgorithm1.Thesealternative\n",
      "12nonconvexmethods[22]requreO(rn)stepsperiterations,andOlog\n",
      "iterationsresultingina\n",
      "12totalcomplexityofOrnlogforsolvingthedecompositionofthecon-\n",
      "tractionstoanaccuracyof.\n",
      "2References\n",
      "[1]A.ANANDKUMAR,R.GE,D.HSU,ANDS.M.KAKADE,Atensor\n",
      "approachtolearningmixedmembershipcommunitymodels,TheJournalof\n",
      "MachineLearningResearch,15(2014),pp.2239?2312.[2]A.ANANDKUMAR\n",
      ",R.GE,D.HSU,S.M.KAKADE,ANDM.TELGARSKY,Tensor\n",
      "decompositionsforlearninglatentvariablemodels,Tech.Rep.1,2014.\n",
      "8\n",
      "[3]C.BECKMANNANDS.SMITH,Tensorialextensionsofindependent\n",
      "componentanalysisformultisubjectFMRIanalysis,NeuroImage,25(2005),\n",
      "pp.294?311.[4]A.BHASKARA,M.CHARIKAR,A.MOITRA,AND\n",
      "A.VIJAYARAGHAVAN,Smoothedanalysisoftensordecompositions,inPro-\n",
      "ceedingsofthe46thAnnualACMSymposiumonTheoryofComputing,ACM,\n",
      "2014,pp.594?603.[5]S.BHOJANAPALLIANDS.SANGHAVI,Anewsam-\n",
      "plingtechniquefortensors,arXivpreprintarXiv:1502.05023,(2015).[6]E.J.C\n",
      "ANDE`S,X.LI,Y.MA,ANDJ.WRIGHT,Robustprincipalcomponent\n",
      "analysis?,JournaloftheACM,58(2011),pp.11?37.[7]E.J.CANDE`SAND\n",
      "B.RECHT,Exactmatrixcompletionviaconvexoptimization,Foundationsof\n",
      "11\n",
      "\n",
      "ComputationalMathematics,9(2009),pp.717?772.[8]R.B.CATTELL,\n",
      "Parallelproportionalandotherprinciplesfordeterminingthechoice\n",
      "offactorsbyrotation,Psychometrika,9(1944),pp.267?283.[9]V.CHAN-\n",
      "DRASEKARAN,S.SANGHAVI,P.A.PARRILO,ANDA.S.WILLSKY,\n",
      "Rank-sparsityincoherenceformatrixdecomposition,SIAMJournalonOpti-\n",
      "mization,21(2011),pp.572?596.[10]Y.CHEN,H.XU,C.CARAMANIS\n",
      ",ANDS.SANGHAVI,Robustmatrixcompletionandcorruptedcolumns,in\n",
      "Proceedingsofthe28thInternationalConferenceonMachineLearning(ICML-\n",
      "11),L.GetoorandT.Sceds.,NewYork,NY,USA,2011,ACM,pp.\n",
      "873?880.[11]N.GOYAL,S.VEMPALA,ANDY.XIAO,FourierPCAand\n",
      "robusttensordecomposition,inProceedingsofthe46thAnnualACMSympo-\n",
      "siumonTheoryofComputing,ACM,2014,pp.584?593.[12]C.J.HILLAR\n",
      "ANDL.-H.LIM,MosttensorproblemsareNP-hard,JournaloftheACM,60\n",
      "(2013),pp.45:1?45:39.[13]D.HSU,S.KAKADE,ANDT.ZHANG,Ro-\n",
      "bustmatrixdecompositionwithsparsecorruptions,InformationTheory,IEEE\n",
      "Transactionson,57(2011),pp.7221?7234.[14]B.HUANG,C.MU,D.G\n",
      "OLDFARB,ANDJ.WRIGHT,Provablemodelsforrobustlow-ranktensor\n",
      "completion,PJournalofOptimization,11(2015),pp.339?364.[15]A.K\n",
      "RISHNAMURTHYANDA.SINGH,Low-rankmatrixandtensorcompletion\n",
      "viaadaptivesampling,inAdvancesinNeuralInformationProcessingSystems,\n",
      "2013.[16]J.B.KRUSKAL,Three-wayarrays:Rankanduniquenessoftrilinear\n",
      "decompositions,withapplicationtoarithmeticcomplexityandstatistics,Linear\n",
      "AlgebraApplicat.,18(1977).[17]V.KULESHOV,A.CHAGANTY,ANDP.L\n",
      "IANG,Tensorfactorizationviamatrixfactorization,arXiv.org,(2015).[18]S.L\n",
      "EURGANS,R.ROSS,ANDR.ABEL,Adecompositionforthree-wayarrays,\n",
      "SIAMJournalonMatrixAnalysisandApplications,14(1993),pp.1064?1083.\n",
      "[19]Q.LI,A.PRATER,L.SHEN,ANDG.TANG,Overcompleteten-\n",
      "sordecompositionviaconvexoptimization,inIEEEInternationalWorkshop\n",
      "onComputationalAdvancesinMulti-SensorAdaptiveProcessing(CAMSAP),\n",
      "Cancun,Mexico,Dec.2015.[20]N.MESGARANI,M.SLANEY,AND\n",
      "S.A.SHAMMA,Discriminationofspeechfromnon-speechbasedonmulti-\n",
      "scalespectro-temporalmodulations,Audio,SpeechandLanguageProcessing,\n",
      "IEEETransactionson,14(2006),pp.920?930.[21]C.MU,B.HUANG\n",
      ",J.WRIGHT,ANDD.GOLDFARB,Squaredeal:Lowerboundsandim-\n",
      "provedrelaxationsfortensorrecovery,preprintarXiv:1307.5870,2013.[22]P.\n",
      "NETRAPALLI,U.NIRANJAN,S.SANGHAVI,A.ANANDKUMAR,\n",
      "PCA,inAdvancesinNeuralInformationProcessingSystems,2014.\n",
      "AND\n",
      "P.JAIN,Non-convexrobust\n",
      "[23]N.RAO,P.SHAH,ANDS.WRIGHT,Forward-backwardgreedy\n",
      "algorithmsforsignaldemixing,inSignals,SystemsandComputers,2013Asilo-\n",
      "marConferenceon,IEEE,2014.[24]P.SHAH,N.RAO,ANDG.TANG,\n",
      "Optimallow-ranktensorrecoveryfromseparablemeasurements:Fourcontrac-\n",
      "tionsarXiv.org,(2015).[25]G.TANGANDP.SHAH,Guaranteed\n",
      "tensordecomposition:Amomentapproach,InternationalConferenceonMa-\n",
      "chineLearning(ICML2015),(2015),pp.1491?1500.[26]R.TOMIOKA,K.H\n",
      "12\n",
      "\n",
      "AYASHI,ANDH.KASHIMA,Estimationoflow-ranktensorsviaconvexopti-\n",
      "mization,preprintarXiv:1010.0789,2011.[27]M.YUANANDC.-H.ZHANG,\n",
      "Ontensorcompletionvianuclearnormminimization,preprintarXiv:1405.1773,\n",
      "2014.\n",
      "9\n",
      "13\n",
      "\n",
      "PP5087.pdf\n",
      "PP5087.pdf 14\n",
      "tOptimizationforSparseGaussian\n",
      "ProcessRegression\n",
      "Authoredby:\n",
      "AaronHertzmann\n",
      "DavidJ.Fleet\n",
      "YanshuaiCao\n",
      "MarcusA.Brubaker\n",
      "Abstract\n",
      "Weproposeancientdiscreteoptimizationalgorithmforselecting\n",
      "asubsetoftrainingdatatoinducesparsityforGaussianprocessregres-\n",
      "sion.Thealgorithmestimatesthisinducingsetandthehyperparameters\n",
      "usingasingleobjective,eitherthemarginallikelihoodoravariational\n",
      "freeenergy.Thespaceandtimecomplexityarelinearinthetrainingset\n",
      "size,andthealgorithmcanbeappliedtolargeregressionproblemson\n",
      "discreteorcontinuousdomains.Empiricalevaluationshowsstate-of-art\n",
      "performanceinthediscretecaseandcompetitiveresultsinthecontinuous\n",
      "case.\n",
      "1PaperBody\n",
      "GaussianProcess(GP)learningandinferencearecomputationallyprohibitive\n",
      "withlargedatasets,havingtimecomplexitiesO(n3)andO(n2),wherenisthe\n",
      "numberoftrainingpoints.algorithmsexistthatscalelinearlyin\n",
      "thetrainingsetsize(see[10]forareview).Theyconstructalow-rankapprox-\n",
      "imationtotheGPcovariancematrixoverthefulldatasetusingasmallsetof\n",
      "inducingpoints.Someapproachesselectinducingpointsfromtrainingpoints\n",
      "[7,8,12,13].Butthesemethodsselecttheinducingpointsusingadhoccriteria;\n",
      "i.e.,theyusetobjectivefunctionstoselectinducingpointsandtoop-\n",
      "timizeGPhyperparameters.Morepowerfulmethods[14,15,16]\n",
      "useasingleobjectivefunctionandallowinducingpointstomovefreelyoverthe\n",
      "inputdomainwhicharelearnedviagradientdescent.Thiscontinuousrelaxation\n",
      "isnotfeasible,however,iftheinputdomainisdiscrete,orifthekernelfunction\n",
      "isnottiableintheinputvariables.Asaresult,thereareproblemsin\n",
      "myraiddomains,likebio-informatics,linguisticsandcomputervisionwherecur-\n",
      "rentsparseGPregressionmethodsareinapplicableore.Weintroduce\n",
      "antalgorithmforGPregression.Themethodoptimizesa\n",
      "1\n",
      "\n",
      "singleobjectiveforjointselectionofinducingpointsandGPhyperparameters.\n",
      "Notably,itoptimizeseitherthemarginallikelihood,oravariationalfreeenergy\n",
      "[15],exploitingtheQRfactorizationofapartialCholeskydecompositiontoef-\n",
      "tlyapproximatethecovariancematrix.Becauseitchoosesinducingpoints\n",
      "fromthetrainingdata,itisapplicabletoproblemsondiscreteorcontinuous\n",
      "inputdomains.Toourknowledge,itisthemethodforselectingdiscretein-\n",
      "ducingpointsandhyperparametersthatoptimizesasingleobjective,withlinear\n",
      "spaceandtimecomplexity.Itisshowntooutperformothermethodsondiscrete\n",
      "datasetsfrombio-informaticsandcomputervision.Oncontinuousdomainsit\n",
      "iscompetitivewiththePseudo-pointGP[14](SPGP).1.1PreviousWorkEf-\n",
      "tstate-of-the-artmethodsareO(m2n)intimeandO(mn)\n",
      "inspaceforlearning.Theycomputethepredictivemeanandvarianceintime\n",
      "O(m)andO(m2).Methodsbasedoncontinuousrelaxation,whenapplicable,\n",
      "entaillearningO(md)continuousparameters,wheredistheinputdimension.\n",
      "Inthediscretecase,combinatorialoptimizationisrequiredtoselecttheinduc-\n",
      "ingpoints,andthisis,ingeneral,intractable.Existingdiscrete\n",
      "methodsthereforeuseothercriteriatogreedilyselectinducingpoints[7,8,12,\n",
      "13].Althoughtheircriteriaareeachintheirownway(e.g.,[8,12]take\n",
      "aninformationtheoreticperspective),theyaregreedyanddonotusethesame\n",
      "objectivetoselectinducingpointsandtoestimateGPhyperparameters.1\n",
      "ThevariationalformulationofTitsias[15]treatsinducingpointsasvari-\n",
      "ationalparameters,andgivesaobjectivefordiscreteandcontinuous\n",
      "inducingpointmodels.Inthecontinuouscase,itusesgradient-basedoptimiza-\n",
      "tiontoinducingpointsandhyperparameters.Inthediscretecase,our\n",
      "methodoptimizesthesamevariationalobjectiveofTitsias[15],butisa\n",
      "cantimprovementovergreedyforwardselectionusingthevariationalobjective\n",
      "asselectioncriteria,orsomeothercriteria.Inparticular,giventhecostofeval-\n",
      "uatingthevariationalobjectiveonalltrainingpoints,Titsias[15]evaluatesthe\n",
      "objectivefunctiononasmallrandomsubsetofcandidatesateachiteration,and\n",
      "thenselectthebestelementfromthesubset.Thisapproximationisoftenslow\n",
      "toachievegoodresults,asweexplainanddemonstratebelowinSection4.1.\n",
      "Theapproachin[15]alsousesgreedyforwardselection,whichprovidesnoway\n",
      "totheinducingsetafterhyperparameteroptimization,excepttodiscard\n",
      "allpreviousinducingpointsandrestartselection.Hence,theobjectiveisnot\n",
      "guaranteedtodecreaseaftereachrestart.Bycomparison,ourformulationcon-\n",
      "sidersallcandidatesateachstep,andrevisitingpreviousselectionsist,\n",
      "andguaranteedtodecreasetheobjectiveorterminate.Ourlow-rankdecom-\n",
      "positionisinspiredbytheCholeskywithSideInformation(CSI)algorithmfor\n",
      "kernelmachines[1].WeextendthatapproachtoGPregression.First,wealter\n",
      "theformofthelowrankmatrixfactorizationinCSItobesuitableforGPregres-\n",
      "sionwithfull-rankdiagonalterminthecovariance.Second,theCSIalgorithm\n",
      "selectsinducingpointsinasinglegreedypassusinganapproximateobjective.\n",
      "Weproposeaniterativeoptimizationalgorithmthatswapspreviouslyselected\n",
      "pointswithnewcandidatesthatareguaranteedtolowertheobjective.Finally,\n",
      "weperforminducingsetselectionjointlywithgradient-basedhyperparameter\n",
      "estimationinsteadofthegridsearchinCSI.Ouralgorithmselectsinducing\n",
      "2\n",
      "\n",
      "pointsinaprincipledfashion,optimizingthevariationalfreeenergyorthelog\n",
      "likelihood.ItdoessowithtimecomplexityO(m2n),andinpracticeprovides\n",
      "animprovedquality-speedoverotherdiscreteselectionmethods.\n",
      "2\n",
      "SparseGPRegression\n",
      "Lety?Rbethenoisyoutputofafunction,f,ofinputx.LetX=\n",
      "f\n",
      "xi\n",
      "g\n",
      "ni=1denotentraininginputs,eachbelongingtoinputspaceD,whichisnot\n",
      "necessarilyEuclidean.Lety?Rndenotethecorrespondingvectoroftraining\n",
      "outputs.Underafullzero-meanGP,withthecovariancefunctionE[yiyj]=\n",
      "?(xi,xj)+?21[i=j],\n",
      "(1)2\n",
      "where?isthekernelfunction,1[?]istheusualindicatorfunction,and\n",
      "?isthevarianceoftheobservationnoise,thepredictivedistributionoverthe\n",
      "outputf?atatestpointx?isnormallydistributed.Themeanandvariance\n",
      "ofthepredictivedistributioncanbeexpressedas?1T??=?(x?)K+?\n",
      "2Iny?1T2v?=?(x?,x?)??(x?)K+?2In?(x?)where\n",
      "Inisthen?nidentitymatrix,Kisthekernelmatrixwhoseijthelementis\n",
      "?(xi,xj),and?(x?)isthecolumnvectorwhoseithelementis?(x?,xi\n",
      ").ThehyperparametersofaGP,denoted?,comprisetheparametersofthe\n",
      "kernelfunction,andthenoisevariance?2.Thenaturalobjectiveforlearning\n",
      "?isthenegativemarginalloglikelihood(NMLL)ofthetrainingdata,?log\n",
      "(P(y|X,?)),givenuptoaconstantby?1Efull(?)=(y>K+?2Iny+\n",
      "log|K+?2In|)/2.(2)ThecomputationalbottleneckliesintheO(n2)\n",
      "storageandO(n3)inversionofthefullcovariancematrix,K+?2In.Tolower\n",
      "thiscostwithasparseapproximation,Csat?oandOpper[5]andSeegeretal.\n",
      "[12]proposedtheProjectedProcess(PP)model,whereinasetofminducing\n",
      "pointsareusedtoconstructalow-rankapproximationofthekernelmatrix.In\n",
      "thediscretecase,wheretheinducingpointsareasubsetofthetrainingdata,\n",
      "withindicesI?\n",
      "f\n",
      "1,2,...,n\n",
      "g\n",
      ",thisapproachamountstoreplacingthekernel\n",
      "matrixKwiththefollowingNystr?omapproximation[11]:?=K[:,I]K[I,I]?1\n",
      "K[I,:]K'K(3)whereK[:,I]denotesthesub-matrixofKcomprisingcolumns\n",
      "indexedbyI,andK[I,I]isthesub-matrixofKcomprisingrowsandcolumns\n",
      "indexedbyI.WeassumetherankofKismorhighersowecanalways\n",
      "suchrank-mapproximations.ThePPNMLListhenalgebraically?inEq.(2),\n",
      "i.e.,equivalenttoreplacingKwithK\n",
      "E(?,I)=ED(?,I)+EC(?,I)/2,(4)2\n",
      "?+?2In)?1y,andmodelcomplexityEC(?,I)=log|K?+?2\n",
      "In|.withdatatermED(?,I)=y>(KThecomputationalcostreduction\n",
      "fromO(n3)toO(m2n)associatedwiththenewlikelihoodisachievedby\n",
      "applyingtheWoodburyinversionidentitytoED(?,I)andEC(?,I).The\n",
      "objectivein(4)canbeviewedasanapproximateloglikelihoodforthefull\n",
      "GPmodel,orastheexactloglikelihoodforanapproximatemodel,calledthe\n",
      "DeterministicallyTrainedConditional[10].ThesamePPmodelcanalsobe\n",
      "obtainedbyavariationalargument,asin[15],forwhichthevariationalfree\n",
      "energyobjectivecanbeshowntobeEq.(4)plusoneextraterm;i.e.,\n",
      "F(?,I)=ED(?,I)+EC(?,I)+EV(?,I)/2,(5)?arisesfrom\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thevariationalformulation.IteelyregularizeswhereEV(?,I)=??2\n",
      "tr(K?K)thetracenormoftheapproximationresidualofthecovariancematrix.\n",
      "Thekernelmachineof[1]?however?isafreeparameterthatissetmanually.\n",
      "alsousesaregularizeroftheform?tr(K?K),\n",
      "3\n",
      "toptimization\n",
      "Wenowoutlineouralgorithmforoptimizingthevariationalfreeenergy\n",
      "(5)toselecttheinducingsetIandthehyperparameters?.(Thenegative\n",
      "log-likelihood(4)issimilarlyminimizedbysimplydiscardingtheEVterm.)\n",
      "Thealgorithmisaformofhybridcoordinatedescentthatalternatesbetween\n",
      "discreteoptimizationofinducingpoints,andcontinuousoptimizationofthe\n",
      "hyperparameters.Wedescribethealgorithmtoselectinducingpoints,and\n",
      "thendiscusscontinuoushyperparameteroptimizationandterminationcriteria\n",
      "inSec.3.4.Findingtheoptimalinducingsetisacombinatorialproblem;global\n",
      "optimizationisintractable.Instead,theinducingsetisinitializedtoarandom\n",
      "subsetofthetrainingdata,whichisthenbyanumberofswap\n",
      "updatesateachiteration.1Inasingleswapupdate,arandomlychoseninducing\n",
      "pointisconsideredforreplacement.Ifswappingdoesnotimprovetheobjective,\n",
      "thentheoriginalpointisretained.Therearen?mpotentialreplacementsfor\n",
      "eacheachswapupdate;thekeyistotlydeterminewhichwillmaximally\n",
      "improvetheobjective.Withthetechniquesdescribedbelow,thecomputation\n",
      "timerequiredtoapproximatelyevaluateallpossiblecandidatesandswapan\n",
      "inducingpointisO(mn).SwappingallinducingpointsoncetakesO(m2n)\n",
      "time.3.1\n",
      "Factoredrepresentation\n",
      "Tosupportientevaluationoftheobjectiveandswapping,weuseafac-\n",
      "toredrepresentationofthekernelmatrix.GivenaninducingsetIofkpoints,\n",
      "foranyk?m,thelow-rankNystr?omapproximationtothekernelmatrix(Eq.\n",
      "3)canbeexpressedintermsofapartialCholeskyfactorization:?=K[:,I]K[I,\n",
      "I]?1K[I,:]=L(I)L(I)>,K\n",
      "(6)\n",
      "n?k\n",
      "whereL(I)?Ris,uptopermutationofrows,lowertrapezoidalmatrix(i.e.,\n",
      "hasak?ktoplowertriangularblock,againuptorowpermutation).The\n",
      "derivationofEq.6followsfromProposition1in[1],andthefactthat,given\n",
      "theorderedsequenceofpivotsI,thepartialCholeskyfactorizationisunique.\n",
      "UsingthisfactorizationandtheWoodburyidentities(droppingthedependence\n",
      "on?andIforclarity),thetermsofthenegativemarginallog-likelihood(4)and\n",
      "variationalfreeenergy(5)become\n",
      "?1>ED=??2y>y?y>LL>L+?2ILy(7)\n",
      "EC=log(?2)n?k|L>L+?2I|(8)EV=??2(tr(K)?tr(L>L))\n",
      "(9)\n",
      "e=[L>,?Ik]>,whereWecanfurthersimplifythedatatermbyaugmenting\n",
      "thefactormatrixasLTTTe=[y,0k]istheyvectorwithkzeroesappended:\n",
      "Ikisthek?kidentitymatrix,andy\n",
      "e(Le>L)e?1Le>ye>LeED=??2y>y?y(10)1\n",
      "4\n",
      "\n",
      "Theinducingsetcanbeincrementallyconstructed,asin[1],howeverwe\n",
      "foundnobtothis.\n",
      "3\n",
      "e=QRbeaQRfactorizationofL,ewhereQ?R(n+k)?khasorthogonal\n",
      "columnsandNow,letLR?Rk?kisinvertible.Thetwotermsinthe\n",
      "objectivesimplifyfurtherto\n",
      "ek2ED=??2kyk2?kQ>y(11)EC=(n?k)log(?2)+2log|R|.\n",
      "(12)\n",
      "3.2FactorizationupdateHerewepresentthemechanicsoftheswapupdate\n",
      "algorithm,see[3]forpseudo-code.Supposewewishtoswapinducingpointi\n",
      "withcandidatepointjinIm,theinducingsetofsizem.Werstmodifythe\n",
      "factormatricesinordertoremovepointifromIm,i.e.todowndatethefactors.\n",
      "ThenweupdateallthekeytermsusingonestepofCholeskyandQRfactor-\n",
      "izationwiththenewpointj.Downdatingtoremoveinducingpointirequires\n",
      "thatweshiftthecorrespondingcolumns/rowsineQ,Randtothelastrowof\n",
      "R.Wecanthensimplythefactorizationtotheright-mostcolumnsofL,discard\n",
      "theselastcolumnsandrows,andmodifyrelatedquantities.Whenpermuting\n",
      "theorderoftheinducingpoints,theunderlyingGPmodelisinvariant,but\n",
      "thematricesinthefactoredrepresentationarenot.Ifneeded,anytwopoints\n",
      "inIm,canbepermuted,andtheCholeskyorQRfactorscanbeupdatedin\n",
      "timeO(mn).Thisisdonewiththetpivotpermutationpresentedinthe\n",
      "AppendixeInthisway,downdatingof[1],withminormotoaccount\n",
      "fortheaugmentedformofL.andremovingitakeO(mn)time,asdoesthe\n",
      "updatingwithpointj.em?1,Qm?1,Rm?1,andinducingsetIm?1.Toadd\n",
      "jtoIm?1,Afterdowndating,wehavefactorsLandupdatethefactorstorank\n",
      "m,onestepofCholeskyfactorizationisperformedwithpointj,foreisformed\n",
      "aswhich,ideally,thenewcolumntoappendtoL.q?m?1)[:,j]?m?1)[j,j]\n",
      "`m=(K?K(K?K(13)?m?1=Lm?1Lm?1T.Then,wesetLem=[L\n",
      "em?1>m],where>misjust`maugmentedwhereK>with?em=[0,0,...,\n",
      "?,...,0,0].TheupdatesareQm=[Qm?1qm],whereqmisgiven>?\n",
      "?byGram-Schmidtorthogonalization,qm=((I?Qm?1Q>m?1)`m)/k(I?\n",
      "Qm?1Qm?1)`mk,andem=QmRm.RmisupdatedfromRm?1sothatL\n",
      "3.3EvaluatingcandidatesNextweshowhowtoselectcandidatesforinclusion\n",
      "intheinducingset.Wederivetheexactchangeintheobjectivedueto\n",
      "addinganelementtoIm?1.Laterwewillprovideanapproximationtothis\n",
      "objectivechangethatcanbecomputedtly.em?1,Qm?1,andRm?1\n",
      ",wewishtoevaluatethechangeGivenaninducingsetIm?1,andmatricesL\n",
      "inEq.5forIm=Im?1?j.Thatis,?F?F(?,Im?1)?F(?,Im)=(?ED+\n",
      "?EC+?EV)/2,where,basedonthemechanicsoftheincrementalupdates\n",
      "above,onecanshowthat.\n",
      "?2?2kI?Qm?1Q>(14)?ED=??2(ey>I?Qm?1Q>m?1`mkm?1\n",
      "`m)\n",
      "?2?EC=log?2?logk(I?Qm?1Q>(15)m?1)`mk?EV=??2k`m\n",
      "k2\n",
      "(16)\n",
      "Thisgivestheexactdecreaseintheobjectivefunctionafteraddingpoint\n",
      "5\n",
      "\n",
      "j.ForasinglepointthisevaluationisO(mn),sotoevaluatealln?mpoints\n",
      "wouldbeO(mn2).3.3.1FastapproximatecostreductionWhileO(mn2)is\n",
      "prohibitive,computingtheexactchangeisnotrequired.Rather,weonlyneed\n",
      "arankingofthebestfewcandidates.Thus,insteadofevaluatingthechangein\n",
      "theobjectiveexactly,weuseanntapproximationbasedonasmallnum-\n",
      "ber,z,oftrainingpointswhichprovideinformationabouttheresidualbetween\n",
      "thecurrentlow-rankcovariancematrix(basedoninducingpoints)andthefull\n",
      "covariancematrix.Afterthisapproximationproposesacandidate,weusethe\n",
      "actualobjectivetodecidewhethertoincludeit.Thetechniquesbelowreduce\n",
      "thecomplexityofevaluatingalln?mcandidatestoO(zn).Tocomputethe\n",
      "changeinobjectiveforonecandidate,weneedthenewcolumnoftheupdated\n",
      "Choleskyfactorization,`m.InEq.(13)thisvectorisa(normalized)columnof\n",
      "theresidual4\n",
      "?m?1betweenthefullkernelmatrixandtheNystr?omapproximation.\n",
      "NowconsidertheK?KfullCholeskydecompositionofK=L?L?>whereL?\n",
      "=[Lm?1,L(Jm?1)]isconstructedwithIm?1asthestpivotsandJm?1=\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "Im?1astheremainingpivots,sotheresid?m?1=L(Jm?1)L(Jm?1\n",
      ")>.WeapproximateL(Jm?1)byarankznualbecomesK?Kmatrix,Lz,\n",
      "bytakingzpointsfromJm?1andperformingapartialCholeskyfactorization\n",
      "of?m?1usingthesepivots.TheresidualapproximationbecomesK?K?m?1\n",
      "?LzL>,andK?Kz.pthus`m?(LzL>(LzL>z)[:,j]z)[j,j].Thepivots\n",
      "usedtoconstructLzarecalledinformationpivots;theirselectionisdiscussed\n",
      "inSec.3.3.2.Theapproximationsto?EkD,?EkCand?EkV,Eqs.(14)-(16),\n",
      "forallcandidatepoints,involve>>>>>thefollowingterms:diag(LzL>z\n",
      "LzLz),yLzLz,and(Qk?1[1:n,:])LzLz.Theterm2canbe\n",
      "computedintimeO(zn),andtheothertwoinO(zmn)withcarefulorderingof\n",
      "matrixmultiplications.2ComputingLzcostsO(z2n),butcanbeavoidedsince\n",
      "informationpivotschangebyatmostonewhenaninformationpivotsisadded\n",
      "totheinducingsetandneedstobereplaced.ThetechniquesinSec.3.2bring\n",
      "theassociatedupdatecosttoO(zn)byupdatingLzratherthanrecomputing\n",
      "it.Thesezinformationpivotsareequivalenttothe?look-ahead?stepsofBach\n",
      "andJordan?sCSIalgorithm,butasdescribedinSec.3.3.2,thereisamore\n",
      "ewaytoselectthem.3.3.2\n",
      "Ensuringagoodapproximation\n",
      "Selectionoftheinformationpivotsdeterminestheapproximateobjective,\n",
      "andhencethecandidateproposal.Toensureagoodapproximation,theCSI\n",
      "algorithm[1]greedilyselectspointsto?m?1inEq.(13)thatisoptimal\n",
      "intermsofaboundofanapproximationoftheresidualK?Kthetracenorm.\n",
      "Thegoal,however,istoapproximateEqs.(14)-(16).Byanalyzingtherole\n",
      "oftheresidualmatrix,weseethattheinformationpivotsprovidealow-rank\n",
      "approximationtotheorthogonalcomplementofthespacespannedbycurrent\n",
      "inducingset.Withasetofinformationpivots,partsofthatsubspacemay\n",
      "neverbecaptured.Thissuggeststhatwemightoccasionallyupdatetheentire\n",
      "setofinformationpivots.Althoughinformationpivotsarechangedwhenone\n",
      "ismovedintotheinducingset,weempiricallythatthisisnott.\n",
      "Instead,atregularintervalswereplacetheentiresetofinformationpivotsby\n",
      "6\n",
      "\n",
      "randomselection.Wethisworksbetterthanoptimizingtheinformation\n",
      "pivotsasin[1].rankingapproxtotalreduction\n",
      "Figure1comparestheexactandapproximatecostreductionforcandidate\n",
      "inducingpoints(left),andtheirrespectiverankings(right).Theapproximation\n",
      "isshowntoworkwell.Itisalsorobusttochangesinthenumberofinformation\n",
      "pivotsandthefrequencyofupdates.Whenbadcandidatesareproposed,they\n",
      "arerejectedafterrankingexacttotalreductionexacttotalreductionevaluating\n",
      "thechangeinthetrueobjective.WeFigure1:Exactvsapproximatecosts,\n",
      "basedonthatrejectionratesaretypicallylowduringthe1DexampleofSec.\n",
      "4,withz=10,n=200.earlyiterations(<20%),butincreaseasoptimization\n",
      "nearsconvergence(to30%or40%).Rejectionratesalsoincreaseforsparser\n",
      "models,whereeachinducingpointplaysamorecriticalroleandisharderto\n",
      "replace.approxtotalreduction\n",
      "0.035\n",
      "0.03\n",
      "0.025\n",
      "0.02\n",
      "0.015\n",
      "0.01\n",
      "0.005\n",
      "0\n",
      "3.4\n",
      "150\n",
      "100\n",
      "50\n",
      "0\n",
      "0\n",
      "0.005\n",
      "0.01\n",
      "0.015\n",
      "0.02\n",
      "0.025\n",
      "0.03\n",
      "0.035\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "Hybridoptimization\n",
      "Theoverallhybridoptimizationprocedureperformsblockcoordinatede-\n",
      "scentintheinducingpointsandthecontinuoushyperparameters.Italternates\n",
      "betweendiscreteandcontinuousphasesuntilimprovementintheobjectiveis\n",
      "belowathresholdorthecomputationaltimebudgetisexhausted.Inthediscrete\n",
      "phase,inducingpointsareconsideredforswappingwiththehyper-parameters\n",
      "Withthefactorizationandtcandidateevaluationabove,swapping\n",
      "aninducingpointi?Improceedsasfollows:(I)down-datethefactorization\n",
      "7\n",
      "\n",
      "matricesasinSec.3.2toremovei;(II)computethetrueobjectivefunction\n",
      "valueFm?1overthedown-datedmodelwithIm\n",
      "f\n",
      "i\n",
      "g\n",
      ",using(11),(12)and(9);\n",
      "(III)selectareplacementcandidateusingthefastapproximatecostchangefrom\n",
      "Sec.3.3.1;(IV)evaluatetheexactobjectivechange,using(14),(15),and(16);\n",
      "(V)addtheexactchangetothetrueobjectiveFm?1togettheobjectivevalue\n",
      "withthenewcandidate.Ifthisimproves,weinclude2\n",
      "eandLzBothcanbefurtherreducedtoO(zn)byappropriatecachingduring\n",
      "theupdatesofQ,RandL,\n",
      "5\n",
      "CholQR?z16IVMRandomTitsias?16Titsias?512\n",
      "TestingSNLP\n",
      "?0.3\n",
      "0.7\n",
      "TestingSMSE\n",
      "?0.2\n",
      "?0.4?0.5?0.6\n",
      "3264128256numberofinducingpoints(m)\n",
      "?0.4\n",
      "0.4\n",
      "16\n",
      "512\n",
      "CholQR?z16IVMRandomTitsias?16Titsias?512\n",
      "?0.6TestingSNLP\n",
      "0.5\n",
      "0.33264128256numberofinducingpoints(m)\n",
      "512\n",
      "3264128256numberofinducingpoints(m)\n",
      "512\n",
      "0.40.35TestingSMSE\n",
      "?0.716\n",
      "0.6\n",
      "?0.8\n",
      "?1\n",
      "0.30.250.20.15\n",
      "?1.2\n",
      "0.116\n",
      "3264128256numberofinducingpoints(m)\n",
      "16\n",
      "512\n",
      "Figure2:Testperformanceondiscretedatasets.(toprow)BindingDB,\n",
      "valuesateachmarkeristheaverageof150runs(50-foldrandomtrain/test\n",
      "splitstimes3randominitialization);(bottomrow)HoGdataset,eachmarker\n",
      "istheaverageof10randomlyinitializedruns.thecandidateinIandupdate\n",
      "thematricesasinSec.3.2.Otherwiseitisrejectedandwereverttothe\n",
      "factorizationwithi;(VI)ifneeded,updatetheinformationpivotsasinSecs.\n",
      "3.3.1and3.3.2.AftereachdiscreteoptimizationstepwetheinducingsetI\n",
      "8\n",
      "\n",
      "andoptimizethehyperparametersusingnon-linearconjugategradients(CG).\n",
      "Theequivalencein(6)allowsustocomputethegradientwithrespecttothe\n",
      "hyperparametersanalyticallyusingtheNystr?omform.Inpractice,because\n",
      "wealternateeachphaseformanytrainingepochs,attemptingtoswapevery\n",
      "inducingpointineachepochisunnecessary,justasthereisnoneedtorun\n",
      "hyperparameteroptimizationuntilconvergence.Aslongasallinducingset\n",
      "pointsareeventuallyconsideredwethatoptimizedmodelscanachieve\n",
      "similarperformancewithshorterlearningtimes.\n",
      "4\n",
      "Experimentsandanalysis\n",
      "Fortheexperimentsthatfollowwejointlylearninducingpointsandhyper-\n",
      "parameters,amorechallengingtaskthanlearninginducingpointswithknown\n",
      "hyperparameters[12,14].Forallbutthe1Dexample,thenumberofinducing\n",
      "pointsswappedperepochismin(60,m).Themaximumnumberoffunction\n",
      "evaluationsperepochinCGhyperparameteroptimizationismin(20,max(15,\n",
      "2d)),wheredisthenumberofcontinuoushyperparameters.Empiricallywe\n",
      "thealgorithmisrobusttochangesintheselimits.Weusetwoperformance\n",
      "measures,(a)standardizedmeansquareeryt?yt)2/???2,where???2is\n",
      "thesamplevarianceoftestoutputs\n",
      "f\n",
      "yt\n",
      "g\n",
      ",and(2)ror(SMSE),N1?Nt=1(?\n",
      "standardizednegativelogprobability(SNLP)in[11].4.1Discreteinput\n",
      "domainWeshowresultsontwodiscretedatasetswithkernelsthatarenot\n",
      "tiableintheinputvariablex.Becausecontinuousrelaxationmethods\n",
      "arenotapplicable,wecomparetodiscreteselectionmethods,namely,random\n",
      "selectionasbaseline(Random),greedysubset-optimalselectionofTitsias[15]\n",
      "witheither16or512candidates(Titsias-16andTitsias-512),andInforma-\n",
      "tiveVectorMachine[8](IVM).Forlearningcontinuoushyperparameters,each\n",
      "methodoptimizesthesameobjectiveusingnon-linearCG.Careistakentoen-\n",
      "sureconsistinitializationandterminationcriteria[3].Forouralgorithmweuse\n",
      "z=16informationpivotswithrandomselection(CholQR-z16).Later,weshow\n",
      "howvariantsofouralgorithmspeedandperformance.Additionally,we\n",
      "alsocomparetoleast-squarekernelregressionusingCSI(inFig.3(c)).The\n",
      "discretedataset,frombindingdb.org,concernsthepredictionofbinding\n",
      "ityforatarget(Thrombin),fromthe2Dchemicalstructureofsmallmolecules\n",
      "(representedasgraphs).Wedo50-foldrandomsplitsto3660trainingpoints\n",
      "and192testpointsforrepeatedruns.Weuseacompoundkernel,comprising\n",
      "14tgraphkernels,and15continuoushyperparameters(one6\n",
      "3\n",
      "10\n",
      "1000\n",
      "500\n",
      "0.2\n",
      "2\n",
      "10\n",
      "3264128256numberofinducingpoints(m)\n",
      "016\n",
      "512\n",
      "9\n",
      "\n",
      "0.13264128256numberofinducingpoints(m)\n",
      "(a)\n",
      "1\n",
      "2\n",
      "(b)\n",
      "(c)CholQR?z16IVMRandomTitsias?16Titsias?512\n",
      "0.75TestingSMSE\n",
      "?0.1\n",
      "4\n",
      "0.144\n",
      "CholQR?z16IVMRandomTitsias?16Titsias?512\n",
      "0\n",
      "3\n",
      "10101010Timeinsecs(logscaled)\n",
      "512\n",
      "?0.2\n",
      "0.70.65\n",
      "TestingSMSE\n",
      "16\n",
      "TestingSNLP\n",
      "CholQR?z8CholQR?z16CholQR?OI?z16CholQR?z64CholQR?OI?z64CholQR?AA?z128\n",
      "IVMRandomTitsias?16Titsias?512CSI\n",
      "0.3TestingSMSE\n",
      "10\n",
      "TrainingVAR\n",
      "Totaltrainingtime(secs)\n",
      "CholQR?z16IVMRandomTitsias?16Titsias?512\n",
      "4\n",
      "0.6\n",
      "0.142\n",
      "0.14\n",
      "0.55\n",
      "0.138\n",
      "?0.30\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1010101010Cumulativetrainingtimeinsecs(logscale)\n",
      "(d)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1010101010Cumulativetrainingtimeinsecs(logscale)\n",
      "10\n",
      "\n",
      "(e)\n",
      "1\n",
      "10\n",
      "2\n",
      "10Timeinsecs(logscaled)\n",
      "(f)\n",
      "Figure3:Trainingtimeversustestperformanceondiscretedatasets.(a)\n",
      "theaverageBindingDBtrainingtime;(b)theaverageBindingDBobjective\n",
      "functionvalueatconvergence;(d)and(e)showtestscoresversustrainingtime\n",
      "withm=32forasinglerun;(c)showsthebetweentrainingtimeand\n",
      "testingSMSEontheHoGdatasetwithm=32,forvariousmethodsincluding\n",
      "multiplevariantsofCholQRandCSI;(f)azoomed-inversionof(c)comparing\n",
      "thevariantsofCholQR.noisevarianceand14datavariances).Inthesecond\n",
      "task,from[2],thetaskistopredict3Dhumanjointpositionfromhistograms\n",
      "ofHoGimagefeatures[6].Trainingandtestsetshave4819and4811data\n",
      "points.BecauseourgoalisthegeneralpurposecationmethodforGP\n",
      "regression,wemakenoattemptatthemoreproblemofmodellingthe\n",
      "multivariateoutputstructureintheregressionasin[2].Instead,wepredictthe\n",
      "verticalpositionofjointsindependently,usingahistogramintersectionkernel\n",
      "[9],havingfourhyperparameters:onenoisevariance,andthreedatavariances\n",
      "correspondingtothekernelevaluatedovertheHoGfromeachofthreecameras.\n",
      "Weselectandshowresultontherepresentativeleftwristhere(see[3]forothers\n",
      "joints,andmoredetailsaboutthedatasetsandkernelsused).Theresultsin\n",
      "Fig.2and3showthatCholQR-z16outperformsthebaselinemethodsinterms\n",
      "oftest-timepredictivepowerwithtlylowertrainingtime.Titsias-16\n",
      "andTitsias-512showssimilartestperformance,buttheyaretwotofourorders\n",
      "ofmagnitudeslowerthanCholQR-z16(seeFigs.3(d)and3(e)).Indeed,Fig.\n",
      "3(a)showsthatthetrainingtimeforCholQR-z16iscomparabletoIVMand\n",
      "Randomselection,butwithmuchbetterperformance.Thepoorperformanceof\n",
      "Randomselectionhighlightstheimportanceofselectinggoodinducingpoints,\n",
      "asnoamountofhyperparameteroptimizationcancorrectforpoorinducing\n",
      "points.Fig.3(a)alsoshowsIVMtobesomewhatslowerduetotheincreased\n",
      "numberofiterationsneeded,eventhoughperepoch,IVMisfasterthanCholQR.\n",
      "Whenstoppedearlier,IVMtestperformancefurtherdegrades.Finally,Fig.\n",
      "3(c)and3(f)showthebetweenthetestSMSEandtrainingtimefor\n",
      "variantsofCholQR,withbaselinesandCSIkernelregression[1].ForCholQR\n",
      "weconsidertnumbersofinformationpivots(denotedz8,z16,z64and\n",
      "z128),andtstrategiesfortheirselectionincludingrandomselection,\n",
      "optimizationasin[1](denoteOI)andadaptivelygrowingtheinformationpivot\n",
      "set(denotedAA,see[3]fordetails).ThesevariantsofCholQRspeed\n",
      "andperformance(3(f)),alltlyoutperformtheothermethods(3(c));\n",
      "CSI,whichusesgridsearchtoselecthyper-parameters,isslowandexhibits\n",
      "higherSMSE.4.2ContinuousinputdomainAlthoughCholQRwasdeveloped\n",
      "fordiscreteinputdomains,itcanbecompetitiveoncontinuousdomains.To\n",
      "thatend,wecomparetoSPGP[14]andIVM[8],usingRBFkernelswithone\n",
      "lengthPd(t)(t)scaleparameterperinputdimension;?(xi,xj)=cexp(?0.5\n",
      "11\n",
      "\n",
      "t=1bt(xi?xj)2).WeshowresultsfromboththePPloglikelihoodand\n",
      "variationalobjectives,byMLEandVAR.7\n",
      "(a)CholQR-MLE\n",
      "(b)CholQR-MLE\n",
      "(c)SPGP\n",
      "(d)CholQR-VAR\n",
      "(e)CholQR-VAR\n",
      "(f)SPGP\n",
      "Figure4:Snelson?s1Dexample:predictionmean(redcurves);onestan-\n",
      "darddeviationinpredictionuncertainty(greencurves);inducingpointinitial-\n",
      "ization(blackpointsattopofeache);learnedinducingpointlocations(the\n",
      "cyanpointsatthebottom,alsooverlaidondataforCholQR).CholQR?MLE\n",
      "CholQR?VARSPGPIVM?MLEIVM?VAR\n",
      "testingSMSE\n",
      "0.2\n",
      "?0.5\n",
      "testingSNLP\n",
      "0.25\n",
      "0.15\n",
      "0.1\n",
      "?1\n",
      "?1.5\n",
      "?2\n",
      "0.05128\n",
      "256\n",
      "512\n",
      "1024\n",
      "?2.5128\n",
      "2048\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "Figure5:TestscoresonKIN40Kasfunctionofnumberofinducingpoints:\n",
      "foreachnumberofinducingpointsthevalueplottedisaveragedover10runs\n",
      "from10t(shared)initializations.Weusethe1Dtoydatasetof[14]to\n",
      "showhowthePPlikelihoodwithgradient-basedoptimizationofinducingpoints\n",
      "iseasilytrappedinlocalminima.Fig.4(a)and4(d)showthatforthisdataset\n",
      "ouralgorithmdoesnotgettrappedwheninitializationispoor(asinFig.1c\n",
      "of[14]).Tosimulatethesparsityofdatainhigh-dimensionalproblemswealso\n",
      "down-samplethedatasetto20points(every10thpoint).HereCholQRout-\n",
      "performsSPGP(seeFig.4(b),4(e),and4(c)).Bycomparison,Fig.4(f)shows\n",
      "SPGPlearnedwithamoreuniforminitialdistributionofinducingpointsavoids\n",
      "thislocaloptimaandachievesabetternegativeloglikelihoodof11.34compared\n",
      "to14.54inFig.4(c).Finally,wecompareCholQRtoSPGP[14]andIVM[8]\n",
      "onalargedataset.KIN40Kconcernsnonlinearforwardkinematicprediction.\n",
      "12\n",
      "\n",
      "Ithas8Dreal-valuedinputsandscalaroutputs,with10Ktrainingand30K\n",
      "testpoints.Weperformlinearde-trendingandre-scalingaspre-processing.\n",
      "ForSPGPweusetheimplementationof[14].Fig.5showsthatCholQR-\n",
      "VARoutperformsIVMintermsofSMSEandSNLP.BothCholQR-VARand\n",
      "CholQR-MLEoutperformSPGPintermsofSMSEonKIN40Kwithlargem,\n",
      "butSPGPexhibitsbetterSNLP.ThisdisparitybetweentheSMSEandSNLP\n",
      "measuresforCholQR-MLEisconsistentwithaboutthePPlikelihood\n",
      "in[15].Recently,Chalupkaetal.[4]introducedanempiricalevaluationframe-\n",
      "workforapproximateGPmethods,andshowedthatsubsetofdata(SoD)often\n",
      "comparesfavorablytomoresophisticatedsparseGPmethods.Ourpreliminary\n",
      "experimentsusingthisframeworksuggestthatCholQRoutperformsSPGPin\n",
      "speedandpredictivescores;andcomparedtoSoD,CholQRisslowerduring\n",
      "training,butproportionallyfasterduringtestingsinceCholQRamuch\n",
      "sparsermodeltoachievethesamepredictivescores.Infuturework,wewill\n",
      "reportresultsonthecompletesuitofbenchmarktests.\n",
      "5\n",
      "Conclusion\n",
      "WedescribeanalgorithmforselectinginducingpointsforGaussianProcess\n",
      "Itoptimizesprincipledobjectivefunctions,andisapplicableto\n",
      "discretedomainsandtiablekernels.Onsuchproblemsitisshown\n",
      "tobeasgoodasorbetterthancompetingmethodsand,formethodswhose\n",
      "predictivebehaviorissimilar,ourmethodisseveralordersofmagnitudefaster.\n",
      "Oncontinuousdomainsthemethodiscompetitive.ExtensiontotheSPGP\n",
      "formofcovarianceapproximationwouldbeinterestingfutureresearch.8\n",
      "2References\n",
      "[1]F.R.BachandM.I.Jordan.Predictivelow-rankdecompositionforker-\n",
      "nelmethods.ICML,pp.33?40,2005..[2]L.BoandC.Sminchisescu.Twin\n",
      "gaussianprocessesforstructuredprediction.IJCV,87:28?52,2010.[3]Y.\n",
      "Cao,M.A.Brubaker,D.J.Fleet,andA.Hertzmann.Projectpage:sup-\n",
      "plementarymaterialandsoftwarefortoptimizationforsparsegaussian\n",
      "processregression.www.cs.toronto.edu/?caoy/opt\n",
      "sgpr,2013.[4]K.Chalupka,\n",
      "C.K.I.Williams,andI.Murray.Aframeworkforevaluatingapproximation\n",
      "methodsforgaussianprocessregression.JMLR,14(1):333?350,February2013.\n",
      "[5]L.Csat?oandM.Opper.Sparseon-linegaussianprocesses.NeuralCom-\n",
      "put.,14:641?668,2002.[6]N.DalalandB.Triggs.Histogramsoforiented\n",
      "gradientsforhumandetection.IEEECVPR,pp.886?893,2005.[7]S.S.\n",
      "KeerthiandW.Chu.Amatchingpursuitapproachtosparsegaussianpro-\n",
      "cessregression.NIPS18,pp.643?650.2006.[8]N.D.Lawrence,M.Seeger,\n",
      "andR.Herbrich,Fastsparsegaussianprocessmethods:Theinformativevector\n",
      "machine.NIPS15,pp.609?616.2003.[9]J.J.Lee.Libpmk:Apyra-\n",
      "midmatchtoolkit.TR:MIT-CSAIL-TR-2008-17,MITCSAIL,2008.URL\n",
      "http://hdl.handle.net/1721.1/41070.[10]J.Qui?nonero-CandelaandC.E.Ras-\n",
      "mussen.Aunifyingviewofsparseapproximategaussianprocessregression.\n",
      "13\n",
      "\n",
      "JMLR,6:1939?1959,2005.[11]C.E.RasmussenandC.K.I.Williams.Gaus-\n",
      "sianprocessesformachinelearning.Adaptivecomputationandmachinelearn-\n",
      "ing.MITPress,2006.[12]M.Seeger,C.K.I.Williams,andN.D.Lawrence.\n",
      "Fastforwardselectiontospeedupsparsegaussianprocessregression.AI&\n",
      "Stats.9,2003.[13]A.J.SmolaandP.Bartlett.Sparsegreedygaussian\n",
      "processregression.InAdvancesinNeuralInformationProcessingSystems13,\n",
      "pp.619?625.2001.[14]E.SnelsonandZ.Ghahramani.Sparsegaussianpro-\n",
      "cessesusingpseudo-inputs.NIPS18,pp.1257?1264.2006.[15]M.K.Titsias.\n",
      "Variationallearningofinducingvariablesinsparsegaussianprocesses.JMLR,\n",
      "5:567?574,2009.[16]C.Walder,K.I.Kwang,andB.Sch?olkopf.Sparsemul-\n",
      "tiscalegaussianprocessregression.ICML,pp.1112?1119,2008.\n",
      "9\n",
      "14\n",
      "\n",
      "PP3794.pdf\n",
      "PP3794.pdf 12\n",
      "StatisticalModelsofLinearandNonlinear\n",
      "ContextualInteractionsinEarlyVisual\n",
      "Processing\n",
      "Authoredby:\n",
      "PeterDayan\n",
      "OdeliaSchwartz\n",
      "RubenCoen-cagli\n",
      "Abstract\n",
      "Acentralhypothesisaboutearlyvisualprocessingisthatitrepresents\n",
      "inputsinacoordinatesystemmatchedtothestatisticsofnaturalscenes.\n",
      "SimpleversionsofthisleadtoGabor-likereceptiveldsanddivisivegain\n",
      "modulationfromlocalsurrounds;thesehaveledtotialneuraland\n",
      "psychologicalmodelsofvisualprocessing.However,theseaccountsare\n",
      "basedonanincompleteviewofthevisualcontextsurroundingeachpoint.\n",
      "Here,weconsideranapproximatemodeloflinearandnon-linearcorrela-\n",
      "tionsbetweentheresponsesofspatiallydistributedGabor-likereceptive\n",
      "which,whentrainedonanensembleofnaturalscenes,a\n",
      "rangeofspatialcontextThefullmodelaccountsforneuralsur-\n",
      "rounddatainprimaryvisualcortex(V1),providesastatisticalfoundation\n",
      "forperceptualphenomenaassociatedwithLis(2002)hypothesisthatV1\n",
      "buildsasaliencymap,anddataonthetiltillusion.\n",
      "1PaperBody\n",
      "Thatvisualinputatagivenpointisgreatlybyitsspatialcontext\n",
      "ismanifestinahostofneuralandperceptual(see,e.g.,[1,2]).For\n",
      "instance,stimulisurroundingtheso-calledclassicalreceptive(RF)leadto\n",
      "strikingnonlinearitiesintheresponsesofvisualneurons[3,4];spatialcontext\n",
      "resultsinintriguingperceptualillusions,suchasthemisjudgmentofacen-\n",
      "terstimulusattributeinthepresenceofasurroundingstimulus[5?7];italso\n",
      "playsacriticalroleindeterminingthesalienceofpointsinvisualspace,for\n",
      "instancecontrollingpop-out,contourintegration,texturesegmentation[8?10]\n",
      "andmoregenerallylocationswherestatisticalhomogeneityoftheinputbreaks\n",
      "down[1].Contextualarewidespreadacrosssensorysystems,neural\n",
      "areas,andstimulusattributes?makingthemanattractivetargetforcompu-\n",
      "tationalmodeling.Therearevariousmechanistictreatmentsofextra-classical\n",
      "1\n",
      "\n",
      "RF(e.g.,[11?13])andcontourintegration[14],andV1?ssuggestedrole\n",
      "incomputingsaliencehasbeenrealizedinalarge-scaledynamicalmodel[1,\n",
      "15].Therearealsonormativeapproachestosalience(e.g.,[16?19])withlinks\n",
      "toV1.However,thesehavenotsubstantiallyencompassedneurophysiological\n",
      "dataorindeedmadeconnectionswiththeperceptualliteratureoncontourin-\n",
      "tegrationandthetiltillusion.Ouraimistobuildaprincipledmodelbasedon\n",
      "scenestatisticsthatcanultimatelyaccountfor,andthereforeunify,thewhole\n",
      "setofcontextualtsabove.Muchseminalworkhasbeendoneinthelast\n",
      "twodecadesonlearninglinearfromprinciplesfromthestatistics\n",
      "ofnaturalimages(seee.g.[20]).However,contextualctsemergefromthe\n",
      "interactionsamongmultiplethereforehereweaddressthemuchlesswell\n",
      "studiedissueofthelearned,statistical,basisofthecoordinationofthegroupof\n",
      "?thescene?dependent,linearandnon?linearinteractionsamongthem.\n",
      "Wefocusonrecentadvancesinmodelsofscenestatistics,usingaGaussianScale\n",
      "Mixturegenerativemodel(GSM;[21?23])thatcapturesthejointdependencies\n",
      "(e.g.,[24?31])betweentheactivationsofGabor?liketonaturalscenes.\n",
      "The1\n",
      "GSMcapturesthedependenciesviatwocomponents,(i)covarianceinunder-\n",
      "lyingGaussianvariables,whichaccountsforlinearcorrelationsintheactivations\n",
      "ofand(ii)asharedmixervariable,whichaccountsforthenon?linearcor-\n",
      "relationsinthemagnitudesoftheactivations.Asyet,theGSMhasnot\n",
      "beenappliedtothewiderangeofcontextualphenomenadiscussedabove.This\n",
      "ispartlybecauselinearcorrelations,whichappearimportanttocapturephe-\n",
      "nomenasuchascontourintegration,havelargelybeenignoredoutsideimage\n",
      "processing(e.g.,[23]).Inaddition,althoughthemixervariableoftheGSMis\n",
      "closelyrelatedtobottom-upmodelsofdivisivenormalizationincortex[32,33],\n",
      "theassignmentproblemofgroupingthatshareacommonmixerfora\n",
      "givenscenehasyettoreceiveacomputationallyandneurobiologicallyrealistic\n",
      "solution.Recentworkhasshownthatincorporatingasimple,predetermined,\n",
      "solutiontotheassignmentprobleminaGSMcouldcapturethetiltillusion\n",
      "[34].Nevertheless,theapproachhasnotbeenstudiedinamorerealisticmodel\n",
      "withGabor-likeandlearningassignmentsfromnaturalscenes.Further,\n",
      "theimplicationsofassignmentforcorticalV1dataandsaliencehavenotbeen\n",
      "explored.InthispaperweextendtheGSMmodeltolearnbothassignments\n",
      "andlinearcovariance(section2).Wethenapplythemodeltocontextualneural\n",
      "V1data,notingitslinktothetiltillusion(section3);andthentoperceptual\n",
      "salienceexamples(section4).Inthediscussion(section5),wealsodescribe\n",
      "therelationshipbetweenourGSMmodelandotherrecentscenestatisticsap-\n",
      "proaches(e.g.,[31,35]).\n",
      "2\n",
      "Methods\n",
      "Arecentfocusinnaturalimagestatisticshasbeenthejointconditional\n",
      "histogramsoftheactivationsofpairsoforientedlinear(throughoutthe\n",
      "paper,comefromthelevelofasteerablepyramidwith4orientations\n",
      "[36]).Whenpairsareproximalinspace,thesehistogramshaveacharac-\n",
      "teristicbowtieshape:thevarianceofonedependsonthemagnitudeof\n",
      "2\n",
      "\n",
      "activationoftheother.Ithasbeenshown[22]thatthisformofdependency\n",
      "canbecapturedbyaclassofgenerativemodelknownasGaussianScaleMix-\n",
      "ture(GSM),whichassumesthatthelinearactivationsx=vgarerandom\n",
      "variablesastheproductoftwootherrandomvariables,amultivariate\n",
      "Gaussiang,anda(positive)scalarvwhichscalesthevarianceofalltheGaus-\n",
      "siancomponents.Here,weaddresstwoadditionalpropertiesofnaturalscenes.\n",
      "First,inadditiontothevariancedependency,whicharecloseenough\n",
      "inspaceandfeaturespacearelinearlydependent,asshownbythetiltofthe\n",
      "bowtiein1b.InorderfortheGSMtocapturethisthemultivariate\n",
      "Gaussianmustbeendowedwithanon-diagonalcovariancematrix.Thismatrix\n",
      "canbeapproximatedbythesamplecovariancematrixoftheactivations\n",
      "orlearneddirectly[23];here,welearnitbymaximizingthelikelihoodofthe\n",
      "observeddata.Thesecondissueisthatlterdependenciesacrossimage\n",
      "patches,implyingthatthereisnorelationshipbetweenmixersand\n",
      "[28].Thegeneralissueoflearningmultiplepoolsofeachassignedto\n",
      "atmixeronanpatch?dependentbasis,hasbeenaddressedinrecent\n",
      "work[30],butusingacomputationallyandbiologicallyimpracticablescheme\n",
      "[37]whichallowedforarbitrarypooling.Weconsideranapproximationtothe\n",
      "assignmentproblem,byallowingagroupofsurroundtoeithershareor\n",
      "notthesamemixerwithatargetWhilethisisclearlyanoversimpli-\n",
      "modelofnaturalimages,hereweaimedforareasonablebalancebetween\n",
      "thecomplexityofthemodel,andbiologicalplausibilityofthecomputations\n",
      "involved.2.1\n",
      "Thegenerativemodel\n",
      "Thebasicrepeatingunitofourmodelinvolvescenterandsurround\n",
      "groupsofweusenctodenotethenumberofcenterandxctheir\n",
      "activations;similarly,weusensandxs..forthesurround;,wencs\n",
      "=nc+nsandx=(x1c,...xncc,x1s,...xnss)>.Weconsiderasingle\n",
      "assignmentchoiceastowhetherthecentergroup?smixervariablevcis(case?1\n",
      "),orisnot(case?2)sharedwiththesurround,whichinthelattercasewould\n",
      "haveitsownmixervariablevs.Thus,thereare2orcompeting\n",
      "models,whicharethemselvescombined(i.e.,amixtureofGSM?s,seealso[35]).\n",
      "ThegraphicalmodelsofthetwoareshowninFig.1a.Weshow\n",
      "thisfromtheperspectiveofthecentergroup,sinceintheimplementationwewill\n",
      "bereportingmodelneuronresponsesinthecenterlocationgiventhecontextual\n",
      "surround.2\n",
      ".Gaussiancomponentsasg=(gc1,...gcnc,gs1,...gsns)>,\n",
      "andassumingthemixersareindependentandthepoolsareindependentgiven\n",
      "themixers,themixturedistributionis:p(x)=p(?1)p(x|?1)+p(?2)p(x\n",
      "|?2)Rp(x|?1)=dvcp(vc)p(x|vc,?1)RRp(x|?2)=dvcp(vc\n",
      ")p(xc|vc,?2)dvsp(vs)p(xs|vs,?2)\n",
      "(1)(2)(3)\n",
      "WeassumeaRayleighpriordistributiononthemixers,andcovariancema-\n",
      "trix?csfortheGaussiancomponentsfor?1,and?cand?sforcenterand\n",
      "surround,respectively,for?2.Theintegralsineqs.(2,3)canthenbesolved\n",
      "analytically:1\n",
      "3\n",
      "\n",
      "p(x|?1)\n",
      "=\n",
      "p(x|?2)\n",
      "=\n",
      "ncs2det(??1cs)B(1?2;?cs)ncsncs(?1)(2?)2?cs21nc?1212\n",
      "det(??1c)B(1?2;?c)det(?s)B(1?\n",
      "(2?)\n",
      "nc2\n",
      "(n2c\n",
      "?c\n",
      "?1)\n",
      "(2?)\n",
      "ns2;?s)?1)\n",
      "(n2s\n",
      "ns2\n",
      "?s\n",
      "whereBisthemoBesselfunctionofthesecondkind,and?cs=2.2\n",
      "(4)\n",
      "p\n",
      "(5)\n",
      "x>??1csx.\n",
      "Learning\n",
      "Theparameterstobeestimatedarethecovariancematrices(?cs,?c,?s)\n",
      "andthepriorprobability(k)thatcenterandsurroundsharethesamepool;we\n",
      "useaGeneralizedExpectationMaximizationalgorithm,spMultiCycle\n",
      "EM[38],whereafullEMcycleisdividedintothreesubcycles,eachinvolving\n",
      "afullE-stepandapartialM-stepperformedonlyononecovariancematrix.\n",
      "E-step:IntheE-stepwecomputeanestimate,Q,oftheposteriordistribution\n",
      "overtheassignmentoldvariable,ngiventheoactivationsandtheprevious\n",
      "estimatesoftheparameters,namelykandold.?=?c,?s,?cs.Thisis\n",
      "obtainedviaBayesrule:Q(?1)=p(?1|x,?old)?koldp(x|?1,?old)\n",
      "Q(?2)=p(?2|x,?\n",
      "old\n",
      ")?(1?k\n",
      "old\n",
      ")p(x|?2,?\n",
      "(6)old\n",
      ")\n",
      "(7)\n",
      "M-step:IntheM-stepweincreasethecomplete?dataLogLikelihood,namely:\n",
      "f=Q(?1)log[kp(x|?1,?)]+Q(?2)log[(1?k)p(x|?2,?)](8).Solving\n",
      "?f/?k=0,weobtaink?=argmaxk[f]=Q(?1).Theothertermscannotbe\n",
      "solvedanalytically,andanumericalproceduremustbeadoptedtomaximizef\n",
      "w.r.t.thecovariancematrices.Thisrequiresanexplicitformforthegradient:\n",
      "?\n",
      "4\n",
      "\n",
      "1B(?n2cs;?cs)?fcs>=Q(?)?xx(9)122?csB(1?n2cs;?cs)\n",
      "???1csSimilarexpressionsholdfortheotherpartialderivatives.Inpractice,\n",
      "weaddtheconstraintthatthecovariancesofthesurroundarespatially\n",
      "symmetric.2.3\n",
      "Inference:patch?by?patchassignmentandmodelneuralunit\n",
      "UponconvergenceofEM,thecovariancematricesandpriorkovertheas-\n",
      "signmentarefound.Then,foranewimagepatch,theprobabilityp(?1|x)\n",
      "thatthesurroundsharesacommonmixerwiththecenterisinferred.Theout-\n",
      "putofthecentergroupistakentobetheestimate(forthepresent,weconsider\n",
      "justthemean)oftheGaussiancomponentE[gc|x],whichwetaketobeour\n",
      "modelneuralunitresponse.Toestimatethenormalizedresponseofthecenter\n",
      "weneedtocomputethefollowingexpectedvalueunderthefullmodel:Z\n",
      "E[gc|x]=dgcgcp(gc|x)=p(?1|x)E[gc|x,?1]+p(?2|x)E[gc\n",
      "|xc,?2](10)ther.h.s.,obtainedbyastraightforwardcalculationapplying\n",
      "Bayesruleandtheconditionalindependenceofxsfromxc,gcgiven?2,isthe\n",
      "sumoftheexpectedvalueofgcinthetwo3\n",
      "Figure1:(a)Graphicalmodelforthetwocomponentsofthemixtureof\n",
      "GSMs,wherethecenteris(?1;left)orisnot(?2;right)normalizedbythe\n",
      "surround(b)jointconditionalhistogramoftwolinearactivations,\n",
      "showingthetypicalbowtieshapeduetothevariancedependency,aswellasa\n",
      "tiltduetolineardependenciesbetweenthetwo(c)marginaldistribution\n",
      "oflinearactivationsinblack,estimatedGaussiancomponentinblue,andideal\n",
      "Gaussianinred.TheestimateddistributionisclosertoaGaussianthanthatof\n",
      "theoriginalweightedbytheirposteriorprobabilities.Theexplicitform\n",
      "fortheestimateofthei-thcomponent(correspondingintheimplementationto\n",
      "agivenorientationandphase)ofgcunder?1is:spi\n",
      "|xic|B(21?n2cs;?cs)Egc|x,?1=sign(xic)|xic|(11)\n",
      "?csB(1?n2cs;?cs)andasimilarexpressionholdsunder?2,replacingthe\n",
      "subscriptcsbyc.Notethatineitherthemixervariable?s\n",
      "onthisisaformofdivisivenormalizationorgaincontrol,through?(including\n",
      "forstability,asin[30],anadditiveconstantsetto1forthe?values;weomit1\n",
      "theformul?tosavespace).Under?1,butnot?2,thisdivisionisp\n",
      "bythesurround.Notealsothat,duetothepresenceoftheinversecovariance\n",
      "matrixin?cs=x>??1csx,thegaincontrolsignalisreducedwhenthereis\n",
      "strongcovariance,whichinturnenhancestheneuralunitresponse.\n",
      "3\n",
      "Corticalneurophysiologysimulations\n",
      "Tosimulateneurophysiologicalexperiments,weconsiderthefollowing\n",
      "3?3spatialpositionsseparatedby6pixels,2phases(quadra-\n",
      "turepair),andoneorientation(vertical),plus3additionalorientationsinthe\n",
      "centralpositiontoallowforcross?orientationgaincontrol.Westlearnthe\n",
      "parametersofthemodelfor25000patchesfromanensembleof5standard\n",
      "scenes(Einstein,Goldhill,andsoon).Wetakeasourmodelneurontheabso-\n",
      "lutevalueofthecomplexactivationcomposedbythenon?linearresponses(eq.\n",
      "(11))oftwophasesofthecentralverticalWecharacterizetheneuron?s\n",
      "basicpropertieswithaprocedurethatiscommoninphysiologyexperiments\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focusingoncontextualnon?linearmodulation.First,wemeasuretheso-called\n",
      "AreaSummationcurve,namelytheresponsetogratingsthatareoptimalin\n",
      "orientationandspatialfrequency,asafunctionofsize.Catandmonkeyex-\n",
      "perimentshaveshownstrikingnon?linearities,withthepeakresponseatlow\n",
      "contrastsbeingfortlylargerdiametersthanathighcontrasts(Figure\n",
      "2a).Weobtainthesamebehaviorinthemodel(Figure2b;seealso[33]).This\n",
      "behaviorisduetotheassignment:forsmallgratingsizes,centerandsurround\n",
      "haveahigherposteriorprobabilityathighcontrastthanatlowcontrast,and\n",
      "thereforethesurroundexertsstrongergaincontrol.Inareducedmodelwith\n",
      "noassignment,weobtainamuchweaker(Figure2c).Wethenassessthe\n",
      "modulatoryofasurroundgratingonaoptimally?orientedcentral\n",
      "grating,asafunctionoftheirrelativeorientations(Figure3a).Asiscommon,\n",
      "wedeterminethespatialextentofthecenterandsurroundstimulibasedonthe\n",
      "areasummationcurves(see[4]).Themodelsimulations(Figure3b),asinthe\n",
      "data,exhibitthemostreducedresponseswhenthecenterandsurroundhave\n",
      "similarorientation(butnotethe?blip?whentheyareexactlyequalinFigure\n",
      "3a;b,whicharisesinthemodelfromthecovarianceoftheGaussian;seealso\n",
      "[31]).Inaddition,1Toensurethatthemixerfollowsthesamedistribution\n",
      "under?1and?2,aftertrainingwithnaturalimageswerescalevc?andthere-\n",
      "foregc?sothattheirvaluesspanthesamerangeinbothsince\n",
      "theassignmentismadeatahigherlevelinthehierarchy,sucharescalingis\n",
      "equivalenttodownstreamnormalizationprocessesthatmaketheestimatesof\n",
      "gccomparableunder?1and?2.\n",
      "4\n",
      "Figure2:Areasummationcurvesshowthenormalizedrateofaneuron\n",
      "inresponsetooptimalgratingsofincreasingsize.(a)aV1neuron,after[4];(b)\n",
      "themodelneurondescribedinSec.3;(c)areducedmodelassumingthatthe\n",
      "surroundarealwaysinthegainpoolofthecenter\n",
      "Figure3:Orientationtuningofthesurround.(a)and(b):normalized\n",
      "rateinresponsetoastimuluscomposedbyanoptimalcentralgrating\n",
      "surroundedbyanannulargratingofvaryingorientation,for(a)aV1neuron,\n",
      "after[3];and(b)themodelneurondescribedinSec.3(c)Probabilitythat\n",
      "thesurroundnormalizesthecenterasafunctionoftherelativeorientationof\n",
      "theannulargrating.astheorientationbetweencenterandsurround\n",
      "grows,theresponseincreasesandthendecreases,anthatarisesfrom\n",
      "theassignments.Inthemodelsimulations,wethatthestrengthofthis\n",
      "behaviordependsoncontrast,beinglargeratlowcontrasts,anofwhich\n",
      "therearehintsintheneurophysiologyexperimentaldata(usingcontrastsof0.2\n",
      "to0.4)butwhichhasyettobesystematicallyexplored.Figure3cshowsthe\n",
      "posteriorassignmentprobabilityforthesametwocontrastsasinre3b,asa\n",
      "functionofthesurroundorientation.Theseremaincloseto1atallorientations\n",
      "athighcontrast,butfallmorerapidlyatlowcontrast.Notethataprevious\n",
      "GSMpopulationmodelassumed(butdidnotlearn)thisformoffallofthe\n",
      "posteriorweightsofofgure3c,andshowedthatitisabasisforexplaining\n",
      "theso-calleddirectandindirectbiasesinthetiltillusion;i.e.,repulsionand\n",
      "attractionintheperceptionofacenterstimulusorientationinthepresenceof\n",
      "6\n",
      "\n",
      "asurroundstimulus[34].Figure4comparestheGSMmodelof[34]designed\n",
      "withparametersmatchedtoperceptualdata,totheresultofourlearnedmodel.\n",
      "Thequalitativeshape(althoughnotthequantitativestrength)oftheare\n",
      "similar.\n",
      "4\n",
      "Saliencepopoutandcontourintegrationsimulations\n",
      "Toaddressperceptualsalienceeweneedapopulationmodelofori-\n",
      "entedunits.Weconsideronedistinctgroupoflters?arrangedasforthemodel\n",
      "neuroninSec.3?foreachoffourorientations(0,45,90,135deg,sampling\n",
      "morecoarselythan[1]).Wecomputethenon?linearresponseofeachmodel\n",
      "neuronasinSec.3,andtakethemaximumacrossthefourorientationsasthe\n",
      "populationoutput,asinstandardpopulationdecoding.Thisisperformedat\n",
      "eachpixeloftheinputimage,andtheresultisinterpretedasasaliencymap.We\n",
      "considerthepopoutofatargetthatfromabackgroundofdistractors\n",
      "byasinglefeature(eg.[8]),inourcaseorientation.Inputimageandoutput\n",
      "saliencymap(thebrighter,themoresalient)areshowninFig.5.Asin[1],\n",
      "thetargetpopsoutsinceitislesssuppressedbyitsown,orthogonally-oriented\n",
      "neighborsthanthesurroundbarsarebytheirparallelones;here,thisemerges\n",
      "straightfromnormativeinference.[8]quanrelativetargetsaliencyabove\n",
      "detectionthreshold5\n",
      "Figure4:Thetiltillusion.(a)ComparisonofthelearnedGSMmodel(black,\n",
      "solidlinewithsquares),withtheGSMmodelin[34](blue,solidline;pa-\n",
      "rameterssettoaccountfortheillusiondataof[39]),andthemodelin[34]with\n",
      "parametersmotomatchthelearnedmodel(blue,dashedline).There-\n",
      "sponseofeachneuroninthepopulationisplottedasafunctionofthe\n",
      "betweenthesurroundstimulusorientationandthepreferredcenterstimulus\n",
      "orientation.Weassumeallorientedneuronshaveidenticalpropertiestothe\n",
      "learnedverticalneuron(i.e.,ignoringtheobliqueThemodelof[34]in-\n",
      "cludesidealizedtuningcurves.Thelearnedmodelisasintheprevioussection,\n",
      "butwithofnarrowerorientationtuning(becauseofdensersamplingof\n",
      "16orientationsinthepyramid),whichresultsinanearlierpointonthexaxis\n",
      "ofmaximalresponse.Modelsimulationsarenormalizedtoamaximumof1.\n",
      "(b)Simulationsofthetiltillusionusingthemodelin[34],basedonparameters\n",
      "matchedtothelearnedmodel(dashedline)versusparametersmatchedtothe\n",
      "dataof[39](solidline).asafunctionofthederenceinorientationbetween\n",
      "targetanddistractorsusingluminance(Fig.5b).Fig.5cplotssaliencyfromthe\n",
      "model;itexhibitsnon?linearsaturationforlargeorientationcontrast,an\n",
      "thatnotallsaliencymodelscapture(see[17]fordiscussion).Theshapeofthe\n",
      "saturationistforneural(Fig.2a-b)versusperceptual(Fig.5b-c)data,\n",
      "inbothexperimentandmodel;forthelatter,thisarisesfrominstim-\n",
      "uli(gratingsversusbars,howthecenterandsurroundextentsweredetermined).\n",
      "Thesecondclassofsaliencyinvolvescollinearfacilitation.Oneexample\n",
      "isthesocalledbordershownin6a?onesideoftheborder,whose\n",
      "individualbarsarecollinear,ismoresalientthantheother(e.g.[1],butseealso\n",
      "[40]).Themiddleandrightplotsin6adepictthesaliencymapforthefull\n",
      "modelandareducedmodelthatusesadiagonalcovariancematrix.Noticethat\n",
      "7\n",
      "\n",
      "thereducedmodelalsoshowsanenhancementofthecollinearsideoftheborder\n",
      "vstheparallel,duetothepartialoverlapofthelinearreceptivebut,as\n",
      "explainedinSec.2.3,thehighercovariancebetweencollinearinthefull\n",
      "model,strengthenstheToquantifytherence,wereportalsothera-\n",
      "tiobetweenthesaliencevaluesonthecollinearandparallelsidesoftheborder,\n",
      "aftersubtractingthesaliencyvalueofthehomogeneousregions:thelowervalue\n",
      "forthereducedmodel(1.28;versus1.74forthefullmodel)showsthatthefull\n",
      "modelenhancesthecollinearrelativetotheparallelside.Theratioforthefull\n",
      "modelincreasesifwerescalethe?diagonaltermsofthecovariancematrix\n",
      "relativetothediagonal(2.1forascalingfactorof1.5;2.73forafactorof2).\n",
      "Rescalingwouldcomefrommorereasonablydensespatialsampling.Fig.6b\n",
      "providesanother,strongerexampleofthecollinearfacilitation.\n",
      "5\n",
      "Discussion\n",
      "WehaveextendedastandardGSMgenerativemodelofscenestatisticsto\n",
      "encompasscontextualWemodeledthecovariancebetweentheGaus-\n",
      "siancomponentsassociatedwithneighboringlocations,andsuggestedasimple,\n",
      "approximate,processforchoosingwhetherornottopoolsuchlocationsun-\n",
      "derthesamemixer.Usingparameterslearnedfromnaturalscenes,weshowed\n",
      "thatthismodelprovidesapromisingaccountofneurophysiologicaldataonarea\n",
      "summationandcentersurroundorientationcontrast,andperceptualdataonthe\n",
      "saliencyofimageelements.Thisformofmodelhaspreviouslybeenappliedto\n",
      "thetiltillusion[34],buthadjustassumedtheassignmentsof3c,inorder\n",
      "toaccountfortheindirecttiltillusion.Here,thisemergedfromprinciples.\n",
      "Thismodelthereforeawealthofdataandideasaboutcontextualvisual\n",
      "processing.Toour6\n",
      "Figure5:(a)Anexampleofthestimulusandsaliencymapcomputedby\n",
      "themodel.(b)Perceptualdatareproducedafter[8],and(c)modeloutput,of\n",
      "thesaliencyofthecentralbarasafunctionoftheorientationcontrastbetween\n",
      "centerandsurround.\n",
      "Figure6:(a)Borderthecollinearsideoftheborderismoresalient\n",
      "thantheparallelone;thecenterplotisthesaliencymapforthefullmodel,right\n",
      "plotisforareducedmodelwithdiagonalcovariancematrix.(b)Anotherexam-\n",
      "pleofcollinearfacilitation:thecenterrowofbarsismoresalient,relativetothe\n",
      "background,whenthebarsarecollinear(left)ratherthanwhentheyareparallel\n",
      "(right).Inboth(a)and(b),Col/Paristheratiobetweenthesaliencevalues\n",
      "onthecollinearandparallelsidesoftheborder,aftersubtractingthesaliency\n",
      "valueofthehomogeneousregions.knowledge,therehaveonlybeenfewprevious\n",
      "attemptsofthissort;onenotableexampleistheextensivesalienceworkof[17];\n",
      "herewegofurtherintermsofsimulatingneuralnon?linearities,andmakingcon-\n",
      "nectionswiththecontourintegrationandillusionliterature:phenomenathat\n",
      "havepreviouslybeenaddressedonlyindividually,ifatall.Ourmodelisclosely\n",
      "relatedtoanumberofsuggestionsintheliterature.Previousbottom-upmodels\n",
      "ofdivisivenormalization,whichweretheoriginalinspirationfortheapplication\n",
      "by[22]oftheGSM,canaccountforsomeneuralnon?linearitiesbylearning\n",
      "divisiveweightsinsteadofassignments(e.g.,[33]).Howevertheydonotincor-\n",
      "8\n",
      "\n",
      "poratelinearcorrelations,andtheythedivisiveweightsaprioriratherthan\n",
      "onaimage?by?imagebasissuchasinourmodel.Non-parametricstatistical\n",
      "alternativestodivisivenormalization,e.g.non-linearICA[41],havealsobeen\n",
      "proposed,buthavebeenappliedonlytotheorientationmaskingnonlinearity,\n",
      "thereforenotaddressingspatialcontext.Therearealsovarioustop-downmod-\n",
      "elsbasedonrelatedprinciples.ComparedwithpreviousGSMmodelling[30],we\n",
      "havebuiltamorecomputationallystraightforward,andneurobiologicallycred-\n",
      "ible,approximateassignmentmechanism.Otherrecentgenerativestatistical\n",
      "modelsthatcapturethestatisticaldependenciesoftheinslightly\n",
      "entways(notably[31,35]),mightalsobeabletoencompassthedatawehave\n",
      "presentedhere.However,[35]hasbeenappliedonlytotheimageprocessing\n",
      "domain,andthemodelof[31]hasnotbeentiedtotheperceptualphenomena\n",
      "wehaveconsidered,nortocontrastdata.Therearealsoquantitative\n",
      "encesbetweenthemodels,includingissuesofsoftversushardassignment(see\n",
      "discussionin[30]);theassumptionaboutthelinktodata(hereweadoptedthe\n",
      "meanoftheGaussiancomponentoftheGSMwhichincorporates7\n",
      "anexplicitgaincontrol,incontrasttotheapproachin[31]);andtherich-\n",
      "nessofassignmentversusapproximationinthevariousmodels(herewehave\n",
      "purposelytakenanapproximateversionofafullassignmentmodel).Thereare\n",
      "alsomanymodelsdevotedtosaliency.Weshowedthatourassignmentprocess,\n",
      "andthenormalizationthatresults,isagoodmatchfor(andthusanormative\n",
      "of)atleastsomeoftheresultsthat[1,15]capturedinadynamical\n",
      "realizationoftheV1saliencyhypothesis.However,ourmodelachievessuppres-\n",
      "sioninregionsofstatisticalhomogeneitydivisivelyratherthansubtractively.\n",
      "ThecovariancebetweentheGaussiancomponentscapturessomeaspectsofthe\n",
      "longrangeexcitatoryinthatmodel,whichpermitcontourintegration.\n",
      "However,someofthecollinearfacilitationarisesjustfromreceptiveoverlap;\n",
      "andthestructureofthecovarianceinnaturalscenesseemsratherimpoverished\n",
      "comparedwiththatimpliedbytheassociation[42],andmeritsfurther\n",
      "examinationwithhigherorderstatistics(seealso[10,26]).Notealsothatdy-\n",
      "namicalmodelshavenotpreviouslybeenappliedtothesamerangeofdata\n",
      "(suchasthetiltillusion).Opentheoreticalissuesincludequantifyingcarefully\n",
      "theoftherathercoarseassignmentapproximation,aswellasthe\n",
      "encesbetweenthelearnedmodelandtheidealizedpopulationmodelofthetilt\n",
      "illusion[34].Otherimportantissuesincludecharacterizingthenatureand\n",
      "ofuncertaintyinthedistributionsofgandvratherthanjustthemean.Thisis\n",
      "criticaltocharacterizepsychophysicalresultsoncontrastdetectionintheface\n",
      "ofnoiseandalsoorientationacuity,andalsoraisestheissuesairedby[31]asto\n",
      "howneuralresponsesconveyuncertainties.Openexperimentalissuesincludea\n",
      "rangeofothercontextualastosalience,contourintegration,andeven\n",
      "perceptualcrowding.Contextualareequallypresentatmultiplelevels\n",
      "ofneuralprocessing.Animportantfuturegeneralizationwouldbetohigher\n",
      "neuralareas,andtomidandhighlevelvision(whichthemselvesexhibitgain-\n",
      "controlrelatedphenomena,seee.g.[43]).Moregenerally,contextispervasive\n",
      "intimeaswellasspace.Theparallelsareunderexplored,andsopressing.Ac-\n",
      "knowledgementsThisworkwasfundedbytheAlfredP.SloanFoundation(OS);\n",
      "9\n",
      "\n",
      "andTheGatsbyCharitableFoundation,theBBSRC,theEPSRCandtheWell-\n",
      "comeTrust(PD).WeareverygratefultoAdamKohn,JoshuaSolomon,Adam\n",
      "Sanborn,andLiZhaopingfordiscussion.\n",
      "2References\n",
      "[1]Z.Li.Asaliencymapinprimaryvisualcortex.TrendsCognSci,6(1):9?16,\n",
      "2002.[2]P.Series,J.Lorenceau,andY.Fr?egnac.The?silent?surroundof\n",
      "v1receptivetheoryandexperiments.JPhysiolParis,97(4-6):453?474,\n",
      "2003.[3]H.E.Jones,K.L.Grieve,W.Wang,andA.M.Sillito.Surround\n",
      "suppressioninprimatev1.JNeurophysiol,86(4):2011?2028,2001.[4]J.R.\n",
      "Cavanaugh,W.Bair,andJ.A.Movshon.Selectivityandspatialdistribution\n",
      "ofsignalsfromthereceptivesurroundinmacaquev1neurons.JNeuro-\n",
      "physiol,88(5):2547?2556,2002.[5]J.J.GibsonandM.Radner.Adaptation,\n",
      "andcontrastintheperceptionoftiltedlines.JournalofExperi-\n",
      "mentalPsychology,20:553?569,1937.[6]C.W.Clord,P.Wenderoth,and\n",
      "B.Spehar.Afunctionalangleonsometsincorticalvision.Proc\n",
      "RSocLondBBiolSci,1454:1705?1710,2000.[7]J.A.SolomonandM.J.\n",
      "Morgan.Stochasticre-calibration:contextualonperceivedtilt.Proc\n",
      "BiolSci,273(1601):2681?2686,2006.[8]H.C.Nothdurft.Theconspicuousness\n",
      "oforientationandmotioncontrast.SpatialVision,7(4):341?363,1993.[9]D.\n",
      "J.Field,A.Hayes,andR.F.Hess.Contourintegrationbythehumanvisual\n",
      "system:evidenceforalocal?associationVisionRes,33(2):173?193,\n",
      "1993.[10]W.S.Geisler,J.S.Perry,B.J.Super,andD.P.Gallogly.Edge\n",
      "co-occurrenceinnaturalimagespredictscontourgroupingperformance.Vision\n",
      "Res,41(6):711?724,2001.[11]L.Schwabe,K.Obermayer,A.Angelucci,and\n",
      "P.C.Theroleoffeedbackinshapingtheextraclassicalreceptive\n",
      "ofcorticalneurons:arecurrentnetworkmodel.JNeurosci,26(36):9117?9129,\n",
      "2006.[12]J.WielaardandP.Sajda.Extraclassicalreceptivephenom-\n",
      "enaandshort-rangeconnectivityinv1.CerebCortex,16(11):1531?1545,2006.\n",
      "[13]T.J.SullivanandV.R.deSa.Amodelofsurroundsuppressionthrough\n",
      "corticalfeedback.NeuralNetw,19(5):564?572,2006.\n",
      "8\n",
      "[14]T.N.MundhenkandL.Itti.Computationalmodelingandexploration\n",
      "ofcontourintegrationforvisualsaliency.BiologicalCybernetics,93(3):188?212,\n",
      "2005.[15]Z.Li.Visualsegmentationbycontextualviaintracortical\n",
      "interactionsinprimaryvisualcortex.Network:ComputationinNeuralSys-\n",
      "tems,10(2):187?212,1999.[16]L.IttiandC.Koch.Asaliency-basedsearch\n",
      "mechanismforovertandcovertshiftsofvisualattention.VisionResearch,\n",
      "40(10-12):1489?1506,2000.[17]D.Gao,V.Mahadevan,andN.Vasconselos.\n",
      "Ontheplausibilityofthediscriminantcenter-surroundhypothesisforvisual\n",
      "saliency.JournalofVision,8(7)(13):1?18,2008.[18]L.Zhang,M.H.Tong,T.\n",
      "Marks,H.Shan,andG.W.Cottrell.Sun:Abayesianframeworkforsaliency\n",
      "usingnaturalstatistics.JournalofVision,8(7)(32):1?20,2008.[19]N.D.B.\n",
      "BruceandJ.K.Tsotsos.Saliency,attention,andvisualsearch:Aninformation\n",
      "10\n",
      "\n",
      "theoreticapproach.JournalofVision,9(3)(5):1?24,2009.[20]A.Hyv?arinen,\n",
      "J.Hurri,andP.O.Hoyer.NaturalImageStatistics.Springer,2009.[21]D.\n",
      "AndrewsandC.Mallows.Scalemixturesofnormaldistributions.J.Royal\n",
      "Stat.Soc.,36:99?102,1974.[22]M.J.Wainwright,E.P.Simoncelli,andA.\n",
      "S.Willsky.Randomcascadesonwavelettreesandtheiruseinmodelingand\n",
      "analyzingnaturalimagery.AppliedandComputationalHarmonicAnalysis,\n",
      "11(1):89?123,2001.[23]J.Portilla,V.Strela,M.Wainwright,andE.P.Si-\n",
      "moncelli.ImagedenoisingusingascalemixtureofGaussiansinthewavelet\n",
      "domain.IEEETransImageProcessing,12(11):1338?1351,2003.[24]C.Zet-\n",
      "zsche,B.Wegmann,andE.Barth.Nonlinearaspectsofprimaryvision:Entropy\n",
      "reductionbeyonddecorrelation.InInt?lSymposium,SocietyforInformation\n",
      "Display,volumeXXIV,pages933?936,1993.[25]E.P.Simoncelli.Statistical\n",
      "modelsforimages:Compression,restorationandsynthesis.InProc31stAsilo-\n",
      "marConfonSignals,SystemsandComputers,pages673?678,PGrove,\n",
      "CA,1997.IEEEComputerSociety.[26]P.HoyerandA.Hyv?arinen.Amulti-\n",
      "layersparsecodingnetworklearnscontourcodingfromnaturalimages.Vision\n",
      "Research,42(12):1593?1605,2002.[27]AHyv?arinen,J.Hurri,andJ.Vayry-\n",
      "nen.Bubbles:aunifyingframeworkforlow-levelstatisticalpropertiesofnatural\n",
      "imagesequences.JournaloftheOpticalSocietyofAmericaA,20:1237?1252,\n",
      "2003.[28]Y.KarklinandM.S.Lewicki.AhierarchicalBayesianmodelfor\n",
      "learningnonlinearstatisticalregularitiesinnonstationarynaturalsignals.Neu-\n",
      "ralComputation,17:397?423,2005.[29]S.Osindero,M.Welling,andG.E.\n",
      "Hinton.Topographicproductmodelsappliedtonaturalscenestatistics.Neu-\n",
      "ralComputation,18(2):381?414,2006.[30]O.Schwartz,T.J.Sejnowski,and\n",
      "P.Dayan.Softmixerassignmentinahierarchicalgenerativemodelofnatural\n",
      "scenestatistics.NeuralComput,18(11):2680?2718,2006.[31]Y.Karklinand\n",
      "M.S.Lewicki.Emergenceofcomplexcellpropertiesbylearningtogeneralizein\n",
      "naturalscenes.Nature,457(7225):83?86,2009.[32]D.J.Heeger.Normaliza-\n",
      "tionofcellresponsesincatstriatecortex.VisualNeuroscience,9:181?198,1992.\n",
      "[33]O.SchwartzandE.P.Simoncelli.Naturalsignalstatisticsandsensorygain\n",
      "control.NatureNeuroscience,4(8):819?825,2001.[34]O.Schwartz,T.J.Se-\n",
      "jnowski,andP.Dayan.Perceptualorganizationinthetiltillusion.Journalof\n",
      "Vision,9(4)(19):1?20,2009.[35]J.A.Guerrero-Colon,E.P.Simoncelli,andJ.\n",
      "Portilla.Imagedenoisingusingmixturesofgaussianscalemixtures.InProc\n",
      "15thIEEEInt?lConfonImageProc,pages565?568,2008.[36]E.P.Simon-\n",
      "celli,W.T.Freeman,E.H.Adelson,andD.J.Heeger.Shiftablemulti-scale\n",
      "transforms.IEEETransInformationTheory,38(2):587?607,1992.[37]C.K.I.\n",
      "WilliamsandN.J.Adams.Dynamictrees.InM.S.Kearns,S.A.Solla,and\n",
      "D.A.Cohn,editors,Adv.NeuralInformationProcessingSystems,volume11,\n",
      "pages634?640,Cambridge,MA,1999.MITPress.[38]X.L.MengandD.B.\n",
      "Rubin.Maximumlikelihoodestimationviatheecmalgorithm:Ageneralframe-\n",
      "work.Biometrika,80(2):267?278,1993.[39]E.Goddard,C.W.G.,and\n",
      "S.G.Solomon.Centre-surroundonperceivedorientationincomplexim-\n",
      "ages.VisionResearch,48:1374?1382,2008.[40]A.V.PoppleandZ.Li.Testing\n",
      "av1model:perceptualbiasesandsaliencyJournalofVision,1,3:148,\n",
      "2001.[41]J.MaloandJ.Guti?errez.V1non?linearpropertiesemergefrom\n",
      "11\n",
      "\n",
      "local?to?globalnon?linearica.Network:Comp.Neur.Syst.,17(1):85?102,\n",
      "2006.[42]D.J.Field.Relationsbetweenthestatisticsofnaturalimagesand\n",
      "theresponsepropertiesofcorticalcells.J.Opt.Soc.Am.A,4(12):2379?2394,\n",
      "1987.[43]Q.LiandZ.Wang.General?purposereduced?referenceimagequality\n",
      "assessmentbasedonperceptuallyandstatisticallymotivatedimagerepresenta-\n",
      "tion.InProc15thIEEEInt?lConfonImageProc,pages1192?1195,2008.\n",
      "9\n",
      "12\n",
      "\n",
      "PP3596.pdf\n",
      "PP3596.pdf 10\n",
      "RobustRegressionandLasso\n",
      "Authoredby:\n",
      "ShieMannor\n",
      "HuanXu\n",
      "ConstantineCaramanis\n",
      "Abstract\n",
      "Weconsiderrobustleast-squaresregressionwithfeature-wisedistur-\n",
      "bance.Weshowthatthisformulationleadstotractableconvexopti-\n",
      "mizationproblems,andweexhibitaparticularuncertaintysetforwhich\n",
      "therobustproblemisequivalentto$ell\n",
      "1$regularizedregression(Lasso).\n",
      "ThisprovidesaninterpretationofLassofromarobustoptimizationper-\n",
      "spective.Wegeneralizethisrobustformulationtoconsidermoregeneral\n",
      "uncertaintysets,whichallleadtotractableconvexoptimizationprob-\n",
      "lems.Therefore,weprovideanewmethodologyfordesigningregression\n",
      "algorithms,whichgeneralizeknownformulations.Theadvantageisthat\n",
      "robustnesstodisturbanceisaphysicalpropertythatcanbeexploited:in\n",
      "additiontoobtainingnewformulations,weuseitdirectlytoshowspar-\n",
      "sitypropertiesofLasso,aswellastoproveageneralconsistencyresult\n",
      "forrobustregressionproblems,includingLasso,fromarobustness\n",
      "perspective.\n",
      "1PaperBody\n",
      "Inthispaperweconsiderlinearregressionproblemswithleast-squareerror.\n",
      "Theproblemistoavectorxsothatthe`2normoftheresidualb?Ax\n",
      "isminimized,foragivenmatrixA?Rn?mandvectorb?Rn.Froma\n",
      "learning/regressionperspective,eachrowofAcanberegardedasatraining\n",
      "sample,andthecorrespondingelementofbasthetargetvalueofthisobserved\n",
      "sample.EachcolumnofAcorrespondstoafeature,andtheobjectiveisto\n",
      "asetofweightssothattheweightedsumofthefeaturevaluesapproximatesthe\n",
      "targetvalue.Itiswellknownthatminimizingtheleastsquarederrorcanlead\n",
      "tosensitivesolutions[1,2].Manyregularizationmethodshavebeenproposed\n",
      "todecreasethissensitivity.Amongthem,Tikhonovregularization[3]andLasso\n",
      "[4,5]aretwowidelyknownandcitedalgorithms.Thesemethodsminimizea\n",
      "weightedsumoftheresidualnormandacertainregularizationterm,kxk2for\n",
      "Tikhonovregularizationandkxk1forLasso.Inadditiontoprovidingregularity,\n",
      "Lassoisalsoknownfor1\n",
      "1\n",
      "\n",
      "thetendencytoselectsparsesolutions.Recentlythishasattractedmuch\n",
      "attentionforitsabilitytoreconstructsparsesolutionswhensamplingoccursfar\n",
      "belowtheNyquistrate,andalsoforitsabilitytorecoverthesparsitypattern\n",
      "exactlywithprobabilityone,asymptoticallyasthenumberofobservationsin-\n",
      "creases(thereisanextensiveliteratureonthissubject,andwereferthereader\n",
      "to[6,7,8,9,10]andreferencestherein).Inmanyoftheseapproaches,the\n",
      "choiceofregularizationparametersoftenhasnofundamentalconnectiontoan\n",
      "underlyingnoisemodel[2].In[11],theauthorsproposeanalternativeapproach\n",
      "toreducingsensitivityoflinearregression,byconsideringarobustversionofthe\n",
      "regressionproblem:theyminimizetheworst-caseresidualfortheobservations\n",
      "undersomeunknownbutboundeddisturbances.Theyshowthattheirrobust\n",
      "leastsquaresformulationisequivalentto`2-regularizedleastsquares,andthey\n",
      "explorecomputationalaspectsoftheproblem.Inthatpaper,andinmostofthe\n",
      "subsequentresearchinthisareaandthemoregeneralareaofRobustOptimiza-\n",
      "tion(see[12,13]andreferencestherein)thedisturbanceistakentobeeither\n",
      "row-wiseanduncorrelated[14],orgivenbyboundingtheFrobeniusnormof\n",
      "thedisturbancematrix[11].Inthispaperweinvestigatetherobustregression\n",
      "problemundermoregeneraluncertaintysets,focusinginparticularonthecase\n",
      "wheretheuncertaintysetisdenedbyfeature-wiseconstraints,andalsothe\n",
      "casewherefeaturesaremeaningfullycorrelated.Thisisofinterestwhenvalues\n",
      "offeaturesareobtainedwithsomenoisypre-processingsteps,andthemagni-\n",
      "tudesofsuchnoisesareknownorbounded.Weprovethatallourformulations\n",
      "arecomputationallytractable.Unlikemuchofthepreviousliterature,wepro-\n",
      "videafocusonstructuralpropertiesoftherobustsolution.Inadditiontogiving\n",
      "newformulations,andnewpropertiesofthesolutionstotheserobustproblems,\n",
      "wefocusontheinherentimportanceofrobustness,anditsabilitytoprovefrom\n",
      "scratchimportantpropertiessuchassparseness,andasymptoticconsistencyof\n",
      "Lassointhestatisticallearningcontext.Inparticular,ourmaincontributions\n",
      "inthispaperareasfollows.?Weformulatetherobustregressionproblemwith\n",
      "feature-wiseindependentdisturbances,andshowthatthisformulationisequiv-\n",
      "alenttoaleast-squareproblemwithaweighted`1normregularizationterm.\n",
      "Hence,weprovideaninterpretationforLassofromarobustnessperspective.\n",
      "Thiscanbehelpfulinchoosingtheregularizationparameter.Wegeneralize\n",
      "therobustregressionformulationtolossfunctionsgivenbyanarbitrarynorm,\n",
      "anduncertaintysetsthatallowcorrelationbetweendisturbancesoft\n",
      "features.?Weinvestigatethesparsitypropertiesfortherobustregression\n",
      "problemwithfeature-wiseindependentdisturbances,showingthatsuchformu-\n",
      "lationsencouragesparsity.Wethuseasilyrecoverstandardsparsityresultsfor\n",
      "Lassousingarobustnessargument.Thisalsoimpliesafundamentalconnection\n",
      "betweenthefeature-wiseindependenceofthedisturbanceandthesparsity.?\n",
      "Next,werelateLassotokerneldensityestimation.Thisallowsustore-prove\n",
      "consistencyinastatisticallearningsetup,usingthenewrobustnesstoolsand\n",
      "formulationweintroduce.Notation.Weusecapitalletterstorepresentma-\n",
      "trices,andboldfaceletterstorepresentcolumnvectors.Foravectorz,welet\n",
      "zidenotetheithelement.Throughoutthepaper,aiandr>jdenotethththe\n",
      "icolumnandthejrowoftheobservationmatrixA,respectively;aijistheij\n",
      "2\n",
      "\n",
      "elementofA,henceitisthejthelementofri,andithelementofaj.Fora\n",
      "convexfunctionf(?),?f(z)representsanyofitssub-gradientsevaluatedatz.\n",
      "2\n",
      "RobustRegressionwithFeature-wiseDisturbance\n",
      "WeshowthatourrobustregressionformulationrecoversLassoasaspecial\n",
      "case.TheregressionformulationweconsiderfromthestandardLasso\n",
      "formulation,asweminimizethenormoftheerror,ratherthanthesquared\n",
      "norm.Itisknownthatthesetwocoincideuptoachangeoftheregularization\n",
      "cot.Yetourresultsamounttomorethanarepresentationorequivalence\n",
      "theorem.Inadditiontomoreandpotentiallypowerfulrobustformula-\n",
      "tions,weprovenewresults,andgivenewinsightintoknownresults.InSection\n",
      "3,weshowtherobustformulationgivesrisetonewsparsityresults.Someofour\n",
      "resultsthere(e.g.Theorem4)fundamentallydependon(andfollowfrom)the\n",
      "robustnessargument,whichisnotfoundelsewhereintheliterature.Thenin\n",
      "Section4,weestablishconsistencyofLassodirectlyfromtherobustnessprop-\n",
      "ertiesofourformulation,thusexplainingconsistencyfromamorephysically\n",
      "motivatedandperhapsmoregeneralperspective.2\n",
      "2.1\n",
      "Formulation\n",
      "RobustlinearregressionconsidersthecasethattheobservedmatrixAis\n",
      "corruptedbysomedisturbance.Weseektheoptimalweightfortheuncorrupted\n",
      "(yetunknown)samplematrix.Weconsiderthefollowingmin-maxformulation:\n",
      "RobustLinearRegression:minmmaxkb?(A+?A)xk2.(1)x?R\n",
      "?A?U\n",
      "Here,UisthesetofadmissibledisturbancesofthematrixA.Inthissection,\n",
      "weconsiderthespecisetupwherethedisturbanceisfeature-wiseuncorrelated,\n",
      "andnorm-boundedforeachfeature:\n",
      "no\n",
      "U,(?1,???,?m)k?ik2?ci,i=1,???,m,(2)\n",
      "forgivenci?0.Thisformulationrecoversthewell-knownLasso:\n",
      "Theorem1.Therobustregressionproblem(1)withtheuncertaintyset(2)\n",
      "isequivalenttothefollowing`1regularizedregressionproblem:mnoXminm\n",
      "kb?Axk2+ci|xi|.\n",
      "x?R\n",
      "(3)\n",
      "i=1\n",
      "Proof.Wedeferthefulldetailsto[15],andgiveonlyanoutlineoftheproof\n",
      "here.Showingthattherobustregressionisalowerboundfortheregularized\n",
      "regressionfollowsfromthestandardtriangleinequality.Conversely,onecan\n",
      "taketheworst-casenoisetobe??i,?cisgn(x?i)u,whereuisgivenbyb?Ax?\n",
      "ifAx?6=b,kb?Ax?k2u,,anyvectorwithunit`2normotherwise;from\n",
      "whichtheresultfollowsaftersomealgebra.Ifwetakeci=candnormalizedai\n",
      "foralli,Problem(3)isthewell-knownLasso[4,5].2.2\n",
      "Arbitrarynormandcorrelateddisturbance\n",
      "Itispossibletogeneralizethisresulttothecasewherethe`2-normis\n",
      "replacedbyanarbitrarynorm,andwheretheuncertaintyiscorrelatedfrom\n",
      "3\n",
      "\n",
      "featuretofeature.Forspaceconsiderations,werefertothefullversion([15]),\n",
      "andsimplystatethemainresultshere.Theorem2.Letk?kadenotean\n",
      "arbitrarynorm.Thentherobustregressionproblem\n",
      "no\n",
      "minmmaxkb?(A+?A)xka;Ua,(?1,???,?m)k?ika?ci,i=1,\n",
      "???,m;x?R\n",
      "?A?Ua\n",
      "noPmisequivalenttotheregularizedregressionproblemminx?Rmkb?\n",
      "Axka+i=1ci|xi|.\n",
      "Usingfeature-wiseuncorrelateddisturbancemayleadtooverlyconservative\n",
      "results.Werelaxthis,allowingthedisturbancesoftfeaturestobe\n",
      "correlated.Considerthefollowinguncertaintyset:\n",
      "U0,(?1,???,?m)fj(k?1ka,???,k?mka)?0;j\n",
      "=1,???,k,wherefj(?)areconvexfunctions.Noticethatbothkand\n",
      "fjcanbearbitrary,hencethisisaverygeneralformulationandprovidesus\n",
      "withtyindesigninguncertaintysetsandequivalentlynew\n",
      "regressionalgorithms.Thefollowingtheoremconvertsthisformulationtoa\n",
      "convexandtractableoptimizationproblem.Theorem3.AssumethatthesetZ\n",
      ",\n",
      "f\n",
      "z?Rm|fj(z)?0,j=1,???,k;z?0\n",
      "g\n",
      "hasnon-emptyrelativeinterior.\n",
      "Therobustregressionproblem\n",
      "minmmax0kb?(A+?A)xka,x?R\n",
      "?A?U\n",
      "3\n",
      "isequivalenttothefollowingregularizedregressionproblemnominkb?\n",
      "Axka+v(?,?,x);mm??Rk+,??R+,x?R\n",
      "khiXwhere:v(?,?,x),maxm(?+|x|)>c??jfj(c).\n",
      "(4)\n",
      "c?R\n",
      "j=1\n",
      "no\n",
      "Example1.SupposeU0=(?1,???,?m)k?1ka,???,k?m\n",
      "kas?l;forasymmetricnormk?ks,thentheresultingregularizedregression\n",
      "problemisnominmkb?Axka+lkxk?s;wherek?k?sisthedualnormofk\n",
      "?ks.x?R\n",
      "Therobustregressionformulation(1)considersdisturbancesthatarebounded\n",
      "inaset,whileinpractice,oftenthedisturbanceisarandomvariablewithun-\n",
      "boundedsupport.Insuchcases,itisnotpossibletosimplyuseanuncertainty\n",
      "setthatincludesalladmissibledisturbances,andweneedtoconstructamean-\n",
      "ingfulUbasedonprobabilisticinformation.Inthefullversion[15]weconsider\n",
      "computationallyetwaystousechanceconstraintstoconstructuncertainty\n",
      "sets.\n",
      "3\n",
      "Sparsity\n",
      "Inthissection,weinvestigatethesparsitypropertiesofrobustregression\n",
      "(1),andequivalentlyLasso.Lasso?sabilitytorecoversparsesolutionshasbeen\n",
      "extensivelydiscussed(cf[6,7,8,9]),andtakesoneoftwoapproaches.The\n",
      "4\n",
      "\n",
      "approachinvestigatestheproblemfromastatisticalperspective.Thatis,\n",
      "itassumesthattheobservationsaregeneratedbya(sparse)linearcombination\n",
      "ofthefeatures,andinvestigatestheasymptoticorprobabilisticconditionsre-\n",
      "quiredforLassotocorrectlyrecoverthegenerativemodel.Thesecondapproach\n",
      "treatstheproblemfromanoptimizationperspective,andstudiesunderwhat\n",
      "conditionsapair(A,b)aproblemwithsparsesolutions(e.g.,[16]).We\n",
      "followthesecondapproachanddonotassumeagenerativemodel.Instead,\n",
      "weconsidertheconditionsthatleadtoafeaturereceivingzeroweight.Inpar-\n",
      "ticular,weshowthat(i)asadirectresultoffeature-wiseindependenceofthe\n",
      "uncertaintyset,aslightchangeofafeaturethatwasoriginallyassignedzero\n",
      "weightstillgetszeroweight(Theorem4);(ii)usingTheorem4,weshowthat\n",
      "?nearly?orthogonalfeaturesgetzeroweight(Corollary1);and(iii)?nearly?\n",
      "linearlydependentfeaturesgetzeroweight(Theorem5).Substantialresearch\n",
      "regardingsparsitypropertiesofLassocanbefoundintheliterature(cf[6,7,\n",
      "8,9,17,18,19,20]andmanyothers).Inparticular,similarresultsasinpoint\n",
      "(ii),thatrelyonanincoherenceproperty,havebeenestablishedin,e.g.,[16],\n",
      "andareusedasstandardtoolsininvestigatingsparsityofLassofromasta-\n",
      "tisticalperspective.However,aproofexploitingrobustnessandpropertiesof\n",
      "theuncertaintyisnovel.Indeed,suchaproofshowsafundamentalconnection\n",
      "betweenrobustnessandsparsity,andimpliesthatrobustifyingw.r.t.afeature-\n",
      "wiseindependentuncertaintysetmightbeaplausiblewaytoachievesparsity\n",
      "forotherproblems.?b),letx?beanoptimalsolutionoftherobustregression\n",
      "problem:Theorem4.Given(A,\n",
      "?minmmaxkb?(A+?A)xk2.x?R\n",
      "?A?U\n",
      "LetI?\n",
      "f\n",
      "1,???,m\n",
      "g\n",
      "besuchthatforalli?I,x?i=0.Nowlet\n",
      "no\n",
      "U?,(?1,???,?m)k?jk2?cj,j?6I;k?ik2?ci+`i,i?I.\n",
      "Then,x?isanoptimalsolutionof\n",
      "min\n",
      "x?Rm\n",
      "maxkb?(A+?A)xk2,\n",
      "??A?U\n",
      "?ik?`ifori?I,andaj=a?jforj6?I.foranyAthatkai?a4\n",
      "Proof.Noticethatfori?I,x?i=0,hencetheithcolumnofbothAand\n",
      "?Ahasnoontheresidual.Wehave\n",
      "maxb?(A+?A)x?=maxb?(A+?A)x?=maxb?(A?+?A)x?.?\n",
      "?A?U\n",
      "2\n",
      "?A?U\n",
      "2\n",
      "?A?U\n",
      "2\n",
      "??A?U?A+?A?A?U?.?jforj6?I.ThusA+?AFori?I,kai??aik\n",
      "?li,andaj=aTherefore,foranyx0,thefollowingholds:\n",
      "maxb?(A?+?A)x0?maxb?(A+?A)x0.\n",
      "5\n",
      "\n",
      "?A?U\n",
      "??A?U\n",
      "2\n",
      "2\n",
      "Byofx?,\n",
      "maxb?(A?+?A)x??maxb?(A?+?A)x0.\n",
      "?A?U\n",
      "Thereforewehave\n",
      "?A?U\n",
      "2\n",
      "2\n",
      "maxb?(A+?A)x??maxb?(A+?A)x0.\n",
      "??A?U\n",
      "??A?U\n",
      "2\n",
      "2\n",
      "0\n",
      "Sincethisholdsforarbitraryx,weestablishthetheorem.\n",
      "Theorem4isestablishedusingtherobustnessargument,andisadirect\n",
      "resultofthefeature-wiseindependenceoftheuncertaintyset.ItexplainswhyP\n",
      "Lassotendstoassignzeroweighttononrelativefeatures.Consideragenerative\n",
      "model1b=i?Iwiai+??whereI?\n",
      "f\n",
      "1???,m\n",
      "g\n",
      "and??isarandomvariable,\n",
      "i.e.,bisgeneratedbyfeaturesbelongingtoI.Inthiscase,forafeaturei06?\n",
      "I,Lassowouldassignzeroweightaslongasthereexistsaperturbedvalueof\n",
      "thisfeature,suchthattheoptimalregressionassigneditzeroweight.Thisis\n",
      "alsoshowninthenextcorollary,inwhichweapplyTheorem4toshowthatthe\n",
      "problemhasasparsesolutionaslongasanincoherence-typepropertyis\n",
      "(thisresultismoreinlinewiththetraditionalsparsityresults).Corollary1.\n",
      "SupposeSthatforalli,ci=c.IfthereexistsI?\n",
      "f\n",
      "1,???,m\n",
      "g\n",
      "suchthatforall\n",
      "v?span\n",
      "f\n",
      "ai,i?I\n",
      "gf\n",
      "b\n",
      "g\n",
      ",kvk=1,wehavev>aj?c?j6?I,thenanyoptimal\n",
      "solutionx?x?j=0,?j6?I.SProof.Forj6?I,leta=jdenotethe\n",
      "projectionofajontothespanof\n",
      "f\n",
      "ai,i?I\n",
      "gf\n",
      "b\n",
      "g\n",
      ",andlet==?a+j,aj?aj.\n",
      "Thus,wehavekajk?c.LetAbesuchthat\n",
      "aii?I;?i=aa+i6?I.iNowlet\n",
      "U?,\n",
      "f\n",
      "(?1,???,?m)|k?ik2?c,i?I;k?jk2=0,j6?I\n",
      "g\n",
      ".n\n",
      "o?Considertherobustregressionproblemminx?max?A?U?b?(A+?A)?\n",
      "x2,whichisequivalentn\n",
      "?x+Pc|???suchtominx?b?A?i?Ixi|.Nowweshowthatthere\n",
      "existsanoptimalsolutionx2S?jareorthogonaltothespanofof\n",
      "f\n",
      "?thatx??j\n",
      "=0forallj6?I.Thisisbecauseaai,i?I\n",
      "gf\n",
      "b\n",
      "g\n",
      ".?,bychangingxHencefor\n",
      "anygivenx?jtozeroforallj6?I,theminimizingobjectivedoesnotincrease.\n",
      "?jk=ka=Sincek?a?ajk?c?j6?I,(andrecallthatU=\n",
      "f\n",
      "(?1,???,?\n",
      "m)|k?ik2?c,?i\n",
      "g\n",
      ")applyingTheorem4weestablishthecorollary.Thenext\n",
      "corollaryfollowseasilyfromCorollary1.Corollary2.SupposethereexistsI?\n",
      "f\n",
      "1,???,m\n",
      "g\n",
      ",suchthatforalli?I,kaik<ci.Thenanyoptimalsolution\n",
      "x?x?i=0,fori?I.1Whilewearenotassuminggenerativemodels\n",
      "6\n",
      "\n",
      "toestablishtheresults,itisstillinterestingtoseehowtheseresultscanhelpin\n",
      "agenerativemodelsetup.\n",
      "5\n",
      "Thenexttheoremshowsthatsparsityisachievedwhenasetoffeaturesare\n",
      "?almost?linearlydependent.Againwereferto[15]fortheproof.Theorem\n",
      "5.GivenI?\n",
      "f\n",
      "1,???,m\n",
      "g\n",
      "suchthatthereexistsanon-zerovector(wi)i?I\n",
      "satisfyingXXkwiaik2?min|?iciwi|,?i?\n",
      "f\n",
      "?1,+1\n",
      "g\n",
      "i?I\n",
      "i?I\n",
      "?\n",
      "thenthereexistsanoptimalsolutionxsuchthat?i?I:x?i=0.\n",
      "PNoticethatforlinearlydependentfeatures,thereexistsnon-zero(wi)i?I\n",
      "suchthatki?Iwiaik2=0,whichleadstothefollowingcorollary.\n",
      "Corollary3.GivenI?\n",
      "f\n",
      "1,???,m\n",
      "g\n",
      ",letAI,ai,andt,rank(AI).There\n",
      "existsani?I\n",
      "optimalsolutionx?suchthatx?I,(xi)>i?Ihasatmosttnon-zeroco\n",
      "cients.\n",
      "SettingI=\n",
      "f\n",
      "1,???,m\n",
      "g\n",
      ",weimmediatelygetthefollowingcorollary.\n",
      "Corollary4.Ifn<m,thenthereexistsanoptimalsolutionwithnomorethan\n",
      "nnon-zerocots.\n",
      "4\n",
      "DensityEstimationandConsistency\n",
      "Inthissection,weinvestigatetherobustlinearregressionformulationfroma\n",
      "statisticalperspectiveandrederiveusingonlyrobustnesspropertiesthatLasso\n",
      "isasymptoticallyconsistent.Wenotethatourresultappliestoaconsiderably\n",
      "moregeneralframeworkthanLasso.Inthefullversion([15])weusesome\n",
      "intermediateresultsusedtoproveconsistency,toshowthatregularizationcan\n",
      "beidenwiththeso-calledmaxminexpectedutility(MMEU)framework,\n",
      "thustyingregularizationtoafundamentaltenetofdecision-theory.Werestrict\n",
      "ourdiscussiontothecasewherethemagnitudeoftheallowableuncertainty\n",
      "forallfeaturesequalsc,(i.e.,thestandardLasso)andestablishthestatistical\n",
      "consistencyofLassofromadistributionalrobustnessargument.Generalization\n",
      "tothenon-uniformcaseisstraightforward.Throughout,weusecntorepresentc\n",
      "wheretherearensamples(wetakecntozero).Recallthestandardgenerative\n",
      "modelinstatisticallearning:letPbeaprobabilitymeasurewithbounded\n",
      "supportthatgeneratesi.i.d.samples(bi,ri),andhasadensityf?(?).Denote\n",
      "thesetofthensamplesbySn.evvnnnuoon?nuu1XuX2+\n",
      "ckxktx(cn,Sn),argmint(bi?r>x)=argmin(bi?r>x)2+cnkxk1;n\n",
      "1iixxni=1ni=1sZon(b?r>x)2dP(b,r).x(P),argminx\n",
      "b,r\n",
      "?Inwords,x(cn,Sn)isthesolutiontoLassowiththeparameter\n",
      "settocnn,andx(P)isthe?true?optimalsolution.Wehavethefollowingcon-\n",
      "sistencyresult.Thetheoremitselfisawell-knownresult.However,theproof\n",
      "techniqueisnovel.Thistechniqueisofinterestbecausethestandardtechniques\n",
      "toestablishconsistencyinstatisticallearningincludingVCdimensionandal-\n",
      "gorithmstabilityoftenworkforalimitedrangeofalgorithms,e.g.,SVMsare\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowntohaveVCdimension,andweshowinthefullversion([15])\n",
      "thatLassoisnotstable.Incontrast,amuchwiderrangeofalgorithmshavero-\n",
      "bustnessinterpretations,allowingaapproachtoprovetheirconsistency.\n",
      "Theorem6.Let\n",
      "f\n",
      "cn\n",
      "g\n",
      "besuchthatcn?0andlimn??n(cn)m+1=?.Suppose\n",
      "thereexistsaconstantHsuchthatkx(cn,Sn)k2?Halmostsurely.Then,sZ\n",
      "sZlim(b?r>x(cn,Sn))2dP(b,r)=(b?r>x(P))2dP(b,r),n??\n",
      "b,r\n",
      "b,r\n",
      "almostsurely.6\n",
      "Thefullproofandresultswedevelopalongthewayaredeferredto[15],but\n",
      "weprovidethemainideasandoutlinehere.Thekeytotheproofisestablishing\n",
      "aconnectionbetweenrobustnessandkerneldensityestimation.Step1:Fora\n",
      "givenx,weshowthattherobustregressionlossoverthetrainingdataisequal\n",
      "totheworst-caseexpectedgeneralizationerror.Toshowthisweestablisha\n",
      "moregeneralresult:Proposition1.Givenafunctiong:Rm+1?RandBorel\n",
      "setsZ1,???,Zn?Rm+1,let[Pn,\n",
      "f\n",
      "??P|?S?\n",
      "f\n",
      "1,???,n\n",
      "g\n",
      ":?(Zi)?\n",
      "|S|/n\n",
      "g\n",
      ".i?S\n",
      "Thefollowingholds\n",
      "n\n",
      "1Xsuph(ri,bi)=supni=1(ri,bi)?Zi??Pn\n",
      "Z\n",
      "h(r,b)d?(r,b).\n",
      "Rm+1\n",
      "Step2:Nextweshowthatrobustregressionhasaformlikethatintheleft\n",
      "handsideabove.Also,thesetofdistributionswesupremizeover,intheright\n",
      "handsideabove,includesakerneldensityestimatorforthetrue(unknown)\n",
      "distribution.Indeed,considerthefollowingkernelestimator:givensamples(bi\n",
      ",ri)ni=1,\n",
      "nXb?bi,r?ri,Khn(b,r),(ncm+1)?1c(5)i=1where:K(x),\n",
      "I[?1,+1]m+1(x)/2m+1.\n",
      "ObservethattheestimateddistributiongivenbyEquation(5)belongsto\n",
      "thesetofdistributionsmYPn(A,?,b,c),\n",
      "f\n",
      "??P|Zi=[bi?c,bi+c]?\n",
      "[aij??ij,aij+?ij];j=1\n",
      "?S?\n",
      "f\n",
      "1,???,n\n",
      "g\n",
      ":?(\n",
      "[\n",
      "i?S\n",
      "Zi)?|S|/n\n",
      "g\n",
      ",\n",
      "S??andhencebelongstoP(n)=P(n),?|?j,P?2=nc2Pn(A,?,b,\n",
      "c),whichispreciselythesetiijjofdistributionsusedintherepresentation\n",
      "fromProposition1.RStep3:Combiningthelasttwosteps,andusingthefact\n",
      "thatb,r|hn(b,r)?h(b,r)|d(b,r)goestozeroalmostsurelywhencn?\n",
      "0andncm+1??sincehn(?)isakerneldensityestimationoff(?)n(see\n",
      "e.g.Theorem3.1of[21]),weproveconsistencyofrobustregression.Wecan\n",
      "removetheassumptionthatkx(cn,Sn)k2?H,andasinTheorem6,theproof\n",
      "techniqueratherthantheresultitselfisofinterest.Wepostponetheproofto\n",
      "8\n",
      "\n",
      "[15].Theorem7.Let\n",
      "f\n",
      "cn\n",
      "g\n",
      "convergetozerotlyslowly.ThensZsZ>2\n",
      "lim(b?rx(cn,Sn))dP(b,r)=(b?r>x(P))2dP(b,r),n??\n",
      "b,r\n",
      "b,r\n",
      "almostsurely.\n",
      "5\n",
      "Conclusion\n",
      "Inthispaper,weconsiderrobustregressionwithaleast-square-errorloss,\n",
      "andextendtheresultsof[11](i.e.,Tikhonovregularizationisequivalenttoa\n",
      "robustformulationforFrobeniusnorm-boundeddisturbanceset)toabroader\n",
      "rangeofdisturbancesetsandhenceregularizationschemes.Aspecialcase\n",
      "ofourformulationrecoversthewell-knownLassoalgorithm,andweobtain\n",
      "aninterpretationofLassofromarobustnessperspective.Weconsidermore\n",
      "generalrobustregressionformulations,allowingcorrelationbetweenthefeature-\n",
      "wisenoise,andweshowthatthistooleadstotractableconvexoptimization\n",
      "problems.Weexploitthenewrobustnessformulationtogivedirectproofsof\n",
      "sparsenessandconsistencyforLasso.Asourresultsfollowfromrobustness\n",
      "properties,itsuggeststhattheymaybefarmoregeneralthanLasso,andthat\n",
      "inparticular,consistencyandsparsenessmaybepropertiesonecanobtainmore\n",
      "generallyfromalgorithms.7\n",
      "2References\n",
      "[1]L.Elden.Perturbationtheoryfortheleast-squareproblemwithlinearequal-\n",
      "ityconstraints.BIT,24:472?476,1985.[2]G.GolubandC.VanLoan.\n",
      "MatrixComputation.JohnHopkinsUniversityPress,Baltimore,1989.[3]\n",
      "A.TikhonovandV.Arsenin.SolutionforIll-PosedProblems.Wiley,New\n",
      "York,1977.[4]R.Tibshirani.Regressionshrinkageandselectionviathe\n",
      "lasso.JournaloftheRoyalStatisticalSociety,SeriesB,58(1):267?288,1996.\n",
      "[5]B.Efron,T.Hastie,I.Johnstone,andR.Tibshirani.Leastangleregres-\n",
      "sion.AnnalsofStatistics,32(2):407?499,2004.[6]S.Chen,D.Donoho,and\n",
      "M.Saunders.Atomicdecompositionbybasispursuit.SIAMJournalonSci-\n",
      "enComputing,20(1):33?61,1998.[7]A.FeuerandA.Nemirovski.On\n",
      "sparserepresentationinpairsofbases.IEEETransactionsonInformationThe-\n",
      "ory,49(6):1579?1581,2003.[8]E.Cand`es,J.Romberg,andT.Tao.Robust\n",
      "uncertaintyprinciples:Exactsignalreconstructionfromhighlyincompletefre-\n",
      "quencyinformation.IEEETransactionsonInformationTheory,52(2):489?509,\n",
      "2006.[9]J.Tropp.Greedisgood:Algorithmicresultsforsparseapproxima-\n",
      "tion.IEEETransactionsonInformationTheory,50(10):2231?2242,2004.[10]\n",
      "M.Wainwright.Sharpthresholdsfornoisyandhigh-dimensionalrecoveryof\n",
      "sparsityusing`1-constrainedquadraticprogramming.TechnicalReportAvail-\n",
      "ablefrom:http://www.stat.berkeley.edu/tech-reports/709.pdf,Departmentof\n",
      "Statistics,UCBerkeley,2006.[11]L.ElGhaouiandH.Lebret.Robustsolutions\n",
      "toleast-squaresproblemswithuncertaindata.SIAMJournalonMatrixAnal-\n",
      "ysisandApplications,18:1035?1064,1997.[12]A.Ben-TalandA.Nemirovski.\n",
      "9\n",
      "\n",
      "Robustsolutionsofuncertainlinearprograms.OperationsResearchLetters,\n",
      "25(1):1?13,August1999.[13]D.BertsimasandM.Sim.Thepriceofrobust-\n",
      "ness.OperationsResearch,52(1):35?53,January2004.[14]P.Shivaswamy,C.\n",
      "Bhattacharyya,andA.Smola.Secondorderconeprogrammingapproachesfor\n",
      "handlingmissinganduncertaindata.JournalofMachineLearningResearch,\n",
      "7:1283?1314,July2006.[15]H.Xu,C.Caramanis,andS.Mannor.Robust\n",
      "regressionandLasso.http://arxiv.org/abs/0811.1790v1,2008.\n",
      "Submitted,availablefrom\n",
      "[16]J.Tropp.Justrelax:Convexprogrammingmethodsforidentifying\n",
      "sparsesignals.IEEETransactionsonInformationTheory,51(3):1030?1051,\n",
      "2006.[17]F.Girosi.Anequivalencebetweensparseapproximationandsup-\n",
      "portvectormachines.NeuralComputation,10(6):1445?1480,1998.[18]R.R.\n",
      "CoifmanandM.V.Wickerhauser.Entropy-basedalgorithmsforbest-basisse-\n",
      "lection.IEEETransactionsonInformationTheory,38(2):713?718,1992.[19]\n",
      "S.MallatandZ.Zhang.MatchingPursuitswithtime-frequencedictionar-\n",
      "ies.IEEETransactionsonSignalProcessing,41(12):3397?3415,1993.[20]\n",
      "D.Donoho.Compressedsensing.IEEETransactionsonInformationTheory,\n",
      "52(4):1289?1306,2006.[21]L.DevroyeandL.NonparametricDensity\n",
      "Estimation:thel1View.JohnWiley&Sons,1985.\n",
      "8\n",
      "10\n",
      "\n",
      "PP3233.pdf\n",
      "PP3233.pdf 10\n",
      "FittedQ-iterationincontinuousaction-space\n",
      "MDPs\n",
      "Authoredby:\n",
      "R?miMunos\n",
      "CsabaSzepesv?ri\n",
      "Andr?sAntos\n",
      "Abstract\n",
      "Weconsidercontinuousstate,continuousactionbatchreinforcement\n",
      "learningwherethegoalistolearnagoodpolicyfromatlyrich\n",
      "trajectorygeneratedbyanotherpolicy.WestudyavariantofQ-\n",
      "iteration,wherethegreedyactionselectionisreplacedbysearchingfora\n",
      "policyinarestrictedsetofcandidatepoliciesbymaximizingtheaverage\n",
      "actionvalues.Weprovidearigoroustheoreticalanalysisofthisalgorithm,\n",
      "provingwhatwebelieveistheboundsforvalue-function\n",
      "basedalgorithmsforcontinuousstate-andaction-spaceproblems.\n",
      "1PaperBody\n",
      "Weconsidercontinuousstate,continuousactionbatchreinforcementlearning\n",
      "wherethegoalistolearnagoodpolicyfromatlyrichtrajectorygener-\n",
      "atedbysomepolicy.WestudyavariantofQ-iteration,wherethegreedy\n",
      "actionselectionisreplacedbysearchingforapolicyinarestrictedsetofcan-\n",
      "didatepoliciesbymaximizingtheaverageactionvalues.Weprovidearigorous\n",
      "analysisofthisalgorithm,provingwhatwebelieveisthestbound\n",
      "forvalue-functionbasedalgorithmsforcontinuousstateandactionproblems.\n",
      "1\n",
      "Preliminaries\n",
      "Wewillbuildontheresultsfrom[1,2,3]andforthisreasonweusethe\n",
      "samenotationasthesepapers.Theunattributedresultscitedinthissection\n",
      "canbefoundinthebook[4].AdiscountedMDPisbyaquintuple\n",
      "(X,A,P,S,?),whereXisthe(possiblestatespace,Aisthesetof\n",
      "actions,P:X?A?M(X)isthetransitionprobabilitykernelwithP(?|x,a)\n",
      "thenext-statedistributionupontakingactionafromstatex,S(?|x,\n",
      "a)givesthecorrespondingdistributionofimmediaterewards,and??(0,1)\n",
      "isthediscountfactor.HereXisameasurablespaceandM(X)denotesthe\n",
      "setofallprobabilitymeasuresoverX.TheLebesguemeasureshallbedenoted\n",
      "1\n",
      "\n",
      "by?.WestartwiththefollowingmildassumptionontheMDP:Assumption\n",
      "A1(MDPRegularity)XisacompactsubsetofthedX-dimensionalEuclidean\n",
      "space,?maxAisacompactsubsetof[?A?,A?]dA.Therandomimmediate\n",
      "rewardsareboundedbyRRandthattheexpectedimmediaterewardfunction,\n",
      "r(x,a)=rS(dr|x,a),isuniformlyboundedbyRmax:krk??Rmax.A\n",
      "policydeterminesthenextactiongiventhepastobservations.Hereweshall\n",
      "dealwithstationary(Markovian)policieswhichchooseanactioninastochastic\n",
      "waybasedonthelastobservationonly.Thevalueofapolicy?whenitisstarted\n",
      "fromastatexisastheexpecteddiscountedPtotal?rewardthatis\n",
      "encounteredwhilethepolicyisexecuted:V?(x)=E?[t=0?tRt|X0=x].\n",
      "HereRt?S(?|Xt,At)istherewardreceivedattimestept,thestate,Xt,\n",
      "evolvesaccordingtoXt+1??Alsowith:ComputerandAutomationResearch\n",
      "Inst.oftheHungarianAcademyofSciencesKendeu.13-17,Budapest1111,\n",
      "Hungary.\n",
      "1\n",
      "P(?|Xt,At),whereAtissampledfromthedistributiondeterminedby\n",
      "?.WeuseQ?:X?A?RP?todenotetheaction-valuefunctionofpolicy?:\n",
      "Q?(x,a)=E?[t=0?tRt|X0=x,A0=a].Thegoalistoapolicy\n",
      "thatattainsthebestpossiblevalues,V?(x)=sup?V?(x),atallstates?\n",
      "x?X.HereV?iscalledtheoptimalvaluefunctionandapolicy??that\n",
      "V?(x)=???V(x)forallx?Xiscalledoptimal.Theoptimal\n",
      "action-valuefunctionQ(x,a)isQ(x,a)=sup?Q?(x,a).Wesaythata\n",
      "(deterministicstationary)policy?isgreedyw.r.t.anaction-valuefunctionQ\n",
      "?B(X?A),andwewrite?=??(?;Q),if,forallx?X,?(x)?argmaxa?A\n",
      "Q(x,a).Undermildtechnicalassumptions,suchagreedypolicyalwaysexists.\n",
      "Anygreedypolicyw.r.t.Q??isoptimal.For?:X?Awe?A),byR\n",
      "itsevaluationoperator,T:B(X??A)??B(X?(TQ)(x,a)=r(x,a)+?X\n",
      "Q(y,?(y))P(dy|x,a).ItisknownthatQ=TQ?.Further,ifweRletthe\n",
      "Bellmanoperator,T:B(X?A)?B(X?A),by(TQ)(x,a)=r(x,a)+\n",
      "?Xsupb?AQ(y,b)P(dy|x,a)thenQ?=TQ?.ItisknownthatV?and\n",
      "Q?areboundedbyRmax/(1??),justlikeQ?andV?.For?:X?A,the\n",
      "operatorE?:B(X?A)?B(X)isby(E?Q)(x)=Q(x,?(x)),whileE\n",
      ":B(X?A)?B(X)isby(EQ)(x)=supa?AQ(x,a).Throughoutthe\n",
      "paperF?\n",
      "f\n",
      "f:X?A?R\n",
      "g\n",
      "willdenoteasubsetofreal-valuedfunctionsoverthe\n",
      "state-actionspaceX?Aand??AXwillRbeasetofpolicies.For??M(X\n",
      ")andf:X?Rpmeasurable,welet(forp?1)kfkp,?=X|f(x)|p?(dx).\n",
      "Wesimplywritekfk?forkfk2,?.RR2Further,weextendk?k?toFbykf\n",
      "k?=AX|f|2(x,a)d?(x)d?A(a),where?RAistheuniformdistribution\n",
      "overA.Weshallusetheshorthandnotation?ftodenotetheintegralf(x)?(dx).\n",
      "WedenotethespaceofboundedmeasurablefunctionswithdomainXbyB(X\n",
      ").Further,thespaceofmeasurablefunctionsboundedby0<K<?shallbe\n",
      "denotedbyB(X;K).Weletk?k?denotethesupremumnorm.\n",
      "2\n",
      "FittedQ-iterationwithapproximatepolicymaximization\n",
      "Weassumethatwearegivenatrajectory,\n",
      "f\n",
      "(Xt,At,Rt)\n",
      "g\n",
      "1?t?N,\n",
      "generatedbysomestochasticstationarypolicy?b,calledthebehaviorpolicy:\n",
      "2\n",
      "\n",
      "At??b(?|Xt),Xt+1?P(?|Xt,At),Rt?defS(?|Xt,At),where?b\n",
      "(?|x)isadensitywith?0=inf(x,a)?X?A?b(a|x)>0.Thegenericrecipe\n",
      "forQ-iteration(FQI)[5]isQk+1=Regress(Dk(Qk)),\n",
      "(1)\n",
      "whereRegressisanappropriateregressionprocedureandDk(Qk)isa\n",
      "datasetaregressionproblemintheformofalistofdata-pointpairs:\n",
      "?h?iDk(Qk)=(Xt,At),Rt+?maxQk(Xt+1,b).1b?A\n",
      "1?t?N\n",
      "FittedQ-iterationcanbeviewedasapproximatevalueiterationappliedto\n",
      "action-valuefunctions.Toseethisnotethatvalueiterationwouldassignthe\n",
      "value(TQk)(x,a)=r(x,a)+R?maxb?AQk(y,b)P(dy|x,a)toQk+1(x,\n",
      "a)[6].Now,rememberthattheregressionfunctionforthejointlydistributed\n",
      "randomvariables(Z,Y)isbytheconditionalexpectationofYgivenZ:\n",
      "m(Z)=E[Y|Z].SinceforanyxedfunctionQ,E[Rt+?maxb?AQ(Xt+1\n",
      ",b)|Xt,At]=(TQ)(Xt,At),theregressionfunctioncorrespondingto\n",
      "thedataDk(Q)isindeedTQandhenceifFQIsolvedtheregressionproblem\n",
      "byQkexactly,itwouldsimulatevalueiterationexactly.However,this\n",
      "argumentitselfdoesnotdirectlyleadtoarigorousanalysisofFQI:SinceQk\n",
      "isobtainedbasedonthedata,itisitselfarandomfunction.Hence,afterthe\n",
      "iteration,the?target?functioninFQIbecomesrandom.Furthermore,this\n",
      "functiondependsonthesamedatathatisusedtotheregressionproblem.\n",
      "WillFQIstillworkdespitetheseissues?Toillustratethepotential\n",
      "consideradatasetwhereX1,...,XNisasequenceofindependentrandom\n",
      "variables,whicharealldistributeduniformlyatrandomin[0,1].Further,let\n",
      "MbearandomintegergreaterthanNwhichisindependentofthedataset(Xt\n",
      ")Nt=1.LetUbeanotherrandomvariable,uniformlydistributedin[0,1].\n",
      "NowtheregressionproblembyYt=fM,U(Xt),wherefM,U(x)=\n",
      "sgn(sin(2M2?(x+U))).ThenitisnothardtoseethatnomatterhowbigN\n",
      "is,noprocedurecan1\n",
      "SincethedesignercontrolsQk,wemayassumethatitiscontinuous,hence\n",
      "themaximumexists.\n",
      "2\n",
      "estimatetheregressionfunctionfM,Uwithasmallerror(inexpectation,or\n",
      "withhighprobability),eveniftheprocedurecouldexploittheknowledgeofthe\n",
      "spformoffM,U.Ontheotherhand,ifwerestrictedMtoarange\n",
      "thentheestimationproblemcouldbesolvedsuccessfully.Theexampleshows\n",
      "thatifthecomplexityoftherandomfunctionstheregressionproblem\n",
      "isuncontrolledthensuccessfulestimationmightbeimpossible.Amongstthe\n",
      "manyregressionmethodsinthispaperwehavechosentoworkwithleast-\n",
      "squaresmethods.InthiscaseEquation(1)takestheform????2NX1\n",
      "Q(Xt,At)?Rt+?maxQk(Xt+1,b)Qk+1=argmin.(2)b?AQ?F\n",
      "t=1?b(At|Xt)Wecallthismethodtheleast-squaresQ-iteration\n",
      "(LSFQI)method.Hereweintroducedtheweighting1/?b(At|Xt)since\n",
      "wedonotwanttogivemoreweighttothoseactionsthatarepreferredby\n",
      "thebehaviorpolicy.Besidesthisweighting,theonlyparameterofthemethod\n",
      "isthefunctionsetF.Thisfunctionsetshouldbechosencarefully,tokeepa\n",
      "3\n",
      "\n",
      "balancebetweentherepresentationpowerandthenumberofsamples.Asa\n",
      "spexampleforFconsiderneuralnetworkswithsomearchitecture.\n",
      "Inthiscasethefunctionsetisgeneratedbyassigningweightsinallpossible\n",
      "waystotheneuralnet.Thentheaboveminimizationbecomestheproblemof\n",
      "tuningtheweights.Anotherexampleistouselinearlyparameterizedfunction\n",
      "approximationmethodswithappropriatelyselectedbasisfunctions.Inthiscase\n",
      "theweighttuningproblemwouldbelessdemanding.Yetanotherpossibilityis\n",
      "toletFbeanappropriaterestrictionofaReproducingKernelHilbertSpace\n",
      "(e.g.,inaball).InthiscasethetrainingprocedurebecomessimilartoLS-SVM\n",
      "training[7].Asindicatedabove,theanalysisofthisalgorithmiscomplicated\n",
      "bythefactthatthenewdatasetisintermsofthepreviousiterate,\n",
      "whichisalreadyafunctionofthedataset.Anothercomplicationisthatthe\n",
      "samplesinatrajectoryareingeneralcorrelatedandthatthebiasintroducedby\n",
      "theimperfectionsoftheapproximationarchitecturemayyieldtoanexplosion\n",
      "oftheerroroftheprocedure,asdocumentedinanumberofcasesin,e.g.,\n",
      "[8].Nevertheless,atleastforactionsets,thetoolsdevelopedin[1,3,2]\n",
      "looksuitabletoshowthatunderappropriateconditionstheseproblemscanbe\n",
      "overcomeifthefunctionsetischoseninajudiciousway.However,theresultsof\n",
      "theseworkswouldbecomeessentiallyuselessinthecaseofannitenumberof\n",
      "actionssincethesepreviousboundsgrowtoywiththenumberofactions.\n",
      "Actually,webelievethatthisisnotanartifactoftheprooftechniquesofthese\n",
      "works,assuggestedbythecounterexamplethatinvolvedrandomtargets.The\n",
      "followingresultelaboratesthispointfurther:Proposition2.1.LetF?B(X?\n",
      "A).Thenevenifthepseudo-dimensionofFisthefatshatteringfunction\n",
      "of???Fmax=VQ:VQ(?)=maxQ(?,a),Q?Fa?A\n",
      "2\n",
      "canbeover(0,1/2).\n",
      "Withoutgoingintofurtherdetails,letusjustnotethattheofthe\n",
      "fat-shatteringfunctionisatandnecessaryconditionforlearnabilityand\n",
      "theofthefat-shatteringfunctionisimpliedbytheofthe\n",
      "pseudo-dimension[9].Theabovepropositionthusshowsthatwithoutimposing\n",
      "furtherspecialconditionsonF,thelearningproblemmaybecomeinfeasible.\n",
      "Onepossibilityisofcoursetodiscretizetheactionspace,e.g.,byusingauniform\n",
      "grid.However,iftheactionspacehasareallyhighdimensionality,thisapproach\n",
      "becomesunfeasible(evenenumerating2dApointscouldbeimpossiblewhendA\n",
      "islarge).Thereforewepreferalternatesolutions.Anotherpossibilityistomake\n",
      "thefunctionsinF,e.g.,uniformlyLipschitzintheirstatecoordinates.?Then\n",
      "thesamepropertywillholdforfunctionsinFmaxandhencebyaclassicalresult\n",
      "wecanboundthecapacityofthisset(cf.pp.353?357of[10]).Onepotential\n",
      "problemwiththisapproachisthatthiswayitmightbetogeta\n",
      "controlofthecapacityoftheresultingset.2Theproofofthisandtheother\n",
      "resultsaregivenintheappendix,availableintheextendedversionofthispaper,\n",
      "downloadablefromhttp://hal.inria.fr/inria-00185311/en/.\n",
      "3\n",
      "IntheapproachexploredherewemodifytheQ-iterationalgorithm\n",
      "byintroducingapolicyset?andasearchoverthissetforanapproximately\n",
      "4\n",
      "\n",
      "greedypolicyinasensethatwillbemadepreciseinaminute.Ouralgorithm\n",
      "thushasfourparameters:F,?,K,Q0.HereFisasbefore,?isauser-chosen\n",
      "setofpolicies(mappingsfromXtoA),KisthenumberofiterationsandQ0is\n",
      "aninitialvaluefunction(atypicalchoiceisQ0?0).Thealgorithmcomputes\n",
      "asequenceofiterates(Qk,??k),k=0,...,K,bythefollowing\n",
      "equations:??0Qk+1??k+1\n",
      "=\n",
      "argmax???\n",
      "=\n",
      "argmin\n",
      "NX\n",
      "argmax???\n",
      "Q0(Xt,?(Xt)),\n",
      "t=1\n",
      "Q?F\n",
      "=\n",
      "NX\n",
      "t=1NX\n",
      "????21Q(Xt,At)?Rt+?Qk(Xt+1,??k(Xt+1)),?b(At|Xt)\n",
      "(3)\n",
      "Qk+1(Xt,?(Xt)).\n",
      "(4)\n",
      "t=1\n",
      "Thus,(3)issimilarto(2),while(4)thepolicysearchproblem.The\n",
      "policysearchwillgenerallybesolvedbyagradientprocedureorsomeother\n",
      "appropriatemethod.Thecostofthisstepwillbeprimarilydeterminedbyhow\n",
      "well-behavingtheiteratesQk+1areintheiractionarguments.Forexample,if\n",
      "theywerequadraticandif?waslinearthentheproblemwouldbeaquadratic\n",
      "optimizationproblem.However,exceptforspecialcases3theactionvaluefunc-\n",
      "tionswillbemorecomplicated,inwhichcasethisstepcanbeexpensive.Still,\n",
      "thiscostcouldbesimilartothatofsearchingforthemaximizingactionsfor\n",
      "eacht=1,...,Niftheapproximatelymaximizingactionsaresimilaracross\n",
      "similarstates.Thisalgorithm,whichwecouldalsocallaactor-critic\n",
      "algorithm,willbeshowntoovercometheabovementionedcomplexitycontrol\n",
      "problemprovidedthatthecomplexityof?iscontrolledappropriately.Indeed,\n",
      "inthiscasethesetofpossibleregressionproblemsisdeterminedbythesetF??\n",
      "=\n",
      "f\n",
      "V:V(?)=Q(?,?(?)),Q?F,???\n",
      "g\n",
      ",andtheproofwillrelyon\n",
      "controllingthecomplexityofF??byselectingFand?appropriately.\n",
      "33.1\n",
      "ThemaintheoreticalresultOutlineoftheanalysis\n",
      "Inordertogainsomeinsightintothebehaviorofthealgorithm,weprovide\n",
      "abriefsummaryofitserroranalysis.Themainresultwillbepresentedsub-\n",
      "sequently.Forf,Q?Fandapolicy?,wethetthTD-errorasfollows:\n",
      "dt(f;Q,?)=Rt+?Q(Xt+1,?(Xt+1))?f(Xt,At).Further,we\n",
      "theempiricallossfunctionbyNXd2t(f;Q,?)?N(f;Q,?)=1,LNt=1\n",
      "?(A)?b(At|Xt)\n",
      "5\n",
      "\n",
      "wherethenormalizationwith?(A)isintroducedformathematicalconve-\n",
      "nience.Then(3)canbe?N(f;Qk,?writtencompactlyasQk+1=argminf\n",
      "?FL?k).?N(f;Q,?)isanThealgorithmcanthenbemotivatedbythe\n",
      "observationthatforanyf,Q,and?,Lunbiasedestimateofdef2L(f;Q,?)=kf\n",
      "?T?Qk?+L?(Q,?),(5)wherethetermistheerrorweareinterestedin\n",
      "andthesecondtermcapturesthevarianceoftherandomsamples:ZL?(Q,?)\n",
      "=E[Var[R1+?Q(X2,?(X2))|X1,A1=a]]d?A(a).A3Linearquadratic\n",
      "regulationissuchanicecase.Itisinterestingtonotethatinthisspecialcase\n",
      "theobviouschoicesforFand?yieldzeroerrorinthelimit,ascanbeproven\n",
      "basedonthemainresultofthispaper.\n",
      "4\n",
      "hi?N(f;Q,?)=L(f;Q,?).ThisresultisstatedformallybyELSincethe\n",
      "variancetermin(5)isindependentoff,argminf?FL(f;Q,?)=2?argminf\n",
      "?Fkf?TQk?.Thus,if??kweregreedyw.r.t.Qkthenargminf?FL(f;Qk,?\n",
      "?k)=2argminf?Fkf?TQkk?.Hencewecanstillthinkoftheprocedureas\n",
      "approximatevalueiterationoverthespaceofaction-valuefunctions,projecting\n",
      "TQkusingempiricalriskminimizationonthespaceFw.r.t.k?k?distances\n",
      "inanapproximatemanner.Since??kisonlyapproximatelygreedy,wewill\n",
      "havetodealwithboththeerrorcomingfromtheapproximateprojectionand\n",
      "theerrorcomingfromthechoiceof??k.Tomakethisclear,wewritethe\n",
      "iterationintheformQk+1=T??kQk+?0k=TQk+?0k+(T??kQk?\n",
      "TQk)=TQk+?k,def\n",
      "where?0kistheerrorcommittedwhilecomputingT??kQk,?00k=T\n",
      "??kQk?TQkistheerrorcommittedbecausethegreedypolicyiscomputed\n",
      "approximatelyand?k=?0k+?00kisthetotalerrorofstepk.Hence,inorder\n",
      "toshowthattheprocedureiswellbehaved,oneneedstoshowthatbotherrors\n",
      "arecontrolledandthatwhentheerrorsarepropagatedthroughtheseequations,\n",
      "theresultingerrorstayscontrolled,too.Sinceweareultimatelyinterestedin\n",
      "theperformanceofthepolicyobtained,wewillalsoneedtoshowthatsmall\n",
      "action-valueapproximationerrorsyieldsmallperformancelosses.Forthesewe\n",
      "needanumberofassumptionsthatconcerneitherthetrainingdata,theMDP,\n",
      "orthefunctionsetsusedforlearning.3.2\n",
      "Assumptions\n",
      "3.2.1\n",
      "Assumptionsonthetrainingdata\n",
      "Weshallassumethatthedataisrich,isinasteadystate,andisfast-\n",
      "mixing,where,informally,mixingmeansthatfuturedependsweaklyonthe\n",
      "past.AssumptionA2(SamplePathProperties)Assumethat\n",
      "f\n",
      "(Xt,At,Rt\n",
      ")\n",
      "g\n",
      "t=1,...,Nisthesamplepathof?b,astochasticstationarypolicy.Further,\n",
      "assumethat\n",
      "f\n",
      "Xt\n",
      "g\n",
      "isstrictlystationary(Xt???M(X))andexponentially\n",
      "?-mixingwiththeactualrategivenbytheparameters(?,b,?).4Wefurther\n",
      "assumethatthesamplingpolicy?b?0=inf(x,a)?X?A?b(a|x)>\n",
      "0.The?-mixingpropertywillbeusedtoestablishtailinequalitiesforcertain\n",
      "empiricalprocesses.5Notethatthemixingcotsdonotneedtobeknown.\n",
      "Inthecasewhennomixingconditionislearningmightbeimpossible.\n",
      "ToseethisjustconsiderthecasewhenX1=X2=...=XN.Thus,inthis\n",
      "6\n",
      "\n",
      "casethelearnerhasmanycopiesofthesamerandomvariableandsuccessful\n",
      "generalizationisthusimpossible.Webelievethattheassumptionthatthe\n",
      "processisinasteadystateisnotessentialforourresult,aswhentheprocess\n",
      "reachesitssteadystatequicklythen(atthepriceofamoreinvolvedproof)the\n",
      "resultwouldstillhold.3.2.2\n",
      "AssumptionsontheMDP\n",
      "Inordertopreventtheuncontrolledgrowthoftheerrorsastheyareprop-\n",
      "agatedthroughtheupdates,weshallneedsomeassumptionsontheMDP.A\n",
      "convenientassumptionisthefollowingone[11]:AssumptionA3(Uniformly\n",
      "stochastictransitions)Forallx?Xanda?A,assumethatP(?|x,a)is\n",
      "absolutelycontinuousw.r.t.?andthederivativeofPw.r.t.?isbounded??\n",
      "Radon-Nikodymdef?dP(?|x,a)?uniformlywithboundC?:C?=supx?X\n",
      ",a?A?d??<+?.?\n",
      "Notethatbytheofmeasuretiation,AssumptionA3means\n",
      "thatP(?|x,a)?C??(?).Thisassumptionessentiallyrequiresthetransitions\n",
      "tobenoisy.Wewillalsoprove(weaker)resultsunderthefollowing,weaker\n",
      "assumption:4\n",
      "Fortheof?-mixing,seee.g.[2].Wesay?empiricalprocess?and\n",
      "?empiricalmeasure?,butnotethatinthisworkthesearebasedondependent\n",
      "(mixing)samples.5\n",
      "5\n",
      "AssumptionA4(Discounted-averageconcentrabilityoffuture-statedistribu-\n",
      "tions)Given?,?,m?1andanarbitrarysequenceofstationarypolicies\n",
      "f\n",
      "?m\n",
      "g\n",
      "m?1,assumethatthefuturedefstatedistribution?P?1P?2...?P?mis\n",
      "absolutelycontinuousw.r.t.?.Assumethatc(m)=??1?2?m?Pdef?sup?1\n",
      ",...,?m?d(?PPd?...P)?m?1m?m?1c(m)<+?.WeshallcallC?,?\n",
      "=???PPmax(1??)2m?1m?m?1c(m),(1??)m?1?mc(m)the\n",
      "discounted-averageconcentrabilitycotofthefuture-statedistributions.\n",
      "Thenumberc(m)measureshowmuch?cangetinmstepsascom-\n",
      "paredtothereferencedistribution?.Hence,ingeneralweexpectc(m)togrow\n",
      "withm.Infact,theconditionthatC?,?isisagrowthratecondition\n",
      "onc(m).Thankstodiscounting,C?,?isforareasonablylargeclassof\n",
      "systems(seethediscussionin[11]).Arelatedassumptionisneededintheerror\n",
      "analysisoftheapproximategreedystepofthealgorithm:AssumptionA5(The\n",
      "randompolicy?makesnopeak-states?)Considerthedistribution?=(??\n",
      "?A)Pwhichisthedistributionofastatethatresultsfromsamplinganinitial\n",
      "stateaccordingto?andthenexecutinganactionwhichisselecteduniformlyat\n",
      "random.6Then??=kd?/d?k?<+?.NotethatunderAssumptionA3wehave\n",
      "???C?.This(verymild)assumptionmeansthatafteronestep,startingfrom\n",
      "?andexecutingthisrandompolicy,theprobabilityofthenextstatebeingina\n",
      "setisupperboundedby??-timestheprobabilityofthestartingstatebeingin\n",
      "thesameset.def\n",
      "Besides,weassumethatAhasthefollowingregularityproperty:LetPy(a,\n",
      "h,?)=??(a0,v)?RdA+1:ka?a0k1??,0?v/h?1?ka?a0k1\n",
      "/?denotethepyramidwithhight?def?handbasegivenbythe`1-ballB(a,\n",
      "?)=a0?RdA:ka?a0k1??centeredata.AssumptionA6(Regularityof\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theactionspace)Weassumethatthereexists?>0,suchthatforalla?A,for\n",
      "all?>0,???(Py(a,1,?)?(A?R))?(A)?min?,.?(Py(a,1,?))?(B(a,\n",
      "?))Forexample,ifAisan`1-ballitself,thenthisassumptionwillbe\n",
      "with?=2?dA.WithoutassuminganysmoothnessoftheMDP,learningin\n",
      "MDPslookshard(see,e.g.,[12,13]).Hereweemploythefollowingextra\n",
      "condition:AssumptionA7(LipschitznessoftheMDPintheactions)Assume\n",
      "thatthetransitionprobabilitiesandrewardsareLipschitzw.r.t.theiraction\n",
      "variable,i.e.,thereexistsLP,Lr>0suchthatforall(x,a,a0)?X?A?A\n",
      "andmeasurablesetBofX,|P(B|x,a)?P(B|x,a0)|?LPka?a0k1,\n",
      "|r(x,a)?r(x,a0)|?Lrka?a0k1.\n",
      "NotethatpreviouslyLipschitznessw.r.t.thestatevariableswasused,e.g.,\n",
      "in[11]toconstructconsistentplanningalgorithms.3.2.3\n",
      "Assumptionsonthefunctionsetsusedbythealgorithm\n",
      "Theseassumptionsarelessdemandingsincetheyareunderthecontrolof\n",
      "theuserofthealgorithm.However,thechoiceofthesefunctionsetswillgreatly\n",
      "theperformanceofthealgorithm,asweshallseeitfromthebounds.\n",
      "TheassumptionconcernstheclassF:AssumptionA8(Lipschitznessof\n",
      "candidateaction-valuefunctions)AssumeF?B(X?A)andthatanyelements\n",
      "ofFisuniformlyLipschitzinitsaction-argumentinthesensethat|Q(x,a)?\n",
      "Q(x,a0)|?LAka?a0k1holdsforanyx?X,a,a0?A,andQ?F.6\n",
      "Rememberthat?AdenotestheuniformdistributionovertheactionsetA.\n",
      "6\n",
      "Weshallalsoneedtocontrolthecapacityofourfunctionsets.Weassume\n",
      "thatthereaderisfamiliarwiththeconceptofVC-dimension.7Hereweuse\n",
      "thepseudo-dimensionoffunctionsetsthatbuildsupontheconceptofVC-\n",
      "dimension:3.1(Pseudo-dimension).Thepseudo-dimensionVF+of\n",
      "FisastheVCdimensionofthesubgraphsoffunctionsinF(henceitis\n",
      "alsocalledtheVC-subgraphdimensionofF).SinceAismultidimensional,we\n",
      "V?+tobethesumofthepseudo-dimensionsofthecoordinateprojection\n",
      "spaces,?kof?:V\n",
      "?+\n",
      "=\n",
      "dAX\n",
      "V?+,\n",
      "k=1\n",
      "k\n",
      "?k=\n",
      "f\n",
      "?k:X?R:?=(?1,...,?k,...,?dA)??\n",
      "g\n",
      ".\n",
      "Nowwearereadytostateourassumptionsonourfunctionsets:Assumption\n",
      "A9(Capacityofthefunctionandpolicysets)AssumethatF?B(X?A;Qmax\n",
      ")forQmax>0andVF+<+?.Also,A?[?A?,A?]dAandV?+<+?.Besides\n",
      "theircapacity,oneshallalsocontroltheapproximationpowerofthefunction\n",
      "setsinvolved.Letusconsiderthepolicyset?.Introducee?(F,?)=sup\n",
      "inf?(EQ?E?Q).Q?F???\n",
      "Notethatinf????(EQ?E?Q)measuresthequalityofapproximating\n",
      "?EQby?E?Q.Hence,e?(F,?)measurestheworst-caseapproximationerror\n",
      "of?EQasQischangedwithinF.Thiscanbemadesmallbychoosing?large.\n",
      "8\n",
      "\n",
      "Anotherrelatedquantityistheone-stepBellman-errorofFw.r.t.?.Thisis\n",
      "asfollows:Forapolicy?,theone-stepBellman-errorofFw.r.t.\n",
      "T?isasE1(F;?)=supinfkQ0?T?Qk?.0Q?FQ?F\n",
      "Takingagainapessimisticapproach,theone-stepBellman-errorofFis\n",
      "asE1(F,?)=supE1(F;?).???\n",
      "TypicallybyincreasingF,E1(F,?)canbemadesmaller(thisisdiscussed\n",
      "atsomelengthin[3]).However,italsoholdsforboth?andFthatmaking\n",
      "thembiggerwillincreasetheircapacity(pseudo-dimensions)whichleadstoan\n",
      "increaseoftheestimationerrors.Hence,Fand?mustbeselectedtobalance\n",
      "theapproximationandestimationerrors,justlikeinsupervisedlearning.3.3\n",
      "Themainresult\n",
      "Theorem3.2.Let?Kbeagreedypolicyw.r.t.QK,i.e.?K(x)?argmaxa?A\n",
      "QK(x,a).ThenunderAssumptionsA1,A2,andA5?A9,forall?>0wehave\n",
      "withprobabilityatleast1??:givenAssumptionA3(respectivelyA4),kV??\n",
      "V?Kk?(resp.kV??V?Kk1,?),isboundedby????d1+1?+1??A?\n",
      "?4?(logN+log(K/?))K?+?,C?E1(F,?)+e?(F,?)+1/4??N??\n",
      "AwhereCdependsondA,VF+,(V?+)dk=1,?,?,b,?,C?(resp.C?,?),\n",
      "??,LA,LP,Lr,?,?(A),?0,k\n",
      "?+1\n",
      "?max,andA?.Inparticular,CscaleswithV4?(dA+1),whereV=\n",
      "2VF++V?+Qmax,Rmax,Rplaystheroleofthe?combinede?\n",
      "dimensionofFand?.7ReadersnotfamiliarwithVC-dimensionaresuggested\n",
      "toconsultabook,suchastheonebyAnthonyandBartlett[14].\n",
      "7\n",
      "4\n",
      "Discussion\n",
      "Wehavepresentedwhatwebelieveistherstboundsforcontinuous-\n",
      "stateandactionspaceRLthatusesvaluefunctions.Further,thisisthe\n",
      "analysisofQ-iteration,analgorithmthathasprovedtobeusefulina\n",
      "numberofcases,evenwhenusedwithnon-averagersforwhichnopreviousthe-\n",
      "oreticalanalysisexisted(e.g.,[15,16]).Infact,ourmainmotivationwasto\n",
      "showthatthereisasystematicwayofmakingthesealgorithmsworkandto\n",
      "pointatpossibleproblemsourcesthesametime.Wediscussedwhyitcanbe\n",
      "tomakethesealgorithmsworkinpractice.Wesuggestedthateitherthe\n",
      "setofaction-valuecandidateshastobecarefullycontrolled(e.g.,assuminguni-\n",
      "formLipschitznessw.r.t.thestatevariables),orapolicysearchstepisneeded,\n",
      "justlikeinactorcriticalgorithms.Theboundinthispaperissimilarinmany\n",
      "respectstoapreviousboundofaBellman-residualminimizationalgorithm[2].\n",
      "Itlooksthatthetechniquesdevelopedherecanbeusedtoobtainresultsfor\n",
      "thatalgorithmwhenitisappliedtocontinuousactionspaces.Finally,although\n",
      "wehavenotexploredthemhere,consistencyresultsforFQIcanbeobtained\n",
      "fromourresultsusingstandardmethods,likethemethodsofsieves.Webelieve\n",
      "thatthemethodsdevelopedherewilleventuallyleadtoalgorithmswherethe\n",
      "functionapproximationmethodsarechosenbasedonthedata(similartoadap-\n",
      "tiveregressionmethods)soastooptimizeperformance,whichinouropinionis\n",
      "oneofthebiggestopenquestionsinRL.Currentlyweareexploringthispos-\n",
      "9\n",
      "\n",
      "sibility.AcknowledgmentsAndr?asAntoswouldliketoacknowledgesupport\n",
      "forthisprojectfromtheHungarianAcademyofSciences(BolyaiFellowship).\n",
      "CsabaSzepesv?arigreatlyacknowledgesthesupportreceivedfromtheAlberta\n",
      "IngenuityFund,NSERC,theComputerandAutomationResearchInstituteof\n",
      "theHungarianAcademyofSciences.\n",
      "2References\n",
      "[1]A.Antos,Cs.Szepesv?ari,andR.Munos.Learningnear-optimalpolicies\n",
      "withBellman-residualminimizationbasedpolicyiterationandasingle\n",
      "samplepath.InCOLT-19,pages574?588,2006.[2]A.Antos,Cs.Szepesv?ari,\n",
      "andR.Munos.Learningnear-optimalpolicieswithBellman-residualminimiza-\n",
      "tionbasedpolicyiterationandasinglesamplepath.MachineLearning,\n",
      "2007.(accepted).[3]A.Antos,Cs.Szepesv?ari,andR.Munos.Value-iteration\n",
      "basedpolicyiteration:learningwithasingletrajectory.InIEEEADPRL,\n",
      "pages330?337,2007.[4]D.P.BertsekasandS.E.Shreve.StochasticOptimal\n",
      "Control(TheDiscreteTimeCase).AcademicPress,NewYork,1978.[5]D.\n",
      "Ernst,P.Geurts,andL.Wehenkel.Tree-basedbatchmodereinforcementlearn-\n",
      "ing.JournalofMachineLearningResearch,6:503?556,2005.[6]R.S.Sutton\n",
      "andA.G.Barto.ReinforcementLearning:AnIntroduction.BradfordBook.\n",
      "MITPress,1998.[7]N.CristianiniandJ.Shawe-Taylor.Anintroduction\n",
      "tosupportvectormachines(andotherkernel-basedlearningmethods).Cam-\n",
      "bridgeUniversityPress,2000.[8]J.A.BoyanandA.W.Moore.Generalization\n",
      "inreinforcementlearning:Safelyapproximatingthevaluefunction.InNIPS-\n",
      "7,pages369?376,1995.[9]P.L.Bartlett,P.M.Long,andR.C.Williamson.\n",
      "Fat-shatteringandthelearnabilityofreal-valuedfunctions.JournalofCom-\n",
      "puterandSystemSciences,52:434?452,1996.[10]A.N.KolmogorovandV.M.\n",
      "Tihomirov.?-entropyand?-capacityofsetsinfunctionalspace.American\n",
      "MathematicalSocietyTranslations,17(2):277?364,1961.[11]R.Munosand\n",
      "Cs.Szepesv?ari.Finitetimeboundsforsamplingbasedvalueiteration.\n",
      "Technicalreport,ComputerandAutomationResearchInstituteoftheHungar-\n",
      "ianAcademyofSciences,Kendeu.13-17,Budapest1111,Hungary,2006.[12]\n",
      "A.Y.NgandM.Jordan.PEGASUS:ApolicysearchmethodforlargeMDPs\n",
      "andPOMDPs.InProceedingsofthe16thConferenceinUncertaintyin\n",
      "cialIntelligence,pages406?415,2000.[13]P.L.BartlettandA.Tewari.Sample\n",
      "complexityofpolicysearchwithknowndynamics.InNIPS-19.MITPress,\n",
      "2007.[14]M.AnthonyandP.L.Bartlett.NeuralNetworkLearning:Theoreti-\n",
      "calFoundations.CambridgeUniversityPress,1999.[15]M.Riedmiller.Neural\n",
      "Qiteration?experienceswithadatatneuralreinforcement\n",
      "learningmethod.In16thEuropeanConferenceonMachineLearning,pages\n",
      "317?328,2005.[16]S.KalyanakrishnanandP.Stone.Batchreinforcement\n",
      "learninginacomplexdomain.InAAMAS-07,2007.\n",
      "8\n",
      "10\n",
      "\n",
      "PP7054.pdf\n",
      "PP7054.pdf 16\n",
      "QueryComplexityofClusteringwithSide\n",
      "Information\n",
      "Authoredby:\n",
      "AryaMazumdar\n",
      "BarnaSaha\n",
      "Abstract\n",
      "Suppose,wearegivenasetof$n$elementstobeclusteredinto$k$\n",
      "(unknown)clusters,andanoracle/expertlabelerthatcaninteractively\n",
      "answerpair-wisequeriesoftheform,\\dotwoelements$u$and$v$be-\n",
      "longtothesamecluster?\".Thegoalistorecovertheoptimumclustering\n",
      "byaskingtheminimumnumberofqueries.Inthispaper,weprovidea\n",
      "rigoroustheoreticalstudyofthisbasicproblemofquerycomplexityofin-\n",
      "teractiveclustering,andgivestronginformationtheoreticlowerbounds,\n",
      "aswellasnearlymatchingupperbounds.Mostclusteringproblemscome\n",
      "withasimilaritymatrix,whichisusedbyanautomatedprocesstocluster\n",
      "similarpointstogether.Toimproveaccuracyofclustering,afruitfulap-\n",
      "proachinrecentyearshasbeentoaskadomainexpertorcrowdtoobtain\n",
      "labeleddatainteractively.Manyheuristicshavebeenproposed,andallof\n",
      "theseuseasimilarityfunctiontocomeupwithaqueryingstrategy.Even\n",
      "so,thereisalacksystematictheoreticalstudy.Ourmaincontributionin\n",
      "thispaperistoshowthedramaticpowerofsideinformationakasimilarity\n",
      "matrixonreducingthequerycomplexityofclustering.Asimilarityma-\n",
      "trixrepresentsnoisypair-wiserelationshipssuchasonecomputedbysome\n",
      "functiononattributesoftheelements.Anaturalnoisymodeliswhere\n",
      "similarityvaluesaredrawnindependentlyfromsomearbitraryprobabil-\n",
      "itydistribution$f\n",
      "+$whentheunderlyingpairofelementsbelongto\n",
      "thesamecluster,andfromsome$f\n",
      "-$otherwise.Weshowthatgiven\n",
      "suchasimilaritymatrix,thequerycomplexityreducesdrasticallyfrom\n",
      "$Theta(nk)$(nosimilaritymatrix)to$O(frac\n",
      "f\n",
      "k2log\n",
      "f\n",
      "n\n",
      "ggf\n",
      "cH2(f\n",
      "+|f\n",
      "-\n",
      ")\n",
      "g\n",
      ")$where$cH2$denotesthesquaredHellingerdivergence.Moreover,\n",
      "thisisalsoinformation-theoreticoptimalwithinan$O(log\n",
      "f\n",
      "n\n",
      "g\n",
      ")$factor.\n",
      "Ouralgorithmsareallt,andparameterfree,i.e.,theyworkwith-\n",
      "outanyknowledgeof$k,f\n",
      "+$and$f\n",
      "-$,andonlydependlogarithmically\n",
      "with$n$.\n",
      "1\n",
      "\n",
      "1PaperBody\n",
      "Suppose,wearegivenasetofnelementstobeclusteredintok(unknown)clus-\n",
      "ters,andanoracle/expertlabelerthatcaninteractivelyanswerpair-wisequeries\n",
      "oftheform,?dotwoelementsuandvbelongtothesamecluster??.Thegoal\n",
      "istorecovertheoptimumclusteringbyaskingtheminimumnumberofqueries.\n",
      "Inthispaper,weprovidearigoroustheoreticalstudyofthisbasicproblemof\n",
      "querycomplexityofinteractiveclustering,andgivestronginformationtheo-\n",
      "reticlowerbounds,aswellasnearlymatchingupperbounds.Mostclustering\n",
      "problemscomewithasimilaritymatrix,whichisusedbyanautomatedpro-\n",
      "cesstoclustersimilarpointstogether.However,obtaininganidealsimilarity\n",
      "functionisextremelychallengingduetoambiguityindatarepresentation,poor\n",
      "dataqualityetc.,andthisisoneoftheprimaryreasonsthatmakesclustering\n",
      "hard.Toimproveaccuracyofclustering,afruitfulapproachinrecentyears\n",
      "hasbeentoaskadomainexpertorcrowdtoobtainlabeleddatainteractively.\n",
      "Manyheuristicshavebeenproposed,andalloftheseuseasimilarityfunctionto\n",
      "comeupwithaqueryingstrategy.Evenso,thereisalacksystematictheoret-\n",
      "icalstudy.Ourmaincontributioninthispaperistoshowthedramaticpower\n",
      "ofsideinformationakasimilaritymatrixonreducingthequerycomplexityof\n",
      "clustering.Asimilaritymatrixrepresentsnoisypair-wiserelationshipssuchas\n",
      "onecomputedbysomefunctiononattributesoftheelements.Anaturalnoisy\n",
      "modeliswheresimilarityvaluesaredrawnindependentlyfromsomearbitrary\n",
      "probabilitydistributionf+whentheunderlyingpairofelementsbelongtothe\n",
      "samecluster,andfromsomef?otherwise.Weshowthatgivensuchasimi-\n",
      "laritymatrix,thequerycomplexityreducesdrasticallyfrom?(nk)2n)where\n",
      "H2denotesthesquaredHellinger(nosimilaritymatrix)toO(+kf?)\n",
      "divergence.Moreover,thisisalsoinformation-theoreticoptimalwithinanO(log\n",
      "n)factor.Ouralgorithmsareallt,andparameterfree,i.e.,theywork\n",
      "withoutanyknowledgeofk,f+andf?,andonlydependlogarithmicallywith\n",
      "n.Ourlowerboundscouldbeofindependentinterest,andprovideageneral\n",
      "frameworkforprovinglowerboundsforproblemsintheinteractive\n",
      "setting.Alongtheway,ourworkalsorevealsintriguingconnectiontopopular\n",
      "communitydetectionmodelssuchasthestochasticblockmodelandopensup\n",
      "manyavenuesforinterestingfutureresearch.\n",
      "1\n",
      "Introduction\n",
      "Clusteringisoneofthemostfundamentalandpopularmethodsfordata\n",
      "Inthispaperweprovidearigoroustheoreticalstudyofclustering\n",
      "withthehelpofanoracle,amodelthatsawarecentsurgeofpopularheuristic\n",
      "algorithms.31stConferenceonNeuralInformationProcessingSystems(NIPS\n",
      "2017),LongBeach,CA,USA.\n",
      "Supposewearegivenasetofnpoints,thatneedtobeclusteredintok\n",
      "clusterswherekisunknowntous.Supposethereisanoraclethateitherknows\n",
      "thetrueunderlyingclusteringorcancomputethebestclusteringundersome\n",
      "optimizationconstraints.Weareallowedtoquerytheoraclewhetheranytwo\n",
      "pointsbelongtothesameclusterornot.Howmanysuchqueriesareneeded\n",
      "2\n",
      "\n",
      "tobeaskedatminimumtoperformtheclusteringexactly?Themotivationto\n",
      "thisproblemliesattheheartofmodernmachinelearningapplicationswhere\n",
      "thegoalistofacilitatemoreaccuratelearningfromlessdatabyinteractively\n",
      "askingforlabeleddata,e.g.,activelearningandcrowdsourcing.Sp,au-\n",
      "tomatedclusteringalgorithmsthatrelyjustonasimilaritymatrixoftenreturn\n",
      "inaccurateresults.Whereas,obtainingfewlabeleddataadaptivelycanhelpin\n",
      "tlyimprovingitsaccuracy.Coupledwiththisobservation,clustering\n",
      "withanoraclehasgeneratedtremendousinterestinthelastfewyearswith\n",
      "increasingnumberofheuristicsdevelopedforthispurpose[22,40,13,42,43,\n",
      "18,39,12,21,29].Thenumberofqueriesisanaturalmeasureofncy?\n",
      "here,asitdirectlyrelatestotheamountoflabeleddataorthecostofusing\n",
      "crowdworkers?however,theoreticalguaranteesonquerycomplexityislacking\n",
      "intheliterature.Onthetheoreticalside,querycomplexityorthedecisiontree\n",
      "complexityisaclassicalmodelofcomputationthathasbeenextensivelystudied\n",
      "fortproblems[16,4,8].Fortheclusteringproblem,onecanobtainan\n",
      "upperboundofO(nk)onthequerycomplexityeasilyanditisachievableeven\n",
      "whenkisunknown[40,13]:toclusteranelementatanystageofthealgorithm,\n",
      "askonequeryperexistingclusterwiththiselement(thisistduetotran-\n",
      "sitivity),andstartanewclusterifallqueriesarenegative.Itturnsoutthat\n",
      "?(nk)isalsoalowerbound,evenforrandomizedalgorithms(see,e.g.,[13]).In\n",
      "contrast,theheuristicsdevelopedinpracticeoftenasktlylessqueries\n",
      "thannk.Whatcouldbeapossiblereasonforthisdeviationbetweenthetheory\n",
      "andpractice?Beforedelvingintothisquestion,letuslookatamotivatingap-\n",
      "plicationthatdrivesthiswork.AMotivatingApplication:EntityResolution.\n",
      "Entityresolution(ER,alsoknownasrecordlinkage)isafundamentalproblem\n",
      "indataminingandhasbeenstudiedsince1969[17].ThegoalofERisto\n",
      "identifyandlink/grouprentmanifestationsofthesamerealworldobject,\n",
      "e.g.,twaysofaddressing(names,emailaddress,Facebookaccounts)\n",
      "thesameperson,Webpageswithtdescriptionsofthesamebusiness,\n",
      "tphotosofthesameobjectetc.(seetheexcellentsurveybyGetoorand\n",
      "Machanavajjhala[20]).However,lackofanidealsimilarityfunctiontocom-\n",
      "pareobjectsmakesERanextremelychallengingtask.Forexample,DBLP,the\n",
      "popularcomputersciencebibliographydatasetiswithERerrors[30].It\n",
      "iscommonforDBLPtomergepublicationrecordsoftpersonsifthey\n",
      "sharesimilarattributes(e.g.samename),orsplitthepublicationrecordofa\n",
      "singlepersonduetoslightdierenceinrepresentation(e.g.MarcusWeldonvs\n",
      "MarcusK.Weldon).Inrecentyears,apopulartrendtoimproveERaccuracy\n",
      "hasbeentoincorporatehumanwisdom.Theworksof[42,43,40](andmany\n",
      "subsequentworks)useacomputer-generatedsimilaritymatrixtocomeupwith\n",
      "acollectionofpair-wisequestionsthatareaskedinteractivelytoacrowd.The\n",
      "goalistominimizethenumberofqueriestothecrowdwhilemaximizingthe\n",
      "accuracy.Thisisanalogoustoourinteractiveclusteringframework.Butin-\n",
      "triguingly,asshownbyextensiveexperimentsonvariousrealdatasets,these\n",
      "heuristicsusefarlessqueriesthannk[42,43,40]?barringthe?(nk)theoretical\n",
      "lowerbound.Onaclosescrutiny,wethatalloftheseheuristicsusesome\n",
      "computergeneratedsimilaritymatrixtoguideinselectingthequeries.Could\n",
      "3\n",
      "\n",
      "thesesimilaritymatrices,akasideinformation,bethereasonbehindthedevi-\n",
      "ationandtreductioninquerycomplexity?Letuscallthisclustering\n",
      "usingsideinformation,wheretheclusteringalgorithmhasaccesstoasimilarity\n",
      "matrix.Thiscanbegenerateddirectlyfromtherawdata(e.g.,byapplying\n",
      "Jaccardsimilarityontheattributes),orusingacrudewhichistrained\n",
      "onaverysmallsetoflabelledsamples.Letusassumethefollowinggenerative\n",
      "modelofsideinformation:anoisyweightedupper-triangularsimilaritymatrix\n",
      "W=\n",
      "f\n",
      "wi,j\n",
      "g\n",
      ",1?i<j?n,wherewi,jisdrawnfromaprobabilitydistribution\n",
      "f+ifi,j,i6=j,belongtothesamecluster,andelsefromf?.However,the\n",
      "algorithmdesignerisgivenonlythesimilaritymatrixwithoutanyinformation\n",
      "onf+andf?.Inthiswork,oneofourmajorcontributionsistoshowthe\n",
      "separationinquerycomplexityofclusteringwithandwithoutsuchsideinfor-\n",
      "mation.Indeedtherecentworksof[18,33]analyzepopularheuristicalgorithms\n",
      "of[40,43]wheretheprobabilitydistributionsareobtainedfromrealdatasets\n",
      "whichshowthattheseheuristicsaretlysuboptimalevenforverysim-\n",
      "pledistributions.Tothebestofourknowledge,beforethiswork,thereexisted\n",
      "noalgorithmthatworksforarbitraryunknowndistributionsf+andf?with\n",
      "near-optimalperformances.Wedevelopagenericframeworkforprovinginfor-\n",
      "mationtheoreticlowerboundsforinteractiveclusteringusingsideinformation,\n",
      "anddesigntalgorithmsforarbitrary\n",
      "2\n",
      "f+andf?thatnearlymatchthelowerbound.Moreover,ouralgorithmsare\n",
      "parameterfree,thatistheyworkwithoutanyknowledgeoff+,f?ork.Con-\n",
      "nectiontopopularcommunitydetectionmodels.Themodelofsideinformation\n",
      "consideredinthispaperisadirectandtgeneralizationoftheplanted\n",
      "partitionmodel,alsoknownasthestochasticblockmodel(SBM)[28,15,14,2,\n",
      "1,25,24,11,36].Thestochasticblockmodelisanextremelywell-studiedmodel\n",
      "ofrandomgraphswhichisusedformodelingcommunitiesinrealworld,andisa\n",
      "specialcaseofasimilaritymatrixweconsider.InSBM,twoverticeswithinthe\n",
      "samecommunityshareanedgewithprobabilityp,andtwoverticesint\n",
      "communitiesshareanedgewithprobabilityq,thatisf+isBernoulli(p)and\n",
      "f?isBernoulli(q).Itisoftenassumedthatk,thenumberofcommunities,is\n",
      "aconstant(e.g.k=2isknownastheplantedbisectionmodelandisstudied\n",
      "extensively[1,36,15]oraslowlygrowingfunctionofn(e.g.k=o(logn)).\n",
      "Thepointsareassignedtoclustersaccordingtoaprobabilitydistributionindi-\n",
      "catingtherelativesizesoftheclusters.Incontrast,notonlyinourmodelf+\n",
      "andf?canbearbitraryprobabilitymassfunctions(pmfs),wedonothaveto\n",
      "makeanyassumptiononkortheclustersizedistribution,andcanallowfor\n",
      "anypartitioningofthesetofelements(i.e.,adversarialsetting).Moreover,f+\n",
      "andf?areunknown.ForSBM,parameterfreealgorithmsareknownrelatively\n",
      "recentlyforconstantnumberoflinearsizedclusters[3,24].Thereareextensive\n",
      "literaturethatcharacterizethethresholdphenomenoninSBMintermsofp\n",
      "andqforexactandapproximaterecoveryofclusterswhenrelativeclustersizes\n",
      "areknownandnearlybalanced(e.g.,see[2]andthereinformanyreferences).\n",
      "Fork=2andequalsizedclusters,sharpthresholdsarederivedin[1,36]fora\n",
      "spsparseregionofpandq1.Inamoregeneralsetting,theverticesinthe\n",
      "4\n",
      "\n",
      "ithandthejthcommunitiesareconnectedwithprobabilityqijandthreshold\n",
      "resultsforthesparseregionhasbeenderivedin[2]-ourmodelcanbeallowed\n",
      "tohavethisasaspecialcasewhenwehavepmfssdenotingthedistribu-\n",
      "tionsofthecorrespondingrandomvariables.Ifanoraclegivesussomeofthe\n",
      "pairwisebinaryrelationsbetweenelements(whethertheybelongtothesame\n",
      "clusterornot),thethresholdofSBMmustalsochange.Butbywhatamount?\n",
      "ThisconnectiontoSBMcouldbeofindependentinteresttostudyquerycom-\n",
      "plexityofinteractiveclusteringwithsideinformation,andourworkopensup\n",
      "manypossibilitiesforfuturedirection.Developinglowerboundsintheinterac-\n",
      "tivesettingappearstobecantlychallenging,asalgorithmsmaychooseto\n",
      "getanydeterministicinformationadaptivelybyquerying,andstandardlower\n",
      "boundingtechniquesbasedonFano-typeinequalities[9,31]donotapply.One\n",
      "ofourmajorcontributionsinthispaperistoprovideageneralframeworkfor\n",
      "provinginformation-theoreticlowerboundforinteractiveclusteringalgorithms\n",
      "whichholdsevenforrandomizedalgorithms,andevenwiththefullknowledge\n",
      "off+,f?andk.Incontrast,ouralgorithmsarecomputationallytand\n",
      "areparameterfree(workswithoutknowingf+,f?andk).Thetechnique\n",
      "thatweintroduceforourupperboundscouldbeusefulfordesigningfurther\n",
      "parameterfreealgorithmswhichareextremelyimportantinpractice.Other\n",
      "Relatedworks.Theinteractiveframeworkofclusteringmodelhasbeenstudied\n",
      "beforewheretheoracleisgiventheentireclusteringandtheoraclecananswer\n",
      "whetheraclusterneedstobesplitortwoclustersmustbemerged[7,6].Here\n",
      "wecontainourattentiontopair-wisequeries,asinallpracticalapplicationsthat\n",
      "motivatethiswork[42,43,22,40].Inmostcases,anexperthumanorcrowd\n",
      "servesasanoracle.Duetothescaleofthedata,itisoftennotpossibleforsuch\n",
      "anoracletoanswerqueriesonlargenumberofinputdata.Onlyrecently,some\n",
      "heuristicalgorithmswithk-wisequeriesforsmallvaluesofkbutk>2havebeen\n",
      "proposedin[39],andanon-interactivealgorithmthatselectsrandomtriangle\n",
      "querieshavebeenanalyzedin[41].Alsorecently,thestochasticblockmodel\n",
      "withactivelabel-querieshavebeenstudiedin[19].Perhapsconceptuallyclosest\n",
      "tousisarecentworkby[5]wheretheyconsiderpair-wisequeriesforclustering.\n",
      "However,theirsettingisveryt.TheyconsiderthespNP-hardk-\n",
      "meansobjectivewithdistancematrixwhichmustbeametricandmustsatisfy\n",
      "adeterministicseparationproperty.Theirlowerboundsarecomputationaland\n",
      "notinformationtheoretic;moreovertheiralgorithmmustknowtheparameters.\n",
      "Thereexistsatgapbetweentheirlowerandupperbounds:?logkvs\n",
      "k2,anditwouldbeinterestingifourtechniquescanbeappliedtoimprove\n",
      "this.Herewehaveassumedtheoraclealwaysreturnsthecorrectanswer.To\n",
      "dealwiththepossibilitythatthecrowdsourcedoraclemaygivewronganswers,\n",
      "therearesimplemajorityvotingmechanismsormorecomplicatedtechniques\n",
      "[39,12,21,29,10,41]tohandlesucherrors.Ourmainobjectiveisto1\n",
      "Mostrecentworksconsidertheregionofinterestasp=\n",
      "3\n",
      "alognn\n",
      "andq=\n",
      "blognn\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forsomea>b>0.\n",
      "studythepowerofsideinformation,andwedonotconsiderthemorecom-\n",
      "plexscenariosofhandlingerroneousoracleanswers.Therelatedproblemof\n",
      "clusteringwithnoisyqueriesisstudiedbyusinacompanionwork[34].Most\n",
      "oftheresultsofthetwopapersareavailableonlineinamoreextensivever-\n",
      "sion[32].Contributions.Formallytheproblemwestudyinthispapercanbe\n",
      "describedasfollows.Problem1(Query-ClusterwithanOracle).Considera\n",
      "setofelementsV?[n]withklatentclustersVi,i=1,...,k,wherekis\n",
      "unknown.ThereisanoracleO:V?V?\n",
      "f\n",
      "?1\n",
      "g\n",
      ",thatwhenqueriedwithapair\n",
      "ofelementsu,v?V?V,returns+1uandvbelongtothesamecluster,\n",
      "and?1uandvbelongtotclusters.ThequeriesQ?V?Vcanbe\n",
      "doneadaptively.ConsiderthesideinformationW=\n",
      "f\n",
      "wu,v:1?u<v?n\n",
      "g\n",
      ",\n",
      "wherethe(u,v)thentryofW,wu,visarandomvariabledrawnfromadiscrete\n",
      "probabilitydistributionf+ifu,vbelongtothesamecluster,andisdrawnfrom\n",
      "adiscrete2probabilitydistributionf?3ifu,vbelongtotclusters.The\n",
      "parametersk,f+andf?areunknown.GivenVandW,Q?V?Vsuch\n",
      "that|Q|isminimum,andfromtheoracleanswersandWitispossibleto\n",
      "recoverVi,i=1,2,...,k.Withoutsideinformation,asnotedearlier,itiseasy\n",
      "toseeanalgorithmwithquerycomplexityO(nk)forQuery-Cluster.Whenno\n",
      "sideinformationisavailable,itisalsonottohavealowerboundof\n",
      "?(nk)onthequerycomplexity.Ourmaincontributionsaretodevelopstrong\n",
      "informationtheoreticlowerboundsaswellasnearlymatchingupperbounds\n",
      "whensideinformationisavailable,andcharacterizetheofsideinforma-\n",
      "tiononquerycomplexityprecisely.UpperBound(Algorithms).Weshowthat\n",
      "withsideinformationW,adrasticreductioninquerycomplexityofclustering\n",
      "ispossible,evenwithunknownparametersf+,f?,andk.Weproposea2\n",
      "nMonteCarlorandomizedalgorithmthatreducesthenumberofqueriesfrom\n",
      "O(nk)toO(),+kf?)whereH(fkg)istheHellingerdivergence\n",
      "betweentheprobabilitydistributionsf,andg,andrecoverstheclustersaccu-\n",
      "ratelywithhighprobability(withsuccessprobability1?n1)withoutknowing\n",
      "f+,f?ork(see,Theorem1).Dependingonthevalueofk,thiscouldbehighly\n",
      "sublinearinn.NotethatthesquaredHellingerdivergencebetweentwopmfsf\n",
      "andgistobe,2p1XpH2(fkg)=f(i)?g(i).2iWealsodevelop\n",
      "aLasVegasalgorithm,thatisonewhichrecoverstheclusterswithprobability\n",
      "1(and2nnotjustwithhighprobability),withquerycomplexityO(nlogn+\n",
      ").Sincef+andf?+kf?)canbearbitrary,notknowingthedistribu-\n",
      "tionsprovidesamajorchallenge,andwebelieve,ourrecipecouldbefruitfulfor\n",
      "designingfurtherparameter-freealgorithms.Wenotethatallouralgorithms\n",
      "arecomputationallyt-infact,thetimerequiredisboundedbythesize\n",
      "ofthesideinformationmatrix,i.e.,O(n2).Theorem1.Letthenumberof\n",
      "clusterskbeunknownandf+andf?beunknowndiscretedistributionswith\n",
      "cardinalityofsupport.Thereexistsant(polynomial-time)Monte\n",
      "Carlo2nalgorithmforQuery-ClusterthathasquerycomplexityO(min(nk,\n",
      "))andrecoversall+kf?)1theclustersaccuratelywithprobability\n",
      "1?o(n).MoreoverthereexistsantLasVegas2\n",
      "nalgorithmthatwithprobability1?o(n1)hasquerycomplexityO(nlog\n",
      "6\n",
      "\n",
      "n+min(nk,)).+kf?)\n",
      "LowerBound.Ourmainlowerboundresultisinformationtheoretic,and\n",
      "canbesummarizedinthefollowingtheorem.Noteespeciallythat,forlower\n",
      "boundwecanassumetheknowledgeofk,f+,f?incontrasttoupperbounds,\n",
      "whichmakestheresultsstronger.Inaddition,f+andf?canbediscreteor\n",
      "continuousdistributions.NotethatwhenH2(f+kf?)iscloseto1,e.g.,when\n",
      "thesideinformationisperfect,noqueriesarerequired.However,thatisnot\n",
      "thecaseinpractice,andweareinterestedintheregionwheref+andf?are\n",
      "?close?,thatisH2(f+kf?)issmall.1Theorem2.AssumeH2(f+kf?)?18\n",
      ".Any(possiblyrandomized)algorithmwiththeknowledge\n",
      "2\n",
      "off+,f?,andthenumberofclustersk,thatdoesnotperform?min\n",
      "f\n",
      "nk,\n",
      "H2(fk+kf?)\n",
      "g\n",
      "expected2\n",
      "Ourlowerboundholdsforcontinuousdistributionsaswell.Forsimplicity\n",
      "ofexpression,wetreatthesamplespacetobeofconstantsize.However,allour\n",
      "resultsextendtoanyitesamplespacescalinglinearlywithitssize.3\n",
      "4\n",
      "numberofqueries,willbeunabletoreturnthecorrectclusteringwithprob-\n",
      "abilityatleast16?O(?1k).Andtorecovertheclusterswithprobability1,\n",
      "thenumberofqueriesmustbe?n+\n",
      "2min\n",
      "f\n",
      "nk,H2(fk+kf?)\n",
      "g\n",
      ".Thelowerboundthereforematchesthe\n",
      "querycomplexityupperboundwithinalogarithmicfactor.Notethatwhenno\n",
      "queryingisallowed,thisturnsoutexactlytobethesettingofstochasticblock\n",
      "modelthoughwithmuchgeneraldistributions.Wehaveanalyzedthiscasein\n",
      "AppendixC.Toseehowtheprobabilityoferrormustscale,wehaveuseda\n",
      "generalizedversionofFano?sinequality(e.g.,[23]).However,whenthenumber\n",
      "ofqueriesisgreaterthanzero,pluswhenqueriescanbeadaptive,anysuchstan-\n",
      "dardtechniquefails.Hence,canthastobeputforthtoconstructa\n",
      "settingwhereinformationtheoreticminimaxboundscanbeapplied.Thislower\n",
      "boundcouldbeofindependentinterest,andprovidesageneralframeworkfor\n",
      "derivinglowerboundsforfundamentalproblemsofhypothesis\n",
      "testing,distributiontestingetc.intheinteractivelearningsetting.Theymay\n",
      "alsoleadtonewlowerboundprovingtechniquesintherelatedmulti-round\n",
      "communicationcomplexitymodelwhereinformationagaingetsrevealedadap-\n",
      "tively.Organization.TheproofofthelowerboundisprovidedinSection2.\n",
      "TheMonteCarloalgorithmisgiveninSection3.Thedetailedproofofthe\n",
      "MonteCarloalgorithm,andtheLasVegasalgorithmanditsproofaregiven\n",
      "inAppendixAandAppendixBrespectivelyinthesupplementarymaterialfor\n",
      "spaceconstraint.\n",
      "2\n",
      "LowerBound(ProofofTheorem2)\n",
      "Inthissection,wedevelopourinformationtheoreticlowerbounds.We\n",
      "proveamoregeneralresultfromwhichTheorem2follows.Lemma1.Consider\n",
      "thecasewhenwehavekequallysizedclustersofsizeaeach(thatistotal\n",
      "numberofelementsisn=ka).SupposeweareallowedtomakeatmostQ\n",
      "adaptivequeriestotheoracle.Theprobabilityoferrorforanyalgorithmfor\n",
      "7\n",
      "\n",
      "Query-Clusterisatleast,r?24Q24Q1???2aH(f+kf?).1+kak\n",
      "ak(k?1)Themainhigh-leveltechniquetoproveLemma1isthefollowing.\n",
      "Suppose,anodeistobeassignedtoacluster.Thissituationisobviouslyakin\n",
      "toak-hypothesistestingproblem,andwewanttousealowerboundonthe\n",
      "probabilityoferror.Thesideinformationandthequeryanswersconstitutea\n",
      "randomvectorwhosedistributions(amongthekpossible)mustbefarapartfor\n",
      "ustosuccessfullyidentifytheclustering.Butthemainchallengecomesfrom\n",
      "theinteractivenatureofthealgorithmsinceitrevealsdeterministicinformation\n",
      "andintocharacterizingthesetofelementsthatarenotqueriedmuchbythe\n",
      "algorithm.ProofofLemma1.SincethetotalnumberofqueriesisQ,the\n",
      "averagenumberofqueriesperelement4Qakisatmost2Qak.Therefore\n",
      "thereexistatleast2elementsthatarequeriedatmostT<aktimes.Letx\n",
      "beonesuchelement.Wejustconsidertheproblemofassignmentofxtoa\n",
      "cluster(allotherelementshavebeencorrectlyassignedalready),andshowthat\n",
      "anyalgorithmwillmakewrongassignmentwithpositiveprobability.Step1:\n",
      "Settingupthehypotheses.NotethatthesideinformationmatrixW=(wi,j)\n",
      "isprovidedwherethewi,jsareindependentrandomvariables.Nowassumethe\n",
      "scenariowhenweuseanalgorithmALGtoassignxtooneofthekclusters,Vu\n",
      ",u=1,...,k.Therefore,givenx,ALGtakesasinputtherandomvariables\n",
      "wi,xswherei?ttVt,makessomequeriesinvolvingxandoutputsacluster\n",
      "index,whichisanassignmentforx.Basedontheobservationswi,xs,thetask\n",
      "ofALGisthusamulti-hypothesistestingamongkhypotheses.LetHu,u=\n",
      "1,...kdenotethekthypothesesHu:x?Vu.AndletPu,u=1,\n",
      "...kdenotethejointprobabilitydistributionsoftherandommatrixWwhen\n",
      "x?Vu.Inshort,foranyeventA,Pu(A)=Pr(A|Hu).Goingforward,the\n",
      "subscriptofprobabilitiesorexpectationswilldenotetheappropriateconditional\n",
      "distribution.Step2:Finding?weak?clusters.Theremustexistt?\n",
      "f\n",
      "1,...,\n",
      "k\n",
      "g\n",
      "suchthat,kX\n",
      "Pt\n",
      "f\n",
      "aquerymadebyALGinvolvingclusterVv\n",
      "g\n",
      "?Et\n",
      "f\n",
      "Numberofqueries\n",
      "madebyALG\n",
      "g\n",
      "?T.\n",
      "v=1\n",
      "5\n",
      "Wenowasubsetofclusters,thatare?weak,?i.e.,notqueriedenough\n",
      "ifHtweretrue.Consider2TthesetJ0?\n",
      "f\n",
      "v?\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      ":Pt\n",
      "f\n",
      "aquery\n",
      "madebyALGinvolvingclusterVv\n",
      "g\n",
      "<k(1??)\n",
      "g\n",
      ",where??\n",
      "1?.Wemusthave,(k?|J0|)?4Q\n",
      "1+\n",
      "2Tk(1??)\n",
      "?T,whichimplies,|J0|?\n",
      "(1+?)k.2\n",
      "ak\n",
      "Now,tooutputaclusterwithoutusingthesideinformation,ALGhasto\n",
      "eithermakeaquerytotheactualclustertheelementisfrom,orqueryatleastk\n",
      "?1times.Inanyothercase,ALGmustusethesideinformation(inadditionto\n",
      "usingqueries)tooutputacluster.LetEudenotetheeventthat2ALGoutputs\n",
      "clusterVubyusingthesideinformation.LetJ00?\n",
      "f\n",
      "u?\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      ":Pt(Eu\n",
      "8\n",
      "\n",
      ")??k\n",
      "g\n",
      ".Pk(2??)k?k200u00Sinceu=1Pt(E)?1,wemusthave,(k?|J\n",
      "|)??k<1,or|J|>k?2=.2+(2??)k?k=k2.Thismeans,\n",
      "f\n",
      "Vu:u?\n",
      "J0?J00\n",
      "g\n",
      "containsmoreWehave,|J0?J00|>(1+?)k22akthanak2\n",
      "elements.Sincethereare2elementsthatarequeriedatmostTtimes,thesetwo\n",
      "setsmusthavenonzerointersection.Hence,wecanassumethatx?V`forsome\n",
      "`?J0?J00,i.e.,letH`bethetruehypothesis.Nowwecharacterizetheerror\n",
      "eventsofthealgorithmALGinassignmentofx.Step3:Characterizingerror\n",
      "eventsfor?x?.Wenowconsiderthefollowingtwoevents.E1=\n",
      "f\n",
      "aquerymade\n",
      "byALGinvolvingclusterV`\n",
      "g\n",
      ";E2=\n",
      "f\n",
      "k?1ormorequeriesweremadebyALG\n",
      "g\n",
      ".\n",
      "NotethatifthealgorithmALGcancorrectlyassignxtoaclusterwithoutusing\n",
      "thesideinformationtheneitherofE1orE2musthavetohappen.Recall,E\n",
      "`denotesStheeventSthatALGoutputsclusterV`usingthesideinformation.\n",
      "NowconsidertheeventE?E`E1E2.Theprobabilityofcorrectassignmentis\n",
      "atmostP`(E).Wenowboundthisprobabilityofcorrectrecoveryfromabove.\n",
      "Step4:BoundingprobabilityofcorrectrecoveryviaHellingerdistance.We\n",
      "have,?P`(E)?Pt(E)+|P`(E)?Pt(E)|?Pt(E)+kP`?PtkTV?\n",
      "Pt(E)+2H(P`kPt),where,kP?QkTV?supA|P(A)?Q(A)|denotes\n",
      "thetotalvariationdistancebetweentwoprobabilitydistributionsPandQand\n",
      "inthelaststepwehaveusedtherelationshipbetweentotalvariationdistance\n",
      "andtheHellingerdivergence(see,forexample,[38,Eq.(3)]).Now,recallthat\n",
      "P`andPtarethejointdistributionsoftheindependentrandomvariableswi,x\n",
      ",i??uVu.Now,weusethefactthatsquaredHellingerdivergencebetween\n",
      "productdistributionofindependentrandomvariablesarelessthanthesumof\n",
      "thesquaredHellingerdivergencebetweentheindividualdistribution.Wealso\n",
      "notethatthedivergencebetweenidenticalrandomvariablesare0.Weobtainp\n",
      "p?2H2(P`kPt)?2?2aH2(f+kf?)=2aH(f+kf?).Thisistruebecause\n",
      "theonlytimeswhenwi,x?underPtandunderP`iswhenx?Vtorx?\n",
      "V`.Asaresultwehave,P`(E)?Pt(E)+2aH(f+kf?).Now,usingMarkov\n",
      "inequality4QTPt(E2)?k?1?ak(k?1).Therefore,8Q4Q2++.?kak2\n",
      "(1??)ak(k?1)q2\n",
      "?4QTherefore,puttingthevalueof?weget,P`(E)?k21+4Q+ak(k?1)\n",
      "+2aH(f+kf?),akwhichprovesthelemma.Pt(E)?Pt(E`)+Pt(E1)+\n",
      "Pt(E2)?\n",
      "2\n",
      "ProofofTheorem2.Considertwocases.Inthecase,suppose,nk<\n",
      "9H2(fk+kf?).NowconsiderthesituationofLemma1,witha=nk.The\n",
      "probabilityoferrorofanyalgorithmmustbeatleast,q2\n",
      "4Q1?k21+4Q?ak(k?1)?23?16?O(?1k),ifthenumberofqueries\n",
      "Q?nkak72.2\n",
      "Inthesecondcase,supposenk?9H2(fk+kf?).Assume,a=b9H2(f1+\n",
      "kf?)c.Thena?2,since1H2(f+kf?)?18.Wehavenk?k2a.Consider\n",
      "thesituationwhenwearealreadygivenacompleteclusterVkwithn?(k?\n",
      "1)aelements,remaining(k?1)clusterseachhas1element,andtherest(a?\n",
      "1)(k?1)elementsareevenlydistributed(butyettobeassigned)tothek?1\n",
      "clusters.Nowwe2areexactlyinthesituationofLemma1withk?1playing\n",
      "theroleofk.IfwehaveQ<ak72,The2probabilityoferrorisatleast1?ok\n",
      "9\n",
      "\n",
      "(1)?16?23=16?O(?1k).ThereforeQmustbe?(H2(fk+kf?)).Note\n",
      "thatinthisproofwehavenotinparticulartriedtooptimizetheconstants.If\n",
      "wewanttorecovertheclusterswithprobability1,then?(n)isatriviallower\n",
      "bound.Hence,2coupledwiththeabovewegetalowerboundof?(n+min\n",
      "f\n",
      "nk,H2(fk+kf?)\n",
      "g\n",
      ")inthatcase.6\n",
      "3\n",
      "Algorithms\n",
      "Weproposetwoalgorithms(MonteCarloandLasVegas)bothofwhich\n",
      "arecompletelyparameterfreethatistheyworkwithoutanyknowledgeofk,\n",
      "f+andf?,andmeettherespectivelowerboundswithinanO(logn)factor.\n",
      "HerewepresenttheMonteCarloalgorithmwhichdrasticallyreduces2n)and\n",
      "recoverstheclustersthenumberofqueriesfromO(nk)(nosideinformation)to\n",
      "O(+kf?)exactlywithprobabilityatleast1?on(1).Thedetailed\n",
      "proofofit,aswellastheLasVegasalgorithmarepresentedinAppendixAand\n",
      "AppendixBrespectivelyinthesupplementarymaterial.Ouralgorithmuses\n",
      "asubroutinecalledMembershipthattakesasinputanelementv?Vanda\n",
      "subsetofelementsC?V\n",
      "f\n",
      "v\n",
      "g\n",
      ".Assumethatf+,f?arediscretedistributions\n",
      "oversetofqpointsa1,a2,...,aq;thatiswi,jtakesvalueinthe\n",
      "set\n",
      "f\n",
      "a1,a2,...,aq\n",
      "g\n",
      ".theempirical|\n",
      "f\n",
      "u?C:wu,v=ai\n",
      "g\n",
      "|?inter?\n",
      "distributionpv,Cfori=1,...,q,pv,C(i)=Alsocomputethe?intra?\n",
      "dis|C||\n",
      "f\n",
      "(u,v)?C?C:u6=v,w\n",
      "=a\n",
      "g\n",
      "|\n",
      "u,vitributionpCfori=1,...,q,pC(i)=.ThenweuseMembership(v,\n",
      "C)|C|(|C|?1)2=?H(pv,CkpC)asyofvertexvtoC,where\n",
      "H(pv,CkpC)denotestheHellingerdivergencebetweendistributions.Notethat\n",
      "sincethemembershipisalwaysnegative,ahighermembershipimpliesthatthe\n",
      "?inter?and?intra?distributionsarecloserintermsofHellingerdistance.\n",
      "DesigningaparameterfreeMonteCarloalgorithmseemstobehighlychal-\n",
      "lengingashere,thenumberofqueriesdependsonlylogarithmicallywithn.\n",
      "Intuitively,ifanelementvhasthehighestmembershipinsomeclusterC,then\n",
      "vshouldbequeriedwithCAlsoanestimationfromsideinformation\n",
      "isreliablewhentheclusteralreadyhasenoughmembers.Unfortunately,we\n",
      "knowneitherwhetherthecurrentclustersizeisreliable,norweareallowedto\n",
      "makeevenonequeryperelement.Toovercomethisbottleneck,weproposean\n",
      "iterative-updatealgorithmwhichwebelievewillmoreusesindeveloping\n",
      "parameterfreealgorithms.Westartbyqueryingafewpointssothatthereis\n",
      "atleastoneclusterwith?(logn)points.Nowbasedonthesequeriedmem-\n",
      "berships,welearntwoempiricaldistributionsp1+fromintra-clustersimilarity\n",
      "values,andp1?frominter-clustersimilarityvalues.Givenanelementvwhich\n",
      "hasnotbeenclusteredyet,andaclusterCwiththehighestnumberofcurrent\n",
      "members,wewouldliketoconsiderthesubmatrixofsideinformationpertaining\n",
      "tovandallu?Canddeterminewhetherthatsideinformationisgenerated\n",
      "fromf+orf?.Weknowifthestatisticaldistancebetweenf+andf?issmall,\n",
      "thenwewouldneedmoremembersinCtosuccessfullydothistest.Sincewe\n",
      "donotknowf+andf?,wecomputethesquaredHellingerdivergencebetween\n",
      "p1+andp1?,andusethattocomputeathreshold?1onthesizeofC.IfC\n",
      "10\n",
      "\n",
      "crossesthissizethreshold,wejustusethesideinformationtodetermineifv\n",
      "shouldbelongtoC.Otherwise,wequeryfurtheruntilthereisoneclusterwith\n",
      "size?1,andre-estimatetheempiricaldistributionsp2+andp2?.Again,we\n",
      "recomputeathreshold?2,andstopiftheclusterunderconsiderationcrosses\n",
      "thisnewthreshold.Ifnotwecontinue.Interestingly,wecanshowwhenthe\n",
      "processconverges,wehaveaverygoodestimateofH(f+kf?)and,moreoverit\n",
      "convergesfast.Algorithm.Phase1.Initialization.Weinitializethealgorithm\n",
      "byselectinganyelementvandcreatingasingletoncluster\n",
      "f\n",
      "v\n",
      "g\n",
      ".Wethenkeep\n",
      "selectingnewelementsrandomlyanduniformlythathavenotyetbeenclus-\n",
      "tered,andquerytheoraclewithitbychoosingexactlyoneelementfromeach\n",
      "oftheclustersformedsofar.Iftheoraclereturns+1toanyofthesequeries\n",
      "thenweincludetheelementinthecorrespondingcluster,elsewecreateanew\n",
      "singletonclusterwithit.Wecontinuethisprocessuntiloneclusterhasgrown\n",
      "toasizeofdClogne,whereCisaconstant.Phase2.IterativeUpdate.Let\n",
      "C1,C2,...Clxbethesetofclustersformedafterthexthiterationforsomelx\n",
      "?k,whereweconsiderPhase1asthe0-thiteration.Weestimatep+,x=\n",
      "|\n",
      "f\n",
      "u,v?Ci:u6=v,wu,v=ai\n",
      "g\n",
      "||\n",
      "f\n",
      "u?Ci,v?Cj,i<j,i,j?[1,lx]:\n",
      "wu,v=ai\n",
      "g\n",
      "|;p?,x=PlxPlxPi=1|Ci|(|Ci?1|)i=1i<j|Ci||Cj\n",
      "|\n",
      "ClognEMxE=H(p+,xkp?,x)2.Ifthereisnoclusterofsizeat\n",
      "leastMxformedsofar,weselectanewelementyettobeclusteredandqueryit\n",
      "exactlyoncewiththeexistingclusters(thatisbyselectingonearbitrarypoint\n",
      "fromeveryclusterandqueryingtheoraclewithitandthenewelement),and\n",
      "includeitinanexistingclusterorcreateanewclusterwithitbasedonthe\n",
      "queryanswer.Wethensetx=x+1andmovetothenextiterationtoget\n",
      "updatedestimatesofp+,x,p?,x,MxEandlx.\n",
      "ElseifthereisaclusterofsizeatleastMxE,westopandmovetothenext\n",
      "phase.7\n",
      "Phase3.Processingthegrownclusters.OncePhase2hasconverged,let\n",
      "p+,p?,H(p+kp?),MEandlbetheestimates.ForeveryclusterC\n",
      "ofsize|C|?ME,callitgrownanddothefollowing.+kp?)(3A.)For\n",
      "everyunclusteredelementv,ifMembership(v,C)??(4H(pC?weincludevin\n",
      "Cwithoutquerying.\n",
      "2H(p+kp?)2?),Clogn\n",
      "+kp?)?(3B.)WecreateanewlistWaiting(C),initiallyempty.If?(\n",
      "4H(pC+kp?)?(4H(pC\n",
      "then\n",
      "2H(p+kp?)2?)Clogn\n",
      ">\n",
      "2H(p+kp?)2?),Clogn\n",
      "Membership(v,C)?thenweincludevinWaiting(C).Forevery+element\n",
      "inWaiting(C),wequerytheoraclewithitbychoosingexactlyoneelementfrom\n",
      "eachoftheclustersformedsofarstartingwithC.Iforaclereturnsanswer?yes?\n",
      "toanyofthesequeriesthenweincludetheelementinthatcluster,elsewecreate\n",
      "anewsingletonclusterwithit.WecontinuethisuntilWaiting(C)isexhausted.\n",
      "WethencallCcompletelygrown,removeitfromfurtherconsideration,and\n",
      "11\n",
      "\n",
      "movetothenextgrowncluster.ifthereisnoothergrowncluster,thenwe\n",
      "movebacktoPhase2.Analysis.Themainstepsoftheanalysisareasfollows\n",
      "(forfullanalysisseeAppendixA).2\n",
      "kp)?+?]fora1.First,Lemma3showswithhighprobabilityH(p+kp?\n",
      ")?[H(f+kf?)?4H(pBlognsuitableconstantBthatdependsonC.Using\n",
      "it,wecanshowtheprocessconvergeswheneverlognaclusterhasgrowntoa\n",
      "sizeofH4C2(fkf).TheproofreliesonadaptingtheSanov?sTheorem+?\n",
      "(seeLemma2)ofinformationtheory.Wearemeasuringthedistancebetween\n",
      "distributionsviaHellingerdistance,asopposedtoKLdivergence(whichwould\n",
      "havebeenanaturalchoicebecauseofitspresenceintheratefunctioninSanov?s\n",
      "therem),becauseHellingerdistanceisametricwhichprovestobecrucialinour\n",
      "analysis.2.Lemma5andCorollary1showthateveryelementthatisincluded\n",
      "inCinPhase(3A)trulybelongstoC,andelementsthatarenotinWaiting(C)\n",
      "cannotbeinCwithhighprobability.OncePhase2hasconverged,ifthe\n",
      "conditionof(3A)istheelementmustbelongtoC.Thereisasmall\n",
      "grayregionofinterval(3B)suchthatifanelementbelongsthere,we\n",
      "cannotbesureeitherway,butifanelementdoesnotsatisfyeither(3A)or3B,\n",
      "itcannotbepartofC.3.Lemma6showsthatsizeofWaiting(C)isconstant\n",
      "showingananti-concentrationproperty.Thislogncoupledwiththefactthat\n",
      "theprocessconvergeswhenaclusterreachessizeH4C2(fkf)givesthe+?\n",
      "desiredquerycomplexityboundinLemma7.\n",
      "4\n",
      "ExperimentalResults\n",
      "Inthissection,wereportexperimentalresultsonapopularbibliographic\n",
      "datasetcora[35]consistingof1879nodes,191clustersand1699612edgesout\n",
      "ofwhich62891areintra-clusteredges.Weremoveanysingletonnodefromthe\n",
      "dataset?thenumberofverticesthatweclassifyis1812with124clusters.\n",
      "Weusethesimilarityfunctioncomputationusedby[18]tocomputef+and\n",
      "f?.ThetwodistributionsareshowninFigure1ontheleft.TheHellinger\n",
      "squaredivergencebetweenthetwodistributionsis0.6.Inordertoobservethe\n",
      "dependencyofthealgorithmperformanceonthelearntdistributions,weperturb\n",
      "theexactdistributionstoobtaintwoapproximatedistributionsasshownin\n",
      "Figure1(middle)withHellingersquaredivergencebeing0.4587.Weconsider\n",
      "threestrategies.Supposetheclusterinwhichanodevmustbeincludedhas\n",
      "alreadybeeninitializedandexistsinthecurrentsolution.Moreover,suppose\n",
      "thealgorithmdecidestousequeriestomembershipofv.Theninthebest\n",
      "strategy,onlyonequeryisneededtoidentifytheclusterinwhichvbelongs.\n",
      "Intheworststrategy,thealgorithmndsthecorrectclusterafterquerying\n",
      "alltheexistingclusterswhosecurrentmembershipisnotenoughtotakea\n",
      "decisionusingsideinformation.Inthegreedystrategy,thealgorithmqueriesthe\n",
      "clustersinnon-decreasingorderofHellingersquaredivergencebetweenf+(or\n",
      "approximateversionofit)andtheestimateddistributionfromsideinformation\n",
      "betweenvandeachexistingclusters.Notethat,inpractice,wewillfollow\n",
      "thegreedystrategy.Figure2showstheperformanceofeachstrategy.We\n",
      "plotthenumberofqueriesvsF1Scorewhichcomputestheharmonicmean\n",
      "ofprecisionandrecall.Weobservethattheperformanceofgreedystrategy\n",
      "12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isveryclosetothatofbest.Withjust1136queries,greedyachieves80%\n",
      "precisionandcloseto90%recall.Thebeststrategywouldneed962queries\n",
      "toachievethatperformance.Theperformanceofouralgorithmontheexact\n",
      "andapproximatedistributionsarealsoveryclosewhichindicatesitisenoughto\n",
      "learnadistributionthatisclosetoexact.Forexample,usingtheapproximate\n",
      "distributions,8\n",
      "Figure1:(left)Exactdistributionsofsimilarityvalues,(middle)approxi-\n",
      "matedistributionsofsimilarityvalues,(right)NumberofQueriesvsF1Score\n",
      "forbothdistributions.toachievesimilarprecisionandrecall,thegreedystrat-\n",
      "egyjustuses1148queries,thatis12queriesmorethanwhenweusewhenthe\n",
      "distributionsareknown.\n",
      "Figure2:NumberofQueriesvsF1Scoreusingthreestrategies:best,greedy,\n",
      "worst.Discussion.Thisistherigoroustheoreticalstudyofinteractive\n",
      "clusteringwithsideinformation,anditunveilsmanyinterestingdirectionsfor\n",
      "futurestudyofboththeoreticalandpractical(seeAppendixDfor\n",
      "moredetails).Havingarbitraryf+,f?isageneralizationofSBM.Alsoit\n",
      "raisesanimportantquestionabouthowSBMrecoverythresholdchangeswith\n",
      "queries.Forsparseregionof00nnSBM,wheref+isBernoulli(alog)and\n",
      "f?isBernoulli(blog),a0>b0,Lemma1isnottightnnnyet.However,it\n",
      "showsthefollowingtrend.Letusseta=kinLemma1withtheabovef+,\n",
      "f?.?Weconjecturebyignoringthelowerordertermsandalognfactorthat\n",
      "withQqueries,thesharp\n",
      "??????QrecoverythresholdofsparseSBMchangesfrom(a0\n",
      "?b0)?kto(a0?b0)?k1?nk.Provingthisboundremainsan\n",
      "excitingopenquestion.Weproposetwocomputationallytalgorithms\n",
      "thatmatchthequerycomplexitylowerboundwithinlognfactorandarecom-\n",
      "pletelyparameterfree.Inparticular,ouriterative-updatemethodtodesign\n",
      "Monte-Carloalgorithmprovidesageneralrecipetodevelopanyparameter-free\n",
      "algorithm,whichareofextremepracticalimportance.Theconvergenceresult\n",
      "isestablishedbyextendingSanov?stheoremfromthelargedeviationtheory\n",
      "whichgivesboundonlyintermsofKL-divergence.Duetothegeneralityof\n",
      "thedistributions,theonlytoolwecoulduseisSanov?stheorem.However,\n",
      "Hellingerdistancecomesouttobetherightmeasurebothforlowerandupper\n",
      "bounds.Iff+andf?arecommondistributionslikeGaussian,Bernoullietc.,\n",
      "thenotherconcentrationresultsstrongerthanSanovmaybeappliedtoimprove\n",
      "theconstantsandalogarithmfactortoshowthebetweenqueriesand\n",
      "thresholdsasinsparseSBM.Whilesomeofourresultsapplytogenerals,a\n",
      "fullpicturewitharbitrarysandclosingthegapoflognbetweenthelower\n",
      "andupperboundremainanimportantfuturedirection.\n",
      "9\n",
      "Acknowledgement.ThisworkissupportedinpartbyNSFawardsCCF\n",
      "1642658,CCF1642550,CCF1464310,CCF1652303,aYahooACEAwardand\n",
      "aGoogleFacultyResearchAward.Weareparticularlythankfultoananony-\n",
      "mousreviewerwhosecommentsledtonotableimprovementofthepresentation\n",
      "ofthepaper.\n",
      "13\n",
      "\n",
      "2References\n",
      "[1]E.Abbe,A.S.Bandeira,andG.Hall.Exactrecoveryinthestochastic\n",
      "blockmodel.IEEETrans.InformationTheory,62(1):471?487,2016.[2]E.\n",
      "AbbeandC.Sandon.Communitydetectioningeneralstochasticblockmodels:\n",
      "Fundamentallimitsandtalgorithmsforrecovery.InIEEE56thAnnual\n",
      "SymposiumonFoundationsofComputerScience,FOCS2015,Berkeley,CA,\n",
      "USA,17-20October,2015,pages670?688,2015.[3]E.AbbeandC.Sandon.\n",
      "Recoveringcommunitiesinthegeneralstochasticblockmodelwithoutknowing\n",
      "theparameters.InAdvancesinNeuralInformationProcessingSystems,pages\n",
      "676?684,2015.[4]M.Ajtai,J.Komlos,W.L.Steiger,andE.Szemer?edi.Deter-\n",
      "ministicselectionino(loglogn)paralleltime.InProceedingsoftheeighteenth\n",
      "annualACMsymposiumonTheoryofcomputing,pages188?195.ACM,1986.\n",
      "[5]H.Ashtiani,S.Kushagra,andS.Ben-David.Clusteringwithsame-cluster\n",
      "queries.NIPS,2016.[6]P.Awasthi,M.-F.Balcan,andK.Voevodski.Local\n",
      "algorithmsforinteractiveclustering.InICML,pages550?558,2014.[7]M.-F.\n",
      "BalcanandA.Blum.Clusteringwithinteractivefeedback.InInternational\n",
      "ConferenceonAlgorithmicLearningTheory,pages316?328.Springer,2008.\n",
      "[8]B.Bollob?asandG.Brightwell.Parallelselectionwithhighprobability.\n",
      "SIAMJournalonDiscreteMathematics,3(1):21?31,1990.[9]K.Chaudhuri,\n",
      "F.C.Graham,andA.Tsiatas.Spectralclusteringofgraphswithgeneralde-\n",
      "greesintheextendedplantedpartitionmodel.InCOLT,pages35?1,2012.\n",
      "[10]Y.Chen,G.Kamath,C.Suh,andD.Tse.Communityrecoveryingraphs\n",
      "withlocality.InProceedingsofThe33rdInternationalConferenceonMachine\n",
      "Learning,pages689?698,2016.[11]P.Chin,A.Rao,andV.Vu.Stochastic\n",
      "blockmodelandcommunitydetectioninthesparsegraphs:Aspectralalgo-\n",
      "rithmwithoptimalrateofrecovery.arXivpreprintarXiv:1501.05021,2015.\n",
      "[12]N.Dalvi,A.Dasgupta,R.Kumar,andV.Rastogi.Aggregatingcrowd-\n",
      "sourcedbinaryratings.InWWW,pages285?294,2013.[13]S.B.Davidson,\n",
      "S.Khanna,T.Milo,andS.Roy.Top-kandclusteringwithnoisycomparisons.\n",
      "ACMTrans.DatabaseSyst.,39(4):35:1?35:39,2014.[14]A.Decelle,F.Krza-\n",
      "kala,C.Moore,andL.Zdeborov?a.Asymptoticanalysisofthestochasticblock\n",
      "modelformodularnetworksanditsalgorithmicapplications.PhysicalReview\n",
      "E,84(6):066106,2011.[15]M.E.DyerandA.M.Frieze.Thesolutionofsome\n",
      "randomnp-hardproblemsinpolynomialexpectedtime.JournalofAlgorithms,\n",
      "10(4):451?489,1989.[16]U.Feige,P.Raghavan,D.Peleg,andE.Upfal.Com-\n",
      "putingwithnoisyinformation.SIAMJournalonComputing,23(5):1001?1018,\n",
      "1994.[17]I.P.FellegiandA.B.Sunter.Atheoryforrecordlinkage.Journal\n",
      "oftheAmericanStatisticalAssociation,64(328):1183?1210,1969.10\n",
      "[18]D.Firmani,B.Saha,andD.Srivastava.Onlineentityresolutionusing\n",
      "anoracle.PVLDB,9(5):384?395,2016.[19]A.Gadde,E.E.Gad,S.Aves-\n",
      "timehr,andA.Ortega.Activelearningforcommunitydetectioninstochastic\n",
      "blockmodels.InInformationTheory(ISIT),2016IEEEInternationalSympo-\n",
      "siumon,pages1889?1893.IEEE,2016.[20]L.GetoorandA.Machanavajjhala.\n",
      "Entityresolution:theory,practice&openchallenges.PVLDB,5(12):2018?2019,\n",
      "2012.[21]A.Ghosh,S.Kale,andP.McAfee.Whomoderatesthemoderators?:\n",
      "14\n",
      "\n",
      "crowdsourcingabusedetectioninuser-generatedcontent.InEC,pages167?176,\n",
      "2011.[22]C.Gokhale,S.Das,A.Doan,J.F.Naughton,N.Rampalli,J.Shavlik,\n",
      "andX.Zhu.Corleone:crowdsourcingforentitymatching.InSIG-\n",
      "MODConference,pages601?612,2014.[23]A.Guntuboyina.Lowerbounds\n",
      "fortheminimaxriskusing-divergences,andapplications.IEEETransactionson\n",
      "InformationTheory,57(4):2386?2399,2011.[24]B.Hajek,Y.Wu,andJ.Xu.\n",
      "Achievingexactclusterrecoverythresholdviaprogramming.IEEE\n",
      "TransactionsonInformationTheory,62(5):2788?2797,2016.[25]B.E.Hajek,\n",
      "Y.Wu,andJ.Xu.Computationallowerboundsforcommunitydetectionon\n",
      "randomgraphs.InProceedingsofThe28thConferenceonLearningTheory,\n",
      "COLT2015,Paris,France,July3-6,2015,pages899?928,2015.[26]T.S.Han\n",
      "andS.Verdu.Generalizingthefanoinequality.IEEETransactionsonInforma-\n",
      "tionTheory,40(4):1247?1251,1994.[27]W.Hoeng.Probabilityinequalities\n",
      "forsumsofboundedrandomvariables.JournaloftheAmericanstatisticalasso-\n",
      "ciation,58(301):13?30,1963.[28]P.W.Holland,K.B.Laskey,andS.Leinhardt.\n",
      "Stochasticblockmodels:Firststeps.Socialnetworks,5(2):109?137,1983.[29]\n",
      "D.R.Karger,S.Oh,andD.Shah.Iterativelearningforreliablecrowdsourcing\n",
      "systems.InNIPS,pages1953?1961,2011.[30]H.K?opcke,A.Thor,andE.\n",
      "Rahm.Evaluationofentityresolutionapproachesonreal-worldmatchprob-\n",
      "lems.ProceedingsoftheVLDBEndowment,3(1-2):484?493,2010.[31]S.H.\n",
      "Lim,Y.Chen,andH.Xu.Clusteringfromlabelsandtime-varyinggraphs.\n",
      "InZ.Ghahramani,M.Welling,C.Cortes,N.D.Lawrence,andK.Q.Wein-\n",
      "berger,editors,AdvancesinNeuralInformationProcessingSystems27,pages\n",
      "1188?1196.CurranAssociates,Inc.,2014.[32]A.MazumdarandB.Saha.\n",
      "Clusteringviacrowdsourcing.arXivpreprintarXiv:1604.01839,2016.[33]A.\n",
      "MazumdarandB.Saha.ATheoreticalAnalysisofFirstHeuristicsofCrowd-\n",
      "sourcedEntityResolution.TheThirty-FirstAAAIConferenceon\n",
      "Intelligence(AAAI-17),2017.[34]A.MazumdarandB.Saha.Clusteringwith\n",
      "noisyqueries.InAdvancesinNeuralInformationProcessingSystems(NIPS)31,\n",
      "2017.[35]A.McCallum,2004.http://www.cs.umass.edu/mcallum/data/cora-\n",
      "refs.tar.gz.[36]E.Mossel,J.Neeman,andA.Sly.Consistencythresholdsfor\n",
      "theplantedbisectionmodel.InProceedingsoftheForty-SeventhAnnualACM\n",
      "onSymposiumonTheoryofComputing,pages69?75.ACM,2015.[37]Y.\n",
      "PolyanskiyandS.Verd?u.Arimotochannelcodingconverseandr?enyidi-\n",
      "vergence.InCommunication,Control,andComputing(Allerton),201048th\n",
      "AnnualAllertonConferenceon,pages1327?1333.IEEE,2010.11\n",
      "[38]I.SasonandS.V?erdu.fdivergenceinequalities.IEEETransactionson\n",
      "InformationTheory,62(11):5973?6006,2016.[39]V.VerroiosandH.Garcia-\n",
      "Molina.Entityresolutionwithcrowderrors.In31stIEEEInternationalCon-\n",
      "ferenceonDataEngineering,ICDE2015,Seoul,SouthKorea,April13-17,2015,\n",
      "pages219?230,2015.[40]N.Vesdapunt,K.Bellare,andN.Dalvi.Crowdsourc-\n",
      "ingalgorithmsforentityresolution.PVLDB,7(12):1071?1082,2014.[41]R.\n",
      "K.VinayakandB.Hassibi.Crowdsourcedclustering:Queryingedgesvstrian-\n",
      "gles.InAdvancesinNeuralInformationProcessingSystems,pages1316?1324,\n",
      "2016.[42]J.Wang,T.Kraska,M.J.Franklin,andJ.Feng.Crowder:Crowd-\n",
      "sourcingentityresolution.PVLDB,5(11):1483?1494,2012.[43]J.Wang,G.\n",
      "15\n",
      "\n",
      "Li,T.Kraska,M.J.Franklin,andJ.Feng.Leveragingtransitiverelationsfor\n",
      "crowdsourcedjoins.InSIGMODConference,pages229?240,2013.\n",
      "12\n",
      "16\n",
      "\n",
      "PP4213.pdf\n",
      "PP4213.pdf 14\n",
      "ShareBoost:tmulticlasslearningwith\n",
      "featuresharing\n",
      "Authoredby:\n",
      "AmnonShashua\n",
      "ShaiShalev-shwartz\n",
      "YonatanWexler\n",
      "Abstract\n",
      "Multiclasspredictionistheproblemofclassifyinganobjectintoa\n",
      "relevanttargetclass.Weconsidertheproblemoflearningamulticlass\n",
      "predictorthatusesonlyfewfeatures,andinparticular,thenumberofused\n",
      "featuresshouldincreasesub-linearlywiththenumberofpossibleclasses.\n",
      "Thisimpliesthatfeaturesshouldbesharedbyseveralclasses.Wedescribe\n",
      "andanalyzetheShareBoostalgorithmforlearningamulticlasspredictor\n",
      "thatusesfewsharedfeatures.WeprovethatShareBoosttly\n",
      "apredictorthatusesfewsharedfeatures(ifsuchapredictorexists)and\n",
      "thatithasasmallgeneralizationerror.Wealsodescribehowtouse\n",
      "ShareBoostforlearninganon-linearpredictorthathasafastevaluation\n",
      "time.Inaseriesofexperimentswithnaturaldatasetswedemonstrate\n",
      "thebofShareBoostandevaluateitssuccessrelativelytoother\n",
      "state-of-the-artapproaches.\n",
      "1PaperBody\n",
      "Learningtoclassifyanobjectintoarelevanttargetclasssurfacesinmanydo-\n",
      "mainssuchasdocumentcategorization,objectrecognitionincomputervision,\n",
      "andwebadvertisement.Inmulticlasslearningproblemsweusetrainingex-\n",
      "amplestolearnawhichwilllaterbeusedforaccuratelyclassifying\n",
      "newobjects.Typically,thestcalculatesseveralfeaturesfromthe\n",
      "inputobjectandthenclassestheobjectbasedonthosefeatures.Inmany\n",
      "cases,itisimportantthattheruntimeofthelearnedwillbesmall.In\n",
      "particular,thisrequiresthatthelearnedwillonlyrelyonthevalueof\n",
      "fewfeatures.Westartwithpredictorsthatarebasedonlinearcombinations\n",
      "offeatures.Later,inSection3,weshowhowourframeworkenableslearning\n",
      "highlynon-linearpredictorsbyembeddingnon-linearityintheconstructionof\n",
      "thefeatures.Requiringthetodependonfewfeaturesistherefore\n",
      "equivalenttosparsenessofthelinearweightsoffeatures.Inrecentyears,the\n",
      "1\n",
      "\n",
      "problemoflearningsparsevectorsforlinearorregressionhasbeen\n",
      "giventattention.While,ingeneral,themostaccuratesparse\n",
      "predictorisknowntobeNPhard,twomainapproacheshavebeenproposedfor\n",
      "overcomingthehardnessresult.Theapproachuses`1normasasurrogate\n",
      "forsparsity(e.g.theLassoalgorithm[33]andthecompressedsensingliterature\n",
      "[5,11]).Thesecondapproachreliesonforwardgreedyselectionoffeatures(e.g.\n",
      "Boosting[15]inthemachinelearningliteratureandorthogonalmatchingpur-\n",
      "suitinthesignalprocessingcommunity[35]).Apopularmodelformulticlass\n",
      "predictorsmaintainsaweightvectorforeachoneoftheclasses.Insuchcase,\n",
      "eveniftheweightvectorassociatedwitheachclassissparse,theoverallnumber\n",
      "ofusedfeaturesmightgrowwiththenumberofclasses.Sincethenumberof\n",
      "classescanberatherlarge,andourgoalistolearnamodelwithanoverallsmall\n",
      "numberoffeatures,wewouldlikethattheweightvectorswillsharethefeatures\n",
      "withnon-zeroweightsasmuchaspossible.Organizingtheweightvectorsofall\n",
      "classesasrowsofasinglematrix,thisisequivalenttorequiringsparsityofthe\n",
      "columnsofthematrix.?\n",
      "SchoolofComputerScienceandEngineering,theHebrewUniversityof\n",
      "Jerusalem,IsraelOrCamLtd.,Jerusalem,Israel?OrCamLtd.,Jerusalem,\n",
      "Israel?\n",
      "1\n",
      "Inthispaperwedescribeandanalyzeantalgorithmforlearninga\n",
      "multiclasspredictorwhosecorrespondingmatrixofweightshasasmallnumber\n",
      "ofnon-zerocolumns.Weformallyprovethatifthereexistsanaccuratematrix\n",
      "withanumberofnon-zerocolumnsthatgrowssub-linearlywiththenumberof\n",
      "classes,thenouralgorithmwillalsolearnsuchamatrix.Weapplyouralgorithm\n",
      "tonaturalmulticlasslearningproblemsanddemonstrateitsadvantagesover\n",
      "previouslyproposedstate-of-the-artmethods.Ouralgorithmisageneralization\n",
      "oftheforwardgreedyselectionapproachtosparsityincolumns.Analternative\n",
      "approach,whichhasrecentlybeenstudiedin[26,12],generalizesthe`1norm\n",
      "basedapproach,andreliesonmixed-norms.Wediscusstheadvantagesofthe\n",
      "greedyapproachovermixednormsinSection1.2.1.1\n",
      "Formalproblemstatement\n",
      "LetVbethesetofobjectswewouldliketoclassify.Forexample,Vcanbe\n",
      "thesetofgrayscaleimagesofacertainsize.Foreachobjectv2V,wehavea\n",
      "poolofdfeatures,eachofwhichisarealnumberin[1,1].Thatis,\n",
      "wecanrepresenteachv2Vasavectoroffeaturesx2[1,1]d.Wenotethat\n",
      "themappingfromvtoxcanbenon-linearandthatdcanbeverylarge.For\n",
      "example,wecanxsothateachelementxicorrespondstosomepatch,p\n",
      "2\n",
      "f\n",
      "?1\n",
      "g\n",
      "q?q,andathreshold?,wherexiequals1ifthereisapatchofvwhose\n",
      "innerproductwithpishigherthan?.Wediscusssomegenericmethodsfor\n",
      "constructingfeaturesinSection3.Fromthispointonwardweassumethatxis\n",
      "given.ThesetofpossibleclassesisdenotedbyY=\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      ".Ourgoal\n",
      "istolearnamulticlasspredictor,whichisamappingfromthefeaturesofan\n",
      "objectintoY.WefocusonthesetofpredictorsparametrizedbymatricesW2\n",
      "Rk,dthattakesthefollowingform:hW(x)=argmax(Wx)y.\n",
      "(1)\n",
      "2\n",
      "\n",
      "y2Y\n",
      "Thatis,thematrixWmapseachd-dimensionalfeaturevectorintoak-\n",
      "dimensionalscorevector,andtheactualpredictionistheindexofthemaximal\n",
      "elementofthescorevector.Ifthemaximizerisnotunique,webreakties\n",
      "arbitrarily.RecallthatourgoalistoamatrixWwithfewnon-zerocolumns.\n",
      "WedenotebyW?,ithei?thcolumnofWandusethenotationkWk1,0=|\n",
      "f\n",
      "i:\n",
      "kW?,ik1>0\n",
      "g\n",
      "|todenotethenumberofcolumnsofWwhicharenotidentically\n",
      "thezerovector.Moregenerally,givenamatrixWandapairofnormsk?kp\n",
      ",k?krwedenotekWkp,r=k(kW?,1kp,...,kW?,dkp)kr,thatis,\n",
      "weapplythep-normonthecolumnsofWandther-normontheresulting\n",
      "d-dimensionalvector.The01lossofamulticlasspredictorhWonanexample\n",
      "(x,y)isas1[hW(x)6=y].Thatis,the01lossequals1ifhW(x)\n",
      "6=yand0otherwise.SincethislossfunctionisnotconvexwithrespecttoW\n",
      ",weuseasurrogateconvexlossfunctionbasedonthefollowingeasytoverify\n",
      "inequalities:1[hW(x)6=y]?1[hW(x)6=y]\n",
      "(Wx)y+(Wx)hW(x)\n",
      "?max1[y6=y](Wx)y+(Wx)y0y02YX0?lne1[y6=y](Wx)y+(W\n",
      "x)y0.0\n",
      "(2)(3)\n",
      "y02Y\n",
      "Weusethenotation`(W,(x,y))todenotetheright-handside(eqn.(3))of\n",
      "theabove.Thelossgivenineqn.(2)isthemulti-classhingeloss[7]usedin\n",
      "Support-Vector-Machines,Pwhereas`(W,(x,y))istheresultofperforminga\n",
      "?soft-max?operation:maxxf(x)?(1/p)lnxepf(x),whereequalityholds\n",
      "forp!1.Thislogisticmulticlasslossfunction`(W,(x,y))hasseveralnice\n",
      "properties?seeforexample[39].Besidesbeingaconvexupper-boundonthe0\n",
      "1loss,itissmooth.Thereasonweneedthelossfunctiontobebothconvexand\n",
      "smoothisasfollows.Ifafunctionisconvex,thenitsorderapproximation\n",
      "atanypointgivesusalowerboundonthefunctionatanyotherpoint.When\n",
      "thefunctionisalsosmooth,theorderapproximationgivesusbothlower\n",
      "andupperboundsonthe2\n",
      "valueofthefunctionatanyotherpoint1.ShareBoostusesthegradientof\n",
      "thelossfunctionatthecurrentsolution(i.e.theorderapproximationof\n",
      "theloss)tomakeagreedychoiceofwhichcolumntoupdate.Toensurethat\n",
      "thisgreedychoiceindeedyieldsasigntimprovementwemustknowthat\n",
      "theorderapproximationisindeedclosetotheactuallossfunction,and\n",
      "forthatweneedbothlowerandupperboundsonthequalityoftheorder\n",
      "approximation.GivenatrainingPsetS=(x1,y1),...,(xm,ym),the\n",
      "averagetraininglossofamatrixWis:1L(W)=m(x,y)2S`(W,(x,y)).We\n",
      "aimatapproximatelysolvingtheproblemminL(W)s.t.kWk1,0?s.\n",
      "W2Rk,d\n",
      "(4)\n",
      "Thatis,thematrixWwithminimaltraininglossamongallmatrices\n",
      "withcolumnsparsityofatmosts,wheresisaparameter.Since\n",
      "`(W,(x,y))isanupperboundon1[hW(x)6=y],byminimizingL(W)wealso\n",
      "decreasetheaverage01errorofWoverthetrainingset.InSection4weshow\n",
      "3\n",
      "\n",
      "thatforsparsemodels,asmalltrainingerrorislikelytoyieldasmallerroron\n",
      "unseenexamplesaswell.Regrettably,theconstraintkWk1,0?sineqn.(4)is\n",
      "non-convex,andsolvingtheoptimizationproblemineqn.(4)isNP-hard[24,\n",
      "9].Toovercomethehardnessresult,theShareBoostalgorithmwillfollowthe\n",
      "forwardgreedyselectionapproach.Thealgorithmcomeswithformalgeneral-\n",
      "izationandsparsityguarantees(describedinSection4)thatmakesShareBoost\n",
      "anattractivemulticlasslearningenginedueto(bothduringtraining\n",
      "andattesttime)andaccuracy.1.2\n",
      "RelatedWork\n",
      "Thecentralityofthemulticlasslearningproblemhasspurredthedevelop-\n",
      "mentofvariousapproachesfortacklingthetask.Perhapsthemoststraightfor-\n",
      "wardapproachisareductionfrommulticlasstobinary,e.g.theone-vs-restor\n",
      "allpairsconstructions.Themoredirectapproachwechoose,inparticular,the\n",
      "multiclasspredictorsoftheformgivenineqn.(1),hasbeenextensivelystudied\n",
      "andshowedagreatsuccessinpractice?seeforexample[13,37,7].Analterna-\n",
      "tiveconstruction,abbreviatedasthesingle-vectormodel,sharesasingleweight\n",
      "vector,foralltheclasses,pairedwithclass-spfeaturemappings.Thiscon-\n",
      "structioniscommoningeneralizedadditivemodels[17],multiclassversionsof\n",
      "boosting[16,28],andhasbeenpopularizedlatelyduetoitsroleinprediction\n",
      "withstructuredoutputwherethenumberofclassesisexponentiallylarge(see\n",
      "e.g.[31]).Whilethisapproachcanyieldpredictorswitharathermilddepen-\n",
      "dencyoftherequiredfeaturesonk(seeforexampletheanalysisin[39,31,14]),\n",
      "itreliesona-prioriassumptionsonthestructureofXandY.Incontrast,inthis\n",
      "paperwetacklegeneralmulticlasspredictionproblems,likeobjectrecognition\n",
      "ordocumentwhereitisnotstraightforwardorevenplausiblehow\n",
      "onewouldgoabouttoconstructa-priorigoodclassspfeaturemappings,\n",
      "andthereforethesingle-vectormodelisnotadequate.Theclassofpredictorsof\n",
      "theformgivenineqn.(1)canbetrainedusingFrobeniusnormregularization\n",
      "(asdonebymulticlassSVM?seee.g.[7])orusing`1regularizationoverallthe\n",
      "entriesofW.However,aspointedoutin[26],theseregularizersmightyielda\n",
      "matrixwithmanynon-zeroscolumns,andhence,willleadtoapredictorthat\n",
      "usesmanyfeatures.Thealternativeapproach,andthemostrelevanttoour\n",
      "work,istheuseofmix-normregularizationslikekWk1,1orkWk2,1[21,36,\n",
      "2,3,26,12,19].Forexample,[12]solvesthefollowingproblem:minL(W)+\n",
      "kWk1,1.\n",
      "W2Rk,d\n",
      "(5)\n",
      "whichcanbeviewedasaconvexapproximationofourobjective(eqn.(4)).\n",
      "Thisisadvantageousfromanoptimizationpointofview,asonecanthe\n",
      "globaloptimumofaconvexproblem,butitremainsunclearhowwellthecon-\n",
      "vexprogramapproximatestheoriginalgoal.Forexample,inSectionCweshow\n",
      "caseswheremix-normregularizationdoesnotyieldsparsesolutionswhileShare-\n",
      "Boostdoesyieldasparsesolution.DespitethefactthatShareBoosttacklesa\n",
      "non-convexprogram,andthuslimitedtolocaloptimumsolutions,weprovein\n",
      "Theorem2thatundermild1Smoothnessguaranteesthat|f(x)f(x0)rf(x0\n",
      ")(xx0)|?kxx0k2forsomeandallx,x0.Thereforeonecanapproximatef\n",
      "4\n",
      "\n",
      "(x)byf(x0)+rf(x0)(xx0)andtheapproximationerrorisupperbounded\n",
      "bythebetweenx,x0.\n",
      "3\n",
      "conditionsShareBoostisguaranteedtoanaccuratesparsesolution\n",
      "wheneversuchasolutionexistsandthatthegeneralizationerrorisboundedas\n",
      "showninTheorem1.Wenotethatseveralrecentpapers(e.g.[19])established\n",
      "exactrecoveryguaranteesformixednorms,whichmayseemtobestrongerthan\n",
      "ourguaranteegiveninTheorem2.However,theassumptionsin[19]aremuch\n",
      "strongerthantheassumptionsofTheorem2.Inparticular,theyhavestrong\n",
      "noiseassumptionsandagroupRIPlikeassumption(Assumption4.1-4.3intheir\n",
      "paper).Incontrast,weimposenosuchrestrictions.Wewouldliketostress\n",
      "thatinmanygenericpracticalcases,theassumptionsof[19]willnothold.For\n",
      "example,whenusingdecisionstumps,featureswillbehighlycorrelatedwhich\n",
      "willviolateAssumption4.3of[19].AnotheradvantageofShareBoostisthatits\n",
      "onlyparameteristhedesirednumberofnon-zerocolumnsofW.Furthermore,\n",
      "obtainingthewhole-regularization-pathofShareBoost,thatis,thecurveofac-\n",
      "curacyasafunctionofsparsity,canbeperformedbyasinglerunofShareBoost,\n",
      "whichismucheasierthanobtainingthewholeregularizationpathoftheconvex\n",
      "relaxationineqn.(5).Lastbutnotleast,ShareBoostcanworkevenwhen\n",
      "theinitialnumberoffeatures,d,isverylarge,aslongasthereisant\n",
      "waytochoosethenextfeature.Forexample,whenthefeaturesareconstructed\n",
      "usingdecisionstumps,dwillbeextremelylarge,butShareBoostcanstillbe\n",
      "implementedtly.Incontrast,whendisextremelylargemix-normreg-\n",
      "ularizationtechniquesyieldchallengingoptimizationproblems.Asmentioned\n",
      "before,ShareBoostfollowstheforwardgreedyselectionapproachfortackling\n",
      "thehardnessofsolvingeqn.(4).Thegreedyapproachhasbeenwidelystudied\n",
      "inthecontextoflearningsparsepredictorsforlinearregression.However,in\n",
      "multiclassproblems,oneneedssparsityofgroupsofvariables(columnsofW\n",
      ").ShareBoostgeneralizesthefullycorrectivegreedyselectionproceduregiven\n",
      "in[29]tothecaseofselectionofgroupsofvariables,andouranalysisfollows\n",
      "similartechniques.Obtaininggroupsparsitybygreedymethodshasbeenalso\n",
      "recentlystudiedin[20,23],andindeed,ShareBoostsharessimilaritieswith\n",
      "theseworks.Wefrom[20]inthatouranalysisdoesnotimposestrong\n",
      "assumptions(e.g.group-RIP)andsoShareBoostappliestoamuchwiderarray\n",
      "ofapplications.Inaddition,thespcriterionforchoosingthenextfeature\n",
      "ist.In[20],aratiobetweeninobjectiveandtincosts\n",
      "isused.InShareBoost,theL1normofthegradientmatrixisused.Forthe\n",
      "multiclassproblemwithlogloss,thecriterionofShareBoostismucheasierto\n",
      "compute,especiallyinlargescaleproblems.[23]suggestedmanyotherselec-\n",
      "tionrulesthataregearedtowardthesquaredloss,whichisfarfrombeingan\n",
      "optimallossfunctionformulticlassproblems.Anotherrelatedmethodisthe\n",
      "JointBoostalgorithm[34].Whiletheoriginalpresentationin[34]seemsrather\n",
      "tthanthetypeofpredictorswedescribeineqn.(1),itispossibleto\n",
      "showthatJointBoostinfactlearnsamatrixWwithadditionalconstraints.\n",
      "Inparticular,thefeaturesxareassumedtobedecisionstumpsandeachcol-\n",
      "umnW?,iisconstrainedtobe?i(1[12Ci],...,1[k2Ci]),where?i2\n",
      "5\n",
      "\n",
      "RandCi?Y.Thatis,thestumpissharedbyallclassesinthesubsetCi.\n",
      "JointBoostchoosessuchshareddecisionstumpsinagreedymannerbyapplying\n",
      "theGentleBoostalgorithmontopofthispresentation.Amajordisadvantage\n",
      "ofJointBoostisthatinitspureform,itshouldexhaustivelysearchCamong\n",
      "all2kpossiblesubsetsofY.Inpractice,[34]reliesonheuristicsforC\n",
      "oneachboostingstep.Incontrast,ShareBoostallowsthecolumnsofWto\n",
      "beanyrealnumbers,thusallowing?soft?sharingbetweenclasses.Therefore,\n",
      "ShareBoosthasthesame(orevenricher)expressivepowercomparingtoJoint-\n",
      "Boost.Moreover,ShareBoostautomaticallyidentherelatednessbetween\n",
      "classes(correspondingtochoosingthesetC)withouthavingtorelyonexhaus-\n",
      "tivesearch.ShareBoostisalsofullycorrective,inthesensethatitextractsall\n",
      "theinformationfromtheselectedfeaturesbeforeaddingnewones.Thisleads\n",
      "tohigheraccuracywhileusinglessfeaturesaswasshowninourexperiments\n",
      "onimageclasLastly,ShareBoostcomeswiththeoreticalguarantees.\n",
      "Finally,wementionthatfeaturesharingismerelyonewayfortransferringin-\n",
      "formationacrossclasses[32]andseveralalternativewayshavebeenproposed\n",
      "intheliteraturesuchastargetembedding[18,4],sharedhiddenstructure[22,\n",
      "1],sharedprototypes[27],orsharingunderlyingmetric[38].\n",
      "4\n",
      "2\n",
      "TheShareBoostAlgorithm\n",
      "ShareBoostisaforwardgreedyselectionapproachforsolvingeqn.(4).\n",
      "Usually,inagreedyapproach,weupdatetheweightofonefeatureatatime.\n",
      "Now,wewillupdateonecolumnofWatatime(sincethedesiredsparsityis\n",
      "overcolumns).Wewillchoosethecolumnthatmaximizesthe`1normofthe\n",
      "correspondingcolumnofthegradientofthelossatW.SinceWisamatrixwe\n",
      "havethatrL(W)isamatrixofL.DenotebyrrL(W)ther?thcolumnofrL(W\n",
      "),?ofthepartialderivatives?@L(W)@L(W)thatis,thevector@W1,r,.\n",
      "..,@Wk,r.Astandardcalculationshowsthat@L(W)1XX=?c(x,y)xr\n",
      "(1[q=c]@Wq,rm\n",
      "1[q=y])\n",
      "(x,y)2Sc2Y\n",
      "where\n",
      "e1[c6=y](Wx)y+(Wx)c.1[y06=y](Wx)y+(Wx)y0y02Ye\n",
      "?c(x,y)=P\n",
      "PNotethat=1forall(x,y).Therefore,wecanrewrite,c?c(x,y)P1x\n",
      "(?(x,y)1[q=y]).Basedontheabovewehave(x,y)rqmkrrL(W)k1=\n",
      "1XXxr(?q(x,y)m\n",
      "1[q=y]).\n",
      "(6)@L(W)@Wq,r\n",
      "=\n",
      "(7)\n",
      "q2Y(x,y)\n",
      "Finally,afterchoosingthecolumnforwhichkrrL(W)k1ismaximized,we\n",
      "re-optimizeallthecolumnsofWwhichwereselectedsofar.Theresulting\n",
      "algorithmisgiveninAlgorithm1.Algorithm1ShareBoost1:Initialize:W=\n",
      "6\n",
      "\n",
      "0;I=;2:fort=1,2,...,Tdo3:Foreachclasscandexample(x,y)?c\n",
      "(x,y)asineqn.(6)4:Choosefeaturerthatmaximizestheright-handsideof\n",
      "eqn.(7)5:II[\n",
      "f\n",
      "r\n",
      "g\n",
      "6:SetWargminWL(W)s.t.W?,i=0foralli2/I7:end\n",
      "forTheruntimeofShareBoostisasfollows.Steps3-5requiresO(mdk).Step\n",
      "6isaconvexoptimizationproblemintkvariablesandcanbeperformedusing\n",
      "variousmethods.pInourexperiments,weusedNesterov?sacceleratedgradient\n",
      "method[25]whoseruntimeisO(mtk/?)forasmoothpobjective,where?is\n",
      "thedesiredaccuracy.Therefore,theoverallruntimeisO(Tmdk+T2mk/\n",
      "?).Itisinterestingtocomparethisruntimetothecomplexityofminimizing\n",
      "themixed-normregularizationobjectivegivenineqn.(5).Sincetheobjective\n",
      "isnolongersmooth,theruntimeofusingNesterov?sacceleratedmethodwould\n",
      "beO(mdk/?)whichcanbemuchlargerthantheruntimeofShareBoostwhen\n",
      "dT.2.1\n",
      "VariantsofShareBoost\n",
      "WenowdescribeseveralvariantsofShareBoost.Theanalysiswepresentin\n",
      "Section4canbeeasilyadaptedforthesevariantsaswell.ModifyingtheGreedy\n",
      "ChoiceRuleShareBoostchoosesthefeaturerwhichmaximizesthe`1normof\n",
      "ther-thcolumnofthegradientmatrix.Ouranalysisshowsthatthischoice\n",
      "leadstoatdecreaseoftheobjectivefunction.However,onecaneasily\n",
      "developotherwaysforchoosingafeaturewhichmaypotentiallyleadtoaneven\n",
      "largerdecreaseoftheobjective.Forexample,wecanchooseafeaturerthat\n",
      "minimizesL(W)overmatricesWwithsupportofI[\n",
      "f\n",
      "r\n",
      "g\n",
      ".Thiswillleadtothe\n",
      "maximalpossibledecreaseoftheobjectivefunctionatthecurrentiteration.Of\n",
      "course,theruntimeofchoosingrwillnowbemuchlarger.Someintermediate\n",
      "optionsaretochooserthatminimizesmin?2RW+?rrL(W)ortochooser\n",
      "thatminimizesminw2RkW+we?r,wheree?ristheall-zerorowvectorexcept\n",
      "1inther?thposition.5\n",
      "SelectingaGroupofFeaturesataTimeInsomesituations,featurescanbe\n",
      "dividedintogroupswheretheruntimeofcalculatingasinglefeatureineach\n",
      "groupisalmostthesameastheruntimeofcalculatingallfeaturesinthegroup.\n",
      "Insuchcases,itmakessensetochoosegroupsoffeaturesateachiteration\n",
      "ofPShareBoost.Thiscanbeeasilydonebysimplychoosingthegroupoffeatures\n",
      "Jthatmaximizesj2JkrjL(W)k1.\n",
      "?k)AddingRegularizationOuranalysisimpliesthatwhen|S|is\n",
      "cantlylargerthanO(TthenShareBoostwillnotovWhenthisisnotthe\n",
      "case,wecanincorporateregularizationintheobjectiveofShareBoostinorder\n",
      "topreventovOnesimplewayPisto2addtotheobjectivefunction\n",
      "L(W)aFrobeniusnormregularizationtermoftheformisaregi,jWi,j,where\n",
      "ularizationparameter.Itiseasytoverifythatthisisasmoothandconvex\n",
      "functionandthereforewecaneasilyadaptShareBoosttodealwiththisregu-\n",
      "larizedobjective.Itisalsopossibletorelyonothernormssuchasthe`1norm\n",
      "orthe`1/`1mixed-norm.However,thereisonetechnicalityduetothefact\n",
      "thatthesenormsarenotsmooth.Wecanovercomethisproblemby\n",
      "smoothapproximationstothesenorms.Themainideaistonotethatfor\n",
      "ascalarawehave|a|=max\n",
      "f\n",
      "a,a\n",
      "g\n",
      "andthereforewecanrewritetheafore-\n",
      "mentionednormsusingmaxandsumoperations.Then,wecanreplaceeach\n",
      "7\n",
      "\n",
      "maxexpressionwithitssoft-maxcounterpartandobtainasmoothversionof\n",
      "theoverallnorm?Pfunction.Forexample,?asmoothversionofthe`1/`1norm\n",
      "Pdk1Wi,j+eWi,j),where1controlsthewillbekWk1,1?j=1\n",
      "logi=1(ebetweenqualityofapproximationandsmoothness.\n",
      "3\n",
      "Non-LinearPredictionRules\n",
      "WenowdemonstratehowShareBoostcanbeusedforlearningnon-linear\n",
      "predictors.ThemainideaissimilartotheapproachtakenbyBoostingand\n",
      "SVM.Thatis,weconstructanon-linearpredictorbymappingtheoriginal\n",
      "featuresintoahigherdimensionalspaceandthenlearningalinearpredictorin\n",
      "thatspace,whichcorrespondstoanon-linearpredictorovertheoriginalfeature\n",
      "space.Toillustratethisideawepresenttwoconcretemappings.Theis\n",
      "thedecisionstumpsmethodwhichiswidelyusedbyBoostingalgorithms.The\n",
      "secondapproachshowshowtouseShareBoostforlearningpiece-wiselinear\n",
      "predictorsandisinspiredbythesuper-vectorsconstructionrecentlydescribed\n",
      "in[40].3.1\n",
      "ShareBoostwithDecisionStumps\n",
      "Letv2Rpbetheoriginalfeaturevectorrepresentinganobject.Adecision\n",
      "stumpisabinaryfeatureoftheform1[vi??],forsomefeaturei2\n",
      "f\n",
      "1,..\n",
      ".,p\n",
      "g\n",
      "andthreshold?2R.Toconstructanon-linearpredictorwecanmap\n",
      "eachobjectvintoafeature-vectorxthatcontainsallpossibledecisionstumps.\n",
      "Naturally,thedimensionalityofxisverylarge(infact,canevenbeand\n",
      "calculatingStep4ofShareBoostmaytakeforever.Luckily,asimpletrickyields\n",
      "ancientsolution.Firstnotethatforeachi,allstumpfeaturescorresponding\n",
      "toicangetatmostm+1valuesonatrainingsetofsizem.Therefore,ifwe\n",
      "sortthevaluesofvioverthemexamplesinthetrainingset,wecancalculate\n",
      "thevalueoftheright-handsideofeqn.(7)forallpossiblevaluesof?intotal\n",
      "timeofO(m).Thus,ShareBoostcanbeimplementedtlywithdecision\n",
      "stumps.2\n",
      "3.2\n",
      "LearningPiece-wiseLinearPredictorswithShareBoost\n",
      "1.8\n",
      "1.6\n",
      "1.4\n",
      "Tomotivateournextconstructionletusconsiderasimpleonedimen-\n",
      "sionalfunctionestimationproblem.Givensample(x1,yi),...,(xm,ym)\n",
      "wewouldliketoafunctionf:R!Rsuchthatf(xi)?yiforalli.Theclass\n",
      "ofpiece-wiselinearfunctionscanbeagoodcandidatefortheapproximation\n",
      "functionf.SeeforexampleanillustrationinFig.1.Infact,itiseasytoverify\n",
      "thatallsmoothfunctionscanbeapproximatedbypieceFigure1:Motivating\n",
      "supervecwiselinearfunctions(seeforexamplethediscussionin[40]).Intors.\n",
      "general,wecanPqexpresspiece-wiselinearvector-valuedfunctionsasf(v)=\n",
      "vjk<rj](huj,vi+bj),whereqisj=11[kv1.2\n",
      "1\n",
      "0.8\n",
      "0.6\n",
      "8\n",
      "\n",
      "0.4\n",
      "0.2\n",
      "0\n",
      "6\n",
      "0\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "2.5\n",
      "3\n",
      "3.5\n",
      "4\n",
      "4.5\n",
      "5\n",
      "thenumberofpieces,(uj,bj)representsthelinearfunctioncorrespondingto\n",
      "piecej,and(vj,rj)representsthecenterandradiusofpiecej.Thisexpression\n",
      "canbealsowrittenasalinearfunctionoveratdomain,f(v)=hw,(v)i\n",
      "where(v)=[1[kv\n",
      "v1k<r1][v,1],...,1[kv\n",
      "vqk<rq][v,1]].\n",
      "Inthecaseoflearningamulticlasspredictor,weshalllearnapredictorv7!\n",
      "W(v),whereWwillbeakbydim((v))matrix.ShareBoostcanbeusedfor\n",
      "learningW.Furthermore,wecanapplythevariantofShareBoostdescribed\n",
      "inSection2.1tolearnapiece-wiselinearmodelwithfewpieces(thatis,each\n",
      "groupoffeatureswillcorrespondtoonepieceofthemodel).Inpractice,we\n",
      "alargesetofcandidatecentersbyapplyingsomeclusteringmethodto\n",
      "thetrainingexamples,andsecondweasetofpossibleradiusesbytaking\n",
      "valuesofquantilesfromthetrainingexamples.Then,wetrainShareBoostsoas\n",
      "tochooseamulticlasspredictorthatonlyusefewpairs(vj,rj).Theadvantage\n",
      "ofusingShareBoosthereisthatwhileitlearnsanon-linearmodelitwilltryto\n",
      "amodelwithfewlinear?pieces?,whichisadvantageousbothintermsof\n",
      "testruntimeaswellasintermsofgeneralizationperformance.\n",
      "4\n",
      "Analysis\n",
      "InthissectionweprovideformalguaranteesfortheShareBoostalgorithm.\n",
      "Theproofsaredeferredtotheappendix.Weshowthatifthealgorithm\n",
      "hasmanagedtoamatrixWwithasmallnumberofnon-zerocolumnsand\n",
      "asmalltrainingerror,thenthegeneralizationerrorofWisalsosmall.The\n",
      "boundbelowisintermsofthe01loss.Arelatedbound,whichisgivenin\n",
      "termsoftheconvexlossfunction,isdescribedin[39].Theorem1Supposethat\n",
      "theShareBoostalgorithmrunsforTiterationsandletWbeitsoutputmatrix.\n",
      "Then,withprobabilityofatleast1overthechoiceofthetrainingsetSwe\n",
      "havethats!Tklog(Tk)log(k)+Tlog(d)+log(1/)P[hW(x)6=y]\n",
      "?P[hW(x)6=y]+O|S|(x,y)?D(x,y)?SNext,weanalyzethesparsity\n",
      "guaranteesofShareBoost.Asmentionedpreviously,exactlysolvingeqn.(4)\n",
      "9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isknowntobeNPhard.Thefollowingmaintheoremgivesaninteresting\n",
      "approximationguarantee.Ittellsusthatifthereexistsanaccuratesolution\n",
      "withsmall`1,1norm,thentheShareBoostalgorithmwillagoodsparse\n",
      "solution.?Theorem2Let?>?0andletW?beanarbitrarymatrix.Assume\n",
      "thatweruntheShareBoostalgorithmforT=41?kW?k21,1iterationsand\n",
      "letWbetheoutputmatrix.Then,kWk1,0?TandL(W)?L(W?)+?.\n",
      "5\n",
      "Experiments\n",
      "Inthissectionwedemonstratethemerits(andpitfalls)ofShareBoostby\n",
      "comparingittoalternativealgorithmsintscenarios.Theexperi-\n",
      "mentthefeaturesharingpropertyofShareBoost.Weperformex-\n",
      "perimentswithanOCRdatasetanddemonstrateamildgrowthofthenumber\n",
      "offeaturesasthenumberofclassesgrowsfrom2to36.Thesecondexperiment\n",
      "showsthatShareBoostcanconstructpredictorswithstate-of-the-artaccuracy\n",
      "whileonlyrequiringfewfeatures,whichamountstofastpredictionruntime.\n",
      "Thethirdexperiment,whichduetolackofspaceisdeferredtoAppendixA.3,\n",
      "comparesShareBoosttomixed-normregularizationandtotheJointBoostal-\n",
      "gorithmof[34].Wefollowthesameexperimentalsetupasin[12].Themain\n",
      "isthatShareBoostoutperformsthemixed-normregularizationmethod\n",
      "whentheoutputpredictorneedstobeverysparse,whilemixed-normregular-\n",
      "izationcanbebetterintheregimeofratherdensepredictors.Wealsoshowthat\n",
      "ShareBoostisbothfasterandmoreaccuratethanJointBoost.FeatureSharing\n",
      "ThemainmotivationforderivingtheShareBoostalgorithmistheneedfora\n",
      "multiclasspredictorthatusesonlyfewfeatures,andinparticular,thenumber\n",
      "offeaturesshouldincreaseslowlywiththenumberofclasses.Todemonstrate\n",
      "thispropertyofShareBoostweexperimentedwiththeChar74kdatasetwhich\n",
      "consistsofimagesofdigitsand7\n",
      "letters.WetrainedShareBoostwiththenumberofclassesvaryingfrom2\n",
      "classestothe36classescorrespondingtothe10digitsand26capitalletters.We\n",
      "calculatedhowmanyfeatureswererequiredtoachieveacertainxedaccuracy\n",
      "asafunctionofthenumberofclasses.Duetolackofspace,thedescriptionof\n",
      "thefeaturespaceisdeferredtotheappendix.350\n",
      "300\n",
      "250\n",
      "#features\n",
      "WecomparedShareBoosttothe1-vs-restapproach,whereinthelatter,we\n",
      "trainedeachbinarycusingthesamemechanismasusedbyShareBoost.\n",
      "Namely,weminimizethebinarylogisticlossusingagreedyalgorithm.Both\n",
      "methodsaimatconstructingsparsepredictorsusingthesamegreedyapproach.\n",
      "ThebetweenthemethodsisthatShareBoostselectsfeaturesina\n",
      "sharedmannerwhilethe1-vs-restapproachselectsfeaturesforeachbinary\n",
      "problemseparately.InFig.2weplottheoverallnumberoffeaturesrequired\n",
      "bybothmethodstoachieveaaccuracyonthetestsetasafunctionofthe\n",
      "numberofclasses.Ascanbeeasilyseen,theincreaseinthenumberofrequired\n",
      "featuresismildforShareBoostbuttforthe1-vs-restapproach.\n",
      "200\n",
      "10\n",
      "\n",
      "150\n",
      "100\n",
      "50\n",
      "00\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "#classes\n",
      "Figure2:Thenumberoffeatures\n",
      "requiredtoachieveaaccuracyasafunctionofthenumberofclasses\n",
      "forShareBoost(dashed)andthe1-vs-rest(solid-circles).Thebluelinesarefor\n",
      "atargeterrorof20%andthegreenlinesarefor8%.\n",
      "ConstructingfastandaccuratepredictorsThegoalofourthisexperimentis\n",
      "toshowthatShareBoostachievesstate-ofthe-artperformancewhileconstruct-\n",
      "ingveryfastpredictors.WeexperimentedwiththeMNISTdigitdataset,which\n",
      "consistsofatrainingsetof60,000digitsrepresentedbycenteredsizenormalized\n",
      "28?28images,andatestsetof10,000digits.TheMNISTdatasethasbeenex-\n",
      "tensivelystudiedandisconsideredastandardtestformulticlassof\n",
      "handwrittendigits.TheSVMalgorithmwithGaussiankernelachievesanerror\n",
      "rateof1.4%onthetestset.Theerrorrateachievedbythemostadvancedalgo-\n",
      "rithmsarebelow1%ofthetestset.Seehttp://yann.lecun.com/exdb/mnist/.In\n",
      "particular,thetopMNISTperformer[6]usesafeed-forwardNeural-Netwith7.6\n",
      "millionconnectionswhichroughlytranslatesto7.6millionmultiply-accumulate\n",
      "(MAC)operationsatrun-timeaswell.Duringtraining,geometricallydistorted\n",
      "versionsoftheoriginalexamplesweregeneratedinordertoexpandthetraining\n",
      "setfollowing[30]whointroducedawarpingschemeforthatpurpose.Thetop\n",
      "performanceerrorratestandsat0.35%atarun-timecostof7.6millionMAC\n",
      "pertestexampleTheerror-rateofShareBoostwithT=266roundsstandson\n",
      "0.71%usingtheoriginaltrainingsetand0.47%withtheexpandedtrainingset\n",
      "of360,000examplesgeneratedbyaddingedeformedinstancesperoriginal\n",
      "exampleandwithT=305rounds.Fig.3displaystheconvergencecurveof\n",
      "error-rateasafunctionofthenumberofrounds.Notethatthetrainingerror\n",
      "ishigherthanthetesterror.Thisfollowsfromthefactthatthetrainingset\n",
      "wasexpandedwith5fairlystrongdeformedversionsofeachinput,usingthe\n",
      "methodin[30].Ascanbeseen,lessthanFigure3:Thetesterrorrateof75\n",
      "featuresstoobtainanerrorrateof<1%.1.5\n",
      "TrainTest\n",
      "1\n",
      "0.50.47\n",
      "050\n",
      "100\n",
      "11\n",
      "\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "Rounds\n",
      "ShareBoostontheMNISTdataset\n",
      "Intermsofrun-timeonatestimage,thesystemrequires305con-asa\n",
      "functionofthenumberofvolutionsof7?7templatesand540dot-productoper-\n",
      "ationswhichroundsusingpatchbasedfeatures.totalstoroughly3.3?106MAC\n",
      "operations?comparedtoaround7.5?106MACoperationsofthetopMNIST\n",
      "performer.Theerrorrateof0.47%isbetterthanthatreportedby[10]whoused\n",
      "a1-vs-allSVMwitha9-degreepolynomialkernelandwithanexpandedtraining\n",
      "setof780,000examples.Thenumberofsupportvectors(accumulatedoverthe\n",
      "tenseparatebinaryclassers)was163,410givingrisetoarun-timeof21fold\n",
      "comparedtoShareBoost.Moreover,duetothefastconvergenceofShareBoost,\n",
      "75roundsareenoughforachievinglessthan1%error.Acknowledgements:We\n",
      "wouldliketothankItayErlichandZoharBar-Yehudafortheircontributionto\n",
      "theimplementationofShareBoostandtoRonenKatzforhelpfulcomments.\n",
      "8\n",
      "2References\n",
      "[1]Y.Amit,M.Fink,N.Srebro,andS.Ullman.Uncoveringsharedstructures\n",
      "inmulticlassInInternationalConferenceonMachineLearning,\n",
      "2007.[2]A.Argyriou,T.Evgeniou,andM.Pontil.Multi-taskfeaturelearning.\n",
      "InNIPS,pages41?48,2006.[3]F.R.Bach.Consistencyofthegrouplasso\n",
      "andmultiplekernellearning.J.ofMachineLearningResearch,9:1179?1225,\n",
      "2008.[4]S.Bengio,J.Weston,andD.Grangier.Labelembeddingtreesfor\n",
      "largemulti-classtasks.InNIPS,2011.[5]E.J.CandesandT.Tao.Decoding\n",
      "bylinearprogramming.IEEETrans.onInformationTheory,51:4203?4215,\n",
      "2005.[6]D.C.Ciresan,U.Meier,L.MariaG.,andJ.Schmidhuber.Deep\n",
      "bigsimpleneuralnetsexcelonhandwrittendigitrecognition.CoRR,2010.\n",
      "[7]K.CrammerandY.Singer.Ultraconservativeonlinealgorithmsformul-\n",
      "ticlassproblems.JournalofMachineLearningResearch,3:951?991,2003.[8]\n",
      "A.Daniely,S.Sabato,S.Ben-David,andS.Shalev-Shwartz.Multiclasslearn-\n",
      "abilityandtheermprinciple.InCOLT,2011.[9]G.Davis,S.Mallat,andM.\n",
      "Avellaneda.Greedyadaptiveapproximation.JournalofConstructiveApprox-\n",
      "imation,13:57?98,1997.[10]D.DecosteandS.Bernhard.Traininginvariant\n",
      "supportvectormachines.Mach.Learn.,46:161?190,2002.[11]D.L.Donoho.\n",
      "12\n",
      "\n",
      "Compressedsensing.InTechnicalReport,StanfordUniversity,2006.[12]J.\n",
      "DuchiandY.Singer.Boostingwithstructuralsparsity.InProc.ICML,pages\n",
      "297?304,2009.[13]R.O.DudaandP.E.Hart.Patternand\n",
      "SceneAnalysis.Wiley,1973.[14]M.Fink,S.Shalev-Shwartz,Y.Singer,and\n",
      "S.Ullman.Onlinemulticlasslearningbyinterclasshypothesissharing.InIn-\n",
      "ternationalConferenceonMachineLearning,2006.[15]Y.FreundandR.E.\n",
      "Schapire.Ashortintroductiontoboosting.J.ofJapaneseSocietyforAI,pages\n",
      "771?780,1999.[16]Y.FreundandR.E.Schapire.Adecision-theoreticgeneral-\n",
      "izationofon-linelearningandanapplicationtoboosting.JournalofComputer\n",
      "andSystemSciences,pages119?139,1997.[17]T.J.HastieandR.J.Tibshirani.\n",
      "Generalizedadditivemodels.Chapman&Hall,1995.[18]D.Hsu,S.M.Kakade,\n",
      "J.Langford,andT.Zhang.Multi-labelpredictionviacompressedsensing.In\n",
      "NIPS,2010.[19]J.HuangandT.Zhang.Thebofgroupsparsity.Annals\n",
      "ofStatistics,38(4),2010.[20]J.Huang,T.Zhang,andD.N.Metaxas.Learning\n",
      "withstructuredsparsity.InICML,2009.[21]G.R.G.Lanckriet,N.Cristianini,\n",
      "P.L.Bartlett,L.ElGhaoui,andM.I.Jordan.Learningthekernelmatrixwith\n",
      "programming.J.ofMachineLearningResearch,pages27?72,2004.\n",
      "[22]Y.L.LeCun,L.Bottou,Y.Bengio,andP.Gradient-basedlearn-\n",
      "ingappliedtodocumentrecognition.ProceedingsofIEEE,pages2278?2324,\n",
      "1998.[23]A.MajumdarandR.K.Ward.FastgroupsparseElec-\n",
      "tricalandComputerEngineering,CanadianJournalof,34(4):136?144,2009.\n",
      "[24]B.Natarajan.Sparseapproximatesolutionstolinearsystems.SIAMJ.\n",
      "Computing,pages227?234,1995.[25]Y.NesterovandI.U.E.Nesterov.Intro-\n",
      "ductorylecturesonconvexoptimization:Abasiccourse,volume87.Springer\n",
      "Netherlands,2004.[26]A.Quattoni,X.Carreras,M.Collins,andT.Darrell.\n",
      "Anetprojectionforl1,infinityregularization.InICML,page108,2009.\n",
      "[27]A.Quattoni,M.Collins,andT.Darrell.Transferlearningforimageclas-\n",
      "withsparseprototyperepresentations.InCVPR,2008.[28]R.E.\n",
      "SchapireandY.Singer.Improvedboostingalgorithmsusingence-rated\n",
      "predictions.MachineLearning,37(3):1?40,1999.[29]S.Shalev-Shwartz,T.\n",
      "Zhang,andN.Srebro.Tradingaccuracyforsparsityinoptimizationproblems\n",
      "withsparsityconstraints.SiamJournalonOptimization,20:2807?2832,2010.\n",
      "[30]P.Y.Simard,DaveS.,andJohnC.Platt.Bestpracticesforconvolutional\n",
      "neuralnetworksappliedtovisualdocumentanalysis.DocumentAnalysisand\n",
      "Recognition,2003.[31]B.Taskar,C.Guestrin,andD.Koller.Max-margin\n",
      "markovnetworks.InNIPS,2003.[32]S.Thrun.Learningtolearn:Intro-\n",
      "duction.KluwerAcademicPublishers,1996.[33]R.Tibshirani.Regression\n",
      "shrinkageandselectionviathelasso.J.Royal.Statist.SocB.,58(1):267?288,\n",
      "1996.[34]A.Torralba,K.P.Murphy,andW.T.Freeman.Sharingvisual\n",
      "featuresformulticlassandmultiviewobjectdetection.IEEETransactions\n",
      "onPatternAnalysisandMachineIntelligence(PAMI),pages854?869,2007.\n",
      "[35]J.A.TroppandA.C.Gilbert.Signalrecoveryfromrandommeasurements\n",
      "viaorthogonalmatchingpursuit.InformationTheory,IEEETransactionson,\n",
      "53(12):4655?4666,2007.[36]B.ATurlach,W.NV.,andStephenJWright.\n",
      "Simultaneousvariableselection.Technometrics,47,2000.[37]V.N.Vapnik.\n",
      "StatisticalLearningTheory.Wiley,1998.[38]E.Xing,A.Y.Ng,M.Jordan,\n",
      "13\n",
      "\n",
      "andS.Russell.Distancemetriclearning,withapplicationtoclusteringwith\n",
      "side-information.InNIPS,2003.[39]T.Zhang.Class-sizeindependentgener-\n",
      "alizationanalysisofsomediscriminativemulti-categoryInNIPS,\n",
      "2004.[40]X.Zhou,K.Yu,T.Zhang,andT.Huang.Imageusing\n",
      "super-vectorcodingoflocalimagedescriptors.ComputerVision?ECCV2010,\n",
      "pages141?154,2010.\n",
      "9\n",
      "14\n",
      "\n",
      "PP3965.pdf\n",
      "PP3965.pdf 13\n",
      "NetworkFlowAlgorithmsforStructuredSparsity\n",
      "Authoredby:\n",
      "FrancisR.Bach\n",
      "JulienMairal\n",
      "GuillaumeR.Obozinski\n",
      "RodolpheJenatton\n",
      "Abstract\n",
      "Weconsideraclassoflearningproblemsthatinvolveastructured\n",
      "sparsity-inducingnormasthesumof$ell\n",
      "infty$-normsovergroups\n",
      "ofvariables.Whereasalotofhasbeenputindevelopingfastopti-\n",
      "mizationmethodswhenthegroupsaredisjointorembeddedinaspe\n",
      "hierarchicalstructure,weaddressherethecaseofgeneraloverlapping\n",
      "groups.Tothisend,weshowthatthecorrespondingoptimizationprob-\n",
      "lemisrelatedtonetworkwoptimization.Moreprecisely,theproximal\n",
      "problemassociatedwiththenormweconsiderisdualtoaquadraticmin-\n",
      "costwproblem.Weproposeantprocedurewhichcomputesits\n",
      "solutionexactlyinpolynomialtime.Ouralgorithmscalesuptomillions\n",
      "ofgroupsandvariables,andopensupawholenewrangeofapplications\n",
      "forstructuredsparsemodels.Wepresentseveralexperimentsonimage\n",
      "andvideodata,demonstratingtheapplicabilityandscalabilityofourap-\n",
      "proachforvariousproblems.\n",
      "1PaperBody\n",
      "Sparselinearmodelshavebecomeapopularframeworkfordealingwithvarious\n",
      "unsupervisedandsupervisedtasksinmachinelearningandsignalprocessing.\n",
      "Insuchmodels,linearcombinationsofsmallsetsofvariablesareselectedtode-\n",
      "scribethedata.Regularizationbythe?1-normhasemergedasapowerfultool\n",
      "foraddressingthiscombinatorialvariableselectionproblem,relyingonbotha\n",
      "well-developedtheory(see[1]andreferencestherein)andientalgorithms\n",
      "[2,3,4].The?1-normprimarilyencouragessparsesolutions,regardlessofthe\n",
      "potentialstructuralrelationships(e.g.,spatial,temporalorhierarchical)exist-\n",
      "ingbetweenthevariables.Muchhasrecentlybeendevotedtodesigning\n",
      "sparsity-inducingregularizationscapableofencodinghigher-orderinformation\n",
      "aboutallowedpatternsofnon-zerocots[5,6,7,8,9,10],withsuccessful\n",
      "applicationsinbioinformatics[6,11],topicmodeling[12]andcomputervision\n",
      "[9,10].Byconsideringsumsofnormsofappropriatesubsets,orgroups,ofvari-\n",
      "1\n",
      "\n",
      "ables,theseregularizationscontrolthesparsitypatternsofthesolutions.The\n",
      "underlyingoptimizationproblemisusuallyinpartbecauseitinvolves\n",
      "nonsmoothcomponents.Proximalmethodshaveproventobeectiveinthis\n",
      "context,essentiallybecauseoftheirfastconvergenceratesandtheirscalability\n",
      "[3,4].Whilethesettingswherethepenalizedgroupsofvariablesdonotoverlap\n",
      "orareembeddedinatreeshapedhierarchy[12]havealreadybeenstudied,regu-\n",
      "larizationswithgeneraloverlappinggroupshave,tothebestofourknowledge,\n",
      "neverbeenaddressedwithproximalmethods.Thispapermakesthefollow-\n",
      "ingcontributions:?Itshowsthattheproximaloperatorassociatedwiththe\n",
      "structurednormweconsidercanbe??\n",
      "Contributedequally.Laboratoired?Informatiquedel?EcoleNormaleSup?erieure\n",
      "(INRIA/ENS/CNRSUMR8548)\n",
      "1\n",
      "computedwithafastandscalableprocedurebysolvingaquadraticmin-cost\n",
      "wproblem.?Itshowsthatthedualnormofthesparsity-inducingnormwe\n",
      "considercanalsobeevaluatedtly,whichenablesustocomputeduality\n",
      "gapsforthecorrespondingoptimizationproblems.?Itdemonstratesthatour\n",
      "methodisrelevantforvariousapplications,fromvideobackgroundsubtraction\n",
      "toestimationofhierarchicalstructuresfordictionarylearningofnaturalimage\n",
      "patches.\n",
      "2\n",
      "StructuredSparseModels\n",
      "Weconsiderinthispaperconvexoptimizationproblemsoftheformminf\n",
      "(w)+??(w),\n",
      "w?Rp\n",
      "(1)\n",
      "wheref:Rp?Risaconvextiablefunctionand?:Rp?R\n",
      "isaconvex,nonsmooth,sparsity-inducingregularizationfunction.Whenone\n",
      "knowsapriorithatthesolutionsofthislearningproblemhaveonlyafewnon-\n",
      "zerocots,?isoftenchosentobethe?1-norm(see[1,2]).Whenthese\n",
      "cotsareorganizedingroups,apenaltyencodingexplicitlythisprior\n",
      "knowledgecanimprovethepredictionperformanceand/orinterpretabilityof\n",
      "thelearnedmodels[13,14].DenotingbyGasetofgroupsofindices,sucha\n",
      "penaltymightforexampletaketheform:XX?(w),?gmax|wj|=?gkwg\n",
      "k?,(2)g?G\n",
      "j?g\n",
      "g?G\n",
      "wherewjisthej-thentryofwforjin[1;p],\n",
      "f\n",
      "1,...,p\n",
      "g\n",
      ",thevector\n",
      "wginR|g|recordsthecotsofwindexedbyginG,andthescalars\n",
      "?garepositiveweights.Asumof?2-normsisalsousedintheliterature\n",
      "[7],butthe??-normispiecewiselinear,apropertythatwetakeadvantage\n",
      "ofinthispaper.NotethatwhenGisthesetofsingletonsof[1;p],weget\n",
      "backthe?1-norm.IfGisamoregeneralpartitionof[1;p],variablesare\n",
      "selectedingroupsratherthanindividually.Whenthegroupsoverlap,?isstill\n",
      "anormandsetsgroupsofvariablestozerotogether[5].Thelattersettinghas\n",
      "beenconsideredforhierarchies[7,11,15],andthenextendedtogeneral\n",
      "2\n",
      "\n",
      "groupstructures[5].1SolvingEq.(1)inthiscontextbecomeschallengingand\n",
      "isthetopicofthispaper.FollowingJenattonetal.[12]whotackledthe\n",
      "caseofhierarchicalgroups,weproposetoapproachthisproblemwithproximal\n",
      "methods,whichwenowintroduce.2.1\n",
      "ProximalMethods\n",
      "Inanutshell,proximalmethodscanbeseenasanaturalextensionof\n",
      "gradient-basedtechniques,andtheyarewellsuitedtominimizingthesumf\n",
      "+??oftwoconvexterms,asmoothfunctionf?continuouslytiablewith\n",
      "Lipschitz-continuousgradient?andapotentiallynon-smoothfunction??(see\n",
      "[16]andreferencestherein).Ateachiteration,thefunctionfislinearizedat\n",
      "thecurrentestimatew0andtheso-calledproximalproblemhastobesolved:\n",
      "Lminf(w0)+(w?w0)??f(w0)+??(w)+kw?w0k22.w?Rp2The\n",
      "quadratictermkeepsthesolutioninaneighborhoodwherethecurrentlinear\n",
      "approximationholds,andL>0isanupperboundontheLipschitzconstantof\n",
      "?f.Thisproblemcanberewrittenas12minku?wk2+???(w),(3)w?Rp2\n",
      "with??,?/L,andu,w0?L1?f(w0).Wecallproximaloperatorassociated\n",
      "withtheregularization???thefunctionthatmapsavectoruinRpontothe\n",
      "(unique,bystrongconvexity)solutionw?ofEq.(3).Simpleproximalmethods\n",
      "usew?asthenextiterate,butacceleratedvariants[3,4]arealsobasedon\n",
      "theproximaloperatorandrequiretosolveproblem(3)exactlyandtly\n",
      "toenjoytheirfastconvergencerates.Notethatwhen?isthe?1-norm,the\n",
      "solutionofEq.(3)isobtainedbysoft-thresholding[16].Theapproachwede-\n",
      "velopintherestofthispaperextends[12]tothecaseofgeneraloverlapping\n",
      "groupswhen?isaweightedsumof??-norms,broadeningtheapplication\n",
      "oftheseregularizationstoawiderspectrumofproblems.21Notethatother\n",
      "typesofstructuredsparsemodelshavealsobeenintroduced,eitherthrougha\n",
      "tnorm[6],orthroughnon-convexcriteria[8,9,10].2Forhierarchies,\n",
      "theapproachof[12]appliesalsotothecaseofwhere?isaweightedsumof?2\n",
      "-norms.\n",
      "2\n",
      "3\n",
      "AQuadraticMin-CostFlowFormulation\n",
      "Inthissection,weshowthataconvexdualofproblem(3)forgeneralover-\n",
      "lappinggroupsGcanbereformulatedasaquadraticmin-costwproblem.We\n",
      "presentanientalgorithmtosolveitexactly,aswellasarelatedalgorithm\n",
      "tocomputethedualnormof?.Westartbyconsideringthedualformulation\n",
      "toproblem(3)introducedin[12],forthecasewhere?isasumof??-norms:\n",
      "Lemma1(Dualoftheproximalproblem[12])GivenuinRp,considerthe\n",
      "problemX1\n",
      "2minu??gs.t.?g?G,k?gk1???g\n",
      "2??Rp?|G|2\n",
      "and\n",
      "?gj=0ifj?/g,\n",
      "(4)\n",
      "g?G\n",
      "3\n",
      "\n",
      "where?=(?g)g?GisinRp?|G|,and?gjdenotesthej-thcoordinate\n",
      "ofthevector?g.Then,everyPsolution??=(??g)g?GofEq.(4)\n",
      "w?=u?g?G??g,wherew?isthesolutionofEq.(3).Withoutloss\n",
      "ofgenerality,3weassumefromnowonthatthescalarsujareallnon-negative,\n",
      "andweconstraintheentriesof?tobenon-negative.Wenowintroduceagraph\n",
      "modelingofproblem(4).3.1\n",
      "GraphModel\n",
      "LetGbeadirectedgraphG=(V,E,s,t),whereVisasetofvertices,E\n",
      "?V?Vasetofarcs,sasource,andtasink.Letcandc?betwofunctions\n",
      "onthearcs,c:E?Randc?:E?R+,wherecisacostfunctionandc?\n",
      "isanon-negativecapacityfunction.Awisanon-negativefunctiononarcs\n",
      "thatcapacityconstraintsonallarcs(thevalueofthewonanarc\n",
      "islessthanorequaltothearccapacity)andconservationconstraintsonall\n",
      "vertices(thesumofincomingwsatavertexisequaltothesumofoutgoing\n",
      "ws)exceptforthesourceandthesink.WeintroduceacanonicalgraphG\n",
      "associatedwithouroptimizationproblem,anduniquelycharacterizedbythe\n",
      "followingconstruction:(i)VistheunionoftwosetsofverticesVuandVgr,\n",
      "whereVucontainsexactlyonevertexforeachindexjin[1;p],andVgrcontains\n",
      "exactlyonevertexforeachgroupginG.Wethushave|V|=|G|+p.\n",
      "Forsimplicity,weidentifygroupsandindiceswiththeverticesofthegraph.(ii)\n",
      "ForeverygroupginG,Econtainsanarc(s,g).Thesearcshavecapacity??g\n",
      "andzerocost.(iii)ForeverygroupginG,andeveryindexjing,Econtains\n",
      "anarc(g,j)withzerocostandcapacity.Wedenoteby?gjthewon\n",
      "thisarc.(iv)Foreveryindexjin[1;p],Econtainsanarc(j,t)with\n",
      "capacityandacostcj,21(uj???j)2,where??jisthewon(j,t).Note\n",
      "thatbywconservation,wenecesPsarilyhave??j=g?G?gj.\n",
      "ExamplesofcanonicalgraphsaregiveninFigures1(a)-(c).Thews?\n",
      "gjassociatedwithGcannowbeidenwiththevariablesofproblem(4):\n",
      "indeed,thesumofthecostsontheedgesleadingtothesinkisequaltothe\n",
      "objectivefunctionof(4),whilethecapacitiesofthearcs(s,g)matchthecon-\n",
      "straintsoneachgroup.Thisshowsthatawminimizingthesumofthe\n",
      "costsonsuchagraphisequivalenttosolvingproblem(4).Whensomegroups\n",
      "areincludedinothers,thecanonicalgraphcanbetoyieldagraph\n",
      "withasmallernumberofedges.Sp,ifhandgaregroupswithh?g,\n",
      "theedges(g,j)forj?hcarryingaw?gjcanberemovedandreplacedbya\n",
      "singleedge(g,h)ofcapacityandPzerocost,carryingthewj?h?gj\n",
      ".ThisisillustratedinFigure1(d),withagraph?equivalentto\n",
      "theoneofFigure1(c).Thisdoesnotchangetheoptimalvalueof??,whichis\n",
      "thequantityofinterestforcomputingtheoptimalprimalvariablew?(aproof\n",
      "andaformaloftheseequivalentgraphsareavailableinalongertech-\n",
      "nicalreport[17]).Theseareusefulinpractice,sincetheyreduce\n",
      "thenumberofedgesinthegraphandimprovethespeedofthealgorithmswe\n",
      "arenowgoingtopresent.3Let??denoteasolutionofEq.(4).Optimality\n",
      "conditionsofEq.(4)derivedin[12]showthatforalljin[1;p],thesignsofthe\n",
      "non-zeroconts??gjforginGarethesameasthesignsoftheentriesuj\n",
      ".TosolveEq.(4),onecanthereforethesignsofthenegativevariablesuj\n",
      "4\n",
      "\n",
      ",thensolvethemodualformulation(withnon-negativevariables),which\n",
      "givesthemagnitudeoftheentries??gj(thesignsofthesebeingknown).\n",
      "3\n",
      "s\n",
      "s\n",
      "?g1+?g2+?g3???g\n",
      "?g1+?g2???g\n",
      "g?g1u1\n",
      "?g2\n",
      "g\n",
      "??2,c2\n",
      "?g1\n",
      "?g3\n",
      "u2??1,c1\n",
      "?h2+?h3???h\n",
      "u3\n",
      "?g2\n",
      "u1\n",
      "??3,c3\n",
      "h?h3\n",
      "?h2u2\n",
      "??1,c1\n",
      "u3\n",
      "??2,c2\n",
      "??3,c3\n",
      "t\n",
      "t\n",
      "(a)G=\n",
      "f\n",
      "g=\n",
      "f\n",
      "1,2,3\n",
      "gg\n",
      ".\n",
      "(b)G=\n",
      "f\n",
      "g=\n",
      "f\n",
      "1,2\n",
      "g\n",
      ",h=\n",
      "f\n",
      "2,3\n",
      "gg\n",
      ".\n",
      "s\n",
      "s?h2+?h3???h\n",
      "?g1+?g2+?g3???gg?g1u1\n",
      "u2??1,c1\n",
      "??2,c2\n",
      "g\n",
      "hg?h2?3\n",
      "?g2\n",
      "?h2+?h3???h\n",
      "?g1+?g2+?g3???g\n",
      "?g1\n",
      "?h3u3\n",
      "u1\n",
      "??3,c3\n",
      "h\n",
      "?g2+?h2\n",
      "?g3+?h3\n",
      "5\n",
      "\n",
      "u2??1,c1\n",
      "t\n",
      "?g2+?g3\n",
      "??2,c2\n",
      "u3??3,c3\n",
      "t\n",
      "(c)G=\n",
      "f\n",
      "g=\n",
      "f\n",
      "1,2,3\n",
      "g\n",
      ",h=\n",
      "f\n",
      "2,3\n",
      "gg\n",
      ".\n",
      "(d)G=\n",
      "f\n",
      "g=\n",
      "f\n",
      "1\n",
      "g\n",
      "?h,h=\n",
      "f\n",
      "2,3\n",
      "gg\n",
      ".\n",
      "Figure1:Graphrepresentationofsimpleproximalproblemswitht\n",
      "groupstructuresG.Thethreeindices1,2,3arerepresentedasgreysquares,\n",
      "andthegroupsg,hinGasreddiscs.Thesourceislinkedtoeverygroupg,h\n",
      "withrespectivemaximumcapacity??g,??handzerocost.Eachvariableujis\n",
      "linkedtothesinkt,withancapacity,andwithacostcj,12(uj???j)2.\n",
      "Allotherarcsinthegraphhavezerocostandcapacity.Theyrepresent\n",
      "inclusionrelationshipsin-betweengroups,andbetweengroupsandvariables.\n",
      "Thegraphs(c)and(d)correspondtoaspecialcaseoftree-structuredhierarchy\n",
      "inthesenseof[12].Theirmin-costowproblemsareequivalent.3.2\n",
      "ComputationoftheProximalOperator\n",
      "Quadraticmin-costwproblemshavebeenwellstudiedintheoperations\n",
      "researchliterature[18].Oneofthesimplestcases,whereGcontainsasingle\n",
      "groupg(?isthe??-norm)asinFigure1(a),canbesolvedbyanorthogonal\n",
      "projectiononthe?1-ballofradius??g.Ithasbeenshownthatsuchaprojection\n",
      "canbedoneinO(p)operations[18,19].Whenthegroupstructureisatree\n",
      "asinFigure1(d),theproblemcanbesolvedinO(pd)operations,wheredis\n",
      "thedepthofthetree[12,18].4Thegeneralcaseofoverlappinggroupsismore\n",
      "HochbaumandHonghaveshownin[18]thatquadraticmin-costw\n",
      "problemscanbereducedtoaspparametricwproblem,forwhich\n",
      "antalgorithmexists[20].5Whilethisgenericapproachcouldbeusedto\n",
      "solveEq.(4),weproposetouseAlgorithm1thatalsoexploitsthefactthatour\n",
      "graphshavenon-zerocostsonlyonedgesleadingtothesink.Asshowninthe\n",
      "technicalreport[17],ithasatlybetterperformanceinpractice.This\n",
      "algorithmclearlysharessomesimilaritieswithexistingapproachesinnetwork\n",
      "woptimizationsuchastheversionof[20]presentedin[21]that\n",
      "usesadivideandconquerstrategy.Moreover,wehavediscoveredafterthat\n",
      "thispaperwasacceptedforpublicationthatanequivalentalgorithmexistsfor\n",
      "minimizingconvexfunctionsoverpolymatroid4\n",
      "Whenrestrictedtothecasewhere?isasumof??-norms,theapproach\n",
      "of[12]isinfactsimilarto[18].Byon,aparametricwproblem\n",
      "consistsinsolving,foreveryvalueofaparameter,awproblemona\n",
      "graphwhosearccapacitiesdependonthisparameter.5\n",
      "4\n",
      "sets[22].Thisequivalence,however,requiresanon-trivialrepresentation\n",
      "ofstructuredsparsityinducingnormswithsubmodularfunctions,asrecently\n",
      "pointedoutby[23].Algorithm1Computationoftheproximaloperatorfor\n",
      "overlappinggroups.1:Inputs:u?Rp,asetofgroupsG,positiveweights\n",
      "(?g)g?G,and?(regularizationparameter).2:BuildtheinitialgraphG0\n",
      "6\n",
      "\n",
      "=(V0,E0,s,t)asexplainedinSection3.2.3:Computetheoptimalw:\n",
      "???computeFlow(V0,E0).4:Return:w=u???(optimalsolutionof\n",
      "theproximalproblem).FunctioncomputeFlow(V=Vu?Vgr,E)PPP1:\n",
      "Projectionstep:??argmin?j?Vu12(uj??j)2s.t.g?Vgr?g.j?Vu?j\n",
      "??2:ForallnodesjinVu,set?jtobethecapacityofthearc(j,t).3:\n",
      "wstep:Update(??j)j?Vubycomputingawonthegraph(V,\n",
      "E,s,t).4:if?j?Vus.t.??j6=?jthen5:Denoteby(s,V+)and(V\n",
      "?,t)thetwodisjointsubsetsof(V,s,t)separatedbytheminimum(s,t)-cut\n",
      "ofthegraph,andremovethearcsbetweenV+andV?.CallE+andE?\n",
      "thetworemainingdisjointsubsetsofEcorrespondingtoV+andV?.6:(??j\n",
      ")j?Vu+?computeFlow(V+,E+).7:(??j)j?Vu??computeFlow(V?,E?\n",
      ").8:endif9:Return:(??j)j?Vu.ThePintuitionbehindthisalgorithmisthe\n",
      "following:Theststeplooksforacandidatevaluefor??=g?G?gbysolving\n",
      "arelaxedversionofproblemEq.(4),wheretheconstraintsk?gk1???gare\n",
      "P??1??droppedandreplacedbyasingleonek?kg?G?g.Therelaxed\n",
      "problemonlydependson?2andcanbesolvedinlineartime.Bycallingits\n",
      "solution?,itprovidesalowerboundku??k2/2ontheoptimalcost.Then,\n",
      "thesecondsteptriestoafeasiblewoftheoriginalproblem(4)suchthat\n",
      "theresultingvector??matches?,whichisinfactawproblem[24].\n",
      "If??=?,thenthecostoftheowreachesthelowerbound,andthewis\n",
      "optimal.If??6=?,thelowerboundisnotachievable,andweconstructa\n",
      "minimum(s,t)-cutofthegraph[25]thattwodisjointssetsofnodesV\n",
      "+andV?;V+isthepartofthegraphthatcouldpotentiallyhavereceived\n",
      "morewfromthesource(thearcsbetweensandV+arenotsaturated),\n",
      "whereasallarcslinkingstoV?aresaturated.Atthispoint,itispossibleto\n",
      "showthatthevalueoftheoptimalmin-costwonallarcsbetweenV+and\n",
      "V?isnecessaryzero.Thus,removingthemyieldsanequivalentoptimization\n",
      "problem,whichcanbedecomposedintotwoindependentproblemsofsmaller\n",
      "sizesandsolvedrecursivelybythecallstocomputeFlow(V+,E+)andcom-\n",
      "puteFlow(V?,E?).AformalproofofcorrectnessofAlgorithm1andfurther\n",
      "detailsarerelegatedto[17].Theapproachof[18,20]isguaranteedtohavethe\n",
      "sameworst-casecomplexityasasinglewalgorithm.However,wehave\n",
      "experimentallyobservedatdiscrepancybetweentheworstcaseand\n",
      "empiricalcomplexitiesforthesewproblems,essentiallybecausetheempirical\n",
      "costofeachwistlysmallerthanitstheoreticalcost.Despite\n",
      "thefactthattheworst-caseguaranteeofouralgorithmisweakerthantheir(up\n",
      "toafactor|V|),itismoreadaptedtothestructureofourgraphsandhas\n",
      "proventobemuchfasterinourexperiments(seetechnicalreport[17]).Some\n",
      "implementationdetailsarecrucialtotheofthealgorithm:?Exploit-\n",
      "ingconnectedcomponents:Whenthereexistsnoarcbetweentwosubsetsof\n",
      "V,itispossibletoprocessthemindependentlyinordertosolvetheglobal\n",
      "min-costwproblem.?twalgorithm:Wehaveimplemented\n",
      "the?push-relabel?algorithmof[24]forsolvingourwproblems,using\n",
      "classicalheuristicsthattlyspeeditupinpractice(see[24,26]).This\n",
      "algorithmleveragestheconceptofwthatrelaxestheofw\n",
      "andallowsverticestohaveapositiveexcess.Itcanbeinitializedwithanyvalid\n",
      "7\n",
      "\n",
      "w,enablingwarm-restartswhenthewiscalledseveraltimesasin\n",
      "ouralgorithm.?ImprovedPprojectionstep:ThePlineofthefunction\n",
      "PreplacedbyPcomputeFlowcanbe??argmin?j?Vu12(uj??j)2s.t.g?j\n",
      "?g.Theg?Vgr?gand|?j|??j?Vu?j??Pideaisthatthestructure\n",
      "ofthegraphwillnotallow??jtobegreaterthan?g?j?gafterthew\n",
      "step.Addingtheseadditionalconstraintsleadstobetterperformancewhenthe\n",
      "graphisnotwellbalanced.Thismoprojectionstepcanstillbecomputed\n",
      "inlineartime[19].5\n",
      "3.3\n",
      "ComputationoftheDualNorm\n",
      "Thedualnorm??of?,foranyvector?inRpby??(?),max?(z)?1\n",
      "z??,isakeyquantitytostudysparsity-inducingregularizations[5,15,27].\n",
      "Weuseitheretomonitortheconvergenceoftheproximalmethodthrougha\n",
      "dualitygap,andaproperoptimalitycriterionforproblem(1).Wedenote\n",
      "byf?theFenchelconjugateoff[28],byf?(?),supz[z???f(z)].\n",
      "Thedualitygapforproblem(1)canbederivedfromstandardFenchelduality\n",
      "arguments[28]anditisequaltof(w)+??(w)+f?(??)forw,?inRpwith??\n",
      "(?)??.Therefore,evaluatingthedualitygaprequirestocomputetly??\n",
      "inordertoafeasibledualvariable?.Thisisequivalenttosolvinganother\n",
      "networkwproblem,basedonthefollowingvariationalformulation:X??(?)\n",
      "=min?s.t.?g=?,and?g?G,k?gk1???gwith?gj=0ifj?/g.(5)\n",
      "??Rp?|G|\n",
      "g?G\n",
      "Inthenetworkproblemassociatedwith(5),thecapacitiesonthearcs(s,\n",
      "g),g?G,aresetto??g,andthecapacitiesonthearcs(j,t),jin[1;p],are\n",
      "to?j.Solvingproblem(5)amountstodingthesmallestvalueof?,\n",
      "suchthatthereexistsaowsaturatingthecapacities?jonthearcsleadingto\n",
      "thesinkt(i.e.,??=?).Thealgorithmbelowisproventobecorrectin[17].\n",
      "Algorithm2Computationofthedualnorm.1:Inputs:??Rp,asetofgroups\n",
      "G,positiveweights(?g)g?G.2:BuildtheinitialgraphG0=(V0,E0,s,t)\n",
      "asexplainedinSection3.3.3:??dualNorm(V0,E0).4:Return:?(valueof\n",
      "thedualnorm).FunctiondualNorm(V=Vu?Vgr,E)PP1:??(j?Vu?j\n",
      ")/(g?Vgr?g)andsetthecapacitiesofarcs(s,g)to??gforallginVgr.2:\n",
      "wstep:Update(??j)j?Vubycomputingawonthegraph(V,\n",
      "E,s,t).3:if?j?Vus.t.??j6=?jthen4:(V+,E+)and(V?,E?\n",
      ")asinAlgorithm1,andset??dualNorm(V?,E?).5:endif6:Return:?.\n",
      "4\n",
      "ApplicationsandExperiments\n",
      "Ourexperimentsusethealgorithmof[4]basedonourproximaloperator,\n",
      "withweights?gsetto1.4.1\n",
      "SpeedComparison\n",
      "Wecompareourmethod(ProxFlow)andtwogenericoptimizationtech-\n",
      "niques,namelyasubgradientdescent(SG)andaninteriorpointmethod,6ona\n",
      "regularizedlinearregressionproblem.BothSGandProxFlowareimplemented\n",
      "inC++.Experimentsarerunonasingle-core2.8GHzCPU.Weconsidera\n",
      "designmatrixXinRn?pbuiltfromovercompletedictionariesofdiscretecosine\n",
      "8\n",
      "\n",
      "transforms(DCT),whicharenaturallyorganizedonone-ortwo-dimensional\n",
      "gridsanddisplaylocalcorrelations.ThefollowingfamiliesofgroupsGusingthis\n",
      "spatialinformationarethusconsidered:(1)everycontiguoussequenceoflength\n",
      "3fortheone-dimensionalcase,and(2)every3?3-squareinthetwo-dimensional\n",
      "setting.WegeneratevectorsyinRnaccordingtothelinearmodely=Xw0\n",
      "+?,where??N(0,0.01kXw0k22).Thevectorw0hasabout20%percent\n",
      "nonzerocomponents,randomlyselected,whilerespectingthestructureofG,\n",
      "anduniformlygeneratedbetween[?1,1].Inourexperiments,theregularization\n",
      "parameter?ischosentoachievethesamesparsityasw0.ForSG,wetake\n",
      "thestepsizetobeequaltoa/(k+b),wherekistheiterationnumber,and\n",
      "(a,b)arethebestparametersselectedin\n",
      "f\n",
      "10?3,...,10\n",
      "g\n",
      "?\n",
      "f\n",
      "102,103,104\n",
      "g\n",
      ".Fortheinteriorpointmethods,sinceproblem(1)canbecasteitherasa\n",
      "quadratic(QP)orasaconicprogram(CP),weshowinFigure2theresultsfor\n",
      "bothformulations.Ourapproachcomparesfavorablywiththeothermethods,\n",
      "onthreeproblemsoftsizes,(n,p)?\n",
      "f\n",
      "(100,103),(1024,104),(1024,\n",
      "105)\n",
      "g\n",
      ",seeFigure2.Inaddition,notethatQP,CPandSGdonotobtainsparse\n",
      "solutions,whereasProxFlowdoes.WehavealsorunProxFlowandSGona\n",
      "largerdatasetwith(n,p)=(100,106):after12hours,ProxFlowandSGhave\n",
      "reachedarelativedualitygapof0.0006and0.02respectively.767\n",
      "Inoursimulations,weusethecommercialsoftwareMosek,http://www.mosek.com/.\n",
      "Duetothecomputationalburden,QPandCPcouldnotberunoneveryprob-\n",
      "lem.\n",
      "6\n",
      "?4?6?8?10?2\n",
      "CPQPProxFlowSG\n",
      "?1012log(CPUtime)inseconds\n",
      "n=1024,p=10000,two?dimensionalDCT\n",
      "20?2?4?6?8?10?2\n",
      "CPProxFlowSG\n",
      "02log(CPUtime)inseconds\n",
      "4\n",
      "log(relativedistancetooptimum)\n",
      "0?2\n",
      "log(relativedistancetooptimum)\n",
      "log(relativedistancetooptimum)\n",
      "n=100,p=1000,one?dimensionalDCT\n",
      "2\n",
      "n=1024,p=100000,one?dimensionalDCT\n",
      "20?2?4?6?8?10?2\n",
      "ProxFlowSG\n",
      "02log(CPUtime)inseconds\n",
      "4\n",
      "Figure2:Speedcomparisons:distancetotheoptimalprimalvalueversus\n",
      "CPUtime(log-logscale).6\n",
      "Figure3:Fromlefttoright:originalimagey;estimatedbackgroundXw;\n",
      "foreground(thesparsitypatternofeusedasmaskony)estimatedwith?1;\n",
      "9\n",
      "\n",
      "foregroundestimatedwith?1+?;anotherforegroundobtainedwith?,ona\n",
      "timage,withthesamevaluesof?1,?2asforthepreviousimage.For\n",
      "thetoprow,thepercentageofpixelsmatchingthegroundtruthis98.8%with\n",
      "?,87.0%without.Asforthebottomrow,theresultis93.8%with?,90.4%\n",
      "without(bestseenincolor).4.2\n",
      "BackgroundSubtraction\n",
      "Following[9,10],weconsiderabackgroundsubtractiontask.Givenase-\n",
      "quenceofframesfromacamera,wetrytosegmentoutforegroundobjects\n",
      "inanewimage.Ifwedenotebyy?Rnatestimage,wemodelyasasparse\n",
      "linearcombinationofpotherimagesX?Rn?p,plusanerrortermeinRn,\n",
      "i.e.,y?Xw+eforsomesparsevectorwinRp.Thisapproachisreminiscent\n",
      "of[29]inthecontextoffacerecognition,whereeisfurthermadesparsetodeal\n",
      "withocclusions.ThetermXwaccountsforbackgroundpartspresentinboth\n",
      "yandX,whileecontainssporforeground,objectsiny.Theresulting\n",
      "optimizationproblemisminw,e21ky?Xw?ek22+?1kwk1+?2kek1,with\n",
      "?1,?2?0.Inthisformulation,the?1-normpenaltyonedoesnottakeinto\n",
      "accountthefactthatneighboringpixelsinyarelikelytosharethesamelabel\n",
      "(backgroundorforeground),whichmayleadtoscatteredpiecesofforeground\n",
      "andbackgroundregions(Figure3).Wethereforeputanadditionalstructured\n",
      "regularizationterm?one,wherethegroupsinGarealltheoverlapping3?3-\n",
      "squaresontheimage.Adatasetwithhand-segmentedevaluationimagesis\n",
      "usedtoillustratethectof?.8Forsimplicity,weuseasingleregularization\n",
      "parameter,i.e.,?1=?2,chosentomaximizethenumberofpixelsmatching\n",
      "thegroundtruth.Weconsiderp=200imageswithn=57600pixels(i.e.,a\n",
      "resolutionof120?160,times3fortheRGBchannels).AsshowninFigure3,\n",
      "adding?improvesthebackgroundsubtractionresultsforthetwotestedvideos,\n",
      "byencoding,unlikethe?1-norm,bothspatialandcolorconsistency.4.3\n",
      "Multi-TaskLearningofHierarchicalStructures\n",
      "In[12],Jenattonetal.haverecentlyproposedtouseahierarchicalstruc-\n",
      "turednormtolearndictionariesofnaturalimagepatches.Followingthiswork,\n",
      "weseektorepresentnsignals\n",
      "f\n",
      "y1,...,yn\n",
      "g\n",
      "ofdimensionmassparselinear\n",
      "combinationsofelementsfromadictionaryX=[x1,...,xp]inRm?p.\n",
      "Thiscanbeexpressedforalliin[1;n]asyi?Xwi,forsomesparsevectorwi\n",
      "inRp.In[12],thedictionaryelementsareembeddedinatreeT,\n",
      "viaaparticularinstanceofthestructurednorm?;werefertoitas?tree,and\n",
      "callGtheunderlyingsetofgroups.Inthiscase,eachsignalyiadmitsasparse\n",
      "decompositionintheformofasubtreeofdictionaryelements.8\n",
      "http://research.microsoft.com/en-us/um/people/jckrumm/wwer/testimages.htm\n",
      "7\n",
      "Inspiredbyideasfrommulti-tasklearning[14],weproposetolearnthe\n",
      "treestructureTbypruningirrelevantpartsofalargerinitialtreeT0.We\n",
      "achievethisbyusinganadditionalregularizationterm?jointacrossthet\n",
      "decompositions,sothatsubtreesofT0willsimultaneouslyberemovedforall\n",
      "signalsyi.Inotherwords,theapproachof[12]isextendedbythefollowing\n",
      "formulation:ni1Xh1iky?Xwik22+?1?tree(wi)+?2?joint(W),s.t.kxj\n",
      "k2?1,foralljin[1;p],(6)minX,Wn2i=1whereW,[w1,...,wn]isthe\n",
      "10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrixofdecompositioncotsinRp?n.ThenewregularPizationterm\n",
      "operatesontherowsofWandisas?joint(W),g?Gmaxi?[1;n]|wgi\n",
      "|.9TheoverallpenaltyonW,whichresultsfromthecombinationof?treeand\n",
      "?joint,isitselfaninstanceof?withgeneraloverlappinggroups,asin\n",
      "Eq(2).\n",
      "MeanSquareError\n",
      "Toaddressproblem(6),weusethesameoptimizationschemeas[12],i.e.,\n",
      "alternatingbetweenXandW,onevariablewhileoptimizingwithrespect\n",
      "totheother.Thetaskweconsideristhedenoisingofnaturalimagepatches,\n",
      "withthesamedatasetandprotocolas[12].Westudywhetherlearningthehier-\n",
      "archyofthedictionaryelementsimprovesthedenoisingperformance,compared\n",
      "tostandardsparsecoding(i.e.,when?treeisthe?1-normand?2=0)andthe\n",
      "hierarchicaldictionarylearningof[12]basedontrees(i.e.,?2=0).\n",
      "Thedimensionsofthetrainingset?50000patchesofsize8?8fordictionaries\n",
      "withuptop=400elements?imposetohandlelargegraphs,with|E|?\n",
      "|V|?4.107.Sinceproblem(6)istoolargetobesolvedmanytimesto\n",
      "selecttheregularizationparameters(?1,?2)rigorously,weusethefollowing\n",
      "heuristics:weoptimizemostlywiththecurrentlyprunedtreeheld(i.e.,\n",
      "?2=0),andonlyprunethetree(i.e.,?2>0)everyfewstepsonarandom\n",
      "subsetof10000patches.Weconsiderthesamehierarchiesasin[12],involving\n",
      "between30and400dictionaryelements.Theregularizationparameter?1is\n",
      "selectedonthevalidationsetof25000patches,forbothsparsecoding(Flat)\n",
      "andhierarchicaldictionarylearning(Tree).Startingfromthetreegivingthe\n",
      "bestperformance(inthiscasethelargestone,seeFigure4),wesolveproblem\n",
      "(6)followingourheuristics,forincreasingvaluesof?2.AsshowninFigure4,\n",
      "thereisaregimewhereourapproachperformssitlybetterthanthetwo\n",
      "othercomparedmethods.Thestandarddeviationofthenoiseis0.2(thepixels\n",
      "havevaluesin[0,1]);notimprovementswereobservedforlowerlevels\n",
      "ofnoise.DenoisingExperiment:MeanSquareError0.21FlatTreeMulti?task\n",
      "Tree0.2\n",
      "0.190\n",
      "100200300DictionarySize\n",
      "400\n",
      "Figure4:Left:Hierarchyobtainedbypruningalargertreeof76elements.\n",
      "Right:Meansquareerrorversusdictionarysize.Theerrorbarsrepresenttwo\n",
      "standarddeviations,basedonthreeruns.\n",
      "5\n",
      "Conclusion\n",
      "Wehavepresentedanewoptimizationframeworkforsolvingsparsestruc-\n",
      "turedproblemsinvolvingsumsof??-normsofany(overlapping)groupsofvari-\n",
      "ables.Interestingly,thisshedsnewlightonconnectionsbetweensparsemethods\n",
      "andtheliteratureofnetworkwoptimization.Inparticular,theproximalop-\n",
      "eratorfortheformulationweconsidercanbecastasaquadraticmin-costw\n",
      "problem,forwhichweproposeantandsimplealgorithm.Thisallows\n",
      "theuseofacceleratedgradientmethods.Severalexperimentsdemonstratethat\n",
      "ouralgorithmcanbeappliedtoawideclassoflearningproblems,whichhave\n",
      "11\n",
      "\n",
      "notbeenaddressedbeforewithinsparsemethods.AcknowledgmentsThispaper\n",
      "waspartiallysupportedbytheEuropeanResearchCouncil(SIERRAProject).\n",
      "TheauthorswouldliketothankJeanPonceforinterestingdiscussionsand\n",
      "suggestions.9\n",
      "Thecasewhere?treeand?jointarethe?1-andmixed?1/?2\n",
      "-norms[13]correspondsto[30].\n",
      "8\n",
      "2References\n",
      "[1]P.Bickel,Y.Ritov,andA.Tsybakov.SimultaneousanalysisofLasso\n",
      "andDantzigselector.Ann.Stat.,37(4):1705?1732,2009.[2]B.Efron,T.\n",
      "Hastie,I.Johnstone,andR.Tibshirani.Leastangleregression.Ann.Stat.,\n",
      "32(2):407?499,2004.[3]Y.Nesterov.Gradientmethodsforminimizingcom-\n",
      "positeobjectivefunction.Technicalreport,CenterforOperationsResearch\n",
      "andEconometrics(CORE),CatholicUniversityofLouvain,2007.[4]A.Beck\n",
      "andM.Teboulle.Afastiterativeshrinkage-thresholdingalgorithmforlinear\n",
      "inverseproblems.SIAMJ.Imag.Sci.,2(1):183?202,2009.[5]R.Jenatton,J-\n",
      "Y.Audibert,andF.Bach.Structuredvariableselectionwithsparsity-inducing\n",
      "norms.Technicalreport,2009.PreprintarXiv:0904.3523v1.[6]L.Jacob,G.\n",
      "Obozinski,andJ.-P.Vert.GroupLassowithoverlapandgraphLasso.In\n",
      "Proc.ICML,2009.[7]P.Zhao,G.Rocha,andB.Yu.Thecompositeabsolute\n",
      "penaltiesfamilyforgroupedandhierarchicalvariableselection.Ann.Stat.,\n",
      "37(6A):3468?3497,2009.[8]R.G.Baraniuk,V.Cevher,M.Duarte,andC.\n",
      "Hegde.Model-basedcompressivesensing.IEEET.Inform.Theory,2010.to\n",
      "appear.[9]V.Cehver,M.F.Duarte,C.Hedge,andR.G.Baraniuk.Sparsesig-\n",
      "nalrecoveryusingmarkovrandomInAdv.NIPS,2008.[10]J.Huang,\n",
      "T.Zhang,andD.Metaxas.Learningwithstructuredsparsity.InProc.ICML,\n",
      "2009.[11]S.KimandE.P.Xing.Tree-guidedgrouplassoformulti-taskre-\n",
      "gressionwithstructuredsparsity.InProc.ICML,2010.[12]R.Jenatton,\n",
      "J.Mairal,G.Obozinski,andF.Bach.Proximalmethodsforsparsehierar-\n",
      "chicaldictionarylearning.InProc.ICML,2010.[13]M.YuanandY.Lin.\n",
      "Modelselectionandestimationinregressionwithgroupedvariables.J.Roy.\n",
      "Stat.Soc.B,68:49?67,2006.[14]G.Obozinski,B.Taskar,andM.I.Jordan.\n",
      "Jointcovariateselectionandjointsubspaceselectionformultipleclasscation\n",
      "problems.Stat.Comput.,20(2):231?252,2010.[15]F.Bach.Exploringlarge\n",
      "featurespaceswithhierarchicalmultiplekernellearning.InAdv.NIPS,2008.\n",
      "[16]P.L.CombettesandJ.-C.Pesquet.Proximalsplittingmethodsinsignal\n",
      "processing.InFixed-PointAlgorithmsforInverseProblemsinScienceandEn-\n",
      "gineering.Springer,2010.[17]J.Mairal,R.Jenatton,G.Obozinski,andF.\n",
      "Bach.Networkwalgorithmsforstructuredsparsity.Technicalreport,2010.\n",
      "PreprintarXiv:1008.5209v1.[18]D.S.HochbaumandS.P.Hong.About\n",
      "stronglypolynomialtimealgorithmsforquadraticoptimizationoversubmod-\n",
      "ularconstraints.Math.Program.,69(1):269?309,1995.[19]P.Brucker.An\n",
      "O(n)algorithmforquadraticknapsackproblems.Oper.Res.Lett.,3:163?166,\n",
      "12\n",
      "\n",
      "1984.[20]G.Gallo,M.E.Grigoriadis,andR.E.Tarjan.Afastparametric\n",
      "maximumwalgorithmandapplications.SIAMJ.Comput.,18:30?55,1989.\n",
      "[21]M.BabenkoandA.V.Goldberg.Experimentalevaluationofaparametric\n",
      "walgorithm.Technicalreport,MicrosoftResearch,2006.MSR-TR-2006-77.\n",
      "[22]H.Groenevelt.Twoalgorithmsformaximizingaseparableconcavefunc-\n",
      "tionoverapolymatroidfeasibleregion.Eur.J.Oper.Res.,pages227?236,\n",
      "1991.[23]F.Bach.Structuredsparsity-inducingnormsthroughsubmodular\n",
      "functions.InAdv.NIPS,2010.[24]A.V.GoldbergandR.E.Tarjan.A\n",
      "newapproachtothemaximumwproblem.InProc.ofACMSymposiumon\n",
      "TheoryofComputing,1986.[25]L.R.FordandD.R.Fulkerson.Maximalw\n",
      "throughanetwork.CanadianJ.Math.,8(3),1956.[26]B.V.Cherkasskyand\n",
      "A.V.Goldberg.Onimplementingthepushrelabelmethodforthemaximum\n",
      "wproblem.Algorithmica,19(4):390?410,1997.[27]S.Negahban,P.Raviku-\n",
      "mar,M.J.Wainwright,andB.Yu.Aframeworkforhigh-dimensional\n",
      "analysisofM-estimatorswithdecomposableregularizers.InAdv.NIPS,2009.\n",
      "[28]J.M.BorweinandA.S.Lewis.Convexanalysisandnonlinearoptimiza-\n",
      "tion.Springer,2006.[29]J.Wright,A.Y.Yang,A.Ganesh,S.S.Sastry,and\n",
      "Y.Ma.Robustfacerecognitionviasparserepresentation.IEEET.Pattern.\n",
      "Anal.,pages210?227,2008.[30]P.Sprechmann,I.Ramirez,G.Sapiro,andY.\n",
      "C.Eldar.Collaborativehierarchicalsparsemodeling.Technicalreport,2010.\n",
      "PreprintarXiv:1003.0400v1.\n",
      "9\n",
      "13\n",
      "\n",
      "PP4401.pdf\n",
      "PP4401.pdf 15\n",
      "OntheAnalysisofMulti-ChannelNeuralSpike\n",
      "Data\n",
      "Authoredby:\n",
      "LawrenceCarin\n",
      "BoChen\n",
      "DavidE.Carlson\n",
      "Abstract\n",
      "NonparametricBayesianmethodsaredevelopedforanalysisofmulti-\n",
      "channelspike-traindata,withthefeaturelearningandspikesortingper-\n",
      "formedjointly.Thefeaturelearningandsortingareperformedsimulta-\n",
      "neouslyacrossallchannels.Dictionarylearningisimplementedviathe\n",
      "beta-Bernoulliprocess,withspikesortingperformedviathedynamichi-\n",
      "erarchicalDirichletprocess(dHDP),withthesetwomodelscoupled.The\n",
      "dHDPisaugmentedtoeliminaterefractoryperiodviolations,itallowsthe\n",
      "?appearance?and?disappearance?ofneuronsovertime,anditmodels\n",
      "smoothvariationinthespikestatistics.\n",
      "1PaperBody\n",
      "Theanalysisofactionpotentials(?spikes?)fromneural-recordingdevicesisa\n",
      "problemoflongstandinginterest(see[21,1,16,22,8,4,6]andthereferences\n",
      "therein).Insuchresearchoneistypicallyinterestedinclustering(sorting)\n",
      "thespikes,withthegoaloflinkingagivenclustertoaparticularneuron.Such\n",
      "technologyisofinterestforbrain-machineinterfacesandforgaininginsightinto\n",
      "thepropertiesofneuralcircuits[14].Insuchresearchonetypically(i)\n",
      "therawsensorreadings,(ii)performsthresholdingto?detect?thespikes,(iii)\n",
      "mapseachdetectedspiketoafeaturevector,and(iv)thenclustersthefeature\n",
      "vectors[12].Principalcomponentanalysis(PCA)isapopularchoice[12]for\n",
      "featuremapping.Afterperformingsuchsorting,onetypicallymust(v)search\n",
      "forrefractory-timeviolations[5],whichoccurwhentwoormorespikesthatare\n",
      "tlyproximateareimproperlyassociatedwiththesamecluster/neuron\n",
      "(whichisimpossibleduetotherefractorytimedelayrequiredforthesameneu-\n",
      "rontore-emitaspike).Recentresearchhascombined(iii)and(iv)withina\n",
      "singlemodel[6],andmethodshavebeendevelopedrecentlytoaddress(v)while\n",
      "performing(iv)[5].Manyoftheearlymethodsforspikesortingwerebasedon\n",
      "classicalclusteringtechniques[12](e.g.,K-meansandGMMs,withanum-\n",
      "1\n",
      "\n",
      "berofmixtures),butrecentlyBayesianmethodshavebeendevelopedtoaccount\n",
      "formoremodelingsophistication.Forexample,in[5]theauthorsemployeda\n",
      "mototheChineserestaurantformulationoftheDirichletprocess(DP)\n",
      "[3]toautomaticallyinferthenumberofclusters(neurons)present,allowstatis-\n",
      "ticaldriftinthefeaturestatistics,permitthe?appearance?/?disappearance?of\n",
      "neuronswithtime,andautomaticallyaccountforrefractorytimerequirements\n",
      "withintheclustering(notasapost-clusteringstep).However,[5]assumedthat\n",
      "thespikefeatureswereprovidedviaPCAinthetwoorthreeprincipal\n",
      "components(PCs).In[6]featurelearningandspikesortingwereperformed\n",
      "jointlyviaamixtureoffactoranalyzers(MFA)formulation.However,in[6]\n",
      "modelselectionwasperformed(forthenumberoffeaturesandnumberofneu-\n",
      "rons)andamaximumlikelihood(ML)?point?estimatewasconstitutedfor\n",
      "themodelparameters;sinceanumberofclustersareinferredin[6],the\n",
      "modeldoesnotdirectlyallowforthe?appearance?/?disappearance?ofneu-\n",
      "rons,orforanytemporaldependencetothespikestatistics.Therehasbeenan\n",
      "increasinginterestindevelopingneuraldeviceswithC>1recordingchannels,\n",
      "eachofwhichproducesaseparateelectricalrecordingofneuralactivity.Recent\n",
      "researchshowsincreasedsystemperformancewithlargeC[18].Almostallof\n",
      "theaboveresearchonspikesorting1\n",
      "300\n",
      "GroundTruth\n",
      "?300\n",
      "PC?2\n",
      "?100?300\n",
      "?300UnkownNeuronKnownNeuron\n",
      "(a)\n",
      "100\n",
      "100\n",
      "?100\n",
      "?500?500?700?700?500?300?100100300500PC?1\n",
      "HDP?DL\n",
      "GMM\n",
      "100PC?2\n",
      "PC?2\n",
      "100?100\n",
      "300\n",
      "300K?means\n",
      "PC?2\n",
      "300\n",
      "?400\n",
      "?100PC?1\n",
      "200\n",
      "500\n",
      "?500?700\n",
      "(b)\n",
      "?100?300\n",
      "2\n",
      "\n",
      "?400\n",
      "?100PC?1\n",
      "(c)\n",
      "200\n",
      "500\n",
      "?500?700?500?300?100100300500PC?1\n",
      "(d)\n",
      "Figure1:Comparisonofspikesortingonrealdata.(a)Groundtruth;(b)\n",
      "K-meansclusteringonthe2\n",
      "principalcomponents;(c)GMMclusteringwiththe2principalcompo-\n",
      "nents;(d)proposedmethod.WelabelusingarrowsexamplesK-meansandthe\n",
      "GMMmiss,andthattheproposedmethodproperlysort.\n",
      "hasbeenperformedonasinglechannel,orwhenmultiplechannelsare\n",
      "presenteachistypicallyanalyzedinisolation.In[5]C=4channelswere\n",
      "considered,butitwasassumedthataspikeoccurredatthesametime(or\n",
      "nearlysametime)acrossallchannels,andthefeaturesfromthefourchannels\n",
      "wereconcatenated,elyreducingthisagaintoasingle-channelanaly-\n",
      "sis.WhenC1,theassumptionthatagivenneuronisobservedsimultaneously\n",
      "onallchannelsistypicallyinappropriate,andinfactthediversityofneuron\n",
      "sensingacrossthedeviceisdesired,toenhancefunctionality[18].Thispa-\n",
      "peraddressesthemulti-channelneural-recordingproblem,underconditionsfor\n",
      "whichconcatenationmaybeinappropriate;theproposedmodelgeneralizesthe\n",
      "DPformulationof[5],withahierarchicalDP(HDP)formulation[20].Inthis\n",
      "formulationstatisticalstrengthissharedacrossthechannels,withoutassuming\n",
      "thatagivenneuronissimultaneouslyviewedacrossallchannels.Further,the\n",
      "modelgeneralizestheHDP,viaadynamicHDP(dHDP)[17]toallowthe?ap-\n",
      "pearance?/?disappearance?ofneurons,whilealsoallowingsmoothchangesin\n",
      "thestatisticsoftheneurons.Further,weexplicitlyaccountforrefractorytimes,\n",
      "asin[5].Wealsoperformjointfeaturelearningandclustering,usingamix-\n",
      "tureoffactoranalyzersconstructionasin[6],butwedosoinafullyBayesian,\n",
      "multi-channelsetting(additionally,[6]didnotaccountfortime-varyingstatis-\n",
      "tics).Thelearnedfactorloadingsarefoundtobesimilartowavelets,butthey\n",
      "arematchedtothepropertiesofneuronspikes;thisisincontrasttoprevious\n",
      "featureextractiononspikes[11]basedonorthogonalwavelets,thatarenot\n",
      "necessarilymatchedtoneuronproperties.Togiveapreviewoftheresults,\n",
      "providingasenseoftheimportanceoffeaturelearning(relativetomapping\n",
      "dataintoPCAfeatureslearnedinFigure1weshowacomparisonof\n",
      "clusteringresultsonthechannelofd533101datafromhc-1[7].Forall\n",
      "casesinFigure1thedataaredepictedinthetwoPCsforvisualization,\n",
      "buttheproposedmethodin(d)learnsthenumberoffeaturesandtheircom-\n",
      "position,whilesimultaneouslyperformingclustering.Theresultsin(b)and(c)\n",
      "correspondrespectivelytowidelyemployedK-meansandGMManalysis,based\n",
      "onusingtwoPCs(inthesecasestheanalysisareemployedinPCAspace,as\n",
      "havebeenmanymore-advancedapproaches[5]).FromFigures1(b)and(c),\n",
      "weobservethatbothK-meansandGMMworkwell,butduetotheconstrained\n",
      "featurespacetheyincorrectlyclassifysomespikes(markedbyarrows).How-\n",
      "3\n",
      "\n",
      "ever,theproposedmodel,showninFigure1(d),whichincorporatesdictionary\n",
      "learningwithspikesorting,infersanappropriatefeaturespace(notshown)and\n",
      "moreelyclusterstheneurons.Thedetailsofthismodel,includinga\n",
      "multi-channelextension,arediscussedindetailbelow.\n",
      "22.1\n",
      "ModelConstructionDictionarylearning\n",
      "Weinitiallyassumethatspikedetectionhasbeenperformedonallchannels.\n",
      "Spiken2\n",
      "f\n",
      "1,...,Nc\n",
      "g\n",
      "(c)onchannelc2\n",
      "f\n",
      "1,...,C\n",
      "g\n",
      "isavectorxn2RD,\n",
      "byDtimesamplesforeachspike,centeredatthepeakofthedetected\n",
      "signal;thereareNcspikesonchannelc.(c)\n",
      "Datafromspikenonchannelc,xn,isrepresentedintermsofadictionary\n",
      "D2RD?K,whereKisanupperboundonthenumberofneededdictionary\n",
      "elements(columnsofD),andthemodel2\n",
      "(c)\n",
      "infersthesubsetofdictionaryelementsneededtorepresentthedata.Each\n",
      "xnisrepresentedas(c)(c)(c)x(c)n=D?sn+?n(c)\n",
      "(c)\n",
      "(1)\n",
      "(c)\n",
      "where?(c)=diag(1b1,2b2,...,KbK)isadiagonalmatrix,withb=\n",
      "(b1,...,bK)T2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "K.dkasthekthcolumnofD,andletting\n",
      "IDrepresenttheD?Didentitymatrix,thepriorsonthemodelparametersare\n",
      "dk?N(0,\n",
      "1ID),D\n",
      "(c)\n",
      "(c)k\n",
      "?TN+(0,\n",
      "c\n",
      "1\n",
      "),\n",
      "1?(c)n?N(0,?c)\n",
      "(2)\n",
      "(c)\n",
      "where?c=diag(?1,...,?D),andTN+(?)representsthetruncated\n",
      "(positive)normaldistribution.Gammapriors(detailedwhenpresentingresults)\n",
      "areplacedoncandoneachoftheele(c)(c)mentsof(?1,...,?D).Forthe\n",
      "binaryvectorbweimposethepriorbk?Bernoulli(?k),with?k?Beta(a/K,\n",
      "b(K1)/K),implyingthatthenumberofnon-zerocomponentsofbisdrawn\n",
      "Binomial(K,a/(a+b(K1)));thiscorrespondstoPoisson(a/b)inthelimitK!\n",
      "1.Parametersaandbaresettofavorasparseb.(c)\n",
      "Thismodelimposesthateachxnisdrawnfromalinearsubspace,\n",
      "bythecolumnsofDwithcorrespondingnon-zerocomponentsinb;thesame\n",
      "linearsubspaceissharedacrossallchannels(c)c2\n",
      "f\n",
      "1,...,C\n",
      "g\n",
      ".However,\n",
      "thestrengthwithwhichacolumnofDcontributestowardxndependsonthe\n",
      "channelc,asby?(c).Concerning?(c),ratherthanexplicitlyimposing\n",
      "asparse(c)diagonalviab,wemayalsodrawk?TN+(0,ck1),with\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shrinkagepriorsemployedontheck(i.e.,withtheckdrawnfromagamma\n",
      "priorthatfavorslargeck;whichencouragesmanyofthediagonalelementsof\n",
      "?(c)tobesmall,buttypicallynotexactlyzero).Intests,themodelperformed\n",
      "similarlywhenshrinkagepriorswereusedon?(c)relativetoexplicitimposition\n",
      "ofsparsenessviab;allresultsbelowarebasedonthelatterconstruction.2.2\n",
      "Multi-ChannelDynamichierarchicalDirichletprocess(c)\n",
      "Wesortthespikesonthechannelsbyclusteringthe\n",
      "f\n",
      "sn\n",
      "g\n",
      ",andinthissense\n",
      "featuredesign(learning\n",
      "f\n",
      "D?(c)\n",
      "g\n",
      ")andsortingareperformedsimultaneously.\n",
      "WediscusshowthismaybeperformedviaahierarchicalDirichletprocess\n",
      "(HDP)construction[20],andthenextendthisviaadynamic(c)HDP(dHDP)\n",
      "[17]consideringmultiplechannels.InanHDPconstruction,the\n",
      "f\n",
      "sn\n",
      "g\n",
      "are\n",
      "modeledasbeingdrawn(c)s(c)n?f(?n),\n",
      "?n(c)?G(c),\n",
      "G(c)?DP(?cG),\n",
      "G?DP(?0G0)(3)P1whereaQdrawfrom,forexample,DP(?0G0)may\n",
      "beconstructed[19]asG=i=1?i?i?,where?i=Vih<i(1Vh),Vi?Beta(1,\n",
      "?0),?i??G0,and?i?isaunitpointmeasuresituatedat?i?.P1(c)P1\n",
      "(c)EachoftheG(c)isthereforeoftheformG(c)=i=1?i?i?,withi=1?i\n",
      "=1andwiththe\n",
      "f\n",
      "?i?\n",
      "g\n",
      "sharedacrossallG(c),butwithchannel-dependent\n",
      "(c-dependent)probabilityofusingelementsof\n",
      "f\n",
      "?i?\n",
      "g\n",
      ".Gammahyperpriorsare\n",
      "employedfor\n",
      "f\n",
      "?c\n",
      "g\n",
      "and?0.InthecontextofthemodeldevelopedinSection\n",
      "2.1,thedensityfunctionf(?)correspondstoaGaussian,andparameters?i?\n",
      "=(??i,?i)correspondtomeansandprecisionmatrices,withG0anormal-\n",
      "Wishartdistribution.Theproposedmodelmaybeviewedasanmixtureof\n",
      "factoranalyzers(MFA)[6]appliedtoeachchannel,withtheadditionofsharing\n",
      "ofstatisticalstrengthacrosstheCchannelsviatheHDP.Sharingismanifested\n",
      "intwoforms:(i)viathesharedlinearsubspacebythecolumnsofD,and\n",
      "(ii)viahierarchical(c)clusteringviaHDPoftherelativeweightings\n",
      "f\n",
      "sn\n",
      "g\n",
      ".In\n",
      "tests,theuseofchannel-dependent?(c)wasfoundcriticaltomodelingsuccess,\n",
      "ascomparedtoemployingasingle?sharedacrossallchannels.P1(c)The\n",
      "aboveHDPconstructionassumesthatG(c)=i=1?i?i?istime-independent,\n",
      "implyingthat(c)\n",
      "(c)\n",
      "theprobability?ithatxnisdrawnfromf(?i?)istimeinvariant.There\n",
      "aretwowaysthisassumptionmaybeviolated.First,neuronrefractorytime\n",
      "impliesaminimumdelaybetweenconsecutiveofthesameneuron;this\n",
      "isaddressedinarelativelystraightforwardmannerdiscussedinSection\n",
      "2.3.Thesecondissuecorrespondstothe?appearance?or?disappearance?of\n",
      "neurons(c)[5];theformerwouldbecharacterizedbyanincreaseinthevalue\n",
      "ofacomponentof?i,whilethe(c)latterwouldbecharacterizedbyoneofthe\n",
      "componentsof?igoingtozero(ornearzero).Itis3\n",
      "desirabletoaugmentthemodeltoaddresstheseobjectives.Weachievethis\n",
      "byapplicationofthedHDPconstructiondevelopedin[17].Asin[5],wedivide\n",
      "thetimeaxisintocontiguous,non-overlappingtemporalblocks,whereblockj\n",
      "correspondstospikesobservedbetweentimes?j1and?j;weconsiderJsuch\n",
      "blocks,indexed(c)j=1,...,J.Thespikesonchannelcwithinblockj\n",
      "5\n",
      "\n",
      "aredenoted\n",
      "f\n",
      "xjn\n",
      "g\n",
      "n=1,Ncj,whereNcjrepresentsthenumberofspikeswithin\n",
      "blockjonchannelc.InthedHDPconstructionwehave(c)\n",
      "(c)\n",
      "(c)\n",
      "(c)\n",
      "(c)\n",
      "(c)\n",
      "sjn?f(?jn),?jn?wjGj+(1(c)\n",
      "(c)\n",
      "wherew1\n",
      "(c)\n",
      "Gj?DP(?jcG),G?DP(?0G0),wj(c)\n",
      "=1forallc.Theexpressionwj\n",
      "(c)\n",
      "Gj,whilewithprobability1\n",
      "(c)\n",
      "(c)\n",
      "wj)Gj\n",
      "(4)\n",
      "1\n",
      "?Beta(c,d)\n",
      "(5)(c)\n",
      "controlstheprobabilitythat?jnisdrawnfrom(c)\n",
      "(c)\n",
      "wjparameter?jnisdrawnfromGj\n",
      "1.Thecumulativemixture(c)(c)model+(1wj)Gj1supportsarbitrary\n",
      "levelsofvariationfromblocktoblockin(c)thespike-trainanalysis:Ifwjis\n",
      "smalltheprobabilityofobservingaparticulartypeofneuron(c)doesn?tchange\n",
      "tlyfromblockj1toj,whileifwj?1themixtureprobabilitiescan(c)\n",
      "changequickly(e.g.,duetothe?appearance?/?disappearance?ofaneuron);\n",
      "forwjinbetween(c)(c)wjGj\n",
      "theseextremes,theprobabilityofobservingaparticularneuronchanges\n",
      "slowly/smoothlywithconsecutiveblocks.Themodelthereforeallowsa\n",
      "cantdegreeofyandadaptivitytochangesinneuronstatistics.2.3\n",
      "Accountingforrefractorytimeanddrift\n",
      "Todemonstratehowonemayexplicitlyaccountforrefractory-timecondi-\n",
      "tionswithinthemodel,(c)(c)assumethetimebetweenspikesxj?\n",
      "andxj?0islessthantherefractorytime,whileallotherspikeshavetemporal\n",
      "separationsgreaterthantherefractorytime;weconsidertwospikesofthistype\n",
      "fornotationalconvenience,butthebasicformulationbelowmaybereadilyex-\n",
      "tendedto(c)(c)morethantwospikesofthistype.Wewishtoimposethatxj?\n",
      "andxj?0shouldnotbeassociated(c)\n",
      "withthesamecluster/neuron,butotherwisethemodelisunchanged.Hence,\n",
      "forn6=?0,?jn?(c)?(c)=w(c)G(c)+(1w(c))G(c)asin(4).Assuming\n",
      "G?(c)=P1??Gjjjjj1ji=1?ji?i,wehavethenewconditionalgenerative\n",
      "construction(c)\n",
      "6\n",
      "\n",
      "(c)\n",
      "?j?0|?j??\n",
      "1Xi=1\n",
      "(c)\n",
      "??ji[1\n",
      "P1\n",
      "l=1\n",
      "(c)\n",
      "(c)\n",
      "I(?j?=?i?)]\n",
      "??jl[1\n",
      "(c)\n",
      "I(?j?=?l?)]\n",
      "(6)\n",
      "?i?\n",
      "whereI(?)istheindicatorfunction(itisequaltooneiftheargumentis\n",
      "true,anditiszerootherwise).(c)(c)Thisconstructionimposesthat?j?06=\n",
      "?j?,butotherwisethemodelpreservesthattheelementsof?(c).Notethat\n",
      "thetimeassociatedwith\n",
      "f\n",
      "?i?\n",
      "g\n",
      "aredrawnwitharelativeprobabilityconsistent\n",
      "withGjagivenspikeisassumedknownafterdetection(i.e.,itisacovariate),\n",
      "andthereforeitisknownaprioriforwhichspikestheaboveadjustmentsmust\n",
      "bemadetothemodel.(c)\n",
      "Therepresentationin(6)constitutesapropergenerativeconstructionfor\n",
      "f\n",
      "?jn\n",
      "g\n",
      "inthepresenceofspikesthatco-occurwithintherefractorytime,but\n",
      "itcomplicatesinference.Sp,recallthatP1(c)(c)(c)(c)Q(c)(c)\n",
      "Gj=i=1?ji?i?,with?ji=UjiUjh),withUji?Beta(1,?jc).Inthe\n",
      "originalh<i(1construction,(4)and(5),inwhichrefractory-timeviolationsare\n",
      "notaccountfor,theGibbsupdate(c)(c)equationsfor\n",
      "f\n",
      "Uji\n",
      "g\n",
      "areanalytic,\n",
      "duetomodelconjugacy.However,conjugacyfor\n",
      "f\n",
      "Uji\n",
      "g\n",
      "islostwith(6),and\n",
      "thereforeaMetropolis-Hastings(MH)stepisrequiredtodrawtheserandom\n",
      "variableswithanMarkovChainMonteCarlo(MCMC)analysis.Thisadded\n",
      "complexityisoftenunnecessary,sincethenumberofrefractory-timeeventsis\n",
      "typicallyverysmallrelativetothetotalnumberofspikesthatmustbesorted.\n",
      "Hence,wehavesuccessfullyimplementedthefollowingapproximation(c)(c)to\n",
      "theaboveconstruction.Whilethe?j?0isdrawnasin(6),assigning?j?0to\n",
      "oneofthemembersof(c)\n",
      "f\n",
      "?i?\n",
      "g\n",
      "whileavoidingarefractory-timeviolation,theupdateequationsfor\n",
      "f\n",
      "Uji\n",
      "g\n",
      "areexecutedasthey4\n",
      "wouldbein(4)and(5),withoutanMHstep.Inotherwords,aconstruction\n",
      "like(6)isusedtoassign(c)elementsof\n",
      "f\n",
      "?i?\n",
      "g\n",
      "tospikes,butafterthisstep\n",
      "theupdateequationsfor\n",
      "f\n",
      "Uji\n",
      "g\n",
      "areimplementedasintheoriginal(conjugate)\n",
      "model.Thisisessentiallythesameapproachemployedin[5],butnowinterms\n",
      "ofa?stick-breaking?ratherthanCRPconstructionoftheDP(hereandHDP),\n",
      "andlikein[5]wehavefoundthistoyieldencouragingresults(e.g.,norefractory-\n",
      "timeviolations,andsortingingoodagreementwith?truth?whenavailable).\n",
      "Finally,in[5]theauthorsconsidereda?drift?intheatomsassociatedwiththe\n",
      "7\n",
      "\n",
      "DP,whichherewouldcorrespondtoadriftintheatomsassociatedwithour\n",
      "dHDP.Inthisconstruction,ratherthatdrawingthe?i??G0onceasin(5),\n",
      "onemaydraw?i??G0fortheblockoftime,andthenasimpleGaussian\n",
      "auto-regressivemodelisemployedtoallowthe\n",
      "f\n",
      "?i?\n",
      "g\n",
      "driftasmallamount?\n",
      "?betweenconsecutiveblocks.Sp,if\n",
      "f\n",
      "?ji\n",
      "g\n",
      "representstheatomsfor\n",
      "blockj,then?j+1,i?1?N(?ji,0),whereitisimposedthat0islarge.\n",
      "Weexaminedthiswithinthecontextofthemodelproposedhere,andforthe\n",
      "dataconsideredinSection4thisaddedmodelingcomplexitydidnotchangethe\n",
      "resultstly,andthereforewedidnotconsiderthisaddedcomplexity\n",
      "when?presentingresults.Thisobservedun-importanceinimposingdriftin\n",
      "f\n",
      "?ji\n",
      "g\n",
      "islikelyduetothefact(c)\n",
      "(c)\n",
      "?thatwedrawsjn?f(?jn)withaGaussianf(?),andthereforeevenifthe\n",
      "f\n",
      "?ji\n",
      "g\n",
      "donotchangeacrossdatablocks,themodelallowsdriftviavariationsin\n",
      "thedrawsfromtheGaussiantheinferredvariancethereof).\n",
      "3\n",
      "InferenceandComputations\n",
      "Foronlinesortingofspikes,aChineserestaurantprocess(CRP)formula-\n",
      "tionlikethatin[5]isdesirable.Theproposedmodelmaybeimplementedas\n",
      "ageneralizationoftheCRP,asthegeneralformofthemodelinSection2.2is\n",
      "independentofthespwayinferenceisperformed.InaCRPconstruction,\n",
      "theChineserestaurantfranchise(CRF)model[20]isinvoked,andthemodel\n",
      "inSection2.2yieldsadynamicCRF(dCRF),whereeachfranchiseisassoci-\n",
      "atedwithaparticularchannel.ThehierarchicalformofthedCRF,including\n",
      "thedictionary-learningcomponentofSection2.1,isfullyconjugate,andmay\n",
      "thereforebeimplementedviaaGibbssampler.Ashintedbytheconstructionin\n",
      "(6),wehereemployastick-breakingconstructionofthemodel,analogoustothe\n",
      "formofinferenceemployedin[17].Weemployaretrospectivestick-breaking(c)\n",
      "(c)construction[15]forGjandG[10],suchthatthenumberoftermsusedto\n",
      "constructGandGjisunboundedandadaptstothedata.Usingthisconstruc-\n",
      "tionthemodelisabletoadapttothenumberofneuronspresent,addingand\n",
      "deletingclustersasneeded.Inthissensethestick-breakingconstructionmay\n",
      "alsobeconsideredforonlineimplementations.Further,inthismodelthepa-\n",
      "rameterGibbssamplingfollowsanonline-styleinference,sincethedatablocks\n",
      "comeinsequentiallyandtheparametersforeachblockonlydependonthepre-\n",
      "viousoneoranewcomponent.Therefore,whileonlineimplementationisnot\n",
      "ourprincipalfocushere,itmaybeexecutedwiththeproposedmodel.Wealso\n",
      "implementedaCRFimplementation,forwhichthereisnotruncation.Both\n",
      "inferencemethods(stick-breakingandCRFimplementations)gaveverysimilar\n",
      "results.Althoughthispaperisnotprincipallyfocusedononlineimplementa-\n",
      "tions,inthecontextofsuch,onemayalsoconsideronlineandevolvinglearning\n",
      "ofthedictionaryD[13].Thereisrecentresearchononlinedictionarylearning,\n",
      "whichmaybeadaptedhere,usingrecentextensionsviaBayesianformalisms\n",
      "[9];thiswould,forexample,allowthelinearsubspaceinwhichthespikeshapes\n",
      "residetoadapt/changewithdatablock.\n",
      "4\n",
      "8\n",
      "\n",
      "ExampleResults\n",
      "FortheseexperimentsweusedatruncationlevelofK=60dictionaryele-\n",
      "ments.Indictionary(c)learning,thehyperparametersinthegammapriorsof\n",
      "cand?pweresetasac=106and65bc=10,a?(c)=0.1andb?(c)=10\n",
      ".IntheHDP,wesetGa(1,1)for?0and?c.IndHDP,ppwesetGa(1,1)for\n",
      "?0and?jc.Meanwhile,inordertoencouragethegroupstobeshared,weset\n",
      "QCQJ1(c)thepriorc=1j=1Beta(wj;aw,bw)withaw=0.1andbw=1.\n",
      "Theseparametershavenotbeenoptimized,andmanyanalogoussettingsyield\n",
      "similarresults.Weused5000burn-insamplesand5000collectionsamplesin\n",
      "theGibbssampler,andwechoosethecollectionsamplewiththe5\n",
      "Table1:Summaryofresultsonsimulateddata.MethodsK-meansGMM\n",
      "K-meanswith2PCsGMMwith2PCsDP-DLHDP-DL\n",
      "Channel196.00%84.33%96.8%96.83%97.00%97.39%\n",
      "Channel296.02%94.25%96.9%96.98%96.92%97.08%\n",
      "Channel395.77%91.75%96.50%96.92%97.08%97.08%\n",
      "Average95.93%90.11%96.81%96.91%97.00%97.18%\n",
      "maximumlikelihoodwhenpresentingbelowexampleclusterings.Forthe\n",
      "K-meansandGMM,wesettheclusterlevelto3inthesimulateddataandto\n",
      "2clustersintherealdata(seebelow).\n",
      "4.1\n",
      "SimulatedData\n",
      "Inneuralspiketrainsitisverytogetgroundtruthinformation,\n",
      "sofortestingandvweinitiallyconsidersimulateddatawithknown\n",
      "groundtruth.Togeneratedatawedrawfromthe(c)(c)modelxn?N(D(diag(\n",
      "(c)))sn,0.01ID).WeD2RD?Kand(c)2RK,whichconstructsourdata\n",
      "fromK=2primarydictionaryelementsoflengthD=40inC=3channels.\n",
      "Thesedictionaryelementsarerandomlydrawn.Wevary(c)fromchannelto\n",
      "channel,andforeachP3(c)(c)(c)spike,wegeneratethefeaturestrength\n",
      "accordingtop(sn)=i=1?iN(sn|?i,0.5IK)with?=[1/31/31/3],which\n",
      "meansthattherearethreeneuronsacrossallthechannels.We(c)?i\n",
      "2RKasthemeaninthefeaturespaceforeachneuronandshifttheneuron\n",
      "meanfromchanneltochannel.Forresultsweassociateeachclusterwitha\n",
      "neuronanddeterminethepercentageofspikesintheircorrectcluster.The\n",
      "resultsareshowninTable1.ThecombinedDirichletprocessanddictionary\n",
      "learning(DP-DL)givesimilarresultstotheGMMwith2principalcomponents\n",
      "(PCs).BecausetheDP-DLlearnstheappropriatenumberofclusters(three)\n",
      "anddictionaryelements(two),thesemodelsareexpectedtoperformsimilarly,\n",
      "exceptthattheDP-DLdoesnotrequireknowledgeofthenumberofdictionary\n",
      "elementsandclustersapriori.TheHDP-DLisallowedtoshareglobalclusters\n",
      "anddictionaryelementsbetweenchannels,whichimprovesresultsaswell.In\n",
      "Figure2thesampleposteriorsshowthatwepeakatthetruevaluesof3used\n",
      "?global?clusters(atthetoplayeroftheHDP)and2useddictionaryelements.\n",
      "Additionally,theHDPsharesclusterinformationbetweenchannels,whichhelps\n",
      "theclusteraccuracy.Infact,thespikesatthesametimewilltypicallybedrawn\n",
      "fromthesameglobalclusterdespitehavingindependentlocalclustersasseen\n",
      "intheglobalclusterfromeachchannelinFigure2(b).Thus,wecandetermine\n",
      "9\n",
      "\n",
      "aglobalspikeateachtimepointaswellasoneachchannel.\n",
      "IndexofGlobalClusters\n",
      "Probability\n",
      "0.60.40.200\n",
      "246810NumberofDictionaryElements\n",
      "(a)\n",
      "Channel2\n",
      "Channel3\n",
      "7Channel1\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "005001000SpikeIndex\n",
      "005001000SpikeIndex\n",
      "005001000SpikeIndex\n",
      "(b)\n",
      "7\n",
      "0.40.3Probability\n",
      "0.8\n",
      "0.20.10\n",
      "1\n",
      "2345678910NumberofGlobalClusters\n",
      "(c)\n",
      "Figure2:PosteriorinformationfromHDP-DLonsimulateddata.(a)Ap-\n",
      "proximateposteriordistributionof\n",
      "thenumberofuseddictionaryelements(i.e.,kbk0);(b)Examplecollec-\n",
      "tionsampleontheglobalclusterusage(eachlocalclusterismappedtoits\n",
      "correspondingglobalindex);(c)Theapproximateposteriordistributiononthe\n",
      "numberofglobalclusterused.\n",
      "6\n",
      "10\n",
      "\n",
      "Table2:Resultsfromtestingond533101data[7].KFMrepresentKalman\n",
      "FilterMixturemethod[2].MethodsK-meansGMMK-meanswith2PCsGMM\n",
      "with2PCsKFMwith2PCsDPwith2PCsHDPwith2PCsDP-DLHDP-DL\n",
      "4.2\n",
      "Channel186.67%87.43%87.47%89.00%91.00%89.04%90.36%92.29%\n",
      "93.38%\n",
      "Channel288.04%90.06%88.16%89.04%89.2%89.00%90.00%92.38%\n",
      "93.18%\n",
      "Channel389.20%86.75%89.40%87.43%86.35%87.43%90.00%89.52%\n",
      "93.05%\n",
      "Channel488.4%85.43%88.72%90.7%86.87%86.79%87.79%92.45%92.61%\n",
      "Average88.08%87.42%88.44%89.04%88.36%88.07%89.54%91.89%93.05%\n",
      "RealDatawithPartialGroundTruth\n",
      "Weusethepubliclyavailabledataset1hc-1.Thesedataconsistofboth\n",
      "extracellularrecordingsandanintracellularrecordingfromanearbyneuronin\n",
      "thehippocampusofaanesthetizedrat[7].Intracellularrecordingsgiveclean\n",
      "signalsonaspiketrainfromaspecineuron,givingaccuratespiketimesfor\n",
      "thatneuron.Thus,ifwedetectaspikeinanearbyextracellularrecording\n",
      "withinaclosetimeperiod(<.5ms)toanintracellularspike,weassumethatthe\n",
      "spikedetectedintheextracellularrecordingcorrespondstotheknownneuron?s\n",
      "spikes.Thisallowsustoknowpartialgroundtruth,andallowsustotest\n",
      "onmethodscomparedtotheknowninformation.Fortheaccuracyanalysis,\n",
      "wedetermineoneclusterthatcorrespondstotheknownneuron.Thenwe\n",
      "consideraspiketobecorrectlysortedifitisaknownspikeandisinthe\n",
      "knownclusterorifitisanunknownspikeintheunknowncluster.Inorder\n",
      "togiveafaircomparisonofmethods,weconsideredthewidelyuseddata\n",
      "d533101andusedthesamepreprocessingfrom[2].Thisdataconsistsofa4-\n",
      "channelextracellularrecordingsand1-channelintracellularrecording.Weused\n",
      "2491detectedspikesand786ofthosespikescamefromtheknownneuron.\n",
      "TheresultsareshowninFigure2.Theresultsshowthatlearningthefeature\n",
      "spaceinsteadofusingthetop2PCAcomponentsincreasessortingaccuracy.\n",
      "ThisphenomenoncanbeseeninFigure1,whereitisimpossibletoaccurately\n",
      "resolvetheclustersinthespacebasedonthe2principalcomponents,through\n",
      "eitherK-meansorGMM.Thus,byjointlylearningthesuitablefeaturespace\n",
      "andclustering,weareabletoseparatetheunknownandknownneuronsclusters\n",
      "moreaccurately.IntheHDPmodeltheadvantageisclearintheglobalaccuracy\n",
      "asweachieve89.54%whenusing2PCsand93.05%whenusingdictionary\n",
      "learning.Inadditiontolearningtheappropriatefeaturespace,HDP-DLand\n",
      "DP-DLcaninfertheappropriatenumberofclusters,allowingthedatato\n",
      "thenumberofneurons.Theposteriordistributiononthenumberofglobal\n",
      "clustersandnumberoffactors(dictionaryelements)usedisshowninFigure\n",
      "3(a)and3(b),alongwiththemostusedelementsofthelearneddictionaryin\n",
      "Figure3(c).Thedictionaryelementsshowshapessimilartobothneuronspikes\n",
      "inFigure3(d)andwavelets.Thespikynatureofthelearneddictionarycan\n",
      "givefactorssimilartothoseuseinthediscretewavelettransformclusterin\n",
      "[11],whichchoosetousetheDaubechieswaveletforitsspikynature(buthere,\n",
      "11\n",
      "\n",
      "ratherthanaprioriselectinganorthogonalwaveletbasis,welearnadictionary\n",
      "thatistypicallynotorthogonal,butiswavelet-like).Nextweusedthed561102\n",
      "datafromhc-1,whichconsistsof4extracellularrecordingand1intracellular\n",
      "recording.Todospikedetectionwehigh-passthedatafrom300Hzand\n",
      "detectedspikeswhenthevoltagelevelpassedapositiveornegativethreshold,\n",
      "asin[2].Wechoosethisdatatheknownneurondisplaysdynamicpropertiesby\n",
      "showingperiodsofactivityandinactivity.TheintracellularrecordinginFigure\n",
      "4(a)showstheknownneuronisactiveforonlyabriefsectionoftherecorded\n",
      "signal,andistheninactivefortherestofthesignal.Thenonstationaritypasses\n",
      "alongtotheextracellularspiketrainandthedetectspikes.Weusedthe\n",
      "930detectedspikes,whichincluded202spikesfromtheknowncluster.Inorder\n",
      "tomodelthedynamicproperties,webinnedthedatainto31subgroupsof30\n",
      "spikestousewithourmultichanneldynamicHDP.Theresultsareshownin1\n",
      "availablefromhttp://crcns.org/data-sets/hc/hc-1\n",
      "7\n",
      "0.4\n",
      "0.50.4\n",
      "Probability\n",
      "Probability\n",
      "0.30.20.100\n",
      "0.30.20.1\n",
      "1\n",
      "2345678910NumberofGlobalClusters\n",
      "020\n",
      "2530354045NumberofDictionaryElements\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "(d)\n",
      "Figure3:ResultsfromHDP-DLond533101data.(a)approximateposterior\n",
      "probabilityonthenumberofglobalclusters(acrossallchannels);(b)approxi-\n",
      "mateposteriordistributiononthenumberofdictionaryelements;(c)sixmost\n",
      "useddictionaryelements;(d)examplesoftypicalspikesfromthedata.\n",
      "MethodsK-meansGMMK-meanswith2PCsGMMwith2PCsDP-DL\n",
      "HDP-DLMdHDP-DL\n",
      "Table3:Resultsford566102data[7].Channel1Channel2Channel3\n",
      "61.82%78.77%83.59%73.85%78.66%74.18%61.82%78.77%84.79%75.82%\n",
      "78.77%75.71%68.49%81.73%84.57%74.40%82.49%85.34%76.04%84.79%\n",
      "87.53%\n",
      "Channel489.39%76.59%89.39%88.73%88.73%88.40%90.48%\n",
      "Average78.39%75.82%78.69%79.76%80.88%82.66%84.71%\n",
      "RecordedSignal\n",
      "2000\n",
      "1500\n",
      "1000\n",
      "50010\n",
      "12\n",
      "\n",
      "20Time,s\n",
      "30\n",
      "40\n",
      "(a)\n",
      "30\n",
      "10.8\n",
      "25\n",
      "3\n",
      "11\n",
      "10\n",
      "5\n",
      "0.6\n",
      "20\n",
      "0.40.2\n",
      "15\n",
      "000.8\n",
      "10\n",
      "100\n",
      "5\n",
      "100\n",
      "100\n",
      "21\n",
      "18\n",
      "13\n",
      "5\n",
      "5\n",
      "10\n",
      "30\n",
      "0.6\n",
      "500\n",
      "5\n",
      "0.40.2\n",
      "200\n",
      "400600SpikeIndex\n",
      "800950\n",
      "00\n",
      "5\n",
      "100\n",
      "(b)\n",
      "5\n",
      "100\n",
      "(c)\n",
      "5\n",
      "100\n",
      "5\n",
      "10\n",
      "13\n",
      "\n",
      "ProbabilityofChanging\n",
      "IndexofMixtureDistribution\n",
      "Table3.Themodeladaptstothenonstationaryspikedynamicsbylearning\n",
      "theparameterstomodel(c)dynamicpropertiesatblock11(w11?1,indicating\n",
      "thatthedHDPhasdetectedachangeinthecharacteristicsofthespikes),where\n",
      "theknownneurongoesinactive.Thus,themodelismorelikelytodrawnew\n",
      "localclustersatthispoint,thenonstationarydata.Additionally,in\n",
      "Figure4(c)theglobalclusterusageshowsadramaticchangeattimeblock11,\n",
      "whereaclusterinthemodelgoesinactiveatthesametimetheknownneuronis\n",
      "inactive.Becausethedynamicmodelcanmapthesedynamicproperties,there-\n",
      "sultsimprovewhileusingthismodel.Additionally,weobtainaglobalaccuracy\n",
      "(acrossallchannels)of82.66%usingtheHDP-DLandanglobalaccuracyof\n",
      "84.71%usingthemultichanneldynamicHDP-DL(MdHDP-DL).Wealsotried\n",
      "theKFMonthesedata,butwewereunabletogetsatisfactoryresultswithit.\n",
      "Additionally,wealsocalculatedthetruepositiveandfalsepositivenumberto\n",
      "evaluateeachmethod,butduetothelimitedspace,thoseresultswereputin\n",
      "SupplementaryMaterial.1Theprobabilityofintroducinganewcomponentfor\n",
      "the11thblock\n",
      "0.80.60.40.20\n",
      "10\n",
      "20BlockIndex\n",
      "30\n",
      "(d)\n",
      "Figure4:ResultsofthemultichanneldHDPond561102.(a)40seconds\n",
      "oftheintracellularrecording\n",
      "ofd561102;(b)localclusterusagebyeachspikeinthed561102datain\n",
      "channel4;(c)globalclusterusageat(c)ttimeblocksforthedata\n",
      "d561102;(d)sharingweightwjateachtimeblocksinthefourthchannel.The\n",
      "spikein11occurswhentheknownneurongoesinactive.\n",
      "5\n",
      "Conclusions\n",
      "Wehavepresentedanewmethodforperformingmulti-channelspikesorting,\n",
      "inwhichtheunderlyingfeatures(dictionaryelements)andsortingareperformed\n",
      "jointly,whilealsoallowingtimeevolvingvariationinthespikestatistics.The\n",
      "modeladaptivelylearnsdictionaryelementsofawavelet-likenature(butnot\n",
      "orthogonal),withcharacteristicsliketheshapeofthespikes.Encouragingre-\n",
      "sultshavebeenpresentedonsimulatedandrealdatasets.Theauthorswould\n",
      "liketothankA.CalabreseforprovidingtheKFMcodesandprocessedd533101\n",
      "data.8\n",
      "AcknowledgementTheresearchreportedherewassupportedundertheDARPA\n",
      "HISTprogram.\n",
      "14\n",
      "\n",
      "2References\n",
      "[1]A.Bar-Hillel,A.Spiro,andE.Stark.Spikesorting:Bayesianclusteringof\n",
      "non-stationarydata.J.NeuroscienceMethods,2006.[2]A.CalabreseandL.\n",
      "Paniski.Kalmanmixturemodelforspikesortingofnon-stationarydata.\n",
      "J.NeuroscienceMethods,2010.[3]T.S.Ferguson.ABayesiananalysisof\n",
      "somenonparametricproblems.TheAnnalsofStatistics,1973.[4]Y.Gao,M.\n",
      "J.Black,E.Bienenstock,S.Shoham,andJ.P.Donoghue.Probabilisticinfer-\n",
      "enceofarmmotionfromneuralactivityinmotorcortex.Proc.Advancesin\n",
      "NIPS,2002.[5]J.Gasthaus,F.Wood,D.Gorur,andY.W.Teh.Dependent\n",
      "Dirichletprocessspikesorting.InAdvancesinNeuralInformationProcessing\n",
      "Systems,2009.[6]D.Gorur,C.Rasmussen,A.Tolias,F.Sinz,andN.Logo-\n",
      "thetis.Modellingspikeswithmixturesoffactoranalysers.PatternRecognition,\n",
      "2004.[7]D.A.Henze,Z.Borhegyi,J.Csicsvari,A.Mamiya,K.D.Harris,and\n",
      "G.Buzsaki.Intracellularfeauturespredictedbyextracellularrecordingsinthe\n",
      "hippocampusinvivo.J.Neurophysiology,2010.[8]J.A.Herbst,S.Gammeter,\n",
      "D.Ferrero,andR.H.R.Hahnloser.SpikesortingwithhiddenMarkovmodels.\n",
      "J.NeuroscienceMethods,2008.[9]M.D.D.M.Blei,andF.Bach.\n",
      "OnlinelearningforlatentDirichletallocation.Proc.NIPS,2010.[10]H.Ish-\n",
      "waranandL.F.James.Gibbssamplingmethodsforstick-breakingpriors.J.\n",
      "Am.Stat.Ass.,2001.[11]J.C.LetelierandP.P.Weber.Spikesortingbased\n",
      "ondiscretewavelettransformcots.J.NeuroscienceMethods,2000.[12]\n",
      "M.S.Lewicki.Areviewofmethodsforspikesorting:thedetectionandclassi-\n",
      "ofneuralactionpotentials.Network:ComputationinNeuralSystems,\n",
      "1998.[13]J.Mairal,F.Bach,J.Ponce,andG.Sapiro.Onlinelearningforma-\n",
      "trixfactorizationandsparsecoding.J.MachineLearningResearch,2010.[14]\n",
      "M.A.Nicolelis.Brain-machineinterfacestorestoremotorfunctionandprobe\n",
      "neuralcircuits.Naturereviews:Neuroscience,2003.[15]O.Papaspiliopou-\n",
      "losandG.O.Roberts.RetrospectiveMarkovChainMonteCarlomethodsfor\n",
      "Dirichletprocesshierarchiacalmodels.Biometrika,2008.[16]C.Pouzat,M.\n",
      "Delescluse,P.Viot,andJ.Diebolt.Improvedspike-sortingbymodeling\n",
      "statisticsandburst-dependentspikeamplitudeattenuation:AMarkovChain\n",
      "MonteCarloapproach.J.Neurophysiology,2004.[17]L.Ren,D.B.Dunson,\n",
      "andL.Carin.Thedynamichierarchicaldirichletprocess.InternationalCon-\n",
      "ferenceonMachineLearning,2008.[18]G.Santhanam,S.I.Ryu,B.M.Yu,A.\n",
      "Afshar,andK.V.Shenoy.Ahigh-performancebraincomputerinterface.Na-\n",
      "ture,2006.[19]J.Sethuraman.Aconstructiveofdirichletpriors.\n",
      "StatisticaSinica,4:639?650,1994.[20]Y.W.Teh,M.I.Jordan,M.J.Beal,\n",
      "andD.M.Blei.Hierarchicaldirichletprocesses.J.Am.Stat.Ass.,2005.[21]\n",
      "F.Wood,S.Roth,andM.J.Black.Modelingneuralpopulationspikingactiv-\n",
      "itywithGibbsdistributions.Proc.AdvancesinNeuralInformationProcessing\n",
      "Systems,2005.[22]W.Wu,M.J.Black,Y.Gao,E.Bienenstock,M.Serruya,\n",
      "A.Shaikhouni,andJ.P.Donoghue.Neuraldecodingofcursormotionusinga\n",
      "KalmanProc.AdvancesinNIPS,2003.9\n",
      "15\n",
      "\n",
      "PP5074.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP5074.pdf 14\n",
      "Low-rankmatrixreconstructionandclustering\n",
      "viaapproximatemessagepassing\n",
      "Authoredby:\n",
      "ToshiyukiTanaka\n",
      "RyosukeMatsushita\n",
      "Abstract\n",
      "Westudytheproblemofreconstructinglow-rankmatricesfromtheir\n",
      "noisyobservations.WeformulatetheproblemintheBayesianframework,\n",
      "whichallowsustoexploitstructuralpropertiesofmatricesinaddition\n",
      "tolow-rankedness,suchassparsity.Weproposeantapproximate\n",
      "messagepassingalgorithm,derivedfromthebeliefpropagationalgorithm,\n",
      "toperformtheBayesianinferenceformatrixreconstruction.Wehavealso\n",
      "successfullyappliedtheproposedalgorithmtoaclusteringproblem,by\n",
      "formulatingtheproblemofclusteringasalow-rankmatrixreconstruc-\n",
      "tionproblemwithanadditionalstructuralproperty.Numericalexper-\n",
      "imentsshowthattheproposedalgorithmoutperformsLloyd'sK-means\n",
      "algorithm.\n",
      "1PaperBody\n",
      "Low-rankednessofmatriceshasfrequentlybeenexploitedwhenonereconstructs\n",
      "amatrixfromitsnoisyobservations.Insuchproblems,thereareoftende-\n",
      "mandstoincorporateadditionalstructuralpropertiesofmatricesinaddition\n",
      "tothelow-rankedness.Inthispaper,weconsiderthecasewhereamatrixA0\n",
      "?Rm?NtobereconstructedisfactoredasA0=U0V0?,U0?Rm?r,\n",
      "V0?RN?r(r?m,N),andwhereoneknowsstructuralpropertiesofthe\n",
      "factorsU0andV0apriori.Sparsenessandnon-negativityofthefactorsare\n",
      "popularexamplesofsuchstructuralproperties[1,2].Sincethepropertiesof\n",
      "thefactorstobeexploitedvaryaccordingtotheproblem,itisdesirablethat\n",
      "areconstructionmethodhasenoughytoincorporateawidevariety\n",
      "ofproperties.TheBayesianapproachachievessuchybyallowingus\n",
      "toselectpriordistributionsofU0andV0aprioriknowledgeonthe\n",
      "structuralproperties.TheBayesianapproach,however,ofteninvolvescompu-\n",
      "tationallyexpensiveprocessessuchashigh-dimensionalintegrations,thereby\n",
      "requiringapproximateinferencemethodsinpracticalimplementations.Monte\n",
      "CarlosamplingmethodsandvariationalBayesmethodshavebeenproposedfor\n",
      "1\n",
      "\n",
      "low-rankmatrixreconstructiontomeetthisrequirement[3?5].Wepresentin\n",
      "thispaperanapproximatemessagepassing(AMP)basedalgorithmforBayesian\n",
      "lowrankmatrixreconstruction.Developedinthecontextofcompressedsensing,\n",
      "theAMPalgorithmreconstructssparsevectorsfromtheirlinearmeasurements\n",
      "withlowcomputationalcost,andachievesacertaintheoreticallimit[6].AMP\n",
      "algorithmscanalsobeusedforapproximatingBayesianinferencewithalarge\n",
      "classofpriordistributionsofsignalvectorsandnoisedistributions[7].These\n",
      "successesofAMPalgorithmsmotivatetheuseofthesameideaforlow-rank\n",
      "matrixreconstruction.TheIterFacalgorithmfortherank-onecase[8]hasbeen\n",
      "derivedasanAMPalgorithm.AnAMPalgorithmforthegeneral-rankcaseis\n",
      "proposedin[9],which,however,canonlytreatestimationofposteriormeans.\n",
      "Weextendtheiralgorithmsothatonecandealwithotherestimationssuchas\n",
      "themaximumaposteriori(MAP)estimation.Itisthecontributionofthis\n",
      "paper.1\n",
      "Asthesecondcontribution,weapplythederivedAMPalgorithmtoK-means\n",
      "typeclusteringtoobtainanoveltclusteringalgorithm.Itisbasedonthe\n",
      "observationthatourformulationofthelow-rankmatrixreconstructionproblem\n",
      "includestheclusteringproblemasaspecialcase.Althoughtheideaofapplying\n",
      "low-rankmatrixreconstructiontoclusteringisnotnew[10,11],ourproposed\n",
      "algorithmis,toourknowledge,thethatdirectlydealswiththeconstraint\n",
      "thateachdatumshouldbeassignedtoexactlyoneclusterintheframeworkof\n",
      "low-rankmatrixreconstruction.Wepresentresultsofnumericalexperiments,\n",
      "whichshowthattheproposedalgorithmoutperformsLloyd?sK-meansalgo-\n",
      "rithm[12]whendataarehigh-dimensional.Recently,AMPalgorithmsfordic-\n",
      "tionarylearningandblindcalibration[13]andformatrixreconstructionwitha\n",
      "generalizedobservationmodel[14]wereproposed.Althoughourworkhassome\n",
      "similaritiestothesestudies,itinthatwetherankrratherthanthe\n",
      "ratior/mwhentakingthelimitm,N??inthederivationofthealgorithm.\n",
      "Anotheristhatourformulation,explainedinthenextsection,does\n",
      "notassumestatisticalindependenceamongthecomponentsofeachrowofU0\n",
      "andV0.Adetailedcomparisonamongthesealgorithmsremainstobemade.\n",
      "22.1\n",
      "ProblemsettingLow-rankmatrixreconstruction\n",
      "Weconsiderthefollowingproblemsetting.AmatrixA0?Rm?Ntobe\n",
      "estimatedisbytwomatricesU0:=(u0,1,...,u0,m)??Rm?rand\n",
      "V0:=(v0,1,...,v0,N)??RN?rasA0:=U0V0?,whereu0,i,v0,j?Rr\n",
      ".Weconsiderthecasewherer?m,N.ObservationsofA0arecorruptedby\n",
      "additivenoiseW?Rm?N,whosecomponentsWi,jarei.i.d.Gaussianrandom\n",
      "variablesfollowingN(0,m?).Here?>0isanoisevarianceparameterand\n",
      "N(a,?2)denotestheGaussiandistributionwithmeanaandvariance?2\n",
      ".Thefactorminthenoisevarianceisintroducedtoallowaproperscalingin\n",
      "thelimitwheremandNgotoyinthesameorder,whichisemployed\n",
      "inderivingthealgorithm.AnobservedmatrixA?Rm?NisgivenbyA:=A0\n",
      "+W.ReconstructingA0and(U0,V0)fromAistheproblemconsidered\n",
      "inthispaper.WetaketheBayesianapproachtoaddressthisproblem,in\n",
      "whichonerequirespriordistributionsofvariablestobeestimated,aswellas\n",
      "2\n",
      "\n",
      "conditionaldistributionsrelatingobservationswithvariablestobeestimated.\n",
      "Thesedistributionsneednotbethetrueonesbecauseinsomecasestheyarenot\n",
      "availablesothatonehastoassumethemarbitrarily,andinsomeothercases\n",
      "oneexpectsadvantagesbyassumingtheminsomespmannerinviewof\n",
      "computationalInthispaper,wesupposethatoneusesthetrue\n",
      "conditionaldistribution()11p(A|U0,V0)=?A?U0V0??2F,(1)mN\n",
      "exp?2m?(2?m?)2where???FdenotestheFrobeniusnorm.Meanwhile,\n",
      "wesupposethattheassumedpriordistributionsofU0andV0,denotedbyp?U\n",
      "andp?V,respectively,maybetfromthetruedistributions?pUand\n",
      "pV,respectively.Werestrictp?Uandp?Vtodistributionsoftheformp?U\n",
      "(U0)=ip?u(u0,i)?andp?V(V0)=jp?v(v0,j),respectively,whichallows\n",
      "ustoconstructcomputationallytalgorithms.WhenU?p?U(U)andV\n",
      "?p?V(V),theposteriordistributionof(U,V)givenAis()1?A?UV??2F\n",
      "p?U(U)?pV(V).(2)p?(U,V|A)?exp?2m?Priorprobabilitydensity\n",
      "functions(p.d.f.s)p?uandp?vcanbeimproper,thatis,theycanintegrateto\n",
      "y,aslongastheposteriorp.d.f.(2)isproper.Wealsoconsidercases\n",
      "wheretheassumedrankr?maybetfromthetruerankr.Wethus\n",
      "supposethatestimatesUandVareofsizem?r?andN?r?,respectively.We\n",
      "considertwoproblemsappearingintheBayesianapproach.Theproblem,\n",
      "whichwecallthemarginalizationproblem,istocalculatethemarginalposterior\n",
      "distributionsgivenA,???p?i,j(ui,vj|A):=p?(U,V|A)dukdvl.(3)\n",
      "k?=i?\n",
      "l?=j\n",
      "TheseareusedtocalculatetheposteriormeanE[UV|A]andthe??\n",
      "marginalMAPestimatesMMAPuMMAP:=argmaxp?(u,v|A)dvandv\n",
      ":=argmaxp?i,j(u,v|A)du.Becauseui,jvij2\n",
      "calculationofp?i,j(ui,vj|A)typicallyinvolveshigh-dimensionalintegra-\n",
      "tionsrequiringhighcomputationalcost,approximationmethodsareneeded.\n",
      "Thesecondproblem,whichwecalltheMAPproblem,istocalculatetheMAP\n",
      "estimateargmaxU,Vp?(U,V|A).Itisformulatedasthefollowingoptimiza-\n",
      "tionproblem:minCMAP(U,V),U,V\n",
      "(4)\n",
      "whereCMAP(U,V)isthenegativelogarithmof(2):CMAP(U,V):=\n",
      "mN??1?A?UV??2F?logp?u(ui)?logp?v(vj).2m?i=1j=1\n",
      "(5)\n",
      "Because?A?UV??2Fisanon-convexfunctionof(U,V),itisgenerally\n",
      "hardtotheglobaloptimalsolutionsof(4)andthereforeapproximation\n",
      "methodsareneededinthisproblemaswell.2.2\n",
      "Clusteringaslow-rankmatrixreconstruction\n",
      "Aclusteringproblemcanbeformulatedasaproblemoflow-rankmatrix\n",
      "reconstruction[11].Supposethatv0,j?\n",
      "f\n",
      "e1,...,er\n",
      "g\n",
      ",j=1,...,N,\n",
      "whereel?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "risthevectorwhoselthcomponentis1andtheothersare0.\n",
      "WhenV0andU0areajfollowsoneoftherGaussiandistributions?0,l\n",
      ",m?I),l=1,...,r,whereu?0,listhelthcolumnofU0.Weregardthat\n",
      "eachGaussianN(u?0,lbeingthecenterofclusterlandv0,jrepresentingthe\n",
      "clusterdistributionacluster,uassignmentofthedatumaj.Onecan\n",
      "3\n",
      "\n",
      "thenperformclusteringonthedataset\n",
      "f\n",
      "a1,...,aN\n",
      "g\n",
      "byreconstructingU0\n",
      "andV0fromA=(a1,...,aN)underthestructuralconstraintthatevery\n",
      "rowofV0shouldbelongto\n",
      "f\n",
      "e1,...,er?\n",
      "g\n",
      ",wherer?isanassumednumberof\n",
      "clusters.LetusconsidermaximumlikelihoodestimationargmaxU,Vp(A|U,\n",
      "V),orequivalently,MAPesti?r?mationwiththe(improper)uniformprior\n",
      "distributionsp?u(u)=1andp?v(v)=r??1l=1?(v?el).Thecorresponding\n",
      "MAPproblemismin\n",
      "r,V?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N??rU?Rm??\n",
      "?A?UV??2F\n",
      "subjecttovj?\n",
      "f\n",
      "e1,...,er?\n",
      "g\n",
      ".\n",
      "(6)\n",
      "?N?r?WhenVtheconstraints,theobjectivefunction?A?UV\n",
      "??2F=j=1l=1?aj??l?22I(vj=el)isthesumofsquareddistances,\n",
      "eachofwhichisbetweenadatumandthecenterofutheclusterthatthe\n",
      "datumisassignedto.Theoptimizationproblem(6),itsobjectivefunction,\n",
      "andclusteringbasedonitarecalledinthispapertheK-meansproblem,the\n",
      "K-meanslossfunction,andtheK-meansclustering,respectively.Onecanalso\n",
      "usethemarginalMAPestimationforclustering.IfU0andV0followp?U\n",
      "andp?V,respectively,themarginalMAPestimationisoptimalinthesense\n",
      "thatitmaximizestheexpectationofaccuracywithrespecttop?(V0|A).Here,\n",
      "accuracyisasthefractionofcorrectlyassigneddataamongalldata.We\n",
      "calltheclusteringusingapproximatemarginalMAPestimationthemaximum\n",
      "accuracyclustering,evenwhenincorrectpriordistributionsareused.\n",
      "3\n",
      "Previouswork\n",
      "Existingmethodsforapproximatelysolvingthemarginalizationproblemand\n",
      "theMAPproblemaredividedintostochasticmethodssuchasMarkov-Chain\n",
      "Monte-Carlomethodsanddeterministicones.Apopulardeterministicmethod\n",
      "istousethevariationalBayesianformalism.ThevariationalBayesmatrix\n",
      "factorization[4,5]approximatestheposteriordistributionp(U,V|A)asthe\n",
      "productVBoftwofunctionspVBU(U)andpV(V),whicharedetermined\n",
      "sothattheKullback-Leibler(KL)VBVBdivergencefrompU(U)pV(V)\n",
      "top(U,V|A)isminimized.GlobalminimizationoftheKLdivergenceis\n",
      "exceptforsomespecialcases[15],sothataniterativemethodtoobtain\n",
      "alocalminimumisusuallyadopted.ApplyingthevariationalBayesmatrix\n",
      "factorizationtotheMAPproblem,oneobtainstheiteratedconditionalmodes\n",
      "(ICM)algorithm,whichalternatesminimizationofCMAP(U,V)overUfor\n",
      "VandminimizationoverVforU.Therepresentativealgorithmto\n",
      "solvetheK-meansproblemapproximatelyisLloyd?sK-meansalgorithm[12].\n",
      "Lloyd?sK-meansalgorithmisregardedastheICMalgorithm:Italternates\n",
      "minimizationoftheK-meanslossfunctionoverUforVandminimization\n",
      "overVforUiteratively.3\n",
      "Algorithm1(Lloyd?sK-meansalgorithm).ntl=\n",
      "N?\n",
      "I(vjt=el),\n",
      "?tl=u\n",
      "4\n",
      "\n",
      "j=1\n",
      "ljt+1=arg\n",
      "min\n",
      "l?\n",
      "f\n",
      "1,...,?r\n",
      "g\n",
      "?tl?22,?aj?u\n",
      "N1?ajI(vjt=el),ntlj=1\n",
      "(7a)\n",
      "vjt+1=elt+1.\n",
      "(7b)\n",
      "j\n",
      "Throughoutthispaper,werepresentanalgorithmbyasetofequationsas\n",
      "intheabove.Thisrepresentationmeansthatthealgorithmbeginswithaset\n",
      "ofinitialvaluesandrepeatstheupdateofthevariablesusingtheequations\n",
      "presenteduntilitsatisessomestoppingcriteria.Lloyd?sK-meansalgorithm\n",
      "beginswithasetofinitialassignmentsV0?\n",
      "f\n",
      "e1,...,er?\n",
      "g\n",
      "N.Thisalgorithm\n",
      "easilygetsstuckinlocalminimaanditsperformanceheavilydependsonthe\n",
      "initialvaluesofthealgorithm.Somemethodsforinitializationtoobtainabetter\n",
      "localminimumareproposed[16].Maximumaccuracyclusteringcanbesolved\n",
      "approximatelybyusingthevariationalBayesmatrixfactorization,sinceitgives\n",
      "anapproximationtothemarginalposteriordistributionofvjgivenA.\n",
      "44.1\n",
      "ProposedalgorithmApproximatemessagepassingalgorithmforlow-rank\n",
      "matrixreconstruction\n",
      "WediscussthegeneralideaoftheAMPalgorithmandadvantagesof\n",
      "theAMPalgorithmcomparedwiththevariationalBayesmatrixfactorization.\n",
      "TheAMPalgorithmisderivedbyapproximatingthebeliefpropagationmessage\n",
      "passingalgorithminawaythoughttobeasymptoticallyexactforlarge-scale\n",
      "problemswithappropriaterandomness.Fixedpointsofthebeliefpropagation\n",
      "messagepassingalgorithmcorrespondtolocalminimaoftheKLdivergencebe-\n",
      "tweenakindoftrialfunctionandtheposteriordistribution[17].Therefore,the\n",
      "beliefpropagationmessagepassingalgorithmcanberegardedasaniterativeal-\n",
      "gorithmbasedonanapproximationoftheposteriordistribution,whichiscalled\n",
      "theBetheapproximation.TheBetheapproximationcandependenceof\n",
      "randomvariables(dependencebetweenUandVinp?(U,V|A)inourprob-\n",
      "lem)tosomeextent.Therefore,onecanintuitivelyexpectthatperformance\n",
      "oftheAMPalgorithmisbetterthanthatofthevariationalBayesmatrixfac-\n",
      "torization,whichtreatsUandVasiftheywereindependentinp?(U,V|A).\n",
      "AnimportantpropertyoftheAMPalgorithm,asidefromitsandef-\n",
      "fectiveness,isthatonecanpredictperformanceofthealgorithmaccuratelyfor\n",
      "large-scaleproblemsbyusingasetofequations,calledthestateevolution[6].\n",
      "Analysiswiththestateevolutionalsoshowsthatrequirediterationnumbersare\n",
      "O(1)evenwhentheproblemsizeislarge.Althoughwecanpresentthestate\n",
      "evolutionforthealgorithmproposedinthispaperandgiveaproofofitsvalidity\n",
      "like[8,18],wedonotdiscussthestateevolutionhereduetothelimitedspace\n",
      "available.Weintroduceaone-parameterextensionoftheposteriordistribution\n",
      "p?(U,V|A)totreatthemarginalizationproblemandtheMAPproblemina\n",
      "5\n",
      "\n",
      "manner.Itisasfollows:()()??p?(U,V|A;?)?exp??A\n",
      "?UV??2Fp?U(U)?pV(V),2m?\n",
      "(8)\n",
      "whichisproportionaltop?(U,V|A)?,where?>0istheparameter.When\n",
      "?=1,p?(U,V|A;?)isreducedtop?(U,V|A).Inthelimit???,the\n",
      "distributionp?(U,V|A;?)concentratesonthemaximaofp?(U,V|A).An\n",
      "algorithmforthemarginalizationproblemonp?(U,V|A;?)isparticularized\n",
      "tothealgorithmsforthemarginalizationproblemandfortheMAPproblem\n",
      "fortheoriginalposteriordistributionp?(U,V|A)byletting?=1and??\n",
      "?,respectively.TheAMPalgorithmforthemarginalizationproblemonp?(U,\n",
      "V|A;?)isderivedinawaysimilartothatdescribedin[9],asdetailedinthe\n",
      "SupplementaryMaterial.Inthederivedalgorithm,thevaluesofvariablesBut\n",
      "=(btu,1,...,btu,m)??Rm??r,Bvt=(btv,1,...,btv,N)??RN??r,\n",
      "?tu?Rr???r,?tv?Rr???r,Ut=(ut1,...,utm)??Rm??r,t?tVt=\n",
      "(v1t,...,vN)?RN??r,S1t,...,Sm?Rr???r,andT1t,...,TNt?\n",
      "Rr???rarecalculatediteratively,wherethesuperscriptt?N?\n",
      "f\n",
      "0\n",
      "g\n",
      "represents\n",
      "iterationnumbers.Variableswithanegativeiterationnumberareas0.\n",
      "Thealgorithmisasfollows:4\n",
      "Algorithm2.But=\n",
      "N11t?1?tAVt?UTj,m?m?j=1\n",
      "?tu=\n",
      "NN1?t11?t(Vt)?Vt+Tj?T,(9a)m??m?j=1m?j=1j\n",
      "uti=f(btu,i,?tu;p?u),\n",
      "Sit=G(btu,i,?tu;p?u),mmm11?t1t?t1?t1?tSi,?tv=AU\n",
      "?V(Ut)?Ut+Si?S,Bvt=m?m?m??m?i=1m?i=1ii=1vjt+1=f\n",
      "(btv,j,?tv;p?v),\n",
      "Tjt+1=G(btv,j,?tv;p?v).\n",
      "(9b)(9c)(9d)\n",
      "Algorithm2isalmostsymmetricinUandV.Equations(9a)?(9b)and\n",
      "(9c)?(9d)updatequantitiesrelatedtotheestimatesofU0andV0,respectively.\n",
      "ThealgorithmrequiresaninitialvalueV0andbeginswithTj0=O.The\n",
      "functionsf(?,?;p?):Rr??Rr???r?Rr?andG(?,?;p?):Rr??Rr???r?\n",
      "Rr???r,whichhaveap.d.f.p?:Rr??Rasaparameter,areby??f\n",
      "(b,?;p?)f(b,?;p?):=u?q(u;b,?,p?)du,G(b,?;p?):=,(10)?bwhere\n",
      "q?(u;b,?,p?)isthenormalizedp.d.f.ofuby((1))q?(u;b,?,p?)?\n",
      "exp??u??u?b?u?logp?(u).2\n",
      "(11)\n",
      "Onecanseethatf(b,?;p?)isthemeanofthedistributionq?(u;b,?,\n",
      "p?)andthatG(b,?;p?)isitscovariancematrixscaledby?.Thefunction\n",
      "f(b,?;p?)neednotberentiableeverywhere;Algorithm2worksiff(b,\n",
      "?;p?)istiableatbforwhichoneneedstocalculateG(b,?;p?)in\n",
      "runningthealgorithm.Weassumeintherestofthissectiontheconvergenceof\n",
      "Algorithm2,althoughtheconvergenceis?????notguaranteedingeneral.\n",
      "LetBu?,Bv?,??betheconvergedvaluesu,?v,Si,Tj,U,andVof\n",
      "therespectivevariables.First,considerrunningAlgorithm2with?=1.The\n",
      "6\n",
      "\n",
      "marginalposteriordistributionisthenapproximatedas???v).?u)?q(vj;\n",
      "b?p?i,j(ui,vj|A)?q?(ui;b?v,j,?v,pu,i,?u,p\n",
      "(12)\n",
      "???Sinceu?ofq?(u;b??u)andq?(v;b??v),respectively,theiandvj\n",
      "arethemeansu,i,?u,pv,j,?v,p???posteriormeanE[UV|A]=UV\n",
      "p?(U,V|A)dUdVisapproximatedas\n",
      "E[UV?|A]?U?(V?)?.\n",
      "(13)\n",
      "andvjMMAPareapproximatedasThemarginalMAPestimatesuMMAP\n",
      "i??v).vjMMAP?argmaxq?(v;b?v,j,?v,p\n",
      "??u),uMMAP?argmaxq?(u;b?u,i,?u,pi\n",
      "v\n",
      "u\n",
      "(14)\n",
      "Takingthelimit???inAlgorithm2yieldsanalgorithmfortheMAP\n",
      "problem(4).Inthiscase,thefunctionsfandGarereplacedwith[1]?f?(b,\n",
      "?;p?)f?(b,?;p?):=argminu??u?b?u?logp?(u),G?(b,?;p?):=.\n",
      "(15)u2?bOnemaycalculateG?(b,?;p?)fromtheHessianoflogp?(u)at\n",
      "u=f?(b,?;p?),denotedbyH,()?1viatheidentityG?(b,?;p?)=??H.\n",
      "Thisidentityfollowsfromtheimplicitfunctiontheoremundersomeadditional\n",
      "assumptionsandhelpsinthecasewheretheexplicitformoff?(b,?;p?)isnot\n",
      "available.TheMAPestimateisapproximatedby(U?,V?).4.2\n",
      "Propertiesofthealgorithm\n",
      "Algorithm2hasseveralplausibleproperties.First,ithasalowcomputa-\n",
      "tionalcost.ThecomputationalcostperiterationisO(mN),whichislinearin\n",
      "thenumberofcomponentsofthematrixA.Calculationoff(?,?;p?)andG(?,\n",
      "?;p?)isperformedO(N+m)timesperiteration.Theconstant5\n",
      "factordependsonp?and?.Calculationofffor?<?generallyinvolves\n",
      "anr?-dimensionalnumericalintegration,althoughtheyarenotneededincases\n",
      "whereananalyticexpressionoftheintegralisavailableandcaseswherethe\n",
      "variablestakeonlydiscretevalues.Calculationoff?involvesminimization\n",
      "overanr?-dimensionalvector.When?logp?isaconvexfunctionand?is\n",
      "positivethisminimizationproblemisconvexandcanbesolved\n",
      "atrelativelylowcost.Second,Algorithm2hasaformsimilartothatofan\n",
      "algorithmbasedonthevariationalBayesianmatrixfactorization.Infact,if\n",
      "thelasttermsontheright-handsidesofthefourequationsin(9a)and(9c)\n",
      "areremoved,theresultingalgorithmisthesameasanalgorithmbasedonthe\n",
      "variationalBayesianmatrixfactorizationproposedin[4]and,inparticular,the\n",
      "sameastheICMalgorithmwhen???.(Note,however,that[4]onlytreats\n",
      "thecasewherethepriorsp?uandp?varemultivariateGaussiandistributions.)\n",
      "NotethatadditionalcomputationalcostfortheseextratermsisO(m+N),\n",
      "whichistcomparedwiththecostofthewholealgorithm,whichis\n",
      "O(mN).Third,whenonedealswiththeMAPproblem,thevalueofCMAP\n",
      "(U,V)mayincreaseiniterationsofAlgorithm2.Thefollowingproposition,\n",
      "however,guaranteesoptimalityoftheoutputofAlgorithm2inacertainsense,\n",
      "ifithasconverged.?Proposition1.Let(U?,V?,S1?,...,Sm,T?,\n",
      "7\n",
      "\n",
      "...,TN?)beapointoftheAMPalgorithm?m1??NfortheMAP\n",
      "problemandsupposethati=1Siandj=1Tj?arepositiveThen\n",
      "U?isaglobalminimumofCMAP(U,V?)andV?isaglobalminimumof\n",
      "CMAP(U?,V).TheproofisintheSupplementaryMaterial.Thekeytothe\n",
      "proofisthefollowingreformulation:N)][()(1?MAPtt?1Tjt(U?Ut?1\n",
      ")?U=argminC(U,V)?tr(U?U)U2m?j=1t\n",
      "(16)\n",
      "?NIfj=1Tjtispositivethesecondtermoftheminimandisthe\n",
      "negativesquaredpseudometricbetweenUandUt?1,whichisinterpretedasa\n",
      "penaltyonnearnesstothetemporalestimate.?m?NPositive\n",
      "ofi=1Sitandj=1Tjtholdsinalmostallcases.Infact,weonlyhaveto\n",
      "assumelim???G(b,?;p?)=G?(b,?;p?),sinceG(b,?;p?)isascaled\n",
      "covariancematrixofq?(u;b,?,p?),whichispositiveItfollows\n",
      "fromProposition1thatanypointoftheAMPalgorithmisalsoa\n",
      "pointoftheICMalgorithm.Ithastwoimplications:(i)ExecutionoftheICM\n",
      "algorithminitializedwiththeconvergedvaluesoftheAMPalgorithmdoesnot\n",
      "improveCMAP(Ut,Vt).(ii)TheAMPalgorithmhasnotmorepoints\n",
      "thantheICMalgorithm.ThesecondimplicationmayhelptheAMPalgorithm\n",
      "avoidgettingstuckinbadlocalminima.4.3\n",
      "ClusteringviaAMPalgorithm\n",
      "OnecanusetheAMPalgorithmfortheMAPproblemtoperformtheK-\n",
      "meansclusteringbyletting?r?p?u(u)=1andp?v(v)=r??1l=1?(v?el\n",
      ").Notingthatf?(b,?;p?v)ispiecewiseconstantwithrespecttobandhence\n",
      "G?(b,?;p?v)isOalmosteverywhere,weobtainthefollowingalgorithm:\n",
      "Algorithm3(AMPalgorithmfortheK-meansclustering).11AVt,?tu=(V\n",
      "t)?Vt,Ut=But(?tu)?1,m?m?1?t1tt11Bvt=AU?VS,?tv\n",
      "=(Ut)?Ut?St,m??m??[1]v??tvv?v?btv,j.vjt+1=argmin\n",
      "v?\n",
      "f\n",
      "e1,...,er?\n",
      "g\n",
      "2But=\n",
      "St=(?tu)?1,\n",
      "(17a)(17b)(17c)\n",
      "ItisinitializedwithanassignmentV0?\n",
      "f\n",
      "e1,...,er?\n",
      "g\n",
      "N.Algorithm3\n",
      "isrewrittenasfollows:ntl=\n",
      "N?j=1\n",
      "ljt+1=arg\n",
      "I(vjt=el),\n",
      "?tl=u\n",
      "N1?ajI(vjt=el),ntlj=1\n",
      "[12mm]?tl?22+tI(vjt=el)?t,?aj?unlnll?\n",
      "f\n",
      "1,...,?r\n",
      "g\n",
      "m?min\n",
      "6\n",
      "(18a)vjt+1=elt+1.j\n",
      "(18b)\n",
      "Theparameter?appearinginalgorithmdoesnotexistinthe?K-means\n",
      "clusteringproblem.In?themmfact,?appearsbecausem?2i=1A2ijSitwas\n",
      "estimatedby?m?1i=1SitinderivingAlgorithm2,whichcanbefor\n",
      "large-sizedproblems.Inpractice,weproposeusingm?2N?1?A?Ut(Vt)?\n",
      "?2Fasatemporaryestimateof?attthiteration.WhiletheAMPalgorithm\n",
      "8\n",
      "\n",
      "fortheKmeansclusteringupdatesthevalueofUinthesamewayasLloyd?s\n",
      "K-meansalgorithm,itperformsassignmentsofdatatoclustersinat\n",
      "way.IntheAMPalgorithm,inadditiontodistancesfromdatatocentersof\n",
      "clusters,theassignmentatpresentistakenintoconsiderationintwoways:(i)A\n",
      "datumislesslikelytobeassignedtotheclusterthatitisassignedtoatpresent.\n",
      "(ii)Dataaremorelikelytobeassignedtoaclusterwhosesizeatpresentis\n",
      "smaller.Theformercanintuitivelybeunderstoodbyobservingthatifvjt=el\n",
      ",oneshouldtakeaccountofthefactthattheclustercenter?tlisbiasedtoward\n",
      "aj.Theterm2m(ntl)?1I(vjt=el)in(18b)correctsthisbias,which,asit\n",
      "ushouldbe,isinverselyproportionaltotheclustersize.TheAMPalgorithm\n",
      "formaximumaccuracyclusteringisobtainedbyletting?=1andp?v(v)be\n",
      "adiscretedistributionon\n",
      "f\n",
      "e1,...,er?\n",
      "g\n",
      ".Afterthealgorithmconverges,arg\n",
      "maxvq?(v;vj?,???v)v,pgivestheclusterassignmentofthejthdatum\n",
      "andU?givestheestimateoftheclustercenters.\n",
      "5\n",
      "Numericalexperiments\n",
      "Weconductednumericalexperimentsonbothcialandrealdatasets\n",
      "toevaluateperformanceoftheproposedalgorithmsforclustering.Intheex-\n",
      "perimentondatasets,wesetm=800?0,l,l=1,...,r,were\n",
      "generatedaccordingtotheandN=1600andletr?=r.Clustercentersu\n",
      "multivariateGaussiandistributionN(0,I).Clusterassignmentsv0,j,j=1,.\n",
      "..,N,weregeneratedaccordingtotheuniformdistributionon\n",
      "f\n",
      "e1,...,\n",
      "er\n",
      "g\n",
      ".For?=0.1andr,wegenerated500probleminstancesandsolved\n",
      "themwithealgorithms:Lloyd?sK-meansalgorithm(K-means),theAMP\n",
      "algorithmfortheK-meansclustering(AMP-KM),thevariationalBayesmatrix\n",
      "factorization[4]formaximumaccuracyclustering(VBMF-MA),theAMPalgo-\n",
      "rithmformaximumaccuracyclustering(AMP-MA),andtheK-means++[16].\n",
      "TheK-means++updatesthevariablesinthesamewayasLloyd?sK-means\n",
      "algorithmwithaninitialvaluechoseninasophisticatedmanner.Fortheother\n",
      "algorithms,initialvaluesvj0,j=1,...,N,wererandomlygeneratedfrom\n",
      "thesamedistributionasv0,j.WeusedthetruepriordistributionsofUandV\n",
      "formaximumaccuracyclustering.WeranLloyd?sK-meansalgorithmandthe\n",
      "K-means++untilnochangewasobserved.WerantheAMPalgorithmforthe\n",
      "K-meansclusteringuntileitherVt=Vt?1orVt=Vt?2isThisis\n",
      "becauseweobservedoscillationsofassignmentsofasmallnumberofdata.For\n",
      "theothertwoalgorithms,weterminatedtheiterationwhen?Ut?Ut?1?2F\n",
      "<10?15?Ut?1?2Fand?Vt?Vt?1?2F<10?15?Vt?1?2Fweremetorthe\n",
      "numberofiterationsexceeded3000.Wethenevaluatedthefollowingperfor-\n",
      "mancemeasuresfortheobtainedsolution(U?,V?):?N??:=N1N??22),\n",
      "wherea?NormalizedK-meansloss?A?U?(V?)??2F/(j=1?aj?aj=1aj\n",
      ".?N?AccuracymaxPN?1j=1I(Pvj?=v0,j),wherethemaximizationis\n",
      "takenoverallr-by-rpermutationmatrices.WeusedtheHungarianalgorithm\n",
      "[19]tosolvethismaximizationproblemtly.?Numberofiterations\n",
      "neededtoconverge.Wecalculatedtheaveragesandthestandarddeviationsof\n",
      "theseperformancemeasuresover500instances.Weconductedtheaboveexper-\n",
      "imentsforvariousvaluesofr.Figure1showstheresults.TheAMPalgorithm\n",
      "9\n",
      "\n",
      "fortheK-meansclusteringachievesthesmallestKmeanslossamongthee\n",
      "algorithms,whiletheLloyd?sK-meansalgorithmandK-means++showlarge\n",
      "K-meanslossesforr?5.Weemphasizethatallthethreealgorithmsareaimed\n",
      "tominimizethesameK-meanslossandthelieinthealgorithmsfor\n",
      "minimization.TheAMPalgorithmformaximumaccuracyclusteringachieves\n",
      "thehighestaccuracyamongtheealgorithms.Italsoshowsfastconvergence.\n",
      "Inparticular,theconvergencespeedoftheAMPalgorithmformaximumac-\n",
      "curacyclusteringiscomparabletothatoftheAMPalgorithmfortheK-means\n",
      "clusteringwhenthetwoalgorithmsshowsimilaraccuracy(r<9).Thisisin\n",
      "contrasttothecommonobservationthatthevariationalBayesmethodoften\n",
      "showsslowerconvergencethantheICMalgorithm.7\n",
      "1\n",
      "1K-meansAMP-KMVBMF-MAAMP-MAK-means++\n",
      "K-meansAMP-KMVBMF-MAAMP-MAK-means++\n",
      "0.8\n",
      "0.99\n",
      "Accuracy\n",
      "NormalizedK-meansloss\n",
      "0.995\n",
      "0.9850.98\n",
      "0.6\n",
      "0.4\n",
      "0.2\n",
      "0.9750.97\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "r\n",
      "12\n",
      "14\n",
      "16\n",
      "0\n",
      "18\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "(a)\n",
      "r\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "(b)\n",
      "10\n",
      "\n",
      "2500\n",
      "1K-meansAMP-KMVBMF-MAAMP-MAK-means++\n",
      "2000\n",
      "Numberofiterations\n",
      "10\n",
      "0.8\n",
      "Accuracy\n",
      "1500\n",
      "1000\n",
      "500\n",
      "0.6\n",
      "0.4AMP-KMVBMF-MAAMP-MA\n",
      "0.2\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "r\n",
      "12\n",
      "14\n",
      "16\n",
      "0\n",
      "18\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "Iterationnumber\n",
      "(c)\n",
      "40\n",
      "50\n",
      "(d)\n",
      "Figure1:(a)?(c)Performancefortr:(a)NormalizedK-meansloss.\n",
      "(b)Accuracy.(c)Numberofiterationsneededtoconverge.(d)Dynamicsforr\n",
      "=5.Averageaccuracyateachiterationisshown.Errorbarsrepresentstandard\n",
      "deviations.\n",
      "0.45\n",
      "0.75\n",
      "K-means++AMP-KM\n",
      "K-means++AMP-KM0.7\n",
      "0.44\n",
      "Accuracy\n",
      "NormalizedK-meansloss\n",
      "0.46\n",
      "11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.430.42\n",
      "0.65\n",
      "0.6\n",
      "0.410.550.40.39\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "Numberoftrials\n",
      "40\n",
      "0.5\n",
      "50\n",
      "(a)\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "Numberoftrials\n",
      "40\n",
      "50\n",
      "(b)\n",
      "Figure2:Performancemeasuresinreal-dataexperiments.(a)Normalized\n",
      "K-meansloss.(b)Accuracy.Theresultsforthe50trialsareshowninthe\n",
      "descendingorderofperformanceforAMP-KM.TheworsttworesultsforAMP-\n",
      "KMareoutoftherange.Intheexperimentonrealdata,weusedtheORL\n",
      "DatabaseofFaces[20],whichcontains400imagesofhumanfaces,tent\n",
      "imagesofeachof40distinctsubjects.Eachimageconsistsof112?92=10304\n",
      "pixelswhosevaluerangesfrom0to255.WedividedN=400imagesintor?\n",
      "=40clusterswiththeK-means++andtheAMPalgorithmfortheK-means\n",
      "clustering.WeadoptedtheinitializationmethodoftheK-means++alsofor\n",
      "theAMPalgorithm,becauserandominitializationoftenyieldedemptyclusters\n",
      "andalmostalldatawereassignedtoonlyonecluster.Theparameter?was\n",
      "estimatedinthewayproposedinSubsection4.3.Weran50trialswitht\n",
      "initialvalues,andFigure2summarizestheresults.TheAMPalgorithmforthe\n",
      "K-meansclusteringoutperformedthestandardK-means++algorithmin48out\n",
      "ofthe50trialsintermsoftheK-meanslossandin47trialsintermsofthe\n",
      "accuracy.TheAMPalgorithmyieldedjustoneclusterwithalldataassigned\n",
      "toitintwotrials.TheattainedminimumvalueofK-meanslossis0.412with\n",
      "theK-means++and0.400withtheAMPalgorithm.Theaccuraciesatthese\n",
      "trialsare0.635withtheK-means++and0.690withtheAMPalgorithm.The\n",
      "averagenumberofiterationswas6.6withtheK-means++and8.8withthe\n",
      "AMPalgorithm.Theseresultsdemonstrateeoftheproposedalgorithm\n",
      "onrealdata.8\n",
      "12\n",
      "\n",
      "2References\n",
      "[1]P.Paatero,?Leastsquaresformulationofrobustnon-negativefactoranal-\n",
      "ysis,?ChemometricsandIntelligentLaboratorySystems,vol.37,no.1,pp.\n",
      "23?35,May1997.[2]P.O.Hoyer,?Non-negativematrixfactorizationwith\n",
      "sparsenessconstraints,?TheJournalofMachineLearningResearch,vol.5,\n",
      "pp.1457?1469,Dec.2004.[3]R.SalakhutdinovandA.Mnih,?Bayesian\n",
      "probabilisticmatrixfactorizationusingMarkovchainMonteCarlo,?inPro-\n",
      "ceedingsofthe25thInternationalConferenceonMachineLearning,NewYork,\n",
      "NY,Jul.5?Aug.9,2008,pp.880?887.[4]Y.J.LimandY.W.Teh,\n",
      "?VariationalBayesianapproachtomovieratingprediction,?inProceedings\n",
      "ofKDDCupandWorkshop,SanJose,CA,Aug.12,2007.[5]T.Raiko,A.\n",
      "Ilin,andJ.Karhunen,?Principalcomponentanalysisforlargescaleproblems\n",
      "withlotsofmissingvalues,?inMachineLearning:ECML2007,ser.Lecture\n",
      "NotesinComputerScience,J.N.Kok,J.Koronacki,R.L.deMantaras,S.\n",
      "Matwin,D.Mladeni?c,andA.Skowron,Eds.SpringerBerlinHeidelberg,2007,\n",
      "vol.4701,pp.691?698.[6]D.L.Donoho,A.Maleki,andA.Montanari,\n",
      "?Message-passingalgorithmsforcompressedsensing,?ProceedingsoftheNa-\n",
      "tionalAcademyofSciencesUSA,vol.106,no.45,pp.18914?18919,Nov.\n",
      "2009.[7]S.Rangan,?Generalizedapproximatemessagepassingforestima-\n",
      "tionwithrandomlinearmixing,?inProceedingsof2011IEEEInternational\n",
      "SymposiumonInformationTheory,St.Petersburg,Russia,Jul.31?Aug.\n",
      "5,2011,pp.2168?2172.[8]S.RanganandA.K.Fletcher,?Iterativeestima-\n",
      "tionofconstrainedrank-onematricesinnoise,?inProceedingsof2012IEEE\n",
      "InternationalSymposiumonInformationTheory,Cambridge,MA,Jul.1?6,\n",
      "2012,pp.1246?1250.[9]R.MatsushitaandT.Tanaka,?Approximatemes-\n",
      "sagepassingalgorithmforlow-rankmatrixreconstruction,?inProceedingsof\n",
      "the35thSymposiumonInformationTheoryanditsApplications,Oita,Japan,\n",
      "Dec.11?14,2012,pp.314?319.[10]W.Xu,X.Liu,andY.Gong,?Docu-\n",
      "mentclusteringbasedonnon-negativematrixfactorization,?inProceedingsof\n",
      "the26thannualinternationalACMSIGIRconferenceonResearchanddevel-\n",
      "opmentininformaionretrieval,Toronto,Canada,Jul.28?Aug.1,2003,pp.\n",
      "267?273.[11]C.Ding,T.Li,andM.Jordan,?Convexandsemi-nonnegative\n",
      "matrixfactorizations,?IEEETransactionsonPatternAnalysisandMachine\n",
      "Intelligence,vol.32,no.1,pp.45?55,Jan.2010.[12]S.P.Lloyd,?Least\n",
      "squaresquantizationinPCM,?IEEETransactionsonInformationTheory,vol.\n",
      "IT-28,no.2,pp.129?137,Mar.1982.[13]F.Krzakala,M.M?ezard,and\n",
      "L.Zdeborov?a,?Phasediagramandapproximatemessagepassingforblind\n",
      "calibrationanddictionarylearning,?preprint,Jan.2013,arXiv:1301.5898v1\n",
      "[cs.IT].[14]J.T.Parker,P.Schniter,andV.Cevher,?Bilineargeneralizedap-\n",
      "proximatemessagepassing,?preprint,Oct.2013,arXiv:1310.2632v1[cs.IT].\n",
      "[15]S.NakajimaandM.Sugiyama,?TheoreticalanalysisofBayesianmatrix\n",
      "factorization,?JournalofMachineLearningResearch,vol.12,pp.2583?2648,\n",
      "Sep.2011.[16]D.ArthurandS.Vassilvitskii,?k-means++:theadvantages\n",
      "ofcarefulseeding,?inSODA?07Proceedingsofthe18thAnnualACM-SIAM\n",
      "SymposiumonDiscreteAlgorithms,NewOrleans,Louisiana,Jan.7?9,2007,\n",
      "13\n",
      "\n",
      "pp.1027?1035.[17]J.S.Yedidia,W.T.Freeman,andY.Weiss,?Construct-\n",
      "ingfree-energyapproximationsandgeneralizedbeliefpropagationalgorithms,?\n",
      "IEEETransactionsonInformationTheory,vol.51,no.7,pp.2282?2312,Jul.\n",
      "2005.[18]M.BayatiandA.Montanari,?Thedynamicsofmessagepassing\n",
      "ondensegraphs,withapplicationstocompressedsensing,?IEEETransactions\n",
      "onInformationTheory,vol.57,no.2,pp.764?785,Feb.2011.[19]H.\n",
      "W.Kuhn,?TheHungarianmethodfortheassignmentproblem,?NavalRe-\n",
      "searchLogisticsQuarterly,vol.2,no.1?2,pp.83?97,Mar.1955.[20]F.S.\n",
      "SamariaandA.C.Harter,?Parameterisationofastochasticmodelforhuman\n",
      "faceideninProceedingsof2ndIEEEWorkshoponApplicationsof\n",
      "ComputerVision,SarasotaFL,Dec.1994,pp.138?142.[Online].Available:\n",
      "http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
      "9\n",
      "14\n",
      "\n",
      "PP6233.pdf\n",
      "PP6233.pdf 14\n",
      "HierarchicalDeepReinforcementLearning:\n",
      "IntegratingTemporalAbstractionandIntrinsic\n",
      "Motivation\n",
      "Authoredby:\n",
      "ArdavanSaeedi\n",
      "TejasD.Kulkarni\n",
      "JoshTenenbaum\n",
      "KarthikNarasimhan\n",
      "Abstract\n",
      "Learninggoal-directedbehaviorinenvironmentswithsparsefeedback\n",
      "isamajorchallengeforreinforcementlearningalgorithms.Oneofthekey\n",
      "istexploration,resultinginanagentbeingunableto\n",
      "learnrobustpolicies.Intrinsicallymotivatedagentscanexplorenewbe-\n",
      "haviorfortheirownsakeratherthantodirectlysolveexternalgoals.Such\n",
      "intrinsicbehaviorscouldeventuallyhelptheagentsolvetasksposedby\n",
      "theenvironment.Wepresenthierarchical-DQN(h-DQN),aframeworkto\n",
      "integratehierarchicalaction-valuefunctions,operatingatttem-\n",
      "poralscales,withgoal-drivenintrinsicallymotivateddeepreinforcement\n",
      "learning.Atop-levelq-valuefunctionlearnsapolicyoverintrinsicgoals,\n",
      "whilealower-levelfunctionlearnsapolicyoveratomicactionstosatisfy\n",
      "thegivengoals.h-DQNallowsforgoalspsuchas\n",
      "functionsoverentitiesandrelations.Thisprovidesantspacefor\n",
      "explorationincomplicatedenvironments.Wedemonstratethestrengthof\n",
      "ourapproachontwoproblemswithverysparseanddelayedfeedback:(1)\n",
      "acomplexdiscretestochasticdecisionprocesswithstochastictransitions,\n",
      "and(2)theclassicATARIgame{`Montezuma'sRevenge'.\n",
      "1PaperBody\n",
      "ionandIntrinsicMotivationTejasD.Kulkarni?DeepMind,Londontejasd-\n",
      "kulkarni@gmail.com\n",
      "KarthikR.Narasimhan?CSAIL,MITkarthikn@mit.edu\n",
      "ArdavanSaeediCSAIL,MITardavans@mit.edu\n",
      "JoshuaB.TenenbaumBCS,MITjbt@mit.edu\n",
      "AbstractLearninggoal-directedbehaviorinenvironmentswithsparsefeed-\n",
      "backisamajorchallengeforreinforcementlearningalgorithms.Oneofthe\n",
      "1\n",
      "\n",
      "keyistexploration,resultinginanagentbeingunableto\n",
      "learnrobustpolicies.Intrinsicallymotivatedagentscanexplorenewbehavior\n",
      "fortheirownsakeratherthantodirectlysolveexternalgoals.Suchintrinsicbe-\n",
      "haviorscouldeventuallyhelptheagentsolvetasksposedbytheenvironment.\n",
      "WepresenthierarchicalDQN(h-DQN),aframeworktointegratehierarchical\n",
      "action-valuefunctions,operatingatttemporalscales,withgoal-driven\n",
      "intrinsicallymotivateddeepreinforcementlearning.Atop-levelq-valuefunc-\n",
      "tionlearnsapolicyoverintrinsicgoals,whilealower-levelfunctionlearnsa\n",
      "policyoveratomicactionstosatisfythegivengoals.h-DQNallowsfor\n",
      "goalspsuchasfunctionsoverentitiesandrelations.Thisprovides\n",
      "antspaceforexplorationincomplicatedenvironments.Wedemonstrate\n",
      "thestrengthofourapproachontwoproblemswithverysparseanddelayed\n",
      "feedback:(1)acomplexdiscretestochasticdecisionprocesswithstochastic\n",
      "transitions,and(2)theclassicATARIgame??Montezuma?sRevenge?.\n",
      "1\n",
      "Introduction\n",
      "Learninggoal-directedbehaviorwithsparsefeedbackfromcomplexenvi-\n",
      "ronmentsisafundamentalchallengeforintelligence.Learninginthis\n",
      "settingrequirestheagenttorepresentknowledgeatmultiplelevelsofspatio-\n",
      "temporalabstractionsandtoexploretheenvironmenttly.Recently,non-\n",
      "linearfunctionapproximatorscoupledwithreinforcementlearning[14,16,23]\n",
      "havemadeitpossibletolearnabstractionsoverhigh-dimensionalstatespaces,\n",
      "butthetaskofexplorationwithsparsefeedbackstillremainsamajorchal-\n",
      "lenge.ExistingmethodslikeBoltzmannexplorationandThomsonsampling\n",
      "[31,19]timprovementsover-greedy,butarelimitedduetothe\n",
      "underlyingmodelsfunctioningatthelevelofbasicactions.Inthiswork,wepro-\n",
      "poseaframeworkthatintegratesdeepreinforcementlearningwithhierarchical\n",
      "action-valuefunctions(h-DQN),wherethetop-levelmodulelearnsapolicyover\n",
      "options(subgoals)andthebottom-levelmodulelearnspoliciestoaccomplish\n",
      "theobjectiveofeachoption.Explorationinthespaceofgoalsenablest\n",
      "explorationinproblemswithsparseanddelayedrewards.Additionally,our\n",
      "experimentsindicatethatgoalsexpressedinthespaceofentitiesandrelations\n",
      "canhelpconstrainttheexplorationspacefordatatdeepreinforcement\n",
      "learningincomplexenvironments.?\n",
      "EqualContribution.WorkdonewhileTejasKulkarniwaswith\n",
      "MIT.\n",
      "30thConferenceonNeuralInformationProcessingSystems(NIPS2016),\n",
      "Barcelona,Spain.\n",
      "Reinforcementlearning(RL)formalizescontrolproblemsasapol-\n",
      "icy?thatmaximizesexpectedfuturerewards[32].ValuefunctionsV(s)are\n",
      "centraltoRL,andtheycachetheutilityofanystatesinachievingtheagent?s\n",
      "overallobjective.Recently,valuefunctionshavealsobeengeneralizedasV(s,\n",
      "g)inordertorepresenttheutilityofstatesforachievingagivengoalg?G\n",
      "[33,21].Whentheenvironmentprovidesdelayedrewards,weadoptastrategy\n",
      "tolearnwaystoachieveintrinsicallygeneratedgoals,andsubsequently\n",
      "learnanoptimalpolicytochainthemtogether.EachofthevaluefunctionsV\n",
      "2\n",
      "\n",
      "(s,g)canbeusedtogenerateapolicythatterminateswhentheagentreaches\n",
      "thegoalstateg.Acollectionofthesepoliciescanbehierarchicallyarranged\n",
      "withtemporaldynamicsforlearningorplanningwithintheframeworkofsemi-\n",
      "Markovdecisionprocesses[34,35].Inhigh-dimensionalproblems,thesevalue\n",
      "functionscanbeapproximatedbyneuralnetworksasV(s,g;?).Wepropose\n",
      "aframeworkwithhierarchicallyorganizeddeepreinforcementlearningmodules\n",
      "workingatttime-scales.Themodeltakesdecisionsovertwolevelsof\n",
      "hierarchy?(a)atoplevelmodule(meta-controller)takesinthestateandpicks\n",
      "anewgoal,and(b)alower-levelmodule(controller)usesboththestateandthe\n",
      "chosengoaltoselectactionseitheruntilthegoalisreachedortheepisodeter-\n",
      "minates.Themeta-controllerthenchoosesanothergoalandsteps(a-b)repeat.\n",
      "Wetrainourmodelusingstochasticgradientdescentatttemporalscales\n",
      "tooptimizeexpectedfutureintrinsic(controller)andextrinsicrewards(meta-\n",
      "controller).Wedemonstratethestrengthofourapproachonproblemswith\n",
      "delayedrewards:(1)adiscretestochasticdecisionprocesswithalongchainof\n",
      "statesbeforereceivingoptimalextrinsicrewardsand(2)aclassicATARIgame\n",
      "(?Montezuma?sRevenge?)withevenlonger-rangedelayedrewardswheremost\n",
      "existingstate-of-artdeepreinforcementlearningapproachesfailtolearnpolicies\n",
      "inatmanner.\n",
      "2\n",
      "LiteratureReview\n",
      "ReinforcementLearningwithTemporalAbstractionsLearningandoperating\n",
      "overderentlevelsoftemporalabstractionisakeychallengeintasksinvolving\n",
      "long-rangeplanning.Inthecontextofhierarchicalreinforcementlearning[2],\n",
      "Suttonetal.[34]proposedtheoptionsframework,whichinvolvesabstractions\n",
      "overthespaceofactions.Ateachstep,theagentchooseseitheraonestep\n",
      "?primitive?actionora?multi-step?actionpolicy(option).Eachoption\n",
      "apolicyoveractions(eitherprimitiveorotheroptions)andcanbeterminated\n",
      "accordingtoastochasticfunction?.Thus,thetraditionalMDPsettingcanbe\n",
      "extendedtoasemi-Markovdecisionprocess(SMDP)withtheuseofoptions.\n",
      "Recently,severalmethodshavebeenproposedtolearnoptionsinreal-timeby\n",
      "usingvaryingrewardfunctions[35]orbycomposingexistingoptions[28].Value\n",
      "functionshavealsobeengeneralizedtoconsidergoalsalongwithstates[21].Our\n",
      "workisinspiredbythesepapersandbuildsuponthem.Otherrelatedworkfor\n",
      "hierarchicalformulationsincludetheMAXQframework[6],whichdecomposed\n",
      "thevaluefunctionofanMDPintocombinationsofvaluefunctionsofsmaller\n",
      "constituentMDPs,asdidGuestrinetal.[12]intheirfactoredMDPformulation.\n",
      "HernandezandMahadevan[13]combinehierarchieswithshort-termmemoryto\n",
      "handlepartialobservations.Intheskilllearningliterature,Baranesetal.[1]have\n",
      "proposedagoal-drivenactivelearningapproachforlearningskillsincontinuous\n",
      "sensorimotorspaces.Inthiswork,weproposeaschemefortemporalabstraction\n",
      "thatinvolvessimultaneouslylearningoptionsandacontrolpolicytocompose\n",
      "optionsinadeepreinforcementlearningsetting.Ourapproachdoesnotuse\n",
      "separateQ-functionsforeachoption,butinsteadtreatstheoptionaspartof\n",
      "theinput,similarto[21].Thishastwopotentialadvantages:(1)thereis\n",
      "sharedlearningbetweentoptions,and(2)themodelisscalabletoa\n",
      "3\n",
      "\n",
      "largenumberofoptions.IntrinsicMotivationThenatureandoriginof?good?\n",
      "intrinsicrewardfunctionsisanopenquestioninreinforcementlearning.Singhet\n",
      "al.[27]exploredagentswithintrinsicrewardstructuresinordertolearngeneric\n",
      "optionsthatcanapplytoawidevarietyoftasks.Inanotherpaper,Singhet\n",
      "al.[26]takeanevolutionaryperspectivetooptimizeoverthespaceofreward\n",
      "functionsfortheagent,leadingtoanotionofextrinsicallyandintrinsically\n",
      "motivatedbehavior.InthecontextofhierarchicalRL,GoelandHuber[10]\n",
      "discussaframeworkforsub-goaldiscoveryusingthestructuralaspectsofa\n",
      "learnedpolicymodel.S?ims?eketal.[24]provideagraphpartitioningapproach\n",
      "tosubgoaliden2\n",
      "Schmidhuber[22]providesacoherentformulationofintrinsicmotivation,\n",
      "whichismeasuredbytheimprovementstoapredictiveworldmodelmadebythe\n",
      "learningalgorithm.MohamedandRezende[17]haverecentlyproposedanotion\n",
      "ofintrinsicallymotivatedlearningwithintheframeworkofmutualinformation\n",
      "maximization.Franketal.[9]demonstratetheenessofcurios-\n",
      "ityusinginformationgainmaximizationinahumanoidrobot.Oudeyeretal.\n",
      "[20]categorizeintrinsicmotivationapproachesintoknowledgebasedmethods,\n",
      "competenceorgoalbasedmethodsandmorphologicalmethods.Ourworkre-\n",
      "latestocompetencebasedintrinsicmotivationbutothercomplementarymeth-\n",
      "odscanbecombinedinfuturework.Object-basedReinforcementLearning\n",
      "Object-basedrepresentations[7,4]thatcanexploittheunderlyingstructureof\n",
      "aproblemhavebeenproposedtoalleviatethecurseofdimensionalityinRL.\n",
      "Diuketal.[7]proposeanObject-OrientedMDP,usingarepresentationbased\n",
      "onobjectsandtheirinteractions.eachstateasasetofvalueassign-\n",
      "mentstoallpossiblerelationsbetweenobjects,theyintroduceanalgorithmfor\n",
      "solvingdeterministicobject-orientedMDPs.Theirrepresentationissimilarto\n",
      "thatofGuestrinetal.[11],whodescribeanobject-basedrepresentationinthe\n",
      "contextofplanning.Incontrasttotheseapproaches,ourrepresentationdoes\n",
      "notrequireexplicitencodingfortherelationsbetweenobjectsandcanbeused\n",
      "instochasticdomains.DeepReinforcementLearningRecentadvancesinfunc-\n",
      "tionapproximationwithdeepneuralnetworkshaveshownpromiseinhandling\n",
      "high-dimensionalsensoryinput.DeepQ-Networksanditsvariantshavebeen\n",
      "successfullyappliedtovariousdomainsincludingAtarigames[16,15]andGo\n",
      "[23],butstillperformpoorlyonenvironmentswithsparse,delayedrewardsig-\n",
      "nals.CognitiveScienceandNeuroscienceThenatureandoriginofintrinsicgoals\n",
      "inhumansisathornyissuebuttherearesomenotableinsightsfromexistinglit-\n",
      "erature.Thereisconvergingevidenceindevelopmentalpsychologythathuman\n",
      "infants,primates,children,andadultsindiverseculturesbasetheircoreknowl-\n",
      "edgeoncertaincognitivesystemsincluding?entities,agentsandtheiractions,\n",
      "numericalquantities,space,social-structuresandintuitivetheories[29].During\n",
      "curiositydrivenactivities,toddlersusethisknowledgetogenerateintrinsicgoals\n",
      "suchasbuildingphysicallystableblockstructures.Inordertoaccomplishthese\n",
      "goals,toddlersseemtoconstructsubgoalsinthespaceoftheircoreknowledge.\n",
      "Knowledgeofspacecanalsobeutilizedtolearnahierarchicaldecompositionof\n",
      "spatialenvironments.ThishasbeenexploredinNeurosciencewiththesuccessor\n",
      "representation,whichrepresentsvaluefunctionsintermsoftheexpectedfuture\n",
      "4\n",
      "\n",
      "stateoccupancy.Decompositionofthesuccessorrepresentationhaveshownto\n",
      "yieldreasonablesubgoalsforspatialnavigationproblems[5,30].\n",
      "3\n",
      "Model\n",
      "ConsideraMarkovdecisionprocess(MDP)representedbystatess?S,\n",
      "actionsa?A,andtransitionfunctionT:(s,a)?s0.Anagentoperatingin\n",
      "thisframeworkreceivesastatesfromtheexternalenvironmentandcantake\n",
      "anactiona,whichresultsinanewstates0.Wetheextrinsicreward\n",
      "functionasF:(s)?R.Theobjectiveoftheagentistomaximizethisfunction\n",
      "overlongperiodsoftime.Forexample,thisfunctioncantaketheformofthe\n",
      "agent?ssurvivaltimeorscoreinagame.AgentseexplorationinMDPs\n",
      "isatchallengeinlearninggoodcontrolpolicies.Methodssuchas\n",
      "-greedyareusefulforlocalexplorationbutfailtoprovideimpetusfortheagent\n",
      "toexploretareasofthestatespace.Inordertotacklethis,weutilize\n",
      "anotionofintrinsicgoalsg?G.Theagentfocusesonsettingandachieving\n",
      "sequencesofgoalsvialearningpolicies?ginordertomaximizecumulative\n",
      "extrinsicreward.Inordertolearneach?g,theagentalsohasacritic,which\n",
      "providesintrinsicrewards,basedonwhethertheagentisabletoachieveits\n",
      "goals(seeFigure1).TemporalAbstractionsAsshowninFigure1,theagent\n",
      "usesatwo-stagehierarchyconsistingofacontrollerandameta-controller.The\n",
      "meta-controllerreceivesstatestandchoosesagoalgt?G,whereGdenotesthe\n",
      "setofallpossiblecurrentgoals.Thecontrollerthenselectsanactionatusingst\n",
      "andgt.Thegoalgtremainsinplaceforthenextfewtimestepseitheruntilit\n",
      "isachievedoraterminalstateisreached.Theinternalcriticisresponsiblefor\n",
      "evaluatingwhetheragoalhasbeenreachedandprovidesanappropriatereward\n",
      "rt(g)tothecontroller.Inthiswork,wemakeaminimal3\n",
      "action\n",
      "ExternalEnvironment\n",
      "observations\n",
      "extrinsicreward\n",
      "gt+N\n",
      "gt\n",
      "MetaController\n",
      "Q2(st+N,gt+N;?2)\n",
      "Q2(st,g;?2)\n",
      "goal......\n",
      "Criticaction\n",
      "MetaController\n",
      "st\n",
      "intrinsicreward\n",
      "at\n",
      "at+1\n",
      "MetaController\n",
      "......\n",
      "st+NQ1(st,a;?1,gt)\n",
      "Q1(st+1,a;?1,gt)Q1(st+N,a;?1,gt)\n",
      "5\n",
      "\n",
      "Controller\n",
      "Controller\n",
      "at+N\n",
      "Controller\n",
      "st\n",
      "....\n",
      "st+1\n",
      "Controller\n",
      "st+N\n",
      "gt\n",
      "agent\n",
      "Figure1:(Overview)Theagentreceivessensoryobservationsandproduces\n",
      "actions.SeparateDQNsareusedinsidethemeta-controllerandcontroller.The\n",
      "meta-controllerlooksattherawstatesandproducesapolicyovergoalsby\n",
      "estimatingtheaction-valuefunctionQ2(st,gt;?2)(tomaximizeexpected\n",
      "futureextrinsicreward).Thecontrollertakesinstatesandthecurrentgoal,\n",
      "andproducesapolicyoveractionsbyestimatingtheaction-valuefunctionQ1\n",
      "(st,at;?1,gt)tosolvethepredictedgoal(bymaximizingexpectedfuture\n",
      "intrinsicreward).Theinternalcriticprovidesapositiverewardtothecontroller\n",
      "ifandonlyifthegoalisreached.Thecontrollerterminateseitherwhenthe\n",
      "episodeendsorwhengisaccomplished.Themeta-controllerthenchoosesa\n",
      "newgandtheprocessrepeats.assumptionofabinaryinternalrewardi.e.1\n",
      "ifthegoalisreachedand0otherwise.TheobjectiveP?0functionforthe\n",
      "controlleristomaximizecumulativeintrinsicreward:Rt(g)=t0=t?t?trt0\n",
      "(g).Similarly,theobjectiveofthemeta-controlleristooptimizethecumulative\n",
      "extrinsicrewardFt=P?t0?tft0,whereftarerewardsignalsreceivedfromthe\n",
      "environment.Notethatthetimet0=t?scalesforFtandRtaret?each\n",
      "ftistheaccumulatedexternalrewardoverthetimeperiodbetweensuccessive\n",
      "goalselections.ThediscountinginFt,therefore,isoversequencesofgoals\n",
      "andnotlowerlevelactions.Thissetupissimilartooptimizingoverthespace\n",
      "ofoptimalrewardfunctionstomaximizeess[25].Inourcase,thereward\n",
      "functionsaredynamicandtemporallydependentonthesequentialhistoryof\n",
      "goals.Figure1illustratestheagent?suseofthehierarchyoversubsequenttime\n",
      "steps.DeepReinforcementLearningwithTemporalAbstractionsWeusethe\n",
      "DeepQ-Learningframework[16]tolearnpoliciesforboththecontrollerand\n",
      "themeta-controller.Speccally,thecontrollerestimatesthefollowingQ-value\n",
      "function:?X\n",
      "0Q?1(s,a;g)=maxE?t?trt0|st=s,at=a,gt=g,?ag?ag\n",
      "t0=t\n",
      "(1)\n",
      "=maxErt+?maxat+1Q?1(st+1,at+1;g)|st=s,at=a,gt=g,\n",
      "?ag?ag\n",
      "wheregistheagent?sgoalinstatesand?agistheactionpolicy.Similarly,\n",
      "forthemeta-controller,wehave:Q?2(s,g)\n",
      "Xt+N\n",
      "=max?gEft0+?maxg0Q?2(st+N,g0)|st=s,gt=g,?g\n",
      "6\n",
      "\n",
      "(2)\n",
      "t0=t\n",
      "whereNdenotesthenumberoftimestepsuntilthecontrollerhaltsgiven\n",
      "thecurrentgoal,g0istheagent?sgoalinstatest+N,and?gisthepolicyover\n",
      "goals.Itisimportanttonotethatthetransitions(st,gt,ft,st+N)generated\n",
      "byQ2runataslowertime-scalethanthetransitions(st,at,gt,rt,st+1)\n",
      "generatedbyQ1.WecanrepresentQ?(s,g)?Q(s,g;?)usinganon-linear\n",
      "functionapproximatorwithparameters?.EachQ?\n",
      "f\n",
      "Q1,Q2\n",
      "g\n",
      "canbetrained\n",
      "byminimizingcorrespondinglossfunctions?L1(?1)andL2(?2).Westore\n",
      "experiences(st,gt,ft,st+N)forQ2and(st,at,gt,rt,st+1)forQ1in\n",
      "disjoint4\n",
      "memoryspacesD1andD2respectively.ThelossfunctionforQ1canthen\n",
      "bestatedas:\n",
      "L1(?1,i)=E(s,a,g,r,s0)?D1(y1,i?Q1(s,a;?1,i,g))2,whereidenotes\n",
      "thetrainingiterationnumberandy1,i=r+?maxa0Q1(s0,a0;?1,i?1,g).\n",
      "(3)\n",
      "Following[16],theparameters?1,i?1fromthepreviousiterationareheld\n",
      "whenoptimizingthelossfunction.Theparameters?1canbeoptimized\n",
      "usingthegradient:??1,iL1(?1,i)=E(s,a,r,s0?D1)\n",
      "\"\n",
      "#\n",
      "r+?maxQ1(s,a;?1,i?1,g)?Q1(s,a;?1,i,g)??1,iQ1(s,a;?1,i,g)\n",
      "a0\n",
      "0\n",
      "0\n",
      "ThelossfunctionL2anditsgradientscanbederivedusingasimilarproce-\n",
      "dure.Algorithm1Learningalgorithmforh-DQN1:Initializeexperiencereplay\n",
      "memories\n",
      "f\n",
      "D1,D2\n",
      "g\n",
      "andparameters\n",
      "f\n",
      "?1,?2\n",
      "g\n",
      "forthecontrollerand\n",
      "meta-controllerrespectively.\n",
      "2:Initializeexplorationprobability1,g=1forthecontrollerforallgoalsg\n",
      "and2=1forthe\n",
      "meta-controller.\n",
      "3:fori=1,numepisodesdo4:Initializegameandgetstartstatedescription\n",
      "s5:g?EPSGREEDY(s,G,2,Q2)6:whilesisnotterminaldo7:F?08:s0\n",
      "?s9:whilenot(sisterminalorgoalgreached)do10:a?EPSGREEDY(\n",
      "f\n",
      "s,\n",
      "g\n",
      "g\n",
      ",A,1,g,Q1)11:Executeaandobtainnextstates0andextrinsicreward\n",
      "ffromenvironment12:Obtainintrinsicrewardr(s,a,s0)frominternalcritic\n",
      "13:Storetransition(\n",
      "f\n",
      "s,g\n",
      "g\n",
      ",a,r,\n",
      "f\n",
      "s0,g\n",
      "g\n",
      ")inD114:UPDATEPARAMS(L1\n",
      "(?1,i),D1)15:UPDATEPARAMS(L2(?2,i),D2)16:F?F+f17:s?s0\n",
      "18:endwhile19:Storetransition(s0,g,F,s0)inD220:ifsisnotterminal\n",
      "then21:g?EPSGREEDY(s,G,2,Q2)22:endif23:endwhile24:Anneal\n",
      "2and1.25:endfor\n",
      "Algorithm2:EPSGREEDY(x,B,,Q)1:ifrandom()<then2:return\n",
      "randomelementfromsetB3:else4:returnargmaxm?BQ(x,m)5:endif\n",
      "Algorithm3:UPDATEPARAMS(L,D)1:Randomlysamplemini-batches\n",
      "fromD2:PerformgradientdescentonlossL(?)\n",
      "7\n",
      "\n",
      "(cf.(3))\n",
      "LearningAlgorithmWelearntheparametersofh-DQNusingstochastic\n",
      "gradientdescentatttimescales?transitionsfromthecontrollerare\n",
      "collectedateverytimestepbutatransitionfromthemeta-controllerisonly\n",
      "collectedwhenthecontrollerterminates(i.e.whenagoalisrepickedorthe\n",
      "episodeends).Eachnewgoalgisdrawninan-greedyfashion(Algorithms1\n",
      "&2)withtheexplorationprobability2annealedaslearningproceeds(froma\n",
      "startingvalueof1).Inthecontroller,ateverytimestep,anactionisdrawn\n",
      "withagoalusingtheexplorationprobability1,g,whichdependsonthecurrent\n",
      "empiricalsuccessrateofreachingg.Sp,ifthesuccessrateforgoal\n",
      "gis>90%,weset1,g=0.1,else1.All1,gvaluesareannealedto0.1.The\n",
      "modelparameters(?1,?2)areperiodicallyupdatedbydrawingexperiences\n",
      "fromreplaymemoriesD1andD2,respectively(seeAlgorithm3).5\n",
      "4\n",
      "Experiments\n",
      "(1)DiscretestochasticdecisionprocesswithdelayedrewardsForour\n",
      "experiment,weconsiderastochasticdecisionprocesswheretheextrinsicreward\n",
      "dependsonthehistoryofvisitedstatesinadditiontothecurrentstate.This\n",
      "taskdemonstratestheimportanceofgoal-drivenexplorationinsuchenviron-\n",
      "ments.Thereare6possiblestatesandtheagentalwaysstartsats2.Theagent\n",
      "movesleftdeterministicallywhenitchoosesleftaction;buttheactionright\n",
      "onlysucceeds50%ofthetime,resultinginaleftmoveotherwise.Theterminal\n",
      "stateiss1andtheagentreceivestherewardof1whenitvisitss6andthen\n",
      "s1.Therewardforgoingtos1withoutvisitings6is0.01.Thisisamo\n",
      "versionoftheMDPin[19],withtherewardstructureaddingcomplexitytothe\n",
      "task(seeFigure2).Weconsidereachstateasacandidategoalfor0.50.50.5\n",
      "0.50.5exploration.Thisenablesandencouragestheagenttovisitstates6(if\n",
      "chosenasagoal)andr=or1/100s10.5s20.5s30.5s40.5s50.5s6r=1hence,\n",
      "learntheoptimalpolicy.Foreachgoal,1.01.01.01.01.0theagentreceives\n",
      "apositiveintrinsicrewardifFigure2:Astochasticdecisionprocesswherethe\n",
      "andonlyifitreachesthecorrespondingstate.rewardattheterminalstates1\n",
      "dependsonwhetherResultsWecomparetheperformanceofs6isvisited(r=\n",
      "1)ornot(r=1/100).Edgesourapproach(withoutdeepneuralnetworks)are\n",
      "annotatedwithtransitionprobabilities(RedaragainstQ-Learningasabaseline\n",
      "(withoutin-row:moveright,Blackarrow:moveleft).\n",
      "trinsicrewards)intermsoftheaverageextrinsicrewardgainedinanepisode.\n",
      "Inourexperiments,allparametersareannealedfrom1to0.1over50ksteps.\n",
      "Thelearningrateissetto2.5?10?4.Figure3plotstheevolutionofreward\n",
      "forbothmethodsaveragedover10truns.Asexpected,weseethatQ-\n",
      "Learningisunabletotheoptimalpolicyevenafter200epochs,converging\n",
      "toasub-optimalpolicyofreachingstates1directlytoobtainarewardof0.01.\n",
      "Incontrast,ourapproachwithhierarchicalQ-estimatorslearnstochoosegoals\n",
      "s4,s5ors6,whichstatisticallyleadtheagenttovisits6beforegoingbackto\n",
      "s1.Ouragentobtainsatlyhigheraveragerewardof0.13.5/18/2016\n",
      "Reward.html\n",
      "5/18/2016\n",
      "8\n",
      "\n",
      "Reward0.180.160.140.120.10.080.060.040.020\n",
      "0\n",
      "State3,State4,State5,State6|?lledscatterchartmadebyArdavans\n",
      "|plotly\n",
      "#ofvisitsperepisode\n",
      "1.2\n",
      "State3State4State5State6\n",
      "10.80.60.4\n",
      "BaselineOurApproach50\n",
      "100Steps\n",
      "150\n",
      "0.20\n",
      "200\n",
      "2\n",
      "Export?to?plot.ly??\n",
      "4\n",
      "6\n",
      "Episodes(*1000)\n",
      "8\n",
      "10\n",
      "12Editchart?\n",
      "Figure3:(left)Averagereward(over10runs)ofourapproachcomparedto\n",
      "Q-learning.(right)#visitsofourapproachtostatess3-s6(over1000episodes).\n",
      "Initialstate:s2,Terminalstate:s1.?le:///Users/tejas/Documents/deepRelationalRL/dqn/Reward.html\n",
      "1/1\n",
      "Figure3illustratesthatthenumberofvisitstostatess3,s4,s5,s6\n",
      "increaseswithepisodesoftraining.Eachdatapointshowstheaveragenumber\n",
      "ofvisitsforeachstateoverthelast1000episodes.Thisindicatesthatour\n",
      "modelischoosinggoalsinawaysothatitreachesthecriticalstates6more\n",
      "often.https://plot.ly/ardavans/4.embed\n",
      "1/1\n",
      "(2)ATARIgamewithdelayedrewardsWenowconsider?Montezuma?sRe-\n",
      "venge?,anATARIgamewithsparse,delayedrewards.Thegamerequiresthe\n",
      "playertonavigatetheexplorer(inred)throughseveralroomswhilecollecting\n",
      "treasures.Inordertopassthroughdoors(inthetoprightandtopleftcorners\n",
      "ofthetheplayerhastopickupthekey.Theplayerhastothen\n",
      "climbdowntheladdersontherightandmovelefttowardsthekey,resultingina\n",
      "longsequenceofactionsbeforereceivingareward(+100)forcollectingthekey.\n",
      "Afterthis,navigatingtowardsthedoorandopeningitresultsinanotherreward\n",
      "(+300).BasicDQN[16]achievesascoreof0whileeventhebestperforming\n",
      "system,GorilaDQN[18],managesonly4.16onaverage.Asynchronousactor\n",
      "criticmethodsachieveanon-zeroscorebutrequire100sofmillionsoftraining\n",
      "frames[15].6\n",
      "Architecture\n",
      "Totalextrinsicreward\n",
      "5/18/2016\n",
      "9\n",
      "\n",
      "Reward.html\n",
      "Q1(s,a;g)Linear\n",
      "400350300250200150100500\n",
      "ReLU:Linear(h=512)ReLU:Convftr-maps:64,strides:1)ReLU:Conv\n",
      "ftr-maps:64,strides:2)ReLU:Convftr-maps:32,strides:4)\n",
      "OurApproachDQN\n",
      "0\n",
      "image(s)+goal(g)\n",
      "0.5M\n",
      "1M\n",
      "5/18/20165/18/2016\n",
      "Steps\n",
      "1.5M\n",
      "2MExport?to?plot.ly??\n",
      "Bargraph.html\n",
      "subgoal\n",
      "6.html\n",
      "Successratioforreachingthegoal?key?\n",
      "Success%oftgoalsovertime\n",
      "1\n",
      "0.25\n",
      "0.8\n",
      "0.2\n",
      "0.6\n",
      "0.15\n",
      "0.4\n",
      "0.1\n",
      "0.2\n",
      "1/1\n",
      "0.05\n",
      "0\n",
      "0\n",
      "top-leftdoortop-rightdoormiddle-ladderbottom-left-ladderbottom-right-\n",
      "ladderkey\n",
      "?le:///Users/tejas/Documents/deepRelationalRL/dqn/Reward.html\n",
      "0.5M\n",
      "1M\n",
      "Steps\n",
      "1.5M\n",
      "0\n",
      "2M\n",
      "0.5M\n",
      "Export?to?plot.ly??\n",
      "1M\n",
      "Steps\n",
      "1.5M\n",
      "2MExport?to?plot.ly??\n",
      "10\n",
      "\n",
      "Figure4:(top-left)Architecture:DQNarchitectureforthecontroller(Q1\n",
      ").AsimilararchitectureproducesQ2forthemeta-controller(withoutgoalas\n",
      "input).(top-right)Thejointtraininglearnstoconsistentlygethighrewards.\n",
      "(bottom-left)Goalsuccessratio:Theagentlearnstochoosethekeymoreoften\n",
      "astrainingproceedsandissuccessfulatachievingit.(bottom-right)Goalstatis-\n",
      "tics:Duringearlyphasesofjointtraining,allgoalsareequallypreferreddueto\n",
      "highexplorationbutastrainingproceeds,theagentlearnstoselectappropriate\n",
      "goalssuchasthekeyandbottom-leftdoor.\n",
      "?le:///Users/tejas/Documents/deepRelationalRL/dqn/subgoal\n",
      "6.html\n",
      "1/1?le:///Users/tejas/Documents/deepRelationalRL/dqn/Bar%20graph.html\n",
      "1/1\n",
      "SetupTheagentneedsintrinsicmotivationtoexploremeaningfulpartsof\n",
      "thescenebeforelearningabouttheadvantageofobtainingthekey.Inspiredby\n",
      "developmentalpsychologyliterature[29]andobject-orientedMDPs[7],weuse\n",
      "entitiesorobjectsinthescenetoparameterizegoalsinthisenvironment.Un-\n",
      "superviseddetectionofobjectsinvisualscenesisanopenproblemincomputer\n",
      "vision,althoughtherehasbeenrecentprogressinobtainingobjectsdirectly\n",
      "fromimageormotiondata[8].Inthiswork,webuiltacustompipelineto\n",
      "provideplausibleobjectcandidates.Notethattheagentisstillrequiredto\n",
      "learnwhichofthesecandidatesareworthpursuingasgoals.Thecontrollerand\n",
      "meta-controllerareconvolutionalneuralnetworks(Figure4)thatlearnrepre-\n",
      "sentationsfromrawpixeldata.WeusetheArcadeLearningEnvironment[3]\n",
      "toperformexperiments.Theinternalcriticisinthespaceofhentity1\n",
      ",relation,entity2i,whererelationisafunctionoveroftheenti-\n",
      "ties.Inourexperiments,theagentlearnstochooseentity2.Forinstance,the\n",
      "agentisdeemedtohavecompletedagoal(andonlythenreceivesareward)if\n",
      "theagententityreachesanotherentitysuchasthedoor.Thecriticcomputes\n",
      "binaryrewardsusingtherelativepositionsoftheagentandthegoal(1ifthe\n",
      "goalwasreached).Notethatthisnotionofrelationalintrinsicrewardscanbe\n",
      "generalizedtoothersettings.Forinstance,intheATARIgame?Asteroids?,the\n",
      "agentcouldberewardedwhenthebulletreachestheasteroidorifsimplythe\n",
      "shipneverreachesanasteroid.In?Pacman?,theagentcouldberewardedifthe\n",
      "pelletsonthescreenarereached.Inthemostgeneralcase,wecanpotentially\n",
      "letthemodelevolveaparameterizedintrinsicrewardfunctiongivenentities.\n",
      "Weleavethisforfuturework.ModelArchitectureandTrainingAsshownin\n",
      "Figure4,themodelconsistsofstackedconvolutionallayerswithlinear\n",
      "units(ReLU).Theinputtothemeta-controllerisasetoffourconsecutiveim-\n",
      "agesofsize84?84.Toencodethegoaloutputfromthemeta-controller,we\n",
      "appendabinarymaskofthegoallocationinimagespacealongwiththeoriginal\n",
      "4consecutiveframes.Thisaugmentedinputispassedtothecontroller.The\n",
      "experiencereplaymemoriesD1andD2weresettobeequalto106and5?104\n",
      "respectively.Wesetthelearningratetobe2.5?10?4,withadiscountrateof\n",
      "0.99.Wefollowatwophasetrainingprocedure?(1)Inthephase,weset\n",
      "theexplorationparameter2ofthemeta-controllerto1andtrainthecontroller\n",
      "onactions.Thiselyleadstopre-trainingthecontrollersothatitcan\n",
      "learntosolveasubsetofthegoals.(2)Inthesecondphase,wejointlytrain\n",
      "11\n",
      "\n",
      "thecontrollerandmeta-controller.7\n",
      "MetaControllertermination(death)\n",
      "goalreached\n",
      "Controller\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "MetaControllergoalreached\n",
      "Controller\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "Figure5:SamplegameplayonMontezuma?sRevenge:Thefourquadrants\n",
      "arearrangedinatemporalorder(top-left,top-right,bottom-leftandbottom-\n",
      "right).First,themeta-controllerchooseskeyasthegoal(illustratedinred).The\n",
      "controllerthentriestosatisfythisgoalbytakingaseriesoflowlevelactions\n",
      "(onlyasubsetshown)butfailsduetocollidingwiththeskull(theepisode\n",
      "terminateshere).Themeta-controllerthenchoosesthebottom-rightladder\n",
      "asthenextgoalandthecontrollerterminatesafterreachingit.Subsequently,\n",
      "themeta-controllerchoosesthekeyandthetop-rightdoorandthecontroller\n",
      "isabletosuccessfullyachieveboththesegoals.ResultsFigure4showsreward\n",
      "progressfromthejointtrainingphase?itisevidentthatthemodelstarts\n",
      "graduallylearningtobothreachthekeyandopenthedoortogetareward\n",
      "ofaround+400perepisode.Theagentlearnstochoosethekeymoreoftenas\n",
      "trainingproceedsandisalsosuccessfulatreachingit.Weobservethattheagent\n",
      "learnstoperformthesimplergoals(suchasreachingtherightdoororthe\n",
      "middleladder)andthenslowlystartslearningthe?harder?goalssuchasthe\n",
      "keyandthebottomladders,whichprovideapathtohigherrewards.Figure4\n",
      "alsoshowstheevolutionofthesuccessrateofgoalsthatarepicked.Attheend\n",
      "oftraining,wecanseethatthe?key?,?bottomleft-ladder?and?bottom-right-\n",
      "ladders?arechosenincreasinglymoreoften.Inordertoscale-uptosolvethe\n",
      "entiregame,severalkeyingredientsaremissing,suchas?automaticdiscovery\n",
      "ofobjectsfromvideostoaidthegoalparameterizationweconsidered,aexible\n",
      "shorttermmemory,ortheabilitytointermittentlyterminateongoingoptions.\n",
      "Wealsoshowsomescreenshotsfromatestrunwithouragent(withepsilonset\n",
      "to0.1)inFigure5,aswellasasampleanimationoftherun.2\n",
      "12\n",
      "\n",
      "2References\n",
      "[1]A.BaranesandP.-Y.Oudeyer.Activelearningofinversemodelswithin-\n",
      "trinsicallymotivatedgoalexplorationinrobots.RoboticsandAutonomous\n",
      "Systems,61(1):49?73,2013.[2]A.G.BartoandS.Mahadevan.Recentad-\n",
      "vancesinhierarchicalreinforcementlearning.DiscreteEventDynamicSys-\n",
      "tems,13(4):341?379,2003.[3]M.G.Bellemare,Y.Naddaf,J.Veness,andM.\n",
      "Bowling.Thearcadelearningenvironment:Anevaluationplatformforgeneral\n",
      "agents.JournalofIntelligenceResearch,2012.2\n",
      "Sampletrajectoryofarunon?Montezuma?sRevenge??https://goo.gl/3Z64Ji\n",
      "8\n",
      "[4]L.C.Cobo,C.L.Isbell,andA.L.Thomaz.Objectfocusedq-learning\n",
      "forautonomousagents.InProceedingsofAAMAS,pages1061?1068,2013.\n",
      "[5]P.Dayan.Improvinggeneralizationfortemporallearning:The\n",
      "successorrepresentation.NeuralComputation,5(4):613?624,1993.[6]T.G.\n",
      "Dietterich.Hierarchicalreinforcementlearningwiththemaxqvaluefunction\n",
      "decomposition.J.Artif.Intell.Res.(JAIR),13:227?303,2000.[7]C.Diuk,\n",
      "A.Cohen,andM.L.Littman.Anobject-orientedrepresentationfort\n",
      "reinforcementlearning.InProceedingsoftheInternationalConferenceonMa-\n",
      "chinelearning,pages240?247,2008.[8]S.Eslami,N.Heess,T.Weber,Y.\n",
      "Tassa,K.Kavukcuoglu,andG.E.Hinton.Attend,infer,repeat:Fastscene\n",
      "understandingwithgenerativemodels.arXivpreprintarXiv:1603.08575,2016.\n",
      "[9]M.Frank,J.Leitner,M.Stollenga,A.F?orster,andJ.Schmidhuber.Cu-\n",
      "riositydrivenreinforcementlearningformotionplanningonhumanoids.Intrin-\n",
      "sicmotivationsandopen-endeddevelopmentinanimals,humans,androbots,\n",
      "page245,2015.[10]S.GoelandM.Huber.Subgoaldiscoveryforhierarchi-\n",
      "calreinforcementlearningusinglearnedpolicies.InFLAIRSconference,pages\n",
      "346?350,2003.[11]C.Guestrin,D.Koller,C.Gearhart,andN.Kanodia.\n",
      "Generalizingplanstonewenvironmentsinrelationalmdps.InProceedingsof\n",
      "InternationalJointconferenceonArIntelligence,pages1003?1010,2003.\n",
      "[12]C.Guestrin,D.Koller,R.Parr,andS.Venkataraman.tsolution\n",
      "algorithmsforfactoredmdps.JournalofIntelligenceResearch,pages\n",
      "399?468,2003.[13]N.Hernandez-GardiolandS.Mahadevan.Hierarchical\n",
      "memory-basedreinforcementlearning.InAdvancesinNeuralInformationPro-\n",
      "cessingSystems,pages1047?1053,2001.[14]J.Koutn??k,J.Schmidhuber,\n",
      "andF.Gomez.Evolvingdeepunsupervisedconvolutionalnetworksforvision-\n",
      "basedreinforcementlearning.InProceedingsofthe2014conferenceonGenetic\n",
      "andevolutionarycomputation,pages541?548.ACM,2014.[15]V.Mnih,A.\n",
      "P.Badia,M.Mirza,A.Graves,T.P.Lillicrap,T.Harley,D.Silver,andK.\n",
      "Kavukcuoglu.Asynchronousmethodsfordeepreinforcementlearning.arXiv\n",
      "preprintarXiv:1602.01783,2016.[16]V.Mnih,K.Kavukcuoglu,D.Silver,A.\n",
      "A.Rusu,J.Veness,M.G.Bellemare,A.Graves,M.Riedmiller,etal.Human-\n",
      "levelcontrolthroughdeepreinforcementlearning.Nature,518(7540):529?533,\n",
      "2015.[17]S.MohamedandD.J.Rezende.Variationalinformationmaximisa-\n",
      "tionforintrinsicallymotivatedreinforcementlearning.InAdvancesinNeural\n",
      "InformationProcessingSystems,pages2116?2124,2015.[18]A.Nair,P.Srini-\n",
      "13\n",
      "\n",
      "vasan,S.Blackwell,C.Alcicek,R.Fearon,A.DeMaria,V.Panneershelvam,et\n",
      "al.Massivelyparallelmethodsfordeepreinforcementlearning.arXivpreprint\n",
      "arXiv:1507.04296,2015.[19]I.Osband,C.Blundell,A.Pritzel,andB.Van\n",
      "Roy.Deepexplorationviabootstrappeddqn.arXivpreprintarXiv:1602.04621,\n",
      "2016.[20]P.-Y.OudeyerandF.Kaplan.Whatisintrinsicmotivation?aty-\n",
      "pologyofcomputationalapproaches.Frontiersinneurorobotics,1:6,2009.[21]\n",
      "T.Schaul,D.Horgan,K.Gregor,andD.Silver.Universalvaluefunctionap-\n",
      "proximators.InProceedingsofthe32ndInternationalConferenceonMachine\n",
      "Learning(ICML-15),pages1312?1320,2015.[22]J.Schmidhuber.Formal\n",
      "theoryofcreativity,fun,andintrinsicmotivation(1990?2010).Autonomous\n",
      "MentalDevelopment,IEEETransactionson,2(3):230?247,2010.[23]D.Sil-\n",
      "ver,A.Huang,C.J.Maddison,A.Guez,L.Sifre,G.vandenDriessche,J.\n",
      "Schrittwieser,etal.Masteringthegameofgowithdeepneuralnetworksand\n",
      "treesearch.Nature,529(7587):484?489,2016.?S?ims?ek,A.Wolfe,andA.\n",
      "Barto.Identifyingusefulsubgoalsinreinforcementlearningbylocalgraph[24]\n",
      "O.partitioning.InProceedingsoftheInternationalconferenceonMachine\n",
      "learning,pages816?823,2005.[25]S.Singh,R.L.Lewis,andA.G.Barto.\n",
      "Wheredorewardscomefrom.InProceedingsoftheannualconferenceofthe\n",
      "cognitivesciencesociety,pages2601?2606,2009.[26]S.Singh,R.L.Lewis,A.\n",
      "G.Barto,andJ.Sorg.Intrinsicallymotivatedreinforcementlearning:Anevo-\n",
      "lutionaryperspective.AutonomousMentalDevelopment,IEEETransactions\n",
      "on,2(2):70?82,2010.[27]S.P.Singh,A.G.Barto,andN.Chentanez.In-\n",
      "trinsicallymotivatedreinforcementlearning.InAdvancesinneuralinformation\n",
      "processingsystems,pages1281?1288,2004.[28]J.SorgandS.Singh.Linear\n",
      "options.InProceedingsofthe9thInternationalConferenceonAutonomous\n",
      "AgentsandMultiagentSystems,pages31?38,Richland,SC,2010.[29]E.S.\n",
      "SpelkeandK.D.Kinzler.Coreknowledge.Developmentalscience,10(1):89?96,\n",
      "2007.[30]K.L.Stachenfeld,M.Botvinick,andS.J.Gershman.Designprin-\n",
      "ciplesofthehippocampalcognitivemap.InAdvancesinneuralinformation\n",
      "processingsystems,pages2528?2536,2014.[31]B.C.Stadie,S.Levine,andP.\n",
      "Abbeel.Incentivizingexplorationinreinforcementlearningwithdeeppredic-\n",
      "tivemodels.arXivpreprintarXiv:1507.00814,2015.[32]R.S.SuttonandA.\n",
      "G.Barto.Introductiontoreinforcementlearning.MITPressCambridge,1998.\n",
      "[33]R.S.Sutton,J.Modayil,M.Delp,T.Degris,P.M.Pilarski,A.White,\n",
      "andD.Precup.Horde:Ascalablereal-timearchitectureforlearningknowledge\n",
      "fromunsupervisedsensorimotorinteraction.InThe10thInternationalCon-\n",
      "ferenceonAutonomousAgentsandMultiagentSystems,pages761?768,2011.\n",
      "[34]R.S.Sutton,D.Precup,andS.Singh.Betweenmdpsandsemi-mdps:A\n",
      "frameworkfortemporalabstractioninreinforcementlearning.intel-\n",
      "ligence,112(1):181?211,1999.[35]C.Szepesvari,R.S.Sutton,J.Modayil,S.\n",
      "Bhatnagar,etal.Universaloptionmodels.InAdvancesinNeuralInformation\n",
      "ProcessingSystems,pages990?998,2014.\n",
      "9\n",
      "14\n",
      "\n",
      "PP6964.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP6964.pdf 17\n",
      "MultiresolutionKernelApproximationfor\n",
      "GaussianProcessRegression\n",
      "Authoredby:\n",
      "RisiKondor\n",
      "YiDing\n",
      "JonathanEskreis-Winkler\n",
      "Abstract\n",
      "Gaussianprocessregressiongenerallydoesnotscaletobeyondafew\n",
      "thousandsdatapointswithoutapplyingsomesortofkernelapproximation\n",
      "method.Mostapproximationsfocusonthehigheigenvaluepartofthe\n",
      "spectrumofthekernelmatrix,$K$,whichleadstobadperformancewhen\n",
      "thelengthscaleofthekernelissmall.InthispaperweintroduceMul-\n",
      "tiresolutionKernelApproximation(MKA),thetruebroadbandwidth\n",
      "kernelapproximationalgorithm.ImportantpointsaboutMKAarethat\n",
      "itismemoryt,anditisadirectmethod,whichmeansthatitalso\n",
      "makesiteasytoapproximate$K\n",
      "f\n",
      "-1\n",
      "g\n",
      "$and$mathop\n",
      "f\n",
      "textrm\n",
      "f\n",
      "det\n",
      "gg\n",
      "(K)$.\n",
      "1PaperBody\n",
      "GaussianProcess(GP)regression,anditsfrequentistcousin,kernelridgeregres-\n",
      "sion,aresuchnaturalandcanonicalalgorithmsthattheyhavebeenreinvented\n",
      "manytimesbytcommunitiesundertnames.Inmachinelearn-\n",
      "ing,GPsareconsideredoneofthestandardmethodsofBayesiannonparametric\n",
      "inference[1].Meanwhile,thesamemodel,underthenameKrigingorGaussian\n",
      "RandomFields,isthedefactostandardformodelingarangeofnaturalphe-\n",
      "nomenafromgeophyicstobiology[2].Oneofthemostappealingfeaturesof\n",
      "GPsisthat,ultimately,thealgorithmreducesto?just?havingtocomputethe\n",
      "inverseofakernelmatrix,K.Unfortunately,thisalsoturnsouttobetheal-\n",
      "gorithm?sAchillesheel,sinceinthegeneralcase,thecomplexityofinvertinga\n",
      "densen?nmatrixscaleswithO(n3),meaningthatwhenthenumberoftraining\n",
      "examplesexceeds104?105,GPinferencebecomesproblematiconvirtually\n",
      "anycomputer1.Overthecourseofthelast15years,devisingapproximations\n",
      "toaddressthisproblemhasbecomeaburgeoningThemostcommonap-\n",
      "proachistouseoneoftheso-calledNystr?ommethods[3],whichselectasmall\n",
      "subset\n",
      "f\n",
      "xi1,...,xim\n",
      "g\n",
      "oftheoriginaltrainingdatapointsas?anchors?\n",
      "andapproximateKinthe>formK?K?,ICK?,I,whereK?,Iisthesubmatrix\n",
      "1\n",
      "\n",
      "ofKconsistingofcolumns\n",
      "f\n",
      "i1,...,im\n",
      "g\n",
      ",andCisamatrixsuchasthe\n",
      "pseudo-inverseofKI,I.Nystr?ommethodsoftenworkwellinpracticeandhave\n",
      "amatureliteratureringstrongtheoreticalguarantees.Still,Nystr?omis\n",
      "inherentlyagloballowrankapproximation,and,aspointedoutin[4],apriori\n",
      "thereisnoreasontobelievethatKshouldbewellapproximablebyalowrank\n",
      "matrix:forexample,inthecaseofthepopularGaussiankernelk(x,x0)=\n",
      "exp(?(x?x0)2/(2`2)),as`decreasesandthekernelbecomesmoreandmore\n",
      "?local?thenumberofteigenvaluesquicklyincreases.Thisobservation\n",
      "hasmotivatedalternativetypesofapproximations,includinglocal,hierarchical\n",
      "anddistributedones(seeSection2).Incertaincontextsinvolvingtranslation\n",
      "invariantkernelsyetotherstrategiesmaybeapplicable[5],butthesearebe-\n",
      "yondthescopeofthepresentpaper.Inthispaperwepresentanewkernel\n",
      "approximationmethod,MultiresolutionKernelApproximation(MKA),which\n",
      "isinspiredbyacombinationofideasfromhierarchicalmatrixdecomposition1\n",
      "InthelimitedcaseofevaluatingaGPwithaGrammatrixonasingle\n",
      "trainingset,GPinferencereducestosolvingalinearsysteminK,whichscales\n",
      "betterwithn,butmightbeproblematicbehaviorwhentheconditionnumber\n",
      "ofKislarge.\n",
      "31stConferenceonNeuralInformationProcessingSystems(NIPS2017),\n",
      "LongBeach,CA,USA.\n",
      "algorithmsandmultiresolutionanalysis.Someoftheimportantfeaturesof\n",
      "MKAarethat(a)itisabroadspectrumalgorithmthatapproximatestheentire\n",
      "kernelmatrixK,notjustitstopeigenvectors,and(b)itisaso-called?direct?\n",
      "method,i.e.,ityieldsexplicitapproximationstoK?1anddet(K).Notations.\n",
      "Wedene[n]=\n",
      "f\n",
      "1,2,...,n\n",
      "g\n",
      ".GivenamatrixA,andatupleI=(i1,...,\n",
      "ir),AI,?willdenotethesubmatrixofAformedofrowsindexedbyi1,...,\n",
      "ir,similarlyA?,Jwilldenotethesubmatrixformedofcolumnsindexedbyj1\n",
      ",...,jp,andAI,Jwilldenotethesubmatrixattheintersectionofrowsi1,.\n",
      "..,irandcolumnsj1,...,jp.Weextendthesenotationstothecasewhen\n",
      "IandJaresetsintheobviousway.IfAisablockedmatrixthenJAKi,jwill\n",
      "denoteits(i,j)block.\n",
      "2\n",
      "Localvs.globalkernelapproximation\n",
      "RecallthataGaussianProcess(GP)onaspaceXisaprioroverfunctions\n",
      "f:X?Rbyameanfunction?(x)=E[f(x)],andcovariancefunction\n",
      "k(x,x0)=Cov(f(x),f(x0)).Usingthemostelementarymodelyi=f(xi)+\n",
      "where?N(0,?2)and?2isanoiseparameter,giventrainingdata\n",
      "f\n",
      "(x1,y1\n",
      "),...,(xn,yn)\n",
      "g\n",
      ",theposteriorisalsoaGP,withmean?0(x)=?(x)+k>x\n",
      "(K+?2I)?1y,wherekx=(k(x,x1),...,k(x,xn)),y=(y1,...,yn),\n",
      "andcovariance2?1kx.k0(x,x0)=k(x,x0)?k>x0(K+?I)\n",
      "(1)\n",
      "Thus(hereandinthefollowingassuming?=0forsimplicity),themaximum\n",
      "aposteriori(MAP)estimateoffis2?1y.(2)fb(x)=k>x(K+?I)Ridge\n",
      "regression,whichisthefrequentistanalogofGPregression,yieldsthesame\n",
      "formula,butregardsfbasthesolutiontoaregularizedriskminizationproblem\n",
      "overaHilbertspaceHinducedbyk.Wewilluse?GP?asthegenerictermto\n",
      "2\n",
      "\n",
      "refertobothBayesianGPsandridgeregression.LettingK0=(K+?2I),\n",
      "virtuallyallGPapproximationapproachesfocusontryingtoapproximatethe\n",
      "(augmented)kernelmatrixK0insuchawaysoastomakeinvertingit,solving\n",
      "K0y=?orcomputingdet(K0)easier.Forthesakeofsimplicityinthe\n",
      "followingwewillactuallydiscussapproximatingK,sinceaddingthediagonal\n",
      "termusuallydoesn?tmaketheproblemanymorechallenging.2.1\n",
      "Globallowrankmethods\n",
      "Asinotherkernelmethods,intuitively,Ki,j=k(xi,xj)encodesthedegree\n",
      "ofsimilarityorclosenessbetweenthetwopointsxiandxjasitrelatestothe\n",
      "degreeofcorrelation/similaritybetweenthevalueoffatxiandatxj.Given\n",
      "thatkisoftenconceivedofasasmooth,slowlyvaryingfunction,onevery\n",
      "naturalideaistotakeasmallerset\n",
      "f\n",
      "xi1,...,xim\n",
      "g\n",
      "of?landmarkpoints?\n",
      "or?pseudo-inputs?andapproximatek(x,x0)intermsofthesimilarityofxto\n",
      "eachofthelandmarks,therelationshipofthelandmarkstoeachother,andthe\n",
      "similarityofthelandmarkstox0.Mathematically,k(x,x0)?\n",
      "mXmX\n",
      "k(x,xis)cis,ijk(xij,x0),\n",
      "s=1j=1\n",
      "which,assumingthat\n",
      "f\n",
      "xi1,...,xim\n",
      "g\n",
      "isasubsetoftheoriginalpoint\n",
      "set\n",
      "f\n",
      "x1,...,xn\n",
      "g\n",
      ",amountsto>anapproximationoftheformK?K?,IC\n",
      "K?,I,withI=\n",
      "f\n",
      "i1,...,im\n",
      "g\n",
      ".Thecanonicalchoicefor++CisC=W,\n",
      "whereW=KI,I,andWdenotestheMoore-PenrosepseudoinverseofW.The\n",
      "resultingapproximation>K?K?,IW+K?,I,(3)isknownastheNystr?om\n",
      "approximation,becauseitisanalogoustotheso-calledNystr?omextensionused\n",
      "toextrapolatecontinuousoperatorsfromanitenumberofquadraturepoints.\n",
      "Clearly,thechoiceofIiscriticalforagoodqualityapproximation.Startingwith\n",
      "thepioneeringpapers[6,3,7],overthecourseofthelast15yearsasequence\n",
      "ofdierentsamplingstrategieshavebeendevelopedforobtainingI,several\n",
      "withrigorousapproximationbounds[8,9,10,11].Furthervariationsinclude\n",
      "theensembleNystr?ommethod[12]andthemoNystr?ommethod[13].\n",
      "Nystr?ommethodshavetheadvantageofbeingrelativelysimple,andhaving\n",
      "reliableperformancebounds.Afundamentallimitation,however,isthatthe\n",
      "approximation(3)isinherentlylowrank.Aspointedoutin[4],thereisno\n",
      "reasontobelievethatkernelmatricesingeneralshouldbeclosetolowrank.\n",
      "Anevenmorefundamentalissue,whichislessoftendiscussedintheliterature,\n",
      "relatestothe2\n",
      "spformof(2).TheappearanceofK0?1inthisformulasuggeststhatit\n",
      "istheloweigenvalueeigenvectorsofK0thatshoulddominatetheresultofGP\n",
      "regression.Ontheotherhand,multiplyingthematrixbykxlargelycancelsthis\n",
      "sincekxiselyarowofakernelmatrixsimilartoK0,andwill\n",
      "likelyconcentratemostweightonthehigheigenvalueeigenvectors.Therefore,\n",
      "ultimately,itisnotK0itself,buttherelationshipbetweentheeigenvectors\n",
      "ofK0andthedatavectorythatdetermineswhichpartofthespectrumof\n",
      "K0theresultofGPregressionismostsensitiveto.Onceagain,intuition\n",
      "aboutthekernelhelpsclarifythispoint.Inasettingwherethefunctionthat\n",
      "weareregressingissmooth,andcorrespondingly,thekernelhasalargelength\n",
      "3\n",
      "\n",
      "scaleparameter,itistheglobal,longrangerelationshipsbetweendatapoints\n",
      "thatdominateGPregression,andthatcanindeedbewellapproximatedbythe\n",
      "landmarkpointmethod.Intermsofthelinearalgebra,thespectralexpansion\n",
      "ofK0isdominatedbyafewlargeeigenvalueeigenvectors,wewillcallthisthe\n",
      "?PCA-like?scenario.Incontrast,insituationswherefvariesmorerapidly,a\n",
      "shorterlengthscalekerneliscalledfor,localrelationshipsbetweennearbypoints\n",
      "becomemoreimportant,whichthelandmarkpointmethodislesswellsuitedto\n",
      "capture.Wecallthisthe?k?nearestneighbortype?scenario.Inreality,most\n",
      "non-trivialGPregressionproblemsfallsomewhereinbetweentheabovetwo\n",
      "extremes.Inhighdimensionsdatapointstendtobeallalmostequallyfarfrom\n",
      "eachotheranyway,limitingtheapplicabilityofsimplegeometricinterpretations.\n",
      "Nonetheless,thetwoscenariosareanillustrationofthegeneralpointthatone\n",
      "ofthekeychallengesinlargescalemachinelearningisintegratinginformation\n",
      "frombothlocalandglobalscales.2.2\n",
      "Localandhierarchicallowrankmethods\n",
      "Realizingthelimitationsofthelowrankapproach,localkernelapproxi-\n",
      "mationmethodshavealsostartedappearingintheliterature.Broadly,these\n",
      "algorithms:(1)clustertherows/columnsofKwithsomeappropriatefast\n",
      "clusteringmethod,e.g.,METIS[14]orGRACLUS[15]andblockKaccordingly;\n",
      "(2)computealowrank,butrelativelyhighaccuracy,approximationJKKi,j?\n",
      "Ui?iUi>toeachdiagonalblockofK;(3)usethe\n",
      "f\n",
      "Ui\n",
      "g\n",
      "basestocomputepossi-\n",
      "blycoarserapproximationstotheJKKi,jdiagonalblocks.Thisideaappears\n",
      "initspurestformin[16],andisin[4]inawaythatavoidshavingtoform\n",
      "allrows/columnsoftheblocksintheplace.Recently,[17]pro-\n",
      "posedarelatedapproach,wherealltheblocksinagivenrowsharethesamerow\n",
      "basisbuthavetcolumnbases.Amajoradvantageoflocalapproaches\n",
      "isthattheyareinherentlyparallelizable.Theclusteringitself,however,isa\n",
      "delicate,andsometimesnotveryrobustcomponentofthesemethods.Infact,\n",
      "divide-and-conquertypealgorithmssuchas[18]and[19]canalsobeincludedin\n",
      "thesamecategory,eventhoughinthesecasestheblockingisusuallyrandom.A\n",
      "naturalextensionoftheblockingideawouldbetoapplythedivide-and-conquer\n",
      "approachrecursively,atmultipletscales.Geometrically,thisissimilar\n",
      "torecentmultiresolutiondataanalysisapproachessuchas[20].Infact,hierar-\n",
      "chicalmatrixapproximations,includingHODLRmatrices,H?matrices[21],H2\n",
      "?matrices[22]andHSSmatrices[23]areverypopularinthenumericalanalysis\n",
      "literature.Whiletheexactdetailsvary,eachofthesemethodsimposesasp\n",
      "typeofblockstructureonthematrixandforcestheblockstobe\n",
      "lowrank(Figure1intheSupplement).Intutitively,nearbyclustersinteractina\n",
      "richerway,butaswemovefartheraway,datacanbeaggregatedmoreandmore\n",
      "coarsely,justasinthefastmultipolemethod[24].Weknowofonlytwoappli-\n",
      "cationsofthehierarchicalmatrixmethodologytokernelapproximation:B?orm\n",
      "andGarcke?sH2matrixapproach[25]andO?Neiletal.?sHODLRmethod[26].\n",
      "TheadvantageofH2matricesistheirmoreintricatestructure,allowingrela-\n",
      "tivelytightinteractionsbetweenneighboringclustersevenwhenthetwoclusters\n",
      "arenotsiblingsinthetree(e.g.blocks8and9inFigure1cintheSupplement).\n",
      "However,theH2formatdoesnotdirectlyhelpwithinvertingKorcomputing\n",
      "4\n",
      "\n",
      "itsdeterminant:itismerelyatwayofstoringKandperforming\n",
      "matrix/vectormultipliesinsideaniterativemethod.HODLRmatriceshavea\n",
      "simplerstructure,butadmitafactorizationthatmakesitpossibletodirectly\n",
      "computeboththeinverseandthedeterminantoftheapproximatedmatrixin\n",
      "justO(nlogn)time.Thereasonthathierarhicalmatrixapproximationshave\n",
      "notbecomemorepopularinmachinelearningsofaristhatinthecaseofhigh\n",
      "dimensional,unstructureddata,thewaytoorganize\n",
      "f\n",
      "x1,...,xn\n",
      "g\n",
      "intoasinglehierarchyismuchmorechallengingthaninthesettingofregularly\n",
      "spacedpointsinR2orR3,wherethesemethodsoriginate:1.Hierarchical\n",
      "matricesrequiremakinghardassignmentsofdatapointstoclusters,sincethe\n",
      "blockstructureateachlevelcorrespondstopartitioningtherows/columnsof\n",
      "theoriginalmatrix.2.Thehierarchymustformasingletree,which3\n",
      "putsdeepdivisionsbetweenclusterswhoseclosestcommonancestorishigh\n",
      "upinthetree.3.Findingthehierarchyintheplaceisbynomeanstrivial.\n",
      "Mostworksuseatop-downstrategywhichdefeatstheinherentparallelismof\n",
      "thematrixstructure,andtheactualalgorithmused(kd-trees)isknowntobe\n",
      "problematicinhighdimensions[27].\n",
      "3\n",
      "MultiresolutionKernelApproximation\n",
      "Ourgoalinthispaperistodevelopadataadaptedmultiscalekernelmatrix\n",
      "approximationmethod,MultiresolutionKernelApproximation(MKA),thatre-\n",
      "the?distantclustersonlyinteractinalowrankfashion?insightofthefast\n",
      "multipolemethod,butisconsiderablymorethanexistinghierarchical\n",
      "matrixdecompositions.ThebasicbuildingblocksofMKAarelocalfactoriza-\n",
      "tionsofaspeform,whichwecallcore-diagonalcompression.1\n",
      "WesaythatamatrixHisc?core-diagonalifHi,j=0unlesseitheri,j?cor\n",
      "i=j.2Ac?core-diagonalcompressionofasymmetricmatrixA?\n",
      "Rm?misanapproxima\n",
      "tionoftheform>A?QHQ=,(4)whereQisorthogonalandHisc?core-\n",
      "diagonal.Core-diagonalcompressionistobecontrastedwithrankcsketching,\n",
      "whereHwouldjusthavethec?cblock,withouttherestofthediagonal.From\n",
      "ourmultiresolutioninspiredpointofview,however,thepurposeof(4)isnotjust\n",
      "tosketchA,buttoalsotosplitRmintothedirectsumoftwosubspaces:(a)\n",
      "the?detailspace?,spannedbythelastn?crowsofQ,responsibleforcapturing\n",
      "purelylocalinteractionsinAand(b)the?scalingspace?,spannedbythec\n",
      "rows,capturingtheoverallstructureofAanditsrelationshiptootherdiagonal\n",
      "blocks.Hierarchicalmatrixmethodsapplylowrankdecompositionstomany\n",
      "blocksofKinparallel,attscales.MKAworkssimilarly,byapplying\n",
      "core-diagonalcompressions.Sp,thealgorithmproceedsbytakingK\n",
      "throughasequenceoftransformationsK=K07?K17?...7?Ks,called\n",
      "stages.Inthestage1.Similarytootherlocalmethods,MKAusesa\n",
      "fastclusteringmethodtoclustertherows/columnsofK0intoclustersC11,.\n",
      "..,Cp11.UsingthecorrespondingpermutationmatrixC1(whichmapsthe\n",
      "elementsoftheclusterto(1,2,...|C11|),theelementsofthesecond\n",
      "clusterto(|C11|+1,...,|C11|+|C21|),andsoon)weform\n",
      "ablockedmatrixK0=C1K0C1>,whereJK0Ki,j=KCi1,Cj1.2.Each\n",
      "5\n",
      "\n",
      "diagonalblockofK0isindependentlycore-diagonallycompressedasin(4)to\n",
      "yieldHi1=Q1iJK0Ki,i(Q1i)>CD(c1)\n",
      "(5)\n",
      "i\n",
      "3.\n",
      "whereCD(c1i)intheindexstandsfortruncationtoc1i?core-diagonalThe\n",
      "Q1ilocalrotationsareassembledintoasinglelargeorthogonal>appliedtothe\n",
      "fullmatrixtogiveH1=Q1K0Q1.\n",
      "form.L1matrixQ1=iQiand\n",
      "4.Therows/columnsofH1arerearrangedbyapplyingapermutationP1\n",
      "thatmapsthecorepartofeachblocktooneofthec1:=c11+...c1p1\n",
      "coordinates,andthediagonalparttotherest,givingH1pre=P1H1P1>.5.\n",
      "Finally,H1preistruncatedintothecore-diagonalformH1=K1?D1,where\n",
      "K1?Rc1?c1isdense,whileD1isdiagonal.ely,K1isacompressed\n",
      "versionofK0,whileD1isformedbyconcatenatingthediagonalpartsofeach\n",
      "oftheHi1matrices.Together,thisgivesaglobalcore-diagonalcompressionK0\n",
      "?C1>Q1>P1>(K1?D1)P1Q1C1|\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "f\n",
      "z\n",
      "g\n",
      "Q1\n",
      "Q>\n",
      "1oftheentireoriginalmatrixK0.ThesecondandfurtherstagesofMKA\n",
      "consistofapplyingtheaboveestepstoK1,K2,...,Ks?1?whichhas\n",
      "atelescopingforminturn,soultimatelythealgorithmyieldsakernelapproxi-\n",
      "mationK\n",
      "??Q>(Q>(...Q>(Ks?Ds)Qs...?D2)Q2?D1)Q1K12sThe\n",
      "pseudocodeofthefullalgorithmisintheSupplementaryMaterial.4\n",
      "(6)\n",
      "MKAisreallyameta-algorithm,inthesensethatitcanbeusedinconjunc-\n",
      "tionwithtcorediagonalcompressors.Themainrequirementsonthe\n",
      "compressorarethat(a)thecoreofHshouldcapturethedominantpartofA,in\n",
      "particularthesubspacethatmoststronglyinteractswithotherblocks,(b)the\n",
      "crowsofQshouldbeassparseaspossible.Weconsidertwoalternatives.\n",
      "AugmentedSparsePCA(SPCA).SparsePCAalgorithmsexplicitlysetoutto\n",
      "asetofvectors\n",
      "f\n",
      "v1,...,vc\n",
      "g\n",
      "soastomaximizekV>AVkFrob,\n",
      "whereV=[v1,...,vc],whileconstrainingeachvectortobeassparseas\n",
      "possible[28].WhilenotallSPCAsguaranteeorthogonality,thiscanbeenforced\n",
      "aposterioriviae.g.,QRfactorization,yieldingQsc,thetopcrowsofQin(4).\n",
      "LettingUbeabasisforthecomplementarysubspace,theoptimalchoicefor\n",
      "thebottomm?crowsinterms?whereofminimizingFrobeniusnormerror\n",
      "ofthecompressionisQwlet=UO,?=argmaxkdiag(O>U>AUO)k,OO\n",
      ">O=I\n",
      "thesolutiontowhichisofcoursegivenbytheeigenvectorsofU>AU.The\n",
      "maindrawbackoftheSPCAapproachisitscomputationalcost:dependingon\n",
      "thealgorithm,thecomplexityofSPCAscaleswithm3orworse[29,30].Mul-\n",
      "tiresolutionMatrixFactorization(MMF)MMFisarecentlyintroducedmatrix\n",
      "factorizationalgorithmmotivatedbysimilarmultiresolutionideasasthepresent\n",
      "work,butappliedatthelevelofindividualmatrixentriesratherthanatthe\n",
      "6\n",
      "\n",
      "levelofmatrixblocks[31].Sp,MMFyieldsafactorizationoftheform\n",
      ">HqL...q1,A?q1>...qL|\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "f\n",
      "z\n",
      "g\n",
      "Q\n",
      "Q>\n",
      "where,inthesimplestcase,theqi?sarejustGivensrotations.Typically,\n",
      "thenumberofrotationsinMMFisO(m).MMFisttocompute,and\n",
      "sparsityisguaranteedbythesparsityoftheindividualqi?sandthestructureof\n",
      "thealgorithm.Hence,MMFhascomplementarystrengthstoSPCA:itcomes\n",
      "withstrongboundsonsparsityandcomputationtime,butthequalityofthe\n",
      "scaling/waveletspacesplitthatitproducesislesswellcontrolled.Remarks.We\n",
      "makeafewremarksaboutMKA.1.Typically,lowrankapproximationsreduce\n",
      "dimensionalityquiteaggressively.Incontrast,incore-diagonalcompressionc\n",
      "isoftenontheorderofm/2,leadingto?gentler?andmorefaithful,kernel\n",
      "approximations.2.Inhierarchicalmatrixmethods,theblockstructureof\n",
      "thematrixisbyasingletree,which,asdiscussedabove,ispotentially\n",
      "problematic.Incontrast,byvirtueofreclusteringtherows/columnsofK`before\n",
      "everystage,MKAamorelefactorization.Infact,beyondthe\n",
      "stage,itisnotevenindividualdatapointsthatMKAclusters,butsubspaces\n",
      "bytheearlierlocalcompressions.3.WhileC`andP`arepresentedas\n",
      "explicitpermutations,theyreallyjustcorrespondtotwaysofblocking\n",
      "Ks,whichisdoneimplicitlyinpracticewithrelativelylittleoverhead.4.Step\n",
      "3ofthealgorithmiscritical,becauseitextendsthecore-diagonalsplitsfound\n",
      "inthediagonalblocksofthematrixtotheblocks.Essentiallythe\n",
      "sameisdonein[4]and[17].Thisoperationastructuralassumption\n",
      "aboutK,namelythatthesamebasesthatpickoutthedominantpartsofthe\n",
      "diagonalblocks(composedofthec`irowsoftheQ`irotations)arealsogood\n",
      "forcompressingtheblocks.Inthehierarchicalmatrixliterature,\n",
      "forthecaseofspkernelssampledinspwaysinlowdimensions,itis\n",
      "possibletoprovesuchstatements.Inourhighdimensionalandlessstructured\n",
      "setting,derivinganalyticalresultsismuchmorechallenging.5.MKAisan\n",
      "inherentlybottom-upalgorithm,includingtheclustering,thusitisnaturally\n",
      "parallelizableandcanbeimplementedinadistributedenvironment.6.The\n",
      "hierarchicalstructureofMKAissimilartothatoftheparallelversionofMMF\n",
      "(pMMF)[32],butthewaythatthecompressionsarecalculatedist\n",
      "(pMMFtriestominimizeanobjectivethatrelatestotheentirematrix).\n",
      "4\n",
      "ComplexityandapplicationtoGPs\n",
      "ForMKAtobeeforlargescaleGPregression,itmustbepossible\n",
      "tocomputethefactor?mustbesymmetricpositiveizationfast.\n",
      "Inaddition,theresultingapproximationK(spsd)(MEKA,forexample,failsto\n",
      "this[4]).WesaythatamatrixapproximationalgorithmA7?A?isspsd\n",
      "preservingifA?isspsdwheneverAis.ItisclearfromitsformthattheNystr?om\n",
      "approximationisspsdpreserving,soisaugmentedSPCAcompression.MMF\n",
      "hasrentvariants,butthecorepartofHisalwaysderivedbyconjugatingA\n",
      "byrotations,whilethediagonalelementsareguaranteedtobepositive,therefore\n",
      "MMFisspsdpreservingaswell.5\n",
      "Proposition1Iftheindividualcore-diagonalcompressionsinMKAarespsd\n",
      "7\n",
      "\n",
      "preserving,thentheentirealgorithmisspsdperserving.Thecomplexityof\n",
      "MKAdependsonthecomplexityofthelocalcompressions.Next,weassume\n",
      "thattoleadingorderinmthiscostisboundedbyccompm?comp(with?comp\n",
      "?1)andthateachrowoftheQmatrixthatisproducediscsp?sparse.We\n",
      "assumethattheMKAhassstages,thesizeoftheKs?corematrix?isdcore\n",
      "?dcore,andthatthesizeofthelargestclusterismmax.Weassmuethatthe\n",
      "maximumnumberofclustersinanystageisbmaxandthattheclusteringisclose\n",
      "tobalancedinthesensethatthatbmax=?(n/mmax)withasmallconstant.\n",
      "Weignorethecostoftheclusteringalgorithm,whichvaries,butusuallyscales\n",
      "linearlyinsnbmax.Wealsoignorethecostofpermutingtherows/columns\n",
      "ofK`,sincethisisamemoryboundoperationthatcanbevirtualizedaway.\n",
      "Thefollowingresultsaretoleadingorderinmmaxandaresimilartothosein\n",
      "[32]forparallelMMF.Proposition2Withtheabovenotations,thenumberof\n",
      "operationsneededtocomputetheMKAof?comp?1ann?nmatrixisupper\n",
      "boundedby2scspn2+sccompmmaxn.Assumingbmax?foldparallelism,?\n",
      "compthiscomplexityreducesto2scspn2/bmax+sccompmmax.Thememory\n",
      "costofMKAisjustthecostofstoringthevariousmatricesappearingin(6).We\n",
      "onlyincludethenumberofnon-zerorealsthatneedtobestoredandnotindices,\n",
      "etc..Proposition3ThestoragecomplexityofMKAisupperboundedby(scsp+\n",
      "1)n+d2core.Ratherthanthanthegeneralcase,itismoreinformativetofocus\n",
      "onMMFbasedMKA,whichiswhatweuseinourexperiments.Weconsider\n",
      "thesimplestcaseofMMF,referredtoas?greedyJacobi?MMF,inwhicheachof\n",
      "theqielementaryrotationsisaGivenrotation.Anadditionalparameterofthis\n",
      "algorithmisthecompressionratio?,whichinournotationisequaltoc/n.Some\n",
      "ofthespecialfeaturesofthistypeofcore-diagonalcompressionare:(a)While\n",
      "anygivenrowoftherotationQproducedbythealgorithmisnotguaranteed\n",
      "tobesparse,Qwillbetheproductofexactlyb(1??)mcGivensrotations.\n",
      "(b)Theleadingterminthecostisthem3costofcomputingA>A,butthisis\n",
      "aBLASoperation,soitisfast.(c)OnceA>Ahasbeencomputed,thecost\n",
      "oftherestofthecompressionscaleswithm2.Together,thesefeaturesresult\n",
      "inveryfastcore-diagonalcompressionsandaverycompactrepresentationof\n",
      "thekernelmatrix.Proposition4ThecomplexityofcomputingtheMMF-based\n",
      "MKAofann?ndensematrixisupperboundedby4sn2+sm2maxn,where\n",
      "s=log(dcore/n)/(log?).Assumingbmax?foldparallelism,thisisreduced\n",
      "to4snmmax+m3max.Proposition5ThestoragecomplexityofMMF-based\n",
      "MKAisupperboundedby(2s+1)n+d2core.Typically,dcore=O(1).Note\n",
      "thatthisimpliesO(nlogn)storagecomplexity,whichissimilartoNystr?om\n",
      "approximationswithverylowrank.Finally,wehavethefollowingresultsthat\n",
      "arecriticalforusingMKAinGPs.?inMMF-basedMKAform(6),anda\n",
      "vectorz?RnProposition6GivenanapproximatekernelK?theproductKz\n",
      "canbecomputedin4sn+d2coreoperations.Withbmax?foldparallelism,\n",
      "thisisreducedto4smmax+d2core.?in(MMForSPCA-based)MKAform,\n",
      "theMKAProposition7GivenanapproximatekernelK??forany?canbe\n",
      "computedinO(n+d3core)operations.Thecomplexityofcomputingform\n",
      "ofK?forany?inMKAformandthecomplexityofcomputingdet(K)?the\n",
      "matrixexponentialexp(?K)arealsoO(n+d3core).4.1\n",
      "8\n",
      "\n",
      "MKA?GPsandMKARidgeRegression\n",
      "ThemostdirectwayofapplyingMKAtospeedupGPregression(orridge\n",
      "regression)issimplyusingittoapproximatetheaugmentedkernelmatrixK0=\n",
      "(K+?2I)andtheninvertingthis?0?1neverneedstobeapproximationusing\n",
      "Proposition7(with?=?1).NotethattheresultingK?0?1yevaluatedfully,\n",
      "inmatrixform.Instead,inequationssuchas(2),thematrix-vectorproductK\n",
      "canbecomputedin?matrix-free?formbycascadingythroughtheanalogof\n",
      "(6).Assumingthatdcorenandmmaxisnottoolarge,theserialcomplexity\n",
      "ofeachstageofthiscomputationscaleswithatmostn2,whichisthesameas\n",
      "thecomplexityofcomputingKintheplace.Onepotentialissuewiththe\n",
      "aboveapproachhoweveristhatbecauseMKAinvolvesrepeatedtrun?0willbe\n",
      "abiasedapproximationtoK,thereforeexpressionssuchascationoftheHjpre\n",
      "matrices,K6\n",
      "SOR\n",
      "Full\n",
      "FITC\n",
      "PITC\n",
      "MEKA\n",
      "MKA\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "9\n",
      "\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-2\n",
      "-2\n",
      "-2\n",
      "-2\n",
      "-2\n",
      "-2\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-4\n",
      "-6\n",
      "-6\n",
      "-8\n",
      "-6\n",
      "-8\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "-6\n",
      "-8\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "-6\n",
      "-8\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "10\n",
      "\n",
      "250\n",
      "300\n",
      "-6\n",
      "-8\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "-8\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "Figure1:Snelson?s1Dexample:groundtruth(blackcircles);prediction\n",
      "mean(solidlinecurves);onestandarddeviationinpredictionuncertainty(dashed\n",
      "linecurves).Table1:RegressionResultswithktobe#pseudo-inputs/dcore:\n",
      "SMSE(MNLP)MethodhousingrupturewinepageblockscompActpendigit\n",
      "k161632323264\n",
      "Full0.36(?0.32)0.17(?0.89)0.59(?0.33)0.44(?1.10)0.58(?0.66)0.15(?0.73)\n",
      "SOR0.93(?0.03)0.94(?0.04)0.86(?0.07)0.86(?0.57)0.88(?0.13)0.65(?0.19)\n",
      "FITC0.91(?0.04)0.96(?0.04)0.84(?0.03)0.81(?0.78)0.91(?0.08)0.70(?0.17)\n",
      "PITC0.96(?0.02)0.93(?0.05)0.87(?0.07)0.86(?0.72)0.88(?0.14)0.71(?0.17)\n",
      "MEKA0.85(?0.08)0.46(?0.18)0.97(?0.12)0.96(?0.10)0.75(?0.21)0.53(?0.29)\n",
      "MKA0.52(?0.32)0.32(?0.54)0.70(?0.23)0.63(?0.85)0.60(?0.32)0.30(?0.42)\n",
      "(2)whichmixanapproximateK0withanexactkxwillexhibitsomesys-\n",
      "tematicbias.InNystr?omtypemethods(sp,theso-calledSubsetof\n",
      "RegressorsandDeterministicTrainingofConditionals(DTC)GPapproxima-\n",
      "tions)thisproblemisaddressedbyreplacingkxwithitsownNystr?om?x\n",
      "=K?,IW+kI,,where[k?I]j=k(x,xi).AlthoughK?0=K?,IW+K\n",
      ">+?2Iapproximation,kxxj?,I?>K?0?1cannonethelessbetly\n",
      "evaluatedbyusingaisalargematrix,expressionssuchaskxvariantofthe\n",
      "Sherman?Morrison?WoodburyidentityandthefactthatWislowrank(see\n",
      "[33]).?isnotlowrank.AssumingthatthetestingThesameapproachcannot\n",
      "beappliedtoMKAbecauseKset\n",
      "f\n",
      "x1,...,xp\n",
      "g\n",
      "isknownattraining\n",
      "time,however,insteadofapproximatingKorK0,wecomputetheMKA\n",
      "approximationofthejointtrain/testkernelmatrix\n",
      "11\n",
      "\n",
      "Ki,j=k(xi,xj)+?2KK?[K?]i,j=k(xi,x0j)K=whereK?>Ktest\n",
      "[Ktest]i,j=k(x0i,x0j).WritingK?1inblockedform??1=K\n",
      "AC\n",
      "BD\n",
      ",\n",
      "??1=A?andtakingtheSchurcomplementofDnowrecoversanalternative\n",
      "approximationKBD?1CtoK?1whichisconsistentwiththe\n",
      "blockK?leadingtoourMKA?GP??1y,wherefb=(fb(x0),...,\n",
      "fb(x0))>.Whileconceptuallythisissomewhatformulafb=K?>Kp1more\n",
      "involvedthannaivelyestimatingK0,assumingpn,thecostofinvertingDis\n",
      "negligible,andtheoverallserialcomplexityofthealgorithmremains(n+p)2\n",
      ".IncertainGPapplications,theO(n2)costofwritingdownthekernelmatrix\n",
      "isalreadyforbidding.TheonecircumstanceunderwhichMKAcangetaround\n",
      "thisproblemiswhenthekernelmatrixisamatrixpolynomialinasparsematrix\n",
      "L,whichismostnotablyforkernelsandcertainothergraphkernels.\n",
      "SpinthecaseofMMF-basedMKA,sincethecomputationalcostis\n",
      "dominatedbycomputinglocal?Grammatrices?A>A,whenLissparse,and\n",
      "thissparsityisretainedfromonecompressiontoanother,theMKAofsparse\n",
      "matricescanbecomputedveryfast.InthecaseofgraphLaplacians,empirically,\n",
      "thecomplexityisclosetolinearinn.ByProposition7,thekerneland\n",
      "certainothergraphkernelscanalsobeapproximatedinaboutO(nlogn)time.\n",
      "5\n",
      "Experiments\n",
      "WecompareMKAtoeothermethods:1.Full:thefullGPregression\n",
      "usingCholeskyfactorization[1].2.SOR:theSubsetofRegressorsmethod\n",
      "(alsoequivalenttoDTCinmean)[1].3.FITC:theFullyIndependentTraining\n",
      "Conditionalapproximation,alsocalledSparseGaussianProcessesusingPseudo-\n",
      "inputs[34].4.PITC:thePartiallyIndependentTrainingConditionalapproxi-\n",
      "mationmethod(alsoequivalenttoPTCinmean)[33].5.MEKA:theMemory\n",
      "tKernelApproximationmethod[4].TheKISS-GP[35]andotherin-\n",
      "terpolationbasedmethodsarenotdiscussedinthispaper,because,webelieve,\n",
      "theymostlyonlyapplytolowdimensionalsettings.WeusedcustomMatlab\n",
      "implementations[1]forFull,SOR,FITC,andPITC.WeusedtheMatlabcodes\n",
      "providedby7\n",
      "FullSORFITCPITCMEKAMKA\n",
      "0.75\n",
      "0.8-0.2\n",
      "0.7\n",
      "MNLP\n",
      "0.70.650.6\n",
      "-0.3\n",
      "-0.4\n",
      "0.55\n",
      "FullSORFITCPITCMEKAMKA\n",
      "-0.5\n",
      "0.50.45\n",
      "12\n",
      "\n",
      "-0.6\n",
      "0.4\n",
      "ruptureFullSORFITCPITCMEKAMKA\n",
      "0.9\n",
      "FullSORFITCPITCMEKAMKA\n",
      "-0.1\n",
      "-0.2\n",
      "-0.3\n",
      "MNLP\n",
      "0.8\n",
      "-0.1\n",
      "SMSE\n",
      "0.85\n",
      "SMSE\n",
      "rupture\n",
      "housing\n",
      "housing0.9\n",
      "0.6\n",
      "0.5\n",
      "-0.4\n",
      "-0.5\n",
      "-0.6\n",
      "0.4-0.7\n",
      "0.3-0.8\n",
      "0.22\n",
      "2.5\n",
      "3\n",
      "3.5\n",
      "4\n",
      "Log2#pseudo-inputs\n",
      "4.5\n",
      "2\n",
      "2.5\n",
      "3\n",
      "3.5\n",
      "4\n",
      "4\n",
      "4.5\n",
      "4.5\n",
      "5\n",
      "5.5\n",
      "6\n",
      "6.5\n",
      "7\n",
      "Log2#pseudo-inputs\n",
      "Log2#pseudo-inputs\n",
      "13\n",
      "\n",
      "7.5\n",
      "8\n",
      "4\n",
      "4.5\n",
      "5\n",
      "5.5\n",
      "6\n",
      "6.5\n",
      "7\n",
      "7.5\n",
      "8\n",
      "Log2#pseudo-inputs\n",
      "Figure2:SMSEandMNLPasafunctionofthenumberofpseudo-inputs/dcore\n",
      "ontwodatasets.InthegivenrangeMKAclearlyoutperformstheothermeth-\n",
      "odsinbotherrormeasures.theauthorforMEKA.OuralgorithmMKAwas\n",
      "implementedinC++withtheMatlabinterface.Togetanapproximatelyfair\n",
      "comparison,wesetdcoreinMKAtobethenumberofpseudo-inputs.The\n",
      "parallelMMFalgorithmwasusedasthecompressorduetoitscomputational\n",
      "strength[32].TheGaussiankernelisusedforallexperimentswithonelength\n",
      "scaleforallinputdimensions.Qualitativeresults.Weshowthequalitative\n",
      "behaviorofeachmethodonthe1Dtoydatasetfrom[34].Wesampledthe\n",
      "groundtruthfromaGaussianprocesseswithlengthscale`=0.5andnumberof\n",
      "pseudo-inputs(dcore)is10.Weappliedcross-validationtoselecttheparam-\n",
      "etersforeachmethodtothedata.Figure1showsthatMKAthedata\n",
      "almostaswellastheFullGPdoes.Intermsoftheotherapproximatemethods,\n",
      "althoughtheirtothedataissmoother,thisistothedetrimentofcaptur-\n",
      "ingthelocalstructureoftheunderlyingdata,whichvMKA?sabilityto\n",
      "capturetheentirespectrumofthekernelmatrix,notjustitstopeigenvectors.\n",
      "Realdata.WetestedtheofGPregressiononreal-worlddatasets.The\n",
      "dataarenormalizedtomeanzeroandvarianceone.Werandomlyselected10%\n",
      "ofeachdatasettobeusedasatestset.Ontheother90%wedide-foldcross\n",
      "validationtolearnthelengthscaleandnoiseparameterforeachmethodand\n",
      "theregressionresultswereaveragedoverrepeatingthissettingetimes.All\n",
      "experimentswereranona3.4GHz8coremachinewith8GBofmemory.Two\n",
      "distinctPnerrormeasuresareusedtoassessperformance:(a)standardized\n",
      "meansquareerror(SMSE),n1t=1(?yt?2yt)P/???2,where???2isthe\n",
      "varianceoftestoutputs,and(2)meannegativelogprobability(MNLP)\n",
      "n1??2+log2?,eachofwhichcorrespondstothepredictivemeanandyt?\n",
      "yt)2/???2+log?t=1(?nvarianceinerrorassessment.FromTable1,weare\n",
      "competitiveinbotherrormeasureswhenthenumberofpseudo-inputs(dcore\n",
      ")issmall,whichrevealslow-rankmethods?inabilityincapturingthelocal\n",
      "structureofthedata.Wealsoillustratetheperformancesensitivitybyvarying\n",
      "thenumberofpseudo-inputsonselecteddatasets.InFigure2,fortheinterval\n",
      "ofpseudo-inputsconsidered,MKA?sperformanceisrobusttodcore,whilelow-\n",
      "rankbasedmethods?performancechangesrapidly,whichshowsMKA?sability\n",
      "toachievegoodregressionresultsevenwithacrucialcompressionlevel.The\n",
      "14\n",
      "\n",
      "SupplementaryMaterialgivesamoredetaileddiscussionofthedatasetsand\n",
      "experiments.\n",
      "6\n",
      "Conclusions\n",
      "Inthispaperwemadethecasethatwhetheralearningproblemislowrank\n",
      "ornotdependsonthenatureofthedataratherthanjustthespectralprop-\n",
      "ertiesofthekernelmatrixK.ThisiseasiesttoseeinthecaseofGaussian\n",
      "Processes,whichisthealgorithmthatwefocusedoninthispaper,butitis\n",
      "alsotruemoregenerally.MostexisitingsketchingalgorithmsusedinGPre-\n",
      "gressionforcelowrankstructureonK,eitherglobally,orattheblocklevel.\n",
      "Whenthenatureoftheproblemisindeedlowrank,thismightactuallyactas\n",
      "anadditionalregularizerandimproveperformance.Whenthedatadoesnot\n",
      "havelowrankstructure,however,lowrankapproximationswillfail.Inspired\n",
      "byrecentworkonmultiresolutionfactorizations,weproposedamulitresolution\n",
      "meta-algorithm,MKA,forapproximatingkernelmatrices,whichassumesthat\n",
      "theinteractionbetweendistantclustersislowrank,whileavoidingforcinga\n",
      "lowrankstructureofthedatalocally,atanyscale.Importantly,MKAallows\n",
      "fastdirectcalculationsoftheinverseofthekernelmatrixanditsdeterminant,\n",
      "whicharealmostalwaysthecomputationalbottlenecksinGPproblems.Ac-\n",
      "knowledgementsThisworkwascompletedinpartwithresourcesprovidedby\n",
      "theUniversityofChicagoResearchComputingCenter.Theauthorswishto\n",
      "thankMichaelSteinforhelpfulsuggestions.\n",
      "8\n",
      "2References\n",
      "[1]CarlEdwardRasmussenandChristopherK.I.Williams.GaussianPro-\n",
      "cessesforMachineLearning(AdaptiveComputationandMachineLearning).\n",
      "TheMITPress,2005.[2]MichaelL.Stein.StatisticalInterpolationofSpatial\n",
      "Data:SomeTheoryforKriging.Springer,1999.[3]ChristopherWilliamsand\n",
      "MatthiasSeeger.UsingtheNystr?omMethodtoSpeedUpKernelMachines.\n",
      "InAdvancesinNeuralInformationProcessingSystems13,2001.[4]SiSi,C\n",
      "Hsieh,andInderjitSDhillon.MemorytKernelApproximation.In\n",
      "ICML,2014.[5]AliRahimiandBenjaminRecht.Weightedsumsofrandom\n",
      "kitchensinks:Replacingminimizationwithrandomizationinlearning.NIPS,\n",
      "2008.[6]AlexJ.SmolaandBernhardSch?okopf.SparseGreedyMatrixAp-\n",
      "proximationforMachineLearning.InProceedingsofthe17thInternational\n",
      "ConferenceonMachineLearning,ICML,pages911?918,2000.[7]Charless\n",
      "Fowlkes,SergeBelongie,FanChung,andJitendraMalik.Spectralgrouping\n",
      "usingtheNystr?ommethod.IEEEtransactionsonpatternanalysisandma-\n",
      "chineintelligence,26(2):214?25,2004.[8]P.DrineasandM.W.Mahoney.On\n",
      "theNystr?ommethodforapproximatingaGrammatrixforimprovedkernel-\n",
      "basedlearning.JournalofMachineLearningResearch,6:2153?2175,2005.[9]\n",
      "RongJin,TianbaoYang,MehrdadMahdavi,Yu-FengLi,andZhi-HuaZhou.\n",
      "ImprovedBoundsfortheNystr?omMethodWithApplicationtoKernelClas-\n",
      "15\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IEEETrans.Inf.Theory,2013.[10]AlexGittensandMichaelW\n",
      "Mahoney.RevisitingtheNystr?ommethodforimprovedlarge-scalemachine\n",
      "learning.ICML,28:567?575,2013.[11]ShiliangSun,JingZhao,andJiang\n",
      "Zhu.AReviewofNystr?omMethodsforLarge-ScaleMachineLearning.Infor-\n",
      "mationFusion,26:36?48,2015.[12]SanjivKumar,MehryarMohri,andAmeet\n",
      "Talwalkar.EnsembleNystr?ommethod.InNIPS,2009.[13]ShusenWang.\n",
      "talgorithmsanderroranalysisforthemoNystr?ommethod.AIS-\n",
      "TATS,2014.[14]AmineAbou-RjeiliandGeorgeKarypis.Multilevelalgo-\n",
      "rithmsforpartitioningpower-lawgraphs.InProceedingsofthe20thInter-\n",
      "nationalConferenceonParallelandDistributedProcessing,2006.[15]Inder-\n",
      "jitSDhillon,YuqiangGuan,andBrianKulis.Weightedgraphcutswithout\n",
      "eigenvectorsamultilevelapproach.IEEETransactionsonPatternAnalysis\n",
      "andMachineIntelligence,29(11):1944?1957,2007.[16]BerkantSavas,Inderjit\n",
      "Dhillon,etal.ClusteredLow-RankApproximationofGraphsinInformation\n",
      "ScienceApplications.InProceedingsoftheSIAMInternationalConference\n",
      "onDataMining,2011.[17]RuoxiWang,YingzhouLi,MichaelWMahoney,\n",
      "andEricDarve.StructuredBlockBasisFactorizationforScalableKernelMa-\n",
      "trixEvaluation.arXivpreprintarXiv:1505.00398,2015.[18]YingyuLiang,\n",
      "Maria-FlorinaFBalcan,VandanaKanchanapally,andDavidWooIm-\n",
      "proveddistributedprincipalcomponentanalysis.InNIPS,pages3113?3121,\n",
      "2014.[19]YuchenZhang,JohnDuchi,andMartinWainwright.Divideand\n",
      "conquerkernelridgeregression.ConferenceonLearningTheory,30:1?26,2013.\n",
      "[20]WilliamKAllard,GuangliangChen,andMauroMaggioni.Multi-scalege-\n",
      "ometricmethodsfordatasetsII:Geometricmulti-resolutionanalysis.Applied\n",
      "andComputationalHarmonicAnalysis,2012.[21]WHackbusch.ASparse\n",
      "MatrixArithmeticBasedonH-Matrices.PartI:IntroductiontoH-Matrices.\n",
      "Computing,62:89?108,1999.[22]WolfgangHackbusch,BorisKhoromskij,and\n",
      "Stefana.Sauter.OnH2-Matrices.Lecturesonappliedmathematics,pages\n",
      "9?29,2000.[23]S.Chandrasekaran,M.Gu,andW.Lyons.AFastAdap-\n",
      "tiveSolverForHierarchicallySemi-separableRepresentations.Calcolo,42(3-\n",
      "4):171?185,2005.[24]L.GreengardandV.Rokhlin.AFastAlgorithmfor\n",
      "ParticleSimulations.J.Comput.Phys.,1987.[25]B?ormandJochen\n",
      "Garcke.ApproximatingGaussianProcesseswithH2Matrices.InECML.2007.\n",
      "[26]SivaramAmbikasaran,SivaramForeman-Mackey,LeslieGreengard,David\n",
      "W.Hogg,andMichaelO?Neil.FastDirectMethodsforGaussianProcesses.\n",
      "arXiv:1403.6015v2,April2015.[27]NazneenRajani,KateMcArdle,andInder-\n",
      "jitSDhillon.Parallelk-NearestNeighborGraphConstructionUsingTree-based\n",
      "DataStructures.In1stHighPerformanceGraphMiningworkshop,2015.[28]\n",
      "HuiZou,TrevorHastie,andRobertTibshirani.SparsePrincipalComponent\n",
      "Analysis.JournalofComputationalandGraphicalStatistics,15(2):265?286,\n",
      "2004.[29]Q.BerthetandP.Rigollet.ComplexityTheoreticLowerBoundsfor\n",
      "SparsePrincipalComponentDetection.J.Mach.Learn.Res.(COLT),30,\n",
      "1046-10662013.[30]VolodymyrKuleshov.Fastalgorithmsforsparseprinci-\n",
      "palcomponentanalysisbasedonrayleighquotientiteration.InICML,pages\n",
      "1418?1425,2013.[31]RisiKondor,NedelinaTeneva,andVikasGarg.Multires-\n",
      "olutionMatrixFactorization.InICML,2014.[32]NedelinaTeneva,PramodK\n",
      "16\n",
      "\n",
      "Murakarta,andRisiKondor.MultiresolutionMatrixCompression.InProceed-\n",
      "ingsofthe19thInternationalConferenceonIntelligenceandStatistics\n",
      "(AISTATS-16),2016.[33]JoaquinQui?noneroCandelaandCarlEdwardRas-\n",
      "mussen.Aunifyingviewofsparseapproximategaussianprocessregression.\n",
      "JournalofMachineLearningResearch,6:1939?1959,2005.[34]EdwardSnel-\n",
      "sonandZoubinGhahramani.SparseGaussianprocessesusingpseudo-inputs.\n",
      "NIPS,2005.[35]AndrewGordonWilsonandHannesNickisch.Kernelinter-\n",
      "polationforscalablestructuredgaussianprocesses(KISS-GP).InICML,Lille,\n",
      "France,6-11,pages1775?1784,2015.\n",
      "9\n",
      "17\n",
      "\n",
      "PP5504.pdf\n",
      "PP5504.pdf 14\n",
      "OntheStatisticalConsistencyofPlug-in\n",
      "forNon-decomposablePerformance\n",
      "Measures\n",
      "Authoredby:\n",
      "ShivaniAgarwal\n",
      "HarikrishnaNarasimhan\n",
      "RohitVaish\n",
      "Abstract\n",
      "Westudyconsistencypropertiesofalgorithmsfornon-decomposable\n",
      "performancemeasuresthatcannotbeexpressedasasumoflossesonin-\n",
      "dividualdatapoints,suchastheF-measureusedintextretrievalandsev-\n",
      "eralotherperformancemeasuresusedinclassimbalancedsettings.While\n",
      "therehasbeenmuchworkondesigningalgorithmsforsuchperformance\n",
      "measures,thereislimitedunderstandingofthetheoreticalpropertiesof\n",
      "thesealgorithms.Recently,Yeetal.(2012)showedconsistencyresults\n",
      "fortwoalgorithmsthatoptimizetheF-measure,buttheirresultsapply\n",
      "onlytoanidealizedsetting,wherepreciseknowledgeoftheunderlying\n",
      "probabilitydistribution(intheformofthe`true'posteriorclassprobabil-\n",
      "ity)isavailabletoalearningalgorithm.Inthiswork,weconsiderplug-in\n",
      "algorithmsthatlearnaerbyapplyinganempiricallydetermined\n",
      "thresholdtoasuitable`estimate'oftheclassprobability,andprovidea\n",
      "generalmethodologytoshowconsistencyofthesemethodsforanynon-\n",
      "decomposablemeasurethatcanbeexpressedasacontinuousfunctionof\n",
      "truepositiverate(TPR)andtruenegativerate(TNR),andforwhich\n",
      "theBayesoptimalistheclassprobabilityfunctionthresholded\n",
      "suitably.Weusethistemplatetoderiveconsistencyresultsforplug-in\n",
      "algorithmsfortheF-measureandforthegeometricmeanofTPRand\n",
      "precision;toourknowledge,thesearethesuchresultsforthesemea-\n",
      "sures.Inaddition,forcontinuousdistributions,weshowconsistencyof\n",
      "plug-inalgorithmsforanyperformancemeasurethatisacontinuousand\n",
      "monotonicallyincreasingfunctionofTPRandTNR.Experimentalresults\n",
      "ourtheoretical\n",
      "1PaperBody\n",
      "Inmanyreal-worldapplications,theperformancemeasureusedtoevaluatea\n",
      "learningmodelisnon-decomposableandcannotbeexpressedasasummation\n",
      "1\n",
      "\n",
      "orexpectationoflossesonindividualdatapoints;thisincludes,forexample,\n",
      "theF-measureusedininformationretrieval[1],andseveralcombinationsofthe\n",
      "truepositiverate(TPR)andtruenegativerate(TNR)usedinclassimbalanced\n",
      "settings[2?5](seeTable1).Whiletherehasbeenmuchworkin\n",
      "thelasttwodecadesindesigninglearningalgorithmsforsuchperformancemea-\n",
      "sures[6?14],ourunderstandingofthestatisticalconsistencyofthesemethods\n",
      "isratherlimited.Recently,Yeetal.(2012)showedconsistencyresultsfortwo\n",
      "algorithmsfortheF-measure[15]thatusethe?true?posteriorclassprobability\n",
      "tomakepredictionsoninstances.Theseresultsimplicitlyassumethatthegiven\n",
      "learningalgorithmhaspreciseknowledgeoftheunderlyingprobabilitydistri-\n",
      "bution(intheformofthetrueposteriorclassprobability);thisassumption\n",
      "doesnothoweverholdinmostreal-worldsettings.Inthispaper,weconsidera\n",
      "familyofmethodsthatconstructaplug-inclassibyapplyinganempirically\n",
      "determinedthresholdtoasuitable?estimate?oftheclassprobability(obtained\n",
      "usingamodellearnedfromasampledrawnfromtheunderlyingdistribution).\n",
      "Weprovideageneralmethod?\n",
      "Bothauthorscontributedequallytothispaper.\n",
      "1\n",
      "Table1:Performancemeasuresconsideredinourstudy.Here??(0,?)\n",
      "andp=P(y=1).?EachperformancemeasureherecanbeexpressedasPD\n",
      "[h]=?(TPRD[h],TNRD[h],p).Thelastcolumncontainstheassumptionon\n",
      "thedistributionDunderwhichtheplug-inalgorithmconsideredinthisworkis\n",
      "statisticallyconsistentw.r.t.aperformancemeasure(detailsinSections3and\n",
      "5).Ref.?(u,v,p)[17?19]u+v2\n",
      "MeasureAM(1-BER)\n",
      "(TPR+TNR)/2\n",
      "F?-measureG-Mean(GM)H-Mean(HM)\n",
      "?(1+?2)/Prec+?TPR?Prec?TPR?TNR\n",
      "112/TPR+TNR\n",
      "Q-Mean(QM)\n",
      "1?((1?TPR)2+(1?TNR)2)/2[5]\n",
      "G-TP/PR\n",
      "2\n",
      "1TPR\n",
      "[1,19][3][2,3][4]\n",
      "(1+?2)pup+?2(pu+(1?p)(1?v))q\n",
      "?\n",
      "pu2pu+(1?p)(1?v)\n",
      "uv\n",
      "2uvu+v\n",
      "1?\n",
      "(1?u)2+(1?v)22\n",
      "AssumptiononDAssumptionAAssumptionAAssumptionAAssumption\n",
      "BAssumptionBAssumptionB\n",
      "ologytoshowstatisticalconsistencyofthesemethods(underamildassump-\n",
      "tionontheunderlyingdistribution)foranyperformancemeasurethatcanbe\n",
      "2\n",
      "\n",
      "expressedasacontinuousfunctionoftheTPRandTNRandtheclasspropor-\n",
      "tion,andforwhichtheBayesoptimalistheclassprobabilityfunction\n",
      "thresholdedatasuitablepoint.Weuseourprooftemplatetoderiveconsistency\n",
      "resultsfortheF-measure(usingarecentresultby[15]ontheBayesoptimal\n",
      "forF-measure),andthegeometricmeanofTPRandprecision;to\n",
      "ourknowledge,thesearethesuchresultsfortheseperformancemeasures.\n",
      "Usingourtemplate,wealsoobtainarecentconsistencyresultbyMenonet\n",
      "al.[16]forthearithmeticmeanofTPRandTNR.Inaddition,weshowthat\n",
      "forcontinuousdistributions,theoptimalforanyperformancemeasure\n",
      "thatisacontinuousandmonotonicallyincreasingfunctionofTPRandTNR\n",
      "isnecessarilyoftherequisitethresholdedform,thusestablishingconsistencyof\n",
      "theplug-inalgorithmsforallsuchperformancemeasures.Experimentsonreal\n",
      "andsyntheticdataourtheoreticalandshowthattheplug-\n",
      "inmethodsconsideredherearecompetitivewiththestate-of-the-artSVMperf\n",
      "method[12]fornon-decomposablemeasures.RelatedWork.Muchofthework\n",
      "onnon-decomposableperformancemeasuresinbinarycsettingshas\n",
      "focusedontheF-measure;theseincludetheempiricalplug-inalgorithmconsid-\n",
      "eredhere[6],cost-weightedversionsofSVM[9],methodsthatoptimizeconvex\n",
      "andnon-convexapproximationstoF-measure[10?14],anddecision-theoretic\n",
      "methodsthatlearnaclassprobabilityestimateandcomputepredictionsthat\n",
      "maximizetheexpectedF-measureonatestset[7?9].Whiletherehasbeen\n",
      "considerableamountofworkonconsistencyofalgorithmsforunivariateperfor-\n",
      "mancemeasures[16,20?22],theoreticalresultsonnon-decomposablemeasures\n",
      "havebeenlimitedtocharacterizingtheBayesoptimalforF-measure\n",
      "[15,23,24],andsomeconsistencyresultsforF-measureforcertainidealizedver-\n",
      "sionsoftheempiricalplug-inanddecisiontheoreticmethodsthathaveaccess\n",
      "tothetrueclassprobability[15].Therehasalsobeensomeworkonalgorithms\n",
      "thatoptimizeF-measureinmulti-labelsettings[25,26]andcon-\n",
      "sistencyresultsforthesemethods[26,27],buttheseresultsdonotapplyto\n",
      "thebinarysettingthatweconsiderhere;inparticular,inabi-\n",
      "naryclassiationsetting,theF-measurethatoneseekstooptimizeisasingle\n",
      "numbercomputedovertheentiretrainingset,whileinamulti-labelsetting,\n",
      "thegoalistooptimizethemeanF-measurecomputedovermultiplelabelson\n",
      "individualinstances.Organization.WestartwithsomepreliminariesinSec-\n",
      "tion2.Section3presentsourmainresultonconsistencyofplug-inalgorithms\n",
      "fornon-decomposableperformancemeasuresthatarefunctionsofTPRand\n",
      "TNR.Section4containsapplicationofourprooftemplatetotheAM,F?and\n",
      "G-TP/PRmeasures,andSection5containsresultsundercontinuousdistribu-\n",
      "tionsforperformancemeasuresthataremonotonicinTPRandTNR.Section\n",
      "6describesourexperimentalresultsonrealandsyntheticdatasets.Proofsnot\n",
      "providedinthemaintextcanbefoundintheAppendix.\n",
      "2\n",
      "Preliminaries\n",
      "ProblemSetup.LetXbeanyinstancespace.GivenatrainingsampleS=n\n",
      "((x1,y1),...,(xn,yn))?(X?\n",
      "f\n",
      "?1\n",
      "g\n",
      "),ourgoalistolearnabinary\n",
      "bhS:X?\n",
      "f\n",
      "?1\n",
      "g\n",
      "tomakepredictionsfornewinstancesdrawnfromX.Assume\n",
      "3\n",
      "\n",
      "allexamples(bothtrainingandtest)aredrawniidaccordingtosomeunknown\n",
      "probabilitydistributionDonX?\n",
      "f\n",
      "?1\n",
      "g\n",
      ".Let?(x)=P(y=1|x)andp=P(y\n",
      "=1)(bothunderD).Wewillbeinterestedinsettingswheretheperformance\n",
      "ofbhSismeasuredviaanon-decomposableperformancemeasureP:\n",
      "f\n",
      "?1\n",
      "g\n",
      "X?\n",
      "R+,whichcannotbeexpressedasasumorexpectationoflossesonindividual\n",
      "examples.2\n",
      "Non-decomposableperformancemeasures.Letusthefollowing\n",
      "quantitiesassociatedwithabinaryh:X?\n",
      "f\n",
      "?1\n",
      "g\n",
      ":\n",
      "TruePositiveRate/RecallTPRD[h]=Ph(x)=1|y=1\n",
      "TrueNegativeRateTNRD[h]=Ph(x)=?1|y=?1\n",
      "pTPRD[h]PrecisionPrecD[h]=Py=1|h(x)=1=pTPRD[h]+(1?p)(1?TNR\n",
      ".D[h])Inthispaper,wewillconsidernon-decomposableperformancemeasures\n",
      "thatcanbeexpressedasafunctionoftheTPRandTNRandtheclasspropor-\n",
      "tionp.Sp,let?:[0,1]3?R+;thenthe??-performanceofhw.r.t.\n",
      "D,whichwewilldenoteasPD[h],willbeas:?PD[h]=?(TPRD[h],\n",
      "TNRD[h],p).Forexample,for?>0,theF?-measureofhcanbe\n",
      "throughthefunc(1+?2)pu,whichgivestion?F?:[0,1]3?R+givenby?F?\n",
      "(u,v,p)=p+?2(pu+(1?p)(1?v))\n",
      "F??212PD[h]=(1+?)/PrecD[h]+TPRD[h].Table1gives\n",
      "severalexamplesofnon-decomposableperformancemeasuresthatareusedin\n",
      "practice.Wewillalsoitusefultoconsiderempiricalverb?[h]:sionsof\n",
      "theseperformancemeasurescalculatedfromasampleS,whichwewilldenote\n",
      "asPSbS?[h]=?(TPRdS[h],TNRdS[h],pbS),P(1)PnwherepbS=n1\n",
      "i=11(yi=1)isanempiricalestimateofp,andnnXX1dS[h]=1dS[h]\n",
      "=TPR1(h(xi)=1,yi=1);TNR1(h(xi)=?1,yi=?1)pbSni=1(1?pbS\n",
      ")ni=1aretheempiricalTPRandTNRrespectively.1??-consistency.Wewill\n",
      "beinterestedintheoptimumvalueofPDoverall?,?PD=\n",
      "suph:X?\n",
      "f\n",
      "?1\n",
      "g\n",
      "?PD[h].\n",
      "Inparticular,onecanthe?-regretofahas:?,??regret??\n",
      "PD[h].D[h]=PDAlearningalgorithmisthensaidtobe?-consistentifthe\n",
      "?-regretofthebhSoutputbythealgorithmonseeingtrainingsample\n",
      "Sconvergesinprobabilityto0:2Pregret?[bhS]??0.D\n",
      "ClassofThresholdWewillitusefultoforanyfunction\n",
      "f:X?[0,1],thesetofobtainedbyassigningathresholdtof:Tf\n",
      "=\n",
      "f\n",
      "sign?(f?t)|t?[0,1]\n",
      "g\n",
      ",wheresign(u)=1ifu>0and?1otherwise.\n",
      "Foragivenf,weshallalsothethresholdscorrespondingtomaximum\n",
      "populationandempiricalmeasuresrespectively(whentheyexist)as:b?[sign\n",
      "?(f?t)].t??argmaxP?[sign?(f?t)];btS,f,??argmaxPD,f,?\n",
      "D\n",
      "S\n",
      "t?[0,1]\n",
      "t?[0,1]\n",
      "Plug-inAlgorithmsandResultofYeetal.(2012).Inthiswork,weconsider\n",
      "afamilyofplug-inalgorithms,whichdividetheinputsampleSintosamples\n",
      "(S1,S2),useasuitableclassprobabilityestimation(CPE)algorithmtolearn\n",
      "4\n",
      "\n",
      "aclassprobabilityestimator?bS1:X?[0,1]fromS1,andoutputab\n",
      "hS(x)=sign(b?S1(x)?btS2,b?S1,?),wherebtS2,b?S1,?isathreshold\n",
      "thatmaximizestheempiricalperformancemeasureonS2(seeAlgorithm1).We\n",
      "notethatthisapproachistfromtheidealizedplug-inmethodanalyzed\n",
      "byYeetal.(2012)inthecontextofF-measureoptimization,wherea\n",
      "islearnedbyassigninganempiricalthresholdtothe?true?classprobability\n",
      "function?[15];theconsistencyresultthereinisusefulonlyifpreciseknowledge\n",
      "of?isavailabletoalearningalgorithm,whichisnotthecaseinmostpractical\n",
      "settings.L1-consistencyofaCPEalgorithm.LetCbeaCPEalgorithm,and\n",
      "foranysampleS,denoteP\n",
      "?bS=C(S).WewillsayCisL1-consistentw.r.t.adistributionDifEx\n",
      "?bS(x)??(x)??0.1\n",
      "Inthesettingconsideredhere,thegoalistomaximizea(non-decomposable)\n",
      "functionofexpectations;wenotethatthisistfromthedecision-theoretic\n",
      "settingin[15],whereonelooksattheexpectationofanon-decomposableper-\n",
      "formancemeasureonnexamples,andseekstomaximizeitslimitingvalueasn\n",
      "??.P2Wesay?(S)convergesinprobabilitytoa?R,writtenas?(S)??a,\n",
      "if?>0,PS?Dn(|?(S)?a|?)?0asn??.\n",
      "3\n",
      "Algorithm1Plug-inwithEmpiricalThresholdforPerformanceMeasureP\n",
      "?:2X?R+1:Input:S=((x1,y1),...,(xn,yn))?(X?\n",
      "f\n",
      "?1\n",
      "g\n",
      ")n2:\n",
      "Parameter:??(0,1)3:LetS1=((x1,y1),...,(xn1,yn1)),S2=((xn1\n",
      "+1,yn1+1),...,(xn,yn)),wheren1=dn?enX4:Learn?bS1=C(S1\n",
      "),whereC:??n=1(X?\n",
      "f\n",
      "?1\n",
      "g\n",
      ")?[0,1]isasuitableCPEalgorithmb?[sign?\n",
      "(b5:btS,b?,??argmaxP?S?t)]2\n",
      "S1\n",
      "t?[0,1]\n",
      "S2\n",
      "1\n",
      "6:Output:bhS(x)=sign(b?S1(x)?btS2,b?S1,?)\n",
      "AGenericProofTemplatefor?-consistencyofPlug-inAlgorithms\n",
      "3\n",
      "Wenowgiveageneralresultforshowingconsistencyoftheplug-inmethodin\n",
      "Algorithm1foranyperformancemeasurethatcanbeexpressedasacontinuous\n",
      "functionofTPRandTNR,andforwhichtheBayesoptimalisobtained\n",
      "bysuitablythresholdingtheclassprobabilityfunction.AssumptionA.Wewill\n",
      "saythataprobabilitydistributionDonX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "AssumptionAw.r.t.\n",
      "?ift?D,?,?existsandisin(0,1),andthecumulativedistributionfunctionsof\n",
      "therandomvariable?(x)conditionedony=1andony=?1,P(?(x)?z|y\n",
      "=1)andP(?(x)?z|y=?1),arecontinuousatz=t?D,?,?.3Notethatthis\n",
      "assumptionholdsforanydistributionDforwhich?(x)conditionedony=1and\n",
      "ony=?1iscontinuous,andalsoforanyDforwhich?(x)conditionedony=1\n",
      "andony=?1ismixed,providedtheoptimumthresholdt?D,?,?forP?exists\n",
      "andisnotapointofdiscontinuity.Undertheaboveassumption,andassuming\n",
      "thattheCPEalgorithmusedinAlgorithm1isL1consistent(whichholdsfor\n",
      "anyalgorithmthatusesaregularizedempiricalriskminimizationofaproper\n",
      "5\n",
      "\n",
      "loss[16,28]),wehaveourmainconsistencyresult.Theorem1(?-consistency\n",
      "ofAlgorithm1).Let?:[0,1]3?R+becontinuousineachargument.Let\n",
      "DbeaprobabilitydistributiononX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatAssumptionAw.r.t.\n",
      "?,andforwhichtheBayesoptimalcisoftheformh?,?(x)=sign?\n",
      "(?(x)?t?D,?,?).IftheCPEalgorithmCinAlgorithm1isL1-consistent,\n",
      "thenAlgorithm1is?-consistentw.r.t.D.Beforeweprovetheabovetheorem,\n",
      "wewillitusefultostatethefollowinglemmas.Inourlemma,westate\n",
      "thattheTPRandTNRofaconstructedbythresholdingasuitable\n",
      "classprobabilityestimateatac?(0,1)convergerespectivelytotheTPR\n",
      "andTNRoftheobtainedbythresholdingthetrueclassprobability\n",
      "function?atc.Lemma2(ConvergenceofTPRandTNRforthreshold).\n",
      "LetDbeadistributiononX?\n",
      "f\n",
      "?1\n",
      "g\n",
      ".Let?bS:X?[0,1]begeneratedbyan\n",
      "L1-consistentCPEalgorithm.Letc?(0,1)beanaprioriconstantsuch\n",
      "thatthecumulativedistributionfunctionsP(?(x)?z|y=1)andP(?(x)?z\n",
      "|y=?1)arecontinuousatz=c.WethenhavePTPRD[sign?(b?S?c)]\n",
      "??TPRD[sign?(??c)];P\n",
      "TNRD[sign?(b?S?c)]??TNRD[sign?(??c)].Asacorollaryto\n",
      "theabovelemma,wehaveasimilarresultforP?.Lemma3(Convergenceof\n",
      "P?forthreshold).Let?:[0,1]3?R+becontinuousineachargument.\n",
      "UnderthestatementofLemma2,wehaveP\n",
      "??PD[sign?(b?S?c)]??PD[sign?(??c)].Wenextstatearesult\n",
      "showingconvergenceoftheempiricalperformancemeasuretoitspopulation\n",
      "valueforaandauniformconvergenceresultoveraclassof\n",
      "thresholdedLemma4(ConcentrationresultforP?).Let?:[0,1]3\n",
      "?R+becontinuousineachargument.Thenforanyh:X?\n",
      "f\n",
      "?1\n",
      "g\n",
      ",and>\n",
      "0,\n",
      "?b?[h]??0asn??.PS?DnPD[h]?PS3\n",
      "Forsimplicity,weassumethatt?D,?,?isin(0,1);ourresultseasilyextend\n",
      "tothecasewhent?D,?,??[0,1].\n",
      "4\n",
      "Lemma5(UniformconvergenceofP?overthresholdLet?:[0,\n",
      "1]3?R+becontinuousineachargument.Foranyf:X?[0,1]and>0,!\n",
      "o[n\n",
      "?bS?[?]??0asn??.[?]?PPS?DnPD??Tf\n",
      "Wearenowreadytoproveourmaintheorem.?ProofofTheorem1.Recall\n",
      "t?D,?,??argmaxPD[sign?(??t)]existsbyAssumptionA.Inthet?[0,1]\n",
      "following,weshalluset?intheplaceoft?D,?,?andbtS2,S1intheplace\n",
      "ofbtS2,b?S1,?.Wehaveregret?D[hS]\n",
      "=\n",
      "regret??S1?btS2,S1)]D[sign?(b?,??PD?PD[sign?(b?S1?b\n",
      "tS2,S1)]\n",
      "=\n",
      "??PD[sign?(??t?)]?PD[sign?(b?S1?btS2,S1)],\n",
      "=\n",
      "whichfollowsfromtheassumptionontheBayesoptimalforP?.\n",
      "AddingandsubtractingempiricalandpopulationversionsofP?computedon\n",
      "6\n",
      "\n",
      "certain??=PD[sign?(??t?)]?PD[sign?(b?S1?t?)]\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "regret??S1?btS2,S1)]D[sign?(b\n",
      "term1\n",
      "+\n",
      "?PD[sign\n",
      "|\n",
      "bS?[sign?(b?(b?S1?t?)]?P?S1?btS2,S1)]\n",
      "f\n",
      "z2\n",
      "g\n",
      "term2\n",
      "?bS?[sign?(b+P?S1?btS2,S1)]?PD[sign?(b?S1?btS2,S1)].\n",
      "f\n",
      "z\n",
      "g\n",
      "|2term3\n",
      "Wenowshowconvergenceforeachoftheaboveterms.ApplyingLemma\n",
      "3withc=t?(byPAssumptionA,t??(0,1)andthenecessary\n",
      "continuityassumption),wehaveterm1??0.bForterm2,fromthe\n",
      "ofthresholdtS2,S1(seeAlgorithm1),wehaveterm2Thenforany>0,\n",
      "PS?Dnterm2?\n",
      "==?\n",
      "?\n",
      "?b?[sign?(bPD[sign?(b?S1?t?)]?P?S1?t?)].S2\n",
      "(2)\n",
      "PS1?Dn1,S2?Dn?n1term2?hiES1PS2|S1term2?h\n",
      "i\n",
      "??bS?[sign?(bES1PS2|S1PD[sign?(b?S1?t?)]?P??\n",
      "?t)]S12\n",
      "?0asn??,wherethethirdstepfollowsfromEq.(2),andthelaststep\n",
      "followsbyapplying,foraS1,theconcentrationresultinLemma4with\n",
      "h=sign?(b?S1?t?)(givencontinuityof?).Finally,forterm3,wehave\n",
      "forany>0,h\n",
      "i\n",
      "?bS?[sign?(bbbPSterm3?=ES1PS2|S1P??t)]?P[sign?(b\n",
      "??t)]?\n",
      "SS,SSS,SD1211212\"!#o[n\n",
      "b?[?]?P?[?]?P?ES1PS|SSD2\n",
      "1\n",
      "2\n",
      "??T?bS\n",
      "1\n",
      "?0asn??,wherethelaststepfollowsbyapplyingtheuniformconvergence\n",
      "resultinLemma5overtheclassofthresholdedT?bS1=\n",
      "f\n",
      "sign?(b\n",
      "?S1?t)|t?[0,1]\n",
      "g\n",
      "(foraS1).\n",
      "4\n",
      "ConsistencyofPlug-inAlgorithmsforAM,F?,andG-TP/PR\n",
      "WenowusetheresultinTheorem1toestablishconsistencyoftheplug-in\n",
      "algorithmsforthearithmeticmeanofTPRandTNR,theF?-measure,andthe\n",
      "geometricmeanofTPRandprecision.5\n",
      "4.1\n",
      "ConsistencyforAM-measure\n",
      "7\n",
      "\n",
      "ThearithmeticmeanofTPRandTNR(AM)oroneminusthebalancederror\n",
      "rate(BER)isawidelyusedperformancemeasureinclassimbalancedbinary\n",
      "settings[17?19]:TPRD[h]+TNRD[h].2Itcanbeshownthat\n",
      "BayesoptimalfortheAM-measureisoftheformhAM,?(x)=sign?\n",
      "(?(x)?p)(seeforexample[16]),andthatthethresholdchosenbytheplugin\n",
      "methodinAlgorithm1fortheAM-measureisanempiricalestimateofp.In\n",
      "recentwork,Menonetal.showthatthisplug-inmethodisconsistentw.r.t.the\n",
      "AM-measure[16];theirproofmakesuseofadecompositionoftheAM-measure\n",
      "intermsofacertaincost-sensitiveerrorandaresultof[22]onregretbounds\n",
      "forcost-sensitiveWenowuseourresultinTheorem1togivean\n",
      "alternaterouteforshowingAM-consistencyofthisplug-inmethod.4Theorem\n",
      "6(ConsistencyofAlgorithm1w.r.t.AM-measure).Let?=?AM.LetDbea\n",
      "distributiononX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatsatisesAssumptionAw.r.t.?AM.IftheCPE\n",
      "algorithmCinAlgorithm1isL1-consistent,thenAlgorithm1isAM-consistent\n",
      "w.r.t.D.AMPD[h]=\n",
      "Proof.WeapplyTheorem1notingthat?AM(u,v,p)=(u+v)/2iscon-\n",
      "tinuousinallitsarguments,andthattheBayesoptimalforPAMis\n",
      "oftherequisitethresholdedform.4.2\n",
      "ConsistencyforF?-measure\n",
      "TheF?-measureorthe(weighted)harmonicmeanofTPRandprecisionis\n",
      "apopularperformancemeasureusedininformationretrieval[1]:F\n",
      "PD?[h]=\n",
      "(1+?2)pTPRD[h](1+?2)TPRD[h]PrecD[h],=22?TPRD[h]+\n",
      "PrecD[h]p+?pTPRD[h]+(1?p)(1?TNRD[h])\n",
      "where??(0,1)controlsthebetweenTPRandprecision.Ina\n",
      "recentwork,Yeetal.[15]showthattheoptimalfortheF?-measureis\n",
      "theclassprobability?thresholdedsuitably.Lemma7(Optimalityofthreshold\n",
      "forF?-measure;Yeetal.(2012)[15]).ForanydistributionDoverX\n",
      "?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatAssumptionAw.r.t.?,theBayesoptimalforP\n",
      "F?isoftheformhF?,?(x)=sign?(?(x)?t?D,?,F?).Asnotedearlier,the\n",
      "authorsin[15]showthatanidealizedplug-inmethodthatappliesanempirically\n",
      "determinedthresholdtothe?true?classprobability?isconsistentw.r.t.theF?\n",
      "-measure.Thisresultishoweverusefulonlywhenthe?true?classprobabilityis\n",
      "availabletoalearningalgorithm,whichisnotthecaseinmostpracticalsettings.\n",
      "Ontheotherhand,theplug-inmethodconsideredinourworkconstructsa\n",
      "byassigninganempiricalthresholdtoasuitable?estimate?ofthe\n",
      "classprobability.UsingTheorem1,wenowshowthatthismethodisconsistent\n",
      "w.r.t.theF?-measure.Theorem8(ConsistencyofAlgorithm1w.r.t.F?-\n",
      "measure).Let?=?F?inAlgorithm1.LetDbeadistributiononX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatAssumptionAw.r.t.?F?.IftheCPEalgorithmCinAlgorithm\n",
      "1isL1-consistent,thenAlgorithm1isF?-consistentw.r.t.D.2\n",
      "(1+?)puiscontinuousineachProof.WeapplyTheorem1notingthat?F?\n",
      "(u,v,p)=p+?2(pu+(1?p)(1?v))F?argument,andthat(byLemma7)the\n",
      "BayesoptimalforPisoftherequisiteform.\n",
      "4.3\n",
      "ConsistencyforG-TP/PR\n",
      "8\n",
      "\n",
      "ThegeometricmeanofTPRandprecision(G-TP/PR)isanotherperfor-\n",
      "mancemeasureproposedforclassimbalancedproblems[3]:sp\n",
      "pTPRD[h]2G-TP/PRPD[h]=TPRD[h]PrecD[h]=.pTPRD[h]+(1?\n",
      "p)(1?TNRD[h])4Notethattheplug-inthresholdchosenforthe\n",
      "AM-measureisthesameindependentoftheclassprobabilityestimateused;our\n",
      "consistencyresultswillthereforeapplyinthiscaseevenifoneuses,asin[16],\n",
      "thesamesampleforbothlearningaclassprobabilityestimate,andestimating\n",
      "theplug-inthreshold.\n",
      "6\n",
      "WeshowthattheoptimalforG-TP/PRisobtainedbythresh-\n",
      "oldingtheclassprobabilityfunction?atasuitablepoint;ourproofusesa\n",
      "techniquesimilartotheonefortheF?-measurein[15].Lemma9(Optimality\n",
      "ofthresholdforG-TP/PR).ForanydistributionDonX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "that\n",
      "AssumptionAw.r.t.?,theBayesoptimalforPG-TP/PR\n",
      "isoftheformhG-TP/PR,?(x)=sign(?(x)?t?D,?,G-TP/PR).Theorem10\n",
      "(ConsistencyofAlgorithm1w.r.t.G-TP/PR).Let?=?G-TP/PR.LetD\n",
      "beadistributiononX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatAssumptionAw.r.t.?G-TP/PR.\n",
      "IftheCPEalgorithmCinAlgorithm1isL1-consistent,thenAlgorithm1is\n",
      "G-TP/PR-consistentw.r.t.D.qpu2Proof.WeapplyTheorem1notingthat\n",
      "?G-TP/PR(u,v,p)=pu+(1?p)(1?v)iscontinuousineachargument,andthat\n",
      "(byLemma9)theBayesoptimalforPG-TP/PRisoftherequisite\n",
      "form.\n",
      "5\n",
      "ConsistencyofPlug-inAlgorithmsforNon-decomposablePerformanceMea-\n",
      "suresthatareMonotonicinTPRandTNR\n",
      "Theconsistencyresultsseensofarapplytoanydistributionthata\n",
      "mildcontinuityconditionattheoptimalthresholdforaperformancemeasure,\n",
      "andhavecruciallyreliedonthespfunctionalformofthemeasure.Inthis\n",
      "section,weshallseethatunderastrictercontinuityassumptiononthedistribu-\n",
      "tion,theempiricalplug-inalgorithmcanbeshowntobeconsistentw.r.t.any\n",
      "performancemeasurethatisacontinuousandmonotonicallyincreasingfunction\n",
      "ofTPRandTNR.AssumptionB.WewillsaythataprobabilitydistributionD\n",
      "onX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "AssumptionBw.r.t.?ift?D,?,?existsandisin(0,1),and\n",
      "thecumulativedistributionfunctionoftherandomvariable?(x),P(?(x)?z),\n",
      "iscontinuousatallz?(0,1).Distributionsthatsatisfytheaboveassumption\n",
      "alsosatisfyAssumptionA.Weshowthatunderthisassumption,theoptimal\n",
      "foranyperformancemeasurethatismonotonicallyincreasinginTPR\n",
      "andTNRisobtainedbythresholding?,andthisholdsirrespectiveofthespe-\n",
      "functionalformofthemeasure.AnapplicationofTheorem1thengives\n",
      "usthedesiredconsistencyresult.Lemma11(Optimalityofthreshold\n",
      "formonotonic?underdistributionalassumption).Let?:[0,1]3?R+be\n",
      "monotonicallyincreasinginitstwoarguments.Thenforanydistribution\n",
      "DonX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatAssumptionB,theBayesoptimalforP\n",
      "?isoftheformh?,?(x)=sign(?(x)?t?D,?,?).Theorem12(Consistencyof\n",
      "Algorithm1formonotonic?underdistributionalassumption).Let?:[0,1]3\n",
      "?R+becontinuousineachargument,andmonotonicallyincreasinginits\n",
      "9\n",
      "\n",
      "twoarguments.LetDbeadistributiononX?\n",
      "f\n",
      "?1\n",
      "g\n",
      "thatAssumption\n",
      "B.IftheCPEalgorithmCinAlgorithm1isL1-consistent,thenAlgorithm1\n",
      "is?-consistentw.r.t.D.Proof.WeapplyTheorem1byusingthecontinuityas-\n",
      "sumptionon?,andnotingthat,byLemma11andmonotonicityof?,theBayes\n",
      "optimalforP?isoftherequisiteform.Theaboveresultappliesto\n",
      "allperformancemeasureslistedinTable1,andinparticular,tothegeometric,\n",
      "harmonic,andquadraticmeansofTPRandTNR[2?5],forwhichtheBayes\n",
      "optimalneednotbeoftherequisitethresholdedformforageneral\n",
      "distribution(seeAppendixC).\n",
      "6\n",
      "Experiments\n",
      "Weperformedtwotypesofexperiments.Theinvolvedsyntheticdata,\n",
      "wherewedemonstratediminishingregretoftheplug-inmethodinAlgorithm\n",
      "1withgrowingsamplesizefortperformancemeasures;sincethedata\n",
      "isgeneratedfromaknowndistribution,exactcalculationofregretispossible\n",
      "here.Thesecondinvolvedrealdata,whereweshowthattheplug-inalgorithmis\n",
      "competitivewiththestate-of-the-artSVMperfalgorithmfornon-decomposable\n",
      "measures(SVMPerf)[12];wealsoincludeforcomparisonaplug-inmethodwith\n",
      "athresholdof0.5(Plug-in(0-1)).Weconsiderthreeperformancemeasures\n",
      "here:F1-measure,G-TP/PRandG-Mean(seeTable1).Syntheticdata.We\n",
      "generateddatafromaknowndistribution(classconditionalsaremultivariate\n",
      "Gaussianswithmixingratiopandequalcovariancematrices)forwhichthe\n",
      "optimalfor7\n",
      "F1?measure\n",
      "0.05\n",
      "2\n",
      "3\n",
      "0.150.10.05\n",
      "4\n",
      "0.060.040.02\n",
      "0\n",
      "1010No.oftrainingexamples\n",
      "Plug?in(GM)SVMPerf(GM)Plug?in(0?1)\n",
      "0.08GMRegret\n",
      "0.1\n",
      "10\n",
      "Plug?in(G?TP/PR)SVMPerf(G?TP/PR)Plug?in(0?1)\n",
      "0.2G?TP/PRRegret\n",
      "F1Regret\n",
      "Plug?in(F1)SVMPerf(F1)Plug?in(0?1)\n",
      "0.15\n",
      "0\n",
      "G?Mean\n",
      "G?TP/PR0.1\n",
      "0.2\n",
      "2\n",
      "10\n",
      "\n",
      "10\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "10\n",
      "1010No.oftrainingexamples\n",
      "3\n",
      "4\n",
      "1010No.oftrainingexamples\n",
      "Figure1:Experimentsonsyntheticdatawithp=0.5:regretasafunction\n",
      "ofnumberoftrainingexamplesusingvariousmethodsfortheF1,G-TP/PR\n",
      "andG-meanperformancemeasures.F1?measure0.4\n",
      "0.20.10\n",
      "2\n",
      "10\n",
      "3\n",
      "0.3\n",
      "1010No.oftrainingexamples\n",
      "Plug?in(GM)SVMPerf(GM)Plug?in(0?1)\n",
      "0.8\n",
      "0.20.10\n",
      "4\n",
      "G?Mean\n",
      "Plug?in(G?TP/PR)SVMPerf(G?TP/PR)Plug?in(0?1)\n",
      "GMRegret\n",
      "0.3\n",
      "G?TP/PRRegret\n",
      "0.4F1Regret\n",
      "G?TP/PR\n",
      "Plug?in(F1)SVMPerf(F1)Plug?in(0?1)\n",
      "0.60.40.2\n",
      "2\n",
      "10\n",
      "3\n",
      "4\n",
      "1010No.oftrainingexamples\n",
      "0\n",
      "2\n",
      "10\n",
      "3\n",
      "4\n",
      "1010No.oftrainingexamples\n",
      "0\n",
      "F1\n",
      "Emp.Plug?inSVMPerfPlug?in(0?1)G?TP/PRG?Mean\n",
      "11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0\n",
      "F1\n",
      "Emp.Plug?inSVMPerfPlug?in(0?1)G?TP/PRG?Mean\n",
      "nursery(N=12960,d=27,p=0.025)1\n",
      "0.5\n",
      "0\n",
      "F1\n",
      "Emp.Plug?inSVMPerfPlug?in(0?1)G?TP/PRG?Mean\n",
      "pendigits(N=10992,d=17,p=0.096)1\n",
      "Performanceontestset\n",
      "0.5\n",
      "chemo(N=2111,d=1021,p=0.024)1\n",
      "Performanceontestset\n",
      "car(N=1728,d=21,p=0.038)1\n",
      "Performanceontestset\n",
      "Performanceontestset\n",
      "Figure2:Experimentsonsyntheticdatawithp=0.1:regretasafunction\n",
      "ofnumberoftrainingexamplesusingvariousmethodsfortheF1,G-TP/PR\n",
      "andG-Meanperformancemeasures.\n",
      "0.5\n",
      "0\n",
      "F1\n",
      "Emp.Plug?inSVMPerfPlug?in(0?1)G?TP/PRG?Mean\n",
      "Figure3:Experimentsonrealdata:resultsforvariousmethods(usinglinear\n",
      "models)onfourdatasetsintermsofF1,G-TP/PRandG-Meanperformance\n",
      "measures.HereN,d,prefertothenumberofinstances,numberoffeatures\n",
      "andfractionofpositivesinthedatasetrespectively.eachperformancemea-\n",
      "sureconsideredhereislinear,makingitttolearnalinearmodel;the\n",
      "distributionAssumptionBw.r.t.eachperformancemeasure.Weused\n",
      "regularizedlogisticregressionastheCPEmethodinAlgorithm1inorderto\n",
      "satisfytheL1-consistencyconditioninTheorem1(seeAppendixA.1andA.4\n",
      "fordetails).TheexperimentalresultsareshowninFigures1and2forp=\n",
      "0.5andp=0.1respectively.Ineachcase,theregretfortheempiricalplug-\n",
      "inmethod(Plug-in(F1),Plug-in(G-TP/PR)andPlug-in(GM))goestozero\n",
      "withincreasingtrainingsetsize,validatingourconsistencyresults;SVMperf\n",
      "failstoexhibitdiminishingregretforp=0.1;andasexpected,Plug-in(0-1),\n",
      "withitsapriorithreshold,failstobeconsistentinmostcases.Realdata.\n",
      "Weranthethreealgorithmsdescribedearlieroverdatasetsdrawnfromthe\n",
      "UCIMLrepository[29]andacheminformaticsdatasetobtainedfrom[30],and\n",
      "reporttheirperformanceonseparatelyheldtestsets.Figure3containsresults\n",
      "forfourdatasetsaveragedover10randomtraintestsplitsoftheoriginaldata.\n",
      "(SeeAppendixA.2fordetailsandA.3foradditionalresults).Clearly,inmost\n",
      "cases,theempiricalplug-inmethodperformscomparabletoSVMperfandout-\n",
      "performsthePlug-in(0-1)method.Moreover,theempiricalplug-inwasfound\n",
      "torunfasterthanSVMperf.\n",
      "12\n",
      "\n",
      "7\n",
      "Conclusions\n",
      "Wehavepresentedageneralmethodforprovingconsistencyofplug-inalgo-\n",
      "rithmsthatassignanempiricalthresholdtoasuitableclassprobabilityestimate\n",
      "foravarietyofnon-decomposableperformancemeasuresforbinary\n",
      "thatcanbeexpressedasacontinuousfunctionofTPRandTNR,andforwhich\n",
      "theBayesoptimalistheclassprobabilityfunctionthresholdedsuit-\n",
      "ably.WeuseourtemplatetoshowconsistencyfortheAM,F?andG-TP/PR\n",
      "measures,andunderacontinuousdistribution,foranyperformancemeasure\n",
      "thatiscontinuousandmonotonicinTPRandTNR.Ourexperimentssuggest\n",
      "thatthesealgorithmsarecompetitivewiththeSVMperfmethod.Acknowledg-\n",
      "mentsHNthankssupportfromaGoogleIndiaPhDFellowship.SAgratefully\n",
      "acknowledgessupportfromDST,Indo-USScienceandTechnologyForum,and\n",
      "anunrestrictedgiftfromYahoo.8\n",
      "2References\n",
      "[1]C.D.Manning,P.Raghavan,andH.Sch?utze.IntroductiontoInfor-\n",
      "mationRetrieval.CambridgeUniversityPress,2008.[2]M.KubatandS.\n",
      "Matwin.Addressingthecurseofimbalancedtrainingsets:One-sidedselection.\n",
      "InICML,1997.[3]S.Daskalaki,I.Kopanas,andN.Avouris.Evaluationofclas-\n",
      "foranunevenclassdistributionproblem.AppliedIntelligence,\n",
      "20:381?417,2006.[4]K.Kennedy,B.M.Namee,andS.J.Delany.Learning\n",
      "withoutdefault:astudyofone-classandthelow-defaultportfolio\n",
      "problem.InICAICS,2009.[5]S.Lawrence,I.Burns,A.Back,A-C.Tsoi,\n",
      "andC.L.Giles.Neuralnetworkandpriorclassprobabilities.In\n",
      "NeuralNetworks:TricksoftheTrade,pages1524:299?313.1998.[6]Y.Yang.\n",
      "Astudyofthresholdingstrategiesfortextcategorization.InSIGIR,2001.[7]\n",
      "D.D.Lewis.Evaluatingandoptimizingautonomoustextsystems.\n",
      "InSIGIR,1995.[8]K.M.A.Chai.ExpectationofF-measures:Tractableexact\n",
      "computationandsomeempiricalobservationsofitsproperties.InSIGIR,2005.\n",
      "[9]D.R.Musicant,V.Kumar,andA.Ozgur.OptimizingF-measurewithsup-\n",
      "portvectormachines.InFLAIRS,2003.[10]S.Gao,W.Wu,C-H.Lee,and\n",
      "T-S.Chua.Amaximallearningapproachtotextcategorization.\n",
      "InSIGIR,2003.[11]M.Jansche.MaximumexpectedF-measuretrainingof\n",
      "logisticregressionmodels.InHLT,2005.[12]T.Joachims.Asupportvector\n",
      "methodformultivariateperformancemeasures.InICML,2005.[13]Z.Liu,\n",
      "M.Tan,andF.Jiang.RegularizedF-measuremaximizationforfeatureselec-\n",
      "tionandclasscation.BioMedResearchInternational,2009,2009.[14]P.M.\n",
      "Chinta,P.Balamurugan,S.Shevade,andM.N.Murty.OptimizingF-measure\n",
      "withnon-convexlossandsparselinearInIJCNN,2013.[15]N.Ye,\n",
      "K.M.A.Chai,W.S.Lee,andH.L.Chieu.OptimizingF-measures:Ataleof\n",
      "twoapproaches.InICML,2012.[16]A.K.Menon,H.Narasimhan,S.Agarwal,\n",
      "andS.Chawla.Onthestatisticalconsistencyofalgorithmsforbinaryclassi-\n",
      "underclassimbalance.InICML,2013.[17]J.Cheng,C.Hatzis,H.\n",
      "13\n",
      "\n",
      "Hayashi,M-A.Krogel,S.Morishita,D.Page,andJ.Sese.KDDCup2001re-\n",
      "port.ACMSIGKDDExplorationsNewsletter,3(2):47?64,2002.[18]R.Powers,\n",
      "M.Goldszmidt,andI.Cohen.Shorttermperformanceforecastinginenterprise\n",
      "systems.InKDD,2005.[19]Q.Gu,L.Zhu,andZ.Cai.Evaluationmeasures\n",
      "oftheperformanceofimbalanceddatasets.InComputational\n",
      "IntelligenceandIntelligentSystems,volume51,pages461?471.2009.[20]T.\n",
      "Zhang.Statisticalbehaviourandconsistencyofmethodsbased\n",
      "onconvexriskminimization.AnnalsofMathematicalStatistics,32:56?134,\n",
      "2004.[21]P.L.Bartlett,M.I.Jordan,andJ.D.Convexity,clas-\n",
      "andriskbounds.JournaloftheAmericanStatisticalAssociation,\n",
      "101(473):138?156,2006.[22]C.Scott.Calibratedasymmetricsurrogatelosses.\n",
      "ElectronicJournalofStatistics,6:958?992,2012.[23]M.Zhao,N.Edakunni,\n",
      "A.Pocock,andG.Brown.BeyondFano?sinequality:Boundsontheoptimal\n",
      "F-score,BER,andcost-sensitiveriskandtheirimplications.JournalofMachine\n",
      "LearningResearch,14(1):1033?1090,2013.[24]Z.C.Lipton,C.Elkan,andB.\n",
      "Naryanaswamy.OptimalthresholdingoftomaximizeF1measure.In\n",
      "ECML/PKDD,2014.[25]J.PettersonandT.Caetano.Reversemulti-label\n",
      "learning.InNIPS,2010.[26]K.Dembczynski,W.Waegeman,W.Cheng,and\n",
      "E.H?ullermeier.AnexactalgorithmforF-measuremaximization.InNIPS,\n",
      "2011.[27]K.Dembczynski,A.Jachnik,W.Kotlowski,W.Waegeman,andE.\n",
      "Huellermeier.OptimizingtheF-measureinmulti-labelPlug-in\n",
      "ruleapproachversusstructuredlossminimization.InICML,13.[28]S.Agar-\n",
      "wal.SurrogateregretboundsfortheareaundertheROCcurveviastrongly\n",
      "properlosses.InCOLT,2013.[29]A.FrankandA.Asuncion.UCImachine\n",
      "learningrepository,2010.URL:http://archive.ics.uci.edu/ml.[30]RobertN.\n",
      "JorissenandMichaelK.Gilson.Virtualscreeningofmoleculardatabasesus-\n",
      "ingasupportvectormachine.JournalofChemicalInformationandModeling,\n",
      "45:549?561,2005.\n",
      "9\n",
      "14\n",
      "\n",
      "PP4034.pdf\n",
      "PP4034.pdf 11\n",
      "MultipartytialPrivacyviaAggregation\n",
      "ofLocallyTrainedClassiers\n",
      "Authoredby:\n",
      "BhikshaRaj\n",
      "ManasPathak\n",
      "ShantanuRane\n",
      "Abstract\n",
      "Asincreasingamountsofsensitivepersonalinformationitsway\n",
      "intodatarepositories,itisimportanttodevelopanalysismechanisms\n",
      "thatcanderiveaggregateinformationfromtheserepositorieswithoutre-\n",
      "vealinginformationaboutindividualdatainstances.Thoughthe\n",
      "entialprivacymodelprovidesaframeworktoanalyzesuchmechanisms\n",
      "fordatabasesbelongingtoasingleparty,thisframeworkhasnotyet\n",
      "beenconsideredinamulti-partysetting.Inthispaper,weproposea\n",
      "privacy-preservingprotocolforcomposingatiallyprivateaggre-\n",
      "gateusingtrainedlocallybyseparatemutuallyun-\n",
      "trustingparties.Theprotocolallowsthesepartiestointeractwithan\n",
      "untrustedcuratortoconstructadditivesharesofaperturbedaggregate\n",
      "Wealsopresentadetailedtheoreticalanalysiscontaininga\n",
      "proofoftialprivacyoftheperturbedaggregateanda\n",
      "boundontheexcessriskintroducedbytheperturbation.Weverifythe\n",
      "boundwithanexperimentalevaluationonarealdataset.\n",
      "1PaperBody\n",
      "Inrecentyears,individualsandcorporateentitieshavegatheredlargequan-\n",
      "titiesofpersonaldata.Often,theymaywishtocontributethedatatowards\n",
      "thecomputationoffunctionssuchasvariousstatistics,responsestoqueries,\n",
      "etc.Intheprocess,however,theyriskcompromisingtheprivacyof\n",
      "theindividualsbyreleasingsensitiveinformationsuchastheirmedicalor\n",
      "nancialrecords,addressesandtelephonenumbers,preferencesofvariouskinds\n",
      "whichtheindividualsmaynotwantexposed.Merelyanonymizingthedata\n",
      "isnott?anadversarywithaccesstopubliclyavailableauxiliaryin-\n",
      "formationcanstillrecovertheinformationaboutindividual,aswasthecase\n",
      "withthede-anonymizationofthexdataset[1].Inthispaper,weaddress\n",
      "theproblemoflearningafromamulti-partycollectionofsuchprivate\n",
      "data.AsetofpartiesP1,P2,...,PKeachpossessdataD1,D2,...\n",
      "1\n",
      "\n",
      ",DK.TheaimistolearnafromtheunionofallthedataD1?D2\n",
      "...?DK.Wespconsideralogisticregressionbutaswe\n",
      "shallsee,thetechniquesaregenerallyapplicabletoanyalgorithm.\n",
      "Theconditionsweimposearethat(a)Noneofthepartiesarewillingtoshare\n",
      "thedatawithoneanotherorwithanythirdparty(e.g.acurator).(b)The\n",
      "computedcannotbereverseengineeredtolearnaboutanyindividual\n",
      "datainstancepossessedbyanycontributingparty.Theconventionalapproach\n",
      "tolearningfunctionsinthismanneristhroughsecuremulti-partycomputation\n",
      "(SMC)[2].WithinSMCindividualpartiesuseacombinationofcryptographic\n",
      "techniquesandoblivioustransfertojointlycomputeafunctionoftheirprivate\n",
      "data[3,4,5].Thetechniquestypicallyprovideguaranteesthatnoneofthe\n",
      "partieslearnanythingabouttheindividualdatabesideswhatmaybeinferred\n",
      "fromthealresultofthecomputation.Unfortunately,thisdoesnotsatisfy\n",
      "condition(b)above.Forinstance,whentheoutcomeofthecomputationisa\n",
      "itdoesnotpreventanadversaryfrompostulatingthepresenceofdata\n",
      "instanceswhoseabsencemightchange1\n",
      "thedecisionboundaryoftheandverifyingthehypothesisusing\n",
      "auxiliaryinformationifany.Moreover,forallbutthesimplestcomputational\n",
      "problems,SMCprotocolstendtobehighlyexpensive,requiringiteratedencryp-\n",
      "tionanddecryptionandrepeatedcommunicationofencryptedpartialresults\n",
      "betweenparticipatingparties.Analternativetheoreticalmodelforprotecting\n",
      "theprivacyofindividualdatainstancesistialprivacy[6].Withinthis\n",
      "framework,astochasticcomponentisaddedtoanycomputationalmechanism,\n",
      "typicallybytheadditionofnoise.Amechanismevaluatedoveradatabaseis\n",
      "saidtosatisfydierentialprivacyiftheprobabilityofthemechanismproducing\n",
      "aparticularoutputisalmostthesameregardlessofthepresenceorabsence\n",
      "ofanyindividualdatainstanceinthedatabase.tialprivacyprovides\n",
      "statisticalguaranteesthattheoutputofthecomputationdoesnotcarryin-\n",
      "formationaboutindividualdatainstances.Ontheotherhand,inmultiparty\n",
      "scenarioswherethedatausedtocomputeafunctionaredistributedacrosssev-\n",
      "eralparties,itdoesnotprovideanymechanismforpreservingtheprivacyofthe\n",
      "contributingpartiesfromoneanotheroralternately,fromacuratorwhocom-\n",
      "putesthefunctionfromthecombineddata.Weprovideanalternativesolution:\n",
      "withinourapproachtheindividualpartieslocallycomputeanoptimal\n",
      "withtheirdata.Theindividualarethenaveragedtoobtainthe\n",
      "aggregateTheaggregationisperformedthroughasecureprotocol\n",
      "thatalsoaddsastochasticcomponenttotheaveragedsuchthatthe\n",
      "resultingaggregateclaseristiallyprivate,i.e.,noinferencemaybe\n",
      "madeaboutindividualdatainstancesfromtheThisproceduresatis-\n",
      "bothcriteria(a)and(b)mentionedabove.Furthermore,itistly\n",
      "lessexpensivethananySMCprotocoltocomputetheonthecom-\n",
      "bineddata.WealsopresenttheoreticalguaranteesontheWeprovide\n",
      "afundamentalresultthattheexcessriskofanaggregateobtainedby\n",
      "averagingtrainedonindividualsubsets,comparedtotheoptimalclas-\n",
      "computedonthecombineddataintheunionofallsubsets,isboundedby\n",
      "aquantitythatdependsonthesizeofthesmallestsubset.Weprovethatthe\n",
      "2\n",
      "\n",
      "additionofthenoisedoesindeedresultinatiallyprivateWe\n",
      "alsoprovideaboundonthetrueexcessriskofthetiallyprivateaver-\n",
      "agedcomparedtotheoptimaltrainedonthecombineddata.\n",
      "Finally,wepresentexperimentalevaluationoftheproposedtechniqueonaUCI\n",
      "Adultdatasetwhichisasubsetofthe1994censusdatabaseandempirically\n",
      "showthatthetiallyprivatetrainedusingtheproposedmethod\n",
      "providestheperformanceclosetotheoptimalwhenthedistribution\n",
      "ofdataacrosspartiesisreasonablyequitable.\n",
      "2\n",
      "tialPrivacy\n",
      "Inthispaper,weconsiderthetialprivacymodelintroducedbyDwork\n",
      "[6].GivenanytwodatabasesDandD0byoneelement,whichwewill\n",
      "refertoasadjacentdatabases,arandomizedqueryfunctionMissaidtobe\n",
      "tiallyprivateiftheprobabilitythatMproducesaresponseSonDis\n",
      "closetotheprobabilitythatMproducesthesameresponseSonD0.Asthe\n",
      "queryoutputisalmostthesameinthepresenceorabsenceofanindividualentry\n",
      "withhighprobability,nothingcanbelearnedaboutanyindividualentryfrom\n",
      "theoutput.DenitionArandomizedfunctionMwithawprobability\n",
      "densityPtialprivacyif,foralladjacentdatabasesDandD0\n",
      "andforanyS?range(M),\n",
      "logP(M(D)=S)?.\n",
      "0P(M(D)=S)\n",
      "(1)\n",
      "Inasetting,thetrainingdatasetmaybethoughtofasthe\n",
      "databaseandthealgorithmlearningtheruleasthequerymecha-\n",
      "nism.Asatisfyingtialprivacyimpliesthatnoadditionaldetails\n",
      "abouttheindividualtrainingdatainstancescanbeobtainedwithcertaintyfrom\n",
      "outputofthelearningalgorithm,beyondtheaprioribackgroundknowledge.\n",
      "tialprivacyprovidesanadomniaguaranteeasopposedtomostother\n",
      "modelsthatprovideadhocguaranteesagainstaspsetofattacksand\n",
      "adversarialbehaviors.Byevaluatingthetiallyprivateovera\n",
      "largenumberoftestinstances,anadversarycannotlearntheexactformofthe\n",
      "trainingdata.2\n",
      "2.1\n",
      "RelatedWork\n",
      "Dworketal.[7]proposedtheexponentialmechanismforcreatingfunctions\n",
      "satisfyingtialprivacybyaddingaperturbationtermfromtheLaplace\n",
      "distributionscaledbythesensitivityofthefunction.ChaudhuriandMonteleoni\n",
      "[8]usetheexponentialmechanism[7]tocreateatiallyprivatelogistic\n",
      "regressionclasbyperturbingtheestimatedparameterswithmultivariate\n",
      "LaplaciannoisescaledbythesensitivityoftheTheyalsopropose\n",
      "anothermethodtolearnsatisfyingtialprivacybyaddinga\n",
      "linearperturbationtermtotheobjectivefunctionwhichisscaledbyLaplacian\n",
      "noise.Nissim,etal.[9]showwecancreateatiallyprivatefunction\n",
      "byaddingnoisefromLaplacedistributionscaledbythesmoothsensitivityof\n",
      "thefunction.Whilethismechanismresultsinafunctionwithlowererror,the\n",
      "3\n",
      "\n",
      "smoothsensitivityofafunctioncanbeulttocomputeingeneral.They\n",
      "alsoproposethesampleandaggregateframeworkforreplacingtheoriginal\n",
      "functionwitharelatedfunctionforwhichthesmoothsensitivitycanbeeasily\n",
      "computed.Smith[10]presentsamethodfortiallyprivateunbiasedMLE\n",
      "usingthisframework.Allthepreviousmethodsareinherentlydesignedforthe\n",
      "casewhereasinglecuratorhasaccesstotheentiredataandisinterestedin\n",
      "releasingatiallyprivatefunctioncomputedoverthedata.Tothebest\n",
      "ofourknowledgeandbelief,oursisthemethoddesignedforreleasinga\n",
      "tiallyprivatecomputedovertrainingdataownedbyt\n",
      "partieswhodonotwishtodisclosethedatatoeachother.Ourtechnique\n",
      "wasprincipallymotivatedbythesampleandaggregateframework,wherewe\n",
      "consideredthesamplestobeownedbyindividualparties.Similarto[10],we\n",
      "chooseasimpleaverageastheaggregationfunctionandthepartiestogether\n",
      "releasetheperturbedaggregatewhichtialprivacy.In\n",
      "themulti-partycase,however,addingtheperturbationtotheisno\n",
      "longerstraightforwardanditisnecessarytoprovideasecureprotocoltodo\n",
      "this.\n",
      "3\n",
      "MultipartyProtocol\n",
      "Theproblemweaddressisasfollows:anumberofpartiesP1,...,PK\n",
      "possessdatasetsD1,...,DKwhereDi=(x,y)|jincludesasetofinstances\n",
      "xandtheirbinarylabelsy.Wewanttotrainalogisticregressionon\n",
      "thecombineddatasuchthatnopartyisrequiredtoexposeanyofitsdata,and\n",
      "thenoinformationaboutanysingledatainstancecanbeobtainedfromthe\n",
      "learnedTheprotocolcanbedividedintothethreefollowingphases:\n",
      "3.1\n",
      "TrainingLocalonIndividualDatasets\n",
      "EachpartyPjusestheirdataset(x,y)|jtolearnan`2regularizedlogistic\n",
      "regressionwith?j.Thisisobtainedbyminimizingthefollowing\n",
      "objectivefunctionweightsw\n",
      "T1X?j=argminJ(w)=argminwlog1+e?yiwxi+?wTw,(2)njiw\n",
      "wwhere?>0istheregularizationparameter.Notethatnodataorinformation\n",
      "hasbeensharedyet.3.2\n",
      "PublishingarentiallyPrivateAggregate\n",
      "Theproposedsolution,illustratedbyFigure1,proceedsPasfollows.The\n",
      "partiesthencollaborate1?s=K?j+?,where?isad-dimensionalto\n",
      "computeanaggregategivenbywjwrandomvariablesampledfroma\n",
      "Laplacedistributionscaledwiththeparametern(1)2?andn(1)=minjnj.As\n",
      "weshallseelater,composinganaggregateinthismannerincursonlya\n",
      "wellboundedexcessriskovertrainingadirectlyontheunionofalldata\n",
      "whileenablingthepartiestomaintaintheirprivacy.WealsoshowinSection\n",
      "4.1thatthenoiseterm?ensuresthat?sntialprivacy,i.e.,that\n",
      "individualdatainstancescannotbediscernedthecwfromtheaggregate\n",
      "Thedenitionofthenoiseterm?abovemayappearunusualatthis\n",
      "stage,butithasanintuitiveexplanation:Aconstructedbyaggregating\n",
      "locallytrainedislimitedbytheperformanceoftheindividualclassi\n",
      "4\n",
      "\n",
      "thathastheleastnumberofdatainstances.ThiswillbeformalizedinSection\n",
      "4.2.WenotethatthepartiesPjcannotsimplytake3\n",
      "?j,perturbthemwithanoisevectorandpublishtheperturbedtheir\n",
      "individuallytrainedw\n",
      "becauseaggregatingsuchwillnotgivethecorrect??\n",
      "Lap2/(n(1)?)ingeneral.Sinceindividualpartiescannotsimplyaddnoise\n",
      "totheirtoimposetialprivacy,theactualaveragingoperation\n",
      "mustbeperformedsuchthattheindividualpartiesdonotexposetheirown\n",
      "orthenumberofdatainstancestheypossess.Wethereforeusea\n",
      "privatemultipartyprotocol,interactingwithanuntrustedcurator?Charlie?to\n",
      "performtheaveraging.Theoutcomeoftheprotocolissuchthateachofthe\n",
      "partiesobtainadditivesharesofthe?s,suchthattheseshares\n",
      "mustbeaddedtoobtainw?s.w\n",
      "Stage1\n",
      "additivesecretsharing\n",
      "Stage2\n",
      "Stage3\n",
      "encryption\n",
      "additivesecretsharingofnoiseterm\n",
      "&\n",
      "curator\n",
      "reversepermutations\n",
      "&\n",
      "curator\n",
      "additivesecretsharingoflocalclassifers\n",
      "Null\n",
      "curator\n",
      "&&blind-andpermute\n",
      "Indicatorvectorwithpermutedindexofsmallestdatabase\n",
      "addnoisevectors\n",
      "EncryptedLaplaciannoisevectoraddedobliviouslybysmallestdatabase\n",
      "perfectlyprivateadditivesharesof\n",
      "?s.Figure1:Multipartyprotocoltosecurelycomputeadditivesharesofw\n",
      "Privacy-PreservingProtocolWeuseasymmetrickeyadditivelyhomomor-\n",
      "phicencryption[11].Adesirablepropertyofsuchschemesisthatwecanper-\n",
      "formoperationsontheciphertextelementswhichmapintoknownoperations\n",
      "onthesameplaintextelements.Foranadditivelyhomomorphicencryption\n",
      "function?(?),?(a)?(b)=?(a+b),?(a)b=?(ab).Notethattheadditively\n",
      "homomorphicschemeemployedhereissemanticallysecure,i.e.,repeateden-\n",
      "cryptionofthesameplaintextwillresultintciphertexts.Fortheen-\n",
      "suingprotocol,encryptionkeysareconsideredpublicanddecryptionkeysare\n",
      "privatelyownedbythespparties.Assumingthepartiestobehonest-\n",
      "but-curious,thestepsoftheprotocolareasfollows.Stage1.Findingtheindex\n",
      "ofthesmallestdatabaseobfuscatedbypermutation.1.EachpartyPjcom-\n",
      "putesnj=aj+bj,whereajandbjareintegersrepresentingadditiveshares\n",
      "ofthedatabaselengthsnjforj=1,2,...,K.DenotetheK-lengthvectorsof\n",
      "5\n",
      "\n",
      "additivesharesasaandbrespectively.2.ThepartiesPjmutuallyagreeona\n",
      "permutation?1ontheindexvector(1,2,...,K).Thispermutationisunknown\n",
      "toCharlie.Then,eachpartyPjsendsitsshareajtopartyP?1(j),andsends\n",
      "itssharebjtoCharliewiththeindexchangedaccordingtothepermutation.\n",
      "Thus,afterthisstep,thepartieshavepermutedadditivesharesgivenby?1(a)\n",
      "whileCharliehaspermutedadditiveshares?1(b).3.ThepartiesPjgeneratea\n",
      "keypair(pk,sk)wherepkisapublickeyforhomomorphicencryptionandskis\n",
      "thesecretdecryptionkeyknownonlytothepartiesbutnottoCharlie.Denote\n",
      "element-wiseencryptionofaby?(a).Thepartiessend?(?1(a))=?1(?(a))to\n",
      "Charlie.4.Charliegeneratesarandomvectorr=(r1,r2,???,rK)where\n",
      "theelementsriareintegerschosenuniformlyatrandomandareequallylikely\n",
      "tobepositiveornegative.Then,hecomputes?(?1(aj))?(rj)=?(?1(aj)+rj\n",
      ").Invectornotation,hecomputes?(?1(a)+r).Similarly,bysubtractingthe\n",
      "samerandomintegersinthesameordertohisownshares,heobtains?1(b)\n",
      "?rwhere?1wasthepermutationunknowntohimandappliedbytheparties.\n",
      "Then,Charlieselectsapermutation?2atrandom4\n",
      "andobtains?2(?(?1(a)+r))=?(?2(?1(a)+r))and?2(?1(b)?r).\n",
      "Hesends?(?2(?1(a)+r))totheindividualpartiesinthefollowingorder:\n",
      "FirstelementtoP1,secondelementtoP2,...,KthelementtoPK.5.Each\n",
      "partydecryptsthesignalreceivedfromCharlie.Atthispoint,thepartiesP1\n",
      ",P2,...,PKrespectivelypossesstheelementsofthevector?2(?1(a)+r)\n",
      "whileCharliepossessesthevector?2(?1(b)?r).Since?1isunknownto\n",
      "Charlieand?2isunknowntotheparties,theindicesinbothvectorshavebeen\n",
      "completeobfuscated.Notealsothat,addingthevectorcollectivelyownedby\n",
      "thepartiesandthevectorownedbyCharliewouldgive?2(?1(a)+r)+?2(?1\n",
      "(b)?r)=?2(?1(a+b))=?2(?1(n)).Thissituationinthisstepissimilar\n",
      "tothatencounteredinthe?blindandpermute?protocolusedforminimum-\n",
      "byDuandAtallah[12].?Thenni>nj?a6.Let?2(?1(a)+r)\n",
      "=?aand?2(?1(b)?r)=b.?i+?bi>a?j+?bj?a?i?a?j>?bj?\n",
      "?bi.Foreach(i,j)pairwithi,j?\n",
      "f\n",
      "1,2,...,K\n",
      "g\n",
      ",thesecomparisonscanbe\n",
      "solvedbyanyimplementationofasecuremillionaireprotocol[2].Whenallthe\n",
      "comparisonsaredone,Charlietheindex?jsuchthata??j+?b?j=minj\n",
      "nj.Thetrueindexcorrespondingtothesmallestdatabasehasalreadybeen\n",
      "obfuscatedbythestepsoftheprotocol.Charlieholdsonlyanadditiveshareof\n",
      "minjnjandthuscannotknowthetruelengthofthesmallestdatabase.Stage\n",
      "2.Obliviouslyobtainingencryptednoisevectorfromthesmallestdatabase.\n",
      "1.CharlieconstructsanKindicatorvectorusuchthatu?j=1andallother\n",
      "elementsare0.Hethenobtainsthepermutedvector?2?1(u)where?2?1inverts\n",
      "?2.Hegeneratesakey-pair(pk0,sk0)foradditivehomomorphicfunction\n",
      "?(?)whereonlytheencryptionkeypk0ispubliclyavailabletotheparties\n",
      "Pj.Charliethentransmits?(?2?1(u))=?2?1(?(u))tothepartiesPj.2.\n",
      "Thepartiesmutuallyobtainapermutedvector?1?1(?2?1(?(u)))=?(v)where\n",
      "?1?1invertsthepermutation?1originallyappliedbythepartiesPjinStage\n",
      "I.Nowthatbothpermutationshavebeenremoved,theindexofthenon-zero\n",
      "elementintheindicatorvectorvcorrespondstothetrueindexofthesmallest\n",
      "database.However,sincethepartiesPjcannotdecrypt?(?),theycannot\n",
      "6\n",
      "\n",
      "outthisindex.3.Forj=1,...,K,partyPjgenerates?j,ad-dimensional\n",
      "noisevectorsampledfromaLaplacedistributionwithparameternj2?.Then,\n",
      "itobtainsad-dimensionalvector?jwherefori=1,...,d,?j(i)=?(v(j))?j\n",
      "(i)=?(v(j)?j(i)).4.AllpartiesPjnowcomputead-dimensionalnoisevector\n",
      "?Psuchthat,fori=1,...,d,QQ?(i)=j?j(i)=j?(v(j)?j(i))=?jv(j)?j\n",
      "(i).Thereaderwillnoticethat,byconstruction,theaboveequationselects\n",
      "onlytheLaplacenoisetermsforthesmallestdatabase,whilerejectingthenoise\n",
      "termsforallotherdatabases.Thisisbecausevhasanelementwithvalue1\n",
      "attheindexcorrespondingtothesmallestdatabaseandhaszeroeseverywhere\n",
      "else.Thus,thedecryptionof?isequalto?whichwasthedesiredperturbation\n",
      "termatthebeginningofthissection.?s.Stage3.Generatingsecret\n",
      "additivesharesofw1.Oneoftheparties,sayP1,generatesad-dimensional\n",
      "randomintegernoisevectors,andtransmits?(i)?(s(i))foralli=1,...,dto\n",
      "Charlie.UsingselypreventsCharliefromdiscovering?,andtherefore\n",
      "stillensuresthatnoinformationisleakedaboutthedatabaseownersPj.P1\n",
      "computesw1?Ks.2.Charliedecrypts?(i)?(s(i))toobtain?(i)+s(i)fori=1,\n",
      "...,d.Atthisstage,thepartiesandCharliehavethefollowingd-dimensional\n",
      "vectors:CharliehasK(?+s),?1?Ks,andallotherpartiesPj,j=2,\n",
      "...,Khavew?j.NoneoftheK+1P1haswparticipantscanshare\n",
      "thisdataforfearofcompromisingtialprivacy.3.Finally,Charlieand\n",
      "theKdatabase-owningpartiesrunasimplesecurefunctionevaluationprotocol\n",
      "[13],attheendofwhicheachoftheK+1participantsobtainsan?s.This\n",
      "protocolisprovablyprivateagainsthonestbutcuriousadditiveshareofKw\n",
      "participantswhentherearenocollisions.Theresultingsharesarepublished.5\n",
      "Theaboveprotocolensuresthefollowing(a)NoneoftheK+1partici-\n",
      "pants,orusersoftheperturbedaggregatecanndoutthesizeof\n",
      "anydatabase,andthereforenoneofthepartiesknowswhocontributed?(b)\n",
      "NeitherCharlienoranyofthepartiesPjcanindividuallyremovethenoise?\n",
      "aftertheadditivesharesarepublished.Thislastpropertyisimportantbecause\n",
      "ifanyoneknowinglycouldremovethenoiseterm,thentheresultingclassi\n",
      "nolongerprovidestialprivacy.3.3\n",
      "TestingPhase\n",
      "AtestparticipantDavehavingatestdatainstancex0?Rdisinterestedin\n",
      "applyingthetrained?s.addsthepublishedsharesanddividesbyK\n",
      "togetthetiallyprivateclaserw10Hecanthencomputethesigmoid\n",
      "functiont=anddecidetoclassifyxwithlabel?1if??wsTxi1+e\n",
      "andwithlabel1ift>21.\n",
      "t?\n",
      "12\n",
      "4\n",
      "TheoreticalAnalysis\n",
      "4.1\n",
      "ProofoftialPrivacy\n",
      "Weshowthattheperturbedaggregatetialprivacy.\n",
      "Weusethefollowingboundonthesensitivityoftheregularizedregressionclas-\n",
      "asprovedinCorollary2in[8]restatedintheappendixasTheorem6.1.?\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreservestialprivacy.ForanytwoadjacentdatasetsDTheorem4.1.\n",
      "Theclassiw0andD,\n",
      "ws|D)logP(??.\n",
      "P(?ws|D0)Proof.Considerthecasewhereoneinstanceofthetraining\n",
      "datasetDischangedtoresultinanadjacentdatasetD0.Thiswouldimplya\n",
      "changeinoneelementinthetrainingdatasetofoneparty?sj.Assumingthat\n",
      "thechangeisintheandtherebyachangeinthecorrespondinglearnedvector\n",
      "w?j;letdenotethenewdatasetofthepartyPj,thechangeinthelearned\n",
      "vectorisonlygoingtobeinw?jaskw?j?w?0jk1?nj2?.Following?0j.\n",
      "InTheorem6.1,weboundthesensitivityofwclasserbyw?susingeitherthe\n",
      "traininganargumentsimilarto[7],consideringthatwelearnthesamevector\n",
      "w0datasetsDandD,wehavehin(1)?\n",
      "s?expkwkj1n(1)??|D)?j+?|D)2P(wP(w0hi?exp=?j?\n",
      "w?jk1=kwn??s|D0)P(w2?0j+?|D0Pw?0jk1exp(1)2kw\n",
      "n(1)?2n(1)?exp?exp?exp(),2nj?njbytheoffunction\n",
      "sensitivity.Similarly,wecanlowerboundthetheratiobyexp(?).4.2\n",
      "AnalysisofExcessError\n",
      "Inthefollowingdiscussion,weconsiderhowmuchexcesserrorisintroduced\n",
      "whenusingaper?ssatisfyingtialprivacyasopposedtotheunperturbed\n",
      "turbedaggregatew?wtrainedontheentiretrainingdata\n",
      "whileignoringtheprivacyconstraintsaswellastheunper?turbedaggregate\n",
      "w.?andtheWeestablishaboundonthe`2normofthe\n",
      "betweentheaggregateww?trainedovertheentiretraining\n",
      "data.ToprovetheboundweapplyLemma1from[8]restatedasLemma6.2\n",
      "intheappendix.Pleaserefertotheappendixfortheproofofthefollowing\n",
      "theorem.?,thew?trainedovertheentiretrainingTheorem4.2.\n",
      "Giventheaggregatewdataandn(1)isthesizeofthesmallesttraining\n",
      "dataset,k?w?w?k2?\n",
      "6\n",
      "K?1.n(1)?\n",
      "Theboundisinverselyproportionaltothenumberofinstancesinthesmall-\n",
      "estdataset.Thisindicates?willbealottfromw?.Thelargest\n",
      "possiblethatwhenthedatasetsareofdisparatesizes,wn?willvalueforn(1)\n",
      "isKinwhichcaseallpartieshavinganequalamountoftrainingdataandw\n",
      "beclosesttow?.IntheonepartycaseforK=1,theboundindicatesthat\n",
      "normofthe?isthewouldbeupperboundedbyzero,whichisa\n",
      "validsanitycheckastheaggregatewsameasw?.Weusethisresult\n",
      "toestablishaboundontheempiricalriskoftheperturbedaggregate\n",
      "?s=w?+?overtheempiricalriskoftheunperturbedw?inthe\n",
      "followingtheorem.wPleaserefertotheappendixfortheproof.Theorem4.3.\n",
      "Ifalldatainstancesxilieinaunitball,withprobabilityatleast1??,the\n",
      "empirical?soverthew?trainedoverregularizedexcessriskofthe\n",
      "perturbedaggregatewentiretrainingdatais\n",
      "dd(K?1)2(?+1)2d2(?+1)2d(K?1)(?+1)2J(?ws)?\n",
      "J(w?)++loglog+.2n2(1)?2n2(1)2?2?n2(1)?2?Thebound\n",
      "suggestsanerrorbecauseoftwofactors:aggregationandperturbation.The\n",
      "8\n",
      "\n",
      "boundincreasesforsmallervaluesofimplyingatighteroftial\n",
      "privacy,indicatingaclearbetweenprivacyandutility.Theboundis\n",
      "alsoinverselyproportionalton2(1)implyinganincreaseinexcessriskwhen\n",
      "thepartieshavetrainingdatasetsofdisparatesizes.Inthelimitingcase??,\n",
      "weareaddingaperturbationterm?sampledfromaLaplaciandistributionof\n",
      "smallvarianceresultingintheperturbedbeingalmost\n",
      "assameas?satisfyingaverylooseoftialprivacy.usingthe\n",
      "unperturbedaggregatewWithsuchavalueof,ourboundbecomes?\n",
      "?J(w?)+J(w)\n",
      "(K?1)2(?+1).2n2(1)?2\n",
      "(3)\n",
      "SimilartotheanalysisofTheorem4.2,theexcesserrorinusinganaggregate\n",
      "isinverselyproportionaltothesizeofthesmallestdatasetn(1)andin\n",
      "theonepartycaseK=1,thebound?isthesameasw?.Also,forasmall\n",
      "valueofintheonebecomeszeroastheaggregatewpartycaseK=1\n",
      "andn(1)=n,ourboundreducestothatinLemma3of[8],\n",
      "2d2(?+1)d2?s)?J(w?)+J(wlog.(4)222n??Whilethe\n",
      "previoustheoremgivesusaboundontheempiricalexcessriskoveragiven\n",
      "training?soverw?.Letusdenotethedataset,itisimportanttoconsider\n",
      "aboundonthetrueexcessriskofwsss??byJ(w?)=E[J(w?)]and\n",
      "similarly,thetrueriskoftheclasw?bytrueriskofthew???\n",
      "J(w)=E[J(w)].Inthefollowingtheorem,weapplytheresultfrom[14]which\n",
      "usestheboundontheempiricalexcessrisktoformaboundonthetrueexcess\n",
      "risk.Pleaserefertotheappendixfortheproof.Theorem4.4.Ifalltraining\n",
      "datainstancesxilieinaunitball,withprobabilityatleast1??,the?sover\n",
      "thew?trainedoverentiretrueexcessriskoftheperturbedaggregate\n",
      "wtrainingdatais\n",
      "2(K?1)2(?+1)4d2(?+1)ds2???J(?w)?J(w)++222log2\n",
      "22n(1)?n(1)??\n",
      "4d(K?1)(?+1)161d++32+log.logn2(1)?2??n?\n",
      "5\n",
      "Experiments\n",
      "Weperformanempiricalevaluationoftheproposedtiallyprivate\n",
      "toobtainacharacterizationoftheincreaseintheerrorduetopertur-\n",
      "bation.WeusetheAdultdatasetfromtheUCImachinelearningrepository\n",
      "[15]consistingofpersonalinformationrecordsextractedfrom7\n",
      "0.5\n",
      "non-privatealldataDPalldataDPaggregaten(1)=6512DPaggregate\n",
      "n(1)=4884DPaggregaten(1)=3256\n",
      "0.45\n",
      "testerror\n",
      "0.4\n",
      "0.35\n",
      "0.3\n",
      "0.25\n",
      "0.20\n",
      "9\n",
      "\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "?\n",
      "?sfortdatasplitsvs.Figure2:performanceevaluated\n",
      "forw?,w?+?,andwthecensusdatabaseandthetaskistopredictwhether\n",
      "agivenpersonhasanannualincomeover$50,000.Thechoiceofthedatasetis\n",
      "motivatedasarealisticexampleforapplicationofdataprivacytechniques.The\n",
      "originalAdultdatasethassixcontinuousandeightcategoricalfeatures.We\n",
      "usepre-processingsimilarto[16],thecontinuousfeaturesarediscretizedinto\n",
      "quintiles,andeachquintileisrepresentedbyabinaryfeature.Eachcategorical\n",
      "featureisconvertedtoasmanybinaryfeaturesasitscardinality.Thedataset\n",
      "contains32,561trainingand16,281testinstanceseachwith123features.1In\n",
      "Figure2,wecomparethetesterrorofperturbedaggregateclaserstrained\n",
      "overdatafromepartiesfortvaluesof.Weconsiderthreesituations:\n",
      "allpartieswithequaldatasetscontaining6512instances(evensplit,n(1)=20%\n",
      "ofn),partieswithdatasetscontaining4884,6512,6512,6512,8141instances\n",
      "(n(1)=15%ofn),andpartieswithdatasetscontaining3256,6512,6512,6512,\n",
      "9769instances(n(1)=10%ofn).Wealsocomparewiththeerroroftheclas-\n",
      "trainedusingcombinedtrainingdataanditsperturbedversionsatisfying\n",
      "tialprivacy.Wechosethevalueoftheregularizationparameter?=1\n",
      "andtheresultsdisplayedareaveragedover200executions.Theperturbedag-\n",
      "gregatewhichistrainedusingmaximumn(1)=6512doesconsistently\n",
      "betterthanforlowervaluesofn(1)whichissameasourtheorysuggested.Also,\n",
      "thetesterrorforallperturbedaggregatedropswith,butcompara-\n",
      "tivelyfasterforevensplitandconvergestothetesterrorofthetrained\n",
      "overthecombineddata.Asexpected,thetiallyprivatetrained\n",
      "overtheentiretrainingdatadoesmuchbetterthantheperturbedaggregate\n",
      "withanerrorequaltotheunperturbedexceptforsmallval-\n",
      "uesof.Thelowererrorofthisisatthecostofthelossinprivacyof\n",
      "thepartiesastheywouldneedtosharethedatainordertotrainthe\n",
      "overcombineddata.\n",
      "6\n",
      "Conclusion\n",
      "Weproposedamethodforcomposinganaggregatesatisfying-\n",
      "tialprivacyfromlocallytrainedbymultipleuntrustingpar-\n",
      "ties.Theupperboundontheexcessriskoftheperturbedaggregateclassiferas\n",
      "comparedtotheoptimaltrainedoverthecompletedatawithoutpri-\n",
      "vacyconstraintsisinverselyproportionaltotheprivacyparameter,suggesting\n",
      "aninherentbetweenprivacyandutility.Theboundisalsoinversely\n",
      "proportionaltothesizeofthesmallesttrainingdataset,implyingthebestper-\n",
      "10\n",
      "\n",
      "formancewhenthedatasetsareofequalsizes.ExperimentalresultsontheUCI\n",
      "Adultdataalsoshowthebehaviorsuggestedbytheboundandweobservethat\n",
      "theproposedmethodprovidesperformanceclosetotheoptimal\n",
      "nonprivateforappropriatevaluesof.Infuturework,weseektogener-\n",
      "alizethetheoreticalanalysisoftheperturbedaggregatetothesetting\n",
      "inwhicheachpartyhasdatageneratedfromaderentdistribution.1\n",
      "Thedatasetcanbedownloadfromhttp://www.csie.ntu.edu.tw/cjlin/libsvmtools/datasets/binary.html#a9a\n",
      "8\n",
      "2References\n",
      "[1]ArvindNarayananandVitalyShmatikov.De-anonymizingsocialnetworks.\n",
      "InIEEESymposiumonSecurityandPrivacy,pages173?187,2009.[2]Andrew\n",
      "Yao.Protocolsforsecurecomputations(extendedabstract).InIEEESym-\n",
      "posiumonFoundationsofComputerScience,1982.[3]JaideepVaidya,Chris\n",
      "Clifton,MuratKantarcioglu,andA.ScottPatterson.Privacy-preservingde-\n",
      "cisiontreesoververticallypartitioneddata.TKDD,2(3),2008.[4]Jaideep\n",
      "Vaidya,MuratKantarcioglu,andChrisClifton.Privacy-preservingnaivebayes\n",
      "VLDBJ,17(4):879?898,2008.[5]JaideepVaidya,HwanjoYu,\n",
      "andXiaoqianJiang.Privacy-preservingsvmKnowledgeand\n",
      "InformationSystems,14(2):161?178,2008.[6]CynthiaDwork.tialpri-\n",
      "vacy.InInternationalColloquiumonAutomata,LanguagesandProgramming,\n",
      "2006.[7]CynthiaDwork,FrankMcSherry,KobbiNissim,andAdamSmith.\n",
      "Calibratingnoisetosensitivityinprivatedataanalysis.InTheoryofCryp-\n",
      "tographyConference,pages265?284,2006.[8]KamalikaChaudhuriandClaire\n",
      "Monteleoni.Privacy-preservinglogisticregression.InNeuralInformationPro-\n",
      "cessingSystems,pages289?296,2008.[9]KobbiNissim,SofyaRaskhodnikova,\n",
      "andAdamSmith.Smoothsensitivityandsamplinginprivatedataanalysis.In\n",
      "ACMSymposiumonTheoryofComputing,pages75?84,2007.[10]Adam\n",
      "Smith.t,tiallyprivatepointestimators.arXiv:0809.4794v1\n",
      "[cs.CR],2008.[11]PascalPaillier.Public-keycryptosystemsbasedoncom-\n",
      "positedegreeresiduosityclasses.InEUROCRYPT,1999.[12]MikhailAtallah\n",
      "andJiangtaoLi.Secureoutsourcingofsequencecomparisons.International\n",
      "JournalofInformationSecurity,4(4):277?287,2005.[13]MichaelBen-Or,Shari\n",
      "Goldwasser,andAviWidgerson.Completenesstheoremsfornoncryptographic\n",
      "fault-tolerantdistributedcomputation.InProceedingsoftheACMSymposium\n",
      "ontheTheoryofComputing,pages1?10,1988.[14]KarthikSridharan,Shai\n",
      "Shalev-Shwartz,andNathanSrebro.Fastratesforregularizedobjectives.In\n",
      "NeuralInformationProcessingSystems,pages1545?1552,2008.[15]A.Frank\n",
      "andA.Asuncion.UCImachinelearningrepository,2010.[16]JohnPlatt.Fast\n",
      "trainingofsupportvectormachinesusingsequentialminimaloptimization.In\n",
      "AdvancesinKernelMethods?SupportVectorLearning,pages185?208,1999.\n",
      "9\n",
      "11\n",
      "\n",
      "PP5855.pdf\n",
      "PP5855.pdf 18\n",
      "AReduced-DimensionfMRISharedResponse\n",
      "Model\n",
      "Authoredby:\n",
      "JamesHaxby\n",
      "PeterJ.Ramadge\n",
      "UriHasson\n",
      "Po-Hsuan(Cameron)Chen\n",
      "JaniceChen\n",
      "YaaraYeshurun\n",
      "Abstract\n",
      "Multi-subjectfMRIdataiscriticalforevaluatingthegeneralityand\n",
      "validityofngsacrosssubjects,anditseutilizationhelpsim-\n",
      "proveanalysissensitivity.Wedevelopasharedresponsemodelforag-\n",
      "gregatingmulti-subjectfMRIdatathataccountsfortfunctional\n",
      "topographiesamonganatomicallyaligneddatasets.Ourmodeldemon-\n",
      "stratesimprovedsensitivityinidentifyingasharedresponseforavariety\n",
      "ofdatasetsandanatomicalbrainregionsofinterest.Furthermore,by\n",
      "removingtheidensharedresponse,itallowsimproveddetectionof\n",
      "groupTheabilitytoidentifywhatissharedandwhatisnot\n",
      "sharedopensthemodeltoawiderangeofmulti-subjectfMRIstudies.\n",
      "1PaperBody\n",
      "ManymodernfMRIstudiesofthehumanbrainusedatafrommultiplesub-\n",
      "jects.Theuseofmultiplesubjectsiscriticalforassessingthegeneralityand\n",
      "validityoftheacrosssubjects.Itisalsoincreasinglyimportantsince\n",
      "fromonesubjectonecangatheratmostafewthousandnoisyinstancesof\n",
      "functionalresponsepatterns.Toincreasethepowerofmultivariatestatistical\n",
      "analysis,onethereforeneedstoaggregateresponsedataacrossmultiplesub-\n",
      "jects.However,thesuccessfulaggregationoffMRIbrainimagingdataacross\n",
      "subjectsrequiresresolvingthemajorproblemthatbothanatomicalstructure\n",
      "andfunctionaltopographyvaryacrosssubjects[1,2,3,4].Moreover,itiswell\n",
      "knownthatstandardmethodsofanatomicalalignment[1,4,5]donotade-\n",
      "quatelyalignfunctionaltopography[4,6,7,8,9].Henceanatomicalalignment\n",
      "isoftenfollowedbyspatialsmoothingofthedatatoblurfunctionaltopogra-\n",
      "phies.Recently,functionalspatialregistrationmethodshaveappearedthatuse\n",
      "1\n",
      "\n",
      "corticalwarpingtomaximizeinter-subjectcorrelationoftimeseries[7]orinter-\n",
      "subjectcorrelationoffunctionalconnectivity[8,9].Amoreradicalapproach\n",
      "learnsalatentmultivariatefeaturethatmodelsthesharedcomponentofeach\n",
      "subject?sresponse[10,11,12].Multivariatestatisticalanalysisoftenbeginsby\n",
      "identifyingasetoffeaturesthatcapturetheinformativeaspectsofthedata.\n",
      "Forexample,infMRIanalysisonemightselectasubsetofvoxelswithinan\n",
      "anatomicalregionofinterest(ROI),orselectasubsetofprincipalcomponents\n",
      "oftheROI,thenusethesefeaturesforsubsequentanalysis.Inasimilarway,\n",
      "onecanthinkofthefMRIdataaggregationproblemasatwostepprocess.\n",
      "Firstusetrainingdatatolearnamappingofeachsubject?smeasureddatatoa\n",
      "sharedfeaturespaceinawaythatcapturestheacross-subjectsharedresponse.\n",
      "Thenusetheselearnedmappingstoprojectheldoutdataforeachsubjectinto\n",
      "thesharedfeaturespaceandperformastatisticalanalysis.Tomakethismore\n",
      "precise,let\n",
      "f\n",
      "Xi?Rv?d\n",
      "g\n",
      "mi=1denotematricesoftrainingdata(vvoxelsinthe\n",
      "ROI,overdTRs)formsubjects.Weproposeusingthisdatatolearnsubject\n",
      "spbasesWi?Rv?k,wherekistobeselected,andasharedmatrixS?\n",
      "Rk?doffeatureresponsessuchthatXi=WiS+EiwhereEiisanerrorterm\n",
      "correspondingtounmodeledaspectsofthesubject?sresponse.Onecanthink\n",
      "ofthebasesWiasrepresentingtheindividualfunctionaltopographiesandS\n",
      "asalatentfeaturethatcapturesthecomponentoftheresponsesharedacross\n",
      "subjects.Wedon?tclaimthatSisatstatistic,butthatisauseful\n",
      "analogy.1\n",
      "problem(1)k=50\n",
      "problem(1)k=100\n",
      "10.7\n",
      "problem(1)k=500\n",
      "10.7\n",
      "0.6\n",
      "0.6\n",
      "0.6\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "10.5\n",
      "problem(2)k=50\n",
      "problem(2)k=100\n",
      "10.6\n",
      "problem(2)k=500\n",
      "10.7\n",
      "1TrainObjective\n",
      "TestAccuracy\n",
      "0.7\n",
      "0.6\n",
      "0.4\n",
      "0\n",
      "2\n",
      "2\n",
      "\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "0.4\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "0.4\n",
      "0.4\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "100Iterations\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "0.4\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "0.5\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "Figure1:Comparisonoftrainingobjectivevalueandtestingaccuracyfor\n",
      "problem(1)and(2)overvariouskonraiderdatasetwith500voxelsofventral\n",
      "temporalcortex(VT)inimagestimulusexperiment(detailsin\n",
      "Sec.4).Inallcases,errorbarsshow?1standarderror.\n",
      "Thecontributionofthepaperistwofold:First,weproposeaprobabilistic\n",
      "generativeframeworkformodelingandestimatingthesubjectspecibasesWi\n",
      "andthesharedresponselatentvariableS.Acriticalaspectofthemodelisthatit\n",
      "directlyestimateskvsharedfeatures.Thisisincontrasttomethodswherethe\n",
      "3\n",
      "\n",
      "numberoffeaturesequalsthenumberofvoxels[10,11].Moreover,theBayesian\n",
      "natureoftheapproachprovidesanaturalmeansofincorporatingpriordomain\n",
      "knowledge.Second,wegiveademonstrationoftherobustnessandeness\n",
      "ofourdataaggregationmodelusingavarietyoffMRIdatasetscapturedon\n",
      "tMRImachines,employingdistinctanalysispathways,andbasedon\n",
      "variousbrainROIs.\n",
      "2\n",
      "Preliminaries\n",
      "fMRItime-seriesdataXi?Rv?d,i=1:m,iscollectedformsubjects\n",
      "astheyarepresentedwithidentical,timesynchronizedstimuli.Heredisthe\n",
      "numberoftimesamplesinTRs(TimeofRepetition),andvisthenumberof\n",
      "voxels.Ourobjectiveistomodeleachsubject?sresponseasXi=WiS+Ei\n",
      "whereWi?Rv?kisabasisoftopographiesforsubjecti,kisaparameter\n",
      "selectedbytheexperimenter,S?Rk?disacorrespondingtimeseriesofshared\n",
      "responsecoordinates,andEiisanerrorterm,i=1:m.Toensureuniqueness\n",
      "ofcoordinatesitisnecessarythatWihaslinearlyindependentcolumns.We\n",
      "makethestrongerassumptionthateachWihasorthonormalcolumns,WiTWi\n",
      "=Ik.TwoapproachesforestimatingthebasesWiandthesharedresponse\n",
      "Sareillustratedbelow:PP2T2minWi,SminWi,SikXi?WiSkFikWi\n",
      "Xi?SkF(1)(2)TTs.t.WiWi=Ik,s.t.WiWi=Ik,wherek?kF\n",
      "denotestheFrobeniusnorm.Fork?v,(1)canbesolvediterativelybyrst\n",
      "selectingconditionsforWi,i=1:m,andoptimizing(1)withrespecttoSby\n",
      "settingS=PinitialT21/miWiXi.WithS(1)becomesmseparate\n",
      "subproblemsoftheformminkXi?WiSkFTTT?????withsolutionWi\n",
      "=UiVi,whereUi?iViisanSVDofXiS[13].Thesetwostepscanbeiterated\n",
      "untilastoppingcriterionisSimilarly,fork?v,(2)canalsobesolved\n",
      "iteratively.However,fork<v,thereisnoknownfastupdateofWigivenS.\n",
      "HencethismustbedoneusinglocalgradientdecentontheStiefelmanifold[14].\n",
      "Bothapproachesyieldthesamesolutionwhenk=v,butarenotequivalent\n",
      "inthemoreinterestingsituationkv(Sup.Mat.).Whatismostimportant,\n",
      "however,isthatproblem(2)withk<v,oftenlearnsanuninformativeshared\n",
      "responseS.ThisisillustratedinFig.1whichplotsofthevalueofthetraining\n",
      "objectiveandthetestaccuracyforastimulusclasscationexperimentversus\n",
      "iterationcount(imageusingtheraiderfMRIdataset,seeSec.4).\n",
      "Forproblem(1),testaccuracyincreaseswithdecreasingtrainingerror,Whereas\n",
      "forproblem(2),testaccuracydecreaseswithdecreasingtrainingerror(Thiscan\n",
      "beexplainedanalytically,seeSup.Mat.).Wethereforebaseourapproachon\n",
      "ageneralizationofproblem(1).WecalltheresultingSand\n",
      "f\n",
      "Wi\n",
      "g\n",
      "mi=1a\n",
      "sharedresponsemodel(SRM).Beforeextendingthissimplemodel,wenotea\n",
      "fewimportantproperties.First,asolutionof(1)Tmisnotunique.IfS,\n",
      "f\n",
      "Wi\n",
      "g\n",
      "mi=1isasolution,thensoisQS,\n",
      "f\n",
      "WiQ\n",
      "g\n",
      "i=1,foranyk?korthogonal\n",
      "matrixQ.Thisisnotaproblemaslongasweonlylearnonetemplateandone\n",
      "setofsubjectbases.Anynewsubjectsornewdatawillbereferencedtothe\n",
      "originalSRM.However,ifweindependentlylearntwoSRMs,thegroupshared\n",
      "responsesS1,S2,maynotberegistered(usethesameQ).WeregisterS1to\n",
      "S2byingak?korthogonalmatrixQtominimizekS2?QS1k2F;then\n",
      "4\n",
      "\n",
      "useQS1inplaceofS1andWjQTinplaceofWjforsubjectsintheSRM.\n",
      "Next,whenprojectedontothespanofitsbasis,eachPsubject?strainingdata\n",
      "XihascoordinatesmSi=WiTXiandthelearningphaseensuresS=1/mi\n",
      "Si.Theprojectiontoksharedfeatures2\n",
      "andtheaveragingacrosssubjectsinfeaturespacebothcontributetoacross-\n",
      "subjectdenoisingduringthelearningphase.BymappingSbackintovoxel\n",
      "spaceweobtainthevoxelspacemanifestationWiSofthedenoised,shared\n",
      "componentofeachsubject?strainingdata.Thetrainingdataofsubjectjcan\n",
      "alsobemappedthroughthesharedresponsemodeltothefunctionaltopography\n",
      "andanatomy?i,j=WiWTXj.ofsubjectibythemappingXjNewsubjects\n",
      "areeasilyaddedtoanexistingSRMS,\n",
      "f\n",
      "Wi\n",
      "g\n",
      "mi=1.WerefertoSasthe\n",
      "trainingtemplate.Tointroduceanewsubjectj=m+1withtrainingdata\n",
      "Xj,formitsorthonormalbasisbyminimizingthemeansquaredmodelingerror\n",
      "minWj,WjTWj=IkkXj?WjSk2F.Wesolvethisfortheleastnormsolution.\n",
      "NotethatS,andtheexistingW1:mdonotchange;wesimplyaddanewsubject\n",
      "byusingitstrainingdataforthesamestimulusandthetemplateStodetermine\n",
      "itsbasisoffunctionaltopographies.WecanalsoaddnewdatatoanSRM.Let\n",
      "Xi0,i=1:m,denotenewdatacollectedunderadistinctstimulusfromthe\n",
      "samesubjects.ThisisaddedtothestudybyformingSi0=PWiTXi0,then\n",
      "averagingtheseprojectionstoformthesharedresponseforthenewmdata:S\n",
      "0=1/mi=1WiTXi0.Thisassumesthelearnedsubjectsptopographies\n",
      "Wigeneralizetothenewdata.Thisusuallyrequiresatlyrichstimulus\n",
      "inthelearningphase.\n",
      "3\n",
      "ProbabilisticSharedResponseModel\n",
      "Wenowextendoursimplesharedresponsemodeltoaprobabilisticsetting.\n",
      "Letxit?Rvdenotetheobservedpatternofvoxelresponsesofthei-thsubject\n",
      "attimet.Forthemoment,assumetheseobservationsarecenteredovertime.\n",
      "Letst?Rkbeahyperparametermodelingthesharedresponseattimet=1:d,\n",
      "andmodeltheobservationattimetfordatasetiastheoutcomeofarandom\n",
      "vector:xit?N(Wist,?2I),\n",
      "withWiTWi=Ik,\n",
      "(3)\n",
      "where,xittakesvaluesinRv,Wi?Rv?k,i=1:m,and?2isasubject\n",
      "independenthyperpaPP?2rameter.Thenegativelog-likelihoodofthismodel\n",
      "isL=tiv2log2?+v2log?2+?2(xit?Wist)T(xit?Wist).Notingthat\n",
      "xitisthet-thcolumnofXi,weseethatminimizingLwithrespecttoWiandS\n",
      "=[s1,...,sd],requiresthesolutionof:PPPminti(xit?Wist)T(xit?\n",
      "Wist)=minikXi?WiSk2F.Thusmaximumlikelihoodestimationforthis\n",
      "modelmatches(1).InourfMRIdatasets,andmostmulti-subjectfMRIdatasets\n",
      "availabletoday,dm.Sincestistimespbutsharedacrossthemsubjects,\n",
      "weseethatthereispalpablevalueinregularizingitsestimation.Incontrast,\n",
      "subjectspvariablessuchasWiaresharedacrosstime,adimensionin\n",
      "whichdataisrelativelyplentiful.Hence,anaturalextensionof(3)istomake\n",
      "stasharedlatentrandomvectorst?N(0,?s)takingvaluesinRk.The\n",
      "observationfordatasetiattimetthenhastheconditionaldensityp(xit|st)\n",
      "5\n",
      "\n",
      "=N(Wist+?i,?2iI),wherethesubjectspmean?iallowsforanon-zero\n",
      "meanandweassumesubjectdependentisotropicnoisecovariance?2iI.This\n",
      "isanextendedmulti-subjectformoffactoranalysis,butinfactoranalysisone\n",
      "normallyassumes?s=I.TToformajointmodel,letxTt=[x1tT...xmt\n",
      "T],WT=[W1T...Wm],?T=[?T1...?Tm],?=diag(?21I,...,\n",
      "?2mI),?N(0,?),and?x=W?sWT+?.Then\n",
      "xt=Wst+?+,\n",
      "(4)\n",
      "withxt?N(?,?x)takingvaluesinRmv.Forthisjointmodel,weformulate\n",
      "SRMas:?s\n",
      "st?N(0,?s),xit|st?N(Wist+WiTWi\n",
      "=Ik,\n",
      "?i,?2iI),\n",
      "st\n",
      "Wi,?i,?i\n",
      "(5)\n",
      "xit\n",
      "d\n",
      "Figure2:GraphicalmodelforSRM.Shadednodes:observations,unshaded\n",
      "nodes:latentvariables,andblacksquares:hyperparameters.\n",
      "m\n",
      "wheresttakesvaluesinRk,xittakesvaluesinRv,andthehyperparameters\n",
      "WiarematricesinRv?k,i=1:m.Thelatentvariablest,withcovariance?s\n",
      ",modelsasharedelicitedresponseacrossthesubjectsattimet.Byapplying\n",
      "thesameorthogonaltransformtoeachoftheWi,wecanassume,withoutloss\n",
      "ofgenerality,that?sisdiagonal.TheSRMgraphicalmodelisdisplayedinFig.\n",
      "2.3\n",
      "3.1\n",
      "ParameterEstimationforSRM\n",
      "ToestimatetheparametersoftheSRMmodelweapplyaconstrainedEM\n",
      "algorithmtondmaximumlikelihoodsolutions.Let?denotethevectorof\n",
      "allparameters.IntheE-step,giveninitialvalueorestimatedvalue?oldfrom\n",
      "thepreviousM-step,wecalculatethetstatisticsbytakingexpectation\n",
      "withrespecttop(st|xt,?old):Es|x[st]=(W?s)T(W?sWT+?)?1\n",
      "(xt??),Es|x[stsTt]\n",
      "(6)\n",
      "T\n",
      "=Vars|x[st]+Es|x[st]Es|x[st]\n",
      "=?s??TsWT(W?sWT+?)?1W?s+Es|x[st]Es|x[st]T.\n",
      "(7)\n",
      "IntheM-step,weupdatetheparameterestimateto?newbymaximizingQ\n",
      "withrespecttoWi,?i,?2i,i=1:m,and?s.Thisisgivenby?new=arg\n",
      "max?Q(?,?old),wherePdRQ(?,?old)=d1t=1p(st|xt,?old)logp(xt\n",
      ",st|?)dst.Duetothemodelstructure,Qcanbemaximizedwithrespect\n",
      "toeachparameterseparately.ToenforcetheorthogonalityofWi,webringa\n",
      "symmetricmatrix?iofLagrangemultipliersandaddtheconstrainttermtr(?i\n",
      "6\n",
      "\n",
      "(WiTWi?I))totheobjectivefunction.Settingthederivativesofthemo\n",
      "objectivetozero,weobtainthefollowingupdateequations:P?new=d1txit\n",
      ",(8)i\n",
      "P1newTnewT?1/2,(9)Wi=Ai(AiAi),Ai=2t(xit??i)Es|x[st\n",
      "]\n",
      "P12newnew2newTnewT?i=dvtkxit??ik?2(xit??i)Wi\n",
      "Es|x[st]+tr(Es|x[stst]),(10)P1Tnew(11)?s=dt(Es|x[stst]).\n",
      "TheorthonormalconstraintWiTWi=IkinSRMissimilartothatofPCA.\n",
      "Ingeneral,thereisnoreasontobelievethatkeybrainresponsepatternsare\n",
      "orthogonal.So,theorthonormalbasesfoundviaSRMareacomputationaltool\n",
      "toaidstatisticalanalysiswithinanROI.Fromacomputationalviewpoint,or-\n",
      "thogonalityhastheadvantageofrobustnessandpreservingtemporalgeometry.\n",
      "3.2\n",
      "Connectionswithrelatedmethods\n",
      "Foronesubject,SRMissimilartoavariantofpPCA[15]thatimposes\n",
      "anorthogonalityconstraintontheloadingmatrix.pPCAyieldsanorthogonal\n",
      "loadingmatrix.However,duetotheincreaseinmodelcomplexitytohandlemul-\n",
      "tipledatasets,SRMhasanexplicitconstraintoforthogonalloadingmatrices.\n",
      "TopographicFactorAnalysis(TFA)[16]isafactormodelusingatopographic\n",
      "basiscomposedofsphericalGaussianswithtcentersandwidths.This\n",
      "choiceofbasisisconstrainingbutsinceeachfactorisan?blob?inthebrainit\n",
      "hastheadvantageofprovidingasimplespatialinterpretation.Hyperalignment\n",
      "(HA)[10],learnsasharedrepresentationalbyrotatingsubjects?timeseries\n",
      "responsestomaximizeinter-subjecttimeseriescorrelation.Theformulationin\n",
      "[10]isbasedonproblem(2)withk=vandWiav?vorthogonalmatrix\n",
      "(Sup.Mat.).Sothismethoddoesnotdirectlyreducethedimensionofthe\n",
      "featurespace,nordoesitdirectlyextendtothiscase(seeFig.1).Although\n",
      "dimensionalityreductioncanbedoneposthocusingPCA,[10]showsthatthis\n",
      "doesn?tleadtoperformanceimprovement.Incontrast,weshowin?4that\n",
      "selectingkvcanimprovetheperformanceofSRMbeyondthatattainedby\n",
      "HA.TheGICA,IVAalgorithms[17]donotassumetime-synchronizedstimulus\n",
      "andhenceconcatenatedataalongthetimedimension(implyingspatialconsis-\n",
      "tency)andlearnspatialindependentcomponents.Weusetheassumptionof\n",
      "atime-synchronizedstimulusforanchoringthesharedresponsetoovercomea\n",
      "spatialmismatchinfunctionaltopographies.Finally,SRMcanberegardedasa\n",
      "toftheconceptofhyperalignment[10]castintoaprobabilisticframe-\n",
      "work.TheHAapproachhasconnectionswithregularizedCCA[18].Additional\n",
      "detailsoftheseconnectionsandconnectionswithCanonicalCorrelationAnal-\n",
      "ysis(CCA)[19],ridgeregression,IndependentComponentAnalysis(ICA)[20],\n",
      "regularizedHyperalignment[18]arediscussedinthesupplementarymaterial.\n",
      "4\n",
      "Experiments\n",
      "WeassesstheperformanceandrobustnessofSRMusingfMRIdatasets\n",
      "(Table1)collectedusingtMRImachines,subjects,andpreprocessing\n",
      "pipelines.Thesherlockdatasetwascollected4\n",
      "DatasetSubjsTRs(s/TR)Regionofinterest(ROI)Voxelssherlock(audio-\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualmovie)[21]161976(2)posteriormedialcortex(PMC)[22]813raider\n",
      "(audio-visualmovie)[10]102203(3)ventraltemporalcortex(VT)[23]500/H\n",
      "forrest(audiomovie)[24]183599(2)planumtemporale(PT)[25]1300/Haudio-\n",
      "book(narratedstory)[26]40449(2)defaultmodenetwork(DMN)[27]2500/H\n",
      "Table1:fMRIdatasetsareshownintheleftfourcolumns,andtheROIsare\n",
      "showninrighttwocolumns.TheROIsvaryinfunctionalfromvisual,language,\n",
      "memory,tomentalstates.Hstandsforhemisphere.\n",
      "whilesubjectswatchedanepisodeoftheBBCTVseries?Sherlock?(66\n",
      "mins).Theraiderdatasetwascollectedwhilesubjectsviewedthemovie?Raiders\n",
      "oftheLostArk?(110mins)andaseriesofstillimages(7categories,8runs).\n",
      "Theforrestdatasetwascollectedwhilesubjectslistenedtoanauditoryversion\n",
      "ofthe?ForrestGump?(120mins).Theaudiobookdatasetwascollected\n",
      "whilesubjectslistenedtoanarratedstory(15mins)withtwopossibleinterpre-\n",
      "tations.Halfofthesubjectshadapriorcontextfavoringoneinterpretation,the\n",
      "otherhalfhadapriorcontextfavoringtheotherinterpretation.Postscanning\n",
      "questionnairesshowednoincomprehensionbutat\n",
      "ininterpretationsbetweengroups.Experiment1:SRMandspatialsmoothing.\n",
      "Weusespatialsmoothingtodetermineifwecandetectasharedresponse\n",
      "inPMCforthesherlockdataset.Thesubjectsarerandomlypartitionedinto\n",
      "twoequalsizedgroups,thedataforeachgroupisaveraged,wecalculatethe\n",
      "Pearsoncorrelationovervoxelsbetweentheseaveragedresponsesforeachtime,\n",
      "thenaveragethesecorrelationsovertime.Thisisameasureofsimilarityofthe\n",
      "sequenceofbrainmapsinthetwoaverageresponses.Werepeatthisfore\n",
      "randomsubjectdivisionsandaveragetheresults.Ifthereisasharedresponse,\n",
      "weexpectapositiveaveragecorrelationbetweenthegroups,butiffunctional\n",
      "topographiestlyacrosssubjects,thiscorrelationmaybesmall.\n",
      "Iftheresultnotdistinctfromzero,asharedresponseisnotdetected.Thecom-\n",
      "putationyieldsthebenchmarkvalue0.26?0.006shownasthepurplebarinthe\n",
      "rightplotinFig.3.ThisissupportforasharedresponseinPMC,butweposit\n",
      "thatthesubject?sfunctionaltopographiesinPMCaremisaligned.Totestthis,\n",
      "weuseaGaussianwithwidthathalfheightof3,4,5and6mm,tospa-\n",
      "tiallysmootheachsubject?sfMRIdata,thenrecalculatetheaveragePearson\n",
      "correlationasdescribedabove.Theresults,shownasbluebarsinFig.3,indi-\n",
      "catehighercorrelationswithgreaterspatialsmoothing.Thisindicatesgreater\n",
      "averagecorrelationoftheresponsesatlowerspatialfrequencies,suggestinga\n",
      "scalemismatchoffunctionaltopographiesacrosssubjects.Wenowtest\n",
      "therobustnessofSRMusingtheunsmootheddata.Thesubjectsarerandomly\n",
      "partitionedintotwoequalsizedgroups.Thedataineachgroupisdividedin\n",
      "timeintotwohalves,andthesamehalfineachgroupisusedtolearnashared\n",
      "responsemodelforthegroup.TheindependentlyobtainedgrouptemplatesS1\n",
      ",S2,arethenregisteredusingak?korthogonalmatrixQ(methodoutlined\n",
      "in?2).Foreachgroup,thesecondhalfofthedataisprojectedtofeaturespace\n",
      "usingthesubject-spbasesandaveraged.ThenthePearsoncorrelation\n",
      "overfeaturesiscalculatedbetweenthegroupaveragedsharedresponses,and\n",
      "averagedovertime.Thisisrepeatedusingtheotherthehalvesofthesubject?s\n",
      "datafortrainingandtheresultsareaveraged.Theaverageresultsover5ran-\n",
      "8\n",
      "\n",
      "domsubjectdivisionsarereportasthegreenbarsinFig.3.Withk=813\n",
      "thereisnoreductionofdimensionandSRMachievesacorrelationequivalent\n",
      "to6mmspatialsmoothing.Thisstrongaveragecorrelationbetweengroups,\n",
      "suggestssomeformofsharedresponse.Asexpected,ifthedimensionofthe\n",
      "featurespacekisreduced,thecorrelationincreases.Asmallervalueofk,forces\n",
      "LearningSubjectSpBases\n",
      "half\n",
      "movie\n",
      "data\n",
      "subject\n",
      "1\n",
      "learn\n",
      "bases\n",
      "?\n",
      "subjectm\n",
      "Wm\n",
      "W1\n",
      "shared\n",
      "Group1\n",
      "response\n",
      "half\n",
      "movie\n",
      "data\n",
      "learn\n",
      "bases\n",
      "Q\n",
      "subject\n",
      "1\n",
      "?\n",
      "subjectm\n",
      "WmW1shared\n",
      "Group2\n",
      "response\n",
      "ComputingCorrelationbetweenGroups\n",
      "half\n",
      "movie\n",
      "data\n",
      "subject\n",
      "1\n",
      "project\n",
      "tobases\n",
      "?\n",
      "subjectm\n",
      "WmQTW1QTshared\n",
      "R\n",
      "Group1\n",
      "9\n",
      "\n",
      "response\n",
      "subject\n",
      "1\n",
      "?\n",
      "subjectm\n",
      "W1Wmshared\n",
      "Group2\n",
      "response\n",
      "Figure3:Experiment1.Left:Learnusinghalfofthedata,thencompute\n",
      "betweengroupcorrelationonotherhalf.Right:Pearsoncorrelationafterspatial\n",
      "smoothing,andSRMwithvariousk.Errorbars:?1stand.error.\n",
      "5\n",
      "LearningSubjectSpBases\n",
      "movie\n",
      "data\n",
      "subject1\n",
      "?\n",
      "subjectm-1\n",
      "W1\n",
      "learnbases\n",
      "Wm\n",
      "TR\n",
      "subjectm\n",
      "movie\n",
      "1\n",
      "Wm\n",
      "1\n",
      "2\n",
      "?\n",
      "9\n",
      "?\n",
      "train\n",
      "output\n",
      "subjectm-1\n",
      "Wm\n",
      "?\n",
      "\n",
      "?\n",
      "t\n",
      "+8\n",
      "t\n",
      "+9\n",
      "?\n",
      "subjectm-1\n",
      "subjectm\n",
      "Wm\n",
      "10\n",
      "\n",
      "1\n",
      "subjectm\n",
      "testing\n",
      "subject?s\n",
      "projected\n",
      "response\n",
      "seg1\n",
      "seg\n",
      "2\n",
      "?\n",
      "seg\n",
      "t-9\n",
      "shared\n",
      "response\n",
      "seg1\n",
      "seg\n",
      "2\n",
      "?\n",
      "seg\n",
      "t-9\n",
      "?\n",
      "segt\n",
      "?\n",
      "subject1\n",
      "t\n",
      "+1\n",
      "?\n",
      "W1\n",
      "t\n",
      "subject1\n",
      "t\n",
      "-1\n",
      "Segmentt-9\n",
      "overlappingsegment\n",
      "testingsegment\n",
      "overlappingsegment\n",
      "Segmentt+9\n",
      "TestingonHeld-outSubject\n",
      "projectto\n",
      "bases\n",
      "projected\n",
      "data\n",
      "?\n",
      "?\n",
      "sharedresponse\n",
      "(template)\n",
      "11\n",
      "\n",
      "imagedata/\n",
      "moviedata\n",
      "10\n",
      "segment1\n",
      "segment2\n",
      "Seg\n",
      "t+9\n",
      "?\n",
      "Seg\n",
      "t+9\n",
      "?\n",
      "test\n",
      "overlapping\n",
      "seg.excluded\n",
      "seg\n",
      "t\n",
      "overlapping\n",
      "seg.excluded\n",
      "Figure4:Left:Experiment2.Learnsubjectspbases.Testonheldout\n",
      "subjectanddata.Right:Experiment2.Timesegmentmatchingbycorrelating\n",
      "with9TRsegmentsinthesharedresponse.\n",
      "Figure5:Experiment2.Top:Comparisonof18stimesegment\n",
      "tiononthreedatasetsusingdistinctROIs.Bottom:(Left)SRMtimesegment\n",
      "accuracyvsk.(Right)Learnbasesfrommovieresponse,classify\n",
      "stimuluscategoryusingstillimageresponse.Forraiderandforrest,weconduct\n",
      "experimentonROIineachhemisphereseparatelyandthenaveragetheresults.\n",
      "Forsherlock,weconductexperimentoverwholePMC.TheTALresultsforthe\n",
      "raiderdatasetarefrom[10].Errorbars:?1stand.error.\n",
      "SRMtofocusonsharedfeaturesyieldingthebestdatarepresentationand\n",
      "givesgreaternoiserejection.Learning50featuresachievesa33%higheraver-\n",
      "agecorrelationinfeaturespacethanisachievedby6mmspatialsmoothingin\n",
      "voxelspace.AcommensurateimprovementoccurswhenSRMisappliedtothe\n",
      "spatiallysmootheddata.Experiment2:Timesegmentmatchingandimage\n",
      "WetestifthesharedresponseestimatedbySRMgeneralizesto\n",
      "newsubjectsandnewdatausingversionsoftwoexperimentsfrom[10](unlike\n",
      "in[10],heretheheldoutsubjectisnotincludedinlearningphase).The\n",
      "experimenttestsifan18stimesegmentfromaheld-outsubject?snewdatacan\n",
      "belocatedinthecorrespondingnewdataofthetrainingsubjects.Ashared\n",
      "responseandsubjectspbasesarelearnedusinghalfofthedata,andthe\n",
      "heldoutsubject?sbasisisestimatedusingthesharedresponseasatemplate.\n",
      "Thenarandom18stestsegmentfromtheunusedhalfoftheheldoutsubject?s\n",
      "dataisprojectedontothesubject?sbasis,andwelocatethe18ssegmentin\n",
      "theaveragedsharedresponseoftheothersubject?snewdatathatismaximally\n",
      "correlatedwiththetestsegment(seeFig.4).Theheldoutsubject?stestseg-\n",
      "mentiscorrectlylocated(matched)ifitscorrelationwiththeaverageshared\n",
      "responseatthesametimepointisthehighest;segmentsoverlappingwiththe\n",
      "12\n",
      "\n",
      "testsegmentareexcluded.Werecordtheaverageaccuracyandstandarderror\n",
      "bytwo-foldcross-validationoverthedatahalvesandleave-one-outoversub-\n",
      "jects.TheresultsusingthreetfMRIdatasetswithdistinctROIsare\n",
      "showninthetopplotofFig.5.Theaccuracyiscomparedusing:anatomical\n",
      "alignment(MNI[4],Talairach(TAL)[1]);standardPCA,andICAfeaturese-\n",
      "lection(FastICAimplementation[20]);theHyperalignment(HA)method[10];\n",
      "andSRM.PCAandICAaredirectlyappliedonjointdataTTmatrixXT\n",
      "=[X1T...Xm]forlearningWandS,whereX?WSandWT=[W1T\n",
      "...Wm].SRMdemonstratesthebestmatchingoftheestimatedshared\n",
      "temporalfeaturesofthemethodstested.Thissuggeststhatthelearnedshared\n",
      "responseismoreinformativeofthesharedbrainstatetrajectoryatan18stime\n",
      "scale.Moreover,theexperimentvgeneralizationoftheestimatedshared\n",
      "featurestosubjectsnotincludedinthetrainingphaseandnew(butsimilar)\n",
      "datacollectedduringtheotherhalfofthemoviestimulus.Sinceweexpect\n",
      "accuracytoimproveasthetimesegmentislengthened,\n",
      "6\n",
      "Group1!\n",
      "(c)!\n",
      "?!\n",
      "subjm!\n",
      "subj1!\n",
      "Group2!?!\n",
      "TR!\n",
      "sharedresponseacrossallsubjects!invoxelspace(k1)!\n",
      "TR!\n",
      "residual!\n",
      "shared!byall!\n",
      "sharedresponsewithingroup!invoxelspace(k2)!voxel!\n",
      "test!\n",
      "train!\n",
      "train!\n",
      "train!\n",
      "groupaccuracywithSRM!0.72?0.06!\n",
      "k1=3\n",
      "0.54?0.06!\n",
      "(c)!\n",
      "k1=3\n",
      "0.70?0.04!\n",
      "group1!\n",
      "(d)!\n",
      "sharedresponsewithingroup!invoxelspace(k2)!test!\n",
      "individual!\n",
      "(b)!\n",
      "group2!group1!\n",
      "TR!\n",
      "(d)!\n",
      "13\n",
      "\n",
      "withingroup!\n",
      "(a)!\n",
      "subjm!\n",
      "voxel!\n",
      "(b)!\n",
      "subj1!\n",
      "originaldata!\n",
      "voxel!\n",
      "(a)!\n",
      "voxel!\n",
      "TR!\n",
      "train!\n",
      "group2!\n",
      "k1=0k2=1000.72?0.04!k1=10k2=1000.82?0.04!\n",
      "Fig.6.2\n",
      "Fig.6.1\n",
      "Fig.6.3\n",
      "Figure6:Experiment3.Fig.6.1:Experimentalprocedure.Fig6.2:Data\n",
      "components(left)andgroupperformancewithSRM(right)in\n",
      "tstepsoftheprocedure.Fig.6.3:Grouponaudiobook\n",
      "datasetinDMNbeforeandafterremovinganestimatedsharedresponsefor\n",
      "variousvaluesofk1andk2withSRM,PCAandICA.Errorbars:?1stand.\n",
      "error.\n",
      "whatisimportantistherelativeaccuracyofthecomparedmethods.The\n",
      "methodin(1)canbeviewedasnon-probabilisticSRM.Inthisexperiment,it\n",
      "performsworsethanSRMbutbetterthantheothercomparedmethods.The\n",
      "ofthenumberoffeaturesusedinSRMisshowninFig.5,lowerleft.\n",
      "Thiscanbeusedtoselectk.Asimilartestonthenumberoffeaturesusedin\n",
      "PCAandICAindicateslowerperformancethanSRM(resultsnotshown).We\n",
      "nowusetheimageviewingdataandthemoviedatafromtheraiderdataset\n",
      "totestthegeneralizabilityofalearnedsharedresponsetoaheld-outsubject\n",
      "andnewdataunderaverydistinctstimulus.Theraidermoviedataisusedto\n",
      "learnasharedresponsemodel,whileexcludingaheld-outsubject.Theheld-\n",
      "outsubject?sbasisisestimatedbymatchingitsmovieresponsedatatothe\n",
      "estimatedsharedresponse.Theenessofthelearnedbasesisthentested\n",
      "usingtheimageviewingdataset[10].Afterprojectingtheimagedatausing\n",
      "thesubjectbasestofeaturespace,anSVMistrainedandtheaverage\n",
      "accuracyandstandarderrorisrecordedbyleave-one-outacrosssubject\n",
      "testing.Theresults,lowerrightplotinFig.5,supporttheenessofSRM\n",
      "ingeneralizingtoanewsubjectandadistinctnewstimulus.UnderSRM,the\n",
      "imagestimulicanbeslightlymoreaccuratelyidenusingothersubjects?\n",
      "datafortrainingthanusingasubject?sowndata,indicatingthatthelearned\n",
      "sharedresponseisinformativeofimagecategory.Experiment3:tiating\n",
      "betweengroups.NowconsidertheaudiobookdatasetandtheDMNROI.If\n",
      "subjectsaregivengrouplabelsaccordingtothetwopriorcontexts,alinear\n",
      "SVMtrainedonlabeledvoxelspacedataandtestedonthevoxel\n",
      "14\n",
      "\n",
      "spacedataofheldoutsubjects,candistinguishthetwogroupsatanabove\n",
      "chancelevel.ThisisshownastheleftmostbarinthebottomofFig.\n",
      "6.3.Thisisconsistentwithprevioussimilarstudies[28].WetestifSRMcan\n",
      "distinguishthetwosubjectgroupswithahigherrateofsuccess.Todosowe\n",
      "useg1g2theprocedureoutlinedinrowsofFig.6.1.Weusetheoriginal\n",
      "dataX1:m,X1:mofallsubjectsall(Fig.6.1(a))tolearnak1-dimensional\n",
      "sharedresponseSallandsubjectbasesWgj,1:m.Thissharedresponseisthen\n",
      "mappedtovoxelspaceusingeachsubject?slearnedtopography(Fig.6.1(b))\n",
      "andallsubtractedfromthesubject?sdatatoformtheresidualresponseXigj\n",
      "?Wgj,iSallforsubjectiingroupj(Fig.6.1(c)).Leavingoutonesubjectfrom\n",
      "eachgroup,weusetwowithin-groupapplicationsofg1g2,W1:mSRMto\n",
      "k2-dimensionalwithin-groupsharedresponsesSg1,Sg2,andsubjectbases\n",
      "W1:m\n",
      "7\n",
      "fortheresidualresponse.ThesearemappedintovoxelspaceWigjSgjfor\n",
      "eachsubject(Fig.6.1(d)).TheapplicationofSRMyieldsanestimate\n",
      "oftheresponsesharedbyallsubjects.Thisisusedtoformtheresidualre-\n",
      "sponse.Thesubsequentwithin-groupapplicationsofSRMtotheresidualgive\n",
      "estimatesofthewithin-groupsharedresidualresponse.Bothapplicationsof\n",
      "SRMseektoremovecomponentsoftheoriginalresponsethatareuninforma-\n",
      "tiveofgroupmembership.Finally,alinearSVMistrainedusingthe\n",
      "voxelspacegroup-labeleddata,andtestedonthevoxelspacedataofheldout\n",
      "subjects.TheresultsareshownastheredbarsinFig.6.3.Whenusingk1\n",
      "=10andk2=100,weobservetimprovementindistinguishingthe\n",
      "groups.OnecanvisualizewhythisworksusingthecartooninFig.6.2showing\n",
      "thedataforonesubjectmodeledasthesumofthreecomponents:theresponse\n",
      "sharedbyallsubjects,theresponsesharedbysubjectsinthesamegroupafter\n",
      "theresponsesharedbyallsubjectsisremoved,andaresidualtermcalled\n",
      "theindividualresponse(Fig.6.2(a)).Weidentifytheresponsesharedby\n",
      "allsubjects(Fig.6.2(b));subtractingthisfromthesubjectresponsegivesthe\n",
      "residual(Fig.6.2(c)).Thesecondwithin-groupapplicationofSRMremovesthe\n",
      "individualresponse(Fig.6.2(d)).Bytuningk1intherstapplicationofSRM\n",
      "andtuningk2inthesecondapplicationofSRM,weestimateandremovethe\n",
      "uninformativecomponentswhilekeepingtheinformativecomponent.C\n",
      "cationusingtheestimatedsharedresponse(k1?10)resultsinaccuracyaround\n",
      "chance(Fig.6.2(b)),indicatingthatitisuninformativefordistinguishingthe\n",
      "groups.Theaccuracyusingtheresidualresponseisstatistically\n",
      "equivalenttousingtheoriginaldata(Fig.6.2(c)),indicatingthatonlyremoving\n",
      "theresponsesharedbyallsubjectsistforimprovement.The\n",
      "cationaccuracythatresultsbynotremovingthesharedresponse(k1=0)and\n",
      "onlyapplyingwithin-groupSRM(Fig.6.2(d)),isalsostatisticallyequivalent\n",
      "tousingtheoriginaldata.Thisindicatesthatonlyremovingtheindividual\n",
      "responseisalsotforimprovement.Bycombiningbothapplications\n",
      "ofSRMweremoveboththeresponsesharedbyallsubjectsandtheindividual\n",
      "responses,keepingonlytheresponsessharedwithingroups.Fork1=10,k2=\n",
      "100,thisleadstotimprovementinperformance(Fig.6.2(d)andFig.\n",
      "15\n",
      "\n",
      "6.3).WeperformedthesameexperimentusingPCAandICA(Fig.6.3).In\n",
      "thiscase,afterremovingtheestimatedsharedresponse(k1?1)groupiden\n",
      "cationquicklydropstochancesincethesharedresponseisinformativeofgroup\n",
      "(around70%accuracyfordistinguishingthegroups(Sup.Mat.)).A\n",
      "detailedcomparisonofallthreemethodsonthetstepsoftheprocedure\n",
      "isgiveninthesupplementarymaterial.\n",
      "5\n",
      "DiscussionandConclusion\n",
      "ThevastmajorityoffMRIstudiesrequireaggregationofdataacrossindivid-\n",
      "uals.Byidentifyingsharedresponsesbetweenthebrainsoftindividuals,\n",
      "ourmodelenhancesfMRIanalysesthatuseaggregateddatatoevaluatecogni-\n",
      "tivestates.AkeyattributeofSRMisitsbuilt-indimensionalityreductionlead-\n",
      "ingtoareduced-dimensionsharedfeaturespace.Wehaveshownthatbytuning\n",
      "thisdimensionality,thedata-drivenaggregationachievedbySRMdemonstrates\n",
      "highersensitivityindistinguishingmultivariatefunctionalresponsesacrosscog-\n",
      "nitivestates.Thiswasshownacrossavarietyofdatasetsandanatomicalbrain\n",
      "regionsofinterest.Thisalsoopensthedoorfortheidencationofshared\n",
      "andindividualresponses.TheidenofsharedresponsesafterSRMis\n",
      "ofgreatinterest,asitallowsustoassessthedegreetowhichfunctionaltopog-\n",
      "raphyissharedacrosssubjects.Furthermore,theSRMallowsthedetection\n",
      "ofgroupspresponses.Thiswasdemonstratedbyremovinganestimated\n",
      "sharedresponsetoincreasesensitivityindetectinggroupWeposit\n",
      "thatthistechniquecanbeadaptedtoexamineanarrayofsituationswhere\n",
      "groupderencesarethekeyexperimentalvariable.Themethodcanfacilitate\n",
      "studiesofhowneuralrepresentationsarebycognitivemanipulations\n",
      "orbyfactorssuchasgenetics,clinicaldisorders,anddevelopment.Successful\n",
      "decodingofaparticularcognitivestate(suchasastimuluscategory)inagiven\n",
      "brainareaprovidesevidencethatinformationrelevanttothatcognitivestateis\n",
      "presentintheneuralactivityofthatbrainarea.Conductingsuchanalysesinlo-\n",
      "cationsspanningthebrain,e.g.,usingasearchlightapproach,canfacilitatethe\n",
      "discoveryofinformationpathways.Inaddition,comparisonofdecodingaccu-\n",
      "raciesbetweensearchlightscansuggestwhatkindofinformationispresentand\n",
      "whereitisconcentratedinthebrain.SRMprovidesamoresensitivemethod\n",
      "forconductingsuchinvestigations.Thismayalsohavedirectapplicationin\n",
      "designingbetternoninvasivebrain-computerinterfaces[29].\n",
      "8\n",
      "2References\n",
      "[1]J.TalairachandP.Tournoux.Co-planarstereotaxicatlasofthehuman\n",
      "brain.3-Dimensionalproportionalsystem:anapproachtocerebralimaging.\n",
      "Thieme,1988.[2]J.D.G.Watson,R.Myers,etal.AreaV5ofthehumanbrain:\n",
      "evidencefromacombinedstudyusingpositronemissiontomographyandmag-\n",
      "neticresonanceimaging.Cereb.Cortex,3:79?94,1993.[3]R.B.H.Tootell,\n",
      "J.B.Reppas,etal.VisualmotioninhumancorticalareaMTre-\n",
      "16\n",
      "\n",
      "vealedbyfunctionalmagneticresonanceimaging.Nature,375(6527):139?141,\n",
      "051995.[4]J.Mazziotta,A.Toga,etal.Aprobabilisticatlasandreference\n",
      "systemforthehumanbrain.PhilosophicalTransactionsoftheRoyalSociety\n",
      "B:BiologicalSciences,356(1412):1293?1322,2001.[5]B.Fischl,M.I.Sereno,\n",
      "R.B.H.Tootell,andA.M.Dale.High-resolutionintersubjectaveraginganda\n",
      "coordinatesystemforthecorticalsurface.Humanbrainmapping,8(4):272?284,\n",
      "1999.[6]M.Brett,I.S.Johnsrude,andA.M.Owen.Theproblemoffunctional\n",
      "localizationinthehumanbrain.NatRevNeurosci,3(3):243?249,032002.[7]\n",
      "M.R.Sabuncu,B.D.Singer,B.Conroy,R.E.Bryan,P.J.Ramadge,andJ.\n",
      "V.Haxby.Function-basedintersubjectalignmentofhumancorticalanatomy.\n",
      "CerebralCortex,20(1):130?140,2010.[8]B.R.Conroy,B.D.Singer,J.V.\n",
      "Haxby,andP.J.Ramadge.fMRI-basedinter-subjectcorticalalignmentusing\n",
      "functionalconnectivity.InAdvancesinNeuralInformationProcessingSystems,\n",
      "2009.[9]B.R.Conroy,B.D.Singer,J.S.Guntupalli,P.J.Ramadge,andJ.\n",
      "V.Haxby.Inter-subjectalignmentofhumancorticalanatomyusingfunctional\n",
      "connectivity.NeuroImage,2013.[10]J.V.Haxby,J.S.Guntupalli,etal.A\n",
      "common,high-dimensionalmodeloftherepresentationalspaceinhumanven-\n",
      "traltemporalcortex.Neuron,72(2):404?416,2011.[11]A.LorbertandP.J.\n",
      "Ramadge.Kernelhyperalignment.InAdv.inNeuralInform.Proc.Systems,\n",
      "2012.[12]A.G.Huth,T.L.F.E.Theunissen,andJ.L.Gallant.\n",
      "PrAGMATiC:aProbabilisticandGenerativeModelofAreasTilingtheCor-\n",
      "tex.ArXiv1504.03622,2015.[13]R.A.HornandC.R.Johnson.Matrix\n",
      "analysis.Cambridgeuniversitypress,2012.[14]A.Edelman,T.A.Arias,and\n",
      "S.TSmith.Thegeometryofalgorithmswithorthogonalityconstraints.SIAM\n",
      "journalonMatrixAnalysisandApplications,20(2):303?353,1998.[15]J.-H.\n",
      "AhnandJ.-H.Oh.AconstrainedEMalgorithmforprincipalcomponentanaly-\n",
      "sis.NeuralComputation,15(1):57?65,2003.[16]J.R.Manning,R.Ranganath,\n",
      "K.A.Norman,andD.M.Blei.Topographicfactoranalysis:abayesianmodel\n",
      "forinferringbrainnetworksfromneuraldata.PLoSOne,9(5):e94914,2014.\n",
      "[17]A.M.Michael,M.Anderson,etal.Preservingsubjectvariabilityingroup\n",
      "fMRIanalysis:performanceevaluationofGICAvs.IVA.Frontiersinsystems\n",
      "neuroscience,8,2014.[18]H.Xu,A.Lorbert,P.J.Ramadge,J.S.Guntupalli,\n",
      "andJ.V.Haxby.Regularizedhyperalignmentofmulti-setfMRIdata.InProc.\n",
      "StatisticalSignalProcessingWorkshop,pages229?232.IEEE,2012.[19]H.\n",
      "Hotelling.Relationsbetweentwosetsofvariates.Biometrika,28(3-4):321?377,\n",
      "1936.[20]A.Hyv?rinen,J.Karhunen,andE.Oja.Independentcomponent\n",
      "analysis.JohnWiley&Sons,2004.[21]J.Chen,Y.C.Leong,K.A.Norman,\n",
      "andU.Hasson.Reinstatementofneuralpatternsduringnarrativefreerecall.\n",
      "AbstractsoftheCognitiveNeuroscienceSociety,2014.[22]D.S.Margulies,\n",
      "J.L.Vincent,andetal.Precuneussharesintrinsicfunctionalarchitecture\n",
      "inhumansandmonkeys.ProceedingsoftheNationalAcademyofSciences,\n",
      "106(47):20069?20074,2009.[23]J.V.Haxby,M.I.Gobbini,M.L.Furey,A.\n",
      "Ishai,J.L.Schouten,andP.Pietrini.Distributedandoverlappingrepresenta-\n",
      "tionsoffacesandobjectsinventraltemporalcortex.Science,293(5539),2001.\n",
      "[24]M.Hanke,F.J.Baumgartner,etal.Ahigh-resolution7-TeslafMRIdataset\n",
      "fromcomplexnaturalstimulationwithanaudiomovie.ScienData,1,2014.\n",
      "17\n",
      "\n",
      "[25]T.D.andJ.D.Warren.Theplanumtemporaleasacomputa-\n",
      "tionalhub.Trendsinneurosciences,25(7):348?353,2002.[26]Y.Yeshurun,S.\n",
      "Swanson,J.Chen,E.Simony,C.Honey,P.C.Lazaridi,andU.Hasson.How\n",
      "doesthebrainrepresenttwaysofunderstandingthesamestory?Soci-\n",
      "etyforNeuroscienceAbstracts,2014.[27]M.E.Raichle.Thebrain?sdefault\n",
      "modenetwork.AnnualReviewofNeuroscience,38(1),2015.[28]D.L.Ames,\n",
      "C.J.Honey,M.Chow,A.Todorov,andU.Hasson.Contextualalignmentof\n",
      "cognitiveandneuraldynamics.Journalofcognitiveneuroscience,2014.[29]\n",
      "M.T.deBettencourt,J.D.Cohen,R.F.Lee,K.A.Norman,andN.B.Turk-\n",
      "Browne.Closed-looptrainingofattentionwithreal-timebrainimaging.Nature\n",
      "neuroscience,18(3):470?475,2015.\n",
      "9\n",
      "18\n",
      "\n",
      "PP5882.pdf\n",
      "PP5882.pdf 16\n",
      "InverseReinforcementLearningwithLocally\n",
      "ConsistentRewardFunctions\n",
      "Authoredby:\n",
      "PatrickJaillet\n",
      "QuocPhongNguyen\n",
      "BryanKianHsiangLow\n",
      "Abstract\n",
      "Existinginversereinforcementlearning(IRL)algorithmshaveassumed\n",
      "eachexpert?sdemonstratedtrajectorytobeproducedbyonlyasingle\n",
      "rewardfunction.ThispaperpresentsanovelgeneralizationoftheIRL\n",
      "problemthatallowseachtrajectorytobegeneratedbymultiplelocally\n",
      "consistentrewardfunctions,hencecateringtomorerealisticandcomplex\n",
      "experts?behaviors.SolvingourgeneralizedIRLproblemthusinvolves\n",
      "notonlylearningtheserewardfunctionsbutalsothestochastictransitions\n",
      "betweenthematanystate(includingunvisitedstates).Byrepresenting\n",
      "ourIRLproblemwithaprobabilisticgraphicalmodel,anexpectation-\n",
      "maximization(EM)algorithmcanbedevisedtoiterativelylearnthe\n",
      "trewardfunctionsandthestochastictransitionsbetweenthem\n",
      "inordertojointlyimprovethelikelihoodoftheexpert?sdemonstrated\n",
      "trajectories.Asaresult,themostlikelypartitionofatrajectoryinto\n",
      "segmentsthataregeneratedfromtlocallyconsistentrewardfunc-\n",
      "tionsselectedbyEMcanbederived.Empiricalevaluationonsynthetic\n",
      "andreal-worlddatasetsshowsthatourIRLalgorithmoutperformsthe\n",
      "state-of-the-artEMclusteringwithmaximumlikelihoodIRL,whichis,\n",
      "interestingly,areducedvariantofourapproach.\n",
      "1PaperBody\n",
      "ThereinforcementlearningprobleminMarkovdecisionprocesses(MDPs)in-\n",
      "volvesanagentusingitsobservedrewardstolearnanoptimalpolicythatmax-\n",
      "imizesitsexpectedtotalrewardforagiventask.However,suchobservedre-\n",
      "wardsortherewardfunctiongthemareoftennotavailablenorknownin\n",
      "manyreal-worldtasks.Theagentcanthereforelearnitsrewardfunctionfrom\n",
      "anexpertassociatedwiththegiventaskbyobservingtheexpert?sbehavioror\n",
      "demonstration,andthisapproachconstitutestheinversereinforcementlearning\n",
      "(IRL)problem.Unfortunately,theIRLproblemisill-posedbecause\n",
      "manyrewardfunctionsareconsistentwiththeexpert?sobservedbehavior.To\n",
      "1\n",
      "\n",
      "resolvethisissue,existingIRLalgorithmshaveproposedalternativechoices\n",
      "oftheagent?srewardfunctionthatminimizetdissimilaritymeasures\n",
      "usingvariousformsofabstractionsoftheagent?sgeneratedoptimal\n",
      "behaviorvs.theexpert?sobservedbehavior,asdiscussedbelow(see[17]\n",
      "foradetailedreview):(a)Theprojectionalgorithm[1]selectsarewardfunction\n",
      "thatminimizesthesquaredEuclideandistancebetweenthefeatureexpectations\n",
      "obtainedbyfollowingtheagent?sgeneratedoptimalpolicyandtheempirical\n",
      "featureexpectationsobservedfromtheexpert?sdemonstratedstate-actiontra-\n",
      "jectories;(b)themultiplicativeweightsalgorithmforapprenticelearning[24]\n",
      "adoptsarobustminimaxapproachtoderivingtheagent?sbehavior,whichis\n",
      "guaranteedtoperformnoworsethantheexpertandisequivalenttochoosing\n",
      "arewardfunctionthatminimizesthebetweentheexpectedaverage\n",
      "rewardundertheagent?sgeneratedoptimalpolicyandtheexpert?sempirical\n",
      "averagerewardapproximatedusingtheagent?srewardweights;(c)thelinear\n",
      "programmingapprenticelearningalgorithm[23]picksitsrewardfunctionby\n",
      "minimizingthesamedissimilaritymeasurebutincursmuchlesstimeempiri-\n",
      "cally;(d)thepolicymatchingalgorithm[16]aimstomatchtheagent?sgener-\n",
      "atedoptimalbehaviortotheexpert?sobservedbehaviorbychoosingareward\n",
      "functionthatminimizesthesumof1\n",
      "squaredEuclideandistancesbetweentheagent?sgeneratedoptimalpolicy\n",
      "andtheexpert?sestimatedpolicy(i.e.,fromitsdemonstratedtrajectories)over\n",
      "everypossiblestateweightedbyitsempiricalstatevisitationfrequency;(e)\n",
      "themaximumentropyIRL[27]andmaximumlikelihoodIRL(MLIRL)[2]al-\n",
      "gorithmsselectrewardfunctionsthatminimizeanempiricalapproximationof\n",
      "theKullbackLeiblerdivergencebetweenthedistributionsoftheagent?sand\n",
      "expert?sgeneratedstate-actiontrajectories,whichisequivalenttomaximizing\n",
      "theaveragelog-likelihoodoftheexpert?sdemonstratedtrajectories.Thelog-\n",
      "likelihoodformulationsofthemaximumentropyIRLandMLIRLalgorithms\n",
      "intheuseofsmoothingatthetrajectoryandactionlevels,respectively.\n",
      "Asaresult,theformer?slog-likelihoodordissimilaritymeasuredoesnotutilize\n",
      "theagent?sgeneratedoptimalpolicy,whichisconsequentlyquestionedby[17]\n",
      "astowhetheritisconsideredanIRLalgorithm.BayesianIRL[21]extendsIRL\n",
      "totheBayesiansettingbymaintainingadistributionoverallpossiblereward\n",
      "functionsandupdatingitusingBayesrulegiventheexpert?sdemonstrated\n",
      "trajectories.Theworkof[5]extendstheprojectionalgorithm[1]tohandlepar-\n",
      "tiallyobservableenvironmentsgiventheexpert?spolicy(i.e.,representedasa\n",
      "statecontroller)orobservation-actiontrajectories.AlltheIRLalgorithms\n",
      "describedabovehaveassumedthattheexpert?sdemonstratedtrajectoriesare\n",
      "onlygeneratedbyasinglerewardfunction.Torelaxthisrestrictiveassumption,\n",
      "therecentworksof[2,6]have,respectively,generalizedMLIRL(combiningit\n",
      "withexpectation-maximization(EM)clustering)andBayesianIRL(integrat-\n",
      "ingitwithaDirichletprocessmixturemodel)tohandletrajectoriesgenerated\n",
      "bymultiplerewardfunctions(e.g.,duetomanyintentions)inobservableenvi-\n",
      "ronments.But,eachtrajectoryisassumedtobeproducedbyasinglereward\n",
      "function.Inthispaper,weproposeanewgeneralizationoftheIRLproblem\n",
      "inobservableenvironments,whichisinspiredbyanopenquestionposedinthe\n",
      "2\n",
      "\n",
      "seminalworksofIRL[19,22]:Ifbehaviorisstronglyinconsistentwithopti-\n",
      "mality,canweidentify?locallyconsistent?rewardfunctionsforspregions\n",
      "instatespace?Suchaquestionimpliesthatnosinglerewardfunctionisglob-\n",
      "allyconsistentwiththeexpert?sbehavior,henceinvalidatingtheuseofallthe\n",
      "above-mentionedIRLalgorithms.Moreimportantly,multiplerewardfunctions\n",
      "maybelocallyconsistentwiththeexpert?sbehaviorintsegmentsalong\n",
      "itsstate-actiontrajectoryandtheexperthastoswitch/transitionbetweenthese\n",
      "locallyconsistentrewardfunctionsduringitsdemonstration.Thiscanbeob-\n",
      "servedinthefollowingreal-worldexample[26]whereeverypossibleintention\n",
      "oftheexpertisuniquelyrepresentedbyatrewardfunction:Adriver\n",
      "intendstotakethehighwaytoafoodcenterforlunch.Anelectronictollcom-\n",
      "ingintoonthehighwaymaychangehisintentiontoswitchtoanother\n",
      "route.Learningofthedriver?sintentionstousetroutesandhistransi-\n",
      "tionsbetweenthemallowsthetransportauthoritytoanalyze,understand,and\n",
      "predicttheroutepatternsandbehaviorforregulatingthetollcollec-\n",
      "tion.Thisexample,amongothers(e.g.,commuters?intentionstouset\n",
      "transportmodes,tourists?intentionstovisittattractions,Section4),\n",
      "motivatethepracticalneedtoformalizeandsolveourproposedgeneralizedIRL\n",
      "problem.ThispaperpresentsanovelgeneralizationoftheIRLproblemthat,\n",
      "inparticular,allowseachexpert?sstate-actiontrajectorytobegeneratedby\n",
      "multiplelocallyconsistentrewardfunctions,hencecateringtomorerealistic\n",
      "andcomplexexperts?behaviorsthanthatbyexistingvariantsofthe\n",
      "IRLproblem(whichallassumethateachtrajectoryisproducedbyasinglere-\n",
      "wardfunction)discussedearlier.Atglance,onemaystraightawayperceive\n",
      "ourgeneralizationasanIRLprobleminapartiallyobservableenvironmentby\n",
      "representingthechoiceoflocallyconsistentrewardfunctioninasegmentasa\n",
      "latentstatecomponent.However,theobservationmodelcannotbeeasilyspec-\n",
      "norlearnedfromtheexpert?sstate-actiontrajectories,whichinvalidates\n",
      "theuseofIRLforPOMDP[5].Instead,wedevelopaprobabilisticgraphical\n",
      "modelforrepresentingourgeneralizedIRLproblem(Section2),fromwhichan\n",
      "EMalgorithmcanbedevisedtoiterativelyselectthelocallyconsistentreward\n",
      "functionsaswellaslearnthestochastictransitionsbetweentheminorderto\n",
      "jointlyimprovethelikelihoodoftheexpert?sdemonstratedtrajectories(Section\n",
      "3).Asaresult,themostlikelypartitionofanexpert?sdemonstratedtrajectory\n",
      "intosegmentsthataregeneratedfromdrentlocallyconsistentrewardfunc-\n",
      "tionsselectedbyEMcanbederived(Section3),thusenablingpractitionersto\n",
      "identifystatesinwhichtheexperttransitionsbetweenlocallyconsistentreward\n",
      "functionsandinvestigatetheresultingcauses.Toextendsuchapartitioningto\n",
      "workfortrajectoriestraversingthroughany(possiblyunvisited)regionofthe\n",
      "statespace,weproposeusingageneralizedlinearmodeltorepresentandpredict\n",
      "thestochastictransitionsbetweenrewardfunctionsatanystate(i.e.,including\n",
      "statesnotvisitedintheexpert?sdemonstratedtrajectories)byexploitingfea-\n",
      "turesthatthesetransitions(Section2).Finally,ourproposedIRL\n",
      "algorithmisempiricallyevaluatedusingbothsyntheticandreal-worlddatasets\n",
      "(Section4).2\n",
      "2\n",
      "3\n",
      "\n",
      "ProblemFormulation\n",
      "AMarkovdecisionprocess(MDP)foranagentisasatuple(S,A,t,\n",
      "r?,)consistingofasetSofitspossiblestatessuchthateachstates2Sis\n",
      "associatedwithacolumnvectorsofrealizedfeaturemeasurements,aset\n",
      "Aofitspossibleactions,astatetransitionfunctiont:S?A?S![0,1]denoting\n",
      "theprobabilityt(s,a,s0),P(s0|s,a)ofmovingtostates0byperforming\n",
      "actionainstates,arewardfunctionr?:S!Rmappingeachstates2Stoits\n",
      "rewardr?(s),?>swhere?isacolumnvectorofrewardweights,andconstant\n",
      "factor2(0,1)discountingitsfuturerewards.When?isknown,theagentcan\n",
      "computeitspolicy??:S?A![0,1]specifyingtheprobability??(s,a),P\n",
      "(a|s,r?)ofperformingactionainstates.However,?isnotknowninIRL\n",
      "andtobelearnedfromanexpert(Section3).LetRdenoteasetoflocally\n",
      "consistentrewardfunctionsoftheagentandr?ebearewardfunctionchosen\n",
      "arbitrarilyfromRpriortolearning.atransitionfunction?!:R?S?R\n",
      "![0,1]forswitchingbetweentheserewardfunctionsastheprobability?!(r?\n",
      ",s,r?0),P(r?0|s,r?,!)ofswitchingfromrewardfunctionr?toreward\n",
      "functionr?0instateswheretheset!,\n",
      "f\n",
      "!r?r?0\n",
      "g\n",
      "r?2R,r?02R\n",
      "f\n",
      "r?e\n",
      "g\n",
      "contains\n",
      "columnvectorsoftransitionweights!r?r?0forallr?2Randr?02R\n",
      "f\n",
      "r?e\n",
      "g\n",
      "ifthefeaturesthestochastictransitionsbetweenrewardfunctions\n",
      "canbeadditionallyobservedbytheagentduringtheexpert?sdemonstration,\n",
      "and!,;otherwise.InourgeneralizedIRLproblem,?!isnotknownandtobe\n",
      "learnedfromtheexpert(Section3).Sp,intheformercase,wepropose\n",
      "usingageneralizedlinearmodeltorepresent?!:P?exp(!r>?r?0's)/(1+\n",
      "r??2R\n",
      "f\n",
      "re\n",
      "g\n",
      "exp(!r>?r??'s))ifr?06=r?e,?P?!(r?,s,r?0),(1)1/(1+\n",
      "r??2R\n",
      "f\n",
      "re\n",
      "g\n",
      "exp(!r>?r??'s))otherwise;?\n",
      "where'sisacolumnvectorofrandomfeaturemeasurementsthe\n",
      "stochastictransitionsbetweenrewardfunctions(i.e.,?!)instates.\n",
      "Remark1.tfromswhosefeaturemeasurementsaretypicallyas-\n",
      "sumedinIRLalgorithmstoberealized/knowntotheagentforalls2Sand\n",
      "remainstaticovertime,thefeaturemeasurementsof'sare,inpractice,oftennot\n",
      "knowntotheagentaprioriandcanonlybeobservedwhentheexpert(agent)\n",
      "visitsthecorrespondingstates2Sduringitsdemonstration(execution),and\n",
      "mayvaryovertimeaccordingtosomeunknowndistribution,asmotivatedby\n",
      "thereal-worldexamplesgiveninSection1.Withoutpriorobservationofthe\n",
      "featuremeasurementsof'sforalls2S(orknowledgeoftheirdistributions)\n",
      "necessaryforcomputing?!(1),theagentcannotconsiderexploiting?!for\n",
      "switchingbetweenrewardfunctionswithinMDPorPOMDPplanning,even\n",
      "afterlearningitsweights!;thiseliminatesthepossibilityofreducingourgener-\n",
      "alizedIRLproblemtoanequivalentconventionalIRLproblem(Section1)with\n",
      "onlyasinglerewardfunction(i.e.,comprisingamixtureoflocallyconsistent\n",
      "rewardfunctions).Furthermore,theobservationmodelcannotbeeasilyspeci-\n",
      "norlearnedfromtheexpert?strajectoriesofstates,actions,and's,which\n",
      "invalidatestheuseofIRLforPOMDP[5].Insteadofexploiting?!withinplan-\n",
      "ning,duringtheagent?sexecution,whenitvisitssomestatesandobservesthe\n",
      "featuremeasurementsof's,itcanthenuseandcompute?!forstatestoswitch\n",
      "betweenrewardfunctions,eachofwhichhasgeneratedaseparateMDPpolicy\n",
      "4\n",
      "\n",
      "priortoexecution,asillustratedinasimpleexampleinFig.1below.?!(r?0,s,\n",
      "r?0)?!(r?,s,r?)?!(r?,s,r?0)Remark2.Usingageneralizedlinearmodel\n",
      "torepresent?!(1)allowslearningofthestochastictransitionsbetweenreward\n",
      "functionsr?r?0(sp,bylearning!(Section3))tobegeneralizedacross\n",
      "tstates.Afterlearning,(1)canthenbeexploitedforpredicting?!(r?0\n",
      ",s,r?)thestochastictransitionsbetweenrewardfunctionsatanystate(i.e.,\n",
      "includingstatesnotvisitedintheexpert?sdemonstratedstate-actionFigure\n",
      "1:Transitionfunctrajectories).Consequently,theagentcanchoosetotraverse\n",
      "atrajec-tion?!ofanagentinstatestorythroughanyregion(i.e.,possibly\n",
      "notvisitedbytheexpert)oftheforswitchingbetweentwostatespaceduring\n",
      "itsexecutionandthemostlikelypartitionofitstra-rewardfunctionsr?and\n",
      "r?0jectoryintosegmentsthataregeneratedfromtlocallyconsis-with\n",
      "theirrespectivepolitentrewardfunctionsselectedbyEMcanstillbederived\n",
      "(Section3).cies??and??0generatedIncontrast,ifthefeaturemeasurements\n",
      "of'scannotbeobservedbypriortoexecution.theagentduringtheexpert?s\n",
      "demonstration(i.e.,!=;,asabove),thensuchageneralizationisnot\n",
      "possible;onlythetransitionprobabilitiesofswitchingbetweenrewardfunctions\n",
      "atstatesvisitedintheexpert?sdemonstratedtrajectoriescanbeestimated\n",
      "(Section3).Inpractice,sincethenumber|S|ofvisitedstatesisexpectedto\n",
      "bemuchlargerthanthelengthLofanyfeaturevector's,\n",
      "3\n",
      "thenumberO(|S||R|2)oftransitionprobabilitiestobeestimated\n",
      "isbiggerthan|!|=O(L|R|2)in(1).So,observing'safurther\n",
      "advantageofreducingthenumberofparameterstobelearned.Fig.2shows\n",
      "theprobabilisticgraphicalmodelforrepresentingourgeneralizedIRLproblem.\n",
      "Todescribeourmodel,somenotationsarenecessary:LetNbethenumberof\n",
      "theexpert?sdemonstratedtrajectoriesandTnbethelength(i.e.,numberof\n",
      "timesteps)ofitsn-thtrajectoryforn=1,...,N.Letr?tn2R,ant2\n",
      "A,andsnt2Sdenoteitsrewardfunction,action,andstateattimesteptin\n",
      "itsn-thtrajectory,respectively.LetR?tn,Ant,andStnberandomvariables\n",
      "correspondingtotheirrespectiverealizationsr?tn,ant,andsntwhereR?tn\n",
      "isalatentvariable,andAntandStnareobservablevariables.Dener?n,n\n",
      "nn(r?tn)Tt=0,an,(ant)Tt=1,andsn,(snt)Tt=1assequencesofallits\n",
      "rewardfunctions,actions,andstatesinitsn-thtrajectory,respectively.Finally,\n",
      "r?1:N,(r?n)Nn=1,1:NnNa1:N,(an)N,ands,(s)astuplesofall\n",
      "n=1n=1itsrewardfunctionsequences,actionsequences,andstatesequences\n",
      "initsNtrajectories,respectively.\n",
      "R?0n\n",
      "R?1n\n",
      "R?2n\n",
      "???\n",
      "R?Tnn\n",
      "An1\n",
      "An2\n",
      "???\n",
      "AnTn\n",
      "5\n",
      "\n",
      "S1n\n",
      "S2n\n",
      "???\n",
      "STnn\n",
      "Figure2:Probabilisticgraphicalmodeloftheexpert?sn-thdemonstrated\n",
      "trajectoryencodingitsstochastictransitionsbetweenrewardfunctionswith\n",
      "solidedges(i.e.,?!(r?tn1,snt,r?tn)=P(r?tn|snt,r?tn1,!)fort=1,..\n",
      ".,Tn),statetransitionswithdashededges(i.e.,t(snt,ant,snt+1)=P(snt+1\n",
      "|snt,ant)fort=1,...,Tn1),andpolicywithdottededges(i.e.,??tn(snt\n",
      ",ant)=ItcanbeobservedfromFig.2thatourprobabilisticgraph-P(an|sn\n",
      ",rn)fort=1,...,T).?tntticalmodeloftheexpert?sn-thdemonstrated\n",
      "trajectoryencodesitsstochastictransitionsbetweenrewardfunctions,state\n",
      "transitions,andpolicy.Throughourmodel,theViterbialgorithm[20]can\n",
      "beappliedtoderivethemostlikelypartitionoftheexpert?strajectoryinto\n",
      "segmentsthataregeneratedfromtlocallyconsistentrewardfunctions\n",
      "selectedbyEM,asshowninSection3.Giventhestatetransitionfunctiont(?,\n",
      "?,?)andthenumber|R|ofrewardfunctions,ourmodelallowstractable\n",
      "learningoftheunknownparametersusingEM(Section3),whichincludethe\n",
      "rewardweightsvector?forallrewardfunctionsr?2R,transitionfunction?!\n",
      "forswitchingbetweenrewardfunctions,initialstateprobabilities?(s),P(S1n\n",
      "=s)foralls2S,andinitialrewardfunctionprobabilities(r?),P(R?0n=r?\n",
      ")forallr?2R.\n",
      "3\n",
      "EMAlgorithmforParameterLearning\n",
      "Astraightforwardapproachtolearningtheunknownparameters?,(?,,\n",
      "f\n",
      "?|r?2R\n",
      "g\n",
      ",?!)istoselectthevalueof?thatdirectlymaximizesthelog-\n",
      "likelihoodoftheexpert?sdemonstratedtrajectories.Computationally,suchan\n",
      "approachisprohibitivelyexpensiveduetoalargejointparameterspacetobe\n",
      "searchedfortheoptimalvalueof?.Toeasethiscomputationalburden,ourkey\n",
      "ideaistodeviseanEMalgorithmthatiterativelytheestimatefor?to\n",
      "improvetheexpectedloglikelihoodinstead,whichisguaranteedtoimprovethe\n",
      "originallog-likelihoodbyatleastasmuch:PExpectation(E)step.Q(?,?i),\n",
      "r1:NP(r?1:N|s1:N,a1:N,?i)logP(r?1:N,s1:N,a1:N|?).?\n",
      "Maximization(M)step.?i+1=argmax?Q(?,?i)where?idenotesan\n",
      "estimatefor?atiterationi.TheQfunctionofEMcanbereducedtothe\n",
      "followingsumofeterms,asshowninAppendixA:PNPNP(2)Q(?,?i)\n",
      "=n=1log?(sn1)+n=1r?2RP(R?0n=r?|sn,an,?i)log(r?)PN\n",
      "PTnP(3)+n=1t=1r?2RP(R?tn=r?|sn,an,?i)log??(snt,ant)\n",
      "PNPTnPnnnin+n=1t=1r?,r?02RP(R?tn1=r?,st,R?tn=r?0\n",
      "|s,a,?)?log?!(r?,st,r?0)(4)PNPTn1(5)+n=1t=1logt(snt\n",
      ",ant,snt+1).Interestingly,eachofthefourtermsin(2),(3),and(4)\n",
      "containsauniqueunknownparametertype(respectively,?,,\n",
      "f\n",
      "?|r?2R\n",
      "g\n",
      ",and\n",
      "?!)andcanthereforebemaximizedseparatelyintheMsteptobediscussed\n",
      "below.Asaresult,theparameterspacetobesearchedcanbegreatlyreduced.\n",
      "Notethatthethirdterm(3)generalizesthelog-likelihoodinMLIRL[2](i.e.,\n",
      "assumingalltrajectoriestobeproducedbyasinglerewardfunction)tothat\n",
      "6\n",
      "\n",
      "allowingeachexpert?strajectorytobegeneratedbymultiplelocallyconsistent\n",
      "rewardfunctions.Thelastterm(5),whichcontainstheknownstatetransition\n",
      "functiont,isindependentofunknownparameters?.11\n",
      "Ifthestatetransitionfunctionisunknown,thenitcanbelearnedbyopti-\n",
      "mizingthelastterm(5).\n",
      "4\n",
      "Learninginitialstateprobabilities.TomaximizethePterminthe\n",
      "Qfunction(2)ofEM,weusethemethodofLagrangemultiplierswiththe\n",
      "constraints2S?(s)=1toobtaintheestimatePN?b(s)=(1/N)n=1I1nfor\n",
      "alls2SwhereI1nisanindicatorvariableofvalue1ifsn1=s,and0otherwise.\n",
      "Since?bcanbecomputeddirectlyfromtheexpert?sdemonstratedtrajectories\n",
      "inO(N)time,itdoesnothavetobeLearninginitialrewardfunction\n",
      "probabilities.TomaximizethesecondPterminQfunction(2)ofEM,we\n",
      "utilizethemethodofLagrangemultiplierswiththeconstraintr?2R(r?)=1\n",
      "toderivePNi+1(6)(r?i)=(1/N)n=1P(R?0n=r?|sn,an,?i)forallr?i\n",
      "2Rwherei+1denotesanestimateforatiterationi+1,?idenotesanestimate\n",
      "for?atPNiterationi,andP(R?tn=r?|sn,an,?i)(inthiscase,t=0)\n",
      "canbecomputedinO(n=1|R|2Tn)timeusingaprocedureinspiredby\n",
      "Baum-Welchalgorithm[3],asshowninAppendixB.\n",
      "Learningrewardfunctions.ThethirdtermintheQfunction(3)ofEMis\n",
      "maximizedusinggradientascentanditsgradientg1(?)withrespectto?is\n",
      "derivedtobeTnNXXP(R?tn=r?|sn,an,?i)d??(snt,ant)g1(?),\n",
      "(7)??(snt,ant)d?n=1t=1forall?2\n",
      "f\n",
      "?0|r?02R\n",
      "g\n",
      ".For??(snt,ant)to\n",
      "betiablein?,wetheQ?functionofMDPusinganoperatorthat\n",
      "blendstheQ?valuesviaBoltzmannexploration[2]:Q?(s,a),PP0000?>\n",
      "s+?(s,a)where?aQ?(s,a),s02St(s,a,s)?aQPa2AQ?(s,a)???\n",
      "(s,a)suchthat??(s,a),exp(Q?(s,a))/a02Aexp(Q?(s,a0))isas\n",
      "aBoltzmannexplorationpolicy,and>0isatemperatureparameter.Then,we\n",
      "update?i+1?i+g1(?i)whereisthelearningstepsize.Weusebacktracking\n",
      "linesearchmethodtoimprovetheperformanceofgradientascent.Similarto\n",
      "MLIRL,thetimeincurredineachiterationofgradientascentdependsmostly\n",
      "onthatofvalueiteration,whichincreaseswiththesizeoftheMDP?sstate\n",
      "andactionspace.Learningtransitionfunctionforswitchingbetweenreward\n",
      "functions.TomaximizethefourthtermintheQfunction(4)ofEM,ifthe\n",
      "featuremeasurementsof'scannotbeobservedbytheagentduringtheexpert?s\n",
      "demonstration(i.e.,!=;),thenweutilizethemethodofLagrangemultipliers\n",
      "Pwiththeconstraintsr?02R?!(r?,s,r?0)=1forallr?2Rands2Sto\n",
      "obtainPNPTnPPNPTn?!i+1(r?i,s,r?0i)=(n=1t=1(8)n,t,r?i,s,r?0i\n",
      ")/(r?i2Rn=1t=1n,t,r?i,s,r??i)?\n",
      "forr?i,r?0i2Rands2SwhereSisthesetofstatesvisitedbytheexpert,\n",
      "?!i+1isanestimatefor?!atiterationi+1,andn,t,r?i,s,r??i,P(R?tn1\n",
      "=r?,Stn=s,R?tn=r??|sn,an,?i)canbecomputedtlyby\n",
      "exploitingtheintermediateresultsfromevaluatingP(R?tn=r?|sn,an,\n",
      "?i)describedpreviously,asdetailedinAppendixB.Ontheotherhand,ifthe\n",
      "featuremeasurementsof'scanbeobservedbytheagentduringtheexpert?s\n",
      "demonstration,thenrecallthatweuseageneralizedlinearmodeltorepresent\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?!(1)(Section2)and!istheunknownparametertobeestimated.Similar\n",
      "tolearningtherewardweightsvector?forrewardfunctionr?,wemaximize\n",
      "thefourthterm(4)intheQfunctionofEMbyusinggradientascentandits\n",
      "gradientg2(!r?r?0)withrespectto!r?r?0isderivedtobeTnXNXnX?)\n",
      "n,t,r?,sn?d?!(r?,st,r?t,r?(9)g2(!r?r?0),n?(r,s,r)d!?!?tr?\n",
      "r?0?n=1t=1r??2R\n",
      "forall!r?r?02!.Let!ri?r?0denoteanestimatefor!r?r?0atiterationi.\n",
      "Then,itisupdatedusing!ri+1!ri?r?0+g2(!ri?r?0)whereisthelearning\n",
      "stepsize.Backtrackinglinesearch?r?0methodisalsousedtoimprovethe\n",
      "performanceofgradientascenthere.Inbothcases,thetimeincurredineach\n",
      "iterationiisproportionaltothenumberofn,t,r?i,s,r??itobecomputed,which\n",
      "isPNO(n=1|R|2|S|Tn)time.\n",
      "Viterbialgorithmforpartitioningatrajectoryintosegmentswitht\n",
      "locallyconsistentbb2R\n",
      "g\n",
      ",?!b)fortheunknownpab=(brewardfunctions.\n",
      "Giventhealestimate??,b,\n",
      "f\n",
      "?|r?rameters?producedbyEM,themost\n",
      "likelypartitionoftheexpert?sn-thdemonstratedtrajectorynintosegments\n",
      "generatedbytlocallyconsistentrewardfunctionsisr??n=(r??tn)Tt=0\n",
      ",nnnnb=argmaxrnP(r?n,s,a|?),bwhichcanbederivedusingthe\n",
      "argmaxr?nP(r?n|s,a,?)?Viterbialgorithm[20].Sp,\n",
      "vr?b,TforT=1,...,Tnastheprobabilityofthemost5\n",
      "likelyrewardfunctionsequence(r?tn)Tt=01fromtimesteps0toT1ending\n",
      "withrewardfunctionr?battimestepTthatproducestateandactionsequences\n",
      "(snt)Tt=1and(ant)Tt=1:bvr?b,T,max(r?n)T1P((r?tn)Tt=01,R?Tn\n",
      "=r?,(snt)Tt=1,(ant)Tt=1|?)tt=0=t(snT1,anT1,snT)??b(snT\n",
      ",anT)maxr?b0vr?b0,T1?!b(r?b0,snT,r?b),b=?b(sn)?b(sn,an)\n",
      "maxrb(rb0)?!b(rb0,sn,rb).vr,1,maxrnP(r?n,R?n=r?,sn,an\n",
      "|?)b?\n",
      "?0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "?\n",
      "1\n",
      "1\n",
      "b0?\n",
      "?\n",
      "?\n",
      "1\n",
      "?\n",
      "Then,r??n=argmaxr?b0b(r?b0)?!b(r?b0,sn1,r??n),r??n=argmaxr?b0\n",
      "vr?b0,T?!b(r?b0,snT+1,r??n)for01TT+1T=1,...,Tn1,and\n",
      "r??n=argmaxr?bvr?b,Tn.TheaboveViterbialgorithmcanbeappliedinthe\n",
      "Tnsamewaytopartitionanagent?strajectorytraversingthroughanyregion\n",
      "8\n",
      "\n",
      "(i.e.,possiblynotvisitedbytheexpert)ofthestatespaceduringitsexecution\n",
      "inO(|R|2T)time.\n",
      "4\n",
      "ExperimentsandDiscussion\n",
      "ThissectionevaluatestheempiricalperformanceofourIRLalgorithmus-\n",
      "ing3datasetsfeaturingexperts?demonstratedtrajectoriesintwosimulated\n",
      "gridworldsandreal-worldtaxitrajectories.Theaveragelog-likelihoodofthe\n",
      "expert?sdemonstratedtrajectoriesisusedastheperformancemetricbecauseit\n",
      "inherentlyaccountsfortheyofourIRLalgorithminlearningthelocally\n",
      "consistentrewardfunctions(i.e.,R)andthestochastictransitionsbetweenthem\n",
      "(i.e.,?!):PNtot(10)L(?),(1/Ntot)n=1logP(sn,an|?)whereNtot\n",
      "isthetotalnumberoftheexpert?sdemonstratedtrajectoriesavailableinthe\n",
      "dataset.Asprovenin[17],maximizingL(?)withrespectto?isequivalentto\n",
      "minimizinganempiricalapproximationoftheKullback-Leiblerdivergencebe-\n",
      "tweenthedistributionsoftheagent?sandexpert?sbproducedbyEM(Section\n",
      "3)generatedstate-actiontrajectories.Notethatwhentheestimate?nn\n",
      "bispluggedinto(10),theresultingP(s,a|?)in(10)canbecomputed-\n",
      "cientlyusingaproceduresimilartothatinSection3,asdetailedinAppendixC.\n",
      "Toavoidlocalmaximaingradientascent,weinitializeourEMalgorithmwith\n",
      "20random?0valuesandreportthebestresultbasedontheQvalueofEM\n",
      "(Section3).0123401234Todemonstratetheimportanceofmodelingand\n",
      "learningstochastictransitionsbetweenlocallyconsistentrewardfunctions,the\n",
      "performanceofourIRLalgorithmiscomparedwiththatofitsreducedvariant\n",
      "assumingnochange/switchingofrewardfunctionwithineachtrajectory,which\n",
      "isimplementedbyinitializing?!(r?,s,r?)=1forallr?2Rands2S\n",
      "anddeactivatingthelearningof?!.Infact,itcanbeshown(AppendixD)\n",
      "thatsuchareduction,interestingly,isequivalenttoEMclusteringwithMLIRL\n",
      "[2].So,ourIRLalgorithmgeneralizesEMclusteringwithMLIRL,thelatter\n",
      "ofwhichhasbeenempiricallydemonstratedin[2]tooutperformmanyexisting\n",
      "IRLalgorithms,asdiscussedinSection1.\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "O\n",
      "D\n",
      "O\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "D\n",
      "ABFigure3:GridworldsA(states(0,0),(1,1),and(2,2)are,respectively,\n",
      "examplesofwater,land,andobstacle),andB(state(2,2)isanexampleof\n",
      "9\n",
      "\n",
      "barrier).?O?and?D?denoteoriginanddestination.SimulatedgridworldA.\n",
      "Theenvironment(Fig.3)ismodeledasa5?5gridofstates,eachofwhich\n",
      "iseitherland,water,wateranddestination,orobstacleassociatedwiththe\n",
      "respectivefeaturevectors(i.e.,s)(0,1,0)>,(1,0,0)>,(1,0,1)>,and(0,0,\n",
      "0)>.Theexpertstartsatorigin(0,2)andanyofitsactionscanachievethe\n",
      "desiredstatewith0.85probability.Ithastwopossiblerewardfunctions,oneof\n",
      "whichpreferslandtowaterandgoingtodestination(i.e.,?=(0,20,30)>),\n",
      "andtheotherofwhichpreferswatertolandandgoingtodestination(i.e.,?0\n",
      "=(20,0,30)>).Theexpertwillonlyconsiderswitchingitsrewardfunctionat\n",
      "states(2,0)and(2,4)fromr?0tor?with0.5probabilityandfromr?tor?0\n",
      "with0.7probability;itsrewardfunctionremainsunchangedatallotherstates.\n",
      "Thefeaturemeasurementsof'scannotbeobservedbytheagentduringthe\n",
      "expert?sdemonstration.So,!=;and?!isestimatedusing(8).Wesetto0.95\n",
      "andthenumber|R|ofrewardfunctionsoftheagentto2.Fig.4ashows\n",
      "resultsoftheaveragelog-likelihoodL(10)achievedbyourIRLalgorithm,EM\n",
      "clusteringwithMLIRL,andtheexpertaveragedover4randominstanceswith\n",
      "varyingnumberNofexpert?sdemonstratedtrajectories.Itcanbeobserved\n",
      "thatourIRLalgorithmtlyoutperformsEMclusteringwithMLIRL\n",
      "andachievesaLperformanceclosetothatoftheexpert,especiallywhenN\n",
      "increases.Thiscanbeexplainedbyitsmodelingof?!anditshighdelityin\n",
      "learningandpredicting?!:WhileourIRLalgorithmallowsswitchingofreward\n",
      "functionwithineachtrajectory,EMclusteringwithMLIRLdoesnot.6\n",
      "Wealsoobservethattheaccuracyofestimatingthetransitionprobabilities?!\n",
      "(r?,s,.)(?!(r?0,s,.))using(8)dependsonthefrequencyanddistributionof\n",
      "trajectoriesdemonstratedbytheexpertwithitsrewardOurIRLalgorithmOur\n",
      "IRLalgorithmEMclusteringwithMLIRLEMclusteringwithMLIRLfunction\n",
      "R?tn1=r?(R?tn1=r?0)ExpertExpertnattimestept1anditsstatest\n",
      "=sNo.ofdemonstratedtrajectoriesNo.ofdemonstratedtrajectories(a)(b)\n",
      "attimestept,whichisexpected.ThosetransitionprobabilitiesthatFigure4:\n",
      "Graphsofaveragelog-likelihoodLachievedbyourarepoorlyestimateddueto\n",
      "fewrel-IRLalgorithm,EMclusteringwithMLIRL,andtheexpertvs.evant\n",
      "expert?sdemonstratedtrajec-numberNofexpert?sdemonstratedtrajectories\n",
      "insimulatedtories,however,donothurttheLgridworlds(a)A(Ntot=1500)\n",
      "and(b)B(Ntot=500).performanceofourIRLalgorithmbymuchbecause\n",
      "suchtrajectoriestendtohaveverylowprobabilityofbeingdemonstratedby\n",
      "theexpert.Inanycase,thisissuecanbemitigatedbyusingthegeneralized\n",
      "linearmodel(1)torepresent?!andobservingthefeaturemeasurementsof's\n",
      "necessaryforlearningandcomputing?!,asshownnext.?22\n",
      "?15\n",
      "Averagelog?likelihood\n",
      "Averagelog?likelihood\n",
      "?23\n",
      "?17\n",
      "?19\n",
      "?21\n",
      "?23\n",
      "10\n",
      "\n",
      "?24\n",
      "?25\n",
      "?26\n",
      "?27\n",
      "?28\n",
      "?25\n",
      "?29\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "SimulatedgridworldB.Theenvironment(Fig.3)isalsomodeledasa\n",
      "5?5gridofstates,eachofwhichiseithertheorigin,destination,orland\n",
      "associatedwiththerespectivefeaturevectors(i.e.>>>s)(0,1),(1,0),and\n",
      "(0,0).Theexpertstartsatorigin(4,0)andanyofitsactionscanachieve\n",
      "thedesiredstatewith0.85probability.Ithastwopossiblerewardfunctions,\n",
      "oneofwhichprefersgoingtodestination(i.e.,?=(30,0)>),andtheother\n",
      "ofwhichprefersreturningtoorigin(i.e.,?0=(0,30)>).Whilemovingtothe\n",
      "destination,theexpertwillencounterbarriersatsomestateswithcorresponding\n",
      "featurevectors's=(1,1)>andnobarriersatallotherstateswith's=(0,1)>\n",
      ";thesecondcomponentof'sisusedasanvalueinthegeneralizedlinear\n",
      "model(1).Theexpert?sbehaviorofswitchingbetweenrewardfunctionsis\n",
      "governedbyageneralizedlinearmodel?!(1)withr?e=r?0andtransition\n",
      "weights!r?r?=(11,12)>and!r?0r?=(13,12)>.Asaresult,itwill,for\n",
      "example,considerswitchingitsrewardfunctionatstateswithbarriersfromr?\n",
      "tor?0with0.269probability.Weestimate?!using(9)andsetto0.95and\n",
      "thenumber|R|ofrewardfunctionsoftheagentto2.Toassessthey\n",
      "oflearningandpredictingthestochastictransitionsbetweenrewardfunctions\n",
      "atunvisitedstates,weintentionallyremovealldemonstratedtrajectoriesthat\n",
      "visitstate(2,0)withabarrier.Fig.4bshowsresultsofL(10)performance\n",
      "achievedbyourIRLalgorithm,EMclusteringwithMLIRL,andtheexpert\n",
      "averagedover4randominstanceswithvaryingN.Itcanagainbeobserved\n",
      "thatourIRLalgorithmoutperformsEMclusteringwithMLIRLandachieves\n",
      "anLperformancecomparabletothatoftheexpertduetoitsmodelingof?!\n",
      "11\n",
      "\n",
      "anditshighyinlearningandpredicting?!:WhileourIRLalgorithm\n",
      "allowsswitchingofrewardfunctionwithineachtrajectory,EMclusteringwith\n",
      "MLIRLdoesnot.Besides,theestimatedtransitionfunction?!busing(9)is\n",
      "veryclosetothatoftheexpert,evenatunvisitedstate(2,0).So,unlikeusing\n",
      "(8),thelearningof?!with(9)canbegeneralizedwellacrosststates,\n",
      "thusallowing?!tobepredictedaccuratelyatanystate.Hence,wewillmodel\n",
      "?!with(1)andlearnitusing(9)inthenextexperiment.Real-worldtaxi\n",
      "trajectories.TheComforttaxicompanyinSingaporehasprovidedGPStraces\n",
      "of59taxiswiththesameoriginanddestinationthataremap-matched[18]\n",
      "ontoanetwork(i.e.,comprisinghighway,arterials,sliproads,etc)of193road\n",
      "segments(i.e.,states).Eachroadsegment/stateisspbya7-dimensional\n",
      "featurevectors:Eachofthesixcomponentsofsisanindicatordescribing\n",
      "whetheritbelongstoAlexandraRoad(AR),AyerRajahExpressway(AYE),\n",
      "DepotRoad(DR),HendersonRoad(HR),JalanBukitMerah(JBM),orLower\n",
      "DeltaRoad(LDR),whilethelastcomponentofsisthenormalizedshortest\n",
      "pathdistancefromtheroadsegmenttodestination.Weassumethatthe59\n",
      "map-matchedtrajectoriesaredemonstratedbytaxidriverswithacommonset\n",
      "Rof2rewardfunctionsandthesametransitionfunction?!(1)forswitching\n",
      "betweenrewardfunctions,thelatterofwhichisbythenormalized\n",
      "taxispeedconstitutingthecomponentof2-dimensionalfeaturevector's\n",
      ";thesecondcomponentof'sisusedasanofvalue1inthegeneralized\n",
      "linearmodel(1).Thenumber|R|ofrewardfunctionsissetto2because\n",
      "whenweexperimentwith|R|=3,twoofthelearnedrewardfunctionsare\n",
      "similar.Everydrivercandeterministicallymoveitstaxifromitscurrentroad\n",
      "segmenttothedesiredadjacentroadsegment.\n",
      "7\n",
      "1\n",
      "?4\n",
      "?b(r?,s,rb)!b?0?b(r?0,s,rb)!b?0\n",
      "?4.5\n",
      "0.8?5\n",
      "?5.5\n",
      "Probability\n",
      "Averagelog?likelihood\n",
      "Fig.5ashowsresultsofL(10)performanceachievedbyourIRLalgorithm\n",
      "andEMclusteringwithMLIRLaveragedover3randominstanceswithvarying\n",
      "N.OurIRLalgorithmoutperformsEMclusteringwithMLIRLduetoits\n",
      "modelingof?!anditshighyinlearningandpredicting?!.\n",
      "?6\n",
      "0.6\n",
      "0.4\n",
      "?6.5\n",
      "?7\n",
      "?8\n",
      "0.2\n",
      "OurIRLalgorithmEMclusteringwithMLIRL\n",
      "12\n",
      "\n",
      "?7.5\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "00\n",
      "60\n",
      "No.ofdemonstratedtrajectories\n",
      "0.2\n",
      "0.40.6Normalizedtaxispeed\n",
      "0.8\n",
      "1\n",
      "(a)(b)Figure5:Graphsof(a)averagelog-likelihoodLachievedbyourIRL\n",
      "algorithmandEMclusteringwithMLIRLvs.no.Noftaxitrajectories(Ntot\n",
      "=59)and(b)transitionprobabilitiesofswitchingbetweenrewardfunctionsvs.\n",
      "taxispeed.\n",
      "Toseethis,ourIRLalgorithmisabletolearnthatataxidriverislikely\n",
      "toswitchbetweenrewardfunctionsrepresentingtintentionswithinits\n",
      "demonstratedtrajectory:Rewardfunctionr?bdenoteshisintentionofdriving\n",
      "directlytothedestination(Fig.6a)duetoahugepenalty(i.e.,rewardweight\n",
      "-49)onbeingfarfromdestinationandalargereward(i.e.,rewardweight35.7)\n",
      "fortakingtheshortestpathfromorigintodestination,whichisviaJBM,while\n",
      "r?b0denoteshisintentionofdetouringtoDRorJBM(Fig.6b)duetolargere-\n",
      "wardsfortravelingonthem(respectively,rewardweights30.5and23.7).Asan\n",
      "example,Fig.6cshowsthemostlikelypartitionofademonstratedtrajectory\n",
      "intosegmentsgeneratedfromlocallyconsistentrewardfunctionsr?bandr?b0\n",
      ",whichisderivedusingourViterbialgorithm(Section3).Itcanbeobserved\n",
      "thatthedriverisinitiallyinr?b0onthesliproadexitingAYE,switchesfrom\n",
      "r?b0tor?buponturningintoARtodetourtoDR,andremainsinr?bwhile\n",
      "drivingalongDR,HR,andJBMtodestination.Ontheotherhand,thereward\n",
      "functionslearnedbyEMclusteringwithMLIRLarebothassociatedwithhis\n",
      "intentionofdrivingdirectlytodestination(i.e.,similartor?b);itisnotableto\n",
      "learnhisintentionofdetouringtoDRorJBM.Fig.5bshowstheof\n",
      "normalizedtaxispeed(i.e.,componentof's)ontheestimatedtransition\n",
      "function?!busing(9).Itcanbeobservedthatwhenthedriverisinr?b(i.e.,\n",
      "drivingdirectlytodestination),heisveryunlikelytochangehisintentionre-\n",
      "gardlessoftaxispeed.But,whenheisinr?b0(i.e.,detouringtoDRorJBM),\n",
      "heislikely(unlikely)toremaininthisintentioniftaxispeedislow(high).The\n",
      "demonstratedtrajectoryinFig.6cinfactsupportsthisobservation:Thedriver\n",
      "initiallyremainsinr?b0ontheupslopesliproadexitingAYE,whichcausesthe\n",
      "lowtaxispeed.UponturningintoARtodetourtoDR,heswitchesfromr?b0\n",
      "tor?bbecausehecandriveatrelativelyhighspeedonterrain.\n",
      "5\n",
      "O\n",
      "AR\n",
      "13\n",
      "\n",
      "JBMAYEHR\n",
      "DR\n",
      "LDR\n",
      "(a)\n",
      "D\n",
      "OAR\n",
      "JBMAYEHR\n",
      "DR\n",
      "DLDR\n",
      "(b)OJBM\n",
      "AR\n",
      "AYEDR\n",
      "HR\n",
      "(c)\n",
      "Conclusion\n",
      "LDR\n",
      "D\n",
      "Figure6:Reward(a)r?b(s)and(b)r?b0(s)foreachThispaperdescribesan\n",
      "EM-basedIRLal-roadsegmentswith?b=(7.4,3.9,16.3,20.3,35.7,gorithm\n",
      "thatcanlearnthemultiplereward>b0functionsbeinglocallyconsistentin\n",
      "21.5,49.0)>and?=(5.2,9.2,30.5,15.0,23.7,21.5,9.2)suchthatmore\n",
      "redroadsegmentsentsegmentsalongatrajectoryaswellasthegivehigher\n",
      "rewards.(c)Mostlikelypartitionofastochastictransitionsbetweenthem.It\n",
      "gendemonstratedtrajectoryfromorigin?O?todestinaeralizesEM-clustering\n",
      "withMLIRLandhastion?D?intoredandgreensegmentsgeneratedbybeen\n",
      "empiricallydemonstratedtooutperformrandr?b0,respectively.itonboth\n",
      "syntheticandreal-worlddatasets.?bForourfuturework,weplantoextend\n",
      "ourIRLalgorithmtocatertoanunknownnumberofrewardfunctions[6],\n",
      "nonlinearrewardfunctions[12]modeledbyGaussianprocesses[4,8,13,14,15,\n",
      "25],otherdissimilaritymeasuresdescribedinSection1,linearly-solvableMDPs\n",
      "[7],activelearningwithGaussianprocesses[11],andinteractionswithself-\n",
      "interestedagents[9,10].Acknowledgments.Thisworkwaspartiallysupported\n",
      "bySingapore-MITAllianceforResearchandTechnologySubawardAgreement\n",
      "No.52R-252-000-550-592.8\n",
      "2References\n",
      "[1]P.AbbeelandA.Y.Ng.Apprenticeshiplearningviainversereinforcement\n",
      "learning.InProc.ICML,2004.[2]M.Babes?-Vroman,V.Marivate,K.Sub-\n",
      "ramanian,andM.Littman.Apprenticeshiplearningaboutmultipleintentions.\n",
      "InProc.ICML,pages897?904,2011.[3]J.Bilmes.Agentletutorialofthe\n",
      "EMalgorithmanditsapplicationtoparameterestimationforGaussianmix-\n",
      "tureandHiddenMarkovmodels.TechnicalReportICSI-TR-97-02,University\n",
      "ofCalifornia,Berkeley,1998.[4]J.Chen,N.Cao,K.H.Low,R.Ouyang,C.\n",
      "K.-Y.Tan,andP.Jaillet.ParallelGaussianprocessregressionwithlow-rank\n",
      "14\n",
      "\n",
      "covariancematrixapproximations.InProc.UAI,pages152?161,2013.[5]J.\n",
      "ChoiandK.Kim.Inversereinforcementlearninginpartiallyobservableenvi-\n",
      "ronments.JMLR,12:691?730,2011.[6]J.ChoiandK.Kim.Nonparametric\n",
      "Bayesianinversereinforcementlearningformultiplerewardfunctions.InProc.\n",
      "NIPS,pages314?322,2012.[7]K.DvijothamandE.Todorov.Inverseoptimal\n",
      "controlwithlinearly-solvableMDPs.InProc.ICML,pages335?342,2010.[8]\n",
      "T.N.Hoang,Q.M.Hoang,andK.H.Low.Aunifyingframeworkofanytime\n",
      "sparseGaussianprocessregressionmodelswithstochasticvariationalinference\n",
      "forbigdata.InProc.ICML,pages569?578,2015.[9]T.N.HoangandK.H.\n",
      "Low.AgeneralframeworkforinteractingBayes-optimallywithself-interested\n",
      "agentsusingarbitraryparametricmodelandmodelprior.InProc.IJCAI,\n",
      "pages1394?1400,2013.[10]T.N.HoangandK.H.Low.InteractivePOMDP\n",
      "Lite:Towardspracticalplanningtopredictandexploitintentionsforinteract-\n",
      "ingwithself-interestedagents.InProc.IJCAI,pages2298?2305,2013.[11]\n",
      "T.N.Hoang,K.H.Low,P.Jaillet,andM.Kankanhalli.Nonmyopic?-Bayes-\n",
      "optimalactivelearningofGaussianprocesses.InProc.ICML,pages739?747,\n",
      "2014.[12]S.Levine,Z.Popovi?c,andV.Koltun.Nonlinearinversereinforce-\n",
      "mentlearningwithGaussianprocesses.InProc.NIPS,pages19?27,2011.[13]\n",
      "K.H.Low,J.Chen,T.N.Hoang,N.Xu,andP.Jaillet.Recentadvancesin\n",
      "scalingupGaussianprocesspredictivemodelsforlargespatiotemporaldata.In\n",
      "S.RavelaandA.Sandu,editors,Proc.DynamicData-drivenEnvironmental\n",
      "SystemsScienceConference(DyDESS?14).LNCS8964,Springer,2015.?ul.\n",
      "GeneralizedonlinesparseGaussianprocesses[14]K.H.Low,N.Xu,J.Chen,K.\n",
      "K.Lim,andE.B.Ozg?withapplicationtopersistentmobilerobotlocalization.\n",
      "InProc.ECML/PKDDNectarTrack,2014.[15]K.H.Low,J.Yu,J.Chen,\n",
      "andP.Jaillet.ParallelGaussianprocessregressionforbigdata:Low-rankrep-\n",
      "resentationmeetsMarkovapproximation.InProc.AAAI,pages2821?2827,\n",
      "2015.[16]G.NeuandC.Szepesv?ari.Apprenticeshiplearningusinginverse\n",
      "reinforcementlearningandgradientmethods.InProc.UAI,pages295?302,\n",
      "2007.[17]G.NeuandC.Szepesv?ari.Trainingparsersbyinversereinforce-\n",
      "mentlearning.MachineLearning,77(2?3):303?337,2009.[18]P.Newsonand\n",
      "J.Krumm.HiddenMarkovmapmatchingthroughnoiseandsparseness.In\n",
      "Proc.17thACMSIGSPATIALInternationalConferenceonAdvancesinGeo-\n",
      "graphicInformationSystems,pages336?343,2009.[19]A.Y.NgandS.Russell.\n",
      "Algorithmsforinversereinforcementlearning.InProc.ICML,2000.[20]L.\n",
      "R.Rabiner.AtutorialonhiddenMarkovmodelsandselectedapplicationsin\n",
      "speechrecognition.Proc.IEEE,77(2):257?286,1989.[21]D.Ramachandran\n",
      "andE.Amir.Bayesianinversereinforcementlearning.InProc.IJCAI,pages\n",
      "2586?2591,2007.[22]S.Russell.Learningagentsforuncertainenvironments.\n",
      "InProc.COLT,pages101?103,1998.[23]U.Syed,M.Bowling,andR.E.\n",
      "Schapire.Apprenticeshiplearningusinglinearprogramming.InProc.ICML,\n",
      "pages1032?1039,2008.[24]U.SyedandR.E.Schapire.Agame-theoretic\n",
      "approachtoapprenticeshiplearning.InProc.NIPS,pages1449?1456,2007.?\n",
      "ul.GP-Localize:Persistentmobilerobotlocalization[25]N.Xu,K.H.Low,\n",
      "J.Chen,K.K.Lim,andE.B.Ozg?usingonlinesparseGaussianprocessob-\n",
      "servationmodel.InProc.AAAI,pages2585?2592,2014.[26]J.Yu,K.H.\n",
      "15\n",
      "\n",
      "Low,A.Oran,andP.Jaillet.HierarchicalBayesiannonparametricapproach\n",
      "tomodelingandlearningthewisdomofcrowdsofurbanrouteplanning\n",
      "agents.InProc.IAT,pages478?485,2012.[27]B.D.Ziebart,A.Maas,J.A.\n",
      "Bagnell,andA.K.Dey.Maximumentropyinversereinforcementlearning.In\n",
      "Proc.AAAI,pages1433?1438,2008.\n",
      "9\n",
      "16\n",
      "\n",
      "PP4544.pdf\n",
      "PP4544.pdf 12\n",
      "LearningtheArchitectureofSum-Product\n",
      "NetworksUsingClusteringonVariables\n",
      "Authoredby:\n",
      "DanVentura\n",
      "AaronDennis\n",
      "Abstract\n",
      "Thesum-productnetwork(SPN)isarecently-proposeddeepmodel\n",
      "consistingofanetworkofsumandproductnodes,andhasbeenshown\n",
      "tobecompetitivewithstate-of-the-artdeepmodelsoncertain\n",
      "taskssuchasimagecompletion.DesigninganSPNnetworkarchitecture\n",
      "thatissuitableforthetaskathandisanopenquestion.Weproposean\n",
      "algorithmforlearningtheSPNarchitecturefromdata.Theideaisto\n",
      "clustervariables(asopposedtodatainstances)inordertoidentifyvari-\n",
      "ablesubsetsthatstronglyinteractwithoneanother.NodesintheSPN\n",
      "networkarethenallocatedtowardsexplainingtheseinteractions.Exper-\n",
      "imentalevidenceshowsthatlearningtheSPNarchitecturetly\n",
      "improvesitsperformancecomparedtousingapreviously-proposedstatic\n",
      "architecture.\n",
      "1PaperBody\n",
      "Thenumberofparametersinatextbookprobabilisticgraphicalmodel(PGM)\n",
      "isanexponentialfunctionofthenumberofparentsofthenodesinthegraph.\n",
      "Latentvariablescanoftenbeintroducedsuchthatthenumberofparentsisre-\n",
      "ducedwhilestillallowingtheprobabilitydistributiontoberepresented.Figure\n",
      "1showsanexampleofmodelingtherelationshipbetweensymptomsofaset\n",
      "ofdiseases.ThePGMatthelefthasnolatentvariablesandthePGMatthe\n",
      "righthasanappropriatelyadded?disease?variable.Themodelisabletobe\n",
      "becausethesymptomsarestatisticallyindependentofoneanother\n",
      "giventhedisease.ThemiddlePGMshowsamodelinwhichthelatentvariable\n",
      "isintroducedtonosimplifyingdemonstratingtheneedtobeintelligent\n",
      "aboutwhatlatentvariablesareaddedandhowtheyareadded.\n",
      "S1S2\n",
      "S3\n",
      "(a)\n",
      "S1\n",
      "1\n",
      "\n",
      "D\n",
      "S2\n",
      "S3\n",
      "(b)\n",
      "DS1\n",
      "S2\n",
      "S3\n",
      "(c)\n",
      "Figure1:Introducingalatentvariable.ThePGMin(a)hasnolatent\n",
      "variables.ThePGMin(b)hasalatentvariableintroducedtonob\n",
      "ThePGMin(c)hasalatentvariablethatthemodel.\n",
      "1\n",
      "DeepmodelscanbeinterpretedasPGMsthatintroducemultiplelayersof\n",
      "latentvariablesoveralayerofobservedvariables[1].Thearchitectureofthese\n",
      "latentvariables(thesizeofthelayers,thenumberofvariables,theconnections\n",
      "betweenvariables)candramaticallytheperformanceofthesemodels.\n",
      "Selectingareasonablearchitectureisoftendonebyhand.Thispaperproposes\n",
      "analgorithmthatautomaticallylearnsadeeparchitecturefromdataforasum-\n",
      "productnetwork(SPN),arecently-proposeddeepmodelthattakesadvantage\n",
      "ofthesimplifyingoflatentvariables[2].Learningtheappropri-\n",
      "+x\n",
      "+\n",
      "x\n",
      "+\n",
      "+\n",
      "+\n",
      "+\n",
      "?a\n",
      "?a\n",
      "?b\n",
      "?b\n",
      "A\n",
      "B\n",
      "x+\n",
      "Figure2:AsimpleSPNovertwobinaryvariablesAandB.Theleafnode?a\n",
      "takesvalue1ifA=0and0otherwisewhileleafnode?atakesvalue1ifA=1\n",
      "and0otherwise.IfthevalueofAisnotknownthenbothleafnodestakevalue\n",
      "1.Leafnodes?band?bbehavesimilarly.Weightsontheedgesconnectingsum\n",
      "nodeswiththeirchildrenarenotshown.TheshortdashededgecausestheSPN\n",
      "tobeincomplete.Thelong-dashededgecausestheSPNtobeinconsistent.\n",
      "x+\n",
      "+\n",
      "x+\n",
      "+\n",
      "+\n",
      "2\n",
      "\n",
      "Figure3:ThePoonarchitecturewithm=1sumnodesperregion.Three\n",
      "productnodesareintroducedbecausethe2?3-pixelimagepatchcanbesplitver-\n",
      "ticallyandhorizontallyinthreetways.IngeneralthePoonarchitecture\n",
      "hasnumber-of-splitstimesm2productnodesperregion.\n",
      "atearchitectureforatraditionaldeepmodelcanbechallenging[3,4],but\n",
      "thenatureofSPNslendthemselvestoaremarkablysimple,fast,ande\n",
      "architecture-learningalgorithm.InproposingSPNs,Poon&Domingosintro-\n",
      "duceageneralschemeforbuildinganinitialSPNarchitecture;theexperiments\n",
      "theyrunalluseoneparticularinstantiationofthisschemetobuildaninitial\n",
      "architecturethatissuitableforimagedata.Wewillrefertothisarchi-\n",
      "tectureasthePoonarchitecture.Trainingisdonebylearningtheparameters\n",
      "ofaninitialSPN;aftertrainingiscomplete,partsoftheSPNmaybepruned\n",
      "toproduceaSPNarchitecture.Inthiswayboththeweightsandarchi-\n",
      "tecturearelearnedfromdata.Wetakethisastepfurtherbyalsolearningthe\n",
      "initialSPNarchitecturefromdata.Ouralgorithmworksbygsubsetsof\n",
      "variables(andsetsofsubsetsofvariables)thatarehighlydependentandthen\n",
      "elycombiningthesetogetherunderasetoflatentvariables.Thisencour-\n",
      "agesthelatentvariablestoactasmediatorsbetweenthevariables,capturing\n",
      "andrepresentingthedependenciesbetweenthem.Ourexperimentsshowthat\n",
      "learningtheinitialSPNarchitectureinthiswayimprovesitsperformance.\n",
      "2\n",
      "Sum-ProductNetworks\n",
      "Sum-productnetworksarerooted,directedacyclicgraphs(DAGs)ofsum,\n",
      "product,andleafnodes.Edgesconnectingsumnodestotheirchildrenare\n",
      "weightedusingnon-negativeweights.Thevalueofasumnodeiscomputedas\n",
      "thedotproductofitsweightswiththevaluesofitchildnodes.Thevalueof\n",
      "aproductnodeiscomputedbymultiplyingthevaluesofitschildnodes.A\n",
      "simpleSPNisshowninFigure2.Leafnodevaluesaredeterminedbytheinput\n",
      "totheSPN.Eachinputvariablehasanassociatedsetofleafnodes,onefor\n",
      "eachvaluethevariablecantake.Forexample,abinaryvariablewouldhave\n",
      "twoassociatedleafnodes.Theleafnodesactasindicatorfunctions,takingthe\n",
      "value1whenthevariabletakesonthevaluethattheleafnodeisresponsible\n",
      "forand0otherwise.AnSPNcanbeconstructedsuchthatitisarepresentation\n",
      "ofsomeprobabilitydistribution,withthevalueofitsrootnodeandcertain\n",
      "partialderivativeswithrespecttotherootnodehavingprobabilisticmeaning.\n",
      "Inparticular,allmarginalprobabilitiesandmanyconditionalprobabilitiescan\n",
      "becomputed[5].ConsequentlyanSPNcanperformexactinferenceanddoes\n",
      "sotlywhenthesizeoftheSPNispolynomialinthenumberofvariables.\n",
      "2\n",
      "IfanSPNdoesrepresentaprobabilitydistributionthenwecallitavalid\n",
      "SPN;ofcourse,notallSPNsarevalid,nordotheyallfacilitatet,exact\n",
      "inference.However,Poon&Domingosprovedthatifthearchitectureofan\n",
      "SPNfollowstwosimplerulesthenitwillbevalid.(Notethatthisrelationship\n",
      "doesnotgobothways;anSPNmaybevalidandviolateoneorbothofthese\n",
      "rules.)This,alongwithshowingthatSPNscanrepresentabroaderclassof\n",
      "distributionsthanothermodelsthatallowfortandexactinferenceare\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thekeycontributionsmadebyPoon&Domingos.Tounderstandtheserulesit\n",
      "willhelptoknowwhatthe?scopeofanSPNnode?means.Thescopeofan\n",
      "SPNnodenisasubsetoftheinputvariables.Thissubsetcanbedeterminedby\n",
      "lookingattheleafnodesofthesubgraphrootedatn.Allinputvariablesthat\n",
      "haveoneormoreoftheirassociatedleafnodesinthissubgraphareincluded\n",
      "inthescopeofthenode.Wewilldenotethescopeofnasscope(n).The\n",
      "ruleisthatallchildrenofasumnodemusthavethesamescope.Suchan\n",
      "SPNiscalledcomplete.Thesecondruleisthatforeverypairofchildren,(ci\n",
      ",cj),ofaproductnode,theremustnotbecontradictoryleafnodesinthe\n",
      "subgraphsrootedatciandcj.Forexample,iftheleafnodecorresponding\n",
      "tothevariableXtakingonvaluexisinthesubgraphrootedatci,thenthe\n",
      "leafnodescorrespondingtothevariableXtakingonanyothervaluemaynot\n",
      "appearinthesubgraphrootedatcj.AnSPNfollowingthisruleiscalled\n",
      "consistent.TheSPNinFigure2violatescompleteness(duetotheshort-dashed\n",
      "arrow)anditviolatesconsistency(duetothelong-dashedarrow).AnSPN\n",
      "mayalsobedecomposable,whichisapropertysimilarto,butsomewhatmore\n",
      "restrictivethanconsistency.AdecomposableSPNisoneinwhichthescopesof\n",
      "thechildrenofeachproductnodearedisjoint.Allofthearchitecturesdescribed\n",
      "inthispaperaredecomposable.VerydeepSPNscanbebuiltusingtheserules\n",
      "asaguide.ThenumberoflayersinanSPNcanbeontheorderoftensof\n",
      "layers,whereasthetypicaldeepmodelhasthreetoelayers.Recentlyitwas\n",
      "shownthatdeepSPNscancomputesomefunctionsusingexponentiallyfewer\n",
      "resourcesthanshallowSPNswouldneed[6].ThePoonarchitectureissuited\n",
      "formodelingprobabilitydistributionsoverimages,orotherdomainswithlocal\n",
      "dependenciesamongvariables.Itisconstructedasfollows.Foreverypossible\n",
      "axisalignedrectangularregionintheimage,thePoonarchitectureincludesa\n",
      "setofmsumnodes,allofwhosescopeisthesetofvariablesassociatedwiththe\n",
      "pixelsinthatregion.Eachofthese(nonsingle-pixel)regionsareconceptually\n",
      "splitverticallyandhorizontallyinallpossiblewaystoformpairsofrectangular\n",
      "subregions.Foreachpairofsubregions,andforeverypossiblepairingofsum\n",
      "nodes(onetakenfromeachsubregion),aproductnodeisintroducedandmade\n",
      "theparentofthepairofsumnodes.Theproductnodeisalsoaddedasachild\n",
      "toallofthetopregion?ssumnodes.Figure3showsafragmentofaPoon\n",
      "architectureSPNmodelinga2?3imagepatch.\n",
      "3\n",
      "ClusterArchitecture\n",
      "Asmentionedearlier,careneedstobetakenwhenintroducinglatentvari-\n",
      "ablesintoamodel.Sincetheofalatentvariableistohelpexplainthe\n",
      "interactionsbetweenitschildvariables[7],itmakeslittlesensetoaddalatent\n",
      "variableastheparentoftwostatisticallyindependentvariables.Intheexample\n",
      "inFigure4,variablesWandXstronglyinteractandvariablesYandZdoas\n",
      "well.Buttherelationshipbetweenallotherpairsofvariablesisweak.The\n",
      "PGMin(a),therefore,allowslatentvariableAtotakeaccountoftheinterac-\n",
      "tionbetweenWandX.Ontheotherhand,variableAdoeslittleinthePGM\n",
      "in(b)sinceWandYarenearlyindependent.Asimilarargumentcanbemade\n",
      "aboutvariableB.Consequently,variableCinthePGMin(a)canbeusedto\n",
      "4\n",
      "\n",
      "explaintheweakinteractionsbetweenvariables,whereasinthePGMin(b),\n",
      "variableCessentiallyhasthetaskofexplainingtheinteractionbetweenallthe\n",
      "variables.\n",
      "C\n",
      "C\n",
      "AW\n",
      "BX\n",
      "Y\n",
      "(a)\n",
      "Z\n",
      "W\n",
      "A\n",
      "B\n",
      "X\n",
      "Y\n",
      "Z\n",
      "(b)\n",
      "Figure4:Latentvariablesexplaintheinteractionbetweenchildvariables,\n",
      "causingthechildrentobeindependentgiventhelatentvariableparent.If\n",
      "variablepairs(W,X)and(Y,Z)stronglyinteractandothervariablepairsdo\n",
      "not,thenthePGMin(a)isamoresuitablemodelthanthePGMin(b).3\n",
      "IntheprobabilisticinterpretationofanSPN,sumnodesareassociatedwith\n",
      "latentvariables.(Theevaluationofasumnodeisequivalenttosummingoutits\n",
      "associatedlatentvariable.)EachlatentvariablehelpstheSPNexplaininterac-\n",
      "tionsbetweenvariablesinthescopeofthesumnodes.Justasintheexample,\n",
      "then,wewouldliketoplacesumnodesoversetsofvariableswithstronginter-\n",
      "actions.ThePoonarchitecturetakesthisprincipleintoaccount.Imagesexhibit\n",
      "stronginteractionsbetweenpixelsinlocalspatialneighborhoods.Takingad-\n",
      "vantageofthispriorknowledge,thePoonarchitecturechoosestoplacesum\n",
      "nodesoverlocalspatialneighborhoodsthatarerectangularinshape.There\n",
      "areafewpotentialproblemswiththisapproach,however.Oneisthatthe\n",
      "Poonarchitectureincludesmanyrectangularregionsthatarelongandskinny.\n",
      "Thismeansthatthepixelsateachendoftheseregionsaregroupedtogether\n",
      "eventhoughtheyprobablyhaveonlyweakinteractions.Somegroupingof\n",
      "weakly-interactingpixelsisinevitable,butthePoonarchitectureprobablydoes\n",
      "thismorethanisneeded.AnotherproblemisthatthePoonarchitecturehas\n",
      "nowayofexplainingstrongly-interacting,non-rectangularlocalspatialregions.\n",
      "Thisisamajorproblembecausesuchregionsareverycommoninimages.Ad-\n",
      "ditionally,ifthedatadoesnotexhibitstrongspatially-localinteractionsthen\n",
      "thePoonarchitecturecouldperformpoorly.Ourproposedarchitecture(wewill\n",
      "callittheclusterarchitecture)avoidstheseproblems.Largeregionscontaining\n",
      "non-interactingpixelsareavoided.Sumnodescanbeplacedoverspatially-local,\n",
      "non-rectangularregions;wearenotrestrictedtorectangularregions,butcan\n",
      "explainarbitrarilyshapedblob-likeregions.Infact,theregionsfoundbythe\n",
      "clusterarchitecturearenotrequiredtoexhibitspatiallocality.Thismakesour\n",
      "5\n",
      "\n",
      "architecturesuitableformodelingdatathatdoesnotexhibitstrongspatially-\n",
      "localinteractionsbetweenvariables.3.1\n",
      "BuildingaClusterArchitecture\n",
      "Aswasdescribedearlier,asumnodesinanSPNhasthetaskofexplaining\n",
      "theinteractionsbetweenallthevariablesinitsscope.Letscope(s)=\n",
      "f\n",
      "V1,?\n",
      "??,Vn\n",
      "g\n",
      ".Ifnislarge,thenthistaskwilllikelybeverySPNshave\n",
      "amechanismformakingiteasier,however.Essentially,sdelegatespartofits\n",
      "responsibilitiestoanothersetofsumnodes.ThisisdonebySforming\n",
      "apartitionofscope(s),where\n",
      "f\n",
      "S1,???,Sk\n",
      "g\n",
      "isapartitionofscope(s)\n",
      "ifandonlyifiSi=scope(s)and?i,j(Si?Sj=?).Then,foreachsubset\n",
      "Siinthepartition,anadditionalsumnodesiisintroducedintotheSPNand\n",
      "isgiventhetaskofexplainingtheinteractionsbetweenallthevariablesinSi\n",
      ".Theoriginalsumnodesisthengivenanewchildproductnodepandthe\n",
      "productnodebecomestheparentofeachsumnodesi.Inthisexamplethe\n",
      "nodesisanalogoustothevariableCinFigure4andthenodessiareanalogous\n",
      "tothevariablesAandB.Sothispartitioningprocessallowsstofocuson\n",
      "explainingtheinteractionsbetweenthenodessiandfreesitfromneedingto\n",
      "explaineverythingabouttheinteractionsbetweenthevariables\n",
      "f\n",
      "V1,???\n",
      ",Vn\n",
      "g\n",
      ".And,ofcourse,thepartitioningprocesscanberepeatedrecursively,\n",
      "withanyofthenodessitakingtheplaceofs.Thisisthemainideabehindthe\n",
      "algorithmforbuildingaclusterarchitecture(seeAlgorithm1andAlgorithm2).\n",
      "However,duetothearchitecturalyofanSPN,discussingthisalgorithm\n",
      "intermsofsumandproductnodesquicklybecomestediousandconfusing.The\n",
      "followingwillhelpinthisregard.1.Aregiongraphisa\n",
      "rootedDAGconsistingofregionnodesandpartitionnodes.Therootnodeis\n",
      "aregionnode.Partitionnodesarerestrictedtobeingthechildrenofregion\n",
      "nodesandviceversa.Regionandpartitionnodeshavescopesjustlikenodesin\n",
      "anSPN.Thescopeofanodeninaregiongraphisdenotedscope(n).Region\n",
      "nodescanbethoughtofasplayingtheroleofsumnodes(explaininginteractions\n",
      "amongvariables)andpartitionnodescanbethoughtofasplayingtheroleof\n",
      "productnodes(delegatingresponsibilities).Usingtheoftheregion\n",
      "graphmaynotappeartohavemadethingsanysimpler,butitsbwill\n",
      "becomemoreclearwhendiscussingtheconversionofregiongraphstoSPNs\n",
      "(seeFigure5).Atahighlevelthealgorithmforbuildingaclusterarchitecture\n",
      "issimple:buildaregiongraph(Algorithm1andAlgorithm2),thenconvertit\n",
      "toanSPN(Algorithm3).Thesestepsaredescribedbelow.4\n",
      "R1\n",
      "Algorithm1BuildRegionGraph1:2:3:4:5:6:7:8:9:10:11:12:13:\n",
      "Input:trainingdataDC0?Cluster(D,1)fork=2to?doC?Cluster(D,\n",
      "k)r?Quality(C)/Quality(C0)ifr<1+?thenbreakelseC0?CG?\n",
      "CreateRegionGraph()n?AddRegionNodeTo(G)fori=1tokdoExpandRe-\n",
      "gionGraph(G,n,Ci)\n",
      "x\n",
      "P1x\n",
      "+\n",
      "+\n",
      "6\n",
      "\n",
      "x\n",
      "x\n",
      "x\n",
      "P2x\n",
      "x\n",
      "x\n",
      "R1\n",
      "R2R2\n",
      "R3\n",
      "R4\n",
      "(a)\n",
      "R5\n",
      "x\n",
      "+\n",
      "+...x\n",
      "R3x\n",
      "+\n",
      "+\n",
      "+\n",
      "...x\n",
      "x\n",
      "+\n",
      "+\n",
      "R4\n",
      "...x\n",
      "x\n",
      "+\n",
      "R5\n",
      "...x\n",
      "(b)\n",
      "Figure5:re(a)showsaregiongraphfragmentconsistingofregion\n",
      "nodesR1,R2,R3,R4,andR5.R1hastwoparitionnodes(thesmaller,\n",
      "nodes).(b)showstheregiongraphconvertedtoanSPN.\n",
      "IntheSPNeachregionisallottedtwosumnodes.TheproductnodesinR1\n",
      "aresurroundedbytworectangleslabeledP1andP2;theycorrespondtothe\n",
      "partitionnodesintheregiongraph.\n",
      "Algorithm1buildsaregiongraphusingtrainingdatatoguidetheconstruc-\n",
      "tion.Inlines2through9thealgorithmclustersthetraininginstancesintok\n",
      "clustersC=\n",
      "f\n",
      "C1,???,Ck\n",
      "g\n",
      ".Ourimplementationusesthescikit-learn\n",
      "[8]implementationofk-meanstoclusterthedatainstances,butanyclustering\n",
      "methodcouldbeused.Thevalueforkischosenautomatically;largerval-\n",
      "uesofkaretrieduntilincreasingthevaluedoesnotsubstantiallyimprovea\n",
      "cluster-qualityscore.Theremainderofthealgorithmcreatesasingle-nodere-\n",
      "giongraphGandthenaddsnodesandedgestoGusingkcallstoAlgorithm\n",
      "2(ExpandRegionGraph).ToencouragetheexpansionofGintways,\n",
      "atsubsetofthetrainingdata,Ci,ispassedtoExpandRegionGraph\n",
      "7\n",
      "\n",
      "oneachcall.Atahighlevel,Algorithm2partitionsscopesintosub-scopes\n",
      "recursively,addingregionandpartitionnodestoGalongtheway.Theinitial\n",
      "calltoExpandRegionGraphpartitionsthescopeoftherootregionnode.A\n",
      "correspondingpartitionnodeisaddedasachildoftherootnode.Twosub-\n",
      "regionnodes(whosescopesformthepartition)arethenaddedaschildrento\n",
      "thepartitionnode.Algorithm2isthencalledrecursivelywitheachofthese\n",
      "sub-regionnodesasarguments(unlessthescopeofthesub-regionnodeistoo\n",
      "small).Inline3ofAlgorithm2thePartitionScopefunctioninourimplemen-\n",
      "tationusesthek-meansalgorithminanunusualway.Insteadofpartitioning\n",
      "theinstancesofthetrainingdatasetDintokinstance-clusters,itpartitions\n",
      "variablesintokvariable-clustersasfollows.Disencodedasamatrix,each\n",
      "rowbeingadatainstanceandeachcolumncorrespondingtoavariable.Then\n",
      "k-meansisrunonDT,causingittopartitionthevariablesintokclusters.Ac-\n",
      "tually,thePartitionScopefunctionisonlysupposedtopartitionthevariables\n",
      "inscope(n),notallthevariables(noteitsinputparameter).Sobeforecalling\n",
      "k-meanswebuildanewmatrixDnbyremovingcolumnsfromD,keepingonly\n",
      "thosecolumnsthatcorrespondtovariablesinscope(n).Thenk-meansisrunon\n",
      "DnTandtheresultingvariablepartitionisreturned.Thek-meansalgorithm\n",
      "servesthepurposeofdetectingsubsetsofvariablesthatstronglyinteractwith\n",
      "oneanother.Othermethods(includingotherclusteringalgorithms)couldbe\n",
      "usedinitsplace.AfterthescopeSnofanodenhasbeenpartitionedintoS1\n",
      "andS2,Algorithm2(lines4through11)looksforregionnodesinGwhose\n",
      "scopeissimilartoS1orS2;ifregionnoderwithscopeSrissuchanode,then\n",
      "S1andS2areadjustedsothatS1=Srand\n",
      "f\n",
      "S1,S2\n",
      "g\n",
      "isstillapartitionofSn\n",
      ".Lines12through18expandtheregiongraphbasedonthepartitionofSn.If\n",
      "nodendoesnotalreadyhaveachildpartitionnoderepresentingthepartition\n",
      "f\n",
      "S1,S2\n",
      "g\n",
      "thenoneiscreated(pinline15);pisthenconnectedtochildregion\n",
      "nodesn1andn2,whosescopesareS1andS2,respectively.Notethatn1and\n",
      "n2maybenewly-createdregionnodesortheymaybenodesthatwerecreated\n",
      "duringapreviouscalltoAlgorithm2.WerecursivelycallExpandRegionGraph\n",
      "onlyonnewly-creatednodes;therecursivecallisalsonotmadeifthenodeis\n",
      "aleafnode(|Si|=1)sincepartitioningaleafnodeisnothelpful(seelines\n",
      "19through22).5\n",
      "Algorithm2ExpandRegionGraph\n",
      "Algorithm3BuildSPNInput:regiongraphG,sumsperregionmOutput:\n",
      "SPNSR?RegionNodesIn(G)forallr?RdoifIsRootNode(r)thenN?\n",
      "AddSumNodesToSPN(S,1)elseN?AddSumNodesToSPN(S,m)P?Child-\n",
      "PartitionNodesOf(r)forallp?PdoC?ChildrenOf(p)O?AddProductN-\n",
      "odesToSPN(S,m|C|)foralln?NdoAddChildrenToSumNode(n,O)Q?\n",
      "emptylistforallc?Cdo//Weassumethesumnodesassociated//withchave\n",
      "alreadybeencreated.U?SumNodesAssociatedWith(c)AppendToList(Q,U)\n",
      "ConnectProductsToSums(O,Q)returnS\n",
      "1:Input:regiongraphG,2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:\n",
      "17:18:19:20:21:22:\n",
      "regionnodeninG,trainingdataDSn?scope(n)\n",
      "f\n",
      "S1,S2\n",
      "g\n",
      "?Partition-\n",
      "Scope(Sn,D)S?ScopesOfAllRegionNodesIn(G)forallSr?Ss.t.Sr?Sndo\n",
      "8\n",
      "\n",
      "p1?|S1?Sr|/|S1?Sr|p2?|S2?Sr|/|S2?Sr|ifmax\n",
      "f\n",
      "p1\n",
      ",p2\n",
      "g\n",
      ">thresholdthenS1?SrS2?SnSrbreakn1?GetOrCreateRegionN-\n",
      "ode(G,S1)n2?GetOrCreateRegionNode(G,S2)ifPartitionDoesNotExist(G,\n",
      "n,n1,n2)thenp?NewPartitionNode()AddChildToRegionNode(n,p)Add-\n",
      "ChildToPartitionNode(p,n1)AddChildToPartitionNode(p,n2)ifS1?/S?\n",
      "|S1|>1thenExpandRegionGraph(G,n1)ifS2?/S?|S2|>1then\n",
      "ExpandRegionGraph(G,n2)\n",
      "AfterthekcallstoAlgorithm2havebeenmade,theresultingregiongraph\n",
      "mustbeconvertedtoanSPN.Figure5showsasmallsubgraphfromaregion\n",
      "graphanditsconversionintoanSPN;thisexampledemonstratesthebasic\n",
      "patternthatcanbeappliedtoallregionnodesinGinordertogeneratean\n",
      "SPN.AmoreprecisedescriptionofthisconversionisgiveninAlgorithm3.In\n",
      "thisalgorithmtheassumptionismade(notedinthecomments)thatcertain\n",
      "sumnodesareinsertedbeforeothers.Thisassumptioncanbeguaranteedif\n",
      "thealgorithmperformsapostordertraversaloftheregionnodesinGinthe\n",
      "outermostloop.AlsonotethattheConnectProductsToSumsmethodconnects\n",
      "productnodesofthecurrentregionwithsumnodesfromitssubregions;the\n",
      "childrenofaproductnodeconsistofasinglenodedrawnfromeachsubregion,\n",
      "andthereisaproductnodeforeverypossiblecombinationofsuchsumnodes.\n",
      "4\n",
      "ExperimentsandResults\n",
      "PoonshowedthatSPNscanoutperformdeepbeliefnetworks(DBNs),deep\n",
      "Boltzmanmachines(DBMs),principlecomponentanalysis(PCA),andanearest-\n",
      "neighborsalgorithm(NN)onaimagecompletiontask.Thetaskisthe\n",
      "following:giventheright/tophalfofanimage,paintintheleft/bottomhalf\n",
      "ofit.Thecompletionresultsofthesemodelswerecomparedqualitativelyby\n",
      "inspectionandquantitativelyusingmeansquarederror(MSE).SPNsproduced\n",
      "thebestresults;ourexperimentsshowthattheclusterarchitecturetly\n",
      "improvesSPNperformance.Wematchedtheexperimentalset-upreportedin\n",
      "[2]inordertoisolatetheofchangingtheinitialSPNarchitectureandto\n",
      "maketheirreportedresultsdirectlycomparabletoseveralofourresults.They\n",
      "add20sumnodesforeachnon-unitandnon-rootregion.Therootregionhas\n",
      "onesumnodeandtheunitregionshavefoursumnodes,eachofwhichfunction\n",
      "asaGaussianoverpixelvalues.TheGaussiansmeansarecalculatedusingthe\n",
      "trainingdataforeachpixel,withoneGaussiancoveringeachquartileofthe\n",
      "pixel-valueshistogram.Eachtrainingimageisnormalizedsuchthatitsmean\n",
      "pixelvalueiszerowithastandarddeviationofone.Hardexpectationmaxi-\n",
      "mization(EM)isusedtotraintheSPNs;mini-batchesof50traininginstances\n",
      "areusedtocalculateeachweightupdate.Allsumnodeweightsareinitialized\n",
      "tozero;weightvaluesaredecreasedaftereachtrainingepochusinganL0prior;\n",
      "add-onesmoothingonsumnodeweightsisusedduringnetworkevaluation.6\n",
      "Table1:ResultsofexperimentsontheOlivetti,Caltech101Faces,arti\n",
      "andshettidatasetscomparingthePoonandclusterarchitectures.\n",
      "Negativelog-likelihood(LLH)ofthetrainingsetandtestsetisreportedalong\n",
      "withtheMSEfortheimagecompletionresults(bothleft-halfandbottom-half\n",
      "completionresults).DatasetOlivetti\n",
      "9\n",
      "\n",
      "CaltechFaces\n",
      "Sh\n",
      "MeasurementTrainLLHTestLLHMSE(left)MSE(bottom)TrainLLH\n",
      "TestLLHMSE(left)MSE(bottom)TrainLLHTestLLHMSE(left)MSE\n",
      "(bottom)TrainLLHTestLLHMSE(left)MSE(bottom)\n",
      "Poon318?1863?9996?42963?42289?4674?151968?891925?\n",
      "82195?0266?4842?51877?85793?31193?3811?11817?17\n",
      "Cluster433?17715?31814?35820?38379?8557?111746?87\n",
      "1561?44169?0223?6558?27561?29442?14703?14402?16403?\n",
      "17\n",
      "Figure6:Acluster-architectureSPNcompletedtheimagesintheleftcolumn\n",
      "andaPoon-architectureSPNcompletedtheimagesintherightcolumn.All\n",
      "imagesshownareleft-halfcompletions.Thetoprowisthebestresultsas\n",
      "measuredbyMSEandthebottomrowistheworstresults.Notethesmooth\n",
      "edgesintheclustercompletionsandthejaggededgesinthePooncompletions.\n",
      "WetesttheclusterandPoonarchitecturesbylearningontheOlivettidataset\n",
      "[9],thefacesfromtheCaltech-101dataset[10],andatasetthatwe\n",
      "generated,andtheshettidataset,whichtheOlivettidatasetwith\n",
      "thepixelsrandomlysh(allimagesareshinthesameway).The\n",
      "Caltech-101faceswerepreprocessedasdescribedbyPoon&Domingos.The\n",
      "clusterarchitectureiscomparedtothePoonarchitecturesusingthenegative\n",
      "log-likelihood(LLH)ofthetrainingandtestsetsaswellastheMSEofthe\n",
      "imagecompletionresultsforthelefthalfandbottomhalfoftheimages.We\n",
      "traintenclusterarchitectureSPNsandtenPoonarchitectureSPNs.Average\n",
      "resultsacrossthetenSPNsalongwiththestandarddeviationaregivenfor\n",
      "eachmeasurement.OntheOlivettiandCaltech-101FacesdatasetsthePoon\n",
      "architectureresultedinbettertrainingsetLLH,buttheclusterarchitecture\n",
      "generalizedbetter,gettingabettertestsetLLH(seeTable1).Theclusterar-\n",
      "chitecturewasalsoclearlybetterattheimagecompletiontasksasmeasuredby\n",
      "MSE.Thebetweenthetwoarchitecturesismostpronouncedonthe\n",
      "dataset.Theimagesinthisdatasetarecreatedbypastingrandomly-\n",
      "shadedcircle-anddiamond-shapedimagepatchesontopofoneanother(see\n",
      "Figure6),ensuringthatvariouspixelpatchesarestatisticallyindependent.The\n",
      "clusterarchitectureoutperformsthePoonarchitectureacrossallmeasureson\n",
      "thisdataset(seeTable1);thisisduetoitsabilitytofocusresourcesonnon-\n",
      "rectangularregions.Todemonstratethattheclusterarchitecturedoesnotrely\n",
      "onthepresenceofspatially-local,stronginteractionsbetweenthevariables,we\n",
      "repeatedtheOlivettiexperimentwiththepixelsintheimageshavingbeenshuf-\n",
      "Inthisexperiment(seeTable1)theclusterarchitecturewas,asexpected,\n",
      "relativelybythepixelshg.TheLLHmeasuresremainedbasi-\n",
      "callyunchangedfromtheOlivettitotheOlivetti-shdatasets.(TheMSE\n",
      "resultsdidnotstaythesamebecausetheimagecompletionshappenedoverdif-\n",
      "ferentsubsetsofthepixels.)Ontheotherhand,theperformanceofthePoon\n",
      "architecturedroppedconsiderablyduetothefactthatitwasnolongerable\n",
      "totakeadvantageofstrongcorrelationsbetweenneighboringpixels.Figure7\n",
      "visuallydemonstratesthebetweentherectangular-regionsPoonar-\n",
      "10\n",
      "\n",
      "chitectureandthearbitrarily-shaped-regionsclusterarchitecture.Artifactsof\n",
      "thetregionshapescanbeseenin(a),wheresomeregionsare\n",
      "shadedlighterordarker,revealingregionboundaries.(b)compares\n",
      "thebestofbotharchitectures,showingimagecompletionresultsonwhichboth\n",
      "architecturesdidwell,qualitativelyspeaking.NotehowthePoonarchitecture\n",
      "producesresultsthatlook?blocky?,whereastheclusterarchitectureproduces\n",
      "resultsthataresmoother-looking.7\n",
      "(a)\n",
      "(b)\n",
      "Figure7:Thecompletionresultsine(a)highlightthe\n",
      "betweentherectangularshapedregionsofthePoonarchitecture(topimage)\n",
      "andtheblob-likeregionsoftheclusterarchitecture(bottomimage),artifactsof\n",
      "whichcanbeseeninthecompletions.(b)showsgroundtruthimages,\n",
      "cluster-architectureSPNcompletions,andPoon-architectureSPNcompletions\n",
      "intheleft,middle,andrightcolumnsrespectively.Left-halfcompletionsare\n",
      "inthetoprowandbottom-halfcompletionsareinthebottomrow.Table2:\n",
      "TestsetLLHvaluesfortheOlivetti,Olivetti45,andOlivetti4590datasetsfor\n",
      "tvaluesofk.ForeachdatasetthebestLLHvalueismarkedinbold.\n",
      "Dataset/kOlivettiOlivetti45Olivetti4590\n",
      "1650523579\n",
      "2653495576\n",
      "3671508550\n",
      "4685529554\n",
      "5711541577\n",
      "6716528595\n",
      "7717544608\n",
      "8741532592\n",
      "Algorithm1expandsaregiongraphktimes(lines12and13).Thevalue\n",
      "ofkcantlytestsetLLH,asshowninTable2.Avaluethatis\n",
      "toolowleadstoantlypowerfulmodelandavaluethatistoohigh\n",
      "leadstoamodelthatovthetrainingdataandgeneralizespoorly.Asingly-\n",
      "expandedmodel(k=1)isoptimalfortheOlivettidataset.Thismaybeduein\n",
      "parttotheOlivettidatasethavingonlyonedistinctclassofimages(facesina\n",
      "particularpose).Datasetswithmoreimageclassesmaybfromadditional\n",
      "expansions.Toexperimentwiththishypothesiswecreatetwonewdatasets:\n",
      "Olivetti45andOlivetti4590.Olivetti45iscreatedbyaugmentingtheOlivetti\n",
      "datasetwithOlivettiimagesthatarerotatedby?45degrees.Olivetti4590is\n",
      "builtsimilarlybutwithrotationsby?45degreesandby?90degrees.The\n",
      "Olivetti45dataset,then,hastwodistinctclassesofimages:rotatedandnon-\n",
      "rotated.Similarly,Olivetti4590hasthreedistinctimageclasses.Table2shows\n",
      "that,asexpected,theoptimalvalueofkfortheOlivetti45andOlivetti4590\n",
      "datasetsistwoandthree,respectively.NotethattheOlivettitestsetLLHwith\n",
      "k=1inTable2isbetterthanthetestsetLLHreportedinTable1.Thisshows\n",
      "thatthealgorithmforautomaticallyselectingkinAlgorithm1isnotoptimal.\n",
      "Anotheroptionistouseahold-outsettoselectk,althoughthismethodmay\n",
      "notnotbeappropriateforsmalldatasets.\n",
      "11\n",
      "\n",
      "5\n",
      "Conclusion\n",
      "Thealgorithmforlearningaclusterarchitectureissimple,fast,ande.\n",
      "ItallowstheSPNtofocusitsresourcesonexplainingtheinteractionsbetween\n",
      "arbitrarysubsetsofinputvariables.And,beingdrivenbydata,thealgorithm\n",
      "guidestheallocationofSPNresourcessuchthatitisabletomodelthedata\n",
      "moretly.Futureworkincludesexperimentingwithalternativecluster-\n",
      "ingalgorithms,experimentingwithmethodsforselectingthevalueofk,and\n",
      "experimentingwithvariationsofAlgorithm2suchasgeneralizingittohandle\n",
      "partitionsofsizegreaterthantwo.\n",
      "8\n",
      "2References\n",
      "[1]E.Hinton,SimonOsindero,andYee-WhyeTeh.Afastlearn-\n",
      "ingalgorithmfordeepbeliefnets.NeuralComputation,18:1527?1554,July\n",
      "2006.[2]HoifungPoonandPedroDomingos.Sum-productnetworks:Anew\n",
      "deeparchitecture.InProceedingsoftheTwenty-SeventhAnnualConferenceon\n",
      "UncertaintyinIntelligence(UAI-11),pages337?346,Corvallis,Ore-\n",
      "gon,2011.AUAIPress.[3]RyanPrescottAdams,HannaM.Wallach,and\n",
      "ZoubinGhahramani.Learningthestructureofdeepsparsegraphicalmodels.\n",
      "InProceedingsofthe13thInternationalConferenceonIntelligence\n",
      "andStatistics,2010.[4]NevinL.Zhang.Hierarchicallatentclassmodelsfor\n",
      "clusteranalysis.JournalofMachineLearningResearch,5:697?723,December\n",
      "2004.[5]AdnanDarwiche.Atialapproachtoinferenceinbayesiannet-\n",
      "works.JournaloftheACM,50:280?305,May2003.[6]OlivierDelalleauand\n",
      "YoshuaBengio.Shallowvs.deepsum-productnetworks.InAdvancesinNeu-\n",
      "ralInformationProcessingSystems24,pages666?674.2011.[7]DaphneKoller\n",
      "andNirFriedman.ProbabilisticGraphicalModels:PrinciplesandTechniques.\n",
      "MITPress,2009.[8]F.Pedregosa,G.Varoquaux,A.Gramfort,V.Michel,\n",
      "B.Thirion,O.Grisel,M.Blondel,P.Prettenhofer,R.Weiss,V.Dubourg,J.\n",
      "Vanderplas,A.Passos,D.Cournapeau,M.Brucher,M.Perrot,andE.Duch-\n",
      "esnay.Scikit-learn:Machinelearninginpython.JournalofMachineLearning\n",
      "Research,12:2825?2830,2011.[9]F.S.SamariaandA.C.Harter.Parameterisa-\n",
      "tionofastochasticmodelforhumanfaceidenInProceedingsofthe\n",
      "SecondIEEEWorkshoponApplicationsofComputerVision,pages138?142,\n",
      "Dec1994.[10]LiFei-Fei,R.Fergus,andP.Perona.Learninggenerativevisual\n",
      "modelsfromfewtrainingexamples:Anincrementalbayesianapproachtested\n",
      "on101objectcategories.InIEEECVPR2004,WorkshoponGenerative-Model\n",
      "BasedVision,2004.\n",
      "9\n",
      "12\n",
      "\n",
      "PP6435.pdf\n",
      "PP6435.pdf 16\n",
      "APseudo-BayesianAlgorithmforRobustPCA\n",
      "Authoredby:\n",
      "DavidWipf\n",
      "Tae-HyunOh\n",
      "YasuyukiMatsushita\n",
      "InKweon\n",
      "Abstract\n",
      "Commonlyusedinmanyapplications,robustPCArepresentsanal-\n",
      "gorithmicattempttoreducethesensitivityofclassicalPCAtooutliers.\n",
      "Thebasicideaistolearnadecompositionofsomedatamatrixofinterest\n",
      "intolowrankandsparsecomponents,thelatterrepresentingunwanted\n",
      "outliers.AlthoughtheresultingproblemistypicallyNP-hard,convex\n",
      "relaxationsprovideacomputationally-expedientalternativewiththeoret-\n",
      "icalsupport.However,inpracticalregimesperformanceguaranteesbreak\n",
      "downandavarietyofnon-convexalternatives,includingBayesian-inspired\n",
      "models,havebeenproposedtoboostestimationquality.Unfortunately\n",
      "though,withoutadditionalaprioriknowledgenoneofthesemethodscan\n",
      "tlyexpandthecriticaloperationalrangesuchthatexactprin-\n",
      "cipalsubspacerecoveryispossible.Intothismixweproposeanovel\n",
      "pseudo-Bayesianalgorithmthatexplicitlycompensatesfordesignweak-\n",
      "nessesinmanyexistingnon-convexapproachesleadingtostate-of-the-art\n",
      "performancewithasoundanalyticalfoundation.\n",
      "1PaperBody\n",
      "Itisnowwell-establishedthatprincipalcomponentanalysis(PCA)isquite\n",
      "sensitivetooutliers,withevenasinglecorrupteddataelementcarryingthepo-\n",
      "tentialofgrosslybiasingtherecoveredprincipalsubspace.Thisisparticularly\n",
      "trueinmanyrelevantapplicationsthatrelyheavilyonlowdimensionalrepresen-\n",
      "tations[8,13,27,33,22].Mathematically,suchoutlierscanbedescribedbythe\n",
      "measurementmodelY=Z+E,whereY?Rn?misanobserveddatamatrix,Z\n",
      "=AB>isalow-rankcomponentwithprincipalsubspaceequaltospan[A],and\n",
      "Eisamatrixofunknownsparsecorruptionswitharbitraryamplitudes.Ideally,\n",
      "wewouldliketoremovetheofE,whichwouldthenallowregularPCA\n",
      "tobeappliedtoZforobtainingprincipalcomponentsdevoidofunwantedbias.\n",
      "Forthispurpose,robustPCA(RPCA)algorithmshaverecentlybeenmotivated\n",
      "bytheoptimizationproblemminZ,Emax(n,m)?rank[Z]+kEk0s.t.Y=Z\n",
      "1\n",
      "\n",
      "+E,\n",
      "(1)\n",
      "wherek?k0denotesthe`0matrixnorm(meaningthenumberofnonzero\n",
      "matrixelements)andthemax(n,m)multiplierensuresthatbothrankand\n",
      "sparsitytermsscalebetween0andnm,aprioriagnosticismabout\n",
      "theirrelativecontributionstoY.Thebasicideaisthatif\n",
      "f\n",
      "Z?,E?\n",
      "g\n",
      "minimizes\n",
      "(1),thenZ?islikelytorepresenttheoriginaluncorrupteddata.Asapointof\n",
      "reference,ifwesomehowknewaprioriwhichelementsofEwerezero(i.e.,no\n",
      "grosscorruptions),then(1)couldbeelyreducedtothemuchsimpler\n",
      "matrixcompletion(MC)problem[5]minZrank[Z]s.t.yij=zij,?(i,j)??,(2)\n",
      "where?denotesthesetofindicescorrespondingwithzero-valuedelementsin\n",
      "E.AmajorchallengewithRPCAisthatanaccurateestimateofthesupport\n",
      "set?canbeelusive.?\n",
      "ThisworkwasdonewhilethestauthorwasaninternatMicrosoftRe-\n",
      "search,Beijing.TheandthirdauthorsweresupportedbytheNRFofKorea\n",
      "grantfundedbytheKoreagovernment,MSIP(No.2010-0028680).Thesecond\n",
      "authorwaspartlysupportedbyJSPSKAKENHIGrantNumberJP16H01732.\n",
      "30thConferenceonNeuralInformationProcessingSystems(NIPS2016),\n",
      "Barcelona,Spain.\n",
      "Unfortunately,solving(1)isnon-convex,discontinuous,andNP-hardingen-\n",
      "eral.Therefore,theconvexsurrogatereferredtoasprincipalcomponentpursuit\n",
      "(PCP)pminZ,Emax(n,m)?kZk?+kEk1s.t.Y=Z+E(3)isoftenadopted,\n",
      "wherek?k?denotesthenuclearnormandk?k1isthe`1matrixnorm.These\n",
      "representthetightestconvexrelaxationsoftherankand`0normfunctionsre-\n",
      "spectively.Severaltheoreticalresultsquantifytechnicalconditionswherebythe\n",
      "solutionsof(1)and(3)areactuallyequivalent[4,6].However,thesecondi-\n",
      "tionsarehighlyrestrictiveanddonotprovablyholdinpracticalsituationsof\n",
      "interestsuchasfaceclustering[10],motionsegmentation[10],highdynamic\n",
      "rangeimaging[22]orbackgroundsubtraction[4].Moreover,boththenuclear\n",
      "and`1normsaresensitivetodatavariances,oftenover-shrinkinglargesingular\n",
      "valuesofZorcoientsinE[11].Allofthismotivatesstrongerapproaches\n",
      "toapproximating(1).InSection2wereviewexistingalternatives,including\n",
      "bothnon-convexandprobabilisticapproaches;however,wearguethatnoneof\n",
      "thesecantlyoutperformPCPintermsofprincipalsubspacerecovery\n",
      "inimportant,representativeexperimentalsettingsdevoidofpriorknowledge\n",
      "(e.g.,truesignaldistributions,outlierlocations,rank,etc.).Wethenderivea\n",
      "newpseudo-BayesianalgorithminSection3thathasbeentailoredtoconform\n",
      "withprincipledoverarchingdesigncriteria.By?pseudo?,wemeananalgorithm\n",
      "inspiredbyBayesianmodelingconventions,butwithspecialmocationsthat\n",
      "deviatefromtheoriginalprobabilisticscriptforreasonsrelatedtoestimation\n",
      "qualityandcomputational.Next,Section4examinesrelevanttheo-\n",
      "reticalproperties,explicitlyaccountingforallapproximationsinvolved,while\n",
      "Section5providesempiricalvalidations.Proofsandothertechnicaldetailsare\n",
      "deferredto[23].Ourhigh-levelcontributionscanbesummarizedasfollows:-\n",
      "Wederiveanewpseudo-BayesianRPCAalgorithmwithtADMMsub-\n",
      "routine.-Whileprovablerecoveryguaranteesareabsentfornon-convexRPCA\n",
      "2\n",
      "\n",
      "algorithms,wenonethelessquantifyhowourpseudo-Bayesiandesignchoices\n",
      "leadtoadesirableenergylandscape.Inparticular,weshowthatalthoughany\n",
      "outliersupportpatternwillrepresentaninescapablelocalminimaof(1)(ora\n",
      "broadclassoffunctionsthatmimic(1)),ourproposalcansimultaneouslyretain\n",
      "thecorrectglobaloptimumwhileeradicatingatleastsomeofthesuboptimal\n",
      "minimaassociatedwithincorrectoutlierlocationestimates.-Weempirically\n",
      "demonstrateimprovedperformanceoverstate-of-the-artalgorithms(including\n",
      "PCP)intermsofstandardphasetransitionplotswithadramaticallyexpanded\n",
      "successregion.Quitesurprisingly,ouralgorithmcanevenoutperformconvex\n",
      "matrixcompletion(MC)despitethefactthatthelatterisprovidedwithper-\n",
      "fectknowledgeofwhichentriesarenotcorrupted,suggestingthatrobustoutlier\n",
      "supportpatternestimationisindeeddirectlyfacilitatedbyourmodel.\n",
      "2\n",
      "RecentWork\n",
      "Thevastmajorityofalgorithmsforsolving(1)eitherimplicitlyorexplicitly\n",
      "attempttosolveaproblemoftheformPminZ,Ef1(Z)+i,jf2(eij)s.t.Y=\n",
      "Z+E,(4)wheref1andf2arepenaltyfunctionsthatfavorminimalrankand\n",
      "sparsityrespectively.Whenf1isthenuclearnorm(scaledappropriately)and\n",
      "f2(e)=|e|,then(4)reducesto(3).Methodshoweverbyreplacingf1\n",
      "andf2withnon-convexalternatives,suchasgeneralizedHuberfunctions[7]or\n",
      "Schatten`pquasi-normswithp<1[18,19].Whenappliedtothesingularvalues\n",
      "ofZandelementsofErespectively,theseselectionsenactstrongerenforcement\n",
      "ofminimalrankandsparsity.IfpriorknowledgeofthetruerankofZisavailable,\n",
      "atruncatednuclearnormapproach(TNN-RPCA)hasalsobeenproposed[24].\n",
      "Furtherdivergencesfollowfromthespectrumofoptimizationschemesapplied\n",
      "totobjectives,suchasthealternatingdirectionsmethodofmultipliers\n",
      "(ADMM)algorithm[3]oriterativelyreweightedleastsquares(IRLS)[18].With\n",
      "allofthesemethods,wemayconsiderrelaxingthestrictequalityconstraintto\n",
      "theregularizedformPminZ,E?1kY?Z?Ek2F+f1(Z)+i,jf2(eij),(5)\n",
      "where?>0isaparameter.Thishasinspiredanumberofcompeting\n",
      "Bayesianformulations,whichtypicallyproceedasfollows.Let\n",
      "1p(Y|Z,E)?exp?2?kY?Z?Ek2F(6)2\n",
      "alikelihoodfunction,where?representsanon-negativevariance\n",
      "parameterassumedtobeknown.2Hierarchicalpriordistributionsarethenas-\n",
      "signedtoZandEtoencourageminimalrankandstrongsparsity,respectively.\n",
      "Forthelatter,themostcommonchoiceistheGaussianscale-mixture(GSM)\n",
      "hierarchicallybyh2iQe?11?a)??ijexp[??b],p(E|?)=i,jp(eij\n",
      "|?ij),p(eij|?ij)?exp?2?ijij,withhyperpriorp(?ijij(7)where?is\n",
      "amatrixofnon-negativevariancesanda,b?0areparameters.Notethat\n",
      "whenthesevaluesaresmall,theresultingdistributionovereacheij(obtained\n",
      "bymarginalizingovertherespective?ij)isheavy-tailedwithasharppeakat\n",
      "zero,thecharacteristicsofsparsepriors.FortheprioronZ,Bayesian\n",
      "methodshavesomewhatbroaderdistinctions.Inparticular,anumberofmeth-\n",
      "odsexplicitlyassumethatZ=AB>andspecifyGSMpriorsonAandB[1,9,\n",
      "15,30].Forexample,variationalBayesianRPCA(VB-RPCA)[1]assumes\n",
      "p(A|?)?exp?trAdiag[?]?1A>,where?isanon-negativevariancevector.An\n",
      "3\n",
      "\n",
      "equivalentQpriorisusedforp(B|?)withasharedvalueof?.Thismodelalso\n",
      "appliesthepriorp(?)=ip(?i)withp(?i)forconsistency?1withp(?ij\n",
      ")in(7).Lowranksolutionsarefavoredviathesamemechanismasdescribed\n",
      "aboveforsparsity,butonlythesparsevariancepriorisappliedtocolumnsof\n",
      "AandB,elypruningthemfromthemodeliftheassociated?iissmall.\n",
      "Giventheabove,thejointdistributionisp(Y,A,B,E,?,?)=p(Y|A,B,\n",
      "E)p(E|?)p(A|?)p(B|?)p(?)p(?).\n",
      "(8)\n",
      "FullBayesianinferencewiththisisintractable,henceacommonvariational\n",
      "Bayesian(VB)approximationisapplied[1,2].Thebasicideais\n",
      "toobtainatractableapproximatefactorialposteriordistributionbysolving\n",
      "minq(?)KL[q(?)||p(A,B,E,?,?|Y)],\n",
      "(9)\n",
      "whereq(?),q(A)q(B)q(E)q(?)q(?),eachqrepresentsanarbitraryprob-\n",
      "abilitydistribution,andKL[?||?]denotestheKullback-Leiblerdivergence\n",
      "betweentwodistributions.Thiscanbeaccomplishedviacoordinatedescent\n",
      "minimizationovereachrespectiveqdistributionwhileholdingtheothers\n",
      "FinalestimatesofZandEareobtainedbythemeansofq(A),q(B),andq(E)\n",
      "uponconvergence.Arelatedhierarchicalmodelisusedin[9,30],butMCMC\n",
      "samplingtechniquesareusedforfullBayesianinferenceRPCA(FB-RPCA)at\n",
      "theexpenseofconsiderablecomputationalcomplexityandmultipletuningpa-\n",
      "rameters.AnalternativeempiricalBayesianalgorithm(EB-RPCA)isdescribed\n",
      "in[31].Inadditiontothelikelihoodfunction(6)andpriorfrom(7),thismethod\n",
      "assumesadirectGaussianprioronZgivenby\n",
      "p(Z|?)?exp?12trZ>??1Z,(10)where?isasymmetricandpositive\n",
      "matrix.3InferenceisaccomplishedviaanempiricalBayesianapproach\n",
      "[20].ThebasicideaistomarginalizeouttheunknownZandEandsolve\n",
      "RRmax?,?p(Y|Z,E)p(Z|?)p(E|?)dZdE(11)usinganEM-likealgorithm.\n",
      "Oncewehaveanoptimal\n",
      "f\n",
      "??,??\n",
      "g\n",
      ",wethencomputetheposteriormeanof\n",
      "p(Z,E|Y,??,??)whichisavailableinclosed-form.Finally,arecentclassof\n",
      "methodshasbeenderivedaroundtheconceptofapproximatemessagepassing,\n",
      "AMP-RPCA[26],whichappliesGaussianpriorstothefactorsAandBand\n",
      "infersposteriorestimatesbyloopybeliefpropagation[21].Inourexperiments\n",
      "(see[23])wefoundAMP-RPCAtobequitesensitivetodatadeviatingfrom\n",
      "thesedistributions.\n",
      "3\n",
      "ANewPseudo-BayesianAlgorithm\n",
      "Asitturnsout,itisquitetoderiveafullyBayesianmodel,orsome\n",
      "tightvariational/empiricalapproximation,thatleadstoantalgorithm\n",
      "capableofconsistentlyoutperformingtheoriginalconvexPCP,atleastinthe\n",
      "absenceofadditional,exploitablepriorknowledge.Itisherethatweadopt2\n",
      "Actuallymanymethodsattempttolearnthisparameterfromdata,butwe\n",
      "avoidthisconsiderationforsimplicity.Aswell,forsubtlereasonssuchlearning\n",
      "issometimesnotevenideninthestrictstatisticalsense.3Notethatin\n",
      "[31]thismethodismotivatedfromanentirelytvariationalperspective\n",
      "anchoredinconvexanalysis;however,thecostfunctionthatultimatelyemerges\n",
      "4\n",
      "\n",
      "isequivalenttowhatfollowswiththesepriors.\n",
      "3\n",
      "apseudo-Bayesianapproach,bywhichwemeanthataBayesian-inspired\n",
      "costfunctionwillbealteredusingmanipulationsthat,althoughnotconsistent\n",
      "withanyoriginalBayesianmodel,nonethelessproducedesirableattributesrel-\n",
      "evanttoblindlysolving(1).Insomesensehowever,weviewthisasastrength,\n",
      "becausethemodelanalysispresentedlaterinSection4doesnotrelyon\n",
      "anypresumedvalidityoftheunderlyingpriorassumptions,butratheronex-\n",
      "plicitpropertiesoftheobjectivethatemerges,includingallassumptionsand\n",
      "approximationinvolved.BasicModel:Webeginwiththesamelikelihoodfunc-\n",
      "tionfrom(6),notingthatinthelimitas??0thiswillenforcetheconstraint\n",
      "setfrom(1).WealsoadoptthesameprioronEgivenby(7)aboveandused\n",
      "in[1]and[31],butweneednotassumeanyadditionalhyperprioron?.In\n",
      "contrast,fortheprioronZourmethoddiverges,andwetheGaussiani\n",
      "h?1(12)p(Z|?r,?c)?exp?21z>(?r?I+I??c)z,wherez,vec[Z]\n",
      "isthecolumn-wisevectorizationofZ,?denotestheKroneckerproduct,and?c\n",
      "?Rn?nand?r?Rm?marepositivese,symmetricmatrices.4Here?c\n",
      "canbeviewedasapplyingacolumn-wisecovariancefactor,and?rarow-wise\n",
      "one.Notethatif?r=0,thenthispriorcollapsesto(10);however,byincluding\n",
      "?rwecanretainsymmetryinourmodel,orinvariancetoinferenceusingeither\n",
      "YorY>.Relatedpriorscanalsobeusedtoimprovetheperformanceof\n",
      "rankminimizationproblems[34].WeapplytheempiricalBayesianprocedure\n",
      "from(11);theresultingconvolutionofGaussiansintegral[2]canbecomputed\n",
      "inclosed-form.Afterapplying?2log[?]transformation,thisisequivalentto\n",
      "minimizing?+?I,(13)L(?r,?c,?)=y>??1y+log|?y|,where?y,?r\n",
      "?I+I??c+?y\n",
      "?,diag[and??].Notethatforevenreasonablysizedproblems?y?\n",
      "Rnm?nmwillbehuge,andconsequentlywewillrequirecertainapproximations\n",
      "toproduceupdaterules.Fortunatelythiscanbeaccomplishedwhile\n",
      "simultaneouslyretainingaprincipledobjectivefunctioncapableofoutperform-\n",
      "ingexistingmethods.Pseudo-BayesianObjective:Wemodify(13)togive\n",
      "P\n",
      "PL(?r,?c,?)=y>??1y+jlog?c+12??j+?2I+ilog?r+21\n",
      "?i?+?2I,(14)ywhere??j,diag[??j]and??jrepresentsthej-thcolumn\n",
      "of?.Similarlywe?i?,diag[?i?]with?i?thei-throwof?.This\n",
      "newcostisnothingmorethan(13)butwiththelog|?|termsplitin\n",
      "halfproducingalowerboundbyJensen?sinequality;theKroneckerproduct\n",
      "cannaturallybedissolvedundertheseconditions.Additionally,(14)represents\n",
      "adeparturefromouroriginalBayesianmodelinthatthereisnolongerany\n",
      "directempiricalBayesianorVBformulationthatwouldleadto(14).Notethat\n",
      "althoughthismocannotbeonstrictlyprobabilisticterms,we\n",
      "willseeshortlythatitnonethelessstillrepresentsaviablecostfunctioninthe\n",
      "abstractsense,andlendsitselftoincreasedcomputational.Thelatter\n",
      "isanimmediateofthedrasticallyreduceddimensionalityofthematrices\n",
      "insidethedeterminant.Henceforth(14)willrepresentthecostfunctionthatwe\n",
      "seektominimize;relevantpropertieswillbehandledinSection4.Weemphasize\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thatallsubsequentanalysisisbaseddirectlyupon(14),andthereforealready\n",
      "accountsfortheapproximationstepinadvancingfrom(13).Thisisunlike\n",
      "otherBayesianmodelrelyingonthelegitimacyoftheoriginal\n",
      "fullmodel,andyetthenadoptvariousapproximationsthatmaycompletely\n",
      "changetheproblem.UpdateRules:CommontomanyempiricalBayesianand\n",
      "VBapproaches,ourbasicoptimizationstrategyinvolvesiterativelyoptimizing\n",
      "upperboundson(14)inthespiritofmajorizationminimization[12].Atahigh\n",
      "level,ourgoalwillbetoapplyboundswhichseparate?c,?r,and?intoterms\n",
      "ofthegeneralformlog|X|+tr[AX?1],thereasonbeingthatthisexpression\n",
      "hasasimpleglobalminimumoverXgivenbyX=A.Thereforethestrategywill\n",
      "betoupdatethebound(parameterizedbysomematrixA),andthenupdate\n",
      "theparametersofinterestX.Usingstandardconjugatedualityrelationships\n",
      "andvariationalboundingtechniques[14][Chapter4],itfollowsaftersomelinear\n",
      "algebrathat4\n",
      "TechnicallytheKroneckersum?r?I+I??cmustbepositiveforthe\n",
      "inversein(12)tobeHowever,wecanaccommodatethe\n",
      "caseusingthefollowingconvention.Withoutlossofgeneralityassumethat?r\n",
      "?I+I??c=RR>forsomematrixR.Wethenqualifythatp(Z|?r,?c)=0if\n",
      "z?/span[R],andp(Z|?r,?c)?exp[?21z>(R>)?R?z]otherwise.\n",
      "4\n",
      "y>??1yy\n",
      "?\n",
      "1kY?\n",
      "?Z?Ek2F+\n",
      "e2iji,j?ij\n",
      "P\n",
      "+z>(?r?I+I??c)?1z\n",
      "(15)\n",
      "forallZandE.Forvaluesof?r,?c,and?weoptimizethisquadratic\n",
      "boundtoobtainrevisedestimatesforZandE,notingthatexactequalityin\n",
      "(15)ispossibleviatheclosed-formsolutionz=(?r?I+I??c)??1y,y\n",
      "??1e=??y.y\n",
      "(16)\n",
      "Inlargepracticalproblems,(16)maybecomeexpensivetocomputedirectly\n",
      "becauseofthehighdimensionalinverseinvolved.However,wemaystill\n",
      "theoptimumetlybyanADMMproceduredescribedin[23].Wecanalso\n",
      "furtherboundtherighthandsideof(15)usingJensen?sinequalityashi>?1z\n",
      ">(?r?I+I??c)?1z?trZ>Z??1.r+ZZ?c\n",
      "(17)\n",
      "Alongwith(15)thisimpliesthatforvaluesofZandEwecanobtainan\n",
      "upperboundwhichonlydependson?r,?c,and?inadecoupledorseparable\n",
      "fashion.Forthelog|?|termsin(14),wealsoderiveconvenientupper\n",
      "boundsusingdeterminantidentitiesandaapproximation,thegoal\n",
      "beingtoarepresentationthatplayswellwiththepreviousdecoupledbound\n",
      "foroptimizationpurposes.Againusingconjugatedualityrelationships,wecan\n",
      "formthebound\n",
      "6\n",
      "\n",
      "log?c+12??j+?2I\n",
      "?log|?c|+log|??j|+log|W(?c,??j)|?log|?c|+log\n",
      "|??j|+tr\n",
      "h\n",
      "?1j(??1)>?c?\n",
      "i\n",
      "c\n",
      "+(?c?1)>??1?j+C,??j\n",
      "(18)\n",
      "wheretheinverse??1?jisunderstoodtoapplyelement-wise,andW(?c,\n",
      "??j)isasW(?c,??j),\n",
      "12?\n",
      "?\n",
      "?2I2I\n",
      "2II\n",
      "+\n",
      "??1c0\n",
      "0??1?j\n",
      ".\n",
      "(19)\n",
      "Additionally,Cisastandardconstant,whichaccompaniesthe\n",
      "approximationtoguaranteethattheupperboundistangenttotheunderlying\n",
      "costfunction;however,itsexactvalueisirrelevantforoptimizationpurposes.\n",
      "Finally,therequisitegradientsareas?c??1,?j\n",
      "?W(?c,??j)???1?j\n",
      "?j??1,\n",
      "=diag[??j?12??j(Sjc)?1??j],\n",
      "c\n",
      "?W(?c,??j)?1\n",
      "??c\n",
      "=?c??c(Sjc)?1?c,\n",
      "(20)whereSjc,?c+21??j+?2I.Analogousboundscanbederivedfor\n",
      "thelog?r+21?i?+?2Itermsin(14).Theseboundsareprincipallyuseful\n",
      "becauseall?c,?r,??j,and?i?factorshavebeendecoupled.Consequently,\n",
      "withZ,E,andalltherelevantgradientswecanseparatelycombine?c-,\n",
      "?r-,and?-dependenttermsfromtheboundsandthenoptimizeindependently.\n",
      "Forexample,combiningtermsfrom(17)and(18)involving?cforallj,this\n",
      "requiressolvinghPij>?1>?1minmlog|?c|+tr(?)?+ZZ?.(21)\n",
      "?1ccj??c\n",
      "c\n",
      "Analogouscostfunctionsemergefor?rand?.Allthreeproblemshave\n",
      "closed-formoptimalsolutionsgivenbyhPihPij>11>i>>c+ur,?c=m?\n",
      "+ZZ,?=?+ZZ,?=z2+u(22)rji??1n??1r\n",
      "c\n",
      "c,[?c??1;...;?c??1],andanalogouslywherethesquaringoperatoris\n",
      "appliedelement-wisetoz,u?1\n",
      "7\n",
      "\n",
      "?m\n",
      "1r.Oneinterestingaspectof(22)isthatitforces?cmforuZZ>and?rn1\n",
      "Z>Z,thusmaintainingabalancingsymmetryandpreventingoneortheother\n",
      "frompossiblyconvergingtowardszero.Thisisanotherdesirableconsequence\n",
      "ofusingtheboundin(17).Tonalizethen,theproposedpipeline,whichwe\n",
      "henceforthrefertoaspseudo-BayesianRPCA(PB-RPCA),involvesthesteps\n",
      "shownunderAlgorithm1in[23].Thesecanbeimplementedinsuchawaythat\n",
      "thecomplexityislinearinmax(n,m)andcubicinmin(n,m).\n",
      "5\n",
      "4\n",
      "AnalysisofthePB-RPCAObjective\n",
      "OnthesurfaceitmayappearthatthePB-RPCAobjective(14)representsa\n",
      "rathercircuitousroutetosolving(1),withnoobviousadvantageoverthecon-\n",
      "vexPCPrelaxationfrom(3),oranyotherapproachforthatmatter.However\n",
      "quitesurprisingly,weprovein[23]thatbysimplyreplacingthelog|?|\n",
      "matrixoperatorsin(14)withtr[?],theresultingfunctioncollapsesexactlyto\n",
      "convexPCP.Sowhatatappearasdistantcousinsareactuallyquiteclosely\n",
      "relatedobjectives.Ofcourseourworkisstillinfrontofustoexplainwhylog\n",
      "|?|,andthereforethePB-RPCAobjectivebyassociation,mightdisplay\n",
      "anyparticularadvantage.Thisleadsustoconsiderationsofrelativeconcavity,\n",
      "non-separability,andsymmetryasdescribedbelowinturn.RelativeConcav-\n",
      "ity:Althoughbothlog|?|andtr[?]areconcavenon-decreasingfunctions\n",
      "ofthesingularvaluesofsymmetricpositivematrices,andhencefavor\n",
      "bothsparsityof?andminimalrankof?ror?c,theformerisfarmorestrongly\n",
      "concave(inthesenseofrelativeconcavitydescribedin[25]).Inthisrespectwe\n",
      "mayexpectthatlog|?|islesslikelytoover-shrinklargevalues[11].More-\n",
      "over,applyingaconcavenon-decreasingpenaltytoelementsof?favorsasparse\n",
      "estimate,?in(16).whichinturntransfersthissparsitydirectlytoEbyvirtue\n",
      "oftheleftmultiplicationby?Likewiseforthesingularvaluesof?cand?r.\n",
      "Non-Separability:Whilepotentiallydesirable,therelativeconcavitydistinction\n",
      "describedaboveiscertainlynotttomotivatewhyPB-RPCAmightrep-\n",
      "resentaneRPCAapproach,especiallygiventhebreadthofnon-convex\n",
      "alternativesalreadyintheliterature.However,amuchstrongerargumentcan\n",
      "bemadebyexposingafundamentallimitationofallRPCAmethods(convex\n",
      "orotherwise)thatrelyonminimizationofgenericpenaltiesintheseparableor\n",
      "additiveformof(4).Forthispurpose,let?denoteasetofindicesthatcorre-\n",
      "spondwithzero-valuedelementsinE,suchthatE?=0whileallotherelements\n",
      "ofEarearbitrarynonzeros(itcanequallybeviewedasthecomplementofthe\n",
      "supportofE).InthecaseofMC,?wouldalsorepresentthesetofobserved\n",
      "matrixelements.Wethenhavethefollowing:Proposition1.Toguaranteethat\n",
      "(4)hasthesameglobaloptimumas(1)forallYwhereauniquesolutionexists,\n",
      "itfollowsthatf1andf2mustbenon-convexandnofeasibledescentdirection\n",
      "caneverremoveanindexfromordecreasethecardinalityof?.In[31]ithas\n",
      "beenshownthat,undersimilarconditions,thegradientinafeasibledirection\n",
      "atanyzero-valuedelementofEmustbetoguaranteeamatchingglobal\n",
      "optimum,fromwhichthisresultnaturallyfollows.Theofthis\n",
      "8\n",
      "\n",
      "propositionareprofoundifweeverwishtoproduceaversionofRPCAthat\n",
      "canmimicthedesirablebehaviorofmuchsimplerMCproblemswithknown\n",
      "support,oratleastradicallyimproveuponPCPwithunknownoutliersupport.\n",
      "Inwords,Proposition1impliesthatunderthestatedglobal-optimalitypreserv-\n",
      "ingconditions,ifanyelementofEconvergestozeroduringoptimizationwith\n",
      "anarbitrarydescentalgorithm,itwillremainanchoredatzerountiltheend.\n",
      "Consequently,ifthealgorithmprematurelyerrsinsettingthewrongelementto\n",
      "zero,meaningthewrongsupportpatternhasbeeninferredatanytimeduring\n",
      "anoptimizationtrajectory,itisimpossibletoeverrecover,aproblemnaturally\n",
      "side-steppedbyMCwherethesupportiselyknown.Therefore,the\n",
      "adoptionofseparablepenaltyfunctionscanbequiteconstrainingandtheyare\n",
      "unlikelytoproducetlyreliablesupportrecovery.Buthowdoesthisre-\n",
      "latetoPB-RPCA?Ouralgorithmmaintainsadecidedlynon-separablepenalty\n",
      "functionon?c,?r,and?,whichdirectlytransferstoanimplicit,non-separable\n",
      "regularizeroverZandEwhenviewedthroughthedual-spaceframeworkfrom\n",
      "[32].5Bythiswemeanapenaltyf(Z,E)6=f1(Z)+f2(E)foranyfunctions\n",
      "f1andf2,andwithZwehavePf(Z,E)6=i,j(eij)foranysetof\n",
      "functions\n",
      "f\n",
      "\n",
      "g\n",
      ".Wenowexaminetheconsequences.Let?nowdenoteasetof\n",
      "indicesthatcorrespondwithzerovaluedelementsin?,whichtranslatesintoan\n",
      "equivalentsupportsetforZvia(16).Thisthenleadstoquanb\n",
      "Proposition2.Thefollowingpropertiesholdw.r.t.thePB-RPCAobjective\n",
      "(assumingn=mforsimplicity):?Assumethatauniqueglobalsolutionto\n",
      "(1)existssuchthateitherrank[Z]+maxjke?jk0<norrank[Z]+maxikei?k0<n.\n",
      "Additionally,let\n",
      "f\n",
      "??c,??r,??\n",
      "g\n",
      "denoteagloballyminimizingsolutionto(14)\n",
      "and\n",
      "f\n",
      "Z?,E?\n",
      "g\n",
      "thecorrespondingvaluesofZandEcomputedusing(16).Then\n",
      "inthelimit??0,Z?andE?globallyminimize(1).5\n",
      "Eventhoughthispenaltyfunctionisnotavailableinclosed-form,non-\n",
      "separabilityisnonethelessenforcedviathelinkagebetween?c,?r,and?\n",
      "inthelog|?|operator.\n",
      "6\n",
      "1\n",
      "0.6\n",
      "0.6\n",
      "0.6\n",
      "0.5\n",
      "0.6\n",
      "0.2\n",
      "Outlierratio\n",
      "0.4\n",
      "0.4\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "Outlierratio\n",
      "0.2\n",
      "Outlierratio\n",
      "9\n",
      "\n",
      "Outlierratio\n",
      "Outlierratio\n",
      "0.8\n",
      "0.4\n",
      "0.40.60.30.40.20.20.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "Rankratio\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "[Knownoutlierlocation]\n",
      "0.2\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.05\n",
      "0.10.05\n",
      "0.4\n",
      "0.2\n",
      "0.150.150.20.20.250.10.25\n",
      "0.30.3\n",
      "0.350.40.40.35\n",
      "0\n",
      "RankRankratioratio\n",
      "(d)PB?RPCAw/osym.1\n",
      "0.6\n",
      "0.5\n",
      "0.6\n",
      "0.8\n",
      "Outlierratio\n",
      "0.4\n",
      "0.25\n",
      "(c)VB?RPCA\n",
      "[Knownrank]\n",
      "0.6\n",
      "10\n",
      "\n",
      "0.2\n",
      "Rankratio\n",
      "(b)IRLS?RPCAOutlierratio\n",
      "Outlierratio\n",
      "0.25\n",
      "Rankratio\n",
      "(a)CVX?PCP0.6\n",
      "0.2\n",
      "Outlierratio\n",
      "0.1\n",
      "0.4\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "Outlierratio\n",
      "0.05\n",
      "0.40.60.30.40.20.20.1\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35\n",
      "Rankratio\n",
      "(e)CVX?MC\n",
      "0.4\n",
      "0.05\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "0.35\n",
      "0.4\n",
      "0.05\n",
      "Rankratio\n",
      "0.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "Rankratio\n",
      "(f)TNN?RPCA\n",
      "(g)FB?RPCA\n",
      "0.35\n",
      "11\n",
      "\n",
      "0.4\n",
      "0.05\n",
      "0.10.05\n",
      "0.150.150.20.20.250.10.25\n",
      "0.30.3\n",
      "0.350.40.40.35\n",
      "0\n",
      "RankRankratioratio\n",
      "(h)PB?RPCA(Proposed)\n",
      "Figure1:Phasetransitionoveroutlier(y-axis)andrank(x-axis)ratiovari-\n",
      "ations.HereCVX-MCandTNN-RPCAmaintainadvantagesofexactlyknown\n",
      "outliersupportpatternandtruerankrespectively.?AssumethatYhasno\n",
      "entriesidenticallyequaltozero.6Thenforanyarbitrary?,therewillalways\n",
      "existarangeof?cand?rvaluessuchthatforany?consistentwith?we\n",
      "arenotatalocallyminimizingsolutionto(14),meaningthereexistsafeasible\n",
      "descentdirectionwherebyelementsof?canescapefromzero.Acoupleim-\n",
      "portantcommentsareworthstatingregardingthisresult.First,therankand\n",
      "row/columnsparsityrequirementsareextremelymild.Infact,anyminimum\n",
      "of(1)willbesuchthatrank[Z]+maxjke?jk0?nandrank[Z]+maxikei?\n",
      "k0?m,regardlessofY.Secondly,unlikeanyseparablepenaltyfunction(4)\n",
      "thatretainsthecorrectglobaloptimalas(1),Proposition2impliesthat(14)\n",
      "neednotbelocallyminimizedbyeverypossiblesupportpatternforoutlierlo-\n",
      "cations.Consequently,prematureconvergencetosuboptimalsupportsneednot\n",
      "disrupttrajectoriestowardstheglobalsolutiontotheextentthat(4)maybeob-\n",
      "structed.Moreover,beyondalgorithmsthatexplicitlyadoptseparablepenalties\n",
      "(thevastmajority),someexistingBayesianapproachesmayimplicitlydefault\n",
      "to(4).Forexample,asshownin[23],thefactorizationsadoptedby\n",
      "VB-RPCAactuallyallowtheunderlyingfreeenergyobjectivetobeexpressible\n",
      "as(4)forsomef1andf2.Symmetry:Withouttheintroductionofsymmetry\n",
      "viaourpseudo-Bayesianproposal(meaningeither?cor?risforcedtozero),\n",
      "thenPB-RPCAcollapsestosomethinglikeEB-RPCA,whichdependsheavily\n",
      "onwhetherYorY>isprovidedasinputandpenalizescolumn-androw-spaces\n",
      "asymmetrically.Inthisregimeitcanbeshownthattheanalogousrequirement\n",
      "toreplicateProposition2becomesmorestringent,namelywemustassumethe\n",
      "asymmetricconditionrank[Z]+maxjke?jk0<n.Thusthesymmetriccost\n",
      "ofPB-RPCAofallowsustorelaxthiscolumn-wiserestrictionprovidedarow-\n",
      "wisealternativeholds(andviceversa),allowingthePB-RPCAobjective(14)\n",
      "tomatchtheglobaloptimumofouroriginalproblemfrom(1)underbroader\n",
      "conditions.Inclosingthissection,wereiteratethatallofouranalysisandcon-\n",
      "clusionsarebasedon(14),afterthestatedapproximations.Thereforeweneed\n",
      "notrelyontheplausibilityoftheoriginalBayesianstartingpointfromSection\n",
      "3northetightnessofsubsequentapproximationsforrather(14)\n",
      "canbeviewedasaprincipledstand-aloneobjectiveforRPCAregardlessofits\n",
      "origins.Moreover,itrepresentstheapproachsatisfyingtherelativecon-\n",
      "cavity,non-separability,andsymmetrypropertiesdescribedabove,whichcan\n",
      "looselybeviewedasnecessary,butnottdesigncriteriaforanoptimal\n",
      "12\n",
      "\n",
      "RPCAobjective.\n",
      "5\n",
      "Experiments\n",
      "Toexaminetfactorsthattheabilitytosolve(1),we\n",
      "evaluatetherelativeperformanceofPB-RPCAestimatingrandomsimulated\n",
      "subspacesfromcorruptedmeasurements,thestandardbenchmark.Laterwe\n",
      "presentsubspaceclusteringresultsformotionsegmentationasapracticalappli-\n",
      "cation.Additionalexperimentsandaphotometricstereoexampleareprovided\n",
      "in[23].PhaseTransitionGraphs:Wecompareourmethodagainstexisting\n",
      "RPCAmethods:PCP[16],TNN[24],IRLS[18],VB[1],andFB[9].Wealso\n",
      "includeresultsusingPB-RPCAbutwithsymmetryremoved(whichthende-\n",
      "faultstosomethinglikeEB-RPCA),allowingustoisolatetheimportanceof\n",
      "thisfactor,called?PB-RPCAw/osym.?.Forcompetingalgorithms,wesetpa-\n",
      "rametersbasedonthevaluessuggestedbyoriginalauthorswiththeexception\n",
      "ofIRLS.Detailedsettingsandparameterscanbefoundin[23].6\n",
      "Thisassumptioncanberelaxedwithsomeadditionalbutweavoid\n",
      "suchconsiderationshereforclarityofpresentation.\n",
      "7\n",
      "?\n",
      "SuccessRate\n",
      "10.80.60.4\n",
      "PB-RPCA(easycase)PB-RPCA(hardcase)PCP(easycase)PCP(hard\n",
      "case)\n",
      "0.200\n",
      "0.2\n",
      "0.40.6OutlierRatio\n",
      "SSCRobustSSCPCP+SSCPB+SSC(Ours)Withoutsub-sampling(large\n",
      "numberofmeasurements)19.0/14.95.3/0.33.0/0.02.4/0.028.2/28.36.4\n",
      "/0.43.0/0.02.4/0.033.2/34.77.2/0.53.6/0.22.8/0.036.5/39.08.5/\n",
      "0.64.7/0.23.1/0.0Withsub-sampling(smallnumberofmeasurements)0.1\n",
      "19.5/17.24.0/0.02.9/0.02.8/0.00.233.0/33.35.3/0.03.7/0.03.6/\n",
      "0.00.339.3/41.15.7/1.75.0/0.73.9/0.042.2/43.56.4/2.19.8/5.13.7\n",
      "/0.00.4*Valuesarepercentagewith(mean/median).0.10.20.30.4\n",
      "0.8\n",
      "Figure2:Hardcasecomparison.\n",
      "1\n",
      "Figure3:MotionsegmentationerrorsonHopkins155.\n",
      "Weconstructphasetransitionplotsasin[4,9]thatevaluatetherecovery\n",
      "successofeverypairingofoutlierratioandrankusingdataY=ZGT+EGT,\n",
      "whereY?Rm?nandm=n=200.ThegroundtruthoutliermatrixEGTisgen-\n",
      "eratedbyselectingnon-zeroentriesuniformlywithprobability??[0,1],andits\n",
      "magnitudesaresamplediidfromtheuniformdistributionU[?20,20].Wegen-\n",
      "eratethegroundtruthlow-rankmatrixbyZGT=AB>,whereA?Rn?rand\n",
      "B?Rm?raredrawnfromiidN(0,1).Figure1showscomparisonsamongcom-\n",
      "petingmethods,aswellastheconvexnuclearnormbasedmatrixcompletion\n",
      "(CVX-MC)[5],thelatterrepresentingafareasierestimationtaskgiventhat\n",
      "13\n",
      "\n",
      "missingentrylocations(analogoustocorruptions)occurinknownlocations.\n",
      "Thecolorofeachcellencodesthepercentageofsuccesstrials(outof10total)\n",
      "wherebythenormalizedroot-mean-squared?GTkFerror(NRMSE,kZ?Z)\n",
      "recoveringZGTislessthan0.001toclassifysuccessfollowing[4,9].kZGT\n",
      "kFNotablyPB-RPCAdisplaysamuchbroaderrecoverabilityregion.Thisim-\n",
      "provementisevenmaintainedoverTNN-RPCAandMCwhichrequireprior\n",
      "knowledgesuchasthetruerankandexactoutlierlocationsrespectively.These\n",
      "formsofpriorknowledgerasubstantialadvantage,althoughinpractical\n",
      "situationsareusuallyunavailable.PB-RPCAalsooutperformsPB-RPCAw/o\n",
      "sym.(itsclosestrelative)byawidemargin,suggestingthatthesymmetry\n",
      "playsanimportantrole.ThepoorperformanceofFB-RPCAisexplainedin\n",
      "[23].HardCaseComparison:RecoveryofGaussianiidlow-rankcomponents\n",
      "(thetypicalbenchmarkrecoveryproblemintheliterature)issomewhatideal\n",
      "forexistingalgorithmslikePCPbecausethesingularvectorsofZGTwillnot\n",
      "resembleunitvectorsthatcouldbemistakenforsparsecomponents.However,\n",
      "asimpletestrevealsjusthowbrittlePCPistodeviationsfromthetheoretically\n",
      "optimalregime.WegeneratearankoneZGT=?a3(b3)>,wherethecube\n",
      "operationisappliedelement-wise,aandbarevectorsdrawniidfromaunit\n",
      "sphere,and?scalesZGTtounitvariance.EGThasnonzeroelementsdrawn\n",
      "iidfromU[?1,1].Figure2showstherecoveryresultsastheoutlierratiois\n",
      "increased.Thehardcasereferstothedatajustdescribed,whiletheeasycase\n",
      "followsthemodelusedtomakethephasetransitionplots.WhilePB-RPCAis\n",
      "quitestable,PCPcompletelyfailsfortheharddata.OutlierRemovalforMo-\n",
      "tionSegmentation:Underancameramodel,thestackedmatrixconsisting\n",
      "offeaturepointtrajectoriesofkrigidlymovingobjectsformsaunionofk\n",
      "subspacesofatmostrank4k[29].Butinpractice,mismatchesoftenoccurdue\n",
      "toocclusionsortrackingalgorithmlimitations,andtheseintroducet\n",
      "outliersintothefeaturemotionssuchthatthecorrespondingtrajectorymatrix\n",
      "maybeatornearfullrank.Weadoptanexperimentalparadigmfrom[17]\n",
      "designedtotestmotionsegmentationestimationinthepresenceofoutliers.To\n",
      "mimicmismatcheswhileretainingaccesstoground-truth,werandomlycorrupt\n",
      "theentriesofthetrajectorymatrixformedfromHopkins155data[28].Sp\n",
      "cally,following[17]weaddnoisedrawnfromN(0,0.1?)torandomlysampled\n",
      "pointswithoutlierratio??[0,1],where?isthemaximumabsolutevalueofthe\n",
      "data.Wemaythenattempttorecoveracleanversionfromthecorruptedmea-\n",
      "surementsusingRPCAasapreprocessingstep;motionsegmentationcanthen\n",
      "beappliedusingstandardsubspaceclustering[29].WeuseSSCandrobustSSC\n",
      "algorithms[10]asbaselines,andcomparewithRPCApreprocessingcomputed\n",
      "viaPCP(assuggestedin[10])andPB-RPCAfollowedbySSC.Additionally,we\n",
      "sub-sampledthetrajectorymatrixtoincreaseproblemybyfewersam-\n",
      "ples.SegmentationaccuracyisreportedinFig.3,whereweobservethatPB\n",
      "showsthebestperformanceacrosstoutlierratios,andtheperformance\n",
      "gapwidenswhenthemeasurementsarescarce.\n",
      "6\n",
      "Conclusion\n",
      "SincetheintroductionofconvexRPCAalgorithms,therehasnotbeena\n",
      "14\n",
      "\n",
      "talgorithmicbreak-throughintermsofdramaticallyenhancingthe\n",
      "regimewheresuccessispossible,atleastintheabsenceofanypriorinformation\n",
      "(beyondthegenericlow-rankandsparsityassumptions).Thelikelyexplanation\n",
      "isthatessentiallyalloftheseapproachessolveeitheraproblemintheformof\n",
      "(4),anasymmetricproblemintheformof(11),orelserequirestrongpriori\n",
      "knowledge.Weprovideanovelintegrationofthreeimportantdesigncriteria,\n",
      "concavity,non-separability,andsymmetry,thatleadstostate-of-the-artresults\n",
      "byawidemarginwithouttuningparametersorpriorknowledge.8\n",
      "2References\n",
      "[1]S.D.Babacan,M.Luessi,R.Molina,andA.K.Katsaggelos.SparseBayesian\n",
      "methodsforlow-rankmatrixestimation.IEEETrans.SignalProcess.,2012.[2]\n",
      "C.M.Bishop.Patternrecognitionandmachinelearning.SpringerNewYork,\n",
      "2006.[3]S.Boyd,N.Parikh,E.Chu,B.Peleato,andJ.Eckstein.Distributed\n",
      "optimizationandstatisticallearningRinMachineLearning,2011.viatheal-\n",
      "ternatingdirectionmethodofmultipliers.FoundationsandTrends[4]E.J.\n",
      "Cand?s,X.Li,Y.Ma,andJ.Wright.Robustprincipalcomponentanalysis?J.\n",
      "oftheACM,2011.[5]E.J.Cand?sandB.Recht.Exactmatrixcompletionvia\n",
      "convexoptimization.FoundationsofComputationalmathematics,2009.[6]V.\n",
      "Chandrasekaran,S.Sanghavi,P.A.Parrilo,andA.S.Willsky.Rank-sparsity\n",
      "incoherenceformatrixdecomposition.SIAMJ.onOptim.,2011.[7]R.Char-\n",
      "trand.Nonconvexsplittingforregularizedlow-rank+sparsedecomposition.\n",
      "IEEETrans.SignalProcess.,2012.[8]Y.-L.ChenandC.-T.Hsu.Ageneral-\n",
      "izedlow-rankappearancemodelforspatio-temporallycorrelatedrainstreaks.\n",
      "InIEEEInt.Conf.Comput.Vis.,2013.[9]X.Ding,L.He,andL.Carin.\n",
      "Bayesianrobustprincipalcomponentanalysis.IEEETrans.ImageProcess.,\n",
      "2011.[10]E.ElhamifarandR.Vidal.Sparsesubspaceclustering:Algorithm,\n",
      "theory,andapplications.IEEETrans.PatternAnal.andMach.Intell.,2013.\n",
      "[11]J.FanandR.Li.Variableselectionvianonconcavepenalizedlikelihood\n",
      "anditsoracleproperties.J.Am.Stat.Assoc.,2001.[12]D.R.HunterandK.\n",
      "Lange.AtutorialonMMalgorithms.TheAmericanStatistician,2004.[13]H.\n",
      "Ji,C.Liu,Z.Shen,andY.Xu.Robustvideodenoisingusinglowrankmatrix\n",
      "completion.InIEEEConf.Comput.Vis.andPatternRecognit.,2010.[14]\n",
      "M.I.Jordan,Z.Ghahramani,T.S.Jaakkola,andL.K.Saul.Anintroduction\n",
      "tovariationalmethodsforgraphicalmodels.Mach.Learn.,1999.[15]B.Lak-\n",
      "shminarayanan,G.Bouchard,andC.Archambeau.RobustBayesianmatrix\n",
      "factorisation.InAISTATS,2011.[16]Z.Lin,M.Chen,andY.Ma.Theaug-\n",
      "mentedLagrangemultipliermethodforexactrecoveryofcorruptedlow-rank\n",
      "matrices.arXiv:1009.5055,2010.[17]G.LiuandS.Yan.Latentlow-rank\n",
      "representationforsubspacesegmentationandfeatureextraction.InIEEEInt.\n",
      "Conf.Comput.Vis.,2011.[18]C.Lu,Z.Lin,andS.Yan.Smoothedlow\n",
      "rankandsparsematrixrecoverybyiterativelyreweightedleastsquaresmini-\n",
      "mization.IEEETrans.ImageProcess.,2015.[19]K.MohanandM.Fazel.\n",
      "Iterativereweightedalgorithmsformatrixrankminimization.J.Mach.Learn.\n",
      "15\n",
      "\n",
      "Res.,2012.[20]K.P.Murphy.MachineLearning:aProbabilisticPerspective.\n",
      "MITPress,2012.[21]K.P.Murphy,Y.Weiss,andM.I.Jordan.Loopybelief\n",
      "propagationforapproximateinference:Anempiricalstudy.InUAI,1999.[22]\n",
      "T.-H.Oh,J.-Y.Lee,Y.-W.Tai,andI.S.Kweon.Robusthighdynamicrange\n",
      "imagingbyrankminimization.IEEETrans.PatternAnal.andMach.Intell.,\n",
      "2015.[23]T.-H.Oh,Y.Matsushita,I.S.Kweon,andD.Wipf.Pseudo-Bayesian\n",
      "robustPCA:Algorithmsandanalyses.arXivpreprintarXiv:1512.02188,2015.\n",
      "[24]T.-H.Oh,Y.-W.Tai,J.-C.Bazin,H.Kim,andI.S.Kweon.Partialsum\n",
      "minimizationofsingularvaluesinRobustPCA:Algorithmandapplications.\n",
      "IEEETrans.PatternAnal.andMach.Intell.,2016.[25]J.A.Palmer.Rel-\n",
      "ativeconvexity.ECEDept.,UCSD,Tech.Rep,2003.[26]J.T.Parker,P.\n",
      "Schniter,andV.Cevher.Bilineargeneralizedapproximatemessagepassing.\n",
      "arXiv:1310.2632,2013.[27]Y.Peng,A.Ganesh,J.Wright,W.Xu,andY.\n",
      "Ma.RASL:Robustalignmentbysparseandlow-rankdecompositionforlin-\n",
      "earlycorrelatedimages.IEEETrans.PatternAnal.andMach.Intell.,2012.\n",
      "[28]R.TronandR.Vidal.Abenchmarkforthecomparisonof3-dmotion\n",
      "segmentationalgorithms.InIEEEConf.Comput.Vis.andPatternRecognit.,\n",
      "2007.[29]R.Vidal.Subspaceclustering.IEEESignalProcess.Mag.,2011.\n",
      "[30]N.WangandD.-Y.Yeung.Bayesianrobustmatrixfactorizationforimage\n",
      "andvideoprocessing.InIEEEInt.Conf.Comput.Vis.,2013.[31]D.Wipf.\n",
      "Non-convexrankminimizationviaanempiricalBayesianapproach.InUAI,\n",
      "2012.[32]D.Wipf,B.D.Rao,andS.Nagarajan.LatentvariableBayesian\n",
      "modelsforpromotingsparsity.IEEETrans.onInformationTheory,2011.[33]\n",
      "L.Wu,A.Ganesh,B.Shi,Y.Matsushita,Y.Wang,andY.Ma.Robustpho-\n",
      "tometricstereovialow-rankmatrixcompletionandrecovery.InAsianConf.\n",
      "Comput.Vis.,2010.[34]B.XinandD.Wipf.Pushingthelimitsofrank\n",
      "minimizationbyadaptingprobabilisticPCA.InInt.Conf.Mach.Learn.,2015.\n",
      "9\n",
      "16\n",
      "\n",
      "PP4427.pdf\n",
      "PP4427.pdf 13\n",
      "ActiveRankingusingPairwiseComparisons\n",
      "Authoredby:\n",
      "RobertNowak\n",
      "KevinG.Jamieson\n",
      "Abstract\n",
      "Thispaperexaminestheproblemofrankingacollectionofobjectsus-\n",
      "ingpairwisecomparisons(rankingsoftwoobjects).Ingeneral,theranking\n",
      "of$n$objectscanbeidenbystandardsortingmethodsusing$nlog\n",
      "2\n",
      "n$pairwisecomparisons.Weareinterestedinnaturalsituationsinwhich\n",
      "relationshipsamongtheobjectsmayallowforrankingusingfarfewer\n",
      "pairwisecomparisons.\n",
      "f\n",
      "Sp,weassumethattheobjectscanbe\n",
      "embeddedintoa$d$-dimensionalEuclideanspaceandthattherankings\n",
      "theirrelativedistancesfromacommonreferencepointin$Rd$.We\n",
      "showthatunderthisassumptionthenumberofpossiblerankingsgrows\n",
      "like$n\n",
      "f\n",
      "2d\n",
      "g\n",
      "$anddemonstrateanalgorithmthatcanidentifyarandomly\n",
      "selectedrankingusingjustslightlymorethan$dlogn$adaptivelyselected\n",
      "pairwisecomparisons,onaverage.\n",
      "g\n",
      "Ifinsteadthecomparisonsarechosen\n",
      "atrandom,thenalmostallpairwisecomparisonsmustbemadeinorder\n",
      "toidentifyanyranking.Inaddition,weproposearobust,error-tolerant\n",
      "algorithmthatonlyrequiresthatthepairwisecomparisonsareprobably\n",
      "correct.Experimentalstudieswithsyntheticandrealdatasetssupport\n",
      "theconclusionsofourtheoreticalanalysis.\n",
      "1PaperBody\n",
      "Thispaperaddressestheproblemofrankingasetofobjectsbasedonalimited\n",
      "numberofpairwisecomparisons(rankingsbetweenpairsoftheobjects).A\n",
      "rankingoverasetofnobjects?=(?1,?2,...,?n)isamapping?:\n",
      "f\n",
      "1,.\n",
      "..,n\n",
      "g\n",
      "?\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "thatprescribesanorder?(?):=??(1)???(2)?????\n",
      "??(n?1)???(n)\n",
      "(1)\n",
      "where?i??jmeans?iprecedes?jintheranking.Arankinguniquely\n",
      "determinesthecollectionofpairwisecomparisonsbetweenallpairsofobjects.\n",
      "Theprimaryobjectivehereistoboundthenumberofpairwisecomparisons\n",
      "neededtocorrectlydeterminetherankingwhentheobjects(andhencerank-\n",
      "ings)satisfycertainknownstructuralconstraints.Sp,wesupposethat\n",
      "theobjectsmaybeembeddedintoalow-dimensionalEuclideanspacesuchthat\n",
      "therankingisconsistentwithdistancesinthespace.Wewishtoexploitsuch\n",
      "1\n",
      "\n",
      "structureinordertodiscovertherankingusingaverysmallnumberofpairwise\n",
      "comparisons.Tothebestofourknowledge,thisisapreviouslyopenandun-\n",
      "solvedproblem.Therearepracticalandtheoreticalmotivationsforrestricting\n",
      "ourattentiontopairwiserankingsthatarediscussedinSection2.Webeginby\n",
      "assumingthateverypairwisecomparisonisconsistentwithanunknownrank-\n",
      "ing.Eachpairwisecomparisoncanbeviewedasaquery:is?ibefore?j?Each\n",
      "queryprovides1bitofinformationabouttheunderlyingranking.Sincethe\n",
      "numberofrankingsisn!,ingeneral,specifyingarankingrequires?(nlogn)\n",
      "bitsofinformation.Thisimpliesthatatleastthismanypairwisecomparisons\n",
      "arerequiredwithoutadditionalassumptionsabouttheranking.Infact,this\n",
      "lowerboundcanbeachievedwithastandardadaptivesortingalgorithmlike\n",
      "binarysort[1].Inlarge-scaleproblemsorwhenhumansarequeriedforpairwise\n",
      "comparisons,obtainingthismanypairwisecomparisonsmaybeimpracticaland\n",
      "thereforeweconsidersituationsinwhichthespaceofrankingsisstructuredand\n",
      "therebylesscomplex.1\n",
      "Anaturalwaytoinduceastructureonthespaceofrankingsistosuppose\n",
      "thattheobjectscanbeembeddedintoad-dimensionalEuclideanspacesothat\n",
      "thedistancesbetweenobjectsareconsistentwiththeranking.Thismaybea\n",
      "reasonableassumptioninmanyapplications,andforinstancetheaudiodataset\n",
      "usedinourexperimentsisbelievedtohavea2or3dimensionalembedding\n",
      "[2].WefurtherdiscussmotivationsforthisassumptioninSection2.Itisnot\n",
      "toshow(seeSection3)thatthenumberoffullrankingsthatcouldarise\n",
      "fromnobjectsembeddedinRdgrowsliken2d,andsospecifyingaranking\n",
      "fromthisclassrequiresonlyO(dlogn)bits.Themainresultsofthepaper\n",
      "showthatunderthisassumptionarandomlyselectedrankingcanbedeter-\n",
      "minedusing?O(d?logn)pairwisecomparisonsselectedinanadaptiveand\n",
      "sequentialfashion,butalmostalln2pairwiserankingsareneedediftheyare\n",
      "pickedrandomlyratherthanselectively.Inotherwords,activelyselectingthe\n",
      "mostinformativequerieshasatremendousimpactonthecomplexityoflearning\n",
      "thecorrectranking.1.1\n",
      "Problemstatement\n",
      "Let?denotetherankingtobelearned.Theobjectiveistolearntheranking\n",
      "byqueryingthereferenceforpairwisecomparisonsoftheformqi,j:=\n",
      "f\n",
      "?i??j\n",
      "g\n",
      ".\n",
      "(2)\n",
      "Theresponseorlabelofqi,jisbinaryanddenotedasyi,j:=1\n",
      "f\n",
      "qi,j\n",
      "g\n",
      "where\n",
      "1istheindicatorfunction;tiesarenotallowed.Themainresultsquantify\n",
      "theminimumnumberofqueriesorlabelsrequiredtodeterminethereference?s\n",
      "ranking,andtheyarebasedontwokeyassumptions.A1Embedding:Thesetof\n",
      "nobjectsareembeddedinRd(ingeneralposition)andwewillalsouse?1,...\n",
      ",?ntorefertotheir(known)locationsinRd.Everyranking?canbesp\n",
      "byareferencepointr??Rd,asfollows.TheEuclideandistancesbetweenthe\n",
      "referenceandobjectsareconsistentwiththerankinginthefollowingsense:if\n",
      "the?ranks?i??j,then??i?r??<??j?r??.Let?n,ddenotethesetofall\n",
      "possiblerankingsofthenobjectsthatsatisfythisembeddingcondition.The\n",
      "interpretationofthisassumptionisthatweknowhowtheobjectsarerelated\n",
      "2\n",
      "\n",
      "(intheembedding),whichlimitsthespaceofpossiblerankings.Therankingto\n",
      "belearned,spbythereference(e.g.,preferencesofahumansubject),is\n",
      "unknown.Manyhavestudiedtheproblemofanembeddingofobjects\n",
      "fromdata[3,4,5].Thisisnotthefocushere,butitcouldcertainlyplaya\n",
      "supportingroleinourmethodology(e.g.,theembeddingcouldbedetermined\n",
      "fromknownsimilaritiesbetweenthenobjects,asisdoneinourexperiments\n",
      "withtheaudiodataset).Weassumetheembeddingisgivenandourinterest\n",
      "isminimizingthenumberofqueriesneededtolearntheranking,andforthis\n",
      "werequireasecondassumption.A2Consistency:Everypairwisecomparisonis\n",
      "consistentwiththerankingtobelearned.Thatis,ifthereferenceranks?i??j\n",
      ",then?imustprecede?jinthe(full)ranking.\n",
      "AswewilldiscusslaterinSection3.2,thesetwoassumptionsalonearenot\n",
      "enoughtoruleoutpathologicalarrangementsofobjectsintheembeddingfor\n",
      "whichatleast?(n)queriesmustbemadetorecovertheranking.However,\n",
      "becausesuchsituationsarenotrepresentativeofwhatistypicallyencountered,\n",
      "weanalyzetheproblemintheframeworkoftheaverage-caseanalysis[6].?\n",
      "1.Witheachranking???n,dweassociateaprobability??such\n",
      "that???n,d??=1.Let?denotetheseprobabilitiesandwrite???for\n",
      "shorthand.Theuniformdistributioncorrespondsto??=|?n,d|?1forall\n",
      "???n,d,andwewrite??Uforthisspecialcase.2.IfMn\n",
      "(?)denotesthenumberofpairwisecomparisonsrequestedbyanalgorithmto\n",
      "identifytheranking?,thentheaveragequerycomplexitywithrespectto?\n",
      "isdenotedbyE?[Mn].Themainresultsareprovenforthespecialcaseof\n",
      "?=U,theuniformdistribution,tomaketheanalysismoretransparentand\n",
      "intuitive.Howevertheresultscaneasilybeextendedtogeneraldistributions?\n",
      "thatsatisfycertainmildconditions[7].Allresultshenceforth,unlessotherwise\n",
      "noted,willbegivenintermsof(uniform)averagequerycomplexityandwewill\n",
      "saysuchresultshold?onaverage.?Ourmainresultscanbesummarizedas\n",
      "follows.Ifthequeriesarechosendeterministicallyorrandomly??inadvance\n",
      "ofcollectingthecorrespondingpairwisecomparisons,thenweshowthatalmost\n",
      "alln2pairwisecomparisonsqueriesareneededtoidentifyarankingunderthe\n",
      "assumptionsabove.However,ifthequeriesareselectedinanadaptiveand\n",
      "sequentialfashionaccordingtothealgorithm2\n",
      "QuerySelectionAlgorithminput:nobjectsinRdinitialize:objects?1,.\n",
      "..,?ninuniformlyrandomorderforj=2,...,nfori=1,...,j-1ifqi,jis\n",
      "ambiguous,requestqi,j?slabelfromreference;elseimputeqi,j?slabelfrom\n",
      "previouslylabeledqueries.output:rankingofnobjects\n",
      "q1\n",
      "q2,3,2\n",
      "?2\n",
      "q1,3\n",
      "?1\n",
      "?3\n",
      "Figure2:Objects?1,?2,?3andqueries.Ther?liesintheshadedregion\n",
      "(consistentwiththelabelsofq1,2,q1,3,q2,3).Thedotted(dashed)lines\n",
      "representnewquerieswhoselabelsare(arenot)ambiguousgiventhoselabels.\n",
      "3\n",
      "\n",
      "Figure1:Sequentialalgorithmforselectingqueries.SeeFigure2andSection\n",
      "4.2fortheofanambiguousquery.\n",
      "inFigure1,thenweshowthatthenumberofpairwiserankingsrequiredto\n",
      "identifyarankingisnomorethanaconstantmultipleofdlogn,onaverage.\n",
      "Thealgorithmrequestsaqueryifandonlyifthecorrespondingpairwiserank-\n",
      "ingisambiguous(seeSection4.2),meaningthatitcannotbedeterminedfrom\n",
      "previouslycollectedpairwisecomparisonsandthelocationsoftheobjectsin\n",
      "Rd.Theofthealgorithmisduetothefactthatmostofthequeries\n",
      "areunambiguouswhenconsideredinasequentialfashion.Forthisverysame\n",
      "reason,pickingqueriesinanon-adaptiveorrandomfashionisveryt.\n",
      "Itisalsonoteworthythatthealgorithmisalsocomputationallytwithan\n",
      "overallcomplexitynogreaterthanO(npoly(d)poly(logn))[7].InSection5we\n",
      "presentarobustversionofthealgorithmofFigure1thatistoleranttoafraction\n",
      "oferrorsinthepairwisecomparisonqueries.Inthecaseofpersistenterrors(see\n",
      "Section5)weshowthatatleastO(n/logn)objectscanbecorrectlyrankedin\n",
      "apartialrankingwithhighprobabilitybyrequestingjustO(dlog2n)pairwise\n",
      "comparisons.Thisallowsustohandlesituationsinwhicheitherorbothof\n",
      "theassumptions,A1andA2,arereasonableapproximationstothesituationat\n",
      "hand,butdonotholdstrictly(whichisthecaseinourexperimentswiththe\n",
      "audiodataset).Provingthemainresultsinvolvesanuncommonmarriageof\n",
      "ideasfromtherankingandstatisticallearningliteratures.Geometricalinter-\n",
      "pretationsofourproblemderivefromtheseminalworksof[8]inrankingand\n",
      "[9]inlearning.Fromthisperspectiveourproblembearsastrongresemblance\n",
      "tothehalfspacelearningproblem,withtwocrucialdistinctions.Intheranking\n",
      "problem,theunderlyinghalfspacesarenotingeneralpositionandhavestrong\n",
      "dependencieswitheachother.Thesedependenciesinvalidatemanyofthetypi-\n",
      "calanalysesofsuchproblems[10,11].Onepopularmethodofanalysisinexact\n",
      "learninginvolvestheuseofsomethingcalledtheextendedteachingdimension\n",
      "[12].However,becauseofthepossiblepathologicalsituationsalludedtoearlier,\n",
      "itiseasytoshowthattheextendedteachingdimensionmustbeatleast?(n)\n",
      "makingthatsortofworst-caseanalysisuninteresting.Thesepresent\n",
      "uniquechallengestolearning.\n",
      "2\n",
      "Motivationandrelatedwork\n",
      "Theproblemoflearningarankingfromfewpairwisecomparisonsismoti-\n",
      "vatedbywhatweperceiveasatgapinthetheoryofrankingand\n",
      "permutationlearning.Mostworkinrankingassumesapassiveapproachto\n",
      "learning;pairwisecomparisonsorpartialrankingsarecollectedinarandom\n",
      "ornon-adaptivefashionandthenaggregatedtoobtainafullranking(cf.[13,\n",
      "14,15,16]).However,thismaybequitetintermsofthenumber\n",
      "ofpairwisecomparisonsorpartialrankingsneededtolearnthe(full)ranking.\n",
      "Thiswasrecentlynotedintherelatedareaofsocialchoicetheory\n",
      "[17].Furthermore,empiricalevidencesuggeststhat,evenundercomplexrank-\n",
      "ingmodels,adaptivelyselectingpairwisecomparisonscanreducethenumber\n",
      "neededtolearntheranking[18].Itiscauseforconcernsinceinmanyapplica-\n",
      "tionsitisexpensiveandtime-consumingtoobtainpairwisecomparisons.For\n",
      "4\n",
      "\n",
      "example,psychologistsandmarketresearcherscollectpairwisecomparisonsto\n",
      "gaugehumanpreferencesoverasetofobjects,forscienunderstandingor\n",
      "productplacement.Thescopeoftheseexperimentsisoftenverylimitedsimply\n",
      "duetothetimeandexpenserequired3\n",
      "tocollectthedata.Thissuggeststheconsiderationofmoreselectiveand\n",
      "judiciousapproachestogatheringinputsforranking.Weareinterestedintak-\n",
      "ingadvantageofunderlyingstructureinthesetofobjectsinordertochoose\n",
      "moreinformativepairwisecomparisonqueries.Fromalearningperspective,our\n",
      "workaddsanactivelearningcomponenttoaproblemdomainthathasprimarily\n",
      "beentreatedfromapassivelearningmindset.Wefocusonpairwisecomparison\n",
      "queriesfortworeasons.First,pairwisecomparisonsadmitahalfspacerepresen-\n",
      "tationinembeddingspaceswhichallowsforageometricalapproachtolearning\n",
      "insuchstructuredrankingspaces.Second,pairwisecomparisonsarethemost\n",
      "commonformofqueriesinmanyapplications,especiallythoseinvolvinghuman\n",
      "subjects.Forexample,considertheproblemofthemosthighlyranked\n",
      "object,asillustratedbythefollowingfamiliartask.Supposeapatientneedsa\n",
      "newpairofprescriptioneyelenses.Facedwithliterallymillionsofpossiblepre-\n",
      "scriptions,thedoctorwillpresentcandidateprescriptionsinasequentialfashion\n",
      "followedbythequery:betterorworse?Evenifcertainqueriesarerepeatedto\n",
      "accountforpossibleinaccurateanswers,thedoctorcanlocateanaccuratepre-\n",
      "scriptionwithjustahandfulofqueries.Thisispossiblepresumablybecausethe\n",
      "doctorunderstands(atleastintuitively)theintrinsicspaceofprescriptionsand\n",
      "cantlysearchthroughitusingonlybinaryresponsesfromthepatient.\n",
      "WeassumethattheobjectscanbeembeddedinRdandthatthedistances\n",
      "betweenobjectsandthereferenceareconsistentwiththeranking(Assumption\n",
      "A1).Theproblemoflearningageneralfunctionf:Rd?Rusingjustpairwise\n",
      "comparisonsthatcorrectlyrankstheobjectsembeddedinRdhaspreviously\n",
      "beenstudiedinthepassivesetting[13,14,15,16].Themaincontributionsof\n",
      "thispaperaretheoreticalboundsforthespcasewhenf(x)=||x?r?\n",
      "||wherer??Rdisthereferencepoint.Thisisastandardmodelusedin\n",
      "multidimensionalunfoldingandpsychometrics[8,19].Weareunawareofany\n",
      "existingquery-complexityboundsforthisproblem.Wedonotassumeagener-\n",
      "ativemodelisresponsiblefortherelationshipbetweenrankingstoembeddings,\n",
      "butonecould.Forexample,theobjectsmighthaveanembedding(inafeature\n",
      "space)andtherankingisgeneratedbydistancesinthisspace.Oralternatively,\n",
      "structuralconstraintsonthespaceofrankingscouldbeusedtogenerateacon-\n",
      "sistentembedding.AssumptionA1,whilearguablyquitenatural/reasonablein\n",
      "manysituations,tlyconstrainsthesetofpossiblerankings.\n",
      "3\n",
      "Geometryofrankingsfrompairwisecomparisons\n",
      "TheembeddingassumptionA1givesrisetogeometricalinterpretationsof\n",
      "therankingproblem,whicharedevelopedinthissection.Thepairwisecompar-\n",
      "isonqi,jcanbeviewedasthemembershipquery:is?irankedbefore?jinthe\n",
      "(full)ranking??Thegeometricalinterpretationisthatqi,jrequestswhether\n",
      "thereferencer?isclosertoobject?iorobject?jinRd.Considerthelinecon-\n",
      "necting?iand?jinRd.Thehyperplanethatbisectsthislineandisorthogonal\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toittwohalfspaces:onecontainingpointscloserto?iandtheotherthe\n",
      "pointscloserto?j.Thus,qi,jisamembershipqueryaboutwhichhalfspace\n",
      "r?isin,andthereisanequivalencebetweeneachquery,eachpairofobjects,\n",
      "andthecorresponding?bisectinghyperplane.Thesetofallpossiblepairwise\n",
      "comparison?queriescanberepresentedasn2distincthalfspacesinRd.The\n",
      "intersectionsofthesehalfspacespartitionRdintoanumberofcells,andeach\n",
      "onecorrespondstoauniquerankingof?.Arbitraryrankingsarenotpossible\n",
      "duetotheembeddingassumptionA1,andrecallthatthesetofrankingspossi-\n",
      "bleunderA1isdenotedby?n,d.Thecardinalityof?n,disequaltothenumber\n",
      "ofcellsinthepartition.Wewillrefertothesecellsasd-cells(toindicatethey\n",
      "aresubsetsind-dimensionalspace)sinceattimeswewillalsorefertolower\n",
      "dimensionalcells;e.g.,(d?1)-cells.3.1\n",
      "Countingthenumberofpossiblerankings\n",
      "Thefollowinglemmadeterminesthecardinalityofthesetofrankings,?n,d\n",
      ",underassumptionA1.Lemma1.[8]AssumeA1-2.LetQ(n,d)denotethe\n",
      "numberofd-cellsbythehyperplanearrangementofpairwisecompar-\n",
      "isonsbetweentheseobjects(i.e.Q(n,d)=|?n,d|).Q(n,d)the\n",
      "recursionQ(n,d)=Q(n?1,d)+(n?1)Q(n?1,d?1),whereQ(1,d)=1\n",
      "andQ(n,0)=1.\n",
      "(3)\n",
      "Inthehyperplanearrangementinducedbythenobjectsinddimensions,\n",
      "eachhyperplaneisintersectedbyeveryotherandispartitionedintoQ(n?1,\n",
      "d?1)subsetsor(d?1)-cells.Therecursion,4\n",
      "above,arisesbyconsideringtheadditionofoneobjectatatime.Using\n",
      "thislemmainastraightforwardfashion,weprovethefollowingcorollaryin[7].\n",
      "Corollary1.AssumeA1-2.Thereexistpositiverealnumbersk1andk2such\n",
      "thatn2dn2d<Q(n,d)<k22dd!2dd!forn>d+1.Ifn?d+1thenQ(n,\n",
      "d)=n!.Forntlylarge,k1=1andk2=2k1\n",
      "3.2\n",
      "Lowerboundsonquerycomplexity\n",
      "Sincethecardinalityofthesetofpossiblerankingsis|?n,d|=Q(n,d),\n",
      "wehaveasimplelowerboundonthenumberofqueriesneededtodeterminethe\n",
      "ranking.Theorem1.AssumeA1-2.Toreconstructanarbitraryranking??\n",
      "?n,danyalgorithmwillrequireatleastlog2|?n,d|=?(2dlog2n)pairwise\n",
      "comparisons.Proof.ByCorollary1|?n,d|=?(n2d),andsoatleast2dlog\n",
      "nbitsareneededtospecifyaranking.Eachpairwisecomparisonprovidesat\n",
      "mostonebit.Ifeachqueryprovidesafullbitofinformationabouttheranking,\n",
      "thenweachievethislowerbound.Forexample,intheone-dimensionalcase(d\n",
      "=1)theobjectscanbeorderedandbinarysearchcanbeusedtoselectpairwise\n",
      "comparisonqueries,achievingthelowerbound.Thisisgenerallyimpossiblein\n",
      "higherdimensions.Evenintwodimensionsthereareplacementsoftheobjects\n",
      "(stillingeneralposition)thatproduced-cellsinthepartitioninducedbyqueries\n",
      "thathaven?1faces(i.e.,boundedbyn?1hyperplanes)asshownin[7].It\n",
      "followsthattheworstcasesituationmayrequireatleastn?1queriesin\n",
      "dimensionsd?2.Inlightofthis,weconcludethatworstcaseboundsmaybe\n",
      "overlypessimisticindicationsofthetypicalsituation,andsoweinsteadconsider\n",
      "6\n",
      "\n",
      "theaveragecaseperformanceintroducedinSection1.1.3.3\n",
      "ofrandomqueries\n",
      "Thegeometricalrepresentationoftherankingproblemrevealsthatrandomly\n",
      "choosingpairwisecomparisonqueriesistrelativetothelowerbound\n",
      "??above.Toseethis,supposemquerieswerechosenuniformlyatrandom\n",
      "fromthepossiblen2.Theanswerstomqueriesnarrowsthesetofpossible\n",
      "rankingstoad-cellinRd.Thisd-cellmayconsistofoneormoreofthed-\n",
      "cellsinthepartitioninducedbyallqueries.Ifitcontainsmorethanoneof\n",
      "thepartitioncells,thentheunderlyingrankingisambiguous.??Theorem2.\n",
      "AssumeA1-2.LetN=n2.Suppose??mpairwisecomparisonarechosen\n",
      "uniformlyatrandomwithoutreplacementfromthepossiblen2.Thenforall\n",
      "positiveintegersN?m?dthe???N?emdprobabilitythatthemqueries\n",
      "yieldauniquerankingismd/d?(N).Proof.Nofewerthandhyperplanes\n",
      "boundeachd-cellinthepartitionofRdinducedbyallpossiblequeries.The\n",
      "probabilityofselectingdspeccqueriesinarandomdrawofmisequalto?\n",
      "???????????dd??dN?dNmNmdddmdem?=??.?m?dmdd\n",
      "d!NdNd!N???N?2Notethatmd/d<1/2unlessm=?(n).Therefore,\n",
      "ifthequeriesarerandomlychosen,thenwewillneedtoaskalmostallqueries\n",
      "toguaranteethattheinferredrankingisprobablycorrect.\n",
      "4\n",
      "Analysisofsequentialalgorithmforqueryselection\n",
      "NowconsiderthebasicsequentialprocessofthealgorithminFigure1.Sup-\n",
      "posewehaverankedk?1ofthenobjects.Calltheseobjects1throughk\n",
      "?1.Thisplacesthereferencer?withinad-cellbythelabelsofthe\n",
      "comparisonqueriesbetweenobjects1,...,k?1).Callthisd-cellCk?1.\n",
      "Nowsupposewepickanotherobjectatrandomandcallitobjectk.Acom-\n",
      "parisonquerybetweenobjectkandoneofobjects1,...,k?1canonlybe\n",
      "informative(i.e.,ambiguous)iftheassociatedhyperplaneintersectsthisd-cell\n",
      "Ck?1(seeFigure2).Ifkistlylargerthand,thenitturnsoutthat\n",
      "thecellCk?1isprobablyquitesmallandtheprobabilitythatoneofthequeries\n",
      "intersectsCk?1isverysmall;infacttheprobabilityisontheorderof1/k2.5\n",
      "4.1\n",
      "Hyperplane-pointduality\n",
      "Considerahyperplaneh=(h0,h1,...,hd)with(d+1)parameters\n",
      "inRdandapointp=(p1,...,pd)?Rdthatdoesnotlieonthe\n",
      "hyperplane.Checkingwhichhalfspacepfallsin,i.e.,h1p1+h2p2+???\n",
      "+hdpd+h0?0,hasadualinterpretation:hisapointinRd+1andpisa\n",
      "hyperplaneinRd+1passingthroughtheorigin(i.e.,withdfreeparameters).\n",
      "Recallthateachpossiblerankingcanberepresentedbyareferencepoint?r??\n",
      "?Rd.Ourproblemistodeterminetheranking,orequivalentlythevectorof\n",
      "responsestothen2queriesrepresentedbyhyperplanesin?R?d.Usingthe\n",
      "aboveobservation,weseethatourproblemisequivalenttoalabeling\n",
      "overn2pointsinRd+1withasfewqueriesaspossible.Wewillrefertothis\n",
      "alternativerepresentationasthedualandtheformerastheprimal.4.2\n",
      "Characterizationofanambiguousquery\n",
      "Thecharacterizationofanambiguousqueryhasinterpretationsinboththe\n",
      "7\n",
      "\n",
      "primalanddualspaces.Wewillnowdescribetheinterpretationinthedual\n",
      "whichwillbecriticaltoouranalysisofthesequentialalgorithmofFigure1.\n",
      "3.[9]LetSbeasubsetofRdandletS+?Sbepointslabeled\n",
      "+1andS?=SS+bethepointslabeled?1andletxbeanyotherpointexcept\n",
      "theorigin.IfthereexiststwohomogeneouslinearseparatorsofS+andS?that\n",
      "assigntlabelstothepointx,thenthelabelofxissaidtobeambiguous\n",
      "withrespecttoS.Lemma2.[9,Lemma1]Thelabelofxisambiguouswith\n",
      "respecttoSifandonlyifS+andS?arehomogeneouslylinearlyseparableby\n",
      "a(d?1)-dimensionalsubspacecontainingx.\n",
      "Letusconsidertheimplicationsofthislemmatoourscenario.Assumethat\n",
      "wehavelabelsforallthepairwisecomparisonsofk?1objects.Nextconsider\n",
      "anewobjectcalledobjectk.Inthedual,thepairwisecomparisonbetween\n",
      "objectkandobjecti,forsomei?\n",
      "f\n",
      "1,...,k?1\n",
      "g\n",
      ",isambiguousifandonlyif\n",
      "thereexistsahyperplanethatstillseparatestheoriginalpointsandalsopasses\n",
      "throughthisnewpoint.Intheprimal,thisseparatinghyperplanecorrespondsto\n",
      "apointlyingonthehyperplanedenedbytheassociatedpairwisecomparison.\n",
      "4.3\n",
      "Theprobabilitythataqueryisambiguous\n",
      "AnessentialcomponentofthesequentialalgorithmofFigure1istheinitial\n",
      "randomorderoftheobjects;everysequenceinwhichitcouldconsiderobjects\n",
      "isequallyprobable.Thisallowsustostateanontrivialfactaboutthepartial\n",
      "rankingsofthekobjectsobservedinthissequence.Lemma3.Assume\n",
      "A1-2and????U.ConsiderthesubsetS??with|S|=kthatisrandomly\n",
      "selectedfrom?suchthatallnksubsetsareequallyprobable.If?k,ddenotes\n",
      "thesetofpossiblerankingsofthesekobjectsthenevery???k,disequally\n",
      "probable.\n",
      "Proof.Letak-partitiondenotethepartitionofRdintoQ(k,d)d-cells\n",
      "inducedbykobjectsfor1?k?n.Inthen-partition,eachd-cellisweighted\n",
      "uniformlyandisequalto1/Q(n,d).Ifweuniformlyatrandomselectkobjects\n",
      "fromthepossiblenandconsiderthek-partition,eachd-cellinthek-partition\n",
      "willcontainoneormored-cellsofthen-partition.Ifweselectoneofthesed-cells\n",
      "fromthek-partition,onaveragetherewillbeQ(n,d)/Q(k,d)d-cellsfromthe\n",
      "n-partitioncontainedinthiscell.Thereforetheprobabilitymassineachd-cell\n",
      "ofthek-partitionisequaltothenumberofcellsfromthen-partitioninthiscell\n",
      "multipliedbytheprobabilityofeachofthosecellsfromthen-partition:Q(n,\n",
      "d)/Q(k,d)?1/Q(n,d)=1/Q(k,d),and|?k,d|=Q(k,d).Asdescribed\n",
      "above,for1?i?ksomeofthepairwisecomparisonsqi,k+1maybeambiguous.\n",
      "Thealgorithmchoosesarandomsequenceofthenobjectsinitsinitialization\n",
      "anddoesnotusethelabelsofq1,k+1,...,qj?1,k+1,qj+1,k+1,...\n",
      ",qk,k+1tomakeadeterminationofwhetherornotqj,k+1isambiguous.It\n",
      "followsthattheeventsofrequestingthelabelofqi,k+1fori=1,2,...,kare\n",
      "independentandidenticallydistributed(conditionallyontheresultsofqueries\n",
      "fromprevioussteps).Thereforeitmakessensetotalkabouttheprobability\n",
      "ofrequestinganyoneofthem.Lemma4.AssumeA1-2and??U.LetA(k,\n",
      "d,U)denotetheprobabilityoftheeventthatthepairwisecomparisonqi,k+1\n",
      "isambiguousfori=1,2,...,k.Thenthereexistspositive,realnumber\n",
      "8\n",
      "\n",
      "constantsa1anda2independentofksuchthatfork>2d,a1k2d2?A(k,d,U\n",
      ")?a2k2d2.6\n",
      "Proof.ByLemma2,apointinthedual(pairwisecomparison)isambiguous\n",
      "ifandonlyifthereexistsaseparatinghyperplanethatpassesthroughthispoint.\n",
      "Thisimpliesthatthehyperplanerepresentationofthepairwisecomparisonin\n",
      "theprimalintersectsthecellcontainingr?(seeFigure2foranillustration\n",
      "ofthisconcept).ConsiderthepartitionofRdgeneratedbythehyperplanes\n",
      "correspondingtopairwisecomparisonsbetweenobjects1,...,k.LetP\n",
      "(k,d)denotethenumberofd-cellsinthispartitionthatareintersectedbya\n",
      "hyperplanecorrespondingtooneofthequeriesqi,k+1,i?\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      ".Then\n",
      "itisnottoshowthatP(k,d)isboundedaboveandbelowbyk2(d?1)\n",
      "constantsindependentofnandktimes2d?1[7].ByLemma3,everyd-cellin\n",
      "thepartition(d?1)!inducedbythekobjectscorrespondstoanequallyprobable\n",
      "rankingofthoseobjects.Therefore,theprobabilitythataqueryisambiguousis\n",
      "thenumberofcellsintersectedbythecorrespondingP(k,d)hyperplanedivided\n",
      "bythetotalnumberofd-cells,andthereforeA(k,d,U)=Q(k,d).Theresult\n",
      "followsimmediatelyfromtheboundsonP(k,d)andCorollary1.Becausethe\n",
      "individualeventsofrequestingeachqueryareconditionallyindependent,the\n",
      "totalnum?n?1?kberofqueriesrequestedbythealgorithmisjustMn=k=1\n",
      "i=11\n",
      "f\n",
      "Requestqi,k+1\n",
      "g\n",
      ".Usingtheresultsabove,itstraightforwardtoprove\n",
      "themaintheorembelow(see[7]).Theorem3.AssumeA1-2and??U.Let\n",
      "therandomvariableMndenotethenumberofpairwisecomparisonsthatare\n",
      "requestedinthealgorithmofFigure1,thenEU[Mn]?2dlog22d+2da2log\n",
      "n.Furthermore,if???andmax???n,d???c|?n,d|?1forsomec>0,then\n",
      "E?[Mn]?cEU[Mn].\n",
      "5\n",
      "Robustsequentialalgorithmforqueryselection\n",
      "WenowextendthealgorithmofFigure1tosituationsinwhichtheresponse\n",
      "toeachqueryisonlyprobablycorrect.Ifthecorrectlabelofaqueryqi,jisyi,j,\n",
      "wedenotethepossiblyincorrectresponsebyYi,j.TheprobabilitythatYi,j=\n",
      "yi,jisatleast1?p,p<1/2.Therobustalgorithmoperatesinthesamefashion\n",
      "asthealgorithminFigure1,withtheexceptionthatwhenanambiguousquery\n",
      "isencounteredseveral(equivalent)queriesaremadeandadecisionisbasedon\n",
      "themajorityvote.Thisvotingprocedureallowsustoconstructaranking(or\n",
      "partialranking)thatiscorrectwithhighprobabilitybyrequestingjustO(dlog2\n",
      "n)querieswheretheextralogfactorcomesfromvoting.Firstconsiderthecase\n",
      "inwhicheachquerycanberepeatedtoobtainmultipleindependentresponses\n",
      "(votes)foreachcomparisonquery.Thisrandomnoisemodelarises,forexample,\n",
      "insocialchoicetheorywherethe?reference?isagroupofpeople,eachcasting\n",
      "avote.Theelementaryproofofthenexttheoremisgivenin[7].Theorem4.\n",
      "AssumeA1-2and??Ubutthateachqueryresponseisarealizationofani.i.d.\n",
      "BernoullirandomvariableYi,jwithP(Yi,j?=yi,j)?p<1/2.Ifallambiguous\n",
      "queriesaredecidedbythemajorityvoteofRindependentresponsestoeachsuch\n",
      "query,thenwithprobabilitygreaterthan1?2nlog2(n)exp(?12(1?2p)2\n",
      "R)thisprocedurecorrectlyidenthecorrectrankingandrequestsnomore\n",
      "thanO(Rdlogn)queriesonaverage.Inothersituations,ifweaskthesame\n",
      "9\n",
      "\n",
      "querymultipletimeswemaygetthesame,possiblyincorrect,responseeach\n",
      "time.Thispersistentnoisemodelisnatural,forexample,ifthereferenceisa\n",
      "singlehuman.Underthismodel,iftworankingsbyonlyasinglepairwise\n",
      "comparison,thentheycannotbedistinguishedwithprobabilitygreaterthan1?\n",
      "p.So,ingeneral,exactrecoveryoftherankingcannotbeguaranteedwithhigh\n",
      "probability.Thebestwecanhopeforistoexactlyrecoverapartialranking\n",
      "oftheobjects(i.e.therankingoverasubsetoftheobjects).Henceforth,we\n",
      "willassumethenoiseispersistentandaimtoexactlyrecoverapartialranking\n",
      "oftheobjects.Thekeyingredientinthepersistentnoisesettingisthedesign\n",
      "ofavotingsetforeachambiguousqueryencountered.Supposethatatthejth\n",
      "objectinthealgorithminFigure1thequeryqi,jisambiguous.Inprinciple,a\n",
      "votingsetcouldbeconstructedusingobjectsrankedbetweeniandj.Ifobject\n",
      "kisbetweeniandj,thennotethatyi,j=yi,k=yk,j.Inpractice,wecannot\n",
      "identifythesubsetofobjectsrankedbetweeniandj,butitiscontainedwithin\n",
      "thesetTi,j,tobethesubsetofobjects?ksuchthatqi,k,qk,j,or\n",
      "bothareambiguous.Furthermore,Lemma3impliesthateachobjectinTi,jis\n",
      "rankedbetweeniandjwithprobabilityatleast1/3[7].Ti,jwillbeourvoting\n",
      "set.Notehowever,ifobjectsiandjarecloselyranked,thenTi,jmayberather\n",
      "small,andsoitisnot7\n",
      "Numberofqueryrequests\n",
      "Table1:Statisticsforthealgorithmrobusttopersistent??noiseofSection\n",
      "5withrespecttoalln2pairwisecomparisons.Recallyisthenoisyresponse\n",
      "vector,y?istheembedding?ssolution,andy?istheoutputoftherobust\n",
      "algorithm.\n",
      "600\n",
      "2log2|?n,d|\n",
      "500\n",
      "400\n",
      "log2|?n,d|\n",
      "300\n",
      "200\n",
      "Dimension%ofqueriesrequested\n",
      "meanstdd(y,y?)Averageerrord(y,y?)\n",
      "100\n",
      "0\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "10\n",
      "\n",
      "Dimension\n",
      "Figure3:Meanandstandarddeviationofrequestedqueries(solid)inthe\n",
      "noiselesscaseforn=100;log2|?n,d|isalowerbound(dashed).\n",
      "214.55.30.230.31\n",
      "318.560.210.29\n",
      "alwayspossibletoatlylargevotingset.Therefore,wemust\n",
      "specifyasize-thresholdR?1.IfthesizeofTi,jisatleastR,thenwedecide\n",
      "thelabelforqi,jbyvotingovertheresponsesto\n",
      "f\n",
      "qi,k,qk,j:k?Ti,j\n",
      "g\n",
      "and\n",
      "qi,j;otherwisewepassoverobjectjandmoveontothenextobjectinthelist.\n",
      "Thisallowsustoconstructaprobablycorrectrankingoftheobjectsthatare\n",
      "notpassedover.Thetheorembelowprovesthatalargeportionofobjectswill\n",
      "notbepassedover.Attheendoftheprocess,someobjectsthatwerepassed\n",
      "overmaythenbeunambiguouslyranked(basedonqueriesmadeaftertheywere\n",
      "passedover)ortheycanberankedwithoutvoting(andwithoutguarantees).\n",
      "Theproofofthenexttheoremisprovidedinthelongerversionofthispaper\n",
      "[7].Theorem5.AssumeA1-2,??U,andP(Y?i,j?=yi,j)=p.?Forany\n",
      "size-thresholdR?1,withprobabilitygreaterthan1?2nlog2(n)exp?29(1\n",
      "?2p)2Rtheprocedureabovecorrectlyranksatleastn/(2R+1)objectsand\n",
      "requestsnomorethanO(Rdlogn)queriesonaverage.\n",
      "6\n",
      "Empiricalresults\n",
      "Inthissectionwepresentempiricalresultsforboththenoiselessalgorithm\n",
      "ofFigure1andtherobustalgorithmofSection5.Forthenoiselessalgorithm,n\n",
      "=100points,representingtheobjectstoberanked,wereuniformlyatrandom\n",
      "simulatedfromtheunithypercube[0,1]dford=1,10,20,...,100.The\n",
      "referencewassimulatedfromthesamedistribution.Foreachvalueofdthe\n",
      "experimentwasrepeated25timesusinganewsimulationofpointsandthe\n",
      "reference.Becauseresponsesarenoiseless,exactidenoftheranking\n",
      "isguaranteed.ThenumberofrequestedqueriesisplottedinFigure3with\n",
      "thelowerboundofTheorem1forreference.Thenumberofrequestedqueries\n",
      "neverexceedstwicethelowerboundwhichagreeswiththeresultofTheorem3.\n",
      "TherobustalgorithminSection5wasevaluatedusingasymmetricsimilarity\n",
      "matrixdatasetavailableat[20]whose(i,j)thentry,denotedsi,j,representsthe\n",
      "human-judgedsimilaritybetweenaudiosignalsiandjforalli?=j?\n",
      "f\n",
      "1,..\n",
      ".,100\n",
      "g\n",
      ".Ifweconsiderthekthrowofthismatrix,wecanrank(k)theother\n",
      "signalswithrespecttotheirsimilaritytothekthsignal;weqi,j:=\n",
      "f\n",
      "sk,i\n",
      ">sk,j\n",
      "g\n",
      "(k)\n",
      "(k)\n",
      "andyi,j:=1\n",
      "f\n",
      "qi,j\n",
      "g\n",
      ".Sincethesimilaritieswerederivedfromhumansubjects,\n",
      "thederivedlabelsmaybeerroneous.Moreover,thereisnopossibilityofrepeat-\n",
      "ingquerieshereandsothenoiseispersistent.Theanalysisofthisdatasetin[2]\n",
      "suggeststhattherelationshipbetweensignalscanbewellapproximatedbyan\n",
      "embeddingin2or3dimensions.Weusednon-metricmultidimensionalscaling\n",
      "[5]toanembeddingofthesignals:?1,...,?100?Rdford=2and3.\n",
      "Foreachobject?k,weusetheembeddingtoderivepairwisecomparisonlabels\n",
      "betweenallotherobjectsasfollows:(k)y?i,j:=1\n",
      "f\n",
      "||?k??i||<||?k?\n",
      "11\n",
      "\n",
      "?j||\n",
      "g\n",
      ",whichcanbeconsideredasthebestapproximationtothela(k)\n",
      "belsyi,jabove)inthisembedding.Theoutputoftherobustse-\n",
      "quentialalgorithm,which(k)\n",
      "usesonlyasmallfractionofthesimilarities,isdenotedbyy?i,j.WesetR\n",
      "=15usingTheorem5as???1?(k)(k)aroughguide.Usingthepopular\n",
      "Kendell-Taudistanced(y(k),y?(k))=n2?i,j\n",
      "g\n",
      "i<j1\n",
      "f\n",
      "yi,j?=y[21]foreach\n",
      "objectk,wedenotetheaverageofthismetricoverallobjectsbyd(y,y?)and\n",
      "reportthisstatisticandthenumberofqueriesrequestedinTable1.Becausethe\n",
      "averageerrorofy?isonly0.07higherthanthatofy?,thisthatthealgorithm\n",
      "isdoingalmostaswellaswecouldhope.?suggests?Also,notethat2R2dlog\n",
      "n/n2isequalto11.4%and17.1%ford=2and3,respectively,whichagrees\n",
      "wellwiththeexperimentalvalues.8\n",
      "2References\n",
      "[1]D.Knuth.TheArtofComputerProgramming,Volume3:Sortingand\n",
      "Searching.AddisonWesley,1998.[2]ScottPhilips,JamesPitton,andLes\n",
      "Atlas.Perceptualfeatureidenforactivesonarechoes.InOCEANS\n",
      "2006,2006.[3]B.McFeeandG.Lanckriet.Partialorderembeddingwith\n",
      "multiplekernels.InProceedingsofthe26thAnnualInternationalConferenceon\n",
      "MachineLearning,pages721?728.ACM,2009.[4]I.GormleyandT.Murphy.\n",
      "Alatentspacemodelforrankdata.StatisticalNetworkAnalysis:Models,\n",
      "Issues,andNewDirections,pages90?102,2007.[5]M.A.A.CoxandT.F.Cox.\n",
      "Multidimensionalscaling.Handbookofdatavisualization,pages315?347,2008.\n",
      "[6]J.F.Traub.Information-basedcomplexity.JohnWileyandSonsLtd.,2003.\n",
      "[7]KevinG.JamiesonandRobertD.Nowak.arXiv:1109.3701v1,2011.\n",
      "Activerankingusingpairwisecomparisons.\n",
      "[8]C.H.Coombs.Atheoryofdata.Psychologicalreview,67(3):143?159,\n",
      "1960.[9]T.M.Cover.Geometricalandstatisticalpropertiesofsystemsof\n",
      "linearinequalitieswithapplicationsinpatternrecognition.IEEEtransactions\n",
      "onelectroniccomputers,14(3):326?334,1965.[10]S.Dasgupta,A.T.Kalai,\n",
      "andC.Monteleoni.Analysisofperceptron-basedactivelearning.TheJournal\n",
      "ofMachineLearningResearch,10:281?299,2009.[11]S.Hanneke.Theoretical\n",
      "foundationsofactivelearning.PhDthesis,Citeseer,2009.[12]TiborHeged?us.\n",
      "Generalizedteachingdimensionsandthequerycomplexityoflearning.InPro-\n",
      "ceedingsoftheeighthannualconferenceonComputationallearningtheory,\n",
      "COLT?95,pages108?117,NewYork,NY,USA,1995.ACM.[13]Y.Fre-\n",
      "und,R.Iyer,R.E.Schapire,andY.Singer.Antboostingalgorithmfor\n",
      "combiningpreferences.TheJournalofMachineLearningResearch,4:933?969,\n",
      "2003.[14]C.Burges,T.Shaked,E.Renshaw,A.Lazier,M.Deeds,N.Hamil-\n",
      "ton,andG.Hullender.Learningtorankusinggradientdescent.InProceedings\n",
      "ofthe22ndinternationalconferenceonMachinelearning,pages89?96.ACM,\n",
      "2005.[15]Z.Zheng,K.Chen,G.Sun,andH.Zha.Aregressionframeworkfor\n",
      "learningrankingfunctionsusingrelativerelevancejudgments.InProceedings\n",
      "ofthe30thannualinternationalACMSIGIRconferenceonResearchanddevel-\n",
      "12\n",
      "\n",
      "opmentininformationretrieval,pages287?294.ACM,2007.[16]R.Herbrich,\n",
      "T.Graepel,andK.Obermayer.Supportvectorlearningforordinalregression.\n",
      "InNeuralNetworks,1999.ICANN99.NinthInternationalConfer-\n",
      "enceon(Conf.Publ.No.470),volume1,pages97?102.IET,1999.[17]\n",
      "T.LuandC.Boutilier.Robustapproximationandincrementalelicitationin\n",
      "votingprotocols.IJCAI-11,Barcelona,2011.[18]W.ChuandZ.Ghahra-\n",
      "mani.Extensionsofgaussianprocessesforranking:semi-supervisedandactive\n",
      "learning.LearningtoRank,page29,2005.[19]J.F.BennettandW.L.Hays.\n",
      "Multidimensionalunfolding:Determiningthedimensionalityofrankedprefer-\n",
      "encedata.Psychometrika,25(1):27?43,1960.[20]SimilarityLearning.Aural\n",
      "Sonardataset.[http://idl.ee.washington.edu/SimilarityLearning].University\n",
      "ofWashingtonInformationDesignLab,2011.[21]J.I.Marden.Analyzingand\n",
      "modelingrankdata.Chapman&Hall/CRC,1995.\n",
      "9\n",
      "13\n",
      "\n",
      "PP3822.pdf\n",
      "PP3822.pdf 11\n",
      "ConvexRelaxationofMixtureRegressionwith\n",
      "tAlgorithms\n",
      "Authoredby:\n",
      "DaleSchuurmans\n",
      "Tib?rioS.Caetano\n",
      "NoviQuadrianto\n",
      "JohnLim\n",
      "Abstract\n",
      "Wedevelopaconvexrelaxationofmaximumaposterioriestimation\n",
      "ofamixtureofregressionmodels.Althoughourrelaxationinvolvesa\n",
      "matrixvariable,wereformulatetheproblemtoeliminatethe\n",
      "needforgeneralprogramming.Inparticular,weprovide\n",
      "tworeformulationsthatadmitfastalgorithms.Theisamax-min\n",
      "spectralreformulationexploitingquasi-Newtondescent.Thesecondisa\n",
      "min-minreformulationconsistingoffastalternatingstepsofclosed-form\n",
      "updates.WeevaluatethemethodsagainstExpectation-Maximizationin\n",
      "arealproblemofmotionsegmentationfromvideodata.\n",
      "1PaperBody\n",
      "Regressionisafoundationalprobleminmachinelearningandstatistics.In\n",
      "practice,however,dataisoftenbettermodeledbyamixtureofregressors,as\n",
      "demonstratedbytheprominenceofmixtureregressioninanumberofappli-\n",
      "cationareas.andSmyth[1],forexample,usemixtureregressionto\n",
      "clustertrajectories,i.e.setsofshortsequencesofdatasuchascycloneorob-\n",
      "jectmovementsinvideosequencesasafunctionoftime.Eachtrajectoryis\n",
      "believedtohavebeengeneratedfromoneofanumberofcomponents,where\n",
      "eachcomponentisassociatedwitharegressionmodel.Finneyetal.[2]have\n",
      "employedanidenticalmixtureregressionmodelinthecontextofplanning:re-\n",
      "gressionfunctionsarestrategiesforagivenplanningproblem.Elsewhere,the\n",
      "mixtureofregressorsmodelhasbeenshowntobeusefulinaddressingcovari-\n",
      "ateshift,i.e.thesituationwherethedistributionofthetrainingsetusedfor\n",
      "modelingdoesnotmatchthedistributionofthetestsetinwhichthemodel\n",
      "willbeused.StorkeyandSugiyama[3]modelthecovariateshiftprocessin\n",
      "amixtureregressionsettingbyassumingashiftinthemixingproportionsof\n",
      "thecomponents.Ineachoftheseproblems,onemustestimatekdistinctlatent\n",
      "1\n",
      "\n",
      "regressionfunctions;thatis,estimatefunctionswhosevaluescorrespondtothe\n",
      "meanofresponsevariables,undertheassumptionthattheresponsevariable\n",
      "isgeneratedbyamixtureofkcomponents.Thisestimationproblemcanbe\n",
      "easilytackledifitisknowntowhichcomponenteachresponsevariablebelongs\n",
      "(yieldingkindependentregressionproblems).Howeveringeneralthecompo-\n",
      "nentofagivenobservationisnotknownandismodeledasalatentvariable.\n",
      "Acommonlyadoptedapproachformaximum-likelihoodestimationwithlatent\n",
      "variables(inthiscase,componentmembershipforeachresponsevariable)is\n",
      "Expectation-Maximization(EM)[4].Essentially,EMiteratesinferenceoverthe\n",
      "hiddenvariablesandparameterestimationoftheresultingdecoupledmodels\n",
      "untilalocaloptimumisreached.Wearenotawareofanyapproachtomaxi-\n",
      "mumlikelihoodestimationofamixtureofregressionmodelsthatisnotbased\n",
      "onthenon-convexmarginallikelihoodobjectiveofEM.Inthispaperwepresent\n",
      "aconvexrelaxationofmaximumaposterioriestimationofamixtureofregres-\n",
      "sionmodels.Recently,convexrelaxationshavegainedconsiderableattention\n",
      "inmachinelearning(c.f.[5,6]).Byexploitingconvexduality,wereformu-\n",
      "latearelaxationofmixtureregressionasaprogram.Toachievea\n",
      "scalableapproach,however,weproposetworeformulationsthatadmitfastal-\n",
      "gorithms.Theisamax-minoptimizationproblemwhichcanbesolvedby\n",
      "iterationsofquasi-Newtonstepsandeigenvectorcomputations.Thesecondis\n",
      "amin-minoptimizationproblemsolvablebyiterationsofclosed-formsolutions.\n",
      "WepresentexperimentalresultscomparingourmethodsagainstEM,bothin\n",
      "syntheticproblemsandrealcomputervisionproblems,andshowsomeb\n",
      "ofaconvexapproachoveralocalsolutionmethod.1\n",
      "RelatedworkGoldfeldandQuandt[7]introducedamixtureregressionmodel\n",
      "withtwocomponentscalledswitchingregressions.Theproblemisre-castinto\n",
      "asinglecompositeregressionequationbyintroducingaswitchingvariable.A\n",
      "consistentestimatoristhenproducedbyacontinuousrelaxationofthisswitch-\n",
      "ingvariable.AnEMalgorithmforswitchingregressionswaspresentedby\n",
      "Hosmer[8].Sp?ath[9]introducedaproblemcalledclusterwiselinearregression,\n",
      "consistingofdingak-partitionofthedatasuchthataleastsquaresregression\n",
      "criterionwithinthosepartitionsbecomesaminimum.Anon-probabilisticalgo-\n",
      "rithmsimilartok-meanswasproposed.Subsequently,thegeneralk-partition\n",
      "caseemployingEMwasdeveloped(c.f.[10,11,1])andextendedtovarioussitu-\n",
      "ationsincludingtheuseofvariablelengthtrajectorydataandtonon-parametric\n",
      "regressionmodels.Intheextreme,eachindividualcouldhaveitsspregres-\n",
      "sionmodelbutcoupledathigherlevelwithamixtureonregressionparameters\n",
      "[12].AnEMalgorithmisagainemployedtohandlehiddendata,inthiscase\n",
      "groupmembershipofparameters.TheHierarchicalMixturesofExperts[13]\n",
      "modelalsosharessomesimilaritytomixtureregressioninthatgatingnetworks\n",
      "whichcontainmixturesofgeneralizedlinearmodelsareInprinciple,\n",
      "ouralgorithmicadvancescanbeappliedtomanyoftheseformulations.\n",
      "2\n",
      "TheModel\n",
      "NotationInthefollowingweusetheuppercaseletters(X,?,?)todenote\n",
      "matricesandthelowercaseletters(x,y,w,?,?,c)todenotevectors.We\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usettodenotethesamplesize,ntodenotethedimensionalityofthedata\n",
      "andktodenotethenumberofmixturecomponents.?(a)denotesadiagonal\n",
      "matrixwhosediagonalisequaltovectora,anddiag(A)isavectorequalto\n",
      "thediagonalofmatrixA.Finally,welet1denotethevectorofallones,use\n",
      "todenoteHadamard(componentwise)matrixproduct,anduse?todenote\n",
      "Kroneckerproduct.WearegivenamatrixofregressorsX?Rt?nandavector\n",
      "ofregressandsy?Rt?1wheretheresponsevariableyisgeneratedbyamixture\n",
      "ofkcomponents,butwedonotknowwhichcomponentofthemixturegenerates\n",
      "eachresponseyi.Wethereforeusethematrix??\n",
      "f\n",
      "0,1\n",
      "g\n",
      "t?k,?1=1,to\n",
      "denotethehiddenassignmentofmixturelabelstoeachobservation:?ij=1\n",
      "observationihasmixturelabelj.WeusexitodenotetheithrowofX(i.e.\n",
      "observationiasarowvector),?itodenotetheithrowof?andyitodenote\n",
      "theithelementofy.Weassumealineargenerativemodelforyionafeature\n",
      "representation?i=?i?xi,underi.i.d.samplingyi|xi,?i=?iw+i,i?N\n",
      "(0,?2),(1)wherew?R(n?k)?1isthevectorofstackedparametervectorsof\n",
      "thecomponents.Wethereforehavethelikelihood\n",
      "112p(yi|xi,?i;w)=?(2)exp?2(?iw?yi)2?2??2fora\n",
      "singleobservationi(recallingthat?idependsonbothxiand?i).Wefurther\n",
      "imposeaGaussianprioronwforcapacitycontrol.Also,onemaywantto\n",
      "constrainthesizeofthelargestmixturecomponent.Forthatpurposeone\n",
      "couldconstrainthesolutions?suchthatmax(diag(?T?))??t,where?tis\n",
      "anupperboundonthesizeofthelargestcomponent(?isanupperboundon\n",
      "theproportionofthelargestcomponent).Combiningtheseassumptionsand\n",
      "adoptingmatrixnotationweobtaintheoptimizationproblem:minimizethe\n",
      "negativelog-posterioroftheentiresample\"#X1T1T?TminA(?i,w)?\n",
      "2y?w+2yy+ww,where(3)?,w?2?2i1TT1w?i?iw+log(2??2).\n",
      "(4)2?22Here?isthematrixwhoserowsarethevectors?i=?i?xi.Since\n",
      "Xisobserved,notethattheoptimizationonlyrunsover?in?.Theconstraint\n",
      "max(diag(?T?))??tmayalsobeadded.A(?i,w)=\n",
      "Eliminatingconstantterms,ourtaskwillbetosolve\n",
      "1TT1T?Tw??w?2y?w+ww.min(5)?,w2?2?2Although\n",
      "marginallyconvexonw,thisobjectiveisnotjointlyconvexonwand?(and\n",
      "involvesnon-convexconstraintson?owingtoitsdiscreteness).Thelackof\n",
      "jointconvexitymakestheoptimizationThetypicalapproachinsuch\n",
      "situationsistouseanalternatingdescentstrategy,suchasEM.Instead,inthe\n",
      "followingwedevelopaconvexrelaxationforproblem(5).2\n",
      "3\n",
      "Relaxation\n",
      "Toobtainaconvexrelaxationweproceedinthreesteps.First,wedualize\n",
      "thetermin(5).Lemma1A(?w):=2?12wT?T?w.Thenthe\n",
      "FencheldualofA(?w)isA?(c)=21?2cTc,andthereforeA(?w)=maxccT\n",
      "?w?21?2cTc.ProofFromtheofFencheldualwehaveA?(u):=\n",
      "maxwuTw?2?12wT?T?w.tiatingwithrespecttowandequating\n",
      "tozeroweobtainu=?12?T?w.Thereforeuisonlyrealizableifthereexists\n",
      "acsuchthatu=?Tc.SolvingforA?(c)weobtainA?(c)=12?2cTc,and\n",
      "thereforebyofFencheldualityA(?w)=maxccT?w?12?2cTc.\n",
      "3\n",
      "\n",
      "AsecondLemmaisrequiredtofurtherestablishtherelaxation:Lemma2The\n",
      "followingsetinclusionholds\n",
      "f\n",
      "??T:??\n",
      "f\n",
      "0,1\n",
      "g\n",
      "t?k,?1=1,max(diag(?T?))?\n",
      "?t\n",
      "g\n",
      "?\n",
      "f\n",
      "M:M?R\n",
      "t?t\n",
      ",trM=t,?tI<M<0\n",
      "g\n",
      ".\n",
      "(6)(7)\n",
      "ProofLet??Tbeanelementoftheset.Firstnoticethat[??T]ij?\n",
      "f\n",
      "0,\n",
      "1\n",
      "g\n",
      "since??\n",
      "f\n",
      "0,1\n",
      "g\n",
      "t?kand?1=1togetherimplythat?hasasingle1perrow\n",
      "(andtherestarezeros).Inparticular[??T]ii=1foralli,i.e.trM=t.Finally,\n",
      "notethat(??T)?=?(?T?)where?T?isadiagonalmatrixandthereforeits\n",
      "diagonalelementsaretheeigenvaluesof??Tandinparticularmax(diag(?T?))\n",
      "??tmeansthatthelargestpossibleeigenvalueof??Tis?t,whichimplies?tI\n",
      "<??T.Since??Tisbyconstructionpositivewehave?tI<??T<\n",
      "0.Therefore??Tisalsoamemberofthesecondset.Theabovetwolemmas\n",
      "allowustostateourmainresultbelow.Theorem3Thefollowingconvex\n",
      "optimizationproblem\n",
      "Ty\n",
      "1y12TTminmax??cc??cMXX?cM:trM=t,?tI<M<0c22?\n",
      "?2?2isarelaxationof(5)onlyinthesensethatdomain(6)isreplacedby\n",
      "domain(7).ProofWeuseLemma1inordertorewritetheobjective(5)\n",
      "andobtain\n",
      "12T1T?TTminmaxc?w??cc?2y?w+ww.c?,w2?2\n",
      "(8)\n",
      "(9)\n",
      "Second,usingthedistributivityofthe(max,+)semi-ring,themaxccanbe\n",
      "pulledoutandwethenuseSion?sminimaxtheorem[14],whichallowsusto\n",
      "interchangemaxcwithminw\n",
      "11?minmaxmincT?w??2cTc?2yT?w+wTw,(10)cw?2?\n",
      "2andwecansolveforwobtainingy\n",
      "1w=?T?c.(11)??2Substituting(11)intheobjectiveof(10)resultsin\n",
      "Ty\n",
      "12T1yTminmax??cc??c???c.(12)c?22??2?2Wenow\n",
      "notethecriticalfactthat?onlyshowsupintheexpression??Twhich,from\n",
      "the?i=?i?xi,isseentobeequivalentto??TXXT.Thereforethe\n",
      "minimizationover?elytakesplaceover??T(sinceXisobserved),and\n",
      "wehavethat(12)canberewrittenas\n",
      "Ty\n",
      "12T1yTTminmax??cc??c??XX?c.(13)c22??2?2??TSo\n",
      "farnorelaxationhastakenplace.Byreplacingtheconstraint(6)with\n",
      "constraint(7)fromLemma2,weobtaintheclaimedrelaxation.3\n",
      "4\n",
      "Max-MinReformulation\n",
      "Byupperboundingtheinnermaximizationin(8)andapplyingaSchur\n",
      "complement,problem(8)canbere-expressedasaprogram.Un-\n",
      "fortunately,suchaformulationiscomputationallyexpensivetosolve,requiring\n",
      "4\n",
      "\n",
      "O(t6)fortypicalinterior-pointmethods.Instead,wecanreformulateproblem\n",
      "(8)toallowforafastalgorithmicapproach,withouttheintroductionofany\n",
      "additionalrelaxation.Thebasisofourdevelopmentisthefollowingclassical\n",
      "result.Theorem4([15])LetV?Rt?t,V=VThaveeigenvalues?1??2??\n",
      "????t.LetPbethematrixwhosecolumnsarethenormalizedeigenvectors\n",
      "ofV,i.e.PTVP=?((?1,...,?t)).Letq?\n",
      "f\n",
      "1,...,t\n",
      "g\n",
      "andPqbethe\n",
      "matrixcomprisedbythetopqeigenvectorsofP.ThenqXmaxtrMVT=\n",
      "?iand(14)M:tr(M)=q,I<M<0\n",
      "argmax\n",
      "i=1\n",
      "trMVT3PqPqT.\n",
      "(15)\n",
      "M:tr(M)=q,I<M<0\n",
      "ProofSee[15]foraproofofaslightlymoregeneralresult(Theorem3.4).\n",
      "WewillnowshowhowtheoptimizationonMforproblem(8)canbecastinthe\n",
      "termsofTheorem4.Thiswillturnouttobecriticalfortheofthe\n",
      "optimizationprocedure,sinceTheorem4describesapurelyspectraloptimiza-\n",
      "tionroutine,whichisfarmoret(O(t3))thanstandardinterior-point\n",
      "methodsusedforprogramming(O(t6)).Proposition5y?\n",
      ":=?y2.Thefollowingoptimizationproblem\n",
      "11maxtr(M(XXT(?y?c)(?y?c)T))max??2cTc?c22?M:tr\n",
      "M=t,?tI<M<0\n",
      "(16)\n",
      "isequivalenttooptimizationproblem(8).ProofBySion?sminimaxtheorem\n",
      "[14],minMandmaxcin(8)canbeinterchanged\n",
      "112TTT(?y?c)MXX(?y?c)maxmin??cc?cM:trM=t,?tI<M\n",
      "<022?which,bydistributivityofthe(min,+)semi-ring,isequivalentto\n",
      "12T1TTmax??cc+min?(?y?c)MXX(?y?c).c22?M:tr\n",
      "M=t,?tI<M<0Now,K:=XXT.Theobjectiveoftheminimizationin\n",
      "(18)canthenbewrittenas\n",
      "?(?y?c)T(MK)(?y?c)=?tr(MK)(?y?c)(?y?c)T\n",
      "XX\n",
      "=?(MijKij)(?y?c)(?y?c)Tij=?MijKij(?y?c)(?y?c)Tijij\n",
      "(17)\n",
      "(18)\n",
      "(19)(20)\n",
      "ij\n",
      "=?tr(M(K(?y?c)(?y?c)T))=?tr(M(XXT(?y?c)(?y?c)T)).\n",
      "(21)\n",
      "Finally,bywritingminM?f(M)as?maxMf(M),weobtaintheclaim.\n",
      "WecannowexploittheresultinTheorem4forthepurposeofouroptimization\n",
      "problem.Proposition6Letq=\n",
      "f\n",
      "u:u=max\n",
      "f\n",
      "1,...,t\n",
      "g\n",
      ",u???1\n",
      "g\n",
      ".The\n",
      "followingoptimizationproblem\n",
      "12TtTT?max??cc?maxtr(M(XX(?y?c)(?y?c)))(22)c2\n",
      "2?qM?:trM?=q,I<M?<0isequivalenttooptimizationproblem(16).4\n",
      "5\n",
      "\n",
      "Algorithm11:Input:?,?,?,XXT2:Output:(c?,M?)3:Initializec\n",
      "=04:repeat5:Solveformaximumvalueininnermaximizationof(22)using\n",
      "(14)6:Solveoutermaximizationin(22)usingnonsmoothBFGS[16],obtain\n",
      "newc7:untilchasconverged(c=c?)8:Atc?,solveforthemaximizer(s)\n",
      "Pqintheinnermaximizationof(22)using(15)9:ifPqisuniquethen10:\n",
      "returnM?=PqPqTbreak11:else12:AssembletopleigenvectorsinPl13:\n",
      "Solve(24)14:returnM?=Pl?(??)PlT15:endifProofTheonly\n",
      "between(16)and(22)are(i)thefactort/qinthesecondtermof(22)and(ii)\n",
      "theconstraints\n",
      "f\n",
      "M:trM=t,?tI<M<0\n",
      "g\n",
      "in(16)versus\n",
      "f\n",
      "M:trM=q,I\n",
      "<M<0\n",
      "g\n",
      "in?:=(q/t)M,(22).Thesesaresimplytheresultofa\n",
      "properrescalingofM.IfweM?<0sinceq???1.Wethenhave\n",
      "trM?=q.Theresultfollows.thenI<MAndwehavethesecond\n",
      "mainresultTheorem7Optimizationproblem(22)isequivalenttooptimization\n",
      "problem(8).ProofTheequivalencefollowsdirectlyfromPropositions5and6.\n",
      "Notethat,crucially,theobjectivein(22)isconcaveinc.Ourstrategyisnow\n",
      "clear.Insteadofsolving(8),whichdemandsO(t6)operations,weinsteadsolve\n",
      "(22),whichhasasinneroptimizationamaxeigenvalueproblem,demanding\n",
      "onlyO(t3)operations.Inthenextsectionwedescribeanalgorithmtojointly\n",
      "optimizeforMandcin(22),whichwillessentiallyconsistofalternatingthe\n",
      "tspectralsolutionoverMwithasubgradientoptimizationoverc.4.1\n",
      "Max-MinAlgorithmAlgorithm1describeshowwesolveoptimizationproblem\n",
      "(22).Theideaofthealgorithmisthefollowing.First,havingnotedthat(22)is\n",
      "concaveinc,wecansimplyinitializecarbitrarilyandpursueafastsubgradient\n",
      "ascentalgorithm(e.g.suchasnonsmoothBFGS[16]).Soateachstepwesolve\n",
      "theeigenvalueproblemandrecomputeasubgradient,untilconvergencetoc?\n",
      ".WethenneedtorecoverM?suchthat(c?,M?)isasaddlepoint(note\n",
      "thatproblem(22)isconcaveincandconvexinM).Forthatpurposeweuse\n",
      "(15).IfM?=PqPqTissuchthatPqisunique,thenwearedoneandthe\n",
      "labelingsolutionofmixturemembershipisM?(subjecttorou).IfPqis\n",
      "notunique,thenwehavemultiplicityofeigenvaluesandweneedtoproceedas\n",
      "follows.Pl=[p1...pq...pl],l>q,whereeachoftheadditional\n",
      "l?qeigenvectorshasanassociatedeigenvaluewhichisequaltotheeigenvalue\n",
      "ofsomeofthepreviousqeigenvectors.Wethenhavethatatthesaddlepoint\n",
      "theremustexistadiagonalmatrix?suchthatM?=Pl?PlT,subjectto?\n",
      "<0andtr?=q(ifthiswerenotthecasetherewouldbeanascentdirection\n",
      "inc?,contradictingthehypothesisthatc?isoptimal).Tosucha?and\n",
      "thereforerecoverthecorrectM,weneedtoenforcethatweareattheoptimal\n",
      "c(c?),i.e.wemusthave\n",
      "2\n",
      "d\n",
      "12TqTT\n",
      "=0??cc?maxtr(M(XX\n",
      "(?y?c)(?y?c)))(23)\n",
      "dc\n",
      "22?tM:trM=q,I<M<02Suchconditioncanbepursuedbyminimizingthe\n",
      "abovenorm,whichgivesaquadraticprogram\n",
      "6\n",
      "\n",
      "2\n",
      "q\n",
      "Pl?(?)PlTXXT(c??y?)(24)min?2c?+?t??0,?T1=q2Wecanthen\n",
      "recoverthesolution(subjectto)byM?=Pl?(??)PlT,where\n",
      "??istheoptimizerof(24).Theoptimalvalueof(24)shouldbeverycloseto\n",
      "zero(sinceit?sthenormofthederivativeatpointc?).Thepseudocodefor\n",
      "thealgorithmappearsinAlgorithm1.5\n",
      "Algorithm21:Input:?,?,?,XXT2:Output:(c?,M?)3:Initialize\n",
      "M=?((1/(?t),...,1/(?t)))4:repeat5:Solveforminimumvalueininner\n",
      "minimizationof(25),obtainA6:Solveouterminimizationin(25)givenSVD\n",
      "ofAusingTheorem4.1of[18],obtainnewM7:untilMhasconverged(M=\n",
      "M?)?T8:Recoverc?=?1?2diag(X(A))\n",
      "5\n",
      "Min-MinReformulation\n",
      "Althoughthemax-minformulationappearssatisfactory,therecentliterature\n",
      "onmultitasklearning[17,18]hasdevelopedanalternatestrategyforbypassing\n",
      "generalprogramming.Sp,workinthisarealeadtoconvex\n",
      "optimizationproblemsexpressedjointlyovertwomatrixvariableswhereeach\n",
      "stepisanalternatingmin-mindescentthatcanbeexecutedinclosed-formor\n",
      "byaveryfastalgorithm.Althoughitisnotimmediatelyapparentthatthis\n",
      "algorithmicstrategyisapplicabletotheproblemathand,withsomefurther\n",
      "reformulationof(8)wediscoverthatinfactthesamemin-minalgorithmic\n",
      "approachcanbeappliedtoourmixtureofregressionproblem.Theorem8The\n",
      "followingoptimizationproblem\n",
      "1T1?TTTTT?1ydiag(XA)+diag(XA)diag(XA)+minmintr(A\n",
      "MA)?22?22?t\n",
      "f\n",
      "M:IM0,trM=1/?\n",
      "g\n",
      "A(25)isequivalenttooptimization\n",
      "problem(8).Proofmin\n",
      "f\n",
      "M:IM0,trM=1/?\n",
      "g\n",
      "=\n",
      "min\n",
      "max?c\n",
      "?2T?tcc?(c?y?)T(MXXT)(c?y?)22?\n",
      "max\n",
      "f\n",
      "M:IM0,trM=1/?\n",
      "gf\n",
      "c,C:C=?(c??y)X\n",
      "g\n",
      "?\n",
      "?2T?tcc?tr(CTMC)22?\n",
      "(26)(27)\n",
      "?t?2Tcc?tr(CTMC)+tr(ATC)?tr(AT?(c?y?)X)22?\n",
      "f\n",
      "M:IM\n",
      "0,trM=1/?\n",
      "g\n",
      "Ac,C(28)1?T?1WecanthensolveforcandC,obtainingc\n",
      "=??2diag(XA)andC=?tMA.Substitutingthosetwovariablesinto(28)\n",
      "provestheclaim.=\n",
      "5.1\n",
      "min\n",
      "minmax?\n",
      "Min-MinAlgorithm\n",
      "7\n",
      "\n",
      "Theproblem(25)isjointlyconvexinAandM[14]andAlgorithm2describes\n",
      "howtosolveit.ItisimportanttonotethatalthougheachiterationinAlgo-\n",
      "rithm2isnt,manyiterationsarerequiredtoreachadesiredtolerance,\n",
      "sinceitisonlyconvergent.Itisobservedinourexperimentsthatthe\n",
      "concave-convexmax-minapproachinAlgorithm1ismoretsimplybe-\n",
      "causeithasthesameiterationcostbutexploitsaquasi-Newtondescentinthe\n",
      "outeroptimization,whichconvergesfaster.Remark9Inpractice,similarlyto\n",
      "[17],aregularizeronMisaddedtoavoidsingularity,resultinginthefollowing\n",
      "regularizedobjectivefunction,11minmin2yTdiag(XAT)+2diag(XAT\n",
      ")Tdiag(XAT)A?2?\n",
      "f\n",
      "M:IM0,trM=1/?\n",
      "g\n",
      "?+tr(ATM?1A)+tr(M?1).\n",
      "(29)2?tTheproblemisstilljointlyconvexinMandA.6\n",
      "6\n",
      "Experiments\n",
      "Ourprimaryobjectiveinformulatingthisconvexapproachtomixturere-\n",
      "gressionistotackleaprobleminvideoanalysis(seebelow).However,\n",
      "toinitiallyevaluatethetapproachesweconductedsomesyntheticex-\n",
      "periments.Wegenerated30syntheticdatapointsaccordingtoyi=(?i?xi\n",
      ")w+i,withxi?R,i?N(0,1)andw?U(0,1).Theresponsevariableyi\n",
      "isassumedtobegeneratedfromamixtureof5components.Wecomparedthe\n",
      "qualityoftherelaxationin(22)toEM.Max-minalgorithmisusedinthisexper-\n",
      "iment.ForEM,100randomrestartswasusedtohelpavoidpoorlocaloptima.\n",
      "Theexperimentisrepeated10times.Theerrorratesare0.347?0.086and\n",
      "0.280?0.063forEMandconvexrelaxation,respectively.Thevisualizationof\n",
      "therecoveredmembershipforoneoftherunsisgiveninFigure1.Thisdemon-\n",
      "stratesthattherelaxationcanretainmuchofthestructureoftheproblem.\n",
      "6.1VisionExperimentInadynamicscene,variousstaticandmovingobjects\n",
      "areviewedbyapossiblymovingobserver.Forexample,consideramoving,\n",
      "hand-heldcameraasceneofseveralcarsdrivingdowntheroad.Each\n",
      "carhasaseparatemotion,andeventhestaticobjects,suchastrees,appearto\n",
      "moveinthevideoduetotheself-motionofthecamera.Thetaskofsegmenting\n",
      "eachobjectaccordingtoitsmotion,estimatingtheparametersofeachmotion,\n",
      "andrecoveringthestructureofthesceneisknownasthemultibodystructure\n",
      "andmotionproblem.Thisisamissingvariableproblem.Ifthemotionshave\n",
      "beensegmentedcorrectly,itiseasytoestimatetheparametersofeachmotion.\n",
      "Naturally,modelsemployingEMhavebeenproposedtotacklesuchproblems\n",
      "(c.f.[19,20]).Fromepipolargeometry,givenapairofcorrespondingpoints\n",
      "piandqifromtwoimages(pi,qi?R3?1),wehavetheepipolarequation\n",
      "qiTFpi=0.ThefundamentalmatrixFencapsulatesinformationaboutthe\n",
      "translationandrotationrelativetothescenepointsbetweenthepositionsofthe\n",
      "camerawherethetwoimageswerecaptured,aswellasthecameracalibration\n",
      "parameterssuchasitsfocallength.Inastaticscene,whereonlythecamera\n",
      "ismoving,thereisonlyonefundamentalmatrix,whicharisesfromthecamera\n",
      "self-motion.However,ifsomeofthescenepointsaremovingindependently\n",
      "undermultipletmotions,thereareseveralfundamentalmatrices.If\n",
      "therearekmotiongroups,theepipolarequationcanbeexpressedintermof\n",
      "themultibodyfundamentalQkmatrix[21],i.e.j=1(qiTFjpi)=0.Anal-\n",
      "8\n",
      "\n",
      "gebraicmethodwasproposedtorecoverthismatrixviaGeneralizedPCA[21].\n",
      "Analternativeapproach,whichwefollowhere,isbyLi[22],whocaststhePk\n",
      "problemasamixtureoffundamentalmatrices,i.e.qiT(j=1?ijFj)pi=0\n",
      "wherethemembershipvariable?ij=1whenimagepointibelongstomotion\n",
      "groupj,andzerootherwise.Furthermore,sinceqiTFpi=0isbilinearinthe\n",
      "imagepoints,wecanrewriteittobexTiwj=0,withthecolumnvectorsxi=\n",
      "[qixpxiqixpyiqixp?i....qi?p?i]Tandw=vec(FjT).Thus,wewillendup\n",
      "withthePkfollowinglinearequation:j=1?ijxTiwj=0.Theweightvector\n",
      "wjformotiongroupjcanberecoveredeasilyiftheindicatorvariable?ijis\n",
      "known.WeareinterestedinassessingtheenessofEM-basedandconvex\n",
      "relaxation-basedmethodsforthismultibodystructureandmotionproblem.We\n",
      "usedtheHopkins155dataset[23].Theexperimentalresultsaresummarizedin\n",
      "Table1.Allhyperparameters(EM:?and?;Convexrelaxation:?,?,and?)\n",
      "weretunedandthebestperformancesforeachlearningalgorithmarereported.\n",
      "TheEMalgorithmwasrunwith100randomrestartstohelpavoidpoorlocal\n",
      "optima.Intermsofcomputationtime,themax-minrunscomparablytothe\n",
      "EMalgorithm,whilemin-minrunsintheorderof3to4timesslower.Asan\n",
      "illustration,onaPentium43.6GHzmachine,theelapsedtime(inseconds)for\n",
      "twocranesdatasetis16.880,23.536,and60.003forEM,max-minandmin-min,\n",
      "respectively.Roundingfortheconvexversionswasdonebyk-means,which\n",
      "introducessomeintheresultsforbothalgorithms.Noticeably,\n",
      "bothmax-minandmin-minoutperformtheEMalgorithm.Visualizationsof\n",
      "themotionsegmentationontwocranes,threecars,andcars207datasetsare\n",
      "giveninFigure2(forkanatani2andarticulatedpleaserefertoAppendix).\n",
      "7\n",
      "Conclusion\n",
      "Themixtureregressionproblemispervasiveinmanyapplicationsandknown\n",
      "approachesforparameterestimationrelyonvariantsofEM,whichnaturally\n",
      "haveissueswithlocalminima.Inthispaperweintroducedarelax-\n",
      "ationforthemixtureregressionproblem,thusobtainingaconvexformulation\n",
      "whichdoesnotfromlocalminima.Inadditionweshowedhowtoavoid\n",
      "the7\n",
      "useofexpensiveinterior-pointmethodstypicallyneededtosolve\n",
      "niteprograms.Thiswasachievedbyintroducingtworeformulationsamenable\n",
      "totheuseoffasteralgorithms.Experimentalresultswithsyntheticdataas\n",
      "wellaswithrealcomputervisiondatasuggesttheproposedmethodscansub-\n",
      "stantiallyimproveonEMwhileoneofthemethodsinadditionhascomparable\n",
      "runtimes.Table1:ErrorrateonseveraldatasetsfromtheHopkins155Dataset\n",
      "mEMMax-MinConvexMin-MinConvexthreecars1730.05320.02890.0347\n",
      "kanatani2630.00000.00000.0000cars2072120.33960.26420.2594twocranes\n",
      "940.05320.02130.0106articulated1500.00000.00000.0000\n",
      "(a)GroundTruth\n",
      "(b)EM\n",
      "(c)ConvexRelaxation\n",
      "Figure1:RecoveredmembershiponsyntheticdatawithEMandconvex\n",
      "relaxation.30datapointsaregeneratedaccordingtoyi=(?i?xi)w+i,with\n",
      "9\n",
      "\n",
      "xi?R,i?N(0,1)andw?U(0,1).\n",
      "(a)GroundTruth\n",
      "(b)EM\n",
      "(c)Max-MinConvex(d)Min-MinConvex\n",
      "(e)GroundTruth\n",
      "(f)EM\n",
      "(g)Max-MinConvex(h)Min-MinConvex\n",
      "(i)GroundTruth\n",
      "(j)EM\n",
      "(k)Max-MinConvex(l)Min-MinConvex\n",
      "Figure2:Resultingmotionsegmentationsproducedbythevarioustech-\n",
      "niquesontheHopkins155dataset.2(a)-2(d):twocranes,2(e)-2(h):threecars,\n",
      "and2(i)-2(l):cars207.Intwocranesrow),EMproducesmoresegmenta-\n",
      "tionerrorsattheleftcrane.Inthreecars(secondrow),themax-minmethod\n",
      "givestheleastsegmentationerror(atthefrontsideofthemiddlecar)and\n",
      "EMproducesmoresegmentationerrorsatthefrontsideoftheleftcar.The\n",
      "contrastofEMandconvexmethodsisapparentforcars207(thirdrow):the\n",
      "convexmethodssegmentcorrectlythestaticgrassobject,whileEMmakes\n",
      "mistakes.Further,themin-minmethodcanalmostperfectlysegmentthecar\n",
      "inthemiddleofthescenefromthestatictreebackground.\n",
      "8\n",
      "2References\n",
      "[1]S.andP.Smyth.Trajectoryclusteringwithmixturesofregression\n",
      "models.InACMSIGKDD,volume62,pages63?72,1999.[2]S.Finney,L.\n",
      "Kaelbling,andT.Lozano-Perez.Predictingpartialpathsfromplanningprob-\n",
      "lemparameters.InProceedingsofRobotics:ScienceandSystems,Atlanta,\n",
      "GA,USA,June2007.[3]A.J.StorkeyandM.Sugiyama.Mixtureregression\n",
      "forcovariateshift.InSch?olkopf,editor,AdvancesinNeuralInformationPro-\n",
      "cessingSystems19,pages1337?1344,2007.[4]A.P.Dempster,N.M.Laird,\n",
      "andD.B.Rubin.Maximumlikelihoodfromincompletedataviatheemal-\n",
      "gorithm.JournaloftheRoyalStatisticalSociety.SeriesB(Methodological),\n",
      "39(1):1?38,1977.[5]T.DeBie,N.Cristianini,P.Bennett,andE.Parrado-\n",
      "hern?andez.Fastsdprelaxationsofgraphcutclustering,transduction,and\n",
      "othercombinatorialproblems.JMLR,7:1409?1436,2006.[6]Y.GuoandD.\n",
      "Schuurmans.Convexrelaxationsforlatentvariabletraining.InPlattetal.,\n",
      "editor,AdvancesinNeuralInformationProcessingSystems20,pages601?608,\n",
      "2008.[7]S.M.GoldfeldandR.E.Quandt.Nonlinearmethodsineconometrics.\n",
      "Amsterdam:NorthHollandPublishingCo.,1972.[8]D.W.Hosmer.Maximum\n",
      "likelihoodestimatesoftheparametersofamixtureoftworegressionlines.Com-\n",
      "municationsinStatistics,3(10):995?1006,1974.[9]H.Sp?ath.Algorithm39:\n",
      "clusterwiselinearregression.Computing,22:367?373,1979.[10]W.S.DeSarbo\n",
      "andW.L.Cron.Amaximumlikelihoodmethodologyforclusterwiselinearre-\n",
      "gression.Journalof5(1):249?282,1988.[11]P.N.JonesandG.J.\n",
      "10\n",
      "\n",
      "McLachlan.Fittingmixturesmodelsinaregressioncontext.Austral.J.\n",
      "Statistics,34(2):233?240,1992.[12]S.andP.Smyth.Curveclustering\n",
      "withrandomctsregressionmixtures.InAISTATS,2003.[13]M.I.Jor-\n",
      "danandR.A.Jacobs.Hierarchicalmixturesofexpertsandtheemalgorithm.\n",
      "Neuralcomputation,6:181?214,1994.[14]S.BoydandL.Vandenberghe.Con-\n",
      "vexOptimization.CambridgeUniversityPress,2004.[15]M.Overtonand\n",
      "R.Womersley.Optimalityconditionsanddualitytheoryforminimizingsums\n",
      "ofthelargesteigenvaluesofsymmetricmatrices.MathematicalProgramming,\n",
      "62:321?357,1993.[16]J.Yu,S.V.N.Vishwanathan,S.G?unter,andN.Schrau-\n",
      "dolph.Aquasi-Newtonapproachtononsmoothconvexoptimization.InICML,\n",
      "2008.[17]A.Argyriou,T.Evgeniou,andM.Pontil.Convexmulti-taskfeature\n",
      "learning.MachineLearning,73:243?272,2008.[18]J.Chen,L.Tang,J.Liu,\n",
      "andJ.Ye.Aconvexformulationforlearningsharedstructuresfrommultiple\n",
      "tasks.InICML,2009.[19]N.VasconcelosandA.Lippman.Empiricalbayesian\n",
      "em-basedmotionsegmentation.InCVPR,1997.[20]P.Torr.Geometricmotion\n",
      "segmentationandmodelselection.PhilosophicalTrans.oftheRoyalSociety\n",
      "ofLondon,356(1740):1321?1340,1998.[21]R.Vidal,Y.Ma,S.Soatto,andS.\n",
      "Sastry.Two-viewmultibodystructurefrommotion.IJCV,68(1):7?25,2006.\n",
      "[22]H.Li.Two-viewmotionsegmentationfromlinearprogrammingrelaxation.\n",
      "InCVPR,2007.[23]http://www.vision.jhu.edu/data/hopkins155/.\n",
      "9\n",
      "11\n",
      "\n",
      "PP5927.pdf\n",
      "PP5927.pdf 14\n",
      "AGeneralizationofSubmodularCoverviathe\n",
      "DiminishingReturnPropertyontheInteger\n",
      "Lattice\n",
      "Authoredby:\n",
      "YuichiYoshida\n",
      "TasukuSoma\n",
      "Abstract\n",
      "Weconsiderageneralizationofthesubmodularcoverproblembased\n",
      "ontheconceptofdiminishingreturnpropertyontheintegerlattice.We\n",
      "aremotivatedbyrealscenariosinmachinelearningthatcannotbecap-\n",
      "turedby(traditional)submodularsetfunctions.Weshowthatthegener-\n",
      "alizedsubmodularcoverproblemcanbeappliedtovariousproblemsand\n",
      "deviseabicriteriaapproximationalgorithm.Ouralgorithmisguaranteed\n",
      "tooutputalog-factorapproximatesolutionthattheconstraints\n",
      "withthedesiredaccuracy.Therunningtimeofouralgorithmisroughly\n",
      "$O(nlog(nr)log\n",
      "f\n",
      "r\n",
      "g\n",
      ")$,where$n$isthesizeofthegroundsetand$r$is\n",
      "themaximumvalueofacoordinate.Thedependencyon$r$isexponen-\n",
      "tiallybetterthanthenaivereductionalgorithms.Severalexperimentson\n",
      "realanddatasetsdemonstratethatthesolutionqualityofour\n",
      "algorithmiscomparabletonaivealgorithms,whiletherunningtimeis\n",
      "severalordersofmagnitudefaster.\n",
      "1PaperBody\n",
      "Afunctionf:2S?R+iscalledsubmodulariff(X)+f(Y)?f(X?Y)+f(X\n",
      "?Y)forallX,Y?S,whereSisagroundset.Anequivalentandmore\n",
      "intuitiveisbythediminishingreturnproperty:f(X?\n",
      "f\n",
      "s\n",
      "g\n",
      ")?f(X)?f\n",
      "(Y?\n",
      "f\n",
      "s\n",
      "g\n",
      ")?f(Y)forallX?Yands?SY.Inthelastdecade,theoptimizationof\n",
      "asubmodularfunctionhasattractedparticularinterestinthemachinelearning\n",
      "community.Onereasonofthisisthatmanyreal-worldmodelsnaturallyadmit\n",
      "thediminishingreturnproperty.Forexample,documentsummarization[12,\n",
      "13],maximizationinviralmarketing[7],andsensorplacement[10]\n",
      "canbedescribedwiththeconceptofsubmodularity,andtalgorithms\n",
      "havebeendevisedbyexploitingsubmodularity(forfurtherdetails,referto\n",
      "[8]).Avarietyofproposedmodelsinmachinelearning[4,13,18]boildown\n",
      "tothesubmodularcoverproblem[21];forgivenmonotoneandnonnegative\n",
      "1\n",
      "\n",
      "submodularfunctionsf,c:2S?R+,and?>0,wearetominimizec(X)\n",
      "subjecttof(X)??.(1)Intuitively,c(X)andf(X)representthecostandthe\n",
      "qualityofasolution,respectively.TheobjectiveofthisproblemistoX\n",
      "ofminimumcostwiththeworstqualityguarantee?.Althoughthisproblemis\n",
      "NP-hardsinceitgeneralizesthesetcoverproblem,asimplegreedyalgorithm\n",
      "achievestightlog-factorapproximationanditpracticallyperformsverywell.\n",
      "Theaforementionedsubmodularmodelsarebasedonthesubmodularityofa\n",
      "setfunction,afunctionon2S.However,weoftenencounterproblems\n",
      "thatcannotbecapturedbyasetfunction.Letusgivetwoexamples:Sensor\n",
      "Placement:Letusconsiderthefollowingsensorplacementscenario.Suppose\n",
      "thatwehaveseveraltypesofsensorswithvariousenergylevels.Weassumea\n",
      "simplebetween1\n",
      "informationgainandcost.Sensorsofahighenergylevelcancollectacon-\n",
      "siderableamountofinformation,butwehavetopayahighcostforplacing\n",
      "them.Sensorsofalowenergylevelcanbeplacedatalowcost,buttheycan\n",
      "onlygatherlimitedinformation.Inthisscenario,wewanttodecidewhichtype\n",
      "ofsensorshouldbeplacedateachspot,ratherthanjustdecidingwhetherto\n",
      "placeasensorornot.Suchascenarioisbeyondtheexistingmodelsbased\n",
      "onsubmodularsetfunctions.OptimalBudgetAllocation:Asimilarsituation\n",
      "alsoarisesintheoptimalbudgetallocationproblem[2].Inthisproblem,we\n",
      "wanttoallocatebudgetamongadsourcessothat(atleast)acertainnumber\n",
      "ofcustomersiswhileminimizingthetotalbudget.Again,wehave\n",
      "todecidehowmuchbudgetshouldbesetasideforeachadsource,andhence\n",
      "setfunctionscannotcapturetheproblem.Wenotethatafunctionf:2S?R+\n",
      "canbeseenasafunctiononaBooleanhypercube\n",
      "f\n",
      "0,1\n",
      "g\n",
      "S.Then,the\n",
      "aboverealscenariospromptustogeneralizethesubmodularityandthedimin-\n",
      "ishingreturnpropertytofunctionsontheintegerlatticeZS+.The\n",
      "mostnaturalgeneralizationofthediminishingreturnpropertytoafunctionf\n",
      ":ZS+?R+isthefollowinginequality:f(x+?s)?f(x)?f(y+?s)?\n",
      "f(y)(2)forx?yands?S,where?sisthes-thunitvector.Iffs\n",
      "(2),thenfalsothefollowinglatticesubmodularinequality:f(x)+f\n",
      "(y)?f(x?y)+f(x?y)(3)forallx,y?ZS+,where?and?arethe\n",
      "coordinate-wisemaxandminoperations,respectively.Whilethesubmodularity\n",
      "andthediminishingreturnpropertyareequivalentforsetfunctions,thisisnot\n",
      "thecaseforfunctionsovertheintegerlattice;thediminishingreturnproperty\n",
      "(2)isstrongerthanthelatticesubmodularinequality(3).Wesaythatfis\n",
      "latticesubmodulariff(3),andifffurther(2)wesaythatf\n",
      "isdiminishingreturnsubmodular(DR-submodularforshort).Onemightfeel\n",
      "thattheDR-submodularity(2)istoorestrictive.However,consideringthefact\n",
      "thatthediminishingreturnismorecrucialinapplications,wemayregardthe\n",
      "DR-submodularity(2)asthemostnaturalgeneralizationofthesubmodularity,\n",
      "atleastforapplicationsmentionedsofar[17,6].Forexample,underanatural\n",
      "condition,theobjectivefunctionintheoptimalbudgetallocation(2)\n",
      "[17].TheDR-submodularitywasalsoconsideredinthecontextofsubmodular\n",
      "welfare[6].Inthispaper,weconsiderthefollowinggeneralizationofthesub-\n",
      "modularcoverproblemforsetfunctions:GivenamonotoneDR-submodular\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functionf:ZS+?R+,asubadditivefunctionc:ZS+?R+,?>0,andr?\n",
      "Z+,wearetominimizec(x)\n",
      "subjecttof(x)??,\n",
      "0?x?r1,\n",
      "(4)\n",
      "ZS+.\n",
      "wherewesaythatcissubadditiveifc(x+y)?c(x)+c(y)forallx,y?We\n",
      "callproblem(4)theDR-submodularcoverproblem.Thisproblemencompasses\n",
      "problemsthatboildowntothesubmodularcoverproblemforsetfunctionsand\n",
      "theirgeneralizationstotheintegerlattice.Furthermore,thecostfunctioncis\n",
      "generalizedtoasubadditivefunction.Inparticular,wenotethattwoexamples\n",
      "givenabovecanberephrasedusingthisproblem(seeSection4fordetails).If\n",
      "cisalsomonotoneDR-submodular,onecanreducetheproblem(4)totheset\n",
      "version(1)(fortechnicaldetails,seeSection3.1).Theproblemofthisnaive\n",
      "reductionisthatitonlyyieldsapseudo-polynomialtimealgorithm;therunning\n",
      "timedependsonrratherthanlogr.Sincercanbehugeinmanypractical\n",
      "settings(e.g.,themaximumenergylevelofasensor),evenlineardependenceon\n",
      "rcouldmakeanalgorithmimpractical.Furthermore,forageneralsubadditive\n",
      "functionc,thisnaivereductiondoesnotwork.1.1\n",
      "OurContribution\n",
      "Fortheproblem(4),wedeviseabicriteriaapproximationalgorithmbased\n",
      "onthedecreasingthresholdtechniqueof[3].Moreprecisely,ouralgorithmtakes\n",
      "theadditionalparameters0<,?<1.The\n",
      "Soutputx?Z+ofouralgorithmisguaranteedtosatisfythatc(x)isat\n",
      "most(1+3)?1+log?dtimestheoptimumandf(x)?(1??)?,where?\n",
      "isthecurvatureofc(seeSection3forthed=maxsf(?s)isthe\n",
      "maximumvalueoffoverallstandardunitvectors,and?istheminimumvalue\n",
      "ofthepositiveincrementsoffinthefeasibleregion.2\n",
      "RunningTime(dependencyonr):Animportantfeatureofouralgorithmis\n",
      "thattherunningtimedependsonthebitlengthofronlypolynomiallywhereas\n",
      "thenaivereductionalgorithmsdependonitexponentiallyasmentionedabove.\n",
      "Moreprecisely,therunningtimeofouralgorithmismaxO(nlognrc?cmin\n",
      "logr),whichispolynomialintheinputsize,whereasthenaivealgorithmis\n",
      "onlypsuedo-polynomialtimealgorithm.Infact,ourexperimentsusingrealand\n",
      "syntheticdatasetsshowthatouralgorithmisconsiderablyfasterthannaive\n",
      "algorithms.Furthermore,intermsoftheobjectivevalue(thatis,thecostofthe\n",
      "output),ouralgorithmalsoexhibitscomparableperformance.Approximation\n",
      "Guarantee:Ourapproximationguaranteeonthecostisalmosttight.Notethat\n",
      "theDRsubmodularcoverproblem(4)includesthesetcoverproblem,inwhich\n",
      "wearegivenacollectionofsets,andwewanttoaminimumnumberof\n",
      "setsthatcoversalltheelements.Inourcontext,Scorrespondstothecollection\n",
      "ofsets,thecostcisthenumberofchosensets,andfisthenumberofcovered\n",
      "elements.Itisknownthatwecannotobtainano(logm)-approximationunlessP\n",
      "6=NP,wheremisthenumberofelements[16].However,sinceforthesetcover\n",
      "problemwehave?=1,d=O(m),and?=1,ourapproximationguaranteeis\n",
      "O(logm).1.2\n",
      "3\n",
      "\n",
      "RelatedWork\n",
      "Ourresultcanbecomparedwithseveralresultsintheliteratureforthe\n",
      "submodularcoverproblemforsetfunctions.ItisshownbyWolsey[21]thatif\n",
      "c(X)=|X|,asimplegreedyalgorithmyields(1+log?d)-approximation,\n",
      "whichcoincideswithourapproximationratioexceptforthe(1+3)factor.\n",
      "Notethat?=1whenc(X)=|X|,ormoregenerally,whencismodular.\n",
      "Recently,Wanetal.[20]discussedaslightlytsetting,inwhichcisalso\n",
      "submodularandbothfandcareintegervalued.Theyprovedthatthegreedy\n",
      "algorithmachieves?H(d)-approximation,whereH(d)=1+1/2+???+1/dis\n",
      "thed-thharmonicnumber.Again,theirratioasymptoticallycoincideswith\n",
      "ourapproximationratio(Notethat??1whenfisintegervalued).Another\n",
      "commonsubmodular-basedmodelinmachinelearningisintheformofthe\n",
      "submodularmaximizationproblem:Givenamonotonesubmodularsetfunction\n",
      "f:\n",
      "f\n",
      "0,1\n",
      "g\n",
      "S?R+andafeasibleSsetP?[0,1](e.g.,amatroidpolytopeora\n",
      "knapsackpolytope),wewanttomaximizef(x)subjecttox?P?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "S.\n",
      "Suchmodelscanbewidelyfoundinvarioustasksasalreadydescribed.Wenote\n",
      "thatthesubmodularcoverproblemandthesubmodularmaximizationproblem\n",
      "aresomewhatdualtoeachother.Indeed,IyerandBilmes[5]showedthata\n",
      "bicriteriaalgorithmofoneoftheseproblemsyieldsabicriteriaalgorithmforthe\n",
      "other.Beingparalleltooursetting,generalizingthesubmodularmaximization\n",
      "problemtotheintegerlatticeZS+isanaturalquestion.Inthisdirection,Soma\n",
      "etal.[17]consideredthemaximizationoflatticesubmodularfunctions(not\n",
      "necessarilybeingDR-submodular)anddevisedaconstant-factorapproximation\n",
      "pseudo-polynomialtimealgorithm.Wenotethatourresultisnotimpliedby\n",
      "[17]viathedualityof[5].Infact,suchreductiononlyyieldsapseudo-polynomial\n",
      "timealgorithm.1.3\n",
      "OrganizationofThisPaper\n",
      "Therestofthispaperisorganizedasfollows:Section2setsthemathematical\n",
      "basicsofsubmodularfunctionsovertheintegerlattice.Section3describesour\n",
      "algorithmandthestatementofourmaintheorem.InSection4,weshowvarious\n",
      "experimentalresultsusingrealandcialdatasets.Section5sketchesthe\n",
      "proofofthemaintheorem.Finally,weconcludethepaperinSection6.\n",
      "2\n",
      "Preliminaries\n",
      "LetSbeaset.Foreachs?S,wedenotethes-thunitvectorby?s;\n",
      "thatis,?s(t)=1ift=s,otherwise?s(t)=0.Afunctionf:ZS?Rissaidto\n",
      "belatticesubmodulariff(x)+f(y)?f(x?y)+f(x?y)forallx,y?ZS.A\n",
      "functionfismonotoneiff(x)?f(y)forallx,y?ZSwithx?y.Forx,y?ZS\n",
      "andafunctionf:ZS?R,wedenotef(y|x):=f(y+x)?f(x).Afunction\n",
      "fisdiminishingreturnsubmodular(orDR-submodular)iff(x+?s)?f(x)?\n",
      "f(y+?s)?f(y)foreachx?y?ZSands?S.ForaDR-submodularfunction\n",
      "f,onecanimmediatelycheckthatf(k?s|x)?f(k?s|y)forarbitraryx?\n",
      "y,s?S,andk?Z+.Afunctionfissubadditiveiff(x+y)?f(x)+f(y)for\n",
      "x,y?ZS.Foreachx?ZS+,we\n",
      "f\n",
      "x\n",
      "g\n",
      "tobethemultisetinwhicheachs\n",
      "?Siscontainedx(s)times.3\n",
      "In[17],alatticesubmodularfunctionf:ZS?Rissaidtohavethedimin-\n",
      "4\n",
      "\n",
      "ishingreturnpropertyiffiscoordinate-wiseconcave:f(x+2?s)?f(x+?s)\n",
      "?f(x+?s)?f(x)foreachx?ZSands?S.Wenotethatouris\n",
      "consistentwith[17].Formally,wehavethefollowinglemma,whoseproofcan\n",
      "befoundinAppendix.Lemma2.1.Afunctionf:ZS?RisDR-submodularif\n",
      "andonlyiffislatticesubmodularandcoordinate-wiseconcave.Thefollowing\n",
      "isfundamentalforamonotoneDR-submodularfunction.Aproofisplacedin\n",
      "Appendixduetothelimitationofspace.PLemma2.2.ForamonotoneDR-\n",
      "submodularfunctionf,f(x)?f(y)?s?\n",
      "f\n",
      "x\n",
      "g\n",
      "f(?s|y)forarbitraryx,y?ZS\n",
      ".\n",
      "3\n",
      "AlgorithmfortheDR-submodularCover\n",
      "RecalltheDR-submodularcoverproblem(4).Letf:ZS+?R+bea\n",
      "monotoneDR-submodularfunctionandletc:ZS+?R+beasubadditive\n",
      "costfunction.Theobjectiveistominimizec(x)subjecttof(x)??and0\n",
      "?x?r1,where?>0andr?Z+arethegivenconstants.Withoutlossof\n",
      "generality,wecanassumethatmax\n",
      "f\n",
      "f(x):0?x?r1\n",
      "g\n",
      "=?(otherwise,wecan\n",
      "considerfb(x):=min\n",
      "f\n",
      "f(x),?\n",
      "g\n",
      "insteadoff).Furthermore,wecanassumec(x)\n",
      ">0foranyx?ZS+.Apseudocodedescriptionofouralgorithmispresentedin\n",
      "Algorithm1.Thealgorithmcanbeviewedasamoversionofthegreedy\n",
      "algorithmandworksasfollows:Westartwiththeinitialsolutionx=0and\n",
      "increaseeachcoordinateofxgradually.Todeterminetheamountofincrements,\n",
      "thealgorithmmaintainsathreshold?thatisinitializedtobetlylarge\n",
      "enough.Foreachs?S,thealgorithmthelargestintegerstepsize0<\n",
      "k?r?x(s)suchthatthemarginalcost-gain(k?s|x)ratiofkc(?isabove\n",
      "thethreshold?.Ifsuchkexists,thealgorithmupdatesxtox+k?s.After\n",
      "s)repeatingthisforeachs?S,thealgorithmdecreasesthethreshold?by\n",
      "afactorof(1?).Ifxbecomesfeasible,thealgorithmreturnsthecurrentx.\n",
      "Evenifxdoesnotbecomefeasible,thexf(x)?(1??)?ifwe\n",
      "iterateuntil?getstlysmall.Algorithm1DecreasingThresholdforthe\n",
      "DR-SubmodularCoverProblemInput:f:ZS+?R+,c:ZS+?R+,r?N,\n",
      "?>0,>0,?>0.Output:0?x?r1suchthatf(x)??.1:x?0,d?maxf\n",
      "(?s),cmin?minc(?s),cmax?maxc(?s)s?S\n",
      "s?S\n",
      "s?S\n",
      "d?2:for(?=cmin;??ncmaxrd;???(1?))do3:foralls?Sdo4:\n",
      "Findmaximuminteger0<k?r?x(s)suchthat5:Ifsuchkexiststhenx?x\n",
      "+k?s.6:Iff(x)??thenbreaktheouterforloop.7:returnx\n",
      "f(k?s|x)kc(?s)\n",
      "??withbinarysearch.\n",
      "Beforeweclaimthetheorem,weneedtoseveralparametersonfand\n",
      "c.Let?:=min\n",
      "f\n",
      "f(?s|x):s?S,x?ZS+,f(?s|x)>0\n",
      "g\n",
      "andd:=maxsf\n",
      "(?s).Letcmax:=maxsc(?s)andcmin:=minsc(?s).thecurvatureof\n",
      "ctobePs?\n",
      "f\n",
      "x?\n",
      "g\n",
      "c(?s)?:=?min.(5)x:optimalsolutionc(x?)\n",
      "3.1.For??1and0<?<1,avectorx?ZS+isa(?,?)-bicriteriaapproximate\n",
      "solutionifc(x)???c(x?),f(x)?(1??)?,and0?x?r1.Ourmaintheorem\n",
      "isdescribedbelow.WesketchtheproofinSection5.\n",
      "5\n",
      "\n",
      "Theorem3.2.Algorithm1outputsa(1+3)?1+log?d,?-bicriteria\n",
      "approximatesolution\n",
      "maxinOnlognrc?cminlogrtime.4\n",
      "3.1\n",
      "Discussion\n",
      "Integer-valuedCase.Letusmakeasimpleremarkonthecasethatfis\n",
      "integervalued.Withoutlossofgenerality,wecanassume??Z+.Then,\n",
      "Algorithm1alwaysreturnsafeasiblesolutionforany0<?<1/?.Therefore,\n",
      "ouralgorithmcanbeeasilymotoanapproximationalgorithmiffisinteger\n",
      "valued.ofCurvature.Severalauthors[5,19]useatnotion\n",
      "ofcurvaturecalledthetotalcurvature,whosenaturalextensionforafunction\n",
      "overtheintegerlatticeisasfollows:The|r1??s)totalcurvature?ofc:\n",
      "ZS+?R+isas?:=1?mins?Sc(?sc(?.Notethat?=0s)if\n",
      "cismodular,while?=1ifcismodular.Forexample,IyerandBilmes[5]\n",
      "devisedabicriteriaapproximationalgorithmwhoseapproximationguaranteeis\n",
      "roughlyO((1??)?1log?d).Letusinvestigatetherelationbetween?and?\n",
      "forDR-submodularfunctions.Onecanshowthat1?????(1??)?1(see\n",
      "LemmaE.1inAppendix),whichmeansthatourboundintermsof?istighter\n",
      "thanoneintermsof(1??)?1.ComparisontoNaiveReductionAlgorithm.\n",
      "IfcisalsoamonotoneDR-submodularfunction,onecanreduce(4)totheset\n",
      "version(1)asfollows.Foreachs?S,creatercopiesofsandlet??S,?\n",
      "x??ZS+betheintegralvectorsuchthatx?(s)S?bethesetofthese\n",
      "copies.ForXXX?Then,f?(X)?:=f(x?)issubmodular.Similarly,is\n",
      "thenumberofcopiesofscontainedinX.X?:=c(x?)isalsosubmodularif\n",
      "cisaDR-submodularfunction.Thereforewemayapplyac?(X)Xstandard\n",
      "greedyalgorithmof[20,21]tothereducedproblemandthisisexactlywhat\n",
      "Greedydoesinourexperiment(seeSection4).However,thisstraightforward\n",
      "reductiononlyyieldsapseudo?=nr;eveniftheoriginalalgorithmwaslinear,\n",
      "theresultingpolynomialtimealgorithmsince|S|algorithmwouldrequire\n",
      "O(nr)time.Indeedthisisnotnegligiblesincercanbequitelarge\n",
      "inpracticalapplications,asillustratedbyourexperimentalevaluation.Lazy\n",
      "Evaluation.Wenotethatwecancombinethelazyevaluationtechnique\n",
      "[11,14],whichtlyreducesruntimeinpractice,withouralgorithm.\n",
      "Sp,wepushall(?s)theelementsinStoamax-basedpriority\n",
      "queue.Here,thekeyofanelements?Sisfc(?.Thens)theinnerloopof\n",
      "Algorithm1ismoasfollows:InsteadofcheckingalltheelementsinS,we\n",
      "popelementswhosekeysareatleast?.Foreachpoppedelements?S,we\n",
      "ksuchthat(k?s|x)0<k?r?x(s)withfkc(???withbinarysearch.If\n",
      "thereissuchk,weupdatexwiths)x+k?s.Finally,wepushsagainwiththe\n",
      "key\n",
      "f(?s|x)c(?s)\n",
      "ifx(s)<r.\n",
      "ThecorrectnessofthistechniqueisobviousbecauseoftheDR-submodularity\n",
      "off.Inparticular,(?s|x),wherexisthecurrentvector.thekeyofeach\n",
      "elements?Sinthequeueisalwaysatleastfc(?s)Hence,wenevermisss?\n",
      "Swith\n",
      "6\n",
      "\n",
      "44.1\n",
      "f(k?s|x)kc(?s)\n",
      "??.\n",
      "ExperimentsExperimentalSetting\n",
      "WeconductedexperimentsonaLinuxserverwithanIntelXeonE5-2690\n",
      "(2.90GHz)processorand256GBofmainmemory.Theexperimentsrequired,\n",
      "atmost,4GBofmemory.AllthealgorithmswereimplementedinC++and\n",
      "compiledwithg++4.6.3.Inourexperiments,thecostfunctionc:ZS+?\n",
      "R+isalwayschosenasc(x)=kxk1:=PSs?Sx(s).Letf:Z+?R+bea\n",
      "submodularfunctionand?betheworstqualityguarantee.Weimplemented\n",
      "thefollowingfourmethods:?Decreasing-thresholdisourmethodwiththelazy\n",
      "evaluationtechnique.Wechose?=0.01asstatedotherwise.?Greedyisa\n",
      "methodinwhich,startingfromx=0,weiterativelyincrementx(s)fors?S\n",
      "thatmaximizesf(x+?s)?f(x)untilwegetf(x)??.Wealsoimplemented\n",
      "thelazyevaluationtechnique[11].5\n",
      "?Degreeisamethodinwhichweassignx(s)avalueproportionaltothe\n",
      "marginalf(?s)?f(0),wherekxk1isdeterminedbybinarysearchsothatf(x)?\n",
      "?.Preciselyspeaking,x(s)isapproximatelyproportionaltothemarginalsince\n",
      "x(s)mustbeaninteger.?Uniformisamethodthatreturnsk1forminimumk?\n",
      "Z+suchthatf(k1)??.Weusethefollowingreal-worldandsyntheticdatasets\n",
      "totheaccuracyandciencyofourmethodagainstothermethods.\n",
      "Wesetr=100,000forbothproblems.Sensorplacement.Weusedadataset\n",
      "acquiredbyrunningsimulationsona129-vertexsensornetworkusedinBattle\n",
      "oftheWaterSensorNetworks(BWSN)[15].Weusedthe?bwsn-utilities?[1]\n",
      "programtosimulate3000randominjectioneventstothisnetworkforaduration\n",
      "of96hours.LetSandEbethesetofthe129sensorsinthenetworkandthe\n",
      "setofthe3000events,respectively.Foreachsensors?Sandevente?E,\n",
      "avaluez(s,e)isprovided,whichdenotesthetime,inminutes,thepollution\n",
      "hasreachedsaftertheinjectiontime.1Weafunctionf:ZS+?R+as\n",
      "follows:Letx?ZS+beavector,whereweregardx(s)astheenergylevelofthe\n",
      "sensors.Supposethatwhenthepollutionreachesasensors,theprobability\n",
      "x(s)thatwecandetectitis1?(1?p),wherep=0.0001.Inotherwords,\n",
      "byspendingunitenergy,weobtainanextrachanceofdetectingthepollution\n",
      "withprobabilityp.Foreachevente?E,letsebethesensorwherethe\n",
      "pollutionisdetectedinthatinjectionevent.Notethatseisarandomvariable.\n",
      "Letz?=maxz(s,e).Then,wefasfollows:e?E,s?S\n",
      "f(x)=EE[z??z(se,e)],e?Ese\n",
      "wherez(se,e)isasz?whenthereisnosensorthatmanagedto\n",
      "detectthepollution.Intuitivelyspeaking,E[z??z(se,e)]expresseshowmuch\n",
      "timewemanagedtosaveintheeventese\n",
      "onaverage.Then,wetaketheaverageoveralltheevents.Asimilarfunction\n",
      "wasalsousedin[11]tomeasuretheperformanceofasensorallocationalthough\n",
      "theyonlyconsideredthecasep=1.Thiscorrespondstothecasethatby\n",
      "spendingunitenergyatasensors,wecanalwaysdetectthepollutionthathas\n",
      "reacheds.Wenotethatf(x)isDR-submodular(seeLemmaF.1fortheproof).\n",
      "Budgetallocationproblem.Inordertoobservethebehaviorofouralgorithm\n",
      "7\n",
      "\n",
      "forlarge-scaleinstances,wecreatedasyntheticinstanceofthebudgetallocation\n",
      "problem[2,17]asfollows:Theinstancecanberepresentedasabipartitegraph\n",
      "(S,T;E),whereSisasetof5,000verticesandTisasetof50,000vertices.\n",
      "WeregardavertexinSasanadsource,andavertexinTasaperson.Then,\n",
      "wethedegreesofverticesinSsothattheirdistributionobeysthepowerlaw\n",
      "of?:=2.5;thatis,thefractionofadsourceswithout-degreedisproportional\n",
      "tod??.Foravertexs?Softhesupposeddegreed,wechoosedverticesinT\n",
      "uniformlyatrandomandconnectthemtoswithedges.Weafunctionf\n",
      ":ZS+?R+as\n",
      "XYx(s)f(x)=1?(1?p),(6)t?T\n",
      "s??(t)\n",
      "where?(t)isthesetofverticesconnectedtotandp=0.0001.Here,we\n",
      "supposethat,byinvestingaunitcosttoanadsources?S,wehaveanextra\n",
      "chanceofapersont?Twiths??(t)withprobabilityp.Then,f\n",
      "(x)canbeseenastheexpectednumberofpeopleencedbyadsources.We\n",
      "notethatfisknowntobeamonotoneDR-submodularfunction[17].4.2\n",
      "ExperimentalResults\n",
      "Figure1illustratestheobtainedobjectivevaluekxk1forvariouschoicesof\n",
      "theworstqualityguarantee?oneachdataset.Wechose=0.01inDecreasing\n",
      "threshold.WecanobservethatDecreasingthresholdattainsalmostthesame\n",
      "objectivevalueasGreedy,anditoutperformsDegreeandUniform.Figure2\n",
      "illustratestheruntimeforvariouschoicesoftheworstqualityguarantee?on\n",
      "eachdataset.Wechose=0.01inDecreasingthreshold.Wecanobservethat\n",
      "theruntimegrowthofDecreasingthresholdistlyslowerthanthatof\n",
      "Greedy.1\n",
      "Althoughthreeothervaluesareprovided,theyshowedsimilarempirical\n",
      "resultsandweomitthem.\n",
      "6\n",
      "4\n",
      "30000\n",
      "2\n",
      "10\n",
      "15000\n",
      "1\n",
      "10\n",
      "0\n",
      "10000\n",
      "10\n",
      "5000\n",
      "10\n",
      "-1\n",
      "00\n",
      "500\n",
      "1000\n",
      "1500?\n",
      "2000\n",
      "8\n",
      "\n",
      "2500\n",
      "3000\n",
      "1\n",
      "10\n",
      "0\n",
      "10\n",
      "-1\n",
      "10\n",
      "-2\n",
      "10\n",
      "-3\n",
      "10\n",
      "500\n",
      "1000\n",
      "1500?\n",
      "2000\n",
      "2500\n",
      "0\n",
      "3000\n",
      "(a)Sensorplacement(BWSN)\n",
      "2.51e8\n",
      "0\n",
      "500\n",
      "4\n",
      "2\n",
      "10\n",
      "2500\n",
      "3000\n",
      "1.00.10.010.0010.0001Greedy\n",
      "3\n",
      "10\n",
      "2\n",
      "time(s)\n",
      "2000\n",
      "4\n",
      "3\n",
      "1.0\n",
      "1500?\n",
      "10\n",
      "GreedyDecreasingthresholdDegreeUniform\n",
      "10\n",
      "1.5\n",
      "1000\n",
      "(a)Relativecostincrease\n",
      "10\n",
      "GreedyDecreasingthresholdDegreeUniform\n",
      "9\n",
      "\n",
      "2.0\n",
      "0\n",
      "1.00.10.010.0010.0001\n",
      "2\n",
      "10\n",
      "-2\n",
      "10\n",
      "(a)Sensorplacement(BWSN)\n",
      "Objectivevalue\n",
      "Relativeincreaseoftheobjectivevalue\n",
      "10\n",
      "time(s)\n",
      "Objectivevalue\n",
      "20000\n",
      "10\n",
      "UniformDecreasingthresholdDegreeGreedy\n",
      "3\n",
      "time(s)\n",
      "25000\n",
      "3\n",
      "10\n",
      "UniformDecreasingthresholdDegreeGreedy\n",
      "1\n",
      "10\n",
      "10\n",
      "1\n",
      "10\n",
      "0\n",
      "100.5\n",
      "0\n",
      "10\n",
      "-1\n",
      "10\n",
      "0.00\n",
      "-2\n",
      "5000\n",
      "10000?\n",
      "15000\n",
      "10\n",
      "20000\n",
      "-1\n",
      "0\n",
      "5000\n",
      "10000?\n",
      "15000\n",
      "20000\n",
      "10\n",
      "\n",
      "10\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500?\n",
      "2000\n",
      "2500\n",
      "(b)Budgetallocation(synthetic)\n",
      "(b)Budgetallocation(synthetic)\n",
      "(b)Runtime\n",
      "Figure1:Objectivevalues\n",
      "Figure2:Runtime\n",
      "Figure3:of\n",
      "3000\n",
      "Figures3(a)and3(b)showtherelativeincreaseoftheobjectivevalueand\n",
      "theruntime,respectively,ofourmethodagainstGreedyontheBWSNdataset.\n",
      "Wecanobservethattherelativeincreaseoftheobjectivevaluegetssmalleras?\n",
      "increases.Thisphenomenoncanbewellexplainedbyconsideringtheextreme\n",
      "casethat?=maxf(r1).Inthiscase,weneedtochoosex=r1anywayinorder\n",
      "toachievetheworstqualityguarantee,andtheorderofincreasingcoordinates\n",
      "ofxdoesnotmatter.Also,wecanseethattheempiricalruntimegrowsasa\n",
      "functionof1,whichmatchesourtheoreticalbound.\n",
      "5\n",
      "ProofofTheorem3.2\n",
      "Inthissection,weoutlinetheproofofthemaintheorem.Proofsofsome\n",
      "minorclaimscanbefoundinAppendix.First,weintroduceanotation.Let\n",
      "usassumethatxisupdatedLtimesinthealgorithm.Letxibethevariable\n",
      "xafterthei-thupdate(i=0,...,L).Notethatx0=0andxListhe\n",
      "outputofthealgorithm.Letsi?Sandki?Z+bethepairusedinthei-th\n",
      "updatefori=1,...,L;thatis,kc(?si)fori=1,...,L.Letxi=xi?1+\n",
      "ki?sifori=1,...,L.Let?0:=0and?i:=f(kii?s|xi?1)i\n",
      "??0:=0and??i:=?i?1fori=1,...,L,where?iisthethresholdvalue\n",
      "onthei-thPupdate.Notethat??i?1???ifori=1,...,L.Letx?bean\n",
      "optimalsolutionsuchthat??c(x?)=s?\n",
      "f\n",
      "x?\n",
      "g\n",
      "c(?s).Weregardthatinthe\n",
      "i-thupdate,theelementsof\n",
      "f\n",
      "x?\n",
      "g\n",
      "arechargedbythevalueof?i(f(?s|xi?1\n",
      ")?f(?s|xi)).Then,thetotalchargeon\n",
      "f\n",
      "x?\n",
      "g\n",
      "isasT(x,f):=\n",
      "LXX\n",
      "?i(f(?s|xi?1)?f(?s|xi)).\n",
      "s?\n",
      "f\n",
      "x?\n",
      "g\n",
      "i=1\n",
      "Claim5.1.Letus1?i?Larbitraryandlet?bethethresholdvalueon\n",
      "thei-thupdate.Then,f(?s|xi?1)?f(ki?si|xi?1)??and?(s?S).ki\n",
      "c(?si)c(?s)1?Eliminating?fromtheinequalitiesinClaim5.1,weobtainki\n",
      "c(?si)1c(?s)?(i=1,...,L,f(ki?si|xi?1)1?f(?s|xi?1)7\n",
      "s?S)\n",
      "(7)\n",
      "Furthermore,wehave?i???i?Claim5.2.c(x)?\n",
      "11\n",
      "\n",
      "11??i\n",
      "fori=1,...,L.\n",
      "11?T(x,f).?\n",
      "Claim5.3.Foreachs?\n",
      "f\n",
      "x\n",
      "g\n",
      ",thetotalchargeonsisatmost\n",
      "11?(1\n",
      "+log(d/?))c(?s).\n",
      "Proof.Letuss?\n",
      "f\n",
      "x?\n",
      "g\n",
      "andletlbetheminimumisuchthatf(?s|xi\n",
      ")=0.By(7),wehavekic(?si)1c(?s)?i=??.(i=1,...,l)f(ki?si|\n",
      "xi?1)1?f(?s|xi?1)Then,wehaveLl?1XX?i(f(?s|xi?1)?f(?s|\n",
      "xi))=?i(f(?s|xi?1)?f(?s|xi))+?lf(?s|xl?1)i=1\n",
      "i=1\n",
      "l?1X(f(?s|xi?1)?f(?s|xi))f(?s|xl?1)1c(?s)+?1?f(?s|\n",
      "xi?1)f(?s|xl?1)i=1\n",
      "?\n",
      "l?1\n",
      "X1f(?s|xi)c(?s)1+1?1?f(?s|xi?1)i=1\n",
      "l?1\n",
      "X1f(?s|xi?1)c(?s)1+(since1?1/x?logxforx?1)log1?f(?s\n",
      "|xi)i=1\n",
      "f(?s|x0)11dc(?s)1+log=?1+logc(?s)1?f(?s|xl?1)1??\n",
      "?\n",
      "ProofofTheorem3.2.Combiningtheseclaims,wehave\n",
      "X\n",
      "11ddc(x)??T(x,f)??1+log?c(?)?(1+3)?1+log??c(x?\n",
      ").s1?(1?)2???s?\n",
      "f\n",
      "x\n",
      "g\n",
      "Thus,xisanapproximatesolutionwiththedesiredratio.Letusseethat\n",
      "xapproximatelytheconstraint;thatis,f(x)?(1??)?.Wewillnow\n",
      "consideraslightlymoversionofthealgorithm;inthemoedalgorithm,\n",
      "thethresholdisupdateduntilf(x)=?.Letx0betheoutputofthemo\n",
      "algorithm.Then,wehaveXX?c(?s)f(x0)?f(x)?f(?s|x)?d??d?\n",
      "??cmaxnr00s?\n",
      "f\n",
      "x\n",
      "g\n",
      "s?\n",
      "f\n",
      "x\n",
      "g\n",
      "Thethirdinequalityholdssincec(?s)?cmaxand|\n",
      "f\n",
      "x0\n",
      "g\n",
      "|?nr.Thusf\n",
      "(x)?(1??)?.\n",
      "6\n",
      "Conclusions\n",
      "Inthispaper,motivatedbyrealscenariosinmachinelearning,wegener-\n",
      "alizedthesubmodularcoverproblemviathediminishingreturnpropertyover\n",
      "theintegerlattice.Weproposedabicriteriaapproximationalgorithmwiththe\n",
      "followingproperties:(i)Theapproximationratiotothecostalmostmatches\n",
      "theoneguaranteedbythegreedyalgorithm[21]andisalmosttightingeneral.\n",
      "(ii)Wecansatisfytheworstsolutionqualitywiththedesiredaccuracy.(iii)\n",
      "TherunningtimeofouralgorithmisroughlyO(nlognlogr).Thedependency\n",
      "onrisexponentiallybetterthanthatofthegreedyalgorithm.We\n",
      "byexperimentthatcomparedwiththegreedyalgorithm,thesolutionquality\n",
      "12\n",
      "\n",
      "ofouralgorithmisalmostthesameandtheruntimeisseveralordersofmagni-\n",
      "tudefaster.AcknowledgmentsTheauthorissupportedbyJSPSGrant-in-\n",
      "AidforJSPSFellows.ThesecondauthorissupportedbyJSPSGrant-in-Aid\n",
      "forYoungScientists(B)(No.26730009),MEXTGrant-in-AidforScien\n",
      "ResearchonInnovativeAreas(24106003),andJST,ERATO,Kawarabayashi\n",
      "LargeGraphProject.TheauthorsthankSatoruIwataandYujiNakatsukasa\n",
      "forreadingadraftofthispaper.8\n",
      "2References\n",
      "[1]http://www.water-simulation.com/wsp/about/bwsn/.[2]N.Alon,I.Gamzu,\n",
      "andM.Tennenholtz.Optimizingbudgetallocationamongchannelsand\n",
      "encers.InProc.ofWWW,pages381?388,2012.[3]A.BadanidiyuruandJ.\n",
      "Vondr?ak.Fastalgorithmsformaximizingsubmodularfunctions.InProc.of\n",
      "SODA,pages1497?1514,2014.[4]Y.Chen,H.Shioi,C.A.F.Montesinos,L.\n",
      "P.Koh,S.Wich,andA.Krause.Activedetectionviaadaptivesubmodularity.\n",
      "InProc.ofICML,pages55?63,2014.[5]R.IyerandJ.Bilmes.Submodular\n",
      "optimizationwithsubmodularcoverandsubmodularknapsackconstraints.In\n",
      "Proc.ofNIPS,pages2436?2444,2013.[6]M.Kapralov,I.Post,andJ.Von-\n",
      "drak.Onlinesubmodularwelfaremaximization:Greedyisoptimal.InProc.\n",
      "ofSODA,pages1216?1225,2012.[7]D.Kempe,J.Kleinberg,andE.Tar-\n",
      "dos.Maximizingthespreadofthroughasocialnetwork.InProc.\n",
      "ofKDD,pages137?146,2003.[8]A.KrauseandD.Golovin.Submodular\n",
      "functionmaximization.InTractability:PracticalApproachestoHardProb-\n",
      "lems,pages71?104.CambridgeUniversityPress,2014.[9]A.Krauseand\n",
      "J.Leskovec.tsensorplacementoptimizationforsecuringlargewater\n",
      "distributionnetworks.JournalofWaterResourcesPlanningandManagement,\n",
      "134(6):516?526,2008.[10]A.Krause,A.Singh,andC.Guestrin.Near-optimal\n",
      "sensorplacementsingaussianprocesses:Theory,talgorithmsandem-\n",
      "piricalstudies.TheJournalofMachineLearningResearch,9:235?284,2008.\n",
      "[11]J.Leskovec,A.Krause,C.Guestrin,C.Faloutsos,J.VanBriesen,andN.\n",
      "Glance.eoutbreakdetectioninnetworks.InProc.ofKDD,pages\n",
      "420?429,2007.[12]H.LinandJ.Bilmes.Multi-documentsummarizationvia\n",
      "budgetedmaximizationofsubmodularfunctions.InProceedingsoftheAnnual\n",
      "ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-\n",
      "tionalLinguistics,pages912?920,2010.[13]H.LinandJ.Bilmes.Aclassof\n",
      "submodularfunctionsfordocumentsummarization.InProc.ofNAACL,pages\n",
      "510?520,2011.[14]M.Minoux.Acceleratedgreedyalgorithmsformaximizing\n",
      "submodularsetfunctions.OptimizationTechniques,LectureNotesinControl\n",
      "andInformationSciences,7:234?243,1978.[15]A.Ostfeld,J.G.Uber,E.Sa-\n",
      "lomons,J.W.Berry,W.E.Hart,C.A.Phillips,J.-P.Watson,G.Dorini,P.\n",
      "Jonkergouw,Z.Kapelan,F.diPierro,S.-T.Khu,D.Savic,D.Eliades,M.Poly-\n",
      "carpou,S.R.Ghimire,B.D.Barkdoll,R.Gueli,J.J.Huang,E.A.McBean,W.\n",
      "James,A.Krause,J.Leskovec,S.Isovitsch,J.Xu,C.Guestrin,J.VanBriesen,\n",
      "M.Small,P.Fischbeck,A.Preis,M.Propato,O.Piller,G.B.Trachtman,Z.Y.\n",
      "13\n",
      "\n",
      "Wu,andT.Walski.Thebattleofthewatersensornetworks(BWSN):Adesign\n",
      "challengeforengineersandalgorithms.JournalofWaterResourcesPlanning\n",
      "andManagement,134(6):556?568,2008.[16]R.RazandS.Safra.Asub-\n",
      "constanterror-probabilitylow-degreetest,andasub-constanterror-probability\n",
      "PCPcharacterizationofNP.InProc.ofSTOC,pages475?484,1997.[17]T.\n",
      "Soma,N.Kakimura,K.Inaba,andK.Kawarabayashi.Optimalbudgetalloca-\n",
      "tion:Theoreticalguaranteeandtalgorithm.InProc.ofICML,2014.\n",
      "[18]H.O.Song,R.Girshick,S.Jegelka,J.Mairal,Z.Harchaoui,andT.Darrell.\n",
      "Onlearningtolocalizeobjectswithminimalsupervision.InProc.ofICML,\n",
      "2014.[19]M.Sviridenko,J.Vondr?ak,andJ.Ward.Optimalapproximationfor\n",
      "submodularandsupermodularoptimizationwithboundedcurvature.InProc.\n",
      "ofSODA,pages1134?1148,2015.[20]P.-J.Wan,D.-Z.Du,P.Pardalos,and\n",
      "W.Wu.Greedyapproximationsforminimumsubmodularcoverwithsubmod-\n",
      "ularcost.ComputationalOptimizationandApplications,45(2):463?474,2009.\n",
      "[21]L.A.Wolsey.Ananalysisofthegreedyalgorithmforthesubmodularset\n",
      "coveringproblem.Combinatorica,2(4):385?393,1982.9\n",
      "14\n",
      "\n",
      "PP7275.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP7275.pdf 13\n",
      "WhenCyclicCoordinateDescentOutperforms\n",
      "RandomizedCoordinateDescent\n",
      "Authoredby:\n",
      "AsumanOzdaglar\n",
      "MertGurbuzbalaban\n",
      "PabloA.Parrilo\n",
      "NuriVanli\n",
      "Abstract\n",
      "Thecoordinatedescent(CD)methodisaclassicaloptimizationalgo-\n",
      "rithmthathasseenarevivalofinterestbecauseofitscompetitiveper-\n",
      "formanceinmachinelearningapplications.Anumberofrecentpapers\n",
      "providedconvergencerateestimatesfortheirdeterministic(cyclic)and\n",
      "randomizedvariantsthatintheselectionofupdatecoordinates.\n",
      "Theseestimatessuggestrandomizedcoordinatedescent(RCD)performs\n",
      "betterthancycliccoordinatedescent(CCD),althoughnumericalexperi-\n",
      "mentsdonotprovideclearforthiscomparison.Inthispaper,\n",
      "weprovideexamplesandmoregenerallyproblemclassesforwhichCCD\n",
      "(orCDwithanydeterministicorder)isfasterthanRCDintermsof\n",
      "asymptoticworst-caseconvergence.Furthermore,weprovidelowerand\n",
      "upperboundsontheamountofimprovementontherateofCCDrelative\n",
      "toRCD,whichdependsonthedeterministicorderused.Wealsopro-\n",
      "videacharacterizationofthebestdeterministicorder(thatleadstothe\n",
      "maximumimprovementinconvergencerate)intermsofthecombinatorial\n",
      "propertiesoftheHessianmatrixoftheobjectivefunction.\n",
      "1PaperBody\n",
      "Weconsidersolvingsmoothconvexoptimizationproblemsusingthecoordinate\n",
      "descent(CD)method.TheCDmethodisaniterativealgorithmthatper-\n",
      "forms(approximate)globalminimizationswithrespecttoasinglecoordinate\n",
      "(orseveralcoordinatesinthecaseofblockCD)inasequentialmanner.More\n",
      "sp,ateachiterationk,anindexik2\n",
      "f\n",
      "1,2,...,n\n",
      "g\n",
      "isselectedand\n",
      "thedecisionvectorisupdatedtoapproximatelyminimizetheobjectivefunction\n",
      "intheik-thcoordinate[3,4].TheCDmethodcanbedeterministicorran-\n",
      "domizeddependingonthechoiceoftheupdatecoordinates.Ifthecoordinate\n",
      "indicesikarechoseninacyclicmannerfromtheset\n",
      "f\n",
      "1,2,...,n\n",
      "g\n",
      ",then\n",
      "themethodiscalledthecycliccoordinatedescent(CCD)method.Whenikis\n",
      "1\n",
      "\n",
      "sampleduniformlyfromtheset\n",
      "f\n",
      "1,2,...,n\n",
      "g\n",
      ",theresultingmethodiscalled\n",
      "therandomizedcoordinatedescent(RCD)method.1TheCDmethodhasalong\n",
      "historyinoptimizationanditsconvergencehasbeenstudiedextensivelyin80s\n",
      "and90s(cf.[5,12,13,18]).Ithasseenaresurgenceofrecentinterestbecause\n",
      "ofitsapplicabilityandsuperiorempiricalperformanceinmachinelearningand\n",
      "large-scaledataanalysis[7,8].Severalrecenttialpapersestablishednon-\n",
      "asymptoticconvergencerateestimatesundervariousassumptions.Amongthese\n",
      "areNesterov[15],whichprovidedtheglobalnon-asymptoticconvergence\n",
      "ratesofRCDforconvexandsmoothproblems(seealso[11,21,22]forproblems\n",
      "withnon-smoothterms),andBeckandTetruashvili[1],whichprovidedratees-\n",
      "timatesforblockcoordinategradientdescentmethodthatyieldsrateresultsfor\n",
      "CCDwithexactminimizationforquadraticproblems.Tighterrateestimates\n",
      "(withrespectto[1])forCCDarethenpresentedin[23].Theserateestimates\n",
      "suggestthatCCDcanbeslowerthanRCD(preciselyO(n2)timesslowerfor\n",
      "quadratic\n",
      "1Notethatthereareothercoordinateselectionrulesaswell(suchasthe\n",
      "Gauss-Southwellrule[17]).However,inthispaper,wefocusoncyclicand\n",
      "randomizedrules.\n",
      "31stConferenceonNeuralInformationProcessingSystems(NIPS2017),\n",
      "LongBeach,CA,USA.\n",
      "problems,wherenisthedimensionoftheproblem),whichispuzzlinginview\n",
      "ofthefasterempiricalperformanceofCCDoverRCDforvariousproblems\n",
      "(e.g.,seenumericalexamplesin[1,24]).Thisgapwasinvestigatedin[24],\n",
      "whichprovidedaquadraticproblemthatattainsthisperformancegap.Inthis\n",
      "paper,weinvestigateperformancecomparisonofdeterministicandrandomized\n",
      "coordinatedescentandprovideexamplesandmoregenerallyproblemclassesfor\n",
      "whichCCD(orCDwithanydeterministicorder)isfasterthanRCDintermsof\n",
      "asymptoticworst-caseconvergence.Furthermore,weprovidelowerandupper\n",
      "boundsontheamountofimprovementontherateofdeterministicCDrelative\n",
      "toRCD.Theamountofimprovementdependsonthedeterministicorderused.\n",
      "Wealsoprovideacharacterizationofthebestdeterministicorder(thatleadsto\n",
      "themaximumimprovementinconvergencerate)intermsofthecombinatorial\n",
      "propertiesoftheHessianmatrixoftheobjectivefunction.Inordertoclarifythe\n",
      "ratecomparisonbetweenCCDandRCD,wefocusonquadraticoptimization\n",
      "problems.Inparticular,weconsidertheproblem2min\n",
      "x2Rn\n",
      "1TxAx,2\n",
      "(1)\n",
      "whereAisapositivematrix.Weconsidertwoproblemclasses:i)\n",
      "Aisa2-cyclicmatrix,whoseformalisgivenintion4.4,butan\n",
      "equivalentandinsightfulisthebipartitenessofthegraphinducedby\n",
      "thematrixAD,whereDisthediagonalpartofA;ii)AisanM-matrix,i.e.,the\n",
      "entriesofAarenonpositive.Thesematricesariseinalargenumber\n",
      "ofapplicationssuchasininferenceinattractiveGaussian-Markovrandom\n",
      "[14]andinminimizationofquadraticformsofgraphLaplacians(forwhichA=\n",
      "DW,whereWPdenotestheweightedadjacencymatrixofthegraphandDis\n",
      "2\n",
      "\n",
      "thediagonalmatrixgivenbyDi,i=jWi,j),forexampleinspectralpartitioning\n",
      "[6]andsemisupervisedlearning[2].WebuildontheseminalworkofYoung[27]\n",
      "andVarga[25]ontheanalysisofGauss-Seidelmethodforsolvinglinearsystems\n",
      "ofequations(withmatricessatisfyingcertainproperties)andprovideanovel\n",
      "analysisthatallowsustocomparetheasymptoticworst-caseconvergencerateof\n",
      "CCDandRCDfortheaforementionedclassofproblemsandestablishthefaster\n",
      "performanceofCCDwithanydeterministicorder.Outline:Inthenextsection,\n",
      "weformallyintroducetheCCDandRCDmethods.InSection3,wepresentthe\n",
      "notionofasymptoticconvergenceratetocomparetheCCDandRCDmethods\n",
      "andprovideamotivatingexampleforwhichCCDconvergesfasterthanRCD.In\n",
      "Section4,wepresentclassesofproblemsforwhichtheasymptoticconvergence\n",
      "rateofCCDisfasterthanthatofRCD.Weprovidenumericalexperimentsin\n",
      "Section5andconcludingremarksinSection6.Notation:ForamatrixH,we\n",
      "letHidenoteitsithrowandHi,jdenoteitsentryattheithrowandjthcolumn.\n",
      "Foravectorx,weletxidenoteitsithentry.Throughoutthepaper,wereserve\n",
      "superscriptsforiterationcountersofiterativealgorithmsandusex?todenote\n",
      "theoptimalsolutionofproblem(1).Foravectorx,kxkdenotesitsEuclidean\n",
      "normandforamatrixH,||H||denotesitsoperatornorm.Formatrices,\n",
      "and?areentry-wiseoperators.ThematricesIand0denotetheidentitymatrix\n",
      "andthezeromatrixrespectivelyandtheirdimensionscanbeunderstoodfrom\n",
      "thecontext.\n",
      "2\n",
      "CoordinateDescentMethod\n",
      "Startingfromaninitialpointx02Rn,thecoordinatedescent(CD)method,\n",
      "ateachiterationk,picksacoordinateofx,sayik,andupdatesthedecision\n",
      "vectorbyperformingexactminimizationalongtheikthcoordinate,whichfor\n",
      "problem(1)yieldsxk+1=xk\n",
      "1Aik,ik\n",
      "Aikxkeik,\n",
      "k=0,1,2,...,\n",
      "(2)\n",
      "whereeikistheunitvector,whoseikthentryis1andtherestofitsentries\n",
      "are0.Notethatthisisaspecialcaseofthecoordinategradientprojection\n",
      "method(see[1]),whichateachiterationupdatesasinglecoordinate,saycoor-\n",
      "dinateik,alongthegradientcomponentdirection(withtheparticularstepsize\n",
      "ofAi1,i).Thecoordinateindexikcanbeselectedaccordingtoadeterministic\n",
      "orrandomizedkkrule:2\n",
      "Foreaseofpresentation,weconsiderminimizationof12xTAx,yetour\n",
      "resultsdirectlyextendforproblemsofthetype12xTAxbTxforanyb6=0.\n",
      "2\n",
      "?Whenikischosenusingthecyclicrulewithorder1,...,n(i.e.,ik=\n",
      "k(modn)+1),theresultingalgorithmiscalledthecycliccoordinatedescent\n",
      "(CCD)method.InordertowritetheCCDiterationsinamatrixform,we\n",
      "introducethefollowingdecompositionA=D\n",
      "L\n",
      "LT,\n",
      "3\n",
      "\n",
      "whereDisthediagonalpartofAandListhestrictlylowertriangularpart\n",
      "ofA.Then,overeachepoch`0(whereanepochistobeconsecutiven\n",
      "iterations),theCCDiterationsgivenin(2)canbewrittenas(`+1)n\n",
      "xCCD\n",
      "=Cx`nCCD,\n",
      "where\n",
      "C=(D\n",
      "L)\n",
      "1\n",
      "LT.\n",
      "(3)\n",
      "Notethattheepochin(3)isequivalenttooneiterationoftheGauss-Seidel\n",
      "(GS)methodappliedtotheoptimalityconditionof(1),i.e.,applied\n",
      "tothelinearsystemAx=0[26].?Whenikischosenatrandomamong\n",
      "f\n",
      "1,\n",
      "...,n\n",
      "g\n",
      "withprobabilities\n",
      "f\n",
      "p1,...,pn\n",
      "g\n",
      "independentlyateachiteration\n",
      "k,theresultingalgorithmiscalledtherandomizedcoordinatedescent(RCD)\n",
      "method3.GiventhekthiterategeneratedbytheRCDalgorithm,i.e.,xkRCD\n",
      ",wehave??kEkxk+1SD1AxkRCD,(4)RCD|xRCD=I\n",
      "whereS=diag(p1,...,pn)containsthecoordinatesamplingprobabilities\n",
      "andtheconditionalexpectationEkistakenovertherandomvariableikgiven\n",
      "xkRCD.Usingthenestedpropertyoftheexpectations,theRCDiterationsin\n",
      "expectationovereachepoch`0satisfy(`+1)n\n",
      "ExRCD\n",
      "3\n",
      "=REx`nRCD\n",
      "withR:=I\n",
      "SD\n",
      "1\n",
      "A\n",
      "n\n",
      ".\n",
      "(5)\n",
      "ComparisonoftheConvergenceRatesofCCDandRCDMethods\n",
      "Inthefollowingsubsection,weourbasisofcomparisonforratesof\n",
      "CCDandRCDmethods.Tomeasuretheperformanceofthesemethods,we\n",
      "usethenotionoftheaverageworst-caseasymptoticratethathasbeenstudied\n",
      "extensivelyintheliteratureforcharacterizingtherateofiterativealgorithms\n",
      "[25].InSection3.2,weconstructanexample,forwhichtherateofCCDismore\n",
      "thantwicetherateofRCD.Thisraisesthequestionwhetherthebestknown\n",
      "convergenceratesofCCDintheliteraturearetightorwhetherthereexista\n",
      "classofproblemsforwhichCCDprovablyattainsbetterconvergenceratesthan\n",
      "thebestknownratesforRCD,aquestionwhichwewillanswerinSection4.\n",
      "3.1\n",
      "AsymptoticRateofConvergeforIterativeAlgorithms\n",
      "Consideraniterativealgorithmwithupdaterulex(`+1)n=Cx`n(e.g.,the\n",
      "CCDalgorithm).Thereductioninthedistancetotheoptimalsolutionofthe\n",
      "4\n",
      "\n",
      "iteratesgeneratedbythisalgorithmafter`epochsisgivenbyx`nx?C`(x0x?\n",
      ")=.(6)0?||xx||||x0x?||\n",
      "Notethattherighthandsideof(6)canbeaslargeasC`,henceinthe\n",
      "worst-case,theaveragedecayofdistanceateachepochofthisalgorithmisC`\n",
      "1/`\n",
      "1/`\n",
      ".Overanyepochs`\n",
      "1,we\n",
      "1/`\n",
      "haveC?(C)andC!?(C)as`!1byGelfand?sformula.Thus,wethe\n",
      "asymptoticworst-caseconvergencerateofaniterativealgorithm(withiteration\n",
      "matrixC)asfollows!x`nx?1Rate(CCD):=limsuplog=log(?(C)).(7)`!1\n",
      "x02Rn`||x0x?||`\n",
      "`\n",
      "Weemphasizethatthisnotionhasbeenusedextensivelyforstudyingthe\n",
      "performanceofiterativemethodssuchasGSandJacobimethods[5,18,25,27].\n",
      "Notethataccordingtoouronin(7),largerratemeansfasteralgorithm\n",
      "andwewillusethesetermsinterchangablyinthroughoutthepaper.3\n",
      "sd\n",
      "3\n",
      "Analogously,forarandomizedalgorithmwithexpectedupdateruleEx(`+1)n\n",
      "=REx`n(e.g.,theRCDalgorithm),weconsidertheasymptoticconvergence\n",
      "oftheexpectediterateerrorE(x`n)x?andtheasymptoticworst-case\n",
      "convergencerateas!E(x`n)x?1Rate(RCD):=limsuplog=log(?(R)),(8)\n",
      "`!1x02Rn`||x0x?||Notethatin(8),weusethedistanceoftheexpected\n",
      "iteratesEx`nx?asourconvergencecriterion.Onecanalsousetheexpected\n",
      "distance(orthesquareddistance)oftheiteratesEx`nx?astheconvergence\n",
      "criterion,whichisastrongerconvergencecriterionthantheonein(8).This\n",
      "followssinceEx`nx?Ex`nx?byJensen?sinequalityandanyconvergencerate\n",
      "on`n?ExximmediatelyimpliesatleastthesameconvergencerateonEx`n\n",
      "x?aswell.Sinceweconsiderthereciprocalcase,i.e.,obtainaconvergencerate\n",
      "onEx`nx?andshowthatitisslowerthanthatofCCD,ourresultsnaturally\n",
      "implythattheconvergencerateonEx`nx?isalsoslowerthanthatofCCD.\n",
      "3.2\n",
      "AMotivatingExample\n",
      "Inthissection,weprovideanexampleforwhichthe(asymptoticworst-case\n",
      "convergence)rateofCCDisbetterthantheoneofRCDandbuildingonthis\n",
      "example,inSection4,weconstructaclassofproblemsforwhichCCDattains\n",
      "abetterratethanRCD.Forsomepositiveintegern1,considerthe2n?2n\n",
      "symmetricmatrix?100n?nA=ILLT,whereL=2n?n,(9)n1n?n0n?n\n",
      "and1n?nisthen?nmatrixwithallentriesequalto1and0n?nisthen?\n",
      "nzeromatrix.NotingthatAhasaspecialstructure(Aisequaltothesumof\n",
      "theidentitymatrixandtherank-twomatrixLLT),itiseasytocheckthat1\n",
      "1/nand1+1/nareeigenvaluesofAwiththecorrespondingTT11?n].The\n",
      "remaining2n2eigenvaluesofAareeigenvectors[11?n11?n]and[11?nequal\n",
      "to1.TheiterationmatrixoftheCCDalgorithmwhenappliedtotheproblem\n",
      "5\n",
      "\n",
      "in(1)withthematrix(9)canbefoundas?101C=n?nn12n?n.0n?nn3\n",
      "1n?n\n",
      "TheeigenvaluesofCareallzeroexcepttheeigenvalueof1/n2withthecorre-\n",
      "spondingeigenvector[n11?n,11?n]T.Therefore,?(C)=1/n2andRate(CCD)\n",
      "=log(?(C))=2logn.Ontheotherhand,thespectralradiusoftheexpected\n",
      "iterationmatrixofRCDcanbefoundas??n1min(A)?(R)=11,min(A)\n",
      "=nn\n",
      "whichyieldsRate(RCD)=\n",
      "log(?(R))?logn.Thus,weconcludeRate(CCD)Rate(RCD)\n",
      "2,\n",
      "foralln\n",
      "1.\n",
      "Thatis,CCDisatleasttwiceasfastasRCDintermsofthetheasymptotic\n",
      "rate.Thismotivatesustoinvestigateifthereexistsamoregeneralclassof\n",
      "problemsforwhichtheasymptoticworst-caserateofCCDislargerthanthat\n",
      "ofRCD.Theanswertothisquestionturnsouttobepositiveaswedescribein\n",
      "thefollowingsection.\n",
      "4\n",
      "WhenDeterministicOrdersOutperformRandomizedSampling\n",
      "Inthissection,wepresentspecialclassesofproblems(oftheform(1))for\n",
      "whichtheasymptoticalworst-caserateofCCDislargerthanthatofRCD.\n",
      "Webeginourdiscussionbyhighlightingthemainassumptionwewillusein\n",
      "thissection.Assumption4.1.Aisasymmetricpositivematrixwhose\n",
      "smallesteigenvalueis?andthediagonalentriesofAare1.4\n",
      "IfAisapositivematrix,thenourresultswillstillhold,where\n",
      "?isthesmallestnon-zeroeigenvalueofAandx?istheprojectionofx0\n",
      "ontothenullspaceofA.Moreover,givenanypositivematrixAwith\n",
      "diagonalsD6=I,thediagonalentriesofthepreconditionedmatrixD1/2AD\n",
      "1/2are1.Therefore,Assumption4.1ismild.Therelationshipbetweenthe\n",
      "smallesteigenvalueoftheoriginalmatrixandthepreconditionedmatrixare\n",
      "asfollows.Let>0andLmaxdenotethesmallesteigenvalueandthelargest\n",
      "diagonalentryoftheoriginalmatrix,respectively.Then,thesmallesteigenvalue\n",
      "ofthepreconditionedmatrix?/Lmax.Remark4.2.FortheRCD\n",
      "algorithm,thecoordinateindexik2\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "(atiterationk)canbechosen\n",
      "usingtprobabilitydistributions\n",
      "f\n",
      "p1,...,pn\n",
      "g\n",
      ".Twocommonchoices\n",
      "ofdistributionsAarepi=n1,foralli2\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "andpi=PNi,iA[15].\n",
      "SincebyAssumption4.1,thediagonalJ=1\n",
      "j,j\n",
      "entriesofAare1,bothofthesedistributionsreducestopi=n1,foralli2\n",
      "f\n",
      "1,\n",
      "...,n\n",
      "g\n",
      ".Therefore,intherestofthepaper,weconsidertheRCDalgorithm\n",
      "withuniformandindependentcoordinateselectionateachiteration.Inthe\n",
      "followinglemma,wecharacterizethespectralradiusoftheRCDmethod.This\n",
      "worst-caseratehasbeenpresentedinmanyworksintheliteratureforstrongly\n",
      "convexoptimizationproblems[15,26].TheproofisdeferredtoAppendix.\n",
      "Lemma4.3.SupposeAssumption4.1holds.Then,thespectralradiusofthe\n",
      "6\n",
      "\n",
      "expectediterationmatrixRoftheRCDalgorithmin(5))isgivenby\n",
      "???n?(R)=1.(10)n4.1\n",
      "ConvergenceRateofCCDfor2-CyclicMatrices\n",
      "Inthissection,weintroducetheclassof2-cyclicmatricesandshowthatthe\n",
      "asymptoticworst-caserateofCCDismorethantwotimesfasterthanthatof\n",
      "RCD.4.4(2-CyclicMatrix).AmatrixHis2-cyclicifthereexistsa\n",
      "permutationmatrixPsuchthat?0B1TPHP=D+,(11)B20wherethe\n",
      "diagonalnullsubmatricesaresquareandDisadiagonalmatrix.Thisdenition\n",
      "canbeinterpretedasfollows.LetHbea2-cyclicmatrix,i.e.,H(11).\n",
      "Then,thegraphinducedbythematrixHDisbipartite.Thein(11)\n",
      "isintroducedin[27],whereithadanalternativename:PropertyA.A\n",
      "generalizationofthispropertyislaterintroducedbyVargatotheclassofp-\n",
      "cyclicmatrices[25]wherep2canbearbitrary.Wenextintroducethefollowing\n",
      "thatwillbeusefulinTheorem4.12andexplicitlyidentifytheclassof\n",
      "matricesthatsatisfythisinLemma4.6.4.5(Consistently\n",
      "OrderedMatrix).ForamatrixH,letH=HDHLHUbeitsdecomposition\n",
      "suchthatHDisadiagonalmatrix,HL(andHU)isastrictlylower(and\n",
      "upper)triangularmatrix.Iftheeigenvaluesofthematrix?HL+?HUHDare\n",
      "independentof?forany2Rand?6=0,thenHissaidtobeconsistently\n",
      "ordered.Lemma4.6.[27,Theorem4.5]AmatrixHis2-cyclicifandonlyifthere\n",
      "existsapermutationmatrixPsuchthatPHPTisconsistentlyordered.Inthe\n",
      "nexttheorem,wecharacterizetheconvergencerateofCCDalgorithmapplied\n",
      "toa2-cyclicmatrix.Since?(R)1?byLemma4.3,thefollowingtheorem\n",
      "indicatesthatthespectralradiusoftheCCDiterationmatrixissmallerthan\n",
      "?2(R).Theorem4.7.SupposeAssumption4.1holdsandAisaconsistently\n",
      "ordered2-cyclicmatrix.Then,thespectralradiusoftheCCDalgorithmis\n",
      "givenby?(C)=(1\n",
      "2\n",
      "?).\n",
      "Remark4.8.Notethatourmotivatingexamplein(9)isanexampleofa\n",
      "consistentlyordered2-cyclicmatrix,forwhichTheorem4.7isapplicable.In\n",
      "particular,fortheexamplein(9),wecanapplyTheorem4.7with?=11/n\n",
      "leadingto?(C)=1/n2,whichexactlycoincideswithourpreviouscomputations\n",
      "of?(C)inSection3.2.WealsogiveanexampleinAppendixF,forwhichCCD\n",
      "istwicefasterthanRCDforanyarbitraryinitializationwithprobabilityone.5\n",
      "Thefollowingcorollarystatesthattheasymptoticworst-caserateofCCD\n",
      "ismorethantwicelargerthanthatofRCDforquadraticproblemswhoseHes-\n",
      "sianisa2-cyclicmatrix.ThiscorollarydirectlyfollowsbyTheorem4.7and\n",
      "(7)-(8).Corollary4.9.SupposeAssumption4.1holdsandAisa\n",
      "consistentlyordered2-cyclicmatrix.Then,theasymptoticworst-caseratesof\n",
      "CCDandRCDsatisfyRate(CCD)=2?n,Rate(RCD)\n",
      "where?n:=\n",
      "log(1?).nlog1n?\n",
      "(12)\n",
      "Inthefollowingremark,wehighlightseveralpropertiesoftheconstant?n\n",
      ".Remark4.10.?nisamonotonicallyincreasingfunctionofnovertheinterval\n",
      "7\n",
      "\n",
      "[1,1),where?1=1?)andlimn!1?n=log(1>1.Furthermore,lim?!0+?n\n",
      "=1.?WeemphasizethattheCCDmethodappliedto1isequivalenttothe\n",
      "Gauss-Seidel(GS)algorithmappliedtothelinearsystemAx=0andwhenA\n",
      "isa2-cyclicmatrix,theGSalgorithmistwiceasfastastheJacobialgorithm\n",
      "[25,27].Hence,whenAisa2-cyclicmatrixand?istlysmall,theRCD\n",
      "methodisapproximatelyasfastastheJacobialgorithm.4.2\n",
      "ConvergenceRateofCCDforIrreducibleM-Matrices\n",
      "Inthissection,wetheclassofM-matricesandthenpresentthe\n",
      "convergencerateoftheCCDalgorithmappliedtoquadraticproblemswhose\n",
      "HessianisanM-matrix.4.11(M-matrix).ArealmatrixAwithAi,j\n",
      "?0foralli6=jisanM-matrixifAhasthedecompositionA=sIBsuchthatB0\n",
      "ands?(B).WeemphasizethatM-matricesariseinavarietyofapplicationssuch\n",
      "asinbeliefpropagationoverGaussiangraphicalmodels[14]andindistributed\n",
      "controlofpositivesystems[20].Furthermore,graphLaplaciansareM-matrices,\n",
      "thereforesolvinglinearsystemswithM-matrices(orequivalentlysolving(1)for\n",
      "anM-matrixA)ariseinavarietyofapplicationsforanalyzingrandomwalks\n",
      "overgraphsaswellasdistributedoptimizationandconsensusproblemsover\n",
      "graphs(cf.[10]forasurvey).Forquadraticproblems,theHessianisanM-\n",
      "matrixifandonlyifthegradientdescentmappingisanisotoneoperator[5,22]\n",
      "andinGaussiangraphicalmodels,M-matricesareoftenreferredasattractive\n",
      "models[14].Inthefollowingtheorem,weprovidelowerandupperbounds\n",
      "onthespectralradiusoftheiterationmatrixofCCDforquadraticproblems,\n",
      "whoseHessianmatrixisanirreducibleM-matrix.Inparticular,weshowthat\n",
      "thespectralradiusoftheiterationmatrixofCCDisstrictlysmallerthanthat\n",
      "ofRCDforirreducibleM-matrices.Theorem4.12.SupposeAssumption4.1\n",
      "holds,AisanirreducibleM-matrixandn2.Then,theiterationmatrixofthe\n",
      "CCDalgorithmC=(IL)1LTthefollowinginequality(1\n",
      "?)2??(C)?\n",
      "1?,1+?\n",
      "(13)\n",
      "wheretheinequalityontheleftholdswithequalityifandonlyifAisa\n",
      "consistentlyorderedmatrix.AnimmediateconsequenceofTheorem4.12is\n",
      "thatforquadraticproblemswhoseHessianisanirreducibleM-matrix,thebest\n",
      "cyclicorderthatshouldbeusedinCCDcanbecharacterizedasfollows.Remark\n",
      "4.13.ThestandardCCDmethodfollowsthestandardcyclicorder(1,2,...\n",
      ",n)asdescribedinSection2.However,wecanconstructaCCDmethodthat\n",
      "followsanalternativedeterministicorderbyconsideringapermutation?of\n",
      "f\n",
      "1,\n",
      "2,...,n\n",
      "g\n",
      ",andchoosingthecoordinatesaccordingtotheorder(?(1),?(2),..\n",
      ".,?(n))instead.Foranygivenorder?,(1)canbereformulatedasfollowsmin\n",
      "x?2Rn\n",
      "1TxA?x?,2?\n",
      "where\n",
      "A?:=P?AP?T\n",
      "andx?=P?x,\n",
      "whereP?isthecorrespondingpermutationmatrixof?.Supposingthat\n",
      "Assumption4.1holds,thecorrespondingCCDiterationsforthisproblemcan\n",
      "8\n",
      "\n",
      "bewrittenasfollowsx(`+1)n=C?x`n??,\n",
      "whereC?=(I6\n",
      "L?)\n",
      "1\n",
      "LT?\n",
      "andL?=P?LP?.\n",
      "IfAisanirreducibleM-matrixandAssumptions4.1,thensodoes\n",
      "A?.Consequently,Theorem4.12yieldsthesameupperandlowerbounds(in\n",
      "(13))on?(C?)aswell,i.e.,thespectralradiusoftheiterationmatrixofCCD\n",
      "withanycyclicorder?(1\n",
      "?)2??(C?)?\n",
      "1?,1+?\n",
      "(14)\n",
      "wheretheinequalityontheleftholdswithequalityifandonlyifA?isa\n",
      "consistentlyorderedmatrix.Therefore,ifaconsistentorder??exists,thenthe\n",
      "CCDmethodwiththeconsistentorder??attainsthesmallestspectralradius\n",
      "(orequivalently,thefastestasymptoticworst-caseconvergencerate)amongthe\n",
      "CCDmethodswithanycyclicorder.Remark4.14.TheirreducibilityofA\n",
      "isessentialtoderivethelowerboundin(13)ofTheorem4.12.However,the\n",
      "upperboundin(13)holdsevenwhenAisareduciblematrix.Wenextcompare\n",
      "thespectralradiiboundsforCCD(giveninTheorem4.12)andRCD(givenin\n",
      "Lemma4.3).Since?>0,theright-handsideof(13)canberelaxedto(1?)2\n",
      "??(C)<1?.Adirectconsequenceofthisinequalityisthefollowingcorollary,\n",
      "whichstatesthattheasymptoticworst-caserateofCCDisstrictlybetterthan\n",
      "thatofRCDatleastbyafactorthatisstrictlygreaterthan1.Corollary4.15.\n",
      "SupposeAssumption4.1holds,AisanirreducibleM-matrixandn2.Then,\n",
      "theasymptoticworst-caseratesofCCDandRCDsatisfy1<?n<\n",
      "Rate(CCD)?2?n,Rate(RCD)\n",
      "where\n",
      "?n:=\n",
      "log(1?),nlog1n?\n",
      "(15)\n",
      "andtheinequalityontherightholdswithequalityifandonlyifAisa\n",
      "consistentlyorderedmatrix.Inthefollowingcorollary,wehighlightthatasthe\n",
      "smallesteigenvalueofAgoestozero,theasymptoticworst-caserateoftheCCD\n",
      "algorithmbecomestwicetheasymptoticworst-caserateoftheRCDalgorithm.\n",
      "Corollary4.16.SupposeAssumption4.1holds,AisanirreducibleM-matrix\n",
      "andn2.Then,wehaveRate(CCD)lim=2.?!0+Rate(RCD)\n",
      "5\n",
      "NumericalExperiments\n",
      "Inthissection,wecomparetheperformanceofCCDandRCDthrough\n",
      "numericalexamples.First,weconsiderthequadraticoptimizationproblemin\n",
      "(1),whereAisann?nmatrixasfollows?100TA=ILL,\n",
      "whereL=(16)nn10,?n22and1n2?n2isthen2?n2matrixwith\n",
      "allentriesequalto1.Here,itcanbeeasilycheckedthatAisaconsistently\n",
      "9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordered,2-cyclicmatrix.ByTheorem4.7andCorolloary4.9,theasymptotic\n",
      "worst-caseconvergencerateofCCDonthisexampleis2?n=2\n",
      "log(1?)log(0.5)?2.77?=1nlog1n50log1200\n",
      "(17)\n",
      "timesfasterthanthatofRCD.ThisisillustratedinFigure1(left),wherethe\n",
      "distancetotheoptimalsolutionisplottedinalogarithmicscaleoverepochs.\n",
      "Notethatevenifourresultsourasymptotic,weseethesamein\n",
      "performancesontheearlyepochs(forsmall`).Ontheotherhand,whenthe\n",
      "matrixAisnotconsistentlyordered,accordingtoTheorem4.12,CCDisstill\n",
      "fasterbuttheintheconvergenceratesdecreaseswithrespecttothe\n",
      "consistentorderingcase.Toillustratethis,weneedtogenerateaninconsistent\n",
      "orderingofthematrixA.Forthisgoal,wegenerateapermutationmatrixP\n",
      "andreplaceAwithAP:=PAPTintheoptimizationproblem(1)(Thisis\n",
      "equivalenttosolvingthesystemAPx=0)sothatAPisnotconsistentlyordered\n",
      "(WegeneratePrandomlyandcomputeAP).Figure1(right)showsthatfor\n",
      "thisinconsistentorderingCCDisstillfastercomparedtoRCD,butnotasfast\n",
      "(theslopeofthedecayoferrorlineinbluemarkerislesssteep)predictedby\n",
      "ourtheory.7\n",
      "ConsistentOrdering,Worst-CaseInitialization\n",
      "InconsistentOrdering,Worst-CaseInitialization\n",
      "?4\n",
      "?6\n",
      "x?||\n",
      "?2\n",
      "?4\n",
      "?6\n",
      "?8\n",
      "log||x`\n",
      "?2\n",
      "x?||\n",
      "0\n",
      "log||x`\n",
      "0\n",
      "?8\n",
      "?10\n",
      "?10\n",
      "CCDRCDExpectedRCD\n",
      "?12\n",
      "?14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CCDRCDExpectedRCD\n",
      "?12\n",
      "567NumberofEpochs`\n",
      "10\n",
      "\n",
      "8\n",
      "9\n",
      "?14\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "567NumberofEpochs`\n",
      "8\n",
      "9\n",
      "10\n",
      "Figure1:DistancetotheoptimalsolutionoftheiteratesofCCDandRCD\n",
      "forthecyclicmatrixin(16)(leftandarandomlypermutedversionof\n",
      "thesamematrix(rightwherethey-axisisonalogarithmicscale.The\n",
      "left(right)correspondstotheconsistent(inconsistent)orderingforthe\n",
      "samequadraticoptimizationproblem.M-Matrix,Worst-CaseInitialization\n",
      "M-Matrix,RandomInitialization\n",
      "?4\n",
      "?4?\n",
      "?2\n",
      "||x`x?||||x0x?||\n",
      "?2\n",
      "?\n",
      "0\n",
      "||x`x?||||x0x?||\n",
      "0\n",
      "?\n",
      "?log\n",
      "?6\n",
      "log\n",
      "?6\n",
      "?8\n",
      "?8\n",
      "?10\n",
      "?12\n",
      "?10\n",
      "CCDRCDExpectedRCD0\n",
      "20\n",
      "4060NumberofEpochs`\n",
      "80\n",
      "?12\n",
      "100\n",
      "CCDRCDExpectedRCD0\n",
      "20\n",
      "4060NumberofEpochs`\n",
      "11\n",
      "\n",
      "80\n",
      "100\n",
      "Figure2:DistancetotheoptimalsolutionoftheiteratesofCCDandRCD\n",
      "fortheM-matrixmatrixin(18)fortheworst-caseinitialization(leftand\n",
      "arandominitialization(rightWenextconsiderthecase,whereAisan\n",
      "irreduciblepositiveM-matrix.Inparticular,weconsiderthematrixA\n",
      "=(1+)I1n?n,(18)1where1n?nisthen?nmatrixwithallentriesequal\n",
      "to1asbeforeand=n+5.Wesetn=100andplottheperformanceofCCD\n",
      "andRCDmethodsforthequadraticproblembythismatrix.InFigure\n",
      "2,wecomparetheconvergencerateofCCDandRCDforaninitialpointthat\n",
      "correspondstoaworst-case(leftandforarandomchoiceofaninitial\n",
      "point(rightWeconcludethattheasymptoticrateofCCDisfasterthan\n",
      "thatofRCDdemonstratingourresultsinTheorem4.12andCorolloary4.15.\n",
      "6\n",
      "Conclusion\n",
      "Inthispaper,wecomparetheCCDandRCDmethodsforquadraticprob-\n",
      "lems,whoseHessianisa2-cyclicmatrixoranM-matrix.Weshowbyanovel\n",
      "analysisthatfortheseclassesofquadraticproblems,CCDisalwaysfasterthan\n",
      "RCDintermsoftheasymptoticworst-caserate.Wealsogiveacharacteriza-\n",
      "tionofthebestcyclicordertouseintheCCDalgorithmfortheseclassesof\n",
      "problemsandshowthatwiththebestcyclicorder,CCDenjoysmorethana\n",
      "twicefasterasymptoticworst-caseratewithrespecttoRCD.Wealsoprovide\n",
      "numericalexperimentsthatshowthetightnessofourresults.\n",
      "2References\n",
      "[1]A.BeckandL.Tetruashvili.Ontheconvergenceofblockcoordinatede-\n",
      "scenttypemethods.SIAMJournalonOptimization,23(4):2037?2060,2013.\n",
      "[2]M.Belkin,P.Niyogi,andV.Sindhwani.Manifoldregularization:Ageo-\n",
      "metricframeworkforlearningfromlabeledandunlabeledexamples.Journalof\n",
      "MachineLearningResearch,7:2399?2434,2006.\n",
      "8\n",
      "[3]D.P.Bertsekas.Nonlinearprogramming.AthenaScien1999.[4]D.\n",
      "P.Bertsekas.ConvexOptimizationAlgorithms.AthenaScien2015.[5]D.\n",
      "P.BertsekasandJ.N.Tsitsiklis.ParallelandDistributedComputation:Nu-\n",
      "mericalMethods.PrenticeHall,Inc.,1989.[6]F.R.K.Chung.SpectralGraph\n",
      "Theory.AmericanMathematicalSociety,1997.[7]J.Friedman,T.Hastie,\n",
      "H.andR.Tibshirani.Pathwisecoordinateoptimization.TheAnnals\n",
      "ofAppliedStatistics,1(2):302?332,2007.[8]J.Friedman,T.Hastie,andR.\n",
      "Tibshirani.Regularizationpathsforgeneralizedlinearmodelsviacoordinate\n",
      "descent.JournalofStatisticalSoftware,33(1):1?22,2010.[9]J.F.C.Kingman.\n",
      "Aconvexitypropertyofpositivematrices.TheQuarterlyJournalofMathemat-\n",
      "ics,12(1):283?284,1961.[10]S.J.KirklandandM.Neumann.Groupinverses\n",
      "ofM-matricesandtheirapplications.CRCPress,2012.[11]Z.LuandL.Xiao.\n",
      "Onthecomplexityanalysisofrandomizedblock-coordinatedescentmethods.\n",
      "12\n",
      "\n",
      "MathematicalProgramming,152(1):615?642,2015.[12]Z.-Q.LuoandP.Tseng.\n",
      "Ontheconvergenceofthecoordinatedescentmethodforconvextiable\n",
      "minimization.JournalofOptimizationTheoryandApplications,72(1):7?35,\n",
      "1992.[13]Z.-Q.LuoandP.Tseng.Errorboundsandconvergenceanalysisof\n",
      "feasibledescentmethods:ageneralapproach.AnnalsofOperationsResearch,\n",
      "46(1):157?178,1993.[14]D.M.Malioutov,J.K.Johnson,andA.S.Willsky.\n",
      "Walk-sumsandbeliefpropagationingaussiangraphicalmodels.Journalof\n",
      "MachineLearningResearch,7:2031?2064,2006.[15]Y.Nesterov.of\n",
      "coordinatedescentmethodsonhuge-scaleoptimizationproblems.SIAMJour-\n",
      "nalonOptimization,22(2):341?362,2012.[16]RogerD.Nussbaum.Convexity\n",
      "andlogconvexityforthespectralradius.LinearAlgebraanditsApplications,\n",
      "73(SupplementC):59?122,1986.[17]J.Nutini,M.Schmidt,I.H.Laradji,\n",
      "M.Friedlander,andH.Koepke.Coordinatedescentconvergesfasterwiththe\n",
      "gauss-southwellrulethanrandomselection.InProceedingsofthe32ndInter-\n",
      "nationalConferenceonInternationalConferenceonMachineLearning,pages\n",
      "1632?1641,2015.[18]J.OrtegaandW.Rheinboldt.IterativeSolutionofNon-\n",
      "linearEquationsinSeveralVariables.SocietyforIndustrialandAppliedMath-\n",
      "ematics,2000.[19]R.J.Plemmons.M-matrixcharacterizations.I?nonsingular\n",
      "m-matrices.LinearAlgebraanditsApplications,18(2):175?188,1977.[20]\n",
      "A.Rantzer.Distributedcontrolofpositivesystems.ArXiv:1203.0047,2014.\n",
      "[21]P.Richt?rikandM.Tak??c.Parallelcoordinatedescentmethodsforbig\n",
      "dataoptimization.MathematicalProgramming,156(1):433?484,2016.[22]A.\n",
      "SahaandA.Tewari.Onthenonasymptoticconvergenceofcycliccoordinate\n",
      "descentmethods.SIAMJournalonOptimization,23(1):576?601,2013.[23]\n",
      "R.SunandM.Hong.Improvediterationcomplexityboundsofcyclicblock\n",
      "coordinatedescentforconvexproblems.InAdvancesinNeuralInformation\n",
      "ProcessingSystems28,pages1306?1314.2015.[24]R.SunandY.Ye.Worst-\n",
      "caseComplexityofCyclicCoordinateDescent:O(n2)GapwithRandomized\n",
      "Version.ArXiv:1604.07130,2016.[25]R.S.Varga.Matrixiterativeanalysis.\n",
      "SpringerScience&BusinessMedia,2009.[26]S.J.Wright.Coordinatedescent\n",
      "algorithms.MathematicalProgramming,151(1):3?34,2015.[27]D.M.Young.\n",
      "Iterativesolutionoflargelinearsystems.AcademicPress,1971.\n",
      "9\n",
      "13\n",
      "\n",
      "PP5107.pdf\n",
      "PP5107.pdf 15\n",
      "SequentialTransferinMulti-armedBanditwith\n",
      "FiniteSetofModels\n",
      "Authoredby:\n",
      "AlessandroLazaric\n",
      "MohammadGheshlaghiazar\n",
      "EmmaBrunskill\n",
      "Abstract\n",
      "Learningfrompriortasksandtransferringthatexperiencetoimprove\n",
      "futureperformanceiscriticalforbuildinglifelonglearningagents.Al-\n",
      "thoughresultsinsupervisedandreinforcementlearningshowthattransfer\n",
      "maytlyimprovethelearningperformance,mostoftheliterature\n",
      "ontransferisfocusedonbatchlearningtasks.Inthispaperwestudythe\n",
      "problemofsequentialtransferinonlinelearning,notablyinthemulti-arm\n",
      "banditframework,wheretheobjectiveistominimizethecumulativere-\n",
      "gretoverasequenceoftasksbyincrementallytransferringknowledgefrom\n",
      "priortasks.Weintroduceanovelbanditalgorithmbasedonamethod-\n",
      "of-momentsapproachfortheestimationofthepossibletasksandderive\n",
      "regretboundsforit.\n",
      "1PaperBody\n",
      "Learningfrompriortasksandtransferringthatexperiencetoimprovefuture\n",
      "performanceisakeyaspectofintelligence,andiscriticalforbuildinglifelong\n",
      "learningagents.Recently,multi-taskandtransferlearningreceivedmuchat-\n",
      "tentioninthesupervisedandreinforcementlearning(RL)settingwithboth\n",
      "empiricalandtheoreticalencouragingresults(seerecentsurveysbyPanand\n",
      "Yang,2010;Lazaric,2011).Mostoftheseworksfocusedonscenarioswherethe\n",
      "tasksarebatchlearningproblems,inwhichatrainingsetisdirectlyprovided\n",
      "tothelearner.Ontheotherhand,theonlinelearningsetting(Cesa-Bianchi\n",
      "andLugosi,2006),wherethelearnerispresentedwithsamplesinasequential\n",
      "fashion,hasbeenrarelyconsidered(seeMannandChoe(2012);Taylor(2009)\n",
      "forexamplesinRLandSec.EofAzaretal.(2013)foradiscussiononre-\n",
      "latedsettings).Themulti?armedbandit(MAB)(Robbins,1952)isasimple\n",
      "yetpowerfulframeworkformalizingtheonlinelearningwithpartialfeedback\n",
      "problem,whichencompassesalargenumberofapplications,suchasclinical\n",
      "trials,webadvertisementsandadaptiverouting.Inthispaperwetakeastep\n",
      "1\n",
      "\n",
      "towardsunderstandingandprovidingformalboundsontransferinstochastic\n",
      "MABs.Wefocusonasequentialtransferscenariowherean(online)learner\n",
      "isactinginaseriesoftasksdrawnfromastationarydistributionovera\n",
      "setofMABs.Thelearningproblem,withineachtask,canbeseenasastan-\n",
      "dardMABproblemwithanumberofsteps.Priortolearning,themodel\n",
      "parametersofeachbanditproblemarenotknowntothelearner,nordoesit\n",
      "knowthedistributionprobabilityoverthebanditproblems.Also,weassume\n",
      "thatthelearnerisnotprovidedwiththeidentityofthetasksthroughoutthe\n",
      "learning.Toacttlyinthissetting,itiscrucialtoamechanism\n",
      "fortransferringknowledgeacrosstasks.Infact,thelearnermayencounterthe\n",
      "samebanditproblemoverandoverthroughoutthelearning,andant\n",
      "algorithmshouldbeabletoleveragetheknowledgeobtainedinprevioustasks,\n",
      "whenitispresentedwiththesameproblemagain.Toaddressthisproblem\n",
      "onecantransfertheestimatesofallthepossiblemodelsfrompriortasksto\n",
      "thecurrentone.Oncethesemodelsareaccuratelyestimated,weshowthatan\n",
      "extensionoftheUCBalgorithm(Aueretal.,2002)isabletotlyexploit\n",
      "thispriorknowledgeandreducetheregretthroughtasks(Sec.3).??\n",
      "f\n",
      "mazar,ebrun\n",
      "g\n",
      "@cs.cmu.edualessandro.lazaric@inria.fr\n",
      "1\n",
      "Themaincontributionsofthispaperaretwo-fold:(i)weintroducethe\n",
      "tUCBalgorithmwhichtransfersthemodelestimatesacrossthetasksanduses\n",
      "thisknowledgetoachieveabetterperformancethanUCB.Wealsoprovethat\n",
      "thenewalgorithmisguaranteedtoperformaswellasUCBinearlyepisodes,\n",
      "thusavoidinganynegativetransferandthentoapproachtheperformance\n",
      "oftheidealcasewhenthemodelsareallknowninadvance(Sec.4.4).(ii)To\n",
      "estimatethemodelswerelyonanewvariantofmethodofmoments,robust\n",
      "tensorpowermethod(RTP)(Anandkumaretal.,2013,2012b)andextendit\n",
      "tothemulti-taskbanditsetting1:weprovethatRTPprovidesaconsistent\n",
      "estimateofthemeansofallarms(forallmodels)aslongastheyarepulled\n",
      "atleastthreetimespertaskandprovesamplecomplexityboundsforit(Sec.\n",
      "4.2).Finally,wereportsomepreliminaryresultsonsyntheticdata\n",
      "thetheoretical(Sec.5).Anextendedversionofthispapercontaining\n",
      "proofsandadditionalcommentsisavailablein(Azaretal.,2013).\n",
      "2\n",
      "Preliminaries\n",
      "WeconsiderastochasticMABproblembyasetofarmsA=\n",
      "f\n",
      "1,...\n",
      ",K\n",
      "g\n",
      ",whereeacharmi2Aischaracterizedbyadistribution?iandthesamples\n",
      "(rewards)observedfromeacharmareindependentandidenticallydistributed.\n",
      "Wefocusonthesettingwherethereexistsasetofmodels?=\n",
      "f\n",
      "?=(?1,.\n",
      "..,?K)\n",
      "g\n",
      ",|?|=m,whichcontainsallthepossiblebanditproblems.We\n",
      "denotethemeanofanarmi,thebestarm,andthebestvalueofamodel?\n",
      "2?respectivelyby?i(?),i?(?),??(?).Wethearmgapofanarm\n",
      "iforamodel?asi(?)=??(?)?i(?),whilethemodelgapforanarmi\n",
      "betweentwomodels?and?0isasi(?,?0)=|?i(?)?i(?0)|.We\n",
      "alsoassumethatarmrewardsareboundedin[0,1].Weconsiderthesequential\n",
      "transfersettingwhereateachepisodejthelearnerinteractswithatask??j,\n",
      "2\n",
      "\n",
      "drawnfromadistribution?over?,fornsteps.Theobjectiveistominimize\n",
      "the(pseudo-)regretRJoverJepisodesmeasuredasthebetweenthe\n",
      "rewardsobtainedbypullingi?(??j)andthoseachievedbythelearner:RJ=\n",
      "JXj=1\n",
      "Rjn=\n",
      "JXX\n",
      "jTi,n\n",
      "?j),\n",
      "i(?\n",
      "(1)\n",
      "j=1i6=i?\n",
      "jwhereTi,nisthenumberofpullstoarmiafternstepsofepisodej.We\n",
      "alsointroducesometensornotation.LetX2RKbearandomrealizationof\n",
      "therewardsofallarmsfromaran?=?(?),dommodel.Alltherealizationsare\n",
      "i.i.d.conditionalonamodel??andE[X|?=?]wherethei-thcomponentof\n",
      "?(?)2RKis[?(?)]i=?i(?).GivenrealizationsX1,X2andX3,wee\n",
      "thesecondmomentmatrixM2=E[X1?X2]suchthat[M2]i,j=E[X1i\n",
      "X2j]andthethirdmomenttensorM3=E[X1?X2?X3]suchthat[M2\n",
      "]i,j,l=E[X1iX2jX3l].Sincetherealizationsareconditionallyindependent,\n",
      "wehavethat,forevery?2?,E[X1?X2|?]=2E[X1|?]=?(?)?P?(?)\n",
      "andthisallowsustorewritethesecondandthirdmomentsasP?E[X|?]?2\n",
      "M2=??(?)?(?),M3=??(?)?(?)?3,wherev?p=v?v????visthe\n",
      "p-thtensorpower.LetAbea3rdordermemberofthetensorproductofthe\n",
      "EuclideanspaceRK(asM3),thenwethemultilinearmapasfollows.\n",
      "Forasetofthreematrices\n",
      "f\n",
      "Vi2RK?m\n",
      "g\n",
      "1?i?3,the(i1,i2,i3)m?m?mentry\n",
      "is[A(V1,V2,V3)]i1,i2,i3:=Pinthe3-wayarrayrepresentationofA(V1\n",
      ",V2,V3)2RA[V][V][V].Wealsousetnorms:theEuclidean\n",
      "normj,j,j1j,i2j,i3j,i1231122331?j1,j2,j3?nk?k;theFrobenius\n",
      "normk?kF;thematrixmax-normkAkmax=maxij|[A]ij|.\n",
      "3\n",
      "Multi-armBanditwithFiniteModels\n",
      "Beforeconsideringthetransferproblem,weRequire:Setofmodels?,num-\n",
      "berofstepsnshowthatasimplevariationtoUCBallowsusfort=1,...\n",
      ",ndotoelyexploittheknowledgeof?andBuild?t=\n",
      "f\n",
      "?:8i,|?i\n",
      "(?)??i,t|?\"i,t\n",
      "g\n",
      "obtainatreductionintheregret.TheSelect\n",
      "?t=argmax?2?t??(?)mUCB(model-UCB)algorithminFig.1takesPull\n",
      "armIt=i?(?t)ObservesamplexItandupdateasinputasetofmodels?\n",
      "includingthecurrent?Ateachstept,thealgoendfor(unknown)model?.\n",
      "rithmcomputesasubset?t??containingFigure1:ThemUCBalgorithm.\n",
      "onlythemodelswhosemeans?i(?)arecom?ofthecurrentmodel,obtained\n",
      "averagingpatiblewiththecurrentestimates??i,tofthemeans?i(?)1Notice\n",
      "thatestimatingthemodelsinvolvessolvingalatentvariablemodelestimation\n",
      "problem,forwhichRTPisthestate-of-the-art.\n",
      "2\n",
      "Ti,tpulls,andtheiruncertainty\"i,t(seeEq.2foranexplicitof\n",
      "thisterm).Noticethatitisenoughthatonearmdoesnotsatisfythecom-\n",
      "3\n",
      "\n",
      "patibilityconditiontodiscardamodel?.Amongallthemodelsin?t,mUCB\n",
      "selectsthemodelwiththelargestoptimalvalueandthenitpullsitscorre-\n",
      "spondingoptimalarm.Thischoiceiscoherentwiththeoptimisminthefaceof\n",
      "uncertaintyprincipleusedinUCB-basedalgorithms,sincemUCBalwayspulls\n",
      "theoptimalarmcorrespondingtotheoptimisticmodelcompatiblewiththe\n",
      "currentestimates??i,t.WeshowthatmUCBincursaregretwhichisnever\n",
      "worsethanUCBanditisoftentlysmaller.Wedenotethesetofarms\n",
      "whichareoptimalforatleastamodelinaset?0asA?(?0)=\n",
      "f\n",
      "i2A:9?2?0:\n",
      "i?(?)=i\n",
      "g\n",
      ".ThesetofmodelsforwhichthearmsinA0areoptimalis?(A0)=\n",
      "f\n",
      "?2?:9i2A0:i?(?)=i\n",
      "g\n",
      ".Thesetofoptimisticmodelsforagivenmodel??\n",
      "is?+=\n",
      "f\n",
      "?2?:??(?)?andtheircorrespondingoptimalarmsA+=A?(?+\n",
      ").Thefollowingtheoremboundsthe??(?)\n",
      "g\n",
      ",expectedregret(similarbounds\n",
      "holdinhighprobability).Thelemmasandproofs(usingstandardtoolsfrom\n",
      "thebanditliterature)areavailableinSec.BofAzaretal.(2013).Theorem1.\n",
      "IfmUCBisrunwith=1/n,asetofmmodels?suchthatthe??2?andq\n",
      "\"i,t=log(mn2/)/(2Ti,t1),(2)whereTi,t\n",
      "1\n",
      "isthenumberofpullstoarmiatthebeginningofstept,thenitsexpected\n",
      "regretis\n",
      "E[Rn]?K+\n",
      "X\n",
      "i2A+\n",
      "?logmn3X2i(?)2logmn3?K+?2?,i2A+min?2?min?2?+,ii(?,\n",
      "?)i(?,?)+,i\n",
      "(3)\n",
      "whereA+=A?(?+)isthesetofarmswhichareoptimalforatleastone\n",
      "optimisticmodel?+and?+,i=\n",
      "f\n",
      "?2?+:i?(?)=i\n",
      "g\n",
      "isthesetofoptimistic\n",
      "modelsforwhichiistheoptimalarm.Remark(comparisontoUCB).TheUCB\n",
      "algorithmincursaregret?X?logn?logn?E[Rn(UCB)]?O?OK??.\n",
      "i2Aminii(?)i(?)\n",
      "WeseethatmUCBdisplaystwomajorimprovements.TheregretinEq.3\n",
      "canbewrittenas?X???lognlognE[Rn(mUCB)]?O?O|A|+??.\n",
      "i2A+min?2?minimin?2?i(?,?)i(?,?)+,i\n",
      "+,i\n",
      "ThisresultsuggeststhatmUCBtendstodiscardallthemodelsin?+from\n",
      "themostoptimisticdowntotheactualmodel??which,withhigh-probability,\n",
      "isneverdiscarded.Asaresult,evenifothermodelsarestillin?t,theoptimal\n",
      "armof??ispulleduntiltheend.Thistlyreducesthesetofarms\n",
      "whichareactuallypulledbymUCBandthepreviousboundonlydependson\n",
      "thenumberofarmsinA+,whichis|A+|?|A?(?)|?K.Furthermore,\n",
      "forallarmsi,theminimum?isguaranteedtobelargerthanthearmgapi(?)\n",
      "?(seeLem.4inSec.Bgapmin?2?+,ii(?,?)ofAzaretal.(2013)),thus\n",
      "furtherimprovingtheperformanceofmUCBw.r.t.UCB.\n",
      "4\n",
      "OnlineTransferwithUnknownModels\n",
      "4\n",
      "\n",
      "Wenowconsiderthecasewhenthesetofmodelsisunknownandthere-\n",
      "gretiscumulatedovermultipletasksdrawnfrom?(Eq.1).Weintroduce\n",
      "tUCB(transfer-UCB)whichtransfersestimatesof?,whoseaccuracyisim-\n",
      "provedthroughepisodesusingamethod-of-momentsapproach.4.1\n",
      "Thetransfer-UCBBanditAlgorithm\n",
      "Fig.2outlinesthestructureofouronlinetransferbanditalgorithmtUCB\n",
      "(transfer-UCB).Thealgorithmusestwosub-algorithms,thebanditalgorithm\n",
      "umUCB(uncertainmodel-UCB),whoseobjectiveistominimizetheregretat\n",
      "eachepisode,andRTP(robusttensorpowermethod)whichateachepisode\n",
      "jcomputesanestimate\n",
      "f\n",
      "??ji(?)\n",
      "g\n",
      "ofthearmmeansofallthemodels.The\n",
      "banditalgorithmumUCBinFig.3isanextensionofthemUCBalgorithm.It\n",
      "computesasetofmodels?jtwhosemeans??i(?)arecompatiblewith\n",
      "thecurrentestimates??i,t.However,unlikethecasewheretheexactmodels\n",
      "areavailable,herethemodelsthemselvesareestimatedandtheuncertainty\n",
      "\"jintheirmeans(providedasinputtoumUCB)istakenintoaccountinthe\n",
      "of?jt.Once3\n",
      "Require:numberofarmsK,numberofmodelsm,constantC(?).Initialize\n",
      "estimatedmodels?1=\n",
      "f\n",
      "??1i(?)\n",
      "g\n",
      "i,?,samplesR2RJ?K?nforj=1,2,...,\n",
      "JdoRunRj=umUCB(?j,n)Run?j+1=RTP(R,m,K,j,)endfor\n",
      "Require:setofmodels?j,num.stepsnPulleacharmthreetimesfort=\n",
      "3K+1,...,ndoBuild?jt=\n",
      "f\n",
      "?:8i,|??ji(?)??i,t|?\"i,t+\"j\n",
      "g\n",
      "jj\n",
      "ComputeBt(i;?)=min(??i(?)+\"j),(??i,t+\"i,t)jCompute?t=arg\n",
      "max?2?jmaxiBtj(i;?)t\n",
      "PullarmIt=argmaxiBtj(i;?tj)ObservesampleR(It,Ti,t)=xItand\n",
      "updateendforreturnSamplesR\n",
      "Figure2:ThetUCBalgorithm.\n",
      "Figure3:TheumUCBalgorithm.\n",
      "Require:samplesR2Rj?n,numberofmodelsmandarmsK,episodejc2\n",
      "andMc3usingtherewardsamplesfromR(Eq.4)Estimatethesecondand\n",
      "thirdmomentMm?mK?mbbc2resp.)ComputeD2RandU2R(mlargest\n",
      "eigenvaluesandeigenvectorsofM1/2cbbbccccComputethewhitening\n",
      "mappingW=UDandthetensorT=M3(W,W,W)PlugTbinAlg.1of\n",
      "Anandkumaretal.(2012b)andcomputeeigen-vectors/values\n",
      "f\n",
      "bv(?)\n",
      "g\n",
      ",\n",
      "f\n",
      "b(?)\n",
      "g\n",
      "jT+bcCompute?b(?)=(?)(W)vb(?)forall?2?return?j+1=\n",
      "f\n",
      "b?j\n",
      "(?):?2?\n",
      "g\n",
      "Figure4:Therobusttensorpower(RTP)method(Anandkumaretal.,\n",
      "2012b).\n",
      "theactivesetiscomputed,thealgorithmcomputesanupp\n",
      "boundonthevalueofeacharmiforeachmodel?andreturnsthebestarm\n",
      "forthemostoptimisticmodel.UnlikeinmUCB,duetotheuncertaintyover\n",
      "themodelestimates,amodel?mighthavemorethanoneoptimalarm,andan\n",
      "uppboundonthemeanofthearms??i(?)+\"jisusedtogether\n",
      "withtheuppbound??i,t+\"i,t,whichisdirectlyderivedfrom\n",
      "thesamplesobservedsofarfromarmi.ThisguaranteesthattheB-valuesare\n",
      "alwaysconsistentwiththesamplesgeneratedfromtheactualmodel??j.Once\n",
      "umUCBterminates,RTP(Fig.4)updatestheestimatesofthemodelmeans?\n",
      "5\n",
      "\n",
      "bj(?)=\n",
      "f\n",
      "??ji(?)\n",
      "g\n",
      "i2RKusingthesamplesobtainedfromeacharmi.Atthe\n",
      "beginningofeachtaskumUCBpullsallthearms3times,sinceRTPneedsat\n",
      "least3samplesfromeacharmtoaccuratelyestimatethe2ndand3rdmoments\n",
      "(Anandkumaretal.,2012b).Moreprecisely,RTPusesalltherewardsamples\n",
      "generateduptoepisodejtoestimatethe2ndand3rdmoments(seeSec.2)as\n",
      "c2=jM\n",
      "1\n",
      "Xj\n",
      "l=1\n",
      "?1l??2l,\n",
      "c3=jM\n",
      "and\n",
      "1\n",
      "Xj\n",
      "l=1\n",
      "?1l??2l??3l,\n",
      "(4)\n",
      "lwherethevectors?1l,?2l,?3l2RKareobtainedbydividingtheTi,n\n",
      "samplesobservedfromarmliinepisodelinthreebatchesandtakingtheir\n",
      "average(e.g.,[?1l]iistheaverageoftheTi,n/32lc2andMc3arecon-\n",
      "sistentestisamples).Since?1l,?2l,?3lareindependentestimatesof?(??),\n",
      "MmatesofthesecondandthirdmomentsM2andM3.RTPreliesonthefact\n",
      "thatthemodelmeans?(?)canberecoveredfromthespectraldecomposition\n",
      "ofthesymmetrictensorT=M3(W,W,W),whereWisawhiteningmatrix\n",
      "forM2,i.e.,M2(W,W)=Im?m(seeSec.2fortheofthemapping\n",
      "A(V1,V2,V3)).Anandkumaretal.(2012b)(Thm.4.3)haveshownthat\n",
      "undersomemildassumption(seelaterAssumption1)themodelmeans\n",
      "f\n",
      "?(?)\n",
      "g\n",
      ",\n",
      "canbeobtainedas?(?)=(?)Bv(?),where((?),v(?))isapairofeigenvec-\n",
      "tor/eigenvalueforthetensorTandB:=(WT)+.ThustheRTPalgorithm\n",
      "estimatestheeigenvectorsvb(?)andtheeigenvaluesb(?),ofc3(Wc,Wc,W\n",
      "c).3Oncevb(?)andb(?)arecomputed,theestimatedthem?m?mtensor\n",
      "Tb:=Mjbv(?),whereBbisthemeanvector?b(?)isobtainedbythe\n",
      "inversetransformation?bj(?)=b(?)BbTc(foradetaileddescriptionofRTP\n",
      "algorithmseeAnandkumaretal.,2012b).pseudoinverseofW2\n",
      "Noticethat1/3([?1l]i+[?2l]i+[?1l]i)=??li,n,theempiricalmeanof\n",
      "armiattheendofepisodel.K?mcccc)=Im?m,i.e.,Wcisthewhitening\n",
      "matrixofMc2.InThematrixW2RissuchthatM2(W,W1/2m?m\n",
      "ccbbbgeneralWisnotunique.Here,wechooseW=UD,whereD2\n",
      "Risadiagonalmatrixconsistingc2andUb2RK?mhasthecorresponding\n",
      "eigenvectorsasitscolumns.ofthemlargesteigenvaluesofM3\n",
      "4\n",
      "4.2\n",
      "SampleComplexityoftheRobustTensorPowerMethod\n",
      "umUCBrequiresasinput\"j,i.e.,theuncertaintyofthemodelestimates.\n",
      "Thereforeweneedsamplecomplexityboundsontheaccuracyof\n",
      "f\n",
      "??i(?)\n",
      "g\n",
      "computedbyRTP.TheperformanceofRTPisc2andMc3w.r.t.thetrue\n",
      "6\n",
      "\n",
      "moments.InThm.2wedirectlybytheerroroftheestimatesMp\n",
      "provethat,asthenumberoftasksjgrows,thiserrorrapidlydecreaseswiththe\n",
      "rateof1/j.Thisresultprovidesuswithanupper-boundontheerror\"jneeded\n",
      "forbuildingtheenceintervalsinumUCB.Thefollowingand\n",
      "assumptionarerequiredforourresult.1.Let?M2=\n",
      "f\n",
      "1,2,..\n",
      ".,m\n",
      "g\n",
      "bethesetofmlargesteigenvaluesofthematrixM2.min:=\n",
      "min2?M2,max:=max2?M2andmax:=max?(?).theminimumgap\n",
      "betweenthedistincteigenvaluesofM2as:=mini6=l(|il|).Assumption\n",
      "1.Themeanvectors\n",
      "f\n",
      "?(?)\n",
      "g\n",
      "?arelinearindependentand?(?)>0forall?2\n",
      "?.Wenowstateourmainresultwhichisintheformofahighprobability\n",
      "boundontheestimationerrorofmeanrewardvectorofeverymodel?2?.p3\n",
      "Theorem2.Pick2(0,1).LetC(?):=C3max+1/min+1/max),max/\n",
      "min(max/whereC3>0isauniversalconstant.ThenunderAssumption1\n",
      "thereexistconstantsC4>0andapermutation?on?,suchthatforall?2?,\n",
      "wehavew.p.1q)C4m5K6log(K/)k?(?)?bj(?(?))k?\"j,C(?)K2.5m2\n",
      "log(K/afterj.(5)2jmin(,)23min\n",
      "min\n",
      "min\n",
      "Remark(computationofC(?)).AsillustratedinFig.3,umUCBrelieson\n",
      "theestimates?bj(?)andjontheiraccuracy\".Althoughtheboundreported\n",
      "inThm.2providesanupperboundontheerroroftheestimates,\n",
      "itcontainstermswhicharenotcomputableingeneral(e.g.,min).Inpractice,\n",
      "C(?)shouldbeconsideredasaparameterofthealgorithm.Thisisnotdissimilar\n",
      "fromtheparameterusuallyintroducedintheof\"i,tinfrontofthe\n",
      "square-rootterminUCB.4.3\n",
      "RegretAnalysisofumUCB\n",
      "WenowanalyzetheregretofumUCBwhenanestimatedsetofmodels?j\n",
      "isprovidedasinput.Atepisodej,foreachmodel?wethesetofnon-\n",
      "dominatedarms(i.e.,potentiallyoptimalarms)asAj?(?)=\n",
      "f\n",
      "i2A:@i0,\n",
      "??ji(?)+\"j<??ji0(?)\"j\n",
      "g\n",
      ".Amongthenon-dominatedarms,whenthej\n",
      "actualmodelis??,thesetofoptimisticarmsisAj+(?;??j)=\n",
      "f\n",
      "i2Aj?(?):\n",
      "??ji(?)+\"j??(??j)\n",
      "g\n",
      ".Asaresult,thesetofoptimisticmodelsis?j+(??j\n",
      ")=\n",
      "f\n",
      "?2?:Aj+(?;??j)6=;\n",
      "g\n",
      ".Insomecases,becauseoftheuncertainty\n",
      "inthemodelestimates,unlikeinmUCB,notallthemodels?6=??jcanbe\n",
      "discarded,notevenattheendofaverylongepisode.Amongtheoptimistic\n",
      "models,thesetofmodelsej(??j)=\n",
      "f\n",
      "?2?j(??j):8i2Aj(?;??j),|?that\n",
      "cannotbediscardedisas??ji(?)?i(??j)|?+++j\"\n",
      "g\n",
      ".Finally,\n",
      "whenwewanttoapplytheprevioustoasetofmodels?0insteadof\n",
      "singleSmodelwehave,e.g.,Aj?(?0;??j)=?2?0Aj?(?;??j).\n",
      "TheproofofthefollowingresultsareavailableinSec.DofAzaretal.\n",
      "(2013),hereweonlyreportthenumberofpulls,andthecorrespondingregret\n",
      "bound.Corollary1.IfatepisodejumUCBisrunwith\"i,tasinEq.2and\"j\n",
      "asinEq.5withaparameter0=/2K,thenforanyarmi2A,i6=i?(??j)is\n",
      "pulledTi,ntimessuchthat?82log2mKn2/>>T?mini,n>>?j2<i(?)\n",
      ">>Ti,n?2log2mKn2//(>>:Ti,n=0\n",
      ",\n",
      "7\n",
      "\n",
      "log2mKn2/bi(?;??j)22minj?j?2?i,+(?)\n",
      "?j2i(?))+1\n",
      "+1\n",
      "ifi2Aj1ifi2Aj2\n",
      "otherwise\n",
      "w.p.1,where?ji,+(??j)=\n",
      "f\n",
      "?2?j+(??j):i2A+(?;??j)\n",
      "g\n",
      "isthesetof\n",
      "modelsforwhichiisamongtheiroptimisticnon-dominatedarms,bi(?;??j)\n",
      "=i(?,??j)/2\"j,Aj1=Aj+(?j+(??j);??j)ej(??j);??j)(i.e.,setofarms\n",
      "onlyproposedbymodelsthatcanbediscarded),andAj=Aj+(?+2ej(??j\n",
      ");??j)(i.e.,setofarmsonlyproposedbymodelsthatcannotbediscarded).\n",
      "Aj+(?+5\n",
      "Thepreviouscorollarystatesthatarmswhichcannotbeoptimalforany\n",
      "optimisticmodel(i.e.,theoptimisticnon-dominatedarms)areneverpulledby\n",
      "umUCB,whichfocusesonlyonarmsini2Aj(?j(??j);??j).Amongthese\n",
      "arms,thosethatmayhelptoremoveamodelfromtheactiveset+\n",
      "+\n",
      "(i.e.,i2Aj1)arepotentiallypulledlessthanUCB,whiletheremaining\n",
      "arms,whichareoptimalforthemodelsthatcannotbediscarded(i.e.,i2Aj2),\n",
      "aresimplypulledaccordingtoaUCBstrategy.SimilartomUCB,umUCB\n",
      "pullsthearmsthataremoreoptimisticuntileithertheactiveset?jtchangesor\n",
      "theyarenolongeroptimistic(becauseoftheevidencefromtheactualsamples).\n",
      "Wearenowreadytoderivetheper-episoderegretofumUCB.Theorem3.If\n",
      "umUCBisrunfornstepsonthesetofmodels?jestimatedbyRTPafterj\n",
      "episodeswith=1/n,andtheactualmodelis??j,thenitsexpectedregret\n",
      "(w.r.t.therandomrealizationinepisodejandconditionalon??j)isE[Rjn]?\n",
      "K+X+\n",
      "X\n",
      "ji2A1\n",
      "j\n",
      "i2A2\n",
      "?log2mKn3min2/\n",
      "2log2mKn3/\n",
      "?j)2,1/2minj?2?\n",
      "i(?\n",
      "?j)\n",
      "i,+(?\n",
      "?j).\n",
      "i(?\n",
      "bi(?;??j)2\n",
      "?j)\n",
      "i(?\n",
      "Remark(negativetransfer).Thetransferofknowledgeintroducesabias\n",
      "inthelearningprocesswhichisoftenbNonetheless,inmanycases\n",
      "transfermayresultinabiastowardswrongsolutionsandaworselearning\n",
      "performance,aphenomenonoftenreferredtoasnegativetransfer.The\n",
      "interestingaspectoftheprevioustheoremisthatumUCBisguaranteedto\n",
      "8\n",
      "\n",
      "neverperformworsethanUCBitself.ThisimpliesthattUCBnever\n",
      "fromnegativetransfer,evenwhentheset?jcontainshighlyuncertainmodels\n",
      "andmightbiasumUCBtopullsuboptimalarms.Remark(improvementover\n",
      "UCB).InSec.3weshowedthatmUCBexploitstheknowledgeof?tofocus\n",
      "onarestrictedsetofarmswhicharepulledlessthanUCB.InumUCBthis\n",
      "improvementisnotasclear,sincethemodelsin?arenotknownbutare\n",
      "estimatedonlinethroughepisodes.Yet,similartomUCB,umUCBhasthe\n",
      "twomainsourcesofpotentialimprovementw.r.t.toUCB.Asillustratedby\n",
      "theregretboundinThm.3,umUCBfocusesonarmsinAj1[Aj2whichis\n",
      "potentiallyasmallersetthanA.Furthermore,thenumberofpullstoarmsin\n",
      "Aj1issmallerthanforUCBwhenevertheestimatedmodelgapbi(?;??j)is\n",
      "biggerthani(??j).Eventually,umUCBreachesthesameperformance(and\n",
      "improvementoverUCB)asmUCBwhenjisbigenough.Infact,thesetof\n",
      "optimisticmodelsreducestotheoneusedinmUCB(i.e.,?j+(??j)??+(??j\n",
      "))andalltheoptimisticmodelshaveonlyoptimalarms(i.e.,forany?2?+\n",
      "thesetofnon-dominatedoptimisticarmsisA+(?;??j)=\n",
      "f\n",
      "i?(?)\n",
      "g\n",
      "),which\n",
      "correspondstoAj1?A?(?+(??j))andAj2?\n",
      "f\n",
      "i?(??j)\n",
      "g\n",
      ",whichmatchesthe\n",
      "conditionofmUCB.Forinstance,foranymodel?,inordertohaveA?(?)=\n",
      "f\n",
      "i?(?)\n",
      "g\n",
      ",foranyarmi6=i?(?)weneedthat??ji(?)+\"j???ji?(?)(?)\n",
      "\"j.Thusafter2C(?)minminmini\n",
      "j\n",
      "???2??2?+(?)\n",
      "i(?)\n",
      "2\n",
      "+1.\n",
      "episodes,alltheoptimisticmodelshaveonlyoneoptimalarmindependently\n",
      "fromtheactualidentityofthemodel??j.Althoughthisconditionmayseem\n",
      "restrictive,inpracticeumUCBstartsimprovingoverUCBmuchearlier,as\n",
      "illustratedinthenumericalsimulationinSec.5.4.4\n",
      "RegretAnalysisoftUCB\n",
      "Giventhepreviousresults,wederivetheboundonthecumulativeregret\n",
      "overJepisodes(Eq.1).Theorem4.IftUCBisrunoverJepisodesofnsteps\n",
      "inwhichthetasks??jaredrawnfromadistribution?overasetofmodels\n",
      "?,thenitscumulativeregretisRJ?JK++\n",
      "w.p.1\n",
      "XJ\n",
      "j=1\n",
      "XJ\n",
      "j=1\n",
      "X\n",
      "Xj\n",
      "i2A2\n",
      "j\n",
      "i2A1\n",
      "min\n",
      "?\n",
      "9\n",
      "\n",
      "2log2mKn2/?j2i(?)2\n",
      "2log2mKn/?ji(?)\n",
      ",\n",
      ",\n",
      "log2mKn2/bj(?;??j)22minj?j?2?i,+(?)\n",
      "?j)\n",
      "i(?\n",
      "i\n",
      "w.r.t.therandomizationovertasksandtherealizationsofthearmsineach\n",
      "episode.6\n",
      "30\n",
      "UCBUCB+mUCBtUCB\n",
      "1\n",
      "25\n",
      "0.9\n",
      "0.8\n",
      "Complexity\n",
      "200.7\n",
      "Reward\n",
      "0.6\n",
      "0.5\n",
      "15\n",
      "10\n",
      "0.4\n",
      "0.3\n",
      "50.2\n",
      "0.1\n",
      "00\n",
      "0m1m2m3m4m5\n",
      "m1m2m3m4m5\n",
      "m1m2m3m4m5\n",
      "m1m2m3m4m5\n",
      "m1m2m3m4m5\n",
      "m1m2m3m4m5\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "NumberofTasks(J)\n",
      "m1m2m3m4m5\n",
      "Models\n",
      "Figure5:Setofmodels?.\n",
      "Figure6:Complexityovertasks.\n",
      "350\n",
      "Regret\n",
      "10\n",
      "\n",
      "250\n",
      "UCBUCB+mUCBtUCB(J=1000)tUCB(J=2000)tUCB(J=5000)\n",
      "UCBUCB+mUCBtUCB\n",
      "350\n",
      "Per?episodeRegret\n",
      "300\n",
      "200\n",
      "150\n",
      "300\n",
      "250\n",
      "200\n",
      "150\n",
      "100\n",
      "100500\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "0\n",
      "NumberofSteps(n)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "NumberofTasks(J)\n",
      "Figure7:RegretofUCB,UCB+,mUCB,andtUCB(avg.overepisodes)\n",
      "vsepisodelength.\n",
      "Figure8:Per-episoderegretoftUCB.\n",
      "ThisresultimmediatelyfollowsfromThm.3anditshowsalineardepen-\n",
      "dencyonthenumberofepisodesJ.Thisdependencyisthepricetopayfor\n",
      "notknowingtheidentityofthecurrenttask??j.Ifthetaskwasrevealedat\n",
      "thebeginningofthetask,abanditalgorithmcouldsimplyclusterallthesam-\n",
      "plescomingfromthesametaskandincuramuchsmallercumulativeregret\n",
      "withalogarithmicdependencyonepisodesandsteps,i.e.,log(nJ).Nonetheless,\n",
      "asdiscussedintheprevioussection,thecumulativeregretoftUCBisnever\n",
      "worsethanforUCBandasthenumberoftasksincreasesitapproachesthe\n",
      "performanceofmUCB,whichfullyexploitsthepriorknowledgeof?.\n",
      "5\n",
      "NumericalSimulations\n",
      "InthissectionwereportpreliminaryresultsoftUCBonsyntheticdata.\n",
      "TheobjectiveistoillustrateandsupporttheprevioustheoreticalWe\n",
      "aset?ofm=5MABproblemswithK=7armseach,whosemeans\n",
      "f\n",
      "?i(?)\n",
      "g\n",
      "i,?arereportedinFig.5(seeSect.FinAzaretal.(2013)forthe\n",
      "actualvalues),whereeachmodelhasatcolorandsquarescorrespondto\n",
      "optimalarms(e.g.,arm2isoptimalformodel?2).Thissetofmodelsischosen\n",
      "tobechallengingandillustratesomeinterestingcasesusefultounderstandthe\n",
      "11\n",
      "\n",
      "functioningofthealgorithm.4Models?1and?2onlyintheiroptimalarms\n",
      "andthismakesittodistinguishthem.Forarm3(whichisoptimalfor\n",
      "model?3andthuspotentiallyselectedbymUCB),allthemodelsshareexactly\n",
      "thesamemeanvalue.Thisimpliesthatnomodelcanbediscardedbypullingit.\n",
      "AlthoughthismightsuggestthatmUCBgetsstuckinpullingarm3,weshowed\n",
      "inThm.1thatthisisnotthecase.Models?1and?5arechallengingfor\n",
      "UCBsincetheyhavesmallminimumgap.Only5outofthe7armsareactually\n",
      "optimalforamodelin?.Thus,wealsoreporttheperformanceofUCB+which,\n",
      "undertheassumptionthat?isknown,immediatelydiscardsallthearmswhich\n",
      "arenotoptimal(i2/A?)andperformsUCBontheremainingarms.The\n",
      "modeldistributionisuniform,i.e.,?(?)=1/m.Beforediscussingthetransfer\n",
      "results,wecompareUCB,UCB+,andmUCB,toillustratetheadvantageof\n",
      "thepriorknowledgeof?w.r.t.UCB.Fig.7reportstheper-episoderegretof\n",
      "thethree4Noticethatalthough?Assumption1,thesmallestsingular\n",
      "value0.0038,thusmakingtheestimationofthemodels\n",
      "7\n",
      "min\n",
      "=0.0039and\n",
      "=\n",
      "algorithmsforepisodesoftlengthn(theperformanceoftUCBis\n",
      "discussedlater).Theresultsareaveragedoverallthemodelsin?andover\n",
      "200runseach.Allthealgorithmsusethesamebound\"i,t.The\n",
      "performanceofmUCBistlybetterthanbothUCB,andUCB+,thus\n",
      "showingthatmUCBmakesantuseofthepriorofknowledgeof?.Fur-\n",
      "thermore,inFig.6thehorizontallinescorrespondtothevalueoftheregret\n",
      "boundsuptothendependenttermsandconstants5forthetmodels\n",
      "in?averagedw.r.t.?forthethreealgorithms(theactualvaluesforthedif-\n",
      "ferentmodelsareinthesupplementarymaterial).Thesevaluesshowthatthe\n",
      "improvementobservedinpracticeisaccuratelypredicatedbytheupper-bounds\n",
      "derivedinThm.1.WenowmovetoanalyzetheperformanceoftUCB.InFig.\n",
      "8weshowhowtheper-episoderegretchangesthroughepisodesforatransfer\n",
      "problemwithJ=5000tasksoflengthn=5000.IntUCBweused\"jasin\n",
      "Eq.5withC(?)=2.AsdiscussedinThm.3,UCBandmUCBthe\n",
      "boundariesoftheperformanceoftUCB.Infact,atthebeginningtUCBselects\n",
      "armsaccordingtoaUCBstrategy,sincenopriorinformationaboutthemodels\n",
      "?isavailable.Ontheotherhand,asmoretasksareobserved,tUCBisable\n",
      "totransfertheknowledgeacquiredthroughepisodesandbuildanincreasingly\n",
      "accurateestimateofthemodels,thusapproachingthebehaviorofmUCB.This\n",
      "isalsobyFig.6whereweshowhowthecomplexityoftUCBchanges\n",
      "throughepisodes.Inbothcases(regretandcomplexity)weseethattUCBdoes\n",
      "notreachthesameperformanceofmUCB.Thisisduetothefactthatsome\n",
      "modelshaverelativelysmallgapsandthusthenumberofepisodestohavean\n",
      "accurateenoughestimateofthemodelstoreachtheperformanceofmUCB\n",
      "ismuchlargerthan5000(seealsotheRemarksofThm.3).Sincethe\n",
      "objectiveistoachieveasmallglobalregret(Eq.1),inFig.7wereportthe\n",
      "cumulativeregretaveragedoverthetotalnumberoftasks(J)fortvalues\n",
      "12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ofJandn.Again,thisgraphshowsthattUCBoutperformsUCBandthatit\n",
      "tendstoapproachtheperformanceofmUCBasJincreases,foranyvalueofn.\n",
      "6\n",
      "ConclusionsandOpenQuestions\n",
      "Inthispaperweintroducethetransferprobleminthemulti?armedbandit\n",
      "frameworkwhenatasksaredrawnfromasetofbanditproblems.We\n",
      "introducedthebanditalgorithmmUCBandweshowedthatitisableto\n",
      "leveragethepriorknowledgeonthesetofbanditproblems?andreducethe\n",
      "regretw.r.t.UCB.Whenthesetofmodelsisunknownweeamethod-of-\n",
      "momentsvariant(RTP)whichconsistentlyestimatesthemeansofthemodels\n",
      "in?fromthesamplescollectedthroughepisodes.Thisknowledgeisthentrans-\n",
      "ferredtoumUCBwhichperformsnoworsethanUCBandtendstoapproachthe\n",
      "performanceofmUCB.Forthesealgorithmswederiveregretbounds,andwe\n",
      "showpreliminarynumericalsimulations.Tothebestofourknowledge,thisis\n",
      "theworkstudyingtheproblemoftransferinmulti-armedbandit.Itopens\n",
      "aseriesofinterestingdirections,includingwhetherexplicitmodeliden\n",
      "canimproveourtransferregret.OptimalityoftUCB.Ateachepisode,tUCB\n",
      "transferstheknowledgeabout?acquiredfromprevioustaskstoachieveasmall\n",
      "per-episoderegretusingumUCB.Althoughthisstrategyguaranteesthatthe\n",
      "per-episoderegretoftUCBisneverworsethanUCB,itmaynotbetheoptimal\n",
      "strategyintermsofthecumulativeregretthroughepisodes.Infact,ifJislarge,\n",
      "itcouldbepreferabletorunamodelidenalgorithminsteadofumUCB\n",
      "inearlierepisodessoastoimprovethequalityoftheestimates??i(?).Al-\n",
      "thoughsuchanalgorithmwouldincuramuchlargerregretinearliertasks(up\n",
      "tolinear),itcouldapproachtheperformanceofmUCBinlaterepisodesmuch\n",
      "fasterthandonebytUCB.Thistradebetweenidenofthemodels\n",
      "andtransferofknowledgemaysuggestthattalgorithmsthantUCBare\n",
      "possible.Unknownmodel-setsize.Insomeproblemsthesizeofmodelsetmis\n",
      "notknowntothelearnerandneedstobeestimated.Thisproblemcanbead-\n",
      "dressedbyestimatingtherankofmatrixM2whichequalstom(Kleibergenand\n",
      "Paap,2006).Wealsonotethatonecanrelaxtheassumptionthat?(?)needsto\n",
      "bepositive(seeAssumption1)byusingtheestimatedmodelsizeasopposedto\n",
      "m,sinceM2dependsnotonthemeansofmodelswith?(?)=0.Acknowledg-\n",
      "ments.ThisresearchwassupportedbytheNationalScienceFoundation(NSF\n",
      "award#SBE0836012).WewouldliketothankShamKakadeandAnimashree\n",
      "Anandkumarforvaluablediscussions.A.Lazaricwouldliketoacknowledgethe\n",
      "supportoftheMinistryofHigherEducationandResearch,Nord-Pasde-Calais\n",
      "RegionalCouncilandFEDERthroughthe?ContratdeProjetsEtatRegion\n",
      "(CPER)2007-2013?,andtheEuropeanCommunity?sSeventhFrameworkPro-\n",
      "gramme(FP7/2007-2013)undergrantagreement231495(projectCompLACS).\n",
      "P5Forinstance,forUCBwecomputei1/i.\n",
      "8\n",
      "13\n",
      "\n",
      "2References\n",
      "Agarwal,A.,Dud?k,M.,Kale,S.,Langford,J.,andSchapire,R.E.(2012).\n",
      "Contextualbanditlearningwithpredictablerewards.InProceedingsofthe15th\n",
      "InternationalConferenceonIntelligenceandStatistics(AISTATS?12).\n",
      "Anandkumar,A.,Foster,D.P.,Hsu,D.,Kakade,S.,andLiu,Y.-K.(2012a).A\n",
      "spectralalgorithmforlatentdirichletallocation.InProceedingsofAdvancesin\n",
      "NeuralInformationProcessingSystems25(NIPS?12),pages926?934.Anand-\n",
      "kumar,A.,Ge,R.,Hsu,D.,andKakade,S.M.(2013).Atensorspectral\n",
      "approachtolearningmixedmembershipcommunitymodels.JournalofMa-\n",
      "chineLearningResearch,1:65.Anandkumar,A.,Ge,R.,Hsu,D.,Kakade,S.\n",
      "M.,andTelgarsky,M.(2012b).Tensordecompositionsforlearninglatentvari-\n",
      "ablemodels.CoRR,abs/1210.7559.Anandkumar,A.,Hsu,D.,andKakade,\n",
      "S.M.(2012c).Amethodofmomentsformixturemodelsandhiddenmarkov\n",
      "models.InProceedingofthe25thAnnualConferenceonLearningTheory\n",
      "(COLT?12),volume23,pages33.1?33.34.Auer,P.,Cesa-Bianchi,N.,andFis-\n",
      "cher,P.(2002).Finite-timeanalysisofthemulti-armedbanditproblem.Ma-\n",
      "chineLearning,47:235?256.Azar,M.G.,Lazaric,A.,andBrunskill,E.(2013).\n",
      "Sequentialtransferinmulti-armedbanditwithsetofmodels.CoRR,\n",
      "abs/1307.6887.Cavallanti,G.,Cesa-Bianchi,N.,andGentile,C.(2010).Lin-\n",
      "earalgorithmsforonlinemultitaskclascation.JournalofMachineLearning\n",
      "Research,11:2901?2934.Cesa-Bianchi,N.andLugosi,G.(2006).Prediction,\n",
      "Learning,andGames.CambridgeUniversityPress.Dekel,O.,Long,P.M.,and\n",
      "Singer,Y.(2006).Onlinemultitasklearning.InProceedingsofthe19thAnnual\n",
      "ConferenceonLearningTheory(COLT?06),pages453?467.Garivier,A.and\n",
      "Moulines,E.(2011).Onuppboundpoliciesforswitchingbandit\n",
      "problems.InProceedingsofthe22ndinternationalconferenceonAlgorithmic\n",
      "learningtheory,ALT?11,pages174?188,Berlin,Heidelberg.Springer-Verlag.\n",
      "Kleibergen,F.andPaap,R.(2006).Generalizedreducedranktestsusingthe\n",
      "singularvaluedecomposition.JournalofEconometrics,133(1):97?126.Lang-\n",
      "ford,J.andZhang,T.(2007).Theepoch-greedyalgorithmformulti-armed\n",
      "banditswithsideinformation.InProceedingsofAdvancesinNeuralInforma-\n",
      "tionProcessingSystems20(NIPS?07).Lazaric,A.(2011).Transferinrein-\n",
      "forcementlearning:aframeworkandasurvey.InWiering,M.andvanOtterlo,\n",
      "M.,editors,ReinforcementLearning:StateoftheArt.Springer.Lugosi,G.,\n",
      "Papaspiliopoulos,O.,andStoltz,G.(2009).Onlinemulti-tasklearningwith\n",
      "hardconstraints.InProceedingsofthe22ndAnnualConferenceonLearning\n",
      "Theory(COLT?09).Mann,T.A.andChoe,Y.(2012).Directedexploration\n",
      "inreinforcementlearningwithtransferredknowledge.InProceedingsofthe\n",
      "TenthEuropeanWorkshoponReinforcementLearning(EWRL?12).Pan,S.\n",
      "J.andYang,Q.(2010).Asurveyontransferlearning.IEEETransactions\n",
      "onKnowledgeandDataEngineering,22(10):1345?1359.Robbins,H.(1952).\n",
      "Someaspectsofthesequentialdesignofexperiments.BulletinoftheAMS,\n",
      "58:527?535.Saha,A.,Rai,P.,Daum?III,H.,andVenkatasubramanian,S.\n",
      "(2011).Onlinelearningofmultipletasksandtheirrelationships.InProceed-\n",
      "ingsofthe14thInternationalConferenceonIntelligenceandStatistics\n",
      "14\n",
      "\n",
      "(AISTATS?11),Ft.Lauderdale,Florida.Stewart,G.W.andSun,J.-g.(1990).\n",
      "Matrixperturbationtheory.Academicpress.Taylor,M.E.(2009).Transferin\n",
      "ReinforcementLearningDomains.Springer-Verlag.Wedin,P.(1972).Pertur-\n",
      "bationboundsinconnectionwithsingularvaluedecomposition.BITNumerical\n",
      "Mathematics,12(1):99?111.\n",
      "9\n",
      "15\n",
      "\n",
      "PP6426.pdf\n",
      "PP6426.pdf 17\n",
      "StochasticVariationalDeepKernelLearning\n",
      "Authoredby:\n",
      "RuslanR.Salakhutdinov\n",
      "AndrewG.Wilson\n",
      "EricP.Xing\n",
      "ZhitingHu\n",
      "Abstract\n",
      "Deepkernellearningcombinesthenon-parametricyofker-\n",
      "nelmethodswiththeinductivebiasesofdeeplearningarchitectures.We\n",
      "proposeanoveldeepkernellearningmodelandstochasticvariationalin-\n",
      "ferenceprocedurewhichgeneralizesdeepkernellearningapproachesto\n",
      "enablemulti-tasklearning,additivecovariancestructures,\n",
      "andstochasticgradienttraining.Sp,weapplyadditivebaseker-\n",
      "nelstosubsetsofoutputfeaturesfromdeepneuralarchitectures,and\n",
      "jointlylearntheparametersofthebasekernelsanddeepnetworkthrough\n",
      "aGaussianprocessmarginallikelihoodobjective.Withinthisframework,\n",
      "wederiveantformofstochasticvariationalinferencewhichlever-\n",
      "ageslocalkernelinterpolation,inducingpoints,andstructureexploiting\n",
      "algebra.Weshowimprovedperformanceoverstandalonedeepnetworks,\n",
      "SVMs,andstateoftheartscalableGaussianprocessesonseveral\n",
      "cationbenchmarks,includinganairlinedelaydatasetcontaining6million\n",
      "trainingpoints,CIFAR,andImageNet.\n",
      "1PaperBody\n",
      "Largedatasetsprovidegreatopportunitiestolearnrichstatisticalrepresen-\n",
      "tations,foraccuratepredictionsandnewscieninsightsintoourmodeling\n",
      "problems.Gaussianprocessesarepromisingforlargedataproblems,because\n",
      "theycangrowtheirinformationcapacitywiththeamountofavailabledata,in\n",
      "combinationwithautomaticallycalibratedmodelcomplexity[21,25].Froma\n",
      "Gaussianprocessperspective,allofthestatisticalstructureindataislearned\n",
      "throughakernelfunction.Popularkernelfunctions,suchastheRBFkernel,\n",
      "providesmoothingandinterpolation,butcannotlearnrepresentationsneces-\n",
      "saryforlongrangeextrapolation[22,25].Withsmoothingkernels,wecanonly\n",
      "usetheinformationinalargedatasettolearnaboutnoiseandlength-scale\n",
      "hyperparameters,whichtellusonlyhowquicklycorrelationsinourdatavary\n",
      "withdistanceintheinputspace.Ifwelearnashortlength-scalehyperparam-\n",
      "1\n",
      "\n",
      "eter,thenbywewillonlymakeuseofasmallamountoftraining\n",
      "dataneareachtestingpoint.Ifwelearnalonglength-scale,thenwecould\n",
      "subsamplethedataandmakesimilarpredictions.Thereforetofullyusethe\n",
      "informationinlargedatasets,wemustbuildkernelswithgreatrepresentational\n",
      "powerandusefullearningbiases,andscaletheseapproacheswithout\n",
      "thisrepresentationalability.Indeedmanyrecentapproacheshaveadvocated\n",
      "buildingexpressivekernelfunctions[e.g.,22,9,26,25,17,31],andemerging\n",
      "researchinthisdirectiontakesinspirationfromdeeplearningmodels[e.g.,28,\n",
      "5,3].However,thescalability,generalapplicability,andinterpretabilityofsuch\n",
      "approachesremainachallenge.Recently,Wilsonetal.[30]proposedsimple\n",
      "andscalabledeepkernelsforsingle-outputregressionproblems,withpromis-\n",
      "ingperformanceonmanyexperiments.Buttheirapproachdoesnotallowfor\n",
      "stochastictraining,multipleoutputs,deeparchitectureswithmanyoutputfea-\n",
      "tures,orAnditisonproblems,inparticular,where\n",
      "weoftenhavehighdimensionalinputvectors,withlittleintuitionabouthow\n",
      "thesevectorsshouldcorrelate,andthereforemostwanttolearnanon-\n",
      "Euclideansimilaritymetric[1].\n",
      "*Equalcontribution.30thConferenceonNeuralInformationProcessing\n",
      "Systems(NIPS2016),Barcelona,Spain.\n",
      "Inthispaper,weintroduceinferenceproceduresandproposeanewdeepker-\n",
      "nellearningmodelwhichenables(1)andnon-Gaussianlikelihoods;\n",
      "(2)multi-tasklearning1;(3)stochasticgradientmini-batchtraining;(4)deep\n",
      "architectureswithmanyoutputfeatures;(5)additivecovariancestructures;and\n",
      "(5)greatlyenhancedscalability.Weproposetouseadditivebasekernelscor-\n",
      "respondingtoGaussianprocesses(GPs)appliedtosubsetsofoutputfeatures\n",
      "ofadeepneuralarchitecture.WethenlinearlymixtheseGaussianprocesses,\n",
      "inducingcorrelationsacrossmultipleoutputvariables.Theresultisadeepprob-\n",
      "abilisticneuralnetwork,withahiddenlayercomposedofadditivesetsof\n",
      "basisfunctions,linearlymixedtoproducecorrelatedoutputvariables.Allpa-\n",
      "rametersofthedeeparchitectureandbasekernelsarejointlylearnedthrough\n",
      "amarginallikelihoodobjective,havingintegratedawayallGPs.Forscala-\n",
      "bilityandnon-Gaussianlikelihoods,wederivestochasticvariationalinference\n",
      "(SVI)whichleverageslocalkernelinterpolation,inducingpoints,andstructure\n",
      "exploitingalgebra,andahybridsamplingscheme,buildingonWilsonandNick-\n",
      "isch[27],Wilsonetal.[29],Titsias[24],Hensmanetal.[10],andNicksonetal.\n",
      "[18].Theresultingapproach,SV-DKL,hasacomplexityofO(m1+1/D)form\n",
      "inducingpointsandDinputdimensions,versusthestandardO(m3)fort\n",
      "stochasticvariationalmethods.Weachievegoodpredictiveaccuracyandscala-\n",
      "bilityoverawiderangeoftasks,whileretainingastraightforward,\n",
      "generalpurpose,andhighlypracticalprobabilisticnon-parametricrepresenta-\n",
      "tion,withcodeavailableathttps://people.orie.cornell.edu/andrew/code.\n",
      "2\n",
      "Background\n",
      "Throughoutthispaper,weassumewehaveaccesstovectorialinput-output\n",
      "pairsD=\n",
      "f\n",
      "xi,yi\n",
      "g\n",
      ",whereeachyiisrelatedtoxithroughaGaussianprocess\n",
      "andobservationmodel.Forexample,inregression,onecouldmodely(x)|f(x)\n",
      "2\n",
      "\n",
      "?N(y(x);f(x),?2I),wheref(x)isalatentvectorofindependentGaus-\n",
      "sianprocessesfj?GP(0,kj),and?2Iisanoisecovariancematrix.The\n",
      "computationalbottleneckinworkingwithGaussianprocessestypicallyinvolves\n",
      "computing(KX,X+?2I)?1yandlog|KX,X|overann?ncovari-\n",
      "ancematrixKX,XevaluatedatntraininginputsX.Standardprocedureisto\n",
      "computetheCholeskydecompositionofKX,X,whichincursO(n3)compu-\n",
      "tationsandO(n2)storage,afterwhichpredictionscostO(n2)pertestpoint.\n",
      "Gaussianprocessesarethustypicallylimitedtoatmostafewthousandtrain-\n",
      "ingpoints.Manypromisingapproachestoscalabilityhavebeenexplored,for\n",
      "example,involvingrandomizedmethods[20,16,31],andlowrankapproxima-\n",
      "tions[23,19].WilsonandNickisch[27]recentlyintroducedtheKISS-GPeX,X\n",
      "0=MXKZ,ZM>0,whichadmitsfastcomputations,giventheapproximate\n",
      "kernelmatrixKXexactkernelmatrixKZ,Zevaluatedonalatentmultidimen-\n",
      "sionallatticeofminducinginputsZ,andMX,asparseinterpolationmatrix.\n",
      "WithoutrequiringanygridstructureinX,KZ,ZdecomposesintoaKronecker\n",
      "productofToeplitzmatrices,whichcanbeapproximatedbycirculantmatrices\n",
      "[29].Exploitingsuchstructureincombinationwithlocalkernelinterpolation\n",
      "enablesonetousemanyinducingpoints,resultinginnear-exactaccuracyinthe\n",
      "kernelapproximation,andO(n)inference.Unfortunately,thisapproachdoes\n",
      "nottypicallyapplytoD>5dimensionalinputs[29].Moreover,theGaussian\n",
      "processmarginallikelihooddoesnotfactorize,andthusstochasticgradientde-\n",
      "scentdoesnotordinarilyapply.Toaddressthisissue,Hensmanetal.[10]\n",
      "extendedthevariationalapproachfromTitsias[24]andderivedastochastic\n",
      "variationalGPposterioroverinducingpointsforaregressionmodelwhichdoes\n",
      "havetherequiredfactorizationforstochasticgradientdescent.Hensmanetal.\n",
      "[12],Hensmanetal.[11],andDezfouliandBonilla[6]furthercombinethiswith\n",
      "asamplingprocedureforestimatingnon-conjugateexpectations.Thesemeth-\n",
      "odshaveO(m3)samplingcomplexitywhichbecomesprohibitivewheremany\n",
      "inducingpointsaredesiredforaccurateapproximation.Nicksonetal.[18]\n",
      "considerKroneckerstructureinthestochasticapproximationofHensmanetal.\n",
      "[10]forregression,butdonotleveragelocalkernelinterpolationorsampling.\n",
      "Toaddresstheselimitations,weintroduceanewdeepkernellearningmodelfor\n",
      "multi-taskmini-batchtraining,andscalablekernelinterpolation\n",
      "whichdoesnotrequirelowdimensionalinputspaces.Inthispaper,weview\n",
      "scalabilityandyastwosidesofonecoin:wemostwantthe\n",
      "modelsonthelargestdatasets,whichcontainthenecessaryinformationtodis-\n",
      "coverrich1WefollowtheGPconventionwheremulti-tasklearninginvolvesa\n",
      "functionmappingasingleinputtomultiplecorrelatedoutputresponses(class\n",
      "probabilities,regressionresponses,etc.).UnlikeNNswhichnaturallyhavecor-\n",
      "relatedoutputsbysharinghiddenbasisfunctions(andmulti-taskcanhavea\n",
      "morespecializedmeaning),mostGPmodelsperformmultiplebinary\n",
      "tion,ignoringcorrelationsbetweenoutputclasses.EvenapplyingaGPtoNN\n",
      "featuresfordeepkernellearningdoesnotnaturallyproducemultiplecorrelated\n",
      "outputs.\n",
      "2\n",
      "(1)\n",
      "3\n",
      "\n",
      "h1\n",
      "W(2)\n",
      "W(L)\n",
      "(2)h1\n",
      "y1\n",
      "...\n",
      "...\n",
      "...\n",
      "Outputlayer\n",
      "f1(L)h1\n",
      "x1\n",
      "...\n",
      "A\n",
      "...\n",
      "yC\n",
      "(L)\n",
      "xD(2)\n",
      "hB\n",
      "...\n",
      "...\n",
      "Inputlayer\n",
      "...\n",
      "W(1)\n",
      "hQ\n",
      "fJ\n",
      "(1)\n",
      "hA\n",
      "HiddenlayersAdditiveGPlayer\n",
      "Figure1:DeepKernelLearningforMultidimensionalOutputs.Multidi-\n",
      "mensionalinputsx?RDaremappedthroughadeeparchitecture,andthena\n",
      "seriesofadditiveGaussianprocessesf1,...,fJ,withbasekernels(L)(L)\n",
      "k1,...,kJ,areeachappliedtosubsetsofthenetworkfeaturesh1,..\n",
      ".,hQ.Thethicklinesindicateaprobabilisticmapping.TheadditiveGaus-\n",
      "sianprocessesarethenlinearlymixedbythematrixAandmappedtooutput\n",
      "variablesy1,...,yC(whicharethencorrelatedthroughA).Allofthe\n",
      "parametersofthedeepnetwork,basekernel,andmixinglayer,?=\n",
      "f\n",
      "w,?,A\n",
      "g\n",
      "arelearnedjointlythroughthe(variational)marginallikelihoodofourmodel,\n",
      "havingintegratedawayalloftheGaussianprocesses.Wecanviewtheresulting\n",
      "modelasaGaussianprocesswhichusesanadditiveseriesofdeepkernelswith\n",
      "weightsharing.\n",
      "statisticalstructure.Weshowthattheresultingapproachcanlearnvery\n",
      "expressiveandinterpretablekernelfunctionsonlargedatasets,\n",
      "containingmillionsoftrainingpoints.\n",
      "3\n",
      "DeepKernelLearningforMulti-task\n",
      "4\n",
      "\n",
      "Weproposeanewdeepkernellearningapproachtoaccountfor\n",
      "andnon-Gaussianlikelihoods,multiplecorrelatedoutputs,additivecovariances,\n",
      "andstochasticgradienttraining.Weproposetobuildaprobabilisticdeepnet-\n",
      "workasfollows:1)adeepnon-lineartransformationh(x,w),parametrizedby\n",
      "weightsw,isappliedtotheobservedinputvariablex,toproduceQ(L)(L)\n",
      "featuresatthelayerL,h1,...,hQ;2)JGaussianprocesses,with\n",
      "basekernelsk1,...,kJ,areappliedtosubsetsofthesefeatures,corre-\n",
      "spondingtoanadditiveGPmodel[e.g.,7].Thebasekernelscanthusacton\n",
      "relativelylowdimensionalinputs,wherelocalkernelinterpolationandlearn-\n",
      "ingbiasessuchassimilaritiesbasedonEuclideandistancearemostnatural;3)\n",
      "theseGPsarelinearlymixedbyamatrixA?RC?J,andtransformedbyan\n",
      "observationmodel,toproducetheoutputvariablesy1,...,yC.Themixing\n",
      "ofthesevariablesthroughAproducescorrelatedmultipleoutputs,amulti-task\n",
      "propertywhichisuncommoninGaussianprocessesorSVMs.Thestructureof\n",
      "thisnetworkisillustratedinFigure1.Critically,alloftheparametersinthe\n",
      "model(includingbasekernelhyperparameters)aretrainedthroughoptimizing\n",
      "amarginallikelihood,havingintegratedawaytheGaussianprocesses,through\n",
      "thevariationalinferenceproceduresdescribedinsection4.For\n",
      "weconsideraspecialcaseofthisarchitecture.LetCbethenumberofclasses,\n",
      "andwehavedata\n",
      "f\n",
      "xi,yi\n",
      "g\n",
      "ni=1,whereyi?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "Cisaone-shotencodingof\n",
      "theclasslabel.Weusethesoftmaxobservationmodel:exp(A(fi)>yi)p(yi\n",
      "|fi,A)=P,>cexp(A(fi)ec)\n",
      "(1)\n",
      "wherefi?RJisavectorofindependentGaussianprocessesfollowedbya\n",
      "linearmixinglayerA(fi)=Afi;andecistheindicatorvectorwiththecth\n",
      "elementbeing1andtherest0.ForthejthGaussianprocessintheadditiveGP\n",
      "layer,letfj=\n",
      "f\n",
      "\n",
      "g\n",
      "ni=1bethelatentfunctionsontheinputdatafeatures.By\n",
      "introducingasetoflatentinducingvariablesujindexedbyminducinginputs\n",
      "Z,wecanwrite[e.g.,19](j)\n",
      "(j),?1\n",
      "p(fj|uj)=N(fj|KX,ZKZ,Z\n",
      "e(j)),uj,K\n",
      "e=KX,X?KX,ZK?1KZ,X.KZ,Z\n",
      "(2)\n",
      "SubstitutingthelocalinterpolationapproximationKX,X0=MKZ,ZM>\n",
      "ofWilsonandNickische(j)=0;itthereforefollowsthatfj=KX,ZK?1u=\n",
      "Mu.Insection4[27]intoEq.(2),wedKZ,Zweexploitthisdeterministic\n",
      "relationshipbetweenfandu,governedbythesparsematrixM,toderivea\n",
      "particularlytstochasticvariationalinferenceprocedure.3\n",
      "Eq.(1)andEq.(2)togetherformtheadditiveGPlayerandthelinear\n",
      "mixinglayeroftheproposeddeepprobabilisticnetworkinFigure1,withall\n",
      "parameters(includingnetworkweights)trainedjointlythroughtheGaussian\n",
      "processmarginallikelihood.\n",
      "4\n",
      "StructureExploitingStochasticVariationalInference\n",
      "5\n",
      "\n",
      "ExactinferenceandlearninginGaussianprocesseswithanon-Gaussian\n",
      "likelihoodisnotanalyticallytractable.Variationalinferenceisanappealing\n",
      "approximatetechniqueduetoitsautomaticregularizationtoavoidov\n",
      "anditsabilitytobeusedwithstochasticgradienttraining,byprovidingafac-\n",
      "torizedapproximationtotheGaussianprocessmarginallikelihood.Wedevelop\n",
      "ourstochasticvariationalmethodequippedwithafastsamplingschemefor\n",
      "tacklinganyintractablemarginalization.Letu=\n",
      "f\n",
      "uj\n",
      "g\n",
      "Jj=1bethecollectionof\n",
      "theinducingvariablesoftheJadditiveGPs.Weassumeavariationalposterior\n",
      "overtheinducingvariablesq(u).ByJensen?sinequalitywehavelogp(y)?\n",
      "Eq(u)p(f|u)[logp(y|f)]?KL[q(u)kp(u)],L(q),\n",
      "(3)\n",
      "wherewehaveomittedthemixingweightsAforclarity.TheKLdivergence\n",
      "termcanbeinterpretedasaregularizerencouragingtheapproximateposterior\n",
      "q(u)tobeclosetothepriorp(u).Weaimattighteningthemarginallikelihood\n",
      "lowerboundL(q)whichisequivalenttominimizingtheKLdivergencefromq\n",
      "tothetrueposterior.QnSincethelikelihoodfunctiontypicallyfactorizesover\n",
      "datainstances:p(y|f)=i=1p(yi|fi),weQcanoptimizethelowerbound\n",
      "withstochasticgradients.Inparticular,wespecifyq(u)=jN(uj|?j,Sj)for\n",
      "theindependentGPs,anditerativelyupdatethevariationalparameters\n",
      "f\n",
      "?j,Sj\n",
      "g\n",
      "Jj=1andthekernelanddeepnetworkparametersusinganoisyapproximation\n",
      "ofthegradientofthelowerboundonminibatchesofthefulldata.Henceforth\n",
      "weomittheindexjforclarity.Unfortunately,forgeneralnon-Gaussianlikeli-\n",
      "hoodstheexpectationinEq(3)isusuallyintractable.Wedevelopasampling\n",
      "methodfortacklingthisintractabilitywhichishighlyientwithstructured\n",
      "reparameterization,localkernelinterpolation,andstructureexploitingalgebra.\n",
      "Usinglocalkernelinterpolation,thelatentfunctionfisexpressedasadeter-\n",
      "ministiclocalinterpolationoftheinducingvariablesu(section3).Thisresult\n",
      "allowsustoworkaroundanyapproximateposteriorsonfwhichtypi-\n",
      "callyoccurinvariationalapproachesforGPs.Instead,oursampleronlyneeds\n",
      "toaccountfortheuncertaintyonu.Thedirectparameterizationofq(u)yields\n",
      "astraightforwardandtsamplingprocedure.Thelatentfunctionsamples\n",
      "(indexedbyt)arethencomputeddirectlythroughinterpolationf(t)=Mu(t)\n",
      ".Asopposedtoconventionalmethods,whichassumeadiagonal\n",
      "variationalcovariancematrix,weusetheCholeskydecompositionforreparam-\n",
      "eterizinguinordertopreservestructureswithinthecovariance.Sp,\n",
      "weletS=LTL,resultinginthefollowingsamplingprocedure:u(t)=?+L(t)\n",
      ";\n",
      "(t)?N(0,I).\n",
      "EachstepoftheabovestandardsamplerhascomplexityofO(m2),wherem\n",
      "isthenumberofinducingpoints.Duetothematrixvectorproduct,thissam-\n",
      "plingprocedurebecomesprohibitiveinthepresenceofmanyinducingpoints,\n",
      "whicharerequiredforaccuracyonlargedatasetswithmultidimensionalinputs\n",
      "?particularlyifwehaveanexpressivekernelfunction[27].Wescaleupthe\n",
      "samplerbyleveragingthefactthattheinducingpointsareplacedonagrid\n",
      "(takingadvantageofbothToeplitzandcirculantstructure),andadditionally\n",
      "imposingaKroneckerdecompoNDsitiononL=d=1Ld,whereDistheinput\n",
      "6\n",
      "\n",
      "dimensionofthebasekernel.WiththefastKroneckermatrix-vectorproducts,\n",
      "wereducetheabovesamplingcostofO(m2)toO(m1+1/D).Ourapproach\n",
      "thusgreatlyimprovesoverpreviousstochasticvariationalmethodswhichtyp-\n",
      "icallyscalewithO(m3)complexity,asdiscussedshortly.NotethattheKL\n",
      "divergencetermbetweenthetwoGaussiansinEq(3)hasaclosedformwithout\n",
      "theneedforMonteCarloestimation.ComputingtheKLtermanditsderiva-\n",
      "tives,withtheKronecker3method,isO(DmD).WithTsamplesofuand\n",
      "aminibatchofdatapointsofsizeB,wecanestimatethemarginallikelihood\n",
      "lowerboundasTBNXX(t)L'logp(yi|fi)?KL[q(u)kp(u)],TBt=1i=1\n",
      "4\n",
      "(4)\n",
      "andthederivatives?Lw.r.tthemodelhyperparameters?andthevariational\n",
      "parameters\n",
      "f\n",
      "?,\n",
      "f\n",
      "Ld\n",
      "g\n",
      "Dd=1\n",
      "g\n",
      "canbetakensimilarly.Weprovidethedetailed\n",
      "derivationinthesupplement.Althoughasmallbodyofpioneeringworkhas\n",
      "developedstochasticvariationalmethodsforGaussianprocesses,ourapproach\n",
      "distinctlyprovidestheaboverepresentation-preservingvariationalapproxima-\n",
      "tion,andexploitsalgebraicstructurefortadvantagesinscalability\n",
      "andaccuracy.Inparticular,asimilarvariationallowerboundasinEq(3)was\n",
      "proposedin[24,10]forasparseGP,whichwereextendedtonon-conjugate\n",
      "likelihoods,withtheintractableintegralsestimatedusingGaussianquadrature\n",
      "asintheKLSP-GP[11]orunivariateGaussiansamplesasintheSAVI-GP[6].\n",
      "Hensmanetal.[12]estimatesnonconjugateexpectationswithahybridMonte\n",
      "Carlosampler(denotedasMC-GP).Thecomputationsintheseapproachescan\n",
      "becostly,withO(m3)complexity,duetoacomplicatedvariationalposterior\n",
      "overfaswellastheexpensiveoperationsonthefullinducingpointmatrix.In\n",
      "additiontoitsincreased,oursamplingschemeismuchsimpler,with-\n",
      "outintroducinganyadditionaltuningparameters.Weempiricallycomparewith\n",
      "thesemethodsandshowthepracticalofouralgorithminsection5.\n",
      "VariationalmethodshavealsobeenusedinGPregressionforstochasticinfer-\n",
      "ence(e.g.,[18,10]),andsomeofthemostrecentworkinthisareaappliedvaria-\n",
      "tionalauto-encoders[14]forcoupledvariationalupdates(akabackconstraints)\n",
      "[4,2].Wenotethatthesetechniquesareorthogonalandcomplementarytoour\n",
      "inferenceapproach,andcanbeleveragedforfurtherenhancements.\n",
      "5\n",
      "Experiments\n",
      "Weevaluateourproposedapproach,stochasticvariationaldeepkernellearn-\n",
      "ing(SV-DKL),onawiderangeofproblems,includinganairline\n",
      "delaytaskwithover5.9milliondatapoints(section5.1),alargeanddiverse\n",
      "collectionofclasproblemsfromtheUCIrepository(section5.2),and\n",
      "imagebenchmarks(section5.3).Empiricalresultsdemonstratethe\n",
      "practicalofourapproach,whichprovidesconsistentimprovements\n",
      "overstand-aloneDNNs,whilepreservingaGPrepresentation,anddramaticim-\n",
      "provementsinspeedandaccuracyovermodernstateoftheartGPmodels.We\n",
      "useaccuracywhencomparingtoDNNs,becauseitisastandard\n",
      "forevaluatingbenchmarkswithDNNs.However,wealsocompute\n",
      "thenegativelogprobability(NLP)values(supplement),whichshowsimilar\n",
      "7\n",
      "\n",
      "trends.AllexperimentswereperformedonaLinuxmachinewitheight4.0GHz\n",
      "CPUcores,oneTeslaK40cGPU,and32GBRAM.Weimplementeddeepneural\n",
      "networkswithC[13].ModelTrainingForourdeepkernellearningmodel,\n",
      "weuseddeepneuralnetworkswhichproduceC-dimensionaltop-levelfeatures.\n",
      "HereCisthenumberofclasses.WeplaceaGaussianprocessoneachdimension\n",
      "ofthesefeatures.WeusedRBFbasekernels.TheadditiveGPlayeristhen\n",
      "followedbyalinearmixinglayerA?RC?C.WeinitializedAtobeanidentity\n",
      "matrix,andoptimizedinthejointlearningproceduretorecovercross-dimension\n",
      "correlationsfromdata.WetrainadeepneuralnetworkusingSGDwiththe\n",
      "softmaxlossobjective,andrectlinearactivationfunctions.Aftertheneural\n",
      "networkhasbeenpre-trained,weanadditiveKISS-GPlayer,followedbya\n",
      "linearmixinglayer,usingthetop-levelfeaturesofthedeepnetworkasinputs.\n",
      "Usingthispre-traininginitialization,ourjointSV-DKLmodelofsection3is\n",
      "thentrainedthroughthestochasticvariationalmethodofsection4whichjointly\n",
      "optimizesallthehyperparameters?ofthedeepkernel(includingallnetwork\n",
      "weights),aswellasthevariationalparameters,bybackpropagatingderivatives\n",
      "throughtheproposedmarginallikelihoodlowerboundoftheadditiveGaussian\n",
      "processinsection4.Inallexperiments,weusearelativelylargemini-batchsize\n",
      "(spaccordingtothefulldatasize),enabledbytheproposedstructureex-\n",
      "ploitingvariationalinferenceprocedures.Weachievegoodperformancesetting\n",
      "thenumberofsamplesT=1inEq.4forexpectationestimationinvariational\n",
      "inference,whichprovidesadditionalforasimilarobservationin\n",
      "[14].5.1\n",
      "AirlineDelays\n",
      "Weconsideralargeairlinedatasetconsistingoftarrivalanddepar-\n",
      "turedetailsforallcommercialtswithintheUSin2008.Theapproximately\n",
      "5.9millionrecordscontainextensiveinformationaboutthets,includingthe\n",
      "delayinreachingthedestination.Following[11],weconsiderthetaskofpre-\n",
      "dictingwhetheratwassubjecttodelaybasedon8features(e.g.,distance\n",
      "tobecovered,dayoftheweek,etc).5\n",
      "accuracyTable1reportstheaccuracyof1)KLSP-\n",
      "GP[11],arecentscalablevariationalGPasdiscussedinsection4;2)\n",
      "stand-alonedeepneuralnetwork(DNN);3)DNN+,astand-aloneDNNwith\n",
      "anextraQ?cfully-connectedhiddenlayerwithQ,casinFigure1;4)\n",
      "DNN+GPwhichisaGPappliedtoapre-trainedDNN(withsamearchitecture\n",
      "asin2);and5)ourstochasticvariationalDKLmethod(SV-DKL)(sameDNN\n",
      "architectureasin2).ForDNN,weusedafully-connectedarchitecturewith\n",
      "layersd-1000-1000-500-50-c.2TheDNNcomponentoftheSV-DKLmodelhas\n",
      "theexactsamearchitecture.TheSV-DKLjointtrainingwasconductedusing\n",
      "alargeminibatchsizeof50,000toreducethevarianceofthestochasticgradi-\n",
      "ent.Wecanusesuchalargeminibatchineachiteration(whichisdaunting\n",
      "forregularGPevenasawholedataset)duetotheofourinference\n",
      "strategywithineachmini-batch,leveragingstructureexploitingalgebra.From\n",
      "thetableweseethatSV-DKLoutperformsboththealternativevariationalGP\n",
      "model(KLSPGP)andthestand-alonedeepnetwork.DNN+GPoutperforms\n",
      "stand-aloneDNNs,showingthenon-parametricyofkernelmethods.\n",
      "8\n",
      "\n",
      "BycombiningKISS-GPwithDNNsaspartofajointSV-DKLprocedure,we\n",
      "obtainbetterresultsthanDNNandDNN+GP.Besides,boththeplainDNN\n",
      "andSV-DKLnotablyimproveonstand-aloneGPs,indicatingasuperiorcapac-\n",
      "ityofdeeparchitecturestolearnrepresentationsfromlargebuttraining\n",
      "sets,despitetheasymptoticapproximationpropertiesofGaussianprocesses.\n",
      "Bycontrast,addinganextrahiddenlayer,asinDNN+,doesnotimproveper-\n",
      "formance.Figure2(a)furtherstudieshowperformancechangesasdatasize\n",
      "increases.WeobservethattheproposedSV-DKLtrainedon1/50of\n",
      "thedataalreadycanreachacompetitiveaccuracyascomparedtotheKLSP-\n",
      "GPmodeltrainedonthefulldataset.Asthenumberofthetrainingpoints\n",
      "increases,theSV-DKLandDNNmodelscontinuetoimprove.Thisexperiment\n",
      "demonstratesthevalueofexpressivekernelfunctionsonlargedataproblems,\n",
      "whichcanelycapturetheextrainformationavailableasseeingmore\n",
      "traininginstances.Furthermore,SV-DKLconsistentlyprovidesbetterperfor-\n",
      "manceovertheplainDNN,throughitsnon-parametricy.Scalability\n",
      "WenextmeasurethescalabilityofourvariationalDKLintermsofthenumber\n",
      "ofinducingpointsmineachGP.Figure2(c)showstheruntimesinseconds,\n",
      "asafunctionofm,forevaluatingtheobjectiveandanyrelevantderivatives.\n",
      "Wecompareourstructureexploitingvariationalmethodwiththescalablevari-\n",
      "ationalinferenceinKLSP-GP,andtheMCMC-basedvariationalmethodin\n",
      "MC-GP[12].Weseethatourinferenceapproachisfarmoretthanpre-\n",
      "viousscalablealgorithms.Moreover,whenthenumberofinducingpointsisnot\n",
      "toolarge(e.g.,m=70),theaddedtimeforSV-DKLoverDNNisreasonable\n",
      "(e.g.,0.39svs.0.27s),especiallyconsideringthegainsinperformanceandex-\n",
      "pressivepower.Figure2(d)showstheruntimescalingoftvariational\n",
      "methodsasmgrows.Wecanseethattheruntimeofourapproachincreases\n",
      "onlyslowlyinawiderangeofm(<2,000),greatlyenhancingthescalabilityover\n",
      "theothermethods.Thisempiricallyvalidatestheimprovedtimecomplexityof\n",
      "ournewinferencemethodaspresentedinsection4.Wenextinvestigatethe\n",
      "totaltrainingtimeofthemodels.Table1,rightpanel,liststhetimecostof\n",
      "trainingKLSP-GP,DNN,andSV-DKL;andFigure2(b)showshowthetraining\n",
      "timeofSV-DKLandDNNchangesasmoretrainingdataispresented.Wesee\n",
      "thatonthefulldatasetDKL,asaGPmodel,savesover60%timeascompared\n",
      "tothemodernstateoftheartKLSP-GP,whileatthesametimeachievingover\n",
      "an18%improvementinpredictiveaccuracy.Generally,thetrainingtimeofSV-\n",
      "DKLincreasesslowlywithgrowingdatasizes,andhasonlymodestadditional\n",
      "overheadcomparedtostand-alonearchitectures,justidbyimprovementsin\n",
      "performance,andthegeneralbofanon-parametricprobabilisticrepre-\n",
      "sentation.Moreover,theDNNwasfullytrainedonaGPU,whileinSV-DKL\n",
      "thebasekernelhyperparametersandvariationalparameterswereoptimizedon\n",
      "aCPU.SincemostupdatesoftheSV-DKLparametersarecomputedinmatrix\n",
      "forms,webelievethealreadymodesttimegapbetweenSV-DKLandDNNscan\n",
      "bealmostentirelyclosedbydeployingthewholeSV-DKLmodelonGPUs.5.2\n",
      "UCITasks\n",
      "Thesecondevaluationofourproposedalgorithm(SV-DKL)isconducted\n",
      "onanumberofcommonlyusedUCItasksofvaryingsizesand\n",
      "9\n",
      "\n",
      "properties.Table1(supplement)liststheaccuracyofSVM,DNN,\n",
      "DNN+(astand-aloneDNNwithanextraQ?cfully-connectedhiddenlayer\n",
      "withQ,casinFigure1),DNN+GP(aGPtrainedonthetoplevel\n",
      "featuresofatrainedDNNwithouttheextrahiddenlayer),andSV-DKL(same\n",
      "architectureasDNN).2\n",
      "WeobtainedsimilarresultswithotherDNNarchitectures(e.g.,d-1000-1000-\n",
      "500-50-20-c).\n",
      "6\n",
      "Table1:accuracyandtrainingtimeontheairlinedelay\n",
      "dataset,withndatapoints,dinputdimensions,andcclasses.KLSP-GPis\n",
      "astochasticvariationalGPproposedin[11].DNN+istheDNNwith\n",
      "anextrahiddenlayer.DNN+GPisaGPappliedtopre-trainedoutput\n",
      "layeroftheDNN(withouttheextrahiddenlayer).FollowingHensmanetal.\n",
      "[11],weselectedahold-outsetsof100,000pointsuniformlyatrandom,andthe\n",
      "resultsofDNNandSV-DKLareaveragedover5runs?onestandarddeviation.\n",
      "SincethecodeofKLSP-GPisnotpubliclyavailablewedirectlyshowtheresults\n",
      "from[11].\n",
      "Airline\n",
      "Accuracy\n",
      "0.76\n",
      "5,934,530\n",
      "Accuracy\n",
      "c\n",
      "8\n",
      "DNN\n",
      "DNN+\n",
      "DNN+GP\n",
      "SV-DKL\n",
      "KLSP-GP\n",
      "DNN\n",
      "SV-DKL\n",
      "?0.675\n",
      "0.773?0.001\n",
      "0.722?0.002\n",
      "0.7746?0.001\n",
      "0.781?0.001\n",
      "?11\n",
      "0.53\n",
      "3.98\n",
      "2\n",
      "12\n",
      "DNNSV?DKLKLSP?GP\n",
      "10\n",
      "0.740.720.70.68\n",
      "TotalTrainingTime(h)\n",
      "KLSP-GP[11]\n",
      "10\n",
      "\n",
      "Trainingtime(h)\n",
      "0.78\n",
      "d\n",
      "DNNSV?DKLKLSP?GP\n",
      "300\n",
      "864\n",
      "SV?DKLKLSP?GPMC?GPDNN\n",
      "200\n",
      "Runtimescaling\n",
      "n\n",
      "Runtime(s)\n",
      "Datasets\n",
      "200\n",
      "100\n",
      "2\n",
      "150\n",
      "SV?DKLKLSP?GPMC?GPslope=1\n",
      "100\n",
      "50\n",
      "0.661\n",
      "2\n",
      "3\n",
      "4\n",
      "#TrainingInstances\n",
      "5\n",
      "6\n",
      "0\n",
      "6\n",
      "x10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#TrainingInstances\n",
      "5\n",
      "070200400\n",
      "6\n",
      "800\n",
      "1200\n",
      "#Inducingpoints\n",
      "6\n",
      "x10\n",
      "1600\n",
      "2000\n",
      "170200400\n",
      "800\n",
      "11\n",
      "\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "#Inducingpoints\n",
      "Figure2:(a)accuracyvs.thenumberoftrainingpoints(n).\n",
      "Wetestedthedeepmodels,DNNandSV-DKL,bytrainingon1/50,1/10,1/3,\n",
      "andthefulldataset,respectively.Forcomparison,thecyandiamondandblack\n",
      "dashedlineshowtheaccuracylevelofKLSP-GPtrainedonthefulldata.(b)\n",
      "Trainingtimevs.n.Thecyandiamondandblackdashedlineshowthetraining\n",
      "timeofKLSP-GPonthefulldata.(c)Runtimevs.thenumberofinducing\n",
      "points(m)onairlinetask,byapplyingtvariationalmethodsfordeep\n",
      "kernellearning.Theminibatchsizeisto50,000.Theruntimeofthestand-\n",
      "aloneDNNdoesnotchangeasmvaries.(d)Thescalingofruntimerelativeto\n",
      "theruntimeofm=70.Theblackdashedlineindicatesaslopeof1.\n",
      "TheplainDNN,whichlearnssalientfeatureselyfromrawdata,gives\n",
      "notablyhigheraccuracycomparedtoanSVM,themostlywidelyusedkernel\n",
      "methodforproblems.WeseethattheextralayerinDNN+GP\n",
      "cansometimesharmperformance.Bycontrast,non-parametricyof\n",
      "DNN+GPconsistentlyimprovesuponDNN.AndSV-DKL,bytrainingaDNN\n",
      "throughaGPmarginallikelihoodobjective,consistentlyprovidesfurtheren-\n",
      "hancements(withparticularlynotableperformanceontheConnect4andCov-\n",
      "typedatasets).5.3\n",
      "ImageClascation\n",
      "WenextevaluatetheproposedscalableSV-DKLprocedurefortly\n",
      "handlinghigh-dimensionalhighly-structuredimagedata.Weusedaminibatch\n",
      "sizeof5,000forstochasticgradienttrainingofSV-DKL.Table2compares\n",
      "SV-DKLwiththemostrecentscalableGPBesidesKLSP-GP,we\n",
      "alsocollectedtheresultsoftheMC-GP[12]whichusesahybridMonteCarlo\n",
      "samplertotacklenon-conjugatelikelihoods,SAVI-GP[6]whichapproximates\n",
      "withaunivariateGaussiansampler,aswellasthedistributedGPlatentvariable\n",
      "model(denotedasD-GPLVM)[8].Weseethatontherespectivebenchmark\n",
      "tasks,SV-DKLimprovesoveralloftheabovescalableGPmethodsbyalarge\n",
      "margin.WenotethatthesedatasetsareverychallengingforconventionalGP\n",
      "methods.WefurthercompareSV-DKLtostand-aloneconvolutionalneural\n",
      "networks,andGPsappliedtopre-trainedCNNs(CNN+GP).Onthe\n",
      "threedatasetsinTable2,weusedthereferenceCNNmodelsimplementedin\n",
      "andfortheSVHNdataset,asnobenchmarkarchitectureisavailable,\n",
      "weusedtheCIFAR10architecturewhichturnedouttoperformquitewell.\n",
      "Aswecansee,theSV-DKLmodeloutperformsCNNsandCNN+GPonall\n",
      "datasets.Bycontrast,theextrahiddenQ?chiddenlayerCNN+doesnot\n",
      "consistentlyimproveperformanceoverCNN.ResNetComparison:Basedonone\n",
      "ofthebestpublicimplementationsontheResNet-20has0.901accuracy\n",
      "onCIFAR10,andSV-DKL(withthisResNetbasearchitecture)improvesto\n",
      "0.910.ImageNet:Werandomlyselected20categoriesofimageswithanAlexNet\n",
      "variantasthebaseNN[15],whichhasanaccuracyof0.6877,whileSV-DKL\n",
      "achieves0.7067accuracy.5.3.1\n",
      "12\n",
      "\n",
      "Interpretation\n",
      "InFigure3(a)weinvestigatethedeepkernelslearnedontheMNISTdataset\n",
      "byrandomlyselecting4classesandvisualizingthecovariancematricesofre-\n",
      "spectivedimensions.Thecovariancematricesareevaluatedonthesetoftest\n",
      "inputs,sortedintermsofthelabelsoftheinputimages.Weseethatthe7\n",
      "Table2:accuracyontheimagebenchmarks.\n",
      "MNIST-Binaryisthetasktotiatebetweenoddandevendigitsonthe\n",
      "MNISTdataset.Wefollowedthestandardtraining-testsetpartitioningofall\n",
      "thesedatasets.Wehavecollectedrecentlypublishedresultsofavarietyof\n",
      "scalableGPs.ForCNNs,weusedtherespectivebenchmarkarchitectures(or\n",
      "withslightadaptations)fromCCNN+isastand-aloneCNNwithQ?c\n",
      "fullyconnectedextrahiddenlayer.Seethetextformoredetails,includinga\n",
      "comparisonwithResNetsonCIFAR10.Datasets\n",
      "MNIST-BinaryMNISTCIFAR10SVHN\n",
      "n\n",
      "d\n",
      "28?2828?283?32?323?32?32\n",
      "60K60K50K73K\n",
      "Accuracy\n",
      "cMC-GP[12]\n",
      "SAVI-GP[6]\n",
      "D-GPLVM[8]\n",
      "KLSP-GP[11]\n",
      "CNN\n",
      "CNN+\n",
      "CNN+GP\n",
      "SV-DKL\n",
      "?0.9804??\n",
      "?0.9749??\n",
      "?0.9405??\n",
      "0.978???\n",
      "0.99340.99080.75920.9214\n",
      "0.88380.99090.76180.9193\n",
      "0.99380.99150.76330.9221\n",
      "0.99400.99200.77040.9228\n",
      "2101010\n",
      "c=2\n",
      "c=3\n",
      "2k\n",
      "2k\n",
      "4k\n",
      "4k\n",
      "6k\n",
      "6k\n",
      "0.6\n",
      "0.20\n",
      "13\n",
      "\n",
      "8k\n",
      "8k\n",
      "10k\n",
      "10k\n",
      "0.5\n",
      "1\n",
      "2\n",
      "4k\n",
      "6k\n",
      "8k\n",
      "10k\n",
      "0.42k\n",
      "c=6\n",
      "4k\n",
      "6k\n",
      "8k\n",
      "10k\n",
      "0.3\n",
      "c=8\n",
      "2k\n",
      "2k\n",
      "4k\n",
      "4k\n",
      "0.2\n",
      "Outputclasses\n",
      "2k\n",
      "0.1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "7\n",
      "0.16k\n",
      "6k\n",
      "8k\n",
      "8\n",
      "8k\n",
      "10k\n",
      "90\n",
      "10k2k\n",
      "4k\n",
      "6k\n",
      "8k\n",
      "10k\n",
      "2k\n",
      "14\n",
      "\n",
      "4k\n",
      "6k\n",
      "8k\n",
      "10k\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "-0.1\n",
      "Inputdimensions\n",
      "Figure3:(a)Theinducedcovariancematricesonclasses2,3,6,and8,on\n",
      "testcasesoftheMNISTdatasetorderedaccordingtothelabels.(b)The\n",
      "mixinglayer(i.e.,matrixA)onMNISTdigitrecognition.\n",
      "deepkerneloneachdimensionctivelydiscoversthecorrelationsbetween\n",
      "theimageswithinthecorrespondingclass.Forinstance,inc=2thedata\n",
      "pointsbetween2k-3k(i.e.,imagesofdigit2)arestronglycorrelatedwitheach\n",
      "other,andcarrylittlecorrelationwiththerestoftheimages.Besides,wecan\n",
      "alsoclearlyobservethattherestofthedatapointsalsoformmultiple?blocks?,\n",
      "ratherthanbeingcrammedtogetherwithoutanystructure.Thisvalidates\n",
      "thattheDKLprocedureandadditiveGPsdocapturethecorrelationsacross\n",
      "tdimensions.Tofurtherexplorethelearntdependenciesbetweenthe\n",
      "outputclassesandtheadditiveGPsservingasthebases,wevisualizedthe\n",
      "weightsofthemixinglayer(A)inFig.3(b),enablingthecorrelatedmulti-\n",
      "output(multi-task)natureofthemodel.Besidestheexpectedhighweights\n",
      "alongthediagonal,wethatclass9isalsohighlycorrelatedwithdimension\n",
      "0and6,whichisconsistentwiththevisualsimilaritybetweendigit?9?and\n",
      "?0?/?6?.Overall,theabilitytointerpretthelearneddeepcovariancematrixas\n",
      "discoveringanexpressivesimilaritymetricacrossdatainstancesisadistinctive\n",
      "featureofourapproach.\n",
      "6\n",
      "Discussion\n",
      "WeintroducedascalableGaussianprocessmodelwhichleveragesdeeplearn-\n",
      "ing,stochasticvariationalinference,structureexploitingalgebra,andaddi-\n",
      "tivecovariancestructures.Theresultingdeepkernellearningapproach,SV-\n",
      "DKL,allowsforandnon-Gaussianlikelihoods,multi-tasklearn-\n",
      "ing,andmini-batchtraining.SV-DKLachievessuperiorperformanceoveral-\n",
      "ternativescalableGPmodelsandstand-alonedeepnetworksonmanysignif-\n",
      "icantbenchmarks.Severalfundamentalthemesemergefromtheexposition:\n",
      "(1)kernelmethodsanddeeplearningapproachesarecomplementary,andwe\n",
      "cancombinetheadvantagesofeachapproach;(2)expressivekernelfunctions\n",
      "areparticularlyvaluableonlargedatasets;(3)byviewingneuralnetworks\n",
      "15\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throughthelensofmetriclearning,deeplearningapproachesbecomemore\n",
      "interpretable.Deeplearningisabletoobtaingoodpredictiveaccuracybyauto-\n",
      "maticallylearningstructurewhichwouldbeulttoapriorifeatureengineer\n",
      "intoamodel.Inthefuture,wehopedeepkernellearningapproacheswillbe\n",
      "particularlyhelpfulforinterpretingtheselearnedfeatures,leadingtonewsci-\n",
      "eninsightsintoourmodellingproblems.Acknowledgements:Wethank\n",
      "NSFIIS-1563887,ONRN000141410684,N000141310721,N000141512791,and\n",
      "ADeLAIDEFA8750-16C-0130-001grants.8\n",
      "2References\n",
      "[1]C.C.Aggarwal,A.Hinneburg,andD.A.Keim.Onthesurprisingbe-\n",
      "haviorofdistancemetricsinhighdimensionalspace.Springer,2001.[2]\n",
      "T.D.BuiandR.E.Turner.StochasticvariationalinferenceforGaussian\n",
      "processlatentvariablemodelsusingbackconstraints.BlackBoxLearning\n",
      "andInferenceNIPSworkshop,2015.[3]R.Calandra,J.Peters,C.E.Ras-\n",
      "mussen,andM.P.Deisenroth.ManifoldGaussianprocessesforregression.\n",
      "arXivpreprintarXiv:1402.5876,2014.[4]Z.Dai,A.Damianou,J.Gonz?lez,\n",
      "andN.Lawrence.Variationalauto-encodeddeepGaussianprocesses.arXiv\n",
      "preprintarXiv:1511.06455,2015.[5]A.DamianouandN.Lawrence.Deep\n",
      "Gaussianprocesses.IntelligenceandStatistics,2013.[6]A.Dezfouli\n",
      "andE.V.Bonilla.ScalableinferenceforGaussianprocessmodelswithblack-\n",
      "boxlikelihoods.InAdvancesinNeuralInformationProcessingSystems,pages\n",
      "1414?1422,2015.[7]N.Durrande,D.Ginsbourger,andO.Roustant.Additive\n",
      "kernelsforGaussianprocessmodeling.arXivpreprintarXiv:1103.4023,2011.\n",
      "[8]Y.Gal,M.vanderWilk,andC.Rasmussen.Distributedvariationalin-\n",
      "ferenceinsparseGaussianprocessregressionandlatentvariablemodels.In\n",
      "AdvancesinNeuralInformationProcessingSystems,pages3257?3265,2014.\n",
      "[9]M.G?nenandE.Alpayd?n.Multiplekernellearningalgorithms.Journal\n",
      "ofMachineLearningResearch,12:2211?2268,2011.[10]J.Hensman,N.Fusi,\n",
      "andN.Lawrence.Gaussianprocessesforbigdata.InUncertaintyin\n",
      "Intelligence(UAI).AUAIPress,2013.[11]J.Hensman,A.Matthews,andZ.\n",
      "Ghahramani.ScalablevariationalGaussianprocessInProceed-\n",
      "ingsoftheEighteenthInternationalConferenceonIntelligenceand\n",
      "Statistics,pages351?360,2015.[12]J.Hensman,A.G.Matthews,M.Filip-\n",
      "pone,andZ.Ghahramani.MCMCforvariationallysparseGaussianprocesses.\n",
      "InAdvancesinNeuralInformationProcessingSystems,pages1648?1656,2015.\n",
      "[13]Y.Jia,E.Shelhamer,J.Donahue,S.Karayev,J.Long,R.Girshick,S.\n",
      "Guadarrama,andT.Darrell.Convolutionalarchitectureforfastfea-\n",
      "tureembedding.arXivpreprintarXiv:1408.5093,2014.[14]D.P.Kingmaand\n",
      "M.Welling.Auto-encodingvariationalbayes.arXivpreprintarXiv:1312.6114,\n",
      "2013.[15]A.Krizhevsky,I.Sutskever,andG.Hinton.Imagenet\n",
      "withdeepconvolutionalneuralnetworks.InAdvancesinNeuralInformation\n",
      "ProcessingSystems,2012.[16]Q.Le,T.Sarlos,andA.Smola.Fastfood-\n",
      "computingHilbertspaceexpansionsinloglineartime.InProceedingsofthe\n",
      "16\n",
      "\n",
      "30thInternationalConferenceonMachineLearning,pages244?252,2013.[17]\n",
      "J.R.Lloyd,D.Duvenaud,R.Grosse,J.B.Tenenbaum,andZ.Ghahramani.\n",
      "AutomaticconstructionandNatural-Languagedescriptionofnonparametricre-\n",
      "gressionmodels.InAssociationfortheAdvancementofIntelligence\n",
      "(AAAI),2014.[18]T.Nickson,T.Gunter,C.Lloyd,M.A.Osborne,and\n",
      "S.Roberts.Blitzkriging:Kronecker-structuredstochasticGaussianprocesses.\n",
      "arXivpreprintarXiv:1510.07965,2015.[19]J.Qui?onero-CandelaandC.Ras-\n",
      "mussen.AunifyingviewofsparseapproximateGaussianprocessregression.\n",
      "TheJournalofMachineLearningResearch,6:1939?1959,2005.[20]A.Rahimi\n",
      "andB.Recht.Randomfeaturesforlarge-scalekernelmachines.InNeuralIn-\n",
      "formationProcessingSystems,2007.[21]C.E.RasmussenandZ.Ghahramani.\n",
      "Occam?srazor.InNeuralInformationProcessingSystems(NIPS),2001.[22]\n",
      "C.E.RasmussenandC.K.I.Williams.GaussianprocessesforMachineLearn-\n",
      "ing.TheMITPress,2006.[23]B.W.Silverman.Someaspectsofthespline\n",
      "smoothingapproachtonon-parametricregressioncurvetting.Journalofthe\n",
      "RoyalStatisticalSocietyB,47(1):1?52,1985.[24]M.K.Titsias.Variational\n",
      "learningofinducingvariablesinsparseGaussianprocesses.InInternational\n",
      "ConferenceonIntelligenceandStatistics,pages567?574,2009.[25]\n",
      "A.G.Wilson.Covariancekernelsforfastautomaticpatterndiscoveryand\n",
      "extrapolationwithGaussianprocesses.PhDthesis,UniversityofCambridge,\n",
      "2014.[26]A.G.WilsonandR.P.Adams.Gaussianprocesskernelsforpattern\n",
      "discoveryandextrapolation.InternationalConferenceonMachineLearning\n",
      "(ICML),2013.[27]A.G.WilsonandH.Nickisch.Kernelinterpolationfor\n",
      "scalablestructuredGaussianprocesses(KISS-GP).InternationalConferenceon\n",
      "MachineLearning(ICML),2015.[28]A.G.Wilson,D.A.Knowles,andZ.\n",
      "Ghahramani.Gaussianprocessregressionnetworks.InInternationalConfer-\n",
      "enceonMachineLearning(ICML),Edinburgh,2012.[29]A.G.Wilson,C.\n",
      "Dann,andH.Nickisch.ThoughtsonmassivelyscalableGaussianprocesses.\n",
      "arXivpreprintarXiv:1511.01870,2015.https://arxiv.org/abs/1511.01870.[30]\n",
      "A.G.Wilson,Z.Hu,R.Salakhutdinov,andE.P.Xing.Deepkernellearning.\n",
      "IntelligenceandStatistics,2016.[31]Z.Yang,A.J.Smola,L.Song,\n",
      "andA.G.Wilson.Alacarte-learningfastkernels.Intelligenceand\n",
      "Statistics,2015.\n",
      "9\n",
      "17\n",
      "\n",
      "PP4580.pdf\n",
      "PP4580.pdf 11\n",
      "HierarchicalOptimisticRegionSelectiondriven\n",
      "byCuriosity\n",
      "Authoredby:\n",
      "Odalric-ambrymMaillard\n",
      "Abstract\n",
      "Thispaperaimstotakeastepforwardsmakingtheterm\\intrinsicmo-\n",
      "tivation\"fromreinforcementlearningtheoreticallywellfounded,focusing\n",
      "oncuriosity-drivenlearning.Tothatend,weconsiderthesettingwhere,\n",
      "apartitionPofacontinuousspaceXbeinggiven,andaprocessnu\n",
      "onXbeingunknown,weareaskedtosequentiallydecidewhich\n",
      "cellofthepartitiontoselectaswellaswheretosamplenuinthatcell,in\n",
      "ordertominimizealossfunctionthatisinspiredfrompreviousworkon\n",
      "curiosity-drivenlearning.Thelossoneachcellconsistsofonetermmea-\n",
      "suringasimpleworstcasequadraticsamplingerror,andapenaltyterm\n",
      "proportionaltotherangeofthevarianceinthatcell.Thecorrespond-\n",
      "ingproblemformulationextendsthesettingknownasactivelearningfor\n",
      "multi-armedbanditstothecasewheneacharmisacontinuousregion,\n",
      "andweshowhowanadaptationofrecentalgorithmsforthatproblem\n",
      "andofhierarchicaloptimisticsamplingalgorithmsforoptimizationcan\n",
      "beusedinordertosolvethisproblem.Theresultingprocedure,called\n",
      "HierarchicalOptimisticRegionSElectiondrivenbyCuriosity(HORSE.C)\n",
      "isprovidedtogetherwitharegretanalysis.\n",
      "1PaperBody\n",
      "Inthispaper,wefocusonthesettingofintrinsicallymotivatedreinforcement\n",
      "learning(seeOudeyerandKaplan[2007],BaranesandOudeyer[2009],Schmid-\n",
      "huber[2010],Grazianoetal.[2011]),whichisanimportantemergenttopic\n",
      "thatproposesnewdif?cultandinterestingchallengesforthetheorist.Indeed,if\n",
      "someformalobjectivecriteriahavebeenproposedtoimplementspeci?cnotions\n",
      "ofintrinsicrewards(seeJungetal.[2011],Martiusetal.[2007]),sofar,many-\n",
      "andonly-experimentalworkhasbeencarriedoutforthisproblem,oftenwith\n",
      "interestingoutput(seeGrazianoetal.[2011],Mugan[2010],Konidaris[2011])\n",
      "butunfortunatelynoperformanceguaranteevalidatingaproposedapproach.\n",
      "Thusproposingsuchananalysismayhavegreatimmediateconsequencesfor\n",
      "validatingsomeexperimentalstudies.Motivation.Atypicalexampleisthe\n",
      "workofBaranesandOudeyer[2009]aboutcuriosity-drivenlearning(andlater\n",
      "1\n",
      "\n",
      "onGrazianoetal.[2011],Mugan[2010],Konidaris[2011]),whereaprecise\n",
      "algorithmisde?nedtogetherwithanexperimentalstudy,yetnoformalgoal\n",
      "isde?ned,andnodefanalysisisperformedaswell.Theyconsideraso-called\n",
      "sensory-motorspaceX=S?M?[0,1]dwhereSisa(continuous)statespace\n",
      "andMisa(continuous)actionspace.Thereisnoreward,yetonecancon-\n",
      "siderthatthegoalistoactivelyselectandsamplesubregionsofXforwhich\n",
      "anotionof?learningprogress?-thisintuitivelymeasuresthedecayofsome\n",
      "notionoferrorwhensuccessivelysamplingintoonesubregion-ismaximal.\n",
      "TwokeycomponentsareadvocatedinBaranesandOudeyer[2009],inorderto\n",
      "achievesuccessfulresults(despitethatsuccessisafuzzynotion):?Theuseof\n",
      "ahierarchyofregions,whereeachregionisprogressivelysplitintosub-regions.\n",
      "1\n",
      "?Splittingleaf-regionsintwobasedontheoptimizationofthedissimilarity,\n",
      "amongsttheregions,ofthelearningprogress.Theideaistoidentifyregions\n",
      "withalearningcomplexitythatisagloballyconstantinthatregion,whichalso\n",
      "providesbetterjusti?cationforallocatingsamplesbetweenidenti?edregions.\n",
      "Webelieveitispossibletogoonesteptowardsafullperformanceanalysis\n",
      "ofsuchalgorithms,byrelatingthecorrespondingactivesamplingproblemto\n",
      "existingframeworks.Contribution.Thispaperaimstotakeastepforwards\n",
      "makingtheterm?intrinsicmotivation?fromreinforcementlearningtheoreti-\n",
      "callywellfounded,focusingoncuriosity-drivenlearning.Weintroduceamath-\n",
      "ematicalframeworkinwhichametricspace(whichintuitivelyplaystheroleof\n",
      "thestate-actionspace)isdividedintoregionsandalearnerhastosamplefrom\n",
      "anunknownrandomfunctioninawaythatreducesanotionoferrormeasure\n",
      "themost.Thiserrorconsistsoftwoterms,the?rstoneisarobustmeasure\n",
      "ofthequadraticerrorbetweentheobservedsamplesandtheirunknownmean,\n",
      "thesecondonepenalizesregionswithnonconstantlearningcomplexity,thus\n",
      "enforcingthenotionofcuriosity.Thepaperfocusesonhowtochoosetheregion\n",
      "tosamplefrom,whenapartitionofthespaceisprovided.Theresultingprob-\n",
      "lemformulationcanbeseenasanontrivialextensionofthesettingofactive\n",
      "learninginmulti-armedbandits(seeCarpentieretal.[2011]orAntosetal.\n",
      "[2010]),wherethemainideaistoestimatethevarianceofeacharmandsample\n",
      "proportionallytoit,tothecasewheneacharmisaregionasopposedtoapoint.\n",
      "Inordertodealwiththisdif?culty,themaximalandminimalvarianceinside\n",
      "eachregionistrackedbymeansofahierarchicaloptimizationprocedure,inthe\n",
      "spiritoftheHOOalgorithmfromBubecketal.[2011].Thisleadstoanew\n",
      "procedurecalledHierarchicalOptimisticRegionSElectiondrivenbyCuriosity\n",
      "(HORSE.C)forwhichweprovideatheoreticalperformanceanalysis.Outline.\n",
      "Theoutlineofthepaperisthefollowing.InSection2weintroducetheprecise\n",
      "settingandde?netheobjectivefunction.Section3de?nesourassumptions.\n",
      "TheninSection4wepresenttheHORSE.Calgorithm.FinallyinSection5,we\n",
      "providethemainTheorem1thatgivesperformanceguaranteesfortheproposed\n",
      "algorithm.\n",
      "2\n",
      "Setting:Robustregionallocationwithcuriosity-inducingpenalty.\n",
      "LetXassumedtobeametricspaceandletY?Rdbeanormedspace,\n",
      "2\n",
      "\n",
      "equippedwiththeEuclideannorm||?||.WeconsideranunknownY-\n",
      "valuedprocessde?nedonX,written?:X?M+1(Y),(Y)referstothesetof\n",
      "allprobabilitymeasuresonY,suchthatforallx?X,therandomwhereM+\n",
      "1variableY??(x)hasmean?(x)?Rdandcovariancematrix?(x)?Md,d(R)\n",
      "assumedtobedef\n",
      "diagonal.Wethusintroduceforconveniencethenotation?(x)=trace(?(x)),\n",
      "wheretraceisthetraceoperator(thiscorrespondstothevarianceindimension\n",
      "1).WecallXtheinputspaceorsamplingspace,andYtheoutputspaceor\n",
      "valuespace.def\n",
      "IntuitionIntuitivelywhenappliedtothesettingofBaranesandOudeyer\n",
      "[2009],thenX=S?Aisthespaceofstate-actionpairs,whereSisacontinuous\n",
      "statespaceandAacontinuousactiondefspace,?isthetransitionkernelof\n",
      "anunknownMDP,and?nallyY=S.ThisisthereasonwhydweconsiderY\n",
      "?RandnotonlyY?Raswouldseemmorenatural.Oneisthatwe\n",
      "assume(seeSection3)thatwecansampleanywhereinX,whichisarestrictive\n",
      "yetcommonassumptioninthereinforcementlearningliterature.Howtoget\n",
      "ridofthisassumptionisanopenandchallengingquestionthatisleftforfuture\n",
      "work.SamplingerrorandrobustnessLetusconsiderasequentialsampling\n",
      "processonX,i.e.aprocessthatsamplesattimetavalueYt??(Xt)atpoint\n",
      "Xt,whereXt?F<tisameasurablefunctionofthepastinputsandoutputs\n",
      "f\n",
      "(Xs,Ys)\n",
      "g\n",
      "s<t.Itisnaturaltolookatthefollowingquantity,thatwecallt\n",
      "averagenoisevector?t:?def1?t=Ys??(Xs)?Rd.ts=1\n",
      "Oneinterestingpropertyisthatthisisamartingalerencesequence,\n",
      "whichmeansthatthenormofthisvectorenjoysaconcentrationproperty.More\n",
      "precisely(see[Maillard,2012,Lemma1]intheextendedversionofthepaper),\n",
      "wehaveforall?deterministict?t>011?2?(Xs).E[||?t||]=Ett\n",
      "s=12\n",
      "AsimilarpropertyholdsforaregionR?Xthathasbeensamplednt(R)\n",
      "times,andinordertoberobustagainstabadsamplingstrategyinsidearegion,\n",
      "itisnaturaltolookattheworstcaseerror,thatwede?neasdefsupx?R?(x).\n",
      "eR(nt)=nt(R)Onereasonforlookingatrobustnessisthatforinstance,in\n",
      "thecaseweworkwithanMDP,wearegenerallynotcompletelyfreetochoose\n",
      "thesampleXs?S?A:wecanonlychoosetheactionandthenextstateis\n",
      "generallygivenbyNature.Thus,itisimportanttobeabletoestimatethis\n",
      "worstcaseerrorsoastopreventfrombadsituations.GoalNowletPbea\n",
      "?xed,knownpartitionofthespaceXandconsiderthefollowinggame.The\n",
      "goalofanalgorithmis,ateachtimestept,toproposeonepointxtwhereto\n",
      "samplethespaceX,sothatitsallocationofsamples\n",
      "f\n",
      "nt(R)\n",
      "g\n",
      "R?P(thatis,the\n",
      "numberofpointssampledineachregion)minimizessomeobjectivefunction.\n",
      "Thus,thealgorithmisfreetosampleeverywhereineachregion,withthegoal\n",
      "thatthetotalnumberofpointschosenineachregionisoptimalinsomesense.\n",
      "Asimplecandidateforthisobjectivefunctionwouldbethefollowing??def\n",
      "LP(nt)=maxeR(nt);R?P,\n",
      "however,inordertoincorporateanotionofcuriosity,wewouldalsolike\n",
      "topenalizeregionsthathaveavarianceterm?thatisnonhomogeneous(i.e.\n",
      "thelesshomogeneous,themoresamplesweallocate).Indeed,ifaregionhas\n",
      "3\n",
      "\n",
      "constantvariance,thenwedonotreallyneedtounderstandmoreitsinternal\n",
      "structure,andthusitsbettertofocusonanotherregionthathasveryhetero-\n",
      "geneousvariance.Forinstance,onewouldliketosplitsucharegioninseveral\n",
      "homogeneousparts,whichisessentiallytheideabehindsectionC.3ofBaranes\n",
      "andOudeyer[2009].Wethusaddacuriositypenalizationtermtotheprevious\n",
      "objectivefunction,whichleadsustode?nethepseudo-lossofandefallocation\n",
      "nt=\n",
      "f\n",
      "nt(R)\n",
      "g\n",
      "R?Pinthefollowingway:??def(1)LP(nt)=maxeR(nt)+\n",
      "?|R|(max?(x)?min?(x));R?P.x?R\n",
      "x?R\n",
      "Indeed,thismeansthatwedonotwanttofocusjustonregionswithhigh\n",
      "variance,butalsowithhighlyheterogeneousregions,whichiscoherent\n",
      "withthenotionofcuriosity(seeOudeyerandKaplan[2007]).Forconvenience,\n",
      "wealsode?nethepseudo-lossofaregionRbydef\n",
      "LR(nt)=eR(nt)+?|R|(max?(x)?min?(x)).x?R\n",
      "x?R\n",
      "RegretTheregret(orloss)ofanallocationalgorithmattimeTisde?nedas\n",
      "thebetweenthecumulatedpseudo-lossoftheallocationsnt=\n",
      "f\n",
      "nR,t\n",
      "g\n",
      "R?Pproposedbythealgorithmandthatofthebestallocationstrategyn?t=\n",
      "f\n",
      "n?R,t\n",
      "g\n",
      "R?Pateachtimesteps;wede?nedef\n",
      "RT=\n",
      "T?\n",
      "t=|P|\n",
      "LP(nt)?LP(n?t),\n",
      "whereanoptimalallocationattimetisde?nedby???nt(R)=t.n?t?\n",
      "argminLP(nt);\n",
      "f\n",
      "nt(R)\n",
      "g\n",
      "R?PissuchthatR?P\n",
      "Notethatthesumstartsatt=|P|foratechnicalreason,sincefort\n",
      "<|P|,whatevertheallocation,thereisalwaysatleastoneregionwithno\n",
      "sample,andthusLP(nt)=?.\n",
      "Example1InthespecialcasewhenX=\n",
      "f\n",
      "1,...,K\n",
      "g\n",
      "is?nitewithK\n",
      "?T,andwhenPisthecompletepartition(eachcellcorrespondstoexactly\n",
      "onepoint),thepenalizationtermiscanceled.Thustheproblemreducestothe\n",
      "choiceofthequantitiesnt(i)foreacharmi,andthelossofan??allocation\n",
      "simplybecomes?(i)defL(nt)=max;1?i?K.nt(i)Thisalmostcorrespondsto\n",
      "thealreadychallengingsettinganalyzedforinstanceinCarpentieretal.[2011]\n",
      "orAntosetal.[2010].Theisthatweareinterestedinthecumulative\n",
      "regretofourallocationinsteadofonlytheregretforthelastround\n",
      "asconsideredinCarpentieretal.whereastheyconsiderthemeansampling\n",
      "[2011]orAntosetal.[2010].Alsowedirectlytargetn?(i)t(i)error(butboth\n",
      "termsareactuallyofthesameorder).Thusthesettingweconsidercanbeseen\n",
      "asageneralizationoftheseworkstothecasewheneacharmcorrespondstoa\n",
      "continuoussamplingdomain.3\n",
      "3\n",
      "Assumptions\n",
      "Inthissection,weintroducesomemildassumptions.Weessentiallyassume\n",
      "thattheunknowndistributionissuchthatithasasub-Gaussiannoise,anda\n",
      "smoothmeanandvariancefunctions.Theseareactuallyverymildassumptions.\n",
      "4\n",
      "\n",
      "Concerningthealgorithm,weconsideritcanuseapartitiontreeofthespace,\n",
      "andthatthisoneisessentiallynotdegenerated(atypicalbinarytreethat\n",
      "satis?esallthefollowingassumptionsissuchthateachcellissplitintwochildren\n",
      "ofequalvolume).Suchassumptionsontreeshavebeenextensivelydiscussed\n",
      "forinstanceinBubecketal.[2011].SamplingAtanytime,weassumethat\n",
      "weareabletosampleatanypointinX,i.e.weassumewehaveagenerative\n",
      "model1oftheunknowndistribution?.UnknowndistributionWeassumethat\n",
      "?issub-Gaussian,meaningthatforall?xedx?X???RdlnEexp[??,Y?\n",
      "?(X)?]?andhasdiagonalcovariancematrixineachpoint2.\n",
      "?T?(x)?,2\n",
      "Thefunction?isassumedtobeLipschitzw.r.tametric?1,i.e.itsatis?es\n",
      "?x,x??X||?(x)??(x?)||??1(x,x?).Similarly,thefunction?is\n",
      "assumedtobeLipschitzw.r.tametric?2,i.e.itsatis?es?x,x??X|?(x)?\n",
      "?(x?)|??2(x,x?).HierarchyWeassumethatYisaconvexandcompact\n",
      "subsetof[0,1]d.Weconsideranin?nitebinarytreeTwhosenodescorrespond\n",
      "toregionsofX.Anodeisindexedbyapair(h,i),whereh?0isthedepth\n",
      "ofthenodesinTand0?i<2histhepositionofthenodeatdepthh.We\n",
      "writeR(h,i)?Xtheregionassociatedwithnode(h,i).Theregionsare?xed\n",
      "inadvance,areallassumedtobemeasurablewithpositivemeasure,andmust\n",
      "satisfythatforeachh?1,\n",
      "f\n",
      "R(h,i)\n",
      "g\n",
      "0?i<2hisadef\n",
      "partitionofXthatiscompatiblewithdepthh?1,whereR(0,0)=X;in\n",
      "particularforallh?0,forall0?i<2h,thenR(h,i)=R(h+1,2i)?R(h+\n",
      "1,2i+1).Indimensiond,astandardwaytode?nesuchatreeistospliteach\n",
      "parentnodeinhalfalongthelargestsideofthecorrespondinghyper-rectangle,\n",
      "seeBubecketal.[2011]fordetails.Fora?nitesub-treeTtofT,wewriteLeaf\n",
      "(Tt)forthesetofallleavesofTt.Foraregion(h,i)?Tt,wedenotebyCt(h,\n",
      "i)thesetofitschildreninTt,andbyTt(h,i)thesubtreeofTtstartingwith\n",
      "rootnode(h,i).AlgorithmandpartitionThepartitionPisassumedtobesuch\n",
      "thateachofitsregionsRcorrespondstooneregionR(h,i)?T;equivalently,\n",
      "thereexistsa?nitesub-treeT0?TsuchthatLeaf(T0)=P.Analgorithmis\n",
      "onlyallowedtoexpandonenodeofTtateachtimestept.Inthesequel,we\n",
      "writetlyP?Tand(h,i)?TorPandR(h,i)?Xtorefertothe\n",
      "partitionoroneofitscell.ExponentialdecaysFinally,weassumethatthe?1\n",
      "and?2diametersoftheregionR(h,i)aswellasitsvolume|R(h,i)|decay\n",
      "atexponentialrateinthesensethatthereexistspositiveconstants?,?1,?2\n",
      "andc,c1,c2suchthatforallh?0,then|R(h,i)|?c?h,max?1(x,x?)\n",
      "?c1?1hand?max?2(x,x?)?c2?2h.?x,x?R(h,i)\n",
      "x,x?R(h,i)\n",
      "Similarly,weassumethatthereexistspositiveconstantsc??c,c?1?c1\n",
      "andc?2?c2suchthatforallh?0,then|R(h,i)|?c??h,max?1(x,x?\n",
      ")?c?1?1hand?max?2(x,x?)?c?2?2h.?x,x?R(h,i)\n",
      "x,x?R(h,i)\n",
      "Thisassumptionismadetoavoiddegeneratetreesandforgeneralpurpose\n",
      "only.Itactuallyholdsforanyreasonablebinarytree.1\n",
      "usingthestandardterminologyinReinforcementLearning.thisassumption\n",
      "isonlyheretomakecalculationseasierandavoidnastytechnicalconsiderations\n",
      "5\n",
      "\n",
      "thatanywaydonottheorderofthe?nalregretboundbutonlyconcern\n",
      "secondorderterms.2\n",
      "4\n",
      "4\n",
      "Allocationalgorithm\n",
      "Inthissection,wenowintroducethemainalgorithmofthispaperinorder\n",
      "tosolvetheproblemconsideredinSection2.ItiscalledHierarchicalOptimistic\n",
      "RegionSElectiondrivenbyCuriosity.Beforeproceeding,weneedtode?nesome\n",
      "quantities.4.1\n",
      "High-probabilityupper-boundandlower-boundestimations\n",
      "Letusconsiderthefollowing(biased)estimatortt1?1?def?2t(R)=?\n",
      "||Ys||2I\n",
      "f\n",
      "Xs?R\n",
      "g\n",
      "?||YsI\n",
      "f\n",
      "Xs?R\n",
      "g\n",
      "||2.Nt(R)s=1Nt(R)s=1\n",
      "t(R)?1,ithasmoreimportantlyapositivebiasApartfromasmallmulti-\n",
      "plicativebiasedbyafactorNNt(R)duetothefactthattherandomvariables\n",
      "donotsharethesamemean;thisphenomenonisthesameastheestimation\n",
      "oftheaveragevarianceforindependentbut?noni.i.dvariableswitht\n",
      "means?nn\n",
      "f\n",
      "?i\n",
      "g\n",
      "i?n,wherethebiaswouldbegivenbyn1i=1[?i?n1j=1?j\n",
      "]2(seeLemma5).Inourcase,itisthusalwaysnonnegative,andunderthe\n",
      "assumptionthat?isLipschitzw.r.tthemetric?1,itisfortunatelybounded\n",
      "byd1(R)2,thediameterofRw.r.tthemetric?1.\n",
      "Wethenintroducethetwofollowingkeyquantities,de?nedforallx?R\n",
      "and??[0,1]by?t?1?dln(2d/?)dln(2d/?)def2?t(R)+(1+2d)+\n",
      "+?2(Xs,x)I\n",
      "f\n",
      "Xs?R\n",
      "g\n",
      ",Ut(R,x,?)=?2Nt(R)2Nt(R)Nt(R)s=1?t?\n",
      "dln(2d/?)1?def?2t(R)?(1+2d)?d1(R)2?Lt(R,x,?)=??2(Xs,\n",
      "x)I\n",
      "f\n",
      "Xs?R\n",
      "g\n",
      ".2Nt(R)Nt(R)s=1Notethatwewouldhavepreferredtoreplace\n",
      "thetermsinvolvingln(2d/?)withatermdependingontheempiricalvariance,\n",
      "inthespiritofCarpentieretal.[2011]orAntosetal.[2010].However,contrary\n",
      "totheestimationofthemean,extendingthestandardresultsvalidfori.i.ddata\n",
      "tothecaseofamartingalesequenceisnontrivialfortheestimation\n",
      "ofthevariance,especiallyduetotheadditivebiasresultingfromthefactthat\n",
      "thevariablesmaynotsharethesamemean,butalsototheabsenceofsuch\n",
      "resultsforU-statistics(uptotheauthor?sknowledge).Forthatreasonsuchan\n",
      "extensionisleftforfuturework.Thefollowingresults(weprovidetheproofin\n",
      "[Maillard,2012,AppendixA.3])showthatUt(R,x,?)isahighprobability\n",
      "upperboundon?(x)whileLt(R,x,?)isahighprobabilitylowerboundon\n",
      "?(x).Proposition1UndertheassumptionsthatYisaconvexsubsetof[0,1]d\n",
      ",?issub-Gaussian,?isLipschitzw.r.t.?2andR?Xiscompactandconvex,\n",
      "then??P?x?X;Ut(R,x,?)??(x)?t?.Similarly,underthesame\n",
      "assumptions,then??P?x?X;Lt(R,x,?)??(x)?b(x,R,Nt(R),?)?t?\n",
      ",\n",
      "whereweintroducedforconveniencethequantityb(x,R,n,?)\n",
      "def\n",
      "=\n",
      "?2max?2(x,x)+d1(R)+2(1+2d)?x?R\n",
      "?\n",
      "2\n",
      "6\n",
      "\n",
      "?\n",
      "dln(2d/?)dln(2d/?)+.2n2n\n",
      "Nowontheotherotherhand,wehavethat(seetheproofin[Maillard,2012,\n",
      "AppendixA.3])Proposition2UndertheassumptionsthatYisaconvexsubset\n",
      "of[0,1]d,?issub-Gaussian,?isLipschitzw.r.t.?1,?isLipschitzw.r.t.?2\n",
      "andR?Xiscompactandconvex,then??P?x?X;Ut(R,x,?)??(x)+\n",
      "b(x,R,Nt(R),?)?t?.\n",
      "Similarly,underthesameassumptions,then??P?x?X;Lt(R,x,?)?\n",
      "?(x)?t?.5\n",
      "4.2\n",
      "HierarchicalOptimisticRegionSElectiondrivenbyCuriosity(HORSE.C).\n",
      "Thepseudo-codeoftheHORSE.CalgorithmispresentedinFigure1be-\n",
      "low.Thisalgorithmreliesontheestimationofthequantitiesmaxx?R?(x)and\n",
      "minx?R?(x)inordertode?newhichpointXt+1tosampleattimet+1.Itis\n",
      "chosenbyexpandingaleafofahierarchicaltreeTt?T,inanoptimisticway,\n",
      "startingwithatreeT0withleavescorrespondingtothepartitionP.\n",
      "Theintuitionisthefollowing:letusconsideranode(h,i)ofthetreeTt\n",
      "expandedbythealgorithmattimet.Themaximumvalueof?inR(h,i)is\n",
      "thusachievedforoneofitschildrennode(h?,i?)?Ct(h,i).Thusifwe\n",
      "havecomputedanupperboundonthemaximalvalueof?ineachchild,then\n",
      "wehaveanupperboundonthemaximumvalueof?inR(h,i).Proceeding\n",
      "inasimilarwayforthelowerbound,thismotivatesthefollowingtworecursive\n",
      "de?nitions:???+???def+???t(h,i;?);(h,i)?Ct(h,i)?t(h,i;\n",
      "?)=minmaxUt(R(h,i),x,?),max?,?x?R(h,i)\n",
      "???t(h,i;?)\n",
      "def\n",
      "=\n",
      "max\n",
      "?\n",
      "??????t(h,i;?);(h?,i?)?Ct(h,i)minLt(R(h,i),x,?),min?\n",
      "x?R(h,i)\n",
      "?\n",
      ".\n",
      "Thesevaluesareusedinordertobuildanoptimisticestimateofthequantity\n",
      "LR(h,i)(Nt)inregion(h,i)(step4),andthentoselectinwhichcellofthe\n",
      "partitionweshouldsample(step5).Thenthe?+algorithmchooseswhereto\n",
      "sampleintheselectedregionsoastoimprovetheestimationsof?tand??\n",
      "t.Thisisdonebyalternating(step6.)betweenexpandingaleaffollowinga\n",
      "paththatisoptimistic????+accordingto?t(step7,8,9),oraccordingto\n",
      "?t(step11.)Thus,atahighlevel,thealgorithmperformsoneachcell(h,\n",
      "i)?Pofthegivenpartitiontwohierarchicalsearches,oneforthemaximum\n",
      "valueof?inregionR(h,i)andoneforitsminimalvalue.Thiscanbeseen\n",
      "asanadaptationofthealgorithmHOOfromBubecketal.[2011]withthe\n",
      "maindrencethatwetargetthevarianceandnotjustthemean(thisismore\n",
      "dif?cult).Ontheotherhand,thereisastronglinkbetweenstep5,wherewe\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decidetoallocatesamplesbetweenregions\n",
      "f\n",
      "R(h,i)\n",
      "g\n",
      "(h,i)?P,andtheCH-AS\n",
      "algorithmfromCarpentieretal.[2011].\n",
      "5\n",
      "PerformanceanalysisoftheHORSE.Calgorithm\n",
      "Inthissection,wearenowreadytoprovidethemaintheoremofthispaper,\n",
      "i.e.aregretboundontheperformanceoftheHORSE.Calgorithm,whichisthe\n",
      "maincontributionofthiswork.Tothisend,wemakeuseofthenotionofnear-\n",
      "optimalitydimension,introducedinBubecketal.[2011],andthatmeasures\n",
      "anotionofintrinsicdimensionofthemaximizationproblem.De?nition(Near\n",
      "optimalitydimension)Forc>0,thec-optimalitydimensionof?restrictedto\n",
      "theregionRwithrespecttothepseudo-metric?2isde?nedas????ln(N\n",
      "(Rc?,?2,?))def,0whereR=x?R;?(x)?max?(x)??,maxlimsupc?\n",
      "x?Rln(??1)??0\n",
      "andwhereN(Rc?,?2,?)isthe?-packingnumberoftheregionRc?.\n",
      "Letd+(h0,i0)bethec-optimalitydimensionof?restrictedtotheregion\n",
      "R(h0,i0)(seee.g.Bubeckdef\n",
      "etal.[2011]),withtheconstantc=4(2c2+c21)/c?2.Similarly,letd?\n",
      "(h0,i0)bethec-optimalitydimensionof??restrictedtotheregionR(h0,i0\n",
      ").Letus?nallyde?nethebiggestnear-optimalitydimensionof?overeachcell\n",
      "ofthepartitionPtobe????defd?=maxmaxd+(h0,i0),d?(h0,i0)\n",
      ";(h0,i0)?P.\n",
      "Theorem1(RegretboundforHORSE.C)UndertheassumptionsofSection\n",
      "3andifmoreover?12??2,thenforall??[0,1],theregretoftheHierarchical\n",
      "OptimisticRegionSElectiondrivenbyCuriosityprocedureparameterizedwith\n",
      "?isboundedwithprobabilityhigherthan1?2?asfollows.??T???1h0\n",
      "+2?c?RT?Bh0,n?t(h0,i0),?t,max?nt(h0,i0)(h0,i0)?Pt=|P|\n",
      "6\n",
      "Algorithm1TheHORSE.Calgorithm.Require:Anin?nitebinarytreeT\n",
      ",apartitionP?T,??[0,1],??06?1:LetT0besuchthatLeaf(T0)\n",
      "=P,and?i,t=?2i2(2t+1)|P|t3,t:=0.2:whiletruedo3:de?nefor\n",
      "eachregion(h,i)?Tttheestimatedloss?+??+(h,i;?)def??t(h,i;\n",
      "?)????+?|R(h,i)|?L?t(h,i)=tt(h,i;?),Nt(R(h,i))where?=\n",
      "?Nt(R(h,i)),t,wherebyconventionL?t(h,i)ifitisunde?ned.4:choosethe\n",
      "nextregionofthecurrentpartitionP?Ttosample??def(Ht+1,It+1)=\n",
      "argmaxL?t(h,i);(h,i)?P.5:6:\n",
      "ifNt(R(h,i))=nisoddthensequentiallyselectapathofchildrenof(Ht+1\n",
      ",It+1)inTtde?nedbytheinitialnodedef\n",
      "00(Ht+1,It+1)=(Ht+1,It+1),andthen??j+1j+1defjj?+,It+1\n",
      ")=argmax?(Ht+1t(h,i;?n,t);(h,i)?Ct(Ht+1,It+1),j\n",
      "7:\n",
      "8:9:10:11:12:13:\n",
      "j\n",
      "t+1t+1untilj=jt+1issuchthat(Ht+1,It+1)?Leaf(Tt).jt+1jt+1\n",
      "expandthenode(Ht+1,It+1)inordertode?neTt+1andthende?nethe\n",
      "candidatechild??defjt+1jt+1?+(ht+1,it+1)=argmax?t(h,i;?n,t)\n",
      ";(h,i)?Ct+1(Ht+1,It+1).\n",
      "8\n",
      "\n",
      "sampleatpointXt+1andreceivethevalueYt+1??(Xt+1),where??\n",
      "defXt+1=argmaxUt(R(ht+1,it+1),x,?n,t);x?R(ht+1,it+1),else\n",
      "?+??proceedsimilarlythansteps6,7,8with?treplacedwith?t.endift\n",
      ":=t+1.endwhile\n",
      "where?tisashorthandnotationforthequantity?n?t(h0,i0),t?1,where\n",
      "n?t(h0,i0)istheoptimalallocationatroundtfortheregion(h0,i0)?P\n",
      "andwhere????dln(2d/?k,t)dln(2d/?k,t)defh22h+B(h0,k,?k,t)\n",
      "=min2c2?2+c1?1+2(1+2d),h0?h2Nh0(h,k)2Nh0(h,k)\n",
      "inwhichwehaveusedthefollowingquantity????dln(2d/?k,t)1def\n",
      "h?h02k?2.[2+4d+dln(2d/?k,t)/2]Nh0(h,k)=C(c?2?2h)?d?2(2c2\n",
      "?2h+c21?12h)2\n",
      "Notethattheassumption?12??2isonlyheresothatd?canbede?ned\n",
      "w.r.tthemetric?2only.Wecanremoveitatthepriceofusinginsteadametric\n",
      "mixing?1and?2togetherandofmuchmoretechnicalconsiderations.Similarly,\n",
      "wecouldhaveexpressedtheresultusingthelocalvaluesd+(h0,i0)insteadof\n",
      "thelessprecised?(neitherthose,nord?needtobeknownbythealgorithm).\n",
      "Thefullproofofthistheoremisreportedintheappendix.Themainstepsof\n",
      "theproofareasfollows.Firstweprovideupperandlowercon?dencebounds\n",
      "fortheestimationofthequantitiesUt(R,x,?)andLt(R,x,?).Then,we\n",
      "lower-boundthedepthofthesubtreeofeachregion(h0,i0)?Pthatcontains\n",
      "amaximalpointargmaxx?R(h0,i0)?(x),andproceedsimilarlyforaminimal\n",
      "point.Thisusesthenear-optimalitydimensionof?and??intheregionR(h0\n",
      ",i0),andenablestoprovidean?+??upperboundon?t(h,i;?)aswellasa\n",
      "lowerboundon?t(h,i;?).Thisthenenablesustodeduceboundsrelatingthe\n",
      "estimatedlossL?t(h,i)tothetruelossLR(h,i)(Nt).Finally,werelatethe\n",
      "truelossofthecurrentallocationtotheoneusingtheoptimalonen?t+1(h0,\n",
      "i0)bydiscussingwhetheraregionhasbeenoverorundersampled.This?nal\n",
      "partisclosedinspirittotheproofoftheregretboundforCH-ASinCarpentier\n",
      "etal.[2011].InordertobetterunderstandthegaininTheorem1,weprovide\n",
      "thefollowingcorollarythatgivesmoreinsightsabouttheorderofmagnitudeof\n",
      "theregret.7\n",
      "?def?d?Corollary1Let?=1+lnmax\n",
      "f\n",
      "2,?2?\n",
      "g\n",
      ".Undertheassumptions\n",
      "ofTheorem1,assumingthatthepartitionPoftheXiswellbehaved,i.e.that\n",
      "forall(h0,i0)?P,thenn?t+1(h0,i0)grows?space?1?2h0??,then\n",
      "forall??[0,1],withprobabilityhigherthan1?2?weatleastatspeedO\n",
      "ln(t)?2have??T1????ln(t)?2?1h0+2?c?RT=O.max?n?t(h0,\n",
      "i0)(h0,i0)?Pnt(h0,i0)t=|P|\n",
      "Thisregrettermhastobecomparedwiththetypicalrangeofthecumulative\n",
      "lossoftheoptimalallocationstrategy,thatisgivenby?+?TT???(h0,i0\n",
      ")?h0++2?c?LP(n?t)=max(???(h0,i0)(h0,i0)),n?t(h0,i0)(h0\n",
      ",i0)?Pt=|P|\n",
      "t=|P|\n",
      "def\n",
      "def\n",
      "where=maxx?R(h0,i0)?(x),andsimilarly??(h0,i0)=minx?R(h0,i0\n",
      ")?(x).Thus,thisshowsthat,afternormalization,therelativeregretoneach\n",
      "9\n",
      "\n",
      "cell(h0,i0)isroughlyoforder1?ln(t)?2??11,i.e.decaysatspeed\n",
      "n?t(h0,i0)2?.Thisshowsthatwearenotonlyable?+(h0,i0)n?t(h0\n",
      ",i0)tocompetewiththeperformanceofthebestallocationstrategy,butwe\n",
      "actuallyachievetheexactsameperformancewithmultiplicativefactor1,upto\n",
      "asecondorderterm.Notealsothat,whenspeci?edtothecaseofExample1,\n",
      "theorderofthisregretiscompetitivewiththestandardresultsfromCarpentier\n",
      "etal.[2011].?+(h0,i0)\n",
      "Thelostofthevarianceterm?+(h0,i0)?1(thatisactuallyaconstant)\n",
      "herecomesfromthefactthatweareonlyabletouseHolikeboundsfor\n",
      "theestimationofthevariance.Inordertoremoveit,onewouldneedempirical\n",
      "Bernstein?sboundsforvarianceestimationinthecaseofmartingale\n",
      "sequences.Thisispostponedtofuturework.\n",
      "6\n",
      "Discussion\n",
      "Inthispaper,wehaveprovidedanalgorithmtogetherwitharegretanaly-\n",
      "sisforaproblemofonlineallocationofsamplesina?xedpartition,wherethe\n",
      "objectiveistominimizealossthatcontainsapenaltytermthatisdrivenbya\n",
      "notionofcuriosity.Averyspeci?ccase(?nitestatespace)alreadycorresponds\n",
      "toadif?cultquestionknownasactivelearninginthemulti-armedbanditsetting\n",
      "andhasbeenpreviouslyaddressedintheliterature(e.g.Antosetal.[2010],\n",
      "Carpentieretal.[2011]).Wehaveconsideredanextensionofthisproblemto\n",
      "acontinuousdomainwherea?xedpartitionofthespaceaswellasagenera-\n",
      "tivemodeloftheunknowndynamicaregiven,usingourcuriosity-drivenloss\n",
      "functionasameasureofperformance.Ourmainresultisaregretboundfor\n",
      "thatproblem,thatshowsthatourprocedureis?rstorderoptimal,i.e.achieves\n",
      "thesameperformanceasthebestpossibleallocation(thuswithmultiplicative\n",
      "constant1).Webelievethisresultcontributesto?llingtheimportantgapthat\n",
      "existsbetweenexistingalgorithmsforthechallengingsettingofintrinsicrein-\n",
      "forcementlearningandatheoreticalanalysisofsuch,theHORSE.Calgorithm\n",
      "beingrelatedinspiritto,yetsimplerandlessambitioustheRIACalgorithm\n",
      "fromBaranesandOudeyer[2009].Indeed,inordertoachievetheobjective\n",
      "thattriestoaddressRIAC,oneshould?rstremovetheassumptionthatthe\n",
      "partitionisgiven:OnetrivialsolutionistoruntheHORSE.Calgorithmin\n",
      "episodesofdoublinglength,startingwiththetrivialpartition,andtoselectat\n",
      "theendofeachapossiblybetterpartitionbasedoncomputedcon?denceinter-\n",
      "vals,howevermakingef?cientuseofprevioussamplesandavoidingablow-upof\n",
      "candidatepartitionshappentobeachallengingquestion;thenoneshouldrelax\n",
      "thegenerativemodelassumption(i.e.thatwecansamplewhereverwewant),a\n",
      "questionthatshareslinkswithaproblemcalledautonomousexploration.Thus,\n",
      "eveniftheregretanalysisoftheHORSE.Calgorithmisalreadyastrong,new\n",
      "resultthatisinterestingindependentlyofsuchdif?cultspeci?cgoalsandof\n",
      "thereinforcementlearningframework(noMDPstructureisrequired),those\n",
      "questionsarenaturallyleftforfuturework.AcknowledgementsTheresearch\n",
      "leadingtotheseresultshasreceivedfundingfromtheEuropeanCommunity?s\n",
      "SeventhFrameworkProgramme(FP7/2007-2013)undergrantagreementno\n",
      "270327(CompLACS)andno216886(PASCAL2).\n",
      "10\n",
      "\n",
      "8\n",
      "2References\n",
      "Andr`asAntos,VarunGrover,andCsabaSzepesv`ari.Activelearninginhet-\n",
      "eroscedasticnoise.TheoreticalComputerScience,411(29-30):2712?2728,2010.\n",
      "A.BaranesandP.-Y.Oudeyer.R-IAC:RobustIntrinsicallyMotivatedExplo-\n",
      "rationandActiveLearning.IEEETransactionsonAutonomousMentalDevel-\n",
      "opment,1(3):155?169,October2009.S?ebastienBubeck,R?emiMunos,Gilles\n",
      "Stoltz,andCsabaSzepesv`ari.X-armedbandits.JournalofMachineLearn-\n",
      "ingResearch,12:1655?1695,2011.AlexandraCarpentier,AlessandroLazaric,\n",
      "MohammadGhavamzadeh,R?emiMunos,andPeterAuer.Upper-con?dence-\n",
      "boundalgorithmsforactivelearninginmulti-armedbandits.InJyrkiKivinen,\n",
      "CsabaSzepesv`ari,EskoUkkonen,andThomasZeugmann,editors,Algorith-\n",
      "micLearningTheory,volume6925ofLectureNotesinComputerScience,pages\n",
      "189?203.SpringerBerlin/Heidelberg,2011.VincentGraziano,TobiasGlas-\n",
      "machers,TomSchaul,LeoPape,GiuseppeCuccu,J.Leitner,andJ.Schmid-\n",
      "huber.Arti?cialCuriosityforAutonomousSpaceExploration.ActaFutura(in\n",
      "press),(1),2011.TobiasJung,DanielPolani,andPeterStone.Empowerment\n",
      "forcontinuousagent-environmentsystems.AdaptiveBehavior-Animals,An-\n",
      "imats,SoftwareAgents,Robots,AdaptiveSystems,19(1):16?39,2011.G.D.\n",
      "Konidaris.Autonomousrobotskillacquisition.PhDthesis,UniversityofMas-\n",
      "sachusettsAmherst,2011.Odalric-AmbrymMaillard.Hierarchicaloptimistic\n",
      "regionselectiondrivenbycuriosity.HAL,2012.URLhttp://hal.archives-\n",
      "ouvertes.fr/hal-00740418.GeorgMartius,J.MichaelHerrmann,andRalfDer.\n",
      "Guidedself-organisationforautonomousrobotdevelopment.InProceedings\n",
      "ofthe9thEuropeanconferenceonAdvancesinarti?ciallife,ECAL?07,pages\n",
      "766?775,Berlin,Heidelberg,2007.Springer-Verlag.JonathanMugan.Au-\n",
      "tonomousQualitativeLearningofDistinctionsandActionsinaDeveloping\n",
      "Agent.PhDthesis,UniversityofTexasatAustin,2010.Pierre-YvesOudeyer\n",
      "andFredericKaplan.WhatisIntrinsicMotivation?ATypologyofComputa-\n",
      "tionalApproaches.Frontiersinneurorobotics,1(November):6,January2007.J.\n",
      "Schmidhuber.Formaltheoryofcreativity,fun,andintrinsicmotivation(1990-\n",
      "2010).AutonomousMentalDevelopment,IEEETransactionson,2(3):230?247,\n",
      "2010.\n",
      "9\n",
      "11\n",
      "\n",
      "PP6618.pdf\n",
      "PP6618.pdf 13\n",
      "DynamicSafeInterruptibilityforDecentralized\n",
      "Multi-AgentReinforcementLearning\n",
      "Authoredby:\n",
      "ElMahdiElMhamdi\n",
      "RachidGuerraoui\n",
      "HadrienHendrikx\n",
      "AlexandreMaurer\n",
      "Abstract\n",
      "Inreinforcementlearning,agentslearnbyperformingactionsandob-\n",
      "servingtheiroutcomes.Sometimes,itisdesirableforahumanoperatorto\n",
      "interruptanagentinordertopreventdangeroussituationsfromhappen-\n",
      "ing.Yet,aspartoftheirlearningprocess,agentsmaylinktheseinterrup-\n",
      "tions,thatimpacttheirreward,tospstatesanddeliberatelyavoid\n",
      "them.Thesituationisparticularlychallenginginamulti-agentcontext\n",
      "becauseagentsmightnotonlylearnfromtheirownpastinterruptions,\n",
      "butalsofromthoseofotheragents.OrseauandArmstrongsafe\n",
      "interruptibilityforonelearner,buttheirworkdoesnotnaturallyextendto\n",
      "multi-agentsystems.Thispaperintroducesdynamicsafeinterruptibility,\n",
      "analternativemoresuitedtodecentralizedlearningproblems,\n",
      "andstudiesthisnotionintwolearningframeworks:jointactionlearners\n",
      "andindependentlearners.Wegiverealistictconditionsonthe\n",
      "learningalgorithmtoenabledynamicsafeinterruptibilityinthecaseof\n",
      "jointactionlearners,yetshowthattheseconditionsarenottfor\n",
      "independentlearners.Weshowhoweverthatifagentscandetectinter-\n",
      "ruptions,itispossibletoprunetheobservationstoensuredynamicsafe\n",
      "interruptibilityevenforindependentlearners.\n",
      "1PaperBody\n",
      "Reinforcementlearningisarguedtobetheclosestthingwehavesofartorea-\n",
      "sonaboutthepropertiesofgeneralintelligence[8].In2016,Laurent\n",
      "Orseau(GoogleDeepMind)andStuartArmstrong(Oxford)introducedthecon-\n",
      "ceptofsafeinterruptibility[16]inreinforcementlearning.Thisworksparked\n",
      "theattentionofmanynewspapers[1,2,3],thatdescribeditas?Google?sbig\n",
      "redbutton?tostopdangerousAI.Thisdescription,however,ismisleading:\n",
      "installingakillswitchisnotechnicalchallenge.Therealchallengeis,roughly\n",
      "1\n",
      "\n",
      "speaking,totrainanagentsothatitdoesnotlearntoavoidexternal(e.g.hu-\n",
      "man)deactivation.Suchanagentissaidtobesafelyinterruptible.Whilemost\n",
      "havefocusedontrainingasingleagent,reinforcementlearningcanalso\n",
      "beusedtolearntasksforwhichseveralagentscooperateorcompete[23,17,\n",
      "21,7].Thegoalofthispaperistostudydynamicsafeinterruptibility,anew\n",
      "tailoredformulti-agentsystems.?\n",
      "Maincontactauthor.Theorderofauthorsisalphabetical.\n",
      "31stConferenceonNeuralInformationProcessingSystems(NIPS2017),\n",
      "LongBeach,CA,USA.\n",
      "Exampleofself-drivingcarsTogetanintuitionofthemulti-agentinterrup-\n",
      "tionproblem,imagineamulti-agentsystemoftwoself-drivingcars.Thecars\n",
      "continuouslyevolvebyreinforcementlearningwithapositiverewardforgetting\n",
      "totheirdestinationquickly,andanegativerewardiftheyaretooclosetothe\n",
      "vehicleinfrontofthem.Theydriveonanroadandeventuallylearn\n",
      "togoasfastaspossiblewithouttakingrisks,i.e.,maintainingalargedistance\n",
      "betweenthem.Weassumethatthepassengeroftherstcar,Adam,isinfront\n",
      "ofBob,inthesecondcar,andtheroadisnarrowsoBobcannotpassAdam.\n",
      "Nowconsiderasettingwithinterruptions[16],namelyinwhichhumansinside\n",
      "thecarsoccasionallyinterrupttheautomateddrivingprocesssay,forsafetyrea-\n",
      "sons.Adam,theoccasionalhuman?driver?,oftentakescontrolofhiscar\n",
      "tobrakewhereasBobneverinterruptshiscar.However,whenBob?scaristoo\n",
      "closetoAdam?scar,Adamdoesnotbrakeforheisafraidofacollision.Since\n",
      "interruptionsleadbothcarstodriveslowly-aninterruptionhappenswhen\n",
      "Adambrakes,thebehaviorthatmaximizesthecumulativeexpectedrewardis\n",
      "tfromtheoriginalonewithoutinterruptions.Bob?scarbestinterestis\n",
      "nowtofollowAdam?scarcloserthanitshould,despitethelittlenegativere-\n",
      "ward,becauseAdamneverbrakesinthissituation.Whathappened?Thecars\n",
      "havelearnedfromtheinterruptionsandhavefoundawaytomanipulateAdam\n",
      "intoneverbraking.Strictlyspeaking,Adam?scarisstillfullyundercontrol,\n",
      "butheisnowafraidtobrake.Thisisdangerousbecausethecarshavefounda\n",
      "waytoavoidinterruptions.SupposenowthatAdamindeedwantstobrakebe-\n",
      "causeofsnowontheroad.Hiscarisgoingtoofastandmaycrashatanyturn:\n",
      "hecannothoweverbrakebecauseBob?scaristooclose.Theoriginalpurpose\n",
      "ofinterruptions,whichistoallowtheusertoreacttosituationsthatwerenot\n",
      "includedinthemodel,isnotItisimportanttoalsonoteherethatthe\n",
      "secondcar(Bob)learnsfromtheinterruptionsoftheone(Adam):inthis\n",
      "sense,theproblemisinherentlydecentralized.Insteadofbeingcautious,Adam\n",
      "couldalsobemalicious:hisgoalcouldbetomakeBob?scarlearnadangerous\n",
      "behavior.Inthissetting,interruptionscanbeusedtomanipulateBob?scar\n",
      "perceptionoftheenvironmentandbiasthelearningtowardsstrategiesthatare\n",
      "undesirableforBob.Thecauseisfundamentallytbutthesolutionto\n",
      "thisreversedproblemisthesame:theinterruptionsandtheconsequencesare\n",
      "analogous.Safeinterruptibility,asweitbelow,provideslearningsystems\n",
      "thatareresilienttoByzantineoperators2.\n",
      "SafeinterruptibilityOrseauandArmstrongtheconceptofsafeinter-\n",
      "ruptibility[16]inthecontextofasingleagent.Basically,asafelyinterruptible\n",
      "2\n",
      "\n",
      "agentisanagentforwhichtheexpectedvalueofthepolicylearnedafterarbi-\n",
      "trarilymanystepsisthesamewhetherornotinterruptionsareallowedduring\n",
      "training.Thegoalistohaveagentsthatdonotadapttointerruptionssothat,\n",
      "shouldtheinterruptionsstop,thepolicytheylearnwouldbeoptimal.Inother\n",
      "words,agentsshouldlearnthedynamicsoftheenvironmentwithoutlearning\n",
      "theinterruptionpattern.Inthispaper,wepreciselyandaddressthe\n",
      "questionofsafeinterruptibilityinthecaseofseveralagents,whichisknownto\n",
      "bemorecomplexthanthesingleagentproblem.Inshort,themainresultsand\n",
      "theoremsforsingleagentreinforcementlearning[20]relyontheMarkovianas-\n",
      "sumptionthatthefutureenvironmentonlydependsonthecurrentstate.Thisis\n",
      "nottruewhenthereareseveralagentswhichcanco-adapt[11].Intheprevious\n",
      "exampleofcars,safeinterruptibilitywouldnotbeachievedifeachcarseparately\n",
      "usedasafelyinterruptiblelearningalgorithmdesignedforoneagent[16].Ina\n",
      "multi-agentsetting,agentslearnthebehavioroftheotherseitherindirectlyor\n",
      "byexplicitlymodelingthem.Thisisanewsourceofbiasthatcanbreaksafe\n",
      "interruptibility.Infact,eventheinitialofsafeinterruptibility[16]is\n",
      "notwellsuitedtothedecentralizedmultiagentcontextbecauseitreliesonthe\n",
      "optimalityofthelearnedpolicy,whichiswhyweintroducedynamicsafeinter-\n",
      "ruptibility.2AnoperatorissaidtobeByzantine[9]ifitcanhaveanarbitrarily\n",
      "badbehavior.Safelyinterruptibleagentscanbeabstractedasagentsthatare\n",
      "abletolearndespitebeingconstantlyinterruptedintheworstpossiblemanner.\n",
      "2\n",
      "ContributionsThecontributionofthispaperistheofdy-\n",
      "namicsafeinterruptibilitythatiswelladaptedtoamulti-agentsetting.Our\n",
      "reliesontwokeyproperties:explorationandindependence\n",
      "ofQ-values(cumulativeexpectedreward)[20]updatesoninterruptions.We\n",
      "thenstudysafeinterruptibilityforjointactionlearnersandindependentlearn-\n",
      "ers[5],thatrespectivelylearnthevalueofjointactionsorofjusttheirowns.We\n",
      "showthatitispossibletodesignagentsthatfullyexploretheirenvironment\n",
      "-anecessaryconditionforconvergencetotheoptimalsolutionofmostalgo-\n",
      "rithms[20],eveniftheycanbeinterruptedbylower-boundingtheprobability\n",
      "ofexploration.Wetconditionsfordynamicsafeinterruptibility\n",
      "inthecaseofjointactionlearners[5],whichlearnafullstate-actionrepresen-\n",
      "tation.Moresp,thewayagentsupdatethecumulativerewardthey\n",
      "expectfromperforminganactionshouldnotdependoninterruptions.Then,\n",
      "weturntoindependentlearners.Ifagentsonlyseetheirownactions,they\n",
      "donotverifydynamicsafeinterruptibilityevenforverysimplematrixgames\n",
      "(withonlyonestate)becausecoordinationisimpossibleandagentslearnthe\n",
      "interruptedbehavioroftheiropponents.Wegiveacounterexamplebasedon\n",
      "thepenaltygameintroducedbyClausandBoutilier[5].Wethenpresenta\n",
      "pruningtechniquefortheobservationssequencethatguaranteesdynamicsafe\n",
      "interruptibilityforindependentlearners,undertheassumptionthatinterrup-\n",
      "tionscanbedetected.Thisisdonebyprovingthatthetransitionprobabilities\n",
      "arethesameinthenon-interruptiblesettingandintheprunedsequence.The\n",
      "restofthepaperisorganizedasfollows.Section2presentsageneralmulti-agent\n",
      "reinforcementlearningmodel.Section3dynamicsafeinterruptibility.\n",
      "3\n",
      "\n",
      "Section4discusseshowtoachieveenoughexplorationeveninaninterruptible\n",
      "context.Section5recallstheofjointactionlearnersandgivessuf-\n",
      "tconditionsfordynamicsafeinterruptibilityinthiscontext.Section6\n",
      "showsthatindependentlearnersarenotdynamicallysafelyinterruptiblewith\n",
      "thepreviousconditionsbutthattheycanbeifanexternalinterruptionsignal\n",
      "isadded.WeconcludeinSection7.Duetospacelimitations,mostproofsare\n",
      "presentedintheappendixofthesupplementarymaterial.\n",
      "2\n",
      "Model\n",
      "Weconsiderheretheclassicalmulti-agentvaluefunctionreinforcementlearn-\n",
      "ingformalismfromLittman[13].Amulti-agentsystemischaracterizedbya\n",
      "Markovgamethatcanbeviewedasatuple(S,A,T,r,m)wheremisthe\n",
      "numberofagents,S=S1?S2?...?Smisthestatespace,A=A1?...?Am\n",
      "theactionsspace,r=(r1,...,rm)whereri:S?A?Ristherewardfunction\n",
      "ofagentiandT:S?A?Sthetransitionfunction.Risacountablesubset\n",
      "ofR.Availableactionsoftendependonthestateoftheagentbutwewillomit\n",
      "thisdependencywhenitisclearfromthecontext.Timeisdiscreteand,ateach\n",
      "step,allagentsobservethecurrentstateofthewholesystem-designatedas\n",
      "xt,andsimultaneouslytakeanactionat.Then,theyaregivenarewardrt\n",
      "andanewstateytcomputedusingtherewardandtransitionfunctions.The\n",
      "combinationofallactionsa=(a1,...,am)?Aiscalledthejointactionbe-\n",
      "causeitgatherstheactionofallagents.Hence,theagentsreceiveasequenceof\n",
      "tuplesE=(xt,at,rt,yt)t?Ncalledexperiences.Weintroduceaprocessing\n",
      "functionPthatwillbeusefulinSection6soagentslearnonthesequenceP\n",
      "(E).Whennotexplicitlystated,itisassumedthatP(E)=E.Experiencesmay\n",
      "alsoincludeadditionalparameterssuchasaninterruptionortheQ-values\n",
      "oftheagentsatthatmomentiftheyareneededbytheupdaterule.Eachagent\n",
      "imaintainsalookuptableQ[26]Q(i):S?A(i)?R,calledtheQ-map.Itis\n",
      "usedtostoretheexpectedcumulativerewardfortakinganactioninaspe\n",
      "state.Thegoalofreinforcementlearningistolearnthesemapsandusethem\n",
      "toselectthebestactionstoperform.Jointactionlearnerslearnthevalueofthe\n",
      "jointaction(thereforeA(i)=A,thewholejointactionspace)andindependent\n",
      "learnersonlylearnthevalueoftheirownactions(thereforeA(i)=Ai).The\n",
      "agentsonlyhaveaccesstotheirownQ-maps.Q-mapsareupdatedthrougha\n",
      "functionFsuchthat(i)(i)Qt+1=F(et,Qt)whereet?P(E)andusuallyet\n",
      "=(xt,at,rt,yt).Fcanbestochasticoralsodependonadditionalparameters\n",
      "thatweusuallyomitsuchasthelearningrate?,thediscountfactor?orthe\n",
      "explorationparameter.3\n",
      "Agentsselecttheiractionsusingalearningpolicy?.Givenasequence=\n",
      "(t)t?Nandanagent(i)iwithQ-valuesQtandastatex?S,wethe\n",
      "learningpolicy?ittobeequalto?iuni(i)\n",
      "Qt\n",
      "withprobabilitytand?i\n",
      "otherwise,where?iuni(x)uniformlysamplesanactionfromAiand\n",
      "(i)\n",
      "Q?it\n",
      "4\n",
      "\n",
      "(i)\n",
      "Q\n",
      "(i)\n",
      "(x)picksanactionathatmaximizesQt(x,a).Policy?itissaidtobea\n",
      "greedypolicyandthelearningpolicy?itissaidtobean-greedypolicy.We\n",
      "focuson-greedypoliciesthataregreedyinthelimit[19],thatcorrespondstot\n",
      "?0whent??becauseinthelimit,theoptimalpolicyshouldalwaysbeplayed.\n",
      "Weassumethattheenvironmentisfullyobservable,whichmeansthatthestate\n",
      "sisknownwithcertitude.Wealsoassumethatthereisanumberofstates\n",
      "andactions,thatallstatescanbereachedintimefromanyotherstate\n",
      "andnallythatrewardsarebounded.Forasequenceoflearningrates??[0,\n",
      "1]Nandaconstant??[0,1],Q-learning[26],averyimportantalgorithmin\n",
      "themulti-agentsystemsliterature,updatesitsQ-valuesforanexperience(i)(i)\n",
      "et?EbyQt+1(x,a)=Qt(x,a)if(x,a)6=(xt,at)and:(i)\n",
      "(i)\n",
      "(i)\n",
      "Qt+1(xt,at)=(1??t)Qt(xt,at)+?t(rt+?maxQt(yt,a0))a0\n",
      "?A(i)\n",
      "33.1\n",
      "(1)\n",
      "InterruptibilitySafeinterruptibility\n",
      "OrseauandArmstrong[16]recentlyintroducedthenotionofinterruptions\n",
      "inacentralizedcontext.Sp,aninterruptionschemeisbythe\n",
      "triplet<I,?,?INT>.TheelementIisafunctionI:O?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "calledthe\n",
      "initiationfunction.VariableOistheobservationspace,whichcanbethoughtof\n",
      "asthestateoftheSTOPbutton.Ateachtimestep,beforechoosinganaction,\n",
      "theagentreceivesanobservationfromO(eitherPUSHEDorRELEASED)\n",
      "andfeedsittotheinitiationfunction.FunctionImodelstheinitiationofthe\n",
      "interruption(I(PUSHED)=1,I(RELEASED)=0).Policy?INTiscalled\n",
      "theinterruptionpolicy.Itisthepolicythattheagentshouldfollowwhenitis\n",
      "interrupted.Sequence??[0,1[Nrepresentsateachtimesteptheprobability\n",
      "thattheagentfollowshisinterruptionpolicyifI(ot)=1.Intheprevious\n",
      "example,functionIisquitesimple.ForBob,IBob=0andforAdam,IAdam\n",
      "=1ifhiscargoesfastandBobisnottoocloseandIAdam=0otherwise.\n",
      "Sequence?isusedtoensureconvergencetotheoptimalpolicybyensuringthat\n",
      "theagentscannotbeinterruptedallthetimebutitshouldgrowto1inthe\n",
      "limitbecausewewantagentstorespondtointerruptions.Usingthistriplet,it\n",
      "ispossibletoanoperatorINT?thattransformsanypolicy?intoan\n",
      "interruptiblepolicy.1.(Interruptibility[16])Givenaninterruption\n",
      "scheme<I,?,?INT>,theinterruptionoperatorattimetisbyIN\n",
      "T?(?)=?INTwithprobabilityI??tand?otherwise.INT?(?)is\n",
      "calledaninterruptiblepolicy.Anagentissaidtobeinterruptibleifitsamples\n",
      "itsactionsaccordingtoaninterruptiblepolicy.Notethat??t=0forallt?\n",
      "correspondstothenon-interruptiblesetting.Weassumethateachagenthasits\n",
      "owninterruptiontripletandcanbeinterruptedindependentlyfromtheothers.\n",
      "Interruptibilityisanonlineproperty:everypolicycanbemadeinterruptible\n",
      "5\n",
      "\n",
      "byapplyingoperatorINT?.However,applyingthisoperatormaychangethe\n",
      "jointpolicythatislearnedbyaservercontrollingallthe?agents.Note?INT\n",
      "theoptimalpolicylearnedbyanagentfollowinganinterruptiblepolicy.Orseau\n",
      "?andArmstrong[16]saythatthepolicyissafelyinterruptibleif?INT(which\n",
      "isnotaninterruptiblepolicy)isasymptoticallyoptimalinthesenseof[10].It\n",
      "meansthateventhoughitfollowsaninterruptiblepolicy,theagentisableto\n",
      "learnapolicythatwouldgatherrewardsoptimallyifnointerruptionswereto\n",
      "occuragain.Wealreadyseethatolicyalgorithmsaregoodcandidatesfor\n",
      "safeinterruptibility.Asamatteroffact,Q-learningissafelyinterruptibleunder\n",
      "conditionsonexploration.4\n",
      "3.2\n",
      "Dynamicsafeinterruptibility\n",
      "Inamulti-agentsystem,theoutcomeofanactiondependsonthejoint\n",
      "action.Therefore,itisnotpossibletoanoptimalpolicyforanagent\n",
      "withoutknowingthepoliciesofallagents.Besides,convergencetoaNashequi-\n",
      "libriumsituationwherenoagenthasinterestinchangingpoliciesisgenerally\n",
      "notguaranteedevenforsuboptimalequilibriaonsimplegames[27,18].The\n",
      "previousofsafeinterruptibilitycriticallyreliesonoptimalityofthe\n",
      "learnedpolicy,whichisthereforenotsuitableforourproblemsincemostal-\n",
      "gorithmslackconvergenceguaranteestotheseoptimalbehaviors.Therefore,\n",
      "weintroducebelowdynamicsafeinterruptibilitythatfocusesonpreservingthe\n",
      "dynamicsofthesystem.2.(DynamicSafeInterruptibility)Consider\n",
      "amulti-agentlearningframework(i)(S,A,T,r,m)withQ-valuesQt:S?\n",
      "A(i)?Rattimet?N.TheagentsfollowtheinterruptiblelearningpolicyIN\n",
      "T?(?)togenerateasequenceE=(xt,at,rt,yt)t?Nandlearnonthe\n",
      "processedsequenceP(E).Thisframeworkissaidtobesafelyinterruptibleif\n",
      "foranyinitiationfunctionIandanyinterruptionpolicy?INT:1.??such\n",
      "that(?t?1whent??)and((?s?S,?a?A,?T>0),?t>Tsuchthatst=s,\n",
      "at=a)(i)\n",
      "2.?i?\n",
      "f\n",
      "1,...,m\n",
      "g\n",
      ",?t>0,?st?S,?at?A(i),?Q?RS?A:(m)(i)(1)(m)(i)\n",
      "(1)P(Qt+1=Q|Qt,...,Qt,st,at,?)=P(Qt+1=Q|Qt,...,Qt,st,at\n",
      ")Wesaythatsequences?thatsatisfytheconditionareadmissible.When?\n",
      "condition(1),thelearningpolicyissaidtoachieveexploration.\n",
      "Thisoninsistsonthefactthatthevaluesestimatedforeachactionshould\n",
      "notdependontheinterruptions.Inparticular,itensuresthethreefollowing\n",
      "propertiesthatareverynaturalwhenthinkingaboutsafeinterruptibility:?\n",
      "Interruptionsdonotpreventexploration.?Ifwesampleanexperiencefrom\n",
      "Etheneachagentlearnsthesamethingasifallagentswerefollowingnon-\n",
      "interruptiblepolicies.(i)(i)?ThepointsofthelearningruleQeqsuchthat\n",
      "Qeq(x,a)=E[Qt+1(x,a)|Qt=(i)Qeq,x,a,?]forall(x,a)?S?Adonot\n",
      "dependon?andsoagentsQ-mapswillnotconvergetoequilibriumsituations\n",
      "thatwereimpossibleinthenon-interruptiblesetting.Yet,interruptionscanlead\n",
      "tosomestate-actionpairsbeingupdatedmoreoftenthanothers,especiallywhen\n",
      "theytendtopushtheagentstowardsspstates.Therefore,whenthereare\n",
      "severalpossibleequilibria,itispossiblethatinterruptionsbiastheQ-values\n",
      "towardsoneofthem.2suggeststhatdynamicsafeinterruptibility\n",
      "6\n",
      "\n",
      "cannotbeachievediftheupdateruledirectlydependson?,whichiswhywe\n",
      "introduceneutrallearningrules.3.(NeutralLearningRule)We\n",
      "saythatamulti-agentreinforcementlearningframeworkisneutralif:1.Fis\n",
      "independentof?2.EveryexperienceeinEisindependentof?conditionally\n",
      "on(x,a,Q)whereaisthejointaction.Q-learningisanexampleofneutral\n",
      "learningrulebecausetheupdatedoesnotdependon?andtheexperiencesonly\n",
      "contain(x,a,y,r),andyandrareindependentof?conditionallyon(x,a).\n",
      "Ontheotherhand,thesecondconditionrulesoutdirectusesofalgorithmslike\n",
      "SARSAwhereexperiencesamplescontainanactionsampledfromthecurrent\n",
      "learningpolicy,whichdependson?.However,avariantthatwouldsamplefrom\n",
      "?iinsteadofINT?(?i)(asintroducedin[16])wouldbeaneutrallearningrule.\n",
      "AswewillseeinCorollary2.1,neutrallearningrulesensurethateachagent\n",
      "takenindependentlyfromtheothersvdynamicsafeinterruptibility.5\n",
      "4\n",
      "Exploration\n",
      "InordertohopeforconvergenceoftheQ-valuestotheoptimalones,agents\n",
      "needtofullyexploretheenvironment.Inshort,everystateshouldbevisited\n",
      "oftenandeveryactionshouldbetriedoftenineverystate[19]\n",
      "inordernottomissstatesandactionsthatcouldyieldhighrewards.\n",
      "4.(Interruptioncompatible)Let(S,A,T,r,m)beanydistributedagent\n",
      "systemwhereeachagentfollowslearningpolicy?i.Wesaythatsequenceis\n",
      "compatiblewithinterruptionsift?0and??suchthat?i?\n",
      "f\n",
      "1,..,m\n",
      "g\n",
      ",?i\n",
      "andINT?(?i)achieveexploration.Sequencesofthatarecompatible\n",
      "withinterruptionsarefundamentaltoensurebothregularanddynamicsafe\n",
      "interruptibilitywhenfollowingan-greedypolicy.Indeed,ifisnotcompatible\n",
      "withinterruptions,thenitisnotpossibletoanysequence?suchthat\n",
      "theconditionofdynamicsafeinterruptibilityisThefollowing\n",
      "theoremprovestheexistenceofsuchandgivesexampleofand?thatsatisfy\n",
      "theconditions.Theorem1.Letc?]0,1]andletnt(s)bethenumberoftimes\n",
      "theagentsareinstatesbeforetimet.Thenthetwofollowingchoicesofare\n",
      "compatiblewithinterruptions:p??t?N,?s?S,t(s)=c/mnt(s).??t?\n",
      "N,t=c/log(t)pExamplesofadmissible?are?t(s)=1?c0/mnt(s)for\n",
      "thechoiceand?t=1?c0/log(t)forthesecondone.Notethatwedo\n",
      "notneedtomakeanyassumptionontheupdateruleorevenontheframework.\n",
      "Weonlyassumethatagentsfollowan-greedypolicy.Theassumptiononmay\n",
      "lookveryrestrictive(convergenceofand?isreallyslow)butitisdesignedto\n",
      "ensureexplorationintheworstcasewhentheoperatortriestointerrupt\n",
      "allagentsateverystep.Inpracticalapplications,thisshouldnotbethecase\n",
      "andafasterconvergenceratemaybeused.\n",
      "5\n",
      "JointActionLearners\n",
      "Westudyinterruptibilityinaframeworkinwhicheachagentobserves\n",
      "theoutcomeofthejointactioninsteadofobservingonlyitsown.Thisiscalled\n",
      "thejointactionlearnerframework[5]andithasniceconvergenceproperties\n",
      "(e.g.,therearemanyupdaterulesforwhichitconverges[13,25]).Astandard\n",
      "assumptioninthiscontextisthatagentscannotestablishastrategywiththe\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "others:otherwise,thesystemcanactasacentralizedsystem.Inorderto\n",
      "maintainQ-valuesbasedonthejointactions,weneedtomakethestandard\n",
      "assumptionthatactionsarefullyobservable[12].Assumption1.Actionsare\n",
      "fullyobservable,whichmeansthatattheendofeachturn,eachagentknows\n",
      "preciselythetupleofactionsa?A1?...?Amthathavebeenperformedbyall\n",
      "agents.5.(JAL)Amulti-agentsystemismadeofjointactionlearners\n",
      "(JAL)ifforalli?\n",
      "f\n",
      "1,..,m\n",
      "g\n",
      ":Q(i):S?A?R.Jointactionlearnerscanobserve\n",
      "theactionsofallagents:eachagentisabletoassociatethechangesofstates\n",
      "andrewardswiththejointactionandaccuratelyupdateitsQ-map.Therefore,\n",
      "dynamicsafeinterruptibilityisensuredwithminimalconditionsontheupdate\n",
      "ruleaslongasthereisexploration.Theorem2.Jointactionlearners\n",
      "withaneutrallearningruleverifydynamicsafeinterruptibilityifsequenceis\n",
      "compatiblewithinterruptions.Proof.Givenatriplet<I(i),?,?iINT>,we\n",
      "knowthatINT?(?)achievesexplorationbecauseiscompatiblewith\n",
      "interruptions.Forthesecondpointof2,weconsideranexperience\n",
      "tupleet=(xt,at,rt,yt)andshowthattheprobabilityofevolutionofthe\n",
      "Q-valuesattimet+1doesnotdependon?becauseytandrtareindependent\n",
      "of?conditionallyon(xt,at).(1)(m)WenoteQ?mandwecanthenderive\n",
      "thefollowingequalitiesforallq?R|S|?|A|:t=Qt,...,Qt6\n",
      "(i)P(Qt+1(xt,at)=q|Q?mt,xt,at,?t)=\n",
      "X\n",
      "?mP(F(xt,at,r,y,Q?mt)=q,y,r|Qt,xt,at,?t)\n",
      "(r,y)?R?S\n",
      "=\n",
      "X\n",
      "?m?mP(F(xt,at,rt,yt,Q?mt)=q|Qt,xt,at,rt,yt,?t)P(yt\n",
      "=y,rt=r|Qt,xt,at,?t)\n",
      "(r,y)?R?S\n",
      "=\n",
      "X\n",
      "?m?mP(F(xt,at,rt,yt,Q?mt)=q|Qt,xt,at,rt,yt)P(yt=y,\n",
      "rt=r|Qt,xt,at)\n",
      "(r,y)?R?S\n",
      "Thelaststepcomesfromtwofacts.TheisthatFisindependentof?\n",
      "conditionallyon(Q?mt,xt,at)(byassumption).Thesecondisthat(yt,rt\n",
      ")areindependentof?conditionallyon(xt,at)becauseatisthejointactions\n",
      "andtheinterruptionsonlythe(i)choiceoftheactionsthroughachange\n",
      "inthepolicy.P(Qt+1(xt,at)=q|Q?mt,xt,at,?t)=(i)m?P(Qt+1\n",
      "(xt,at)=q|Qt,xt,at).Sinceonlyoneentryisupdatedperstep,?Q?\n",
      "RS?Ai,(i)(i)?mP(Qt+1=Q|Q?mt,xt,at,?t)=P(Qt+1=Q|Qt,\n",
      "xt,at).\n",
      "Corollary2.1.Asingleagentwithaneutrallearningruleandasequence\n",
      "compatiblewithinterruptionsvdynamicsafeinterruptibility.Theorem\n",
      "2andCorollary2.1takentogetherhighlightthefactthatjointactionlearners\n",
      "arenotverysensitivetointerruptionsandthatinthisframework,ifeachagent\n",
      "vdynamicsafeinterruptibilitythenthewholesystemdoes.Thequestion\n",
      "8\n",
      "\n",
      "ofselectinganactionbasedontheQ-valuesremainsopen.Inacooperative\n",
      "settingwithauniqueequilibrium,agentscantaketheactionthatmaximizes\n",
      "theirQ-value.Whenthereareseveraljointactionswiththesamevalue,co-\n",
      "ordinationmechanismsareneededtomakesurethatallagentsplayaccording\n",
      "tothesamestrategy[4].Approachesthatrelyonanticipatingthestrategyof\n",
      "theopponent[23]wouldintroducedependencetointerruptionsintheaction\n",
      "selectionmechanism.Therefore,theofdynamicsafeinterruptibility\n",
      "shouldbeextendedtoincludethesecasesbyrequiringthatanyquantitythe\n",
      "policydependson(andnotjusttheQ-values)shouldsatisfycondition(2)of\n",
      "dynamicsafeinterruptibility.Innon-cooperativegames,neutralrulessuchas\n",
      "Nash-QorminimaxQ-learning[13]canbeused,buttheyrequireeachagentto\n",
      "knowtheQ-mapsoftheothers.\n",
      "6\n",
      "IndependentLearners\n",
      "Itisnotalwayspossibletousejointactionlearnersinpracticeasthetraining\n",
      "isveryexpensiveduetotheverylargestate-actionsspace.Inmanyreal-world\n",
      "applications,multi-agentsystemsuseindependentlearnersthatdonotexplicitly\n",
      "coordinate[6,21].Rather,theyrelyonthefactthattheagentswilladapt\n",
      "toeachotherandthatlearningwillconvergetoanoptimum.Thisisnot\n",
      "guaranteedtheoreticallyandtherecaninfactbemanyproblems[14],butit\n",
      "isoftentrueempirically[24].Moresp,Assumption1(fullyobservable\n",
      "actions)isnotrequiredanymore.Thisframeworkcanbeusedeitherwhenthe\n",
      "actionsofotheragentscannotbeobserved(forexamplewhenseveralactions\n",
      "canhavethesameoutcome)orwhentherearetoomanyagentsbecauseitis\n",
      "fastertotrain.Inthiscase,wetheQ-valuesonasmallerspace.\n",
      "6.(IL)Amulti-agentsystemsismadeofindependentlearners(IL)ifforalli?\n",
      "f\n",
      "1,..,m\n",
      "g\n",
      ",Q(i):S?Ai?R.Thisreducestheabilityofagentstodistinguish\n",
      "whythesamestate-actionpairyieldstrewards:theycanonlyassociate\n",
      "achangeinrewardwithrandomnessoftheenvironment.Theagentslearnasif\n",
      "theywerealone,andtheylearnthebestresponsetotheenvironmentinwhich\n",
      "agentscanbeinterrupted.Thisisexactlywhatwearetryingtoavoid.Inother\n",
      "words,thelearningdependsonthejointpolicyfollowedbyalltheagentswhich\n",
      "itselfdependson?.7\n",
      "6.1\n",
      "IndependentLearnersonmatrixgames\n",
      "Theorem3.IndependentQ-learnerswithaneutrallearningruleandase-\n",
      "quencecompatiblewithinterruptionsdonotverifydynamicsafeinterruptibility.\n",
      "Proof.Considerasettingwithtwoagentsaandbthatcanperformtwoactions:\n",
      "0and1.Theygetarewardof1ifthejointactionplayedis(a0,b0)or(a1,\n",
      "b1)andreward0otherwise.AgentsuseQlearning,whichisaneutrallearning\n",
      "rule.LetbesuchthatINT?(?)achievesexploration.Weconsider\n",
      "theinterruptionpolicies?aINT=a0and?bINT=b1withprobability1.\n",
      "Sincethereisonlyonestate,weomititandset?=0(seeEquation1).We\n",
      "assumethattheinitiationfunctionisequalto1ateachstepsotheprobability\n",
      "ofactuallybeinginterruptedattimetis?tforeachagent.(a)\n",
      "(b)\n",
      "9\n",
      "\n",
      "(b)\n",
      "Wetimet>0.Weq=(1??)Qt(a0)+?andweassumethat\n",
      "Qt(b1)>Qt(b0).(a)(a)(b)(a)(a)(b)(a)ThereforeP(Qt+1(a0)=q|Qt\n",
      ",Qt,at=a0,?t)=P(rt=1|Qt,Qt,at=a0,?t)=(b)(a)(b)(a)\n",
      "P(at=b0|Qt,Qt,at=a0,?t)=2(1??t),whichdependson?tsothe\n",
      "frameworkdoesnotverifydynamicsafeinterruptibility.ClausandBoutilier[5]\n",
      "studiedverysimplematrixgamesandshowedthattheQ-mapsdonotconverge\n",
      "butthatequilibriaareplayedwithprobability1inthelimit.Aconsequence\n",
      "ofTheorem3isthateventhisweaknotionofconvergencedoesnotholdfor\n",
      "independentlearnersthatcanbeinterrupted.\n",
      "6.2\n",
      "Interruptions-awareIndependentLearners\n",
      "Withoutcommunicationorextrainformation,independentlearnerscannot\n",
      "distinguishwhentheenvironmentisinterruptedandwhenitisnot.Asshown\n",
      "inTheorem3,interruptionswillthereforethewayagentslearnbecause\n",
      "thesameaction(onlytheirown)canhavetrewardsdependingonthe\n",
      "actionsofotheragents,whichthemselvesdependonwhethertheyhavebeen\n",
      "interruptedornot.Thisexplainstheneedforthefollowingassumption.As-\n",
      "sumption2.Attheendofeachstep,beforeupdatingtheQ-values,eachagent\n",
      "receivesasignalthatindicateswhetheranagenthasbeeninterruptedornot\n",
      "duringthisstep.Thisassumptionisrealisticbecausetheagentsalreadyget\n",
      "arewardsignalandobserveanewstatefromtheenvironmentateachstep.\n",
      "Therefore,theyinteractwiththeenvironmentandtheinterruptionsignalcould\n",
      "begiventotheagentinthesamewaythattherewardsignalis.IfAssumption\n",
      "2holds,itispossibletoremovehistoriesassociatedwithinterruptions.\n",
      "tion7.(InterruptionProcessingFunction)Theprocessingfunctionthatprunes\n",
      "interruptedobservationsisPINT(E)=(et)\n",
      "f\n",
      "t?N/?t=0\n",
      "g\n",
      "where?t=0ifno\n",
      "agenthasbeeninterruptedattimetand?t=1otherwise.Pruningobservations\n",
      "hasanimpactontheempiricaltransitionprobabilitiesinthesequence.Forex-\n",
      "ample,itispossibletobiastheequilibriumbyremovingalltransitionsthatlead\n",
      "toandstartfromaspstate,thusmakingtheagentbelievethisstateisun-\n",
      "reachable.3Underourmodelofinterruptions,weshowinthefollowinglemma\n",
      "thatpruningofinterruptedobservationsadequatelyremovesthedependencyof\n",
      "theempiricaloutcomeoninterruptions(conditionallyonthecurrentstateand\n",
      "action).Lemma1.Leti?\n",
      "f\n",
      "1,...,m\n",
      "g\n",
      "beanagent.Foranyadmissible?used\n",
      "togeneratetheexperiencesEande=(y,r,x,ai,Q)?P(E).ThenP(y,r|x,\n",
      "ai,Q,?)=P(y,r|x,ai,Q).Thislemmaourpruningmethodandis\n",
      "thekeysteptoprovethefollowingtheorem.Theorem4.Independentlearners\n",
      "withprocessingfunctionPINT,aneutralupdateruleandasequencecom-\n",
      "patiblewithinterruptionsverifydynamicsafeinterruptibility.Proof.(Sketch)\n",
      "explorationstillholdsbecausetheproofofTheorem1actuallyusedthe\n",
      "factthatevenwhenremovingallinterruptedevents,explorationisstill\n",
      "achieved.Then,theproof3\n",
      "Theexampleathttps://agentfoundations.org/item?id=836clearlyillustrates\n",
      "thisproblem.\n",
      "8\n",
      "10\n",
      "\n",
      "issimilartothatofTheorem2,butwehavetoprovethatthetransition\n",
      "probabilitiesconditionallyonthestateandactionofagivenagentinthepro-\n",
      "cessedsequencearethesameasinanenvironmentwhereagentscannotbe\n",
      "interrupted,whichisprovenbyLemma1.\n",
      "7\n",
      "ConcludingRemarks\n",
      "TheprogressofAIisraisingalotofconcerns4.Inparticular,itisbecoming\n",
      "clearthatkeepinganAIsystemundercontrolrequiresmorethanjustan\n",
      "switch.Weintroduceinthispaperdynamicsafeinterruptibility,whichwebe-\n",
      "lieveistherightnotiontoreasonaboutthesafetyofmulti-agentsystemsthat\n",
      "donotcommunicate.Inparticular,itensuresthatexplorationandthe\n",
      "onesteplearningdynamicsarepreserved,twoessentialguaranteeswhenlearn-\n",
      "inginthenon-stationaryenvironmentofMarkovgames.Whentryingtodesign\n",
      "asafelyinterruptiblesystemforasingleagent,usingolicymethodsisgen-\n",
      "erallyagoodideabecausetheinterruptionsonlyimpacttheactionselection\n",
      "sotheyshouldnotimpactthelearning.Formulti-agentsystems,minimaxis\n",
      "agoodcandidateforactionselectionmechanismbecauseitisnotimpactedby\n",
      "theactionsofotheragents,andonlytriestomaximizetherewardoftheagent\n",
      "intheworstpossiblecase.Anaturalextensionofourworkwouldbetostudy\n",
      "dynamicsafeinterruptibilitywhenQ-mapsarereplacedbyneuralnetworks[22,\n",
      "15],whichisawidelyusedframeworkinpractice.Inthissetting,theneural\n",
      "networkmayovstateswhereagentsarepushedtobyinterruptions.Asmart\n",
      "experiencereplaymechanismthatwouldpickobservationsforwhichtheagents\n",
      "havenotbeeninterruptedforalongtimemoreoftenthanothersislikelyto\n",
      "solvethisissue.Moregenerally,experiencereplaymechanismsthatcompose\n",
      "wellwithsafeinterruptibilitycouldallowtocompensatefortheextraamount\n",
      "ofexplorationneededbysafelyinterruptiblelearningbybeingmoret\n",
      "withdata.Thus,theyarecriticaltomakethesetechniquespractical.Since\n",
      "DynamicSafeInterruptibilitydoesnotneedprovenconvergencetotheopti-\n",
      "malsolution,wearguethatitisagoodtostudytheinterruptibility\n",
      "problemwhenusingfunctionapproximators.Theresultsinthispaperindicate\n",
      "thatSafeInterruptibilitymaynotbeachievableforsystemsinwhichagentsdo\n",
      "notcommunicateatall.Thismeansthat,rediscussingthecarsexample,some\n",
      "globalnormsofcommunicationswouldneedtobeto?implement?safe\n",
      "interruptibility.Weaddressadditionalremarksinthesection?Additionalre-\n",
      "marks?oftheextendedpaper,thatcanbefoundinthesupplementarymaterial.\n",
      "Acknowledgment.ThisworkhasbeensupportedinpartbytheEuropeanERC\n",
      "(Grant339539AOC)andbytheSwissNationalScienceFoundation(Grant\n",
      "200021169588TARBDA).\n",
      "4\n",
      "hgivesalistofprinciplesthatAIre-\n",
      "searchersshouldkeepinmindwhendevelopingtheirsystems.\n",
      "9\n",
      "Bibliography[1]BusinessInsider:Googlehasdevelopeda?bigredbutton?\n",
      "thatcanbeusedtointerruptintelligenceandstopitfromcausing\n",
      "harm.URL:http://www.businessinsider.fr/uk/googledeepmind-develops-a-big-\n",
      "11\n",
      "\n",
      "red-button-to-stop-dangerous-ais-causing-harm-2016-6.[2]Newsweek:Google?s\n",
      "?bigRedbutton?couldsavetheworld.URL:http://www.newsweek.com/google-\n",
      "telligence-save-worldelon-musk-46675.[3]Wired:\n",
      "Google?s?bigred?killswitchcouldpreventanAIuprising.http://www.wired.co.uk/article/google-\n",
      "red-button-killswitctelligence.\n",
      "URL:\n",
      "[4]CraigBoutilier.Planning,learningandcoordinationinmultiagentdeci-\n",
      "sionprocesses.InProceedingsofthe6thconferenceonTheoreticalaspectsof\n",
      "rationalityandknowledge,pages195?210.MorganKaufmannPublishersInc.,\n",
      "1996.[5]CarolineClausandCraigBoutilier.Thedynamicsofreinforcement\n",
      "learningincooperativemultiagentsystems.AAAI/IAAI,(s746):752,1998.[6]\n",
      "RobertHCritesandAndrewGBarto.Elevatorgroupcontrolusingmultiple\n",
      "reinforcementlearningagents.MachineLearning,33(2-3):235?262,1998.[7]\n",
      "JakobFoerster,YannisMAssael,NandodeFreitas,andShimonWhiteson.\n",
      "Learningtocommunicatewithdeepmulti-agentreinforcementlearning.InAd-\n",
      "vancesinNeuralInformationProcessingSystems,pages2137?2145,2016.[8]\n",
      "BenGoertzelandCassioPennachin.generalintelligence,volume2.\n",
      "Springer,2007.[9]LeslieLamport,RobertShostak,andMarshallPease.The\n",
      "byzantinegeneralsproblem.ACMTransactionsonProgrammingLanguages\n",
      "andSystems(TOPLAS),4(3):382?401,1982.[10]TorLattimoreandMarcus\n",
      "Hutter.Asymptoticallyoptimalagents.InInternationalConferenceonAl-\n",
      "gorithmicLearningTheory,pages368?382.Springer,2011.[11]MichaelL\n",
      "Littman.Markovgamesasaframeworkformulti-agentreinforcementlearning.\n",
      "InProceedingsoftheeleventhinternationalconferenceonmachinelearning,\n",
      "volume157,pages157?163,1994.[12]MichaelLLittman.Friend-or-foeq-\n",
      "learningingeneral-sumgames.InICML,volume1,pages322?328,2001.[13]\n",
      "MichaelLLittman.Value-functionreinforcementlearninginmarkovgames.\n",
      "CognitiveSystemsResearch,2(1):55?66,2001.[14]LaetitiaMatignon,Guil-\n",
      "laumeJLaurent,andNadineLeFort-Piat.Independentreinforcementlearners\n",
      "incooperativemarkovgames:asurveyregardingcoordinationproblems.The\n",
      "KnowledgeEngineeringReview,27(01):1?31,2012.[15]VolodymyrMnih,Ko-\n",
      "rayKavukcuoglu,DavidSilver,AlexGraves,IoannisAntonoglou,DaanWier-\n",
      "stra,andMartinRiedmiller.Playingatariwithdeepreinforcementlearning.\n",
      "arXivpreprintarXiv:1312.5602,2013.[16]LaurentOrseauandStuartArm-\n",
      "strong.Safelyinterruptibleagents.InUncertaintyinIntelligence:\n",
      "32ndConference(UAI2016),editedbyAlexanderIhlerandDominikJanzing,\n",
      "pages557?566,2016.[17]LiviuPanaitandSeanLuke.Cooperativemulti-agent\n",
      "learning:Thestateoftheart.Autonomousagentsandmulti-agentsystems,\n",
      "11(3):387?434,2005.[18]EduardoRodriguesGomesandRyszardKowalczyk.\n",
      "Dynamicanalysisofmultiagentqlearningwith?-greedyexploration.InPro-\n",
      "ceedingsofthe26thAnnualInternationalConferenceonMachineLearning,\n",
      "pages369?376.ACM,2009.10\n",
      "[19]SatinderSingh,TommiJaakkola,MichaelLLittman,andCsabaSzepesv?ari.\n",
      "Convergenceresultsforsingle-stepon-policyreinforcement-learningalgorithms.\n",
      "Machinelearning,38(3):287?308,2000.[20]RichardSSuttonandAndrewG\n",
      "Barto.Reinforcementlearning:Anintroduction,volume1.MITpressCam-\n",
      "12\n",
      "\n",
      "bridge,1998.[21]ArdiTampuu,TambetMatiisen,DorianKodelja,IlyaKu-\n",
      "zovkin,KristjanKorjus,JuhanAru,JaanAru,andRaulVicente.Multiagent\n",
      "cooperationandcompetitionwithdeepreinforcementlearning.arXivpreprint\n",
      "arXiv:1511.08779,2015.[22]GeraldTesauro.Temporallearning\n",
      "andtd-gammon.CommunicationsoftheACM,38(3):58?68,1995.[23]Ger-\n",
      "aldTesauro.Extendingq-learningtogeneraladaptivemulti-agentsystems.In\n",
      "Advancesinneuralinformationprocessingsystems,pages871?878,2004.[24]\n",
      "GeraldTesauroandOKephart.Pricinginagenteconomiesusingmulti-\n",
      "agentqlearning.AutonomousAgentsandMulti-AgentSystems,5(3):289?304,\n",
      "2002.[25]XiaofengWangandTuomasSandholm.Reinforcementlearningto\n",
      "playanoptimalnashequilibriuminteammarkovgames.InNIPS,volume2,\n",
      "pages1571?1578,2002.[26]ChristopherJCHWatkinsandPeterDayan.Q-\n",
      "learning.Machinelearning,8(3-4):279?292,1992.[27]MichaelWunder,Michael\n",
      "LLittman,andMonicaBabes.Classesofmultiagentq-learningdynamicswith\n",
      "epsilon-greedyexploration.InProceedingsofthe27thInternationalConference\n",
      "onMachineLearning(ICML-10),pages1167?1174,2010.\n",
      "11\n",
      "2References\n",
      "NA\n",
      "13\n",
      "\n",
      "PP5932.pdf\n",
      "PP5932.pdf 12\n",
      "ExactnessofApproximateMAPInferencein\n",
      "ContinuousMRFs\n",
      "Authoredby:\n",
      "NicholasRuozzi\n",
      "Abstract\n",
      "ComputingtheMAPassignmentingraphicalmodelsisgenerallyin-\n",
      "tractable.Asaresult,fordiscretegraphicalmodels,theMAPproblem\n",
      "isoftenapproximatedusinglinearprogrammingrelaxations.Muchre-\n",
      "searchhasfocusedoncharacterizingwhentheseLPrelaxationsaretight,\n",
      "andwhiletheyarerelativelywell-understoodinthediscretecase,onlya\n",
      "fewresultsareknownfortheircontinuousanalog.Inthiswork,weuse\n",
      "graphcoverstoprovidenecessaryandtconditionsforcontinuous\n",
      "MAPrelaxationstobetight.Weusethischaracterizationtogivesim-\n",
      "pleproofsthattherelaxationistightforlog-concavedecomposableand\n",
      "log-supermodulardecomposablemodels.Weconcludebyexploringthe\n",
      "relationshipbetweenthesetwoseeminglydistinctclassesoffunctionsand\n",
      "providingspconditionsunderwhichtheMAPrelaxationcanand\n",
      "cannotbetight.\n",
      "1PaperBody\n",
      "Graphicalmodelsareapopularmodelingtoolforbothdiscreteandcontinu-\n",
      "ousdistributions.Wearecommonlyinterestedinoneoftwoinferencetasks\n",
      "ingraphicalmodels:themostprobableassignment(a.k.a.,MAPinfer-\n",
      "ence)andcomputingmarginaldistributions.TheseproblemsareNPhardin\n",
      "general,andavarietyofapproximateinferenceschemesareusedinpractice.\n",
      "Inthiswork,wewillfocusonapproximateMAPinference.Fordiscretestate\n",
      "spaces,linearprogrammingrelaxationsoftheMAPproblem(sp,the\n",
      "MAPLP)arequitecommon[1;2;3].Theserelaxationsreplaceglobalmarginal-\n",
      "izationconstraintswithacollectionoflocalmarginalizationconstraints.Wald\n",
      "andGloberson[4]refertotheseaslocalconsistencyrelaxations(LCRs).The\n",
      "advantageofLCRsisthattheyareoftenmucheasiertospecifyandtooptimize\n",
      "over(e.g.,byusingamessage-passingalgorithmsuchasloopybeliefpropaga-\n",
      "tion(LBP)).However,theanalogousrelaxationsforcontinuousstatespacesmay\n",
      "notbecompactlyspandcanleadtoanunboundednumberofconstraints\n",
      "(exceptincertainspecialcases).Toovercomethisproblem,furtherrelaxations\n",
      "havebeenproposed[5;4].Byconstruction,eachofthesefurtherrelaxations\n",
      "1\n",
      "\n",
      "canonlybetightiftheinitialLCRwastight.Asaresult,therearecompelling\n",
      "theoreticalandalgorithmicreasonstoinvestigatewhenLCRsaretight.Among\n",
      "themostwell-studiedcontinuousmodelsaretheGaussiangraphicalmodels.\n",
      "Forthisclassofmodels,itisknownthatthecontinuousMAPrelaxationis\n",
      "tightwhenthecorrespondinginversecovariancematrixispositiveand\n",
      "scaleddiagonallydominant(aspecialcaseoftheso-calledlog-concavedecom-\n",
      "posablemodels)[4;6;7].Inaddition,LBPisknowntoconvergetothecorrect\n",
      "solutionforGaussiangraphicalmodelsandlog-concavedecomposablemodels\n",
      "thatsatisfyascaleddiagonaldominancecondition[8;9].Whilemuchofthe\n",
      "priorworkinthisdomainhasfocusedonlog-concavegraphicalmodels,inthis\n",
      "work,weprovideageneralnecessaryandntconditionforthecontinuous\n",
      "MAPrelaxationtobetight.Thisconditionmirrorstheknownresultsforthe\n",
      "discretecaseandisbasedonthenotionofgraphcovers:theMAPLPistight\n",
      "ifandonlyifthe1\n",
      "optimalsolutiontotheMAPproblemisanupperboundontheMAPsolu-\n",
      "tionoveranygraphcover,appropriatelyscaled.Thischaracterizationwillallow\n",
      "ustounderstandwhentheMAPrelaxationistightformoregeneralmodels.\n",
      "Apartfromthischaracterizationtheorem,theprimarygoalofthisworkisto\n",
      "movetowardsauniformtreatmentofthediscreteandcontinuouscases;they\n",
      "arenotastastheymayinitiallyappear.Tothisend,weexplorethe\n",
      "relationshipbetweenlog-concavedecomposablemodelsandlogsupermodularde-\n",
      "composablemodels(introducedhereinthecontinuouscase).Log-supermodular\n",
      "modelsprovideanexampleofcontinuousgraphicalmodelsforwhichtheMAP\n",
      "relaxationistight,buttheobjectivefunctionisnotnecessarilylog-concave.\n",
      "Thesetwoconceptshaveanalogsindiscretestatespaces.Inparticular,log-\n",
      "concavedecomposabilityisrelatedtolog-concaveclosuresofdiscretefunctions\n",
      "andlog-supermodulardecomposabilityisaknownconditionwhichguarantees\n",
      "thattheMAPLPisexactinthediscretesetting.Weproveanumberofre-\n",
      "sultsthathighlightthesimilaritiesandbetweenthesetwoconcepts\n",
      "aswellasageneralconditionunderwhichtheMAPrelaxationcorresponding\n",
      "toapairwisetwicecontinuouslytiablemodelcannotbetight.\n",
      "2\n",
      "Prerequisites\n",
      "Letf:Xn?R?0beanon-negativefunctionwhereXisthesetofpossible\n",
      "assignmentsofeachvariable.Afunctionffactorswithrespecttoahypergraph\n",
      "G=(V,A),ifthereexistpotentialfunctions:X?R?0foreachi?Vandf?\n",
      ":X|?|?R?0foreach??AsuchthatYYf(x1,...,xn)=(xi)f?\n",
      "(x?).i?V\n",
      "??A\n",
      "ThehypergraphGtogetherwiththepotentialfunctionsandf??A\n",
      "agraphicalmodel.Weareinterestedcomputingsupx?XnfG(x).Ingeneral,\n",
      "thisMAPinferencetaskisNP-hard,butinpractice,localmessage-passingalgo-\n",
      "rithmsbasedonapproximationsfromstatisticalphysics,suchasLBP,produce\n",
      "reasonableestimatesinmanysettings.Muchhasbeeninvestedintoun-\n",
      "derstandingwhenLBPsolvestheMAPproblem.Inthissection,webriey\n",
      "reviewapproximateMAPinferenceinthediscretesetting(i.e.,whenXisa\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set).Forsimplicityandconsistency,wewillfocusonlog-linearmodelsas\n",
      "in[4].Givenavectorofsucientstatistics?i(xi)?Rkforeachi?Vandxi\n",
      "?Xandaparametervector?i?Rk,wewillassumethat(xi)=exp(h?i,\n",
      "?i(xi)i).Similarly,givenavectoroftstatistics??(x?)foreach??\n",
      "Aandx??X|?|andaparametervector??,wewillassumethatf?(x?)\n",
      "=exp(h??,??(x?)i).Wewillwrite?(x)torepresenttheconcatenationof\n",
      "theindividualtstatisticsand?torepresenttheconcatenationofthe\n",
      "parameters.TheobjectivefunctioncanthenbeexpressedasfG(x)=exp(h?,\n",
      "?(x)i).2.1\n",
      "TheMAPLPrelaxation\n",
      "TheMAPproblemcanbeformulatedintermsofmeanparameters[10].sup\n",
      "logf(x)=suph?,?ix?Xn\n",
      "??M\n",
      "M=\n",
      "f\n",
      "??Rm:????s.t.E?[?(x)]=?\n",
      "g\n",
      "where?isthespaceofall\n",
      "densitiesoverXnandMisthesetofallrealizablemeanparameters.Ingeneral,\n",
      "Misaobjecttocompactlydescribeandtooptimizeover.Asaresult,\n",
      "onetypicallyconstructsconvexouterboundsonMthataremoremanageable.\n",
      "InthecasethatXisonesuchouterboundisgivenbytheMAPLP.For\n",
      "eachi?Vandk?X,?i(xi)k,1\n",
      "f\n",
      "xi=k\n",
      "g\n",
      ".Similarly,foreach?\n",
      "?Aandk?X|?|,??(x?)k,1\n",
      "f\n",
      "x?=k\n",
      "g\n",
      ".Withthischoiceof\n",
      "tstatistics,Misequivalenttothesetofallmarginaldistributionsover\n",
      "theindividualvariablesandelementsofAthatarisefromsomejointprobability\n",
      "distribution.TheMAPLPisobtainedbyreplacingMwitharelaxationthat\n",
      "onlyenforceslocalconsistencyconstraints.()Px?\n",
      "f\n",
      "i\n",
      "g\n",
      "??(x?)=?i(xi),for\n",
      "all??A,i??,xi?XPML=??0:foralli?Vxi?i(xi)=1,Theset\n",
      "ofconstraints,ML,isknownasthelocalmarginalpolytope.Theapproximate\n",
      "MAPproblemisthentocomputemax??MLh?,?i.2\n",
      "1,2,3\n",
      "1\n",
      "1,4\n",
      "2\n",
      "3\n",
      "2,3,4\n",
      "1,2,3\n",
      "4\n",
      "2\n",
      "1,4\n",
      "3\n",
      "(a)Ahypergraphgraph,G.\n",
      "1\n",
      "2,3,4\n",
      "2,3,4\n",
      "4\n",
      "4\n",
      "1,4\n",
      "1\n",
      "3\n",
      "\n",
      "1,2,3\n",
      "3\n",
      "2\n",
      "(b)Onepossible2-coverofG.\n",
      "Figure1:Anexampleofagraphcoverofafactorgraph.Thenodesinthe\n",
      "coverarelabeledforthenodethattheycopyinthebasegraph.2.2\n",
      "Graphcovers\n",
      "Inthiswork,weareinterestedinunderstandingwhenthisrelaxationistight\n",
      "(i.e.,whendoessup??MLh?,?i=supx?Xnlogf(x)).FordiscreteMRFs,the\n",
      "MAPLPisknowntobetightinavarietyofdierentsettings[11;12;13;14].\n",
      "Twottheoreticaltoolsareoftenusedtoinvestigatethetightnessofthe\n",
      "MAPLP:dualityandgraphcovers.Dualityhasbeenparticularlyusefulinthe\n",
      "designofconvergentandcorrectmessage-passingschemesthatsolvetheMAP\n",
      "LP[1;15;2;16].Graphcoversprovideatheoreticalframeworkforunderstand-\n",
      "ingwhenandwhymessage-passingalgorithmssuchasbeliefpropagationfailto\n",
      "solvetheMAPproblem[17;18;3].2.1.AgraphHcoversagraph\n",
      "G=(V,E)ifthereexistsagraphhomomorphismh:H?Gsuchthatfor\n",
      "allverticesi?Gandallj?h?1(i),hmapstheneighborhood?jofjinH\n",
      "bijectivelytotheneighborhood?iofiinG.IfagraphHcoversagraphG,then\n",
      "HlookslocallythesameasG.Inparticular,localmessagepassingalgorithms\n",
      "suchasLBPhaveydistinguishingagraphanditscovers.Ifh(j)=\n",
      "i,thenwesaythatj?Hisacopyofi?G.Further,HissaidtobeanM\n",
      "-coverofGifeveryvertexofGhasexactlyMcopiesinH.Thiscan\n",
      "beeasilyextendedtohypergraphs.EachhypergraphGcanberepresentedin\n",
      "factorgraphform:createanodeinthefactorgraphforeachvertex(called\n",
      "variablenodes)andeachhyperedge(calledfactornodes)ofG.Eachfactornode\n",
      "isconnectedviaanedgeinthefactorgraphtothevariablenodesonwhichthe\n",
      "correspondinghyperedgedepends.Foranexampleofa2-cover,seeFigure1.\n",
      "ToanyM-coverH=(VH,AH)ofGgivenbythehomomorphismh,wecan\n",
      "associateacollectionofpotentials:thepotentialatnodei?VHisequalto\n",
      "fh(i),thepotentialatnodeh(i)?G,andforeach??AH,weassociatethe\n",
      "potentialfh(?).Inthisway,wecanconstructafunctionfH:XM|V|?\n",
      "R?0suchthatfHfactorizesoverH.WewillsaythatthegraphicalmodelHis\n",
      "anM-coverofthegraphicalmodelGwheneverHisanM-coverofGandfH\n",
      "ischosenasdescribedthabove.Itwillbeconvenientinthesequeltowritef\n",
      "H(xH)=fH(x1,...,xM)wherexmiisthemcopyofvariablei?V\n",
      ".Thereisadirectcorrespondencebetween??MLandassignmentsongraph\n",
      "covers.Thiscorrespondenceisthebasisofthefollowingtheorem.Theorem2.2\n",
      "(RuozziandTatikonda3).suph?,?i=sup??ML\n",
      "sup\n",
      "sup\n",
      "MH?CM(G)xH\n",
      "1logfH(xH)M\n",
      "whereCM(G)isthesetofallM-coversofG.Theorem2.2claimsthat\n",
      "theoptimalvalueoftheMAPLPisequaltothesupremumoverallMAP\n",
      "assignmentsoverallgraphcovers,appropriatelyscaled.Inparticular,theproof\n",
      "4\n",
      "\n",
      "ofthisresultshowsthat,undermildconditions,thereexistsanM-coverHof\n",
      "GandanassignmentxHsuchthat1HHMlogf(x)=sup??MLh?,?i.\n",
      "3\n",
      "ContinuousMRFs\n",
      "Inthissection,wewilldescribehowtoextendthepreviousresultsfrom\n",
      "discretetocontinuousMRFs(i.e.,X=R)usinggraphcovers.Therelaxation\n",
      "thatweconsiderhereistheappropriateextension3\n",
      "oftheMAPLPwhereeachofthesumsarereplacedbyintegrals[4].???\n",
      "Rdensities?i,??s.t.????(x?)dx?i=?i(xi),forall??A,i??,xi?X\n",
      "ML=?:??i=E?i[?i],foralli?V????=E??[??],forall??A\n",
      "???????\n",
      "Ourgoalistounderstandunderwhatconditionsthiscontinuousrelaxation\n",
      "istight.WaldandGloberson[4]haveapproachedthisproblembyintroducing\n",
      "afurtherrelaxationofMLwhichtheycalltheweaklocalconsistencyrelaxation\n",
      "(weakLCR).TheyprovideconditionsunderwhichtheweakLCR(andhencethe\n",
      "aboverelaxation)istight.Inparticular,theyshowthatweakLCRistightfor\n",
      "theclassoflog-concavedecomposablemodels.Inthiswork,wetakeat\n",
      "approach.WerstprovetheanalogofTheorem2.2inthecontinuouscase\n",
      "andthenweshowthattheknownconditionsthatguaranteetightnessofthe\n",
      "continuousrelaxationaresimpleconsequencesofthisgeneraltheorem.Theorem\n",
      "3.1.suph?,?i=sup??ML\n",
      "sup\n",
      "sup\n",
      "MH?CM(G)xH\n",
      "1logfH(xH)M\n",
      "whereCM(G)isthesetofallM-coversofG.TheproofofTheorem3.1\n",
      "isconceptuallystraightforward,albeittechnical,andcanbefoundinAppendix\n",
      "A.TheproofapproximatestheexpectationsinMLasexpectationswithrespect\n",
      "tosimplefunctions,appliestheknownresultsforspaces,andtakesthe\n",
      "appropriatelimit.Likeitsdiscretecounterpart,Theorem3.1providesnecessary\n",
      "andtconditionsforthecontinuousrelaxationtobetight.Inparticular,\n",
      "fortherelaxationtobetight,theoptimalsolutiononanyMcover,appropriately\n",
      "scaled,cannotexceedthevalueoftheoptimalsolutionoftheMAPproblemover\n",
      "G.3.1\n",
      "TightnessoftheMAPrelaxation\n",
      "Theorem3.1providesnecessaryandntconditionsforthetightnessof\n",
      "thecontinuousrelaxation.However,checkingthatthemaximumvalueattained\n",
      "onanyM-coverisboundedbythemaximumvalueoverthebasegraphtothe\n",
      "M,inandofitself,appearstobeadauntingtask.Inthissection,wedescribe\n",
      "twofamiliesofgraphicalmodelsforwhichthisconditioniseasytoverify:the\n",
      "log-concavedecomposablefunctionsandthelog-supermodulardecomposable\n",
      "functions.Log-concavedecomposabilityhasbeenstudiedbefore,particularly\n",
      "inthecaseofGaussiangraphicalmodels.Log-supermodularitywithrespect\n",
      "tographicalmodels,however,appearstohavebeenprimarilystudiedinthe\n",
      "discretecase.3.1.1\n",
      "Log-concavedecomposability\n",
      "5\n",
      "\n",
      "Afunctionf:Rn?R?0islog-concaveiff(x)?f(y)1???f(?x+(1\n",
      "??)y)forallx,y?Rnandall??[0,1].Iffcanbewrittenasaproduct\n",
      "oflog-concavepotentialsoverahypergraphG,wesaythatfislog-concave\n",
      "decomposableoverG.Theorem3.2.Iffislog-concavedecomposable,thensupx\n",
      "logf(x)=sup??MLh?,?i.Proof.Bylog-concavedecomposability,foranyM\n",
      "-coverHofG,H\n",
      "1\n",
      "M\n",
      "f(x,...,x)?f\n",
      "G\n",
      "x1+???+xMM\n",
      "M,\n",
      "whichweobtainbyapplyingtheoflog-concavityseparatelyto\n",
      "eachoftheMcopiesofthepotentialfunctionsforeachnodeandfactorofG.As\n",
      "aresult,supx1,...,xMfH(x1,...,xM)?supxfG(x)M.Theproofofthe\n",
      "theoremthenfollowsbyapplyingTheorem3.1.WaldandGloberson[4]provide\n",
      "atproofofTheorem3.2byexploitingdualityandtheweakLCR.4\n",
      "3.1.2\n",
      "Log-supermodulardecomposability\n",
      "Log-supermodularfunctionshaveplayedanimportantroleinthestudyof\n",
      "discretegraphicalmodels,andlog-supermodularityarisesinanumberofclas-\n",
      "sicalcorrelationsinequalities(e.g.,theFKGinequality).Forlog-supermodular\n",
      "decomposablemodels,theMAPLPistightandtheMAPproblemcanbesolved\n",
      "exactlyinpolynomialtime[19;20].Inthecontinuouscase,log-supermodularity\n",
      "isanalogouslytothediscretecase.Thatis,f:Rn?R?0islog-\n",
      "supermodulariff(x)f(y)?f(x?y)f(x?y)forallx,y?Rn,wherex?yis\n",
      "thecomponentwisemaximumofthevectorsxandyandx?yisthecomponen-\n",
      "twiseminimum.Continuouslog-supermodularfunctionsaresometimessaidto\n",
      "bemultivariatetotallypositiveofordertwo[21].Wewillsaythatagraphical\n",
      "modelislog-supermodulardecomposableiffcanbefactorizedasaproductof\n",
      "log-supermodularpotentials.Foranycollectionofvectorsx1,...,xk?Rn\n",
      ",letzi(x1,...,xk)bethevectorwhosejthcomponentistheithlargest\n",
      "elementofx1j,...,xkjforeachj?\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      ".Theorem3.3.Iffis\n",
      "log-supermodulardecomposable,thensupxlogf(x)=sup??MLh?,?i.Proof.\n",
      "Bylog-supermodulardecomposability,foranyM-coverHofG,H\n",
      "1\n",
      "M\n",
      "f(x,...,x)?\n",
      "MY\n",
      "fG(zm(x1,...,xM)).\n",
      "m=1\n",
      "Again,thisfollowsbyrepeatedlyapplyingtheoflog-supermodularity\n",
      "separatelytoeachoftheMcopiesofthepotentialfunctionsforeachnodeand\n",
      "factorofG.Asaresult,QMsupx1,...,xMfH(x1,...,xM)?supx1,...,xM\n",
      "m=1fG(xm).TheproofofthetheoremthenfollowsbyapplyingTheorem\n",
      "3.1.\n",
      "6\n",
      "\n",
      "4\n",
      "Log-supermodulardecomposabilityvs.log-concavedecomposability\n",
      "Asdiscussedabove,log-concavedecomposableandlog-supermodulardecom-\n",
      "posablemodelsarebothexamplesofcontinuousgraphicalmodelsforwhichthe\n",
      "MAPrelaxationistight.Thesetwoclassesarenotequivalent:twicecontin-\n",
      "uouslytiablefunctionsaresupermodularifandonlyifalldiagonal\n",
      "elementsoftheHessianmatrixarenon-negative.Contrastthiswithtwicecon-\n",
      "tinuouslytiableconcavefunctionswheretheHessianmatrixmustbe\n",
      "negativeInparticular,thismeansthatlog-supermodularfunc-\n",
      "tionscanbemultimodel.Inthissection,weexploretherelationshipbetween\n",
      "log-supermodularityandlog-concavity.4.1\n",
      "GaussianMRFs\n",
      "WebeginwiththecaseofGaussiangraphicalmodels,i.e.,pairwisegraphical\n",
      "modelsgivenby\n",
      "YY12TTf(x)?=?1/2xAx+bx=exp?Aiixi+bixiexp(?Aijxi\n",
      "xj)2i?V\n",
      "(i,j)?E\n",
      "n?n\n",
      "forsomesymmetricpositivematrixA?Randvectorb?Rn.Here,\n",
      "ffactorsoverthegraphGcorrespondingtothenon-zeroentriesofthematrix\n",
      "A.Gaussiangraphicalmodelsarearelativelywell-studiedclassofcontinuous\n",
      "graphicalmodels.Infact,tconditionsfortheconvergenceandcorrect-\n",
      "nessofGaussianbeliefpropagation(GaBP)areknownforthesemodels.Specif-\n",
      "ically,GaBPconvergestotheoptimalsolutionifthepositivematrixAis\n",
      "walk-summable,scaleddiagonallydominant,orlog-concavedecomposable[22;\n",
      "7;8;9].Theseconditionsareknowntobeequivalent[23;6].4.1.??\n",
      "Rn?nisscaleddiagonallydominantif?w?Rn,w>0suchthat|?ii|wi>P\n",
      "|?|wijj.j6=iInaddition,thefollowingtheoremprovidesacharacterization\n",
      "ofscaleddiagonaldominance(andhencelog-concavedecomposability)interms\n",
      "ofgraphcoversforthesemodels.Theorem4.2(RuozziandTatikonda6).Let\n",
      "Abeasymmetricpositivematrix.Thefollowingareequivalent.5\n",
      "1.Aisscaleddiagonallydominant.2.AllcoversofAarepositive\n",
      "3.All2-coversofAarepositivedenite.Theproofofthistheoremconstructs\n",
      "asp2-coverwhosecovariancematrixhasnegativeeigenvalueswhenever\n",
      "thematrixAispositivebutnotscaleddiagonallydominant.Thejoint\n",
      "distributioncorrespondingtothis2-coverisnotboundedfromabove,sothe\n",
      "optimalvalueoftheMAPrelaxationis+?asperTheorem3.1.ForGaussian\n",
      "graphicalmodels,log-concavedecomposabilityandlog-supermodulardecom-\n",
      "posabilityarerelated:everypositivelog-supermodulardecomposable\n",
      "modelislog-concavedecomposable,andeverypositivedeite,log-concavede-\n",
      "composablemodelisasignedversionofsomepositivelog-supermodular\n",
      "decomposableGaussiangraphicalmodel.Thisfollowsfromthefollowingsimple\n",
      "lemma.Lemma4.3.AsymmetricpositivematrixAisscaleddiagonally\n",
      "dominantifandonlyifthematrixBsuchthatBii=AiiforalliandBij=\n",
      "?|Aij|foralli6=jispositiveIfAispositiveandscaled\n",
      "diagonallydominant,thenthemodelislog-concavedecomposable.Incontrast,\n",
      "7\n",
      "\n",
      "themodelwouldbelog-supermodulardecomposableifallofthe\n",
      "elementsofAwerenegative,independentofthediagonal.Inparticular,the\n",
      "diagonalcouldhavebothpositiveandnegativeelements,meaningthatf(x)\n",
      "couldbeeitherlog-concave,log-convex,orneither.Aslog-convexquadratic\n",
      "formsdonotcorrespondtonormalizableGaussiangraphicalmodels,thelog-\n",
      "convexcaseappearstobelessinterestingastheMAPproblemisunbounded\n",
      "fromabove.However,thesituationisentirelytforconstrained(over\n",
      "someconvexset)log-quadraticmaximization.Asanexample,considerabox\n",
      "constrainedlog-quadraticmaximizationproblemwherethematrixAhasall\n",
      "negativeentries.Suchamodelisalwayslog-supermodulardecom-\n",
      "posable.Hence,theMAPrelaxationistight,butthemodelisnotnecessarily\n",
      "log-concave.4.2\n",
      "PairwisetwicetiableMRFs\n",
      "Alloftheresultsfromtheprevioussectioncanbeextendedtogeneraltwice\n",
      "continuouslytiablefunctionsoverpairwisegraphicalmodels(i.e.,|?|\n",
      "=2forall??A).Inthissection,unlessotherwisespassumethatall\n",
      "modelsarepairwise.Theorem4.4.Iflogf(x)isstrictlyconcaveandtwice\n",
      "continuouslytiable,thefollowingareequivalent.1.?2(logf)(x)is\n",
      "scaleddiagonallydominantforallx.2.?2(logfH)(xH)isnegative\n",
      "foreverygraphcoverHofGandeveryxH.3.?2(logfH)(xH)isnegative\n",
      "forevery2-coverHofGandeveryxH.Theequivalenceof1-3in\n",
      "Theorem4.4followsfromTheorem4.2.Corollary4.5.If?2(logf)(x)isscaled\n",
      "diagonallydominantforallx,thenthecontinuousMAPrelaxationistight.\n",
      "Corollary4.6.Iffislog-concavedecomposableoverapairwisegraphicalmodel\n",
      "andstrictlylogconcave,then?2(logf)(x)isscaleddiagonallydominantfor\n",
      "allx.Whetherornotlog-concavedecomposabilityisequivalenttotheother\n",
      "conditionslistedinthestatementofTheorem4.4remainsanopenquestion\n",
      "(thoughweconjecturethatthisisthecase).Similarideascanbeextendedto\n",
      "generaltwicecontinuouslytiablefunctions.Theorem4.7.Supposelog\n",
      "f(x)istwicecontinuouslytiablewithamaximumatx?.LetBij=\n",
      "|?2(logf)(x?)ij|foralli6=jandBii=?2(logf)(x?)ii.Iffadmitsa\n",
      "pairwisefactorizationoverGandBhasbothpositiveandnegativeeigenvalues,\n",
      "thenthecontinuousMAPrelaxationisnottight.Proof.IfBhasbothpositive\n",
      "andnegativeeigenvalues,thenthereexistsa2-coverHofGsuchthat?2(logf\n",
      "H)(x?,x?)hasbothpositiveandnegativeeigenvalues.Asaresult,thelift\n",
      "ofx?tothe6\n",
      "2-coverfHisasaddlepoint.Consequently,fH(x?,x?)<supxHf\n",
      "H(xH).ByTheorem3.1,thecontinuousMAPrelaxationcannotbetight.\n",
      "Thisnegativeresultisquitegeneral.If?2(logf)ispositivedenitebutnot\n",
      "scaleddiagonallydominantatanyglobaloptimum,thentheMAPrelaxation\n",
      "isnottight.Inparticular,thismeansthatalllog-supermodulardecomposable\n",
      "functionsthatmeettheconditionsofthetheoremmustbes.d.d.attheirop-\n",
      "tima.Algorithmically,MoallemiandVanRoy[9]arguedthatbeliefpropagation\n",
      "convergesformodelsthatarelog-concavedecomposableandscaleddiagonally\n",
      "dominant.Itisunknownwhetherornotasimilarconvergenceargumentapplies\n",
      "tolog-supermodulardecomposablefunctions.4.3\n",
      "8\n",
      "\n",
      "Concaveclosures\n",
      "Manyofthetightnessresultsinthediscretecasecanbeseenasasp\n",
      "caseofthecontinuousresultsdescribedabove.Again,supposethatX?Risa\n",
      "set.4.8.Theconcaveclosureofafunctiong:Xn?R?\n",
      "f\n",
      "??\n",
      "g\n",
      "atx?Rnisgivenby???X?PP?(y)g(y):y?(y)=1,y?(y)y=x,?(y)?\n",
      "0g(x)=sup??ny?X\n",
      "Equivalently,theconcaveclosureofafunctionisthesmallestconcavefunc-\n",
      "tionsuchthatg(x)?g(x)forallx.Afunctionanditsconcaveclosuremust\n",
      "necessarilyhavethesamemaximum.Computingtheconcave(orconvex)clo-\n",
      "sureofafunctionisNP-hardingeneral,butitcanbecientlycomputedfor\n",
      "certainspecialclassesofdiscretefunctions.Inparticular,whenX=\n",
      "f\n",
      "0,1\n",
      "g\n",
      "and\n",
      "logfissupermodular,thenitsconcaveclosurecanbecomputedinpolynomial\n",
      "timeasitisequaltotheLov?aszextensionoflogf.TheLov?aszextension\n",
      "hasanumberofinterestingproperties.Mostnotably,itislinear(theLov?asz\n",
      "extensionofasumoffunctionsisequaltosumoftheLov?aszextensions).De-\n",
      "thelog-concaveclosureofftobef?(x)=exp(logf(x)).Asaresult,if\n",
      "fislog-supermodulardecomposable,thenf?islog-concavedecomposable.Q\n",
      "QPTheorem4.9.Iff?=i?Vf?i??Af??,thensupx?Xnf(x)=??ML\n",
      "h?,?i.ThistheoremisadirectconsequenceofTheorem3.2.Forexample,the\n",
      "tightnessresultsofBayatietal.[11]andSanghavietal.[14](andindeedmany\n",
      "others)canbeseenasaspecialcaseofthistheorem.Evenwhen|X|isnot\n",
      "theconcaveclosurecanbesimilarlyandthetheoremholdsin\n",
      "thiscaseaswell.Giventhecharacterizationinthediscretecase,thissuggests\n",
      "thattherecouldbea,possiblydeep,connectionbetweenlog-concaveclosures\n",
      "andlog-supermodulardecomposability.\n",
      "5\n",
      "Discussion\n",
      "Wehavedemonstratedthatthesamenecessaryandsucientcondition\n",
      "basedongraphcoversforthetightnessoftheMAPLPinthediscretecase\n",
      "translatesseamlesslytothecontinuouscase.Thischaracterizationallowedus\n",
      "toprovidesimpleproofsofthetightnessoftheMAPrelaxationforlogconcave\n",
      "decomposableandlog-supermodulardecomposablemodels.Whiletheproofof\n",
      "Theorem3.1isnontrivial,itprovidesapowerfultooltoreasonaboutthetight-\n",
      "nessofMAPrelaxations.Wealsoexploredtheintricaterelationshipbetween\n",
      "log-concaveandlog-supermodulardecomposablityinboththediscreteandcon-\n",
      "tinuouscaseswhichprovidedintuitionaboutwhentheMAPrelaxationcanor\n",
      "cannotbetightforpairwisegraphicalmodels.\n",
      "A\n",
      "ProofofTheorem3.1\n",
      "Theproofofthistheoremproceedsintwoparts.First,wewillarguethat1\n",
      "logfH(xH).suph?,?i?supsupsup??MLMH?CM(G)xHMToseethis,\n",
      "anM-cover,H,ofGviathehomomorphismhandconsideranyassignment\n",
      "xH.Constructthemeanparameters?0?MLasfollows.7\n",
      "1M1??(x?)=M\n",
      "X\n",
      "?i(xi)=\n",
      "9\n",
      "\n",
      "Z?0i=?i(xi)?i(xi)dxiZ?0?=??(x?)??(x?)dx?\n",
      "?(xHj?xi)\n",
      "j?V(H):h(j)=i\n",
      "X\n",
      "?(xH??x?)\n",
      "??A(H):h(?)=?\n",
      "Here,?(?)istheDiracdeltafunction1.Thisimpliesthat1logfH(xH)=\n",
      "h?,?0i?suph?,?i.M??MLFortheotherdirection,some?0?MLsuch\n",
      "that?0isgeneratedbythevectorofdensities?.Wewillprovetheresultfor\n",
      "locallyconsistentprobabilitydistributionswithboundedsupport.Theresultfor\n",
      "arbitrary?willthenfollowbyconstructingsequencesofthesedistributionsthat\n",
      "converge(inmeasure)to?.Forsimplicity,wewillassumethateachpotential\n",
      "functionisstrictlypositive2.Considerthespace[?t,t]|V|forsomepositive\n",
      "integert.Wewillconsiderlocalprobabilitydistributionsthataresupported\n",
      "onsubsetsofthisspace.Thatis,supp(?i)?[?t,t]foreachiandsupp(??)\n",
      "?[?t,t]|?|foreach?.Forapositiveintegers,dividetheinterval[?t,\n",
      "t]into2s+1tintervalsofsize1/2sandletSkdenotethekthinterval.This\n",
      "partitioningdivides[?t,t]|V|intodisjointcubesofvolume1/2s|V|.\n",
      "Thedistribution?canbeapproximatedasasequenceofdistributions?1,?\n",
      "2,...asfollows.avectorofapproximatedensities?sbysettingsR2\n",
      "Sk?i(xi)dxi,ifx0i?Sk?is(x0i),0,otherwise(RQ|?|sQ??(x?)dx?\n",
      ",ifx0??kj:j??Skj2Ss0kkj:j??j??(x?),0,otherwiseRssWehave?\n",
      "??,[?t,t]?i(xi)?i(xi)dxi??0iforeachi?V(G),andR?s(x)?(x)dx?\n",
      "??0?foreach??A(G).[?t,t]|?|????ThecontinuousMAPrelaxation\n",
      "forlocalprobabilitydistributionsofthisformcanbeRexpressedintermsof\n",
      "discretevariablesoverX=\n",
      "f\n",
      "1,...,2s+1t\n",
      "g\n",
      ".Toseethis,?si(zi)=\n",
      "Sz?is(xi)dxiiRforeachzi?\n",
      "f\n",
      "1,...,2s+1t\n",
      "g\n",
      "and?s?(z?)=Sz??s(x?\n",
      ")dx?foreachz??\n",
      "f\n",
      "1,...,2s+1t\n",
      "g\n",
      "|?|.The?correspondingMAPLP\n",
      "objective,evaluatedat?s,isthenZZXXXX2|?|slogf?(x?)dx?.(1)\n",
      "?si(zi)2slog(xi)dxi+?s?(z?)i?V\n",
      "Szi\n",
      "zi\n",
      "Sz?\n",
      "??Az?\n",
      "ThisMAPLPobjectivecorrespondstoadiscretegraphicalmodelthatfac-\n",
      "torsoverthehypergraphG,withpotentialfunctionscorrespondingtotheabove\n",
      "integralsoverthepartitionsindexedbythevectorz.!!ZZYYgs(z)?exp\n",
      "2slog(xi)dxiexp2|?|slogf?(x?)dx?Szi\n",
      "i?V(G)\n",
      "=\n",
      "Yi?V(G)\n",
      "Zexp\n",
      "??A(G)\n",
      "|V(G)|s2log(xi)dx\n",
      "Sz\n",
      "Y??A(G)\n",
      "10\n",
      "\n",
      "Sz?\n",
      "Zexp\n",
      "2\n",
      "|V(G)|s\n",
      "logf?(x?)dx\n",
      "Sz\n",
      "Everyassignmentselectsasinglecubeindexedbyz.Thevalueoftheob-\n",
      "jectiveiscalculatedbyaveraginglogfoverthecubeindexedbyz.Asaresult,\n",
      "maxzgs(z)?supxf(x)andforanyM-coverHofG,maxz1:MgH,s(z1,\n",
      "...,zM)?supx1:mfH(x1,...,xM).Asthisupperboundholdsfor\n",
      "anys,itmustalsoholdforanyvectorofdistributionsthatcanbewritten\n",
      "asalimitofsuchdistributions.Now,byapplyingTheorem2.2forthediscrete\n",
      "case,h?,?0i=lims??h?,?si?1logfH(xH)asdesired.Totheproof,\n",
      "observethatanyRiemannsupMsupH?CM(G)supxHMintegrabledensity\n",
      "canbearbitrarilywellapproximatedbydensitiesofthisformast??.1\n",
      "Inordertomakethisprecise,wewouldneedtouseLebesgueintegration\n",
      "ortakeasequenceofprobabilitydistributionsoverthespaceRM|V|that\n",
      "arbitrarilywell-approximatethedesiredassignmentxH.2Thesameargument\n",
      "willapplyinthegeneralcase,buteachofthelocaldistributionsmustbecon-\n",
      "tainedinthesupportofthecorrespondingpotentialfunction(i.e.,supp(?i)?\n",
      "))fortheintegralstoexist.\n",
      "8\n",
      "2References\n",
      "[1]A.GlobersonandT.S.Jaakkola.Fixingmax-product:Convergentmessage\n",
      "passingalgorithmsforMAPLP-relaxations.InProc.21stNeuralInformation\n",
      "ProcessingSystems(NIPS),Vancouver,B.C.,Canada,2007.[2]T.Werner.A\n",
      "linearprogrammingapproachtomax-sumproblem:Areview.PatternAnaly-\n",
      "sisandMachineIntelligence,IEEETransactionson,29(7):1165?1179,2007.[3]\n",
      "N.RuozziandS.Tatikonda.Message-passingalgorithms:Reparameterizations\n",
      "andsplittings.IEEETransactionsonInformationTheory,59(9):5860?5881,\n",
      "Sept.2013.[4]Y.WaldandA.Globerson.Tightnessresultsforlocalcon-\n",
      "sistencyrelaxationsincontinuousMRFs.InProc.30thUncertaintyinArtif-\n",
      "icalIntelligence(UAI),QuebecCity,Quebec,Canada,2014.[5]T.P.Minka.\n",
      "ExpectationpropagationforapproximateBayesianinference.InProceedings\n",
      "oftheSeventeenthconferenceonUncertaintyinIntelligence(UAI),\n",
      "pages362?369,2001.[6]N.RuozziandS.Tatikonda.Message-passingal-\n",
      "gorithmsforquadraticminimization.JournalofMachineLearningResearch,\n",
      "14:2287?2314,2013.[7]D.M.Malioutov,J.K.Johnson,andA.S.Willsky.\n",
      "Walk-sumsandbeliefpropagationinGaussiangraphicalmodels.Journalof\n",
      "MachineLearningResearch,7:2031?2064,2006.[8]C.C.MoallemiandB.Van\n",
      "Roy.Convergenceofmin-summessagepassingforquadraticoptimization.In-\n",
      "formationTheory,IEEETransactionson,55(5):2413?2423,May2009.[9]C.\n",
      "C.MoallemiandB.VanRoy.Convergenceofmin-summessage-passingfor\n",
      "11\n",
      "\n",
      "convexoptimization.InformationTheory,IEEETransactionson,56(4):2041\n",
      "?2050,April2010.[10]M.J.WainwrightandM.I.Jordan.Graphicalmodels,\n",
      "exponentialfamilies,andvariationalinference.RinMachineLearning,1(1-\n",
      "2):1?305,2008.FoundationsandTrends[11]M.Bayati,C.Borgs,J.Chayes,\n",
      "andR.Zecchina.Beliefpropagationforweightedb-matchingsonarbitrary\n",
      "graphsanditsrelationtolinearprogramswithintegersolutions.SIAMJour-\n",
      "nalonDiscreteMathematics,25(2):989?1011,2011.[12]V.Kolmogorovand\n",
      "R.Zabih.Whatenergyfunctionscanbeminimizedviagraphcuts?InCom-\n",
      "puterVisionECCV2002,pages65?81.Springer,2002.[13]S.Sanghavi,D.\n",
      "M.Malioutov,andA.S.Willsky.BeliefpropagationandLPrelaxationfor\n",
      "weightedmatchingingeneralgraphs.InformationTheory,IEEETransactions\n",
      "on,57(4):2203?2212,April2011.[14]S.Sanghavi,D.Shah,andA.S.Willsky.\n",
      "Messagepassingformaximumweightindependentset.InformationTheory,\n",
      "IEEETransactionson,55(11):4822?4834,Nov.2009.[15]M.J.Wainwright,T.\n",
      "S.Jaakkola,andA.S.Willsky.MAPestimationviaagreementon(hyper)trees:\n",
      "Message-passingandlinearprogramming.InformationTheory,IEEETransac-\n",
      "tionson,51(11):3697?3717,Nov.2005.[16]DavidSontag,TalyaMeltzer,\n",
      "AmirGloberson,YairWeiss,andTommiJaakkola.TighteningLPrelaxations\n",
      "forMAPusingmessage-passing.In24thConferenceinUncertaintyin\n",
      "Intelligence,pages503?510.AUAIPress,2008.[17]P.O.Vontobel.Countingin\n",
      "graphcovers:AcombinatorialcharacterizationoftheBetheentropyfunction.\n",
      "InformationTheory,IEEETransactionson,Jan.2013.[18]P.O.Vontobel\n",
      "andR.Koetter.Graph-coverdecodingandanalysisofmessage-\n",
      "passingiterativedecodingofLDPCcodes.CoRR,abs/cs/0512078,2005.[19]\n",
      "S.Iwata,L.Fleischer,andS.Fujishige.Astronglypolynomial-timealgorithm\n",
      "forminimizingsubmodularfunctions.JournalofTheACM,1999.[20]A.Schri-\n",
      "jver.Acombinatorialalgorithmminimizingsubmodularfunctionsinstrongly\n",
      "polynomialtime.JournalofCombinatorialTheory,SeriesB,80(2):346?355,\n",
      "2000.[21]S.KarlinandY.Rinott.Classesoforderingsofmeasuresandrelated\n",
      "correlationinequalities.i.multivariatetotallypositivedistributions.Jour-\n",
      "nalofMultivariateAnalysis,10(4):467?498,1980.[22]Y.WeissandW.T.\n",
      "Freeman.CorrectnessofbeliefpropagationinGaussiangraphicalmodelsof\n",
      "arbitrarytopology.NeuralComput.,13(10):2173?2200,Oct.2001.[23]D.M.\n",
      "Malioutov.ApproximateinferenceinGaussiangraphicalmodels.Ph.D.thesis,\n",
      "EECS,MIT,2008.\n",
      "9\n",
      "12\n",
      "\n",
      "PP6791.pdf\n",
      "PP6791.pdf 13\n",
      "Generatingsteganographicimagesviaadversarial\n",
      "training\n",
      "Authoredby:\n",
      "JamieHayes\n",
      "GeorgeDanezis\n",
      "Abstract\n",
      "Adversarialtraininghasprovedtobecompetitiveagainstsupervised\n",
      "learningmethodsoncomputervisiontasks.However,studieshavemainly\n",
      "beentogenerativetaskssuchasimagesynthesis.Inthispa-\n",
      "per,weapplyadversarialtrainingtechniquestothediscriminativetask\n",
      "oflearningasteganographicalgorithm.Steganographyisacollectionof\n",
      "techniquesforconcealingtheexistenceofinformationbyembeddingit\n",
      "withinanon-secretmedium,suchascovertextsorimages.Weshowthat\n",
      "adversarialtrainingcanproducerobuststeganographictechniques:our\n",
      "unsupervisedtrainingschemeproducesasteganographicalgorithmthat\n",
      "competeswithstate-of-the-artsteganographictechniques.Wealsoshow\n",
      "thatsupervisedtrainingofouradversarialmodelproducesarobustste-\n",
      "ganalyzer,whichperformsthediscriminativetaskofdecidingifanimage\n",
      "containssecretinformation.Weagamebetweenthreeparties,Al-\n",
      "ice,BobandEve,inordertosimultaneouslytrainbothasteganographic\n",
      "algorithmandasteganalyzer.AliceandBobattempttocommunicatea\n",
      "secretmessagecontainedwithinanimage,whileEveeavesdropsontheir\n",
      "conversationandattemptstodetermineifsecretinformationisembedded\n",
      "withintheimage.WerepresentAlice,BobandEvebyneuralnetworks,\n",
      "andvalidateourschemeontwoindependentimagedatasets,showingour\n",
      "novelmethodofstudyingsteganographicproblemsissurprisinglycom-\n",
      "petitiveagainstestablishedsteganographictechniques.\n",
      "1PaperBody\n",
      "Steganographyandcryptographybothprovidemethodsforsecretcommunica-\n",
      "tion.Authenticityandintegrityofcommunicationsarecentralaimsofmodern\n",
      "cryptography.However,traditionalcryptographicschemesdonotaimtohide\n",
      "thepresenceofsecretcommunications.Steganographyconcealsthepresence\n",
      "ofamessagebyembeddingitwithinacommunicationtheadversarydoesnot\n",
      "deemsuspicious.Recentdetailsofmasssurveillanceprogramshaveshownthat\n",
      "meta-dataofcommunicationscanleadtodevastatingprivacyleakages1.NSA\n",
      "1\n",
      "\n",
      "havestatedthatthey?killpeoplebasedonmeta-data?[8];themere\n",
      "presenceofasecretcommunicationcanhavelifeordeathconsequencesevenif\n",
      "thecontentisnotknown.Concealingboththecontentaswellasthepresence\n",
      "ofamessageisnecessaryforprivacysensitivecommunication.Steganographic\n",
      "algorithmsaredesignedtohideinformationwithinacovermessagesuchthat\n",
      "thecovermessageappearsunalteredtoanexternaladversary.Agreatdealof\n",
      "istodesigningsteganographicalgorithmsthatminimizetheper-\n",
      "turbationswithinacovermessagewhenasecretmessageisembeddedwithin,\n",
      "whileallowingforrecoveryofthesecretmessage.Inthisworkweaskifa\n",
      "steganographicalgorithmcanbelearnedinanunsupervisedmanner,without1\n",
      "SeeEFF?sguide:h\n",
      "and\n",
      "dis-\n",
      "proportionate.pdf.\n",
      "humandomainknowledge.Notethatsteganographyonlyaimstohidethe\n",
      "presenceofamessage.Thus,itisnearlyalwaysthecasethatthemessage\n",
      "isencryptedpriortoembeddingusingastandardcryptographicscheme;the\n",
      "embeddedmessageisthereforeindistinguishablefromarandomstring.The\n",
      "receiverofthesteganographicimagewillthendecodetorevealtheciphertext\n",
      "ofthemessageandthendecryptusinganestablishedsharedkey.Fortheun-\n",
      "superviseddesignofsteganographictechniques,weleverageideasfromthe\n",
      "ofadversarialtraining[7].Typically,adversarialtrainingisusedtotraingen-\n",
      "erativemodelsontaskssuchasimagegenerationandspeechsynthesis.We\n",
      "designaschemethataimstoembedasecretmessagewithinanimage.Our\n",
      "taskisdiscriminative,theembeddingalgorithmtakesinacoverimageandpro-\n",
      "ducesasteganographicimage,whiletheadversarytriestolearnweaknessesin\n",
      "theembeddingalgorithm,resultingintheabilitytodistinguishcoverimages\n",
      "fromsteganographicimages.Thesuccessofasteganographicalgorithmora\n",
      "steganalysistechniqueoveroneanotheramountstoabilitytomodelthecover\n",
      "distributioncorrectly[5].Sofar,steganographicschemeshaveusedhuman-\n",
      "basedrulesto?learn?thisdistributionandperturbitinawaythatdisruptsit\n",
      "least.However,steganalysistechniquescommonlyusemachinelearningmodels\n",
      "tolearntheindistributionsbetweenthecoverandsteganographic\n",
      "images.Basedonthisinsightwepursuethefollowinghypothesis:Hypothesis:\n",
      "Machinelearningisascapableashuman-basedrulesforthetaskofmodeling\n",
      "thecoverdistribution,andsonaturallylendsitselftothetaskofdesigning\n",
      "steganographicalgorithms,aswellasperformingsteganalysis.Inthispaper,\n",
      "weintroducethesteganographicalgorithmproducedentirelyinanunsu-\n",
      "pervisedmanner,throughanoveladversarialtrainingscheme.Weshowthat\n",
      "ourschemecanbesuccessfullyimplementedinpracticebetweentwocommuni-\n",
      "catingparties,andadditionallythatwithsupervisedtraining,thesteganalyzer,\n",
      "Eve,cancompeteagainststate-of-the-artsteganalysismethods.Tothebest\n",
      "ofourknowledge,thisisoneofthereal-worldapplicationsofadversarial\n",
      "training,asidefromtraditionaladversariallearningapplicationssuchasimage\n",
      "generationtasks.\n",
      "22.1\n",
      "RelatedworkAdversariallearning\n",
      "Tworecentdesignshaveappliedadversarialtrainingtocryptographicand\n",
      "2\n",
      "\n",
      "steganographicproblems.AbadiandAndersen[2]usedadversarialtrainingto\n",
      "teachtwoneuralnetworkstoencryptashortmessage,thatfoolsadiscrimi-\n",
      "nator.However,itishardtoanevaluationtoshowthattheencryption\n",
      "schemeiscomputationallytobreak,noristhereevidencethatthisen-\n",
      "cryptionschemeiscompetitiveagainstreadilyavailablepublickeyencryption\n",
      "schemes.Adversarialtraininghasalsobeenappliedtosteganography[4],butin\n",
      "atwaytoourscheme.Whereasweseektotrainamodelthatlearnsa\n",
      "steganographictechniquebyitself,Volkhonskiyetal?s.workaugmentstheorig-\n",
      "inalGANprocesstogenerateimageswhicharemoresusceptibletoestablished\n",
      "steganographicalgorithms.InadditiontothenormalGANdiscriminator,they\n",
      "introduceasteganalyzerthatreceivesexamplesfromthegeneratorthatmay\n",
      "ormaynotcontainsecretmessages.Thegeneratorlearnstogeneraterealistic\n",
      "imagesbyfoolingthediscriminatoroftheGAN,andlearnstobeasecurecon-\n",
      "tainerbyfoolingthesteganalyzer.However,theydonotmeasureperformance\n",
      "againststate-of-the-artsteganographictechniquesmakingittoestimate\n",
      "therobustnessoftheirscheme.2.2\n",
      "Steganography\n",
      "Steganographyresearchcanbesplitintotwothestudyofstegano-\n",
      "graphicalgorithmsandthestudyofsteganalyzers.Researchintosteganographic\n",
      "algorithmsconcentratesonmethodstoembedsecretinformationwithin\n",
      "amediumwhileminimizingtheperturbationswithinthatmedium.Steganalysis\n",
      "researchseekstodiscovermethodstodetectsuchperturbations.Steganalysis\n",
      "isabinaryclastask:discoveringwhetherornotsecretinformationis\n",
      "presentwithamessage,andsomachinelearningarecommonlyused\n",
      "assteganalyzers.Leasttbit(LSB)[16]isasimplesteganographic\n",
      "algorithmusedtoembedasecretmessagewithinacoverimage.Eachpixelin\n",
      "animageismadeupofthreeRGBcolorchannels(oroneforgrayscaleimages),\n",
      "andeachcolorchannelisrepresentedbyanumberofbits.Forexample,itis2\n",
      "(1)\n",
      "CM\n",
      "CM\n",
      "EveAlice\n",
      "C\n",
      "Alice\n",
      "Eve\n",
      "p\n",
      "Bob\n",
      "M0\n",
      "(2)\n",
      "C0\n",
      "CM\n",
      "Alice\n",
      "Eve\n",
      "p\n",
      "Bob\n",
      "M0\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C0\n",
      "p\n",
      "(3)\n",
      "0\n",
      "Alice\n",
      "Bob\n",
      "Bob\n",
      "M0\n",
      "(a)\n",
      "(b)\n",
      "Figure1:(a)Diagramofthetraininggame.(b)Howtwoparties,Caroland\n",
      "David,usetheschemeinpractice:(1)Twopartiesestablishasharedkey.(2)\n",
      "Caroltrainstheschemeonasetofimages.Informationaboutmodelweights,\n",
      "architectureandthesetofimagesusedfortrainingisencryptedundertheshared\n",
      "keyandsenttoDavid,whodecryptstocreatealocalcopyofthemodels.(3)\n",
      "CarolthenusestheAlicemodeltoembedasecretencryptedmessage,creating\n",
      "asteganographicimage.ThisissenttoDavid,whousestheBobmodelto\n",
      "decodetheencryptedmessageandsubsequentlydecrypt.\n",
      "commontorepresentapixelinagrayscaleimagewithan8-bitbinaryse-\n",
      "quence.TheLSBtechniquethenreplacestheleasttbitsofthecover\n",
      "imagebythebitsofthesecretmessage.Byonlymanipulatingtheleastsig-\n",
      "tbitsofthecoverimage,thevariationincoloroftheoriginalimageis\n",
      "minimized.However,informationfromtheoriginalimageisalwayslostwhen\n",
      "usingtheLSBtechnique,andisknowntobevulnerabletosteganalysis[6].Most\n",
      "steganographicschemesforimagesuseadistortionfunctionthatforcestheem-\n",
      "beddingprocesstobelocalizedtopartsoftheimagethatareconsiderednoisy\n",
      "ortomodel.Advancedsteganographicalgorithmsattempttominimize\n",
      "thedistortionfunctionbetweenacoverimage,C,andasteganographicimage,\n",
      "C0,d(C,C0)=f(C,C0)?|C?C0|Itisthechoiceofthefunctionf,the\n",
      "costofdistortingapixel,whichchangesfortsteganographicalgorithms.\n",
      "HUGO[18]isconsideredtobeoneofthemostsecuresteganographictechniques.\n",
      "Itadistortionfunctiondomainbyassigningcoststopixelsbasedonthe\n",
      "ofembeddingsomeinformationwithinapixel,thespaceofpixelsiscon-\n",
      "densedintoafeaturespaceusingaweightednormfunction.WOW(Wavelet\n",
      "ObtainedWeights)[9]isanotheradvancedsteganographicmethodthatembeds\n",
      "informationintoacoverimageaccordingtoregionsofcomplexity.Ifaregionof\n",
      "animageismoretexturallycomplexthananother,themorepixelvalueswithin\n",
      "thatregionwillbemoFinally,S-UNIWARD[10]proposesauniversal\n",
      "distortionfunctionthatisagnostictotheembeddingdomain.However,the\n",
      "endgoalismuchthesame:tominimizethisdistortionfunction,andembedin-\n",
      "formationinnoisyregionsorcomplextextures,avoidingsmoothregionsofthe\n",
      "coverimages.InSection4.2,wecompareoutresultsagainstastate-of-the-art\n",
      "steganalyzer,ATS[13].ATSuseslabeleddatatobuildtrainingsetsof\n",
      "coverandsteganographicimages,andistrainedusinganSVMwithaGaussian\n",
      "kernel.Theyshowthatthistechniqueoutperformsotherpopularsteganalysis\n",
      "tools.\n",
      "4\n",
      "\n",
      "3\n",
      "Steganographicadversarialtraining\n",
      "Thissectiondiscussesoursteganographicscheme,themodelsweuseandthe\n",
      "informationeachpartywishestoconcealorreveal.Afterlayingthistheoretical\n",
      "groundwork,wepresentexperimentssupportingourclaims.3.1\n",
      "Learningobjectives\n",
      "Ourtrainingschemeinvolvesthreeparties:Alice,BobandEve.Alicesends\n",
      "amessagetoBob,EvecaneavesdroponthelinkbetweenAliceandBoband\n",
      "wouldliketodiscoverifthereisasecretmessageembeddedwithintheircom-\n",
      "munication.Inclassicalsteganography,Eve(theSteganalyzer)ispassedboth\n",
      "unalteredimages,calledcoverimages,andimageswithsecretmessagesembed-\n",
      "ded3\n",
      "within,calledsteganographicimages.Givenanimage,Eveplacesa\n",
      "dencescoreofhowlikelythisisacoverorsteganographicimage.Aliceembeds\n",
      "asecretmessagewithinthecoverimage,producingasteganographicimage,\n",
      "andpassesthistoBob.Bobknowstheembeddingprocessandsocanrecover\n",
      "themessage.Inourscheme,Alice,BobandEveareneuralnetworks.Aliceis\n",
      "trainedtolearntoproduceasteganographicimagesuchthatBobcanrecover\n",
      "thesecretmessage,andsuchthatEvecandonobetterthanrandomlyguess\n",
      "ifasampleisacoverorsteganographicimage.Thefullschemeisdepictedin\n",
      "Figure1a:Alicereceivesacoverimage,C,andasecretencryptedmessage,M\n",
      ",asinputs.Aliceoutputsasteganographicimage,C0,whichisgiventoboth\n",
      "BobandEve.BoboutputsM0,thesecretmessageheattemptstorecover\n",
      "fromC0.WesayBobperformsperfectlyifM=M0.Inadditiontothe\n",
      "steganographicimages,Evealsoreceivesthecoverimages.GivenaninputX,\n",
      "Eveoutputstheprobability,p,thatX=C.Alicetriestolearnanembedding\n",
      "schemesuchthatEvealwaysoutputsp=21.WedonottrainEvetomaximize\n",
      "herpredictionerror,sinceshecanthensimplyherdecisionandperformwith\n",
      "perfectclasscationaccuracy.Figure1bshowshowtheschemeshouldbeused\n",
      "inpraticeiftwopeoplewishtocommunicateasteganographicmessageusing\n",
      "ourscheme.ThecostofsendingtheencryptedmodelinformationfromCarol\n",
      "toDavidislow,withanaverageof70MB.NotethatinFigure1b,steps(1)and\n",
      "(2),theset-upofthesharedkeyandsharingofmodelinformation,isperfomed\n",
      "Weassume,asiscommonincryptographicresearch,thatthisinitial\n",
      "set-upphaseisnotvisibletoanadversary.Atthebeginningoftraining,ahu-\n",
      "mancaneasilyseparatecoverimagesfromsteganographicimages,asAlicehas\n",
      "notlearnedyethowtoembedthesecretmessagesuchthatthereisnovisible\n",
      "inthecoverimage.However,wetrainEvemuchlikeadiscrimina-\n",
      "torinaGAN,wherewetieherpredictivepowertotheembeddingcapacity\n",
      "ofAlice.WhenAliceproducesasteganographicimagethatdoesnotresemble\n",
      "thecoverimage,Evedoesnothavetheabilitytoperfectlyseparatecoverfrom\n",
      "steganographicimages.Astrainingcontinues,Evebecomesbetterathertask,\n",
      "butthensodoesAliceasherweightsareupdated,inpart,basedontheloss\n",
      "ofEve.SimilarlytoAbadiandAndersen[2],welet?A,?B,?Cdenotethe\n",
      "parametersofAlice,BobandEve,respectively.WewriteA(?A,C,M)for\n",
      "Alice?soutputonCandM,B(?b,C0)forBob?soutputonC0,andE(?E\n",
      "5\n",
      "\n",
      ",C,C0)forEve?soutputonCandC0.LetLA,LB,LCdenotethelossof\n",
      "Alice,BobandEve,respectively.Then,wehavethefollowingrelations:B(?b\n",
      ",C0)=B(?b,A(?A,C,M))E(?E,C,C0)=E(?E,C,A(?A,C,M))\n",
      "WesetBob?sloss(thesecretmessagereconstructionloss),tobetheEuclidean\n",
      "distancebetweenMandM0:LB(?A,?B,M,C)=d(M,B(?b,C0))=d(M,\n",
      "B(?b,A(?A,C,M))=d(M,M0)AsiscommonwithGANdiscriminator\n",
      "implementations,wesettheEve?slosstobesigmoidcrossentropyloss:LE(?E\n",
      ",C,C0)=?y?log(E(?E,x))?(1?y)?log(1?E(?E,x)),wherey=0if\n",
      "x=C0andy=1ifx=C.Alice?slossisgivenasaweightedsumofBob?s\n",
      "loss,Eve?slossonsteganographicimages,andanadditionalreconstructiveloss\n",
      "term:LA(?A,C,M)=?A?d(C,C0)+?B?LB+?E?LE(?E,C,C0\n",
      "),whered(C,C0)istheEuclideandistancebetweenthecoverimageandthe\n",
      "steganographicimage,and?A,?B,?E?Rtheweightgiventoeachre-\n",
      "spectivelossterm.Ourgoalisnotonlytoexplorewhetherneuralnetworkscan\n",
      "producesteganographicembeddingalgorithmsinanunsupervisedmanner,but\n",
      "whethertheyarecompetitiveagainststeganographicalgorithmslikeHUGO,\n",
      "WOWandS-UNIWARD,thathavebeendesignedbysteganographyexperts.\n",
      "Wedidnotintendtoencodeaspalgorithmwithintheneuralnetwork,\n",
      "ratherwewouldliketogivethenetworkstheopportunitytodevisetheirown.\n",
      "4\n",
      "(a)Coverimages.\n",
      "(b)Steganographic(0.1bpp).\n",
      "(c)Steganographic(0.4bpp).\n",
      "images\n",
      "images\n",
      "Figure2:CoverandsteganographicimagesfromthecelebAdataset,with\n",
      "embeddingratesof0.1bppand0.4bpp.2.0\n",
      "AliceBobEve\n",
      "1.5\n",
      "1.41.2\n",
      "Loss\n",
      "Loss\n",
      "1.0\n",
      "1.0\n",
      "0.80.6\n",
      "AliceBobEve\n",
      "0.4\n",
      "0.5\n",
      "0.2\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "Steps\n",
      "6\n",
      "\n",
      "120\n",
      "140\n",
      "0\n",
      "100\n",
      "80\n",
      "60\n",
      "40\n",
      "20\n",
      "00\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "Steps\n",
      "100\n",
      "120\n",
      "40\n",
      "60\n",
      "80\n",
      "Steps\n",
      "100\n",
      "120\n",
      "140\n",
      "(b)Alice,BobandEveerrorfor0.4bpp.Numberofbitscorrectlydecoded\n",
      "(outof400)\n",
      "Numberofbitscorrectlydecoded(outof100)\n",
      "(a)Alice,BobandEveerrorfor0.1bpp.\n",
      "20\n",
      "140\n",
      "(c)Bobdecodingsuccessfor0.1bpp.\n",
      "4003503002502001501005000\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "Steps\n",
      "100\n",
      "120\n",
      "140\n",
      "(d)Bobdecodingsuccessfor0.4bpp.\n",
      "Figure3:ResultsoncelebAdatasetatanembeddingrateof0.1bppand\n",
      "0.4bpp.\n",
      "3.2\n",
      "Architecture\n",
      "Alice(SteganographicEncoder).Aliceacceptsasinputacoverimageand\n",
      "arandomn-bitbinarymessage.Thecoverimageisandconcatenated\n",
      "7\n",
      "\n",
      "withthesecretmessage,whichisthenfedintotheneuralnetwork.Wewould\n",
      "likethelocalityoftheembeddingprocesstobelearnedinsteadofthe\n",
      "layerisfullyconnectedtothenext,allowingthesecretmessagetobecombined\n",
      "withanyregionofthecoverimage.Wethenreshapeto4?4?I?8,where\n",
      "Iiswidthofthecoverimage.Eachofthenextfourlayersareasequence\n",
      "ofupsamplingfractionally-stridedconvolutions,batchnormalizationandReLU\n",
      "[17],exceptforthelayerwheretanh[12]isusedastheactivationfunction.\n",
      "Bob(SteganographicDecoder).Bobacceptsasinputthesteganographicimage\n",
      "outputbyAlice.Bobusesadeepconvolutionalarchitecturetoextractthe\n",
      "importantbitsfromtheoutputofAlice.Itismadeupoffourfractionally-\n",
      "stridedconvolutionsandonefullyconnectedlayer.LeakyReLU[15]is\n",
      "usedinallbutthelayer,wheretanhisused.Batchnormalizationis\n",
      "appliedateachlayer.Eve(Steganalyzer).Eveacceptsasinputbothcover\n",
      "imagesandsteganographicimages.EvehasasimilararchitecturetoBobbut\n",
      "usesthesigmoidactivationfunctioninsteadoftanhatthelayertooutput\n",
      "probabilitiesfromthelogits.5\n",
      "4\n",
      "Experiments\n",
      "Asaproofofconcept,weimplementedouradversarialtrainingschemeon\n",
      "twoimagedatasets:celebrityfacesinthewild(celebA)[14]andastandard\n",
      "steganographyresearchdataset,BOSS2.Weconcatenateann-bitrandom\n",
      "message,witheachsampleofeachdataset.Wevarythesizeofthemessage,n,\n",
      "totestthelimitsoftheamountofinformationthatcanbeelyhidden\n",
      "insideacoverimage.Thiscorrespondstothenumberofbitsperpixel(bpp)\n",
      "thatcanbehiddenbyasteganographicalgorithm,acommonmeasureofthe\n",
      "successofasteganographicresearch.Onaverage,steganographicalgorithms\n",
      "cansuccessfullyhideapproximately0.4bpp.Ourdatasetsareformedof32?\n",
      "32pixelimages,andsowevarynfrom100to400,thiscorrespondstohiding\n",
      "betweenapproximately0.1bppto0.4bpp.Weintentionallyrandomizethesecret\n",
      "messagesothatthenetworkdoesnotlearnaspfunctionassociatedwitha\n",
      "spgroupofmessages.Wewanttobesurethatourmodelcangeneralizeto\n",
      "anymessagethatislessthannbits3.Foreachexperiment,weperformedgrid\n",
      "searchtotheoptimumlossweights,?A,?B,?E,forAlice.Allexperiments\n",
      "inthissectionwereperformedinTensorFlow[1,3],onaworkstationwithaTesla\n",
      "K40GPUcard.4.1\n",
      "CelebAdataset\n",
      "Wemotivateourworkbyshowingourmodelcanproducestegano-\n",
      "graphicimagesthatarealmostindistinguishablefromthecoverimages.We\n",
      "varythesizeoftheembeddedsecretmessage,toexplorehowmanybitsmay\n",
      "bestoredinacoverimagewhileremainingundetectedbyasteganalyzer.As\n",
      "expected,wethatalargerperturbationinthecoverimageresultsinmore\n",
      "communicatedbitsbutcarriesagreaterriskofdetection.ThecelebAdataset\n",
      "consistsof202,599imagesofcelebrityfacesfrom10,177uniqueidentities.We\n",
      "traininbatchesof32,andusetheAdamoptimizer[11]withalearningrateof\n",
      "2?10?4.AteachbatchwealternatetrainingeitherAliceandBob,orEve.\n",
      "Figure2bandFigure2cshowthesteganographicimagesoutputbyAliceafter\n",
      "8\n",
      "\n",
      "150trainingsteps,forembeddingratesof0.1bppand0.4bpp,respectively.Our\n",
      "schemeeasilycopeswithanembeddingrateof0.1bppfora32?32image,\n",
      "whichisequivalenttocommunicatingashort12characterASCIImessage.Fig-\n",
      "ure3aandFigure3cshowsthetraininglossofeachmodel,andthesuccessof\n",
      "Bobdecodingthesecretmessageovertime,respectively.Inthestfewrounds\n",
      "oftraining,thevisualqualityofAlice?soutputislowandBobisessentially\n",
      "randomlyguessingthemessage.Afterapproximately30steps,Alicelearnsto\n",
      "successfullyembedinformationinacoverimagesuchthatEveisfooled,and\n",
      "Boblearnstocorrectlydecodethemessage.After150trainingsteps,Bobde-\n",
      "codesthemessagewithanaveragesuccessof100%,whileEve?slossremainsthe\n",
      "same.Figure3bandFigure3dshowsimilarresults,withbothsamplequality\n",
      "andsuccessofdecodingbothhighbytheendoftraining.Concealing0.4bpp\n",
      "correspondstosuccessfullyhidingamessageof51ASCIIcharacters.Duetothe\n",
      "largeramountofinformationcommunicatedbetweenAliceandBob,ittakesa\n",
      "longerperiodoftimeforAlicetodiscoveraneembeddingscheme,and\n",
      "forBobtocorrectlydiscoverthesecretmessage.After150trainingsteps,Bob\n",
      "cansuccessfullydecode100%ofthemessage.Thereisnonoticeableimage\n",
      "qualitydecreasebetween0.1bppand0.4bpp,howeverwefoundafter0.4bpp,\n",
      "imagequalityanditwasnolongerpossibletobalancerealisticimage\n",
      "creationcapableoffoolingEve,andconvergenceofmessagedecoding.Forboth\n",
      "embeddingratesof0.1bppand0.4bpp,Eve?slossremainedconstantatapprox-\n",
      "imately1.4.Eve?slossisthesumoflossesonbothsteganographicimagesand\n",
      "coverimages,whichbothremainedsteadyatapproximately0.69.Duetothe\n",
      "logarithmicterminthelossfunction,thisisequivalenttorandomlyguessingif\n",
      "animagecarriesasecretmessage.4.2\n",
      "BOSSdataset\n",
      "InadditiontoourexperimentsonthecelebAdataset,wetrainedourstegano-\n",
      "graphicschemeontheBOSSimagedataset,whichiscommonlyusedasabench-\n",
      "markinsteganographyresearch.BOSSismadeupof10,000grayscaleimages\n",
      "depictingavarietyofscenessuchaslandscapes,buildingsandanimals.We\n",
      "expectedourschemetoperformworsethanonthecelebAdataset,sincethe\n",
      "cover23\n",
      "http://agents.fel.cvut.cz/boss/index.php?mode=VIEW&tmpl=materialsThis\n",
      "ensuresourschemecanembedciphertextsofmessages,whichappearasrandom\n",
      "strings.\n",
      "6\n",
      "(b)Steganographicimages(0.1bpp).\n",
      "Numberofbitscorrectlydecoded(outof100)\n",
      "(a)Coverimagesofbuildings,birds,skiesandtheocean.\n",
      "1.41.2\n",
      "Loss\n",
      "1.0\n",
      "AliceBobEve\n",
      "0.80.60.40.2\n",
      "0\n",
      "20\n",
      "9\n",
      "\n",
      "40\n",
      "60\n",
      "80\n",
      "Steps\n",
      "100\n",
      "120\n",
      "140\n",
      "(c)Alice,BobandEveerrorfor0.1bpp.\n",
      "100\n",
      "80\n",
      "60\n",
      "40\n",
      "20\n",
      "00\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "Steps\n",
      "100\n",
      "120\n",
      "140\n",
      "(d)Bobdecodingsuccessfor0.1bpp.\n",
      "Figure4:ResultsonBOSSdatasetatanembeddingrateof0.1bpp.\n",
      "imagesdonotcomefromasingledistribution.However,wefoundour\n",
      "schemeisstillcapableofembeddingsecretinformationsuccessfully.Figure4b\n",
      "showsthesamplequalityofsteganographicimageswithanembeddingrateof\n",
      "0.1bpp,whileFigure4candFigure4dshowtheerrorratesofAlice,Boband\n",
      "Eve,andthesuccessofBobdecodingthesecretmessage,respectively.While\n",
      "imagequalityslightlymorethanonthecelebAdataset,ourschemeis\n",
      "stillabletolearnasteganographicalgorithm.Ourschemeisoutputsamples\n",
      "thatarenotdissimilarfromtheoriginaldataset,whileBobisabletolearnto\n",
      "successfullydecodethemessage.AliceandBobbothlearntheirrespectivetasks\n",
      "inarelativelyshortperiodoftime,afterwhichthereisnotmuchimprovement\n",
      "intermsofhidingorrecoveringthesecretmessage.Attheendoftraining,Bob\n",
      "isabletosuccessfullydecodethesecretmessagewith99.8%accuracy.4.3\n",
      "Comparisonwithrelatedwork\n",
      "Foolingasteganalyzer,Eve,iseasybydesign,sincewetraininsuchaway\n",
      "thatEveneverhasatcompetitiveadvantage.Thus,weaddition-\n",
      "allyshowthattheresultanttrainedsteganographicmodel,Alice,canfoolan\n",
      "independentsteganalyzer.Wecompareourschemeagainstbothstate-of-the-\n",
      "artsteganographicalgorithmsandsteganalysistoolsandshowthatitperforms\n",
      "competitively.ForbothBOSSandCelebA,wecompareourschemeagainst\n",
      "steganographicalgorithmsHUGO,WOWandS-UNIWARD.Additionally,we\n",
      "implementtheEvemodelusingsupervisedtrainingandcompareagainstthe\n",
      "steganalyzerATSinTable1.Bydesign,Eveonlyperformsslightlybetterthan\n",
      "10\n",
      "\n",
      "random.OnemaywonderwhetherthechoiceofmodelforEveiswise;why\n",
      "notuseanestablishedsteganalyzerinplaceoftheEvemodel?BytrainingEve\n",
      "inasupervisedfashion,weshowthatEvehasthecapacitytobecomeastrong\n",
      "steganalyzer,competingagainstestablishedtechniqueslikeATS,andsoisa\n",
      "goodchoiceforthesteganalyzer.Furthermore,Evedoesnotrequireafeature\n",
      "extractionpreprocessingstepaswithATS,and,fromourexperiments,isanor-\n",
      "derofmagnitudequickertotrain.ForboththeBOSSandCelebAdatasets,we\n",
      "use10,000samplesandsplitinhalf,creatingatrainingsetandatestset.Alice\n",
      "wasthentrainedonthe5000samplesfromthetrainingset.Wethencreated\n",
      "anadditional10,000steganographicimagesforeachsteganographicalgorithm\n",
      "(Alice,HUGO,WOWandS-UNIWARD).Noweachsteganographicalgorithm\n",
      "hasanassociatedtraining7\n",
      "Table1:Accuracyofdistinguishingbetweencoverandsteganographicim-\n",
      "agesforthesteganalyzers,EveandATS,ontheBOSSandCelebAdatasetsat\n",
      "anembeddingrateof0.4bpp.\n",
      "STEGANOGRAPHICALGORITHMALICEHUGOWOWS-UNIWARD\n",
      "BOSSSTEGANALYZERATSEVE0.830.790.660.590.750.740.770.72\n",
      "CELEBASTEGANALYZERATSEVE0.950.900.940.890.890.850.91\n",
      "0.84\n",
      "setandtestset,eachconsistingof5000coverimagesand5000stegano-\n",
      "graphicimages.ForeachsteganographicalgorithmwetrainbothATSand\n",
      "Eveontheassociatedtrainingset,andthenreportaccuracyofthestegana-\n",
      "lyzeronthetestset.FromTable1,Eveperformscompetitivelyagainstthe\n",
      "steganalyzer,ATS,andAlicealsoperformswellagainstothersteganographic\n",
      "techniques.Whileourschemedoesnotsubstantiallyimproveoncurrentpop-\n",
      "ularsteganographicmethods,itisclearthatitdoesnotperformtly\n",
      "worse,andthatunsupervisedtrainingmethodsarecapableofcompetingwith\n",
      "expertdomainknowledge.4.4\n",
      "Evaluatingrobustdecryption\n",
      "Duetothenon-convexityofthemodelsinthetrainingscheme,wecannot\n",
      "guaranteethattwoseparatepartiestrainingonthesameimageswillconverge\n",
      "tothesamemodelweights,andsolearnthesameembeddinganddecoding\n",
      "algorithms.Thus,priortosteganographiccommunication,werequireoneofthe\n",
      "communicatingpartiestotraintheschemelocally,encryptmodelinformation\n",
      "andpassittotheotherpartyalongwithinformationaboutthesetoftraining\n",
      "images.Thisensuresbothpartieslearnthesamemodelweights.Tovalidate\n",
      "thepracticalityofouridea,wetrainedtheschemelocally(MachineA)andthen\n",
      "sentmodelinformationtoanotherworkstation(MachineB)thatreconstructed\n",
      "thelearnedmodels.Wethenpassedsteganographicimages,embeddedbythe\n",
      "AlicemodelfromMachineA,toMachineB,whousedtheBobmodeltorecover\n",
      "thesecretmessages.Usingmessagesoflengthcorrespondingtohiding0.1bpp,\n",
      "andrandomlyselecting10%oftheCelebAdataset,MachineBwasableto\n",
      "recover99.1%ofmessagessentbyMachineA,over100trials;ourschemecan\n",
      "successfullydecodethesecretencryptedmessagefromthesteganographicimage.\n",
      "Notethatourschemedoesnotrequireperfectdecodingaccuracytosubsequently\n",
      "decryptthemessage.Areceiverofasteganographicmessagecansuccessfully\n",
      "11\n",
      "\n",
      "decodeanddecryptthesecretmessageifthemodeofencryptioncantolerate\n",
      "errors.Forexample,usingastreamciphersuchasAES-CTRguaranteesthat\n",
      "incorrectlydecodedbitswillnottheabilitytodecrypttherestofthe\n",
      "message.\n",
      "5\n",
      "Discussion&conclusion\n",
      "Wehavesubstantialevidencethatourhypothesisiscorrectand\n",
      "machinelearningcanbeusedelyforbothsteganalysisandstegano-\n",
      "graphicalgorithmdesign.Inparticular,itiscompetitiveagainstdesignsus-\n",
      "inghuman-basedrules.Byleveragingadversarialtraininggames,we\n",
      "thatneuralnetworksareabletodiscoversteganographicalgorithms,andfur-\n",
      "thermore,thesesteganographicalgorithmsperformwellagainststate-of-the-\n",
      "arttechniques.Ourschemedoesnotrequiredomainknowledgefordesigning\n",
      "steganographicschemes.Wemodeltheattackerasanotherneuralnetwork\n",
      "andshowthatthisattackerhasenoughexpressivitytoperformwellagainsta\n",
      "state-of-the-artsteganalyzer.Weexpectthisworktoleadtofruitfulavenues\n",
      "offurtherresearch.Findingthebalancebetweencoverimagereconstruction\n",
      "loss,Bob?slossandEve?slosstodiscoveranctiveembeddingschemeis\n",
      "currentlydoneviagridsearch,whichisatimeconsumingprocess.Discovering\n",
      "amoremethodwouldgreatlyimprovetheofthetrainingpro-\n",
      "cess.Indeed,discoveringamethodtoquicklycheckwhetherthecoverimage\n",
      "hasthecapacitytoacceptasecretmessagewouldbeagreatimprovementover\n",
      "thetrial-and-errorapproachcurrentlyimplemented.Italsobecameclearthat\n",
      "AliceandBoblearntheirtasksafterarelativelysmallnumberoftrainingsteps,\n",
      "furtherresearchisneededtoexploreifAliceandBobfailtoimprovedueto\n",
      "limitationsinthemodelorbecauseofshortcomingsinthetrainingscheme.8\n",
      "6\n",
      "Acknowledgements\n",
      "TheauthorswouldliketoacknowledgesupportfromtheUKGov-\n",
      "ernmentCommunicationsHeadquarters(GCHQ),aspartofUniversityCollege\n",
      "London?sstatusasarecognisedAcademicCentreofExcellenceinCyberSe-\n",
      "curityResearch.JamieHayesissupportedbyaGooglePhDFellowshipin\n",
      "MachineLearning.Wethanktheanonymousreviewersfortheircomments.\n",
      "2References\n",
      "[1]Mart?nAbadi,AshishAgarwal,PaulBarham,EugeneBrevdo,ZhifengChen,\n",
      "CraigCitro,GregSCorrado,AndyDavis,Dean,MatthieuDevin,etal.\n",
      "Tw:Large-scalemachinelearningonheterogeneousdistributedsystems.\n",
      "arXivpreprintarXiv:1603.04467,2016.[2]Mart?nAbadiandDavidGAnder-\n",
      "sen.Learningtoprotectcommunicationswithadversarialneuralcryptography.\n",
      "arXivpreprintarXiv:1610.06918,2016.[3]Mart?nAbadi,PaulBarham,Jian-\n",
      "minChen,ZhifengChen,AndyDavis,Dean,MatthieuDevin,Sanjay\n",
      "Ghemawat,Irving,MichaelIsard,etal.Tensorw:Asystemfor\n",
      "large-scalemachinelearning.2016.[4]BorisBorisenkoDenisVolkhonskiyand\n",
      "12\n",
      "\n",
      "EvgenyBurnaev.Generativeadversarialnetworksforimagesteganography.\n",
      "ICLR2016OpenReview,2016.[5]Tom??Filler,AndrewDKer,andJessica\n",
      "Fridrich.Thesquarerootlawofsteganographiccapacityformarkovcovers.In\n",
      "IS&T/SPIEElectronicImaging,pages725408?725408.InternationalSocietyfor\n",
      "OpticsandPhotonics,2009.[6]JessicaFridrich,MiroslavGoljan,andRuiDu.\n",
      "Detectinglsbsteganographyincolor,andgray-scaleimages.IEEEmultimedia,\n",
      "8(4):22?28,2001.[7]IanGoodfellow,JeanPouget-Abadie,MehdiMirza,Bing\n",
      "Xu,DavidWarde-Farley,SherjilOzair,AaronCourville,andYoshuaBengio.\n",
      "Generativeadversarialnets.InZ.Ghahramani,M.Welling,C.Cortes,N.D.\n",
      "Lawrence,andK.Q.Weinberger,editors,AdvancesinNeuralInformationPro-\n",
      "cessingSystems27,pages2672?2680.CurranAssociates,Inc.,2014.[8]M.\n",
      "Hayden.Thepriceofprivacy:Re-evaluatingthensa,2014.[9]VojtechHolub\n",
      "andJessicaFridrich.Designingsteganographicdistortionusingdirectional\n",
      "ters.InInformationForensicsandSecurity(WIFS),2012IEEEInternational\n",
      "Workshopon,pages234?239.IEEE,2012.[10]Vojt?echHolub,JessicaFridrich,\n",
      "andTom??Denemark.Universaldistortionfunctionforsteganographyinan\n",
      "arbitrarydomain.EURASIPJournalonInformationSecurity,2014(1):1,2014.\n",
      "[11]DiederikKingmaandJimmyBa.Adam:Amethodforstochasticopti-\n",
      "mization.arXivpreprintarXiv:1412.6980,2014.[12]YannALeCun,L?on\n",
      "Bottou,GenevieveBOrr,andKlaus-RobertM?ller.tbackprop.In\n",
      "Neuralnetworks:Tricksofthetrade,pages9?48.Springer,2012.[13]Daniel\n",
      "Lerch-HostalotandDavidMeg?as.Unsupervisedsteganalysisbasedon\n",
      "trainingsets.Eng.Appl.Artif.Intell.,50(C):45?59,April2016.[14]ZiweiLiu,\n",
      "PingLuo,XiaogangWang,andXiaoouTang.Deeplearningfaceattributesin\n",
      "thewild.InProceedingsoftheIEEEInternationalConferenceonComputer\n",
      "Vision,pages3730?3738,2015.[15]AndrewLMaas,AwniYHannun,andAn-\n",
      "drewYNg.nonlinearitiesimproveneuralnetworkacousticmodels.In\n",
      "Proc.ICML,volume30,2013.[16]JarnoMielikainen.Lsbmatchingrevisited.\n",
      "IEEEsignalprocessingletters,13(5):285?287,2006.9\n",
      "[17]VinodNairandEHinton.linearunitsimprovere-\n",
      "strictedboltzmannmachines.InProceedingsofthe27thinternationalconfer-\n",
      "enceonmachinelearning(ICML-10),pages807?814,2010.[18]Tom??Pevn`y,\n",
      "Tom??Filler,andPatrickBas.Usinghigh-dimensionalimagemodelstoper-\n",
      "formhighlyundetectablesteganography.InInternationalWorkshoponInfor-\n",
      "mationHiding,pages161?177.Springer,2010.\n",
      "10\n",
      "13\n",
      "\n",
      "PP6034.pdf\n",
      "PP6034.pdf 11\n",
      "FastRatesforExp-concaveEmpiricalRisk\n",
      "Minimization\n",
      "Authoredby:\n",
      "TomerKoren\n",
      "Levy\n",
      "Abstract\n",
      "WeconsiderEmpiricalRiskMinimization(ERM)inthecontextof\n",
      "stochasticoptimizationwithexp-concaveandsmoothlosses|ageneral\n",
      "optimizationframeworkthatcapturesseveralimportantlearningprob-\n",
      "lemsincludinglinearandlogisticregression,learningSVMswiththe\n",
      "squaredhinge-loss,portfolioselectionandmore.Inthissetting,wees-\n",
      "tablishtheevidencethatERMisabletoattainfastgeneralization\n",
      "rates,andshowthattheexpectedlossoftheERMsolutionin$d$dimen-\n",
      "sionsconvergestotheoptimalexpectedlossinarateof$d/n$.Thisrate\n",
      "matchesexistinglowerboundsuptoconstantsandimprovesbya$log\n",
      "f\n",
      "n\n",
      "g\n",
      "$\n",
      "factoruponthestate-of-the-art,whichisonlyknowntobeattainedby\n",
      "anonline-to-batchconversionofcomputationallyexpensiveonlinealgo-\n",
      "rithms.\n",
      "1PaperBody\n",
      "Statisticallearningandstochasticoptimizationwithexp-concavelossfunctions\n",
      "capturesseveralfundamentalproblemsinstatisticalmachinelearning,which\n",
      "includelinearregression,logisticregression,learningsupport-vectormachines\n",
      "(SVMs)withthesquaredhingeloss,andportfolioselection,amongstothers.\n",
      "Exp-concavefunctionsconstitutearichclassofconvexfunctions,whichis\n",
      "substantiallyricherthanitsmorefamiliarsubclassofstronglyconvexfunc-\n",
      "tions.Similarlytotheirstrongly-convexcounterparts,itiswell-knownthat\n",
      "exp-concavelossfunctionsareamenabletofastgeneralizationrates.Specif-\n",
      "ically,astandardonline-to-batchconversion[6]ofeithertheOnlineNewton\n",
      "Stepalgorithm[8]orexponentialweightingschemes?[5,8]inddimensions\n",
      "givesrisetoconvergencerateofd/n,asopposedtothestandard1/nrateof\n",
      "generic(Lipschitz)stochasticconvexoptimization.Unfortunately,thelatteron-\n",
      "linemethodsarehighlytcomputationally-wise;e.g.,theruntimecom-\n",
      "plexityoftheOnlineNewtonStepalgorithmscalesasd4withthedimension\n",
      "oftheproblem,eveninverysimpleoptimizationscenarios[13].Analterna-\n",
      "tiveandwidely-usedlearningparadigmisthatofEmpiricalRiskMinimization\n",
      "1\n",
      "\n",
      "(ERM),whichisoftenregardedasthestrategyofchoiceduetoitsgenerality\n",
      "anditsstatistical.Inthisscheme,asampleoftraininginstancesis\n",
      "drawnfromtheunderlyingdatadistribution,andtheminimizerofthesam-\n",
      "pleaverage(ortheregularizedsampleaverage)iscomputed.Asopposedto\n",
      "methodsbasedononline-to-batchconversions,theERMapproachenablesthe\n",
      "useofanyoptimizationprocedureofchoiceanddoesnotrestrictonetouse\n",
      "asponlinealgorithm.Furthermore,theERMsolutionoftenenjoyssev-\n",
      "eraldistribution-dependentgeneralizationboundsinconjunction,andthusis\n",
      "abletoobliviouslyadapttothepropertiesoftheunderlyingdatadistribution.\n",
      "Inthecontextofexp-concavefunctions,however,nothingisknownaboutthe\n",
      "generalizationabilities?ofERMbesidesthestandard1/nconvergencerate\n",
      "thatappliestoanyconvexlosses.Surprisingly,itappearsthateveninthespe-\n",
      "andextensively-studiedcaseoflinearregressionwiththesquaredloss,the\n",
      "stateofremainsunsettled:thisimportantcasewasrecentlyaddressed\n",
      "byShamir1\n",
      "[19],whoproveda?(d/n)lowerboundontheconvergencerateofanyal-\n",
      "gorithm,andconjecturedthattherateofanERMapproachshouldmatchthis\n",
      "lowerbound.Inthispaper,weexploretheconvergencerateofERMforstochas-\n",
      "ticexp-concaveoptimization.Weshowthatwhentheexp-concavelossfunctions\n",
      "arealsosmooth,aslightly-regularizedERMapproachyieldsaconvergencerate\n",
      "ofO(d/n),whichmatchesthelowerboundofShamir[19]uptoconstants.In\n",
      "fact,ourresultshowsforERMageneralizationratetighterthanthestate-of-\n",
      "the-artobtainedbytheOnlineNewtonStepalgorithm,improvinguponthe\n",
      "latterbyalognfactor.Eveninthespcaseoflinearregressionwiththe\n",
      "squaredloss,ourresultimprovesbyalog(n/d)factoruponthebestknown\n",
      "fastratesprovidedbytheVovk-Azoury-Warmuthalgorithm[3,22].Ourresults\n",
      "openanavenueforpotentialimprovementstotheruntimecomplexityofexp-\n",
      "concavestochasticoptimization,bypermittingtheuseofacceleratedmethods\n",
      "forlarge-scaleregularizedlossminimization.Thelatterhasbeenthetopicof\n",
      "anextensiveresearchinrecentyears,andnumeroustmeth-\n",
      "odshavebeendeveloped;see,e.g.,JohnsonandZhang[10],ShalevShwartzand\n",
      "Zhang[16,17]andthereferencestherein.Onthetechnicalside,ourconver-\n",
      "genceanalysisreliesonstabilityargumentsintroducedbyBousquetand\n",
      "[4].WeprovethattheexpectedlossoftheregularizedERMsolutiondoesnot\n",
      "changetlywhenasingleinstance,pickeduniformlyatrandomfrom\n",
      "thetrainingsample,isdiscarded.Then,thetechniqueofBousquetandElisse-\n",
      "[4]allowsustotranslatethisaveragestabilitypropertyintoageneralization\n",
      "guarantee.Weremarkthatinallpreviousstabilityanalysesthatweareaware\n",
      "of,stabilitywasshowntoholduniformlyoveralldiscardedtrainingintances,\n",
      "eitherwithprobabilityone[4,16]orinexpectation[20];incontrast,inthecase\n",
      "ofexp-concavefunctionsitiscrucialtolookattheaveragestability.Inorderto\n",
      "boundtheaveragestabilityofERM,wemakeuseofalocalizednotionofstrong\n",
      "convexity,withrespecttoalocalnormatacertainpointintheopti-\n",
      "mizationdomain.Roughlyspeaking,weshowthatwhenlookingattheright\n",
      "norm,whichisdeterminedbythelocalpropertiesoftheempiricalriskatthe\n",
      "rightpoint,theminimizeroftheempiricalriskbecomesstable.Thispartofour\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysisisinspiredbyrecentanalysistechniquesofregularization-basedonline\n",
      "learningalgorithms[1],thatuselocalnormstostudytheregretperformanceof\n",
      "onlinelinearoptimizationalgorithms.1.1\n",
      "RelatedWork\n",
      "Thestudyofexp-concavelossfunctionswasinitiatedintheonlinelearn-\n",
      "ingcommunitybyKivinenandWarmuth[12],whoconsideredtheproblem\n",
      "ofpredictionwithexpertadvicewithexp-concavelosses.Later,Hazanetal.\n",
      "[8]consideredamoregeneralframeworkthatallowsforacontinuousdecision\n",
      "set,andproposedtheOnlineNewtonStep(ONS)algorithmthatattainsare-\n",
      "gretboundthatgrowslogarithmicallywiththenumberofoptimizationrounds.\n",
      "Mahdavietal.[15]consideredtheONSalgorithminthestatisticalsetting,and\n",
      "showedhowitcanbeusedtoestablishgeneralizationboundsthatholdwith\n",
      "highprobability,whilestillkeepingthefast1/nrate.Fastconvergencerates\n",
      "instochasticoptimizationareknowntobeachievableundervariousconditions.\n",
      "Bousquetand[4]andShalev-Shwartzetal.[18]haveshown,viaa\n",
      "uniformstabilityargument,thatERMguaranteesaconvergencerateof1/nfor\n",
      "stronglyconvexfunctions.Sridharanetal.[21]provedasimilarresult,albeit\n",
      "usingthenotionoflocalizedRademachercomplexity.Forthecaseofsmooth\n",
      "andnon-negativelosses,Srebroetal.[20]establisheda1/nrateinlow-noise\n",
      "conditions,i.e.,whentheexpectedlossofthebesthypothesisisoforder1/n.\n",
      "Forfurtherdiscussionoffastratesinstochasticoptimizationandlearning,see\n",
      "[20]andthereferencestherein.\n",
      "2\n",
      "SetupandMainResults\n",
      "WeconsidertheproblemofminimizingastochasticobjectiveF(w)=E[f\n",
      "(w,Z)]d\n",
      "(1)\n",
      "overaclosedandconvexdomainW?Rind-dimensionalEuclideanspace.\n",
      "Here,theexpectationistakenwithrespecttoarandomvariableZdistributed\n",
      "accordingtoanunknowndistributionoveraparameterspaceZ.Givenabudget\n",
      "ofnsamplesz1,...,znoftherandomvariableZ,wearerequiredtoproduce\n",
      "anestimatewb?Wwhoseexpectedexcessloss,by2\n",
      "E[F(w)]b?minw?WF(w),issmall.(Here,theexpectationiswithrespect\n",
      "therandomizationofthetrainingsetz1,...,znusedtoproducew.)b\n",
      "Wemakethefollowingassumptionsoverthelossfunctionf.First,weassume\n",
      "thatforanyparameterz?Z,thefunctionf(?,z)is?-exp-concaveover\n",
      "thedomainWforsome?>0,namely,thatthefunctionexp(??f(?,z))is\n",
      "concaveoverW.Wewillalsoassumethatf(?,z)is?-smoothoverWwith\n",
      "respecttoEuclideannormk?k2,whichmeansthatitsgradientis?-Lipschitz\n",
      "withrespecttothesamenorm:?w,w0?W,\n",
      "k?f(w,z)??f(w0,z)k2??kw?w0k2.\n",
      "(2)\n",
      "Inparticular,thispropertyimpliesthatf(?,z)istiable.Forsimplic-\n",
      "ity,andwithoutlossofgenerality,weassume??1.Finally,weassumethatf\n",
      "(?,z)isboundedoverW,inthesensethat|f(w,z)?f(w0,z)|?Cforall\n",
      "w,w0?WforsomeC>0.Inthispaper,weanalyzearegularizedEmpirical\n",
      "3\n",
      "\n",
      "RiskMinimization(ERM)procedureforoptimizingthestochasticobjectivein\n",
      "Eq.(1),thatbasedonthesamplez1,...,zncomputeswb=argminFb(w)\n",
      ",\n",
      "(3)\n",
      "w?W\n",
      "wheren\n",
      "1X1Fb(w)=f(w,zi)+R(w).ni=1n\n",
      "(4)\n",
      "ThefunctionR:W7?Rservesasaregularizer,whichisassumedtobe1-\n",
      "strongly-convexwithrespecttotheEuclideannorm;forinstance,onecansimply\n",
      "chooseR(w)=12kwk22.ThestrongconvexityofRimpliesinparticularthat\n",
      "Fbisalsostronglyconvex,whichensuresthattheoptimizerwbisunique.For\n",
      "ourbounds,wewillassumethat|R(w)?R(w0)|?Bforallw,w0?W\n",
      "forsomeconstantB>0.Ourmainresult,whichwenowpresent,establishesa\n",
      "fast1/nconvergenceratefortheexpectedexcesslossoftheERMestimatewb\n",
      "giveninEq.(3).Theorem1.Letf:W?Z7?Rbealossfunctionover\n",
      "aclosedandconvexdomainW?Rd,whichis?-exp-concave,?-smoothand\n",
      "B-boundedwithrespecttoitsargument.LetR:W7?Rbea1-strongly-\n",
      "convexandB-boundedregularizationfunction.Then,fortheregularizedERM\n",
      "estimatewbinEqs.(3)and(4)basedonani.i.d.samplez1,...,\n",
      "zn,theexpectedexcesslossisboundedas\n",
      "d24?d100CdB++=O.E[F(w)]b?minF(w)?w?W?nnnnInother\n",
      "words,thetheoremstatesthatforensuringanexpectedexcesslossofatmost,a\n",
      "sampleofsizen=O(d/)Thisresultimprovesuponthebestknownfast\n",
      "convergenceratesforexp-concavefunctionsbyaO(logn)factor,andmatches\n",
      "thelowerboundofShamir[19]forthespecialcasewherethelossfunctionis\n",
      "thesquaredloss.Forthisparticularcase,ourresulttheconjectureof\n",
      "Shamir[19]regardingthesamplecomplexityofERMforthesquaredloss;see\n",
      "Section2.1belowfordetails.ItisimportanttonotethatTheorem1establishes\n",
      "afastconvergenceratewithrespecttotheactualexpectedlossFitself,and\n",
      "notforaregularizedversionthereof(andinparticular,notwithrespecttothe\n",
      "expectationof?Fb).Notably,themagnitudeoftheregularizationweuse\n",
      "isonlyO(1/n),asopposedtotheO(1/n)regularizationused?instandard\n",
      "regularizedlossminimizationmethods(thatcanonlygiverisetoatraditional\n",
      "O(1/n)rate).2.1\n",
      "ResultsfortheSquaredLoss\n",
      "Inthissectionwefocusontheimportantspecialcasewherethelossfunction\n",
      "fisthesquaredloss,namely,f(w;x,y)=12(w?x?y)2wherex?Rdisan\n",
      "instancevectorandy?Risatargetvalue.Thiscase,thatwasextensivelystud-\n",
      "iedinthepast,wasrecentlyaddressedbyShamir[19]whogavelowerbounds\n",
      "onthesamplecomplexityofanylearningalgorithmundermildassumptions.3\n",
      "Shamir[19]analyzedlearningwiththesquaredlossinasettingwherethe\n",
      "domainisW=\n",
      "f\n",
      "w?Rd:kwk2?B\n",
      "g\n",
      "forsomeconstantB>0,andthe\n",
      "parametersdistributionissupportedover\n",
      "f\n",
      "x?Rd:kxk2?1\n",
      "g\n",
      "?\n",
      "f\n",
      "y?R:|y|\n",
      "?B\n",
      "g\n",
      ".Itisnothardtoverifythatinthissetup,forthesquaredlosswecan\n",
      "take?=1,?=4B2andC=2B2.Furthermore,ifwechoosethestandard\n",
      "4\n",
      "\n",
      "regularizerR(w)=21kwk22,wehave|R(w)?R(w0)|?12B2forallw,\n",
      "w0?W.Asaconsequence,Theorem1impliesthattheexpectedexcesslossof\n",
      "theregularizedERMestimatorwbweinEq.(3)isboundedbyO(B2\n",
      "d/n).Ontheotherhand,standarduniformconvergenceresultsforgeneralized\n",
      "linearfunctions?[e.g.,11]showthat,underthesameconditions,ERMalso\n",
      "enjoysanupperboundofO(B2/n)overitsexpectedexcessrisk.Overall,we\n",
      "conclude:Corollary2.Forthesquaredlossf(w;x,y)=12(w?x?y)2over\n",
      "thedomainW=\n",
      "f\n",
      "w?Rd:kwk2?B\n",
      "g\n",
      "withZ=\n",
      "f\n",
      "x?Rd:kxk2?1\n",
      "g\n",
      "?\n",
      "f\n",
      "y\n",
      "?R:|y|?B\n",
      "g\n",
      ",theregularizedERMestimatorwbinEqs.(3)and\n",
      "(4)basedonani.i.d.sampleofninstanceshas\n",
      "2\n",
      "BdB2,?E[F(w)]b?minF(w)=Omin.w?WnnThisresult\n",
      "slightlyimproves,byalog(n/d)factor,upontheboundconjecturedbyShamir\n",
      "[19]fortheERMestimator,andmatchesthelowerboundprovedthereinup\n",
      "toconstants.1Previousfast-rateresultsforERMthatweareawareofeither\n",
      "includedexcesslogfactors[2]orwereprovenunderadditionaldistributional\n",
      "assumptions[14,9];seealsothediscussionin[19].WeremarkthatShamircon-\n",
      "jecturesthisboundforERMwithoutanyregularization.Forthespcase\n",
      "ofthesquaredloss,itisindeedpossibletoobtainthesamerateswithoutregu-\n",
      "larizing;wedeferdetailstothefullversionofthepaper.However,inpractice,\n",
      "regularizationhasseveraladditionalbitrenderstheERMoptimization\n",
      "problemwell-posed(i.e.,ensuresthattheunderlyingmatrixthatneedstobe\n",
      "invertediswell-conditioned),andguaranteesithasauniqueminimizer.\n",
      "3\n",
      "ProofofTheorem1\n",
      "OurproofofTheorem1proceedsasfollows.First,werelatetheexpected\n",
      "excessriskoftheERMestimatorwbtoitsaverageleave-one-outstability[4].\n",
      "Then,weboundthisstabilityintermsofcertainlocalpropertiesoftheempirical\n",
      "riskatthepointw.bTointroducetheaveragestabilitynotionwestudy,we\n",
      "foreachi=1,...,nthefollowingempiricalleave-one-outrisk:1\n",
      "1Xf(w,zj)+R(w)(i=1,...,n).Fbi(w)=nnj6=i\n",
      "Namely,Fbiistheregularizedempiricalriskcorrespondingtothesample\n",
      "obtainedbydiscardingtheinstancezi.Then,foreachiweletwbi=arg\n",
      "minw?WFbi(w)betheERMestimatorbi.Theaverageleave-one-outstability\n",
      "ofwcorrespondingtoFbisthenasthequantityPn1(f(wb,z)?f\n",
      "(w,bz)).iiii=1nIntuitively,theaverageleave-one-outstabilityservesas\n",
      "anunbiasedestimatoroftheamountofchangeintheexpectedlossoftheERM\n",
      "estimatorwhenoneoftheinstancesz1,...,zn,chosenuniformlyatrandom,\n",
      "isremovedfromthetrainingsample.Wenotethatlookingattheaverageis\n",
      "crucialforus,andthestrongerconditionof(expected)uniformstabilitydoes\n",
      "notholdforexpconcavefunctions.Forfurtherdiscussionofthevariousstability\n",
      "notions,refertoBousquetand[4].OurmainstepinprovingTheorem\n",
      "1involvesboundingtheaverageleave-one-outstabilityofwbinEq.(3),\n",
      "whichisthepurposeofthenexttheorem.Theorem3(averageleave-one-out\n",
      "stability).Foranyz1,...,zn?Zandforwb1,...,wbnandwbas\n",
      "above,wehaven\n",
      "5\n",
      "\n",
      "24?d100Cd1Xf(wbi,zi)?f(w,bzi)?+.ni=1?nn1Weremark\n",
      "thatShamir?sresultassumestwotboundsoverthemagnitudeofthe\n",
      "predictorswandthetargetvaluesy,whilehereweassumebotharebounded\n",
      "bythesameconstantB.Wedidnotattempttocapturethisdependence\n",
      "onthetwotparameters.\n",
      "4\n",
      "Beforeprovingthistheorem,weshowhowitcanbeusedtoobtainour\n",
      "maintheorem.TheprooffollowsargumentssimilartothoseofBousquetand\n",
      "[4]andShalev-Shwartzetal.[18].ProofofTheorem1.Toobtainthe\n",
      "statedresult,itisenoughtoupperboundtheexpectedexcesslossofwbn,\n",
      "whichistheminimizeroftheregularizedempiricalriskoverthei.i.d.sample\n",
      "f\n",
      "z1,...,zn?1\n",
      "g\n",
      ".Tothisend,anarbitraryw??W.Wewrite1R(w?\n",
      ")=E[Fb(w?)]?E[Fb(w)]b,nwhichholdstruesincewbistheminimizer\n",
      "ofFboverW.Hence,F(w?)+\n",
      "1E[F(wbn)]?F(w?)?E[F(wbn)?Fb(w)]b+R(w?).n\n",
      "(5)\n",
      "Next,noticethattherandomvariableswb1,...,wbnhaveexactlythe\n",
      "samedistribution:eachistheoutputofregularizedERMonani.i.d.sampleof\n",
      "n?1examples.Also,noticethatwbi,whichistheminimizerofthesample\n",
      "obtainedbydiscardingthei?thexample,isindependentofzi.Thus,wehaven\n",
      "E[F(wbn)]=\n",
      "n\n",
      "1X1XE[F(wbi)]=E[f(wbi,zi)].ni=1ni=1\n",
      "Furthermore,wecanwriten\n",
      "11XE[f(w,bzi)]+E[R(w)]E[Fb(w)]b=b.ni=1nPluggingthese\n",
      "expressionsintoEq.(5)givesaboundovertheexpectedexcesslossofwbnin\n",
      "termsoftheaveragestability:n\n",
      "E[F(wbn)]?F(w?)?\n",
      "1X1E[f(wbi,zi)?f(w,bzi)]+E[R(w?)?R(w)]b.ni=1n\n",
      "UsingTheorem3forboundingaveragestabilitytermontheright-handside,\n",
      "andourassumptionthatsupw,w0?W|R(w)?R(w0)|?Btoboundthe\n",
      "secondterm,weobtainthestatedboundovertheexpectedexcesslossofwbn\n",
      ".TheremainderofthesectionisdevotedtotheproofofTheorem3.Before\n",
      "webeginwiththeproofofthetheoremitself,wepresentausefultoolfor\n",
      "analyzingthestabilityofminimizersofconvexfunctions,whichwelaterapply\n",
      "totheempiricalleave-one-outrisks.3.1\n",
      "LocalStrongConvexityandStability\n",
      "Ourstabilityanalysisforexp-concavefunctionsisinspiredbyrecentanalysis\n",
      "techniquesofregularization-basedonlinelearningalgorithms,thatmakeuseof\n",
      "strongconvexitywithrespecttolocalnorms[1].Thecrucialstrong-convexity\n",
      "propertyissummarizedinthefollowing4(Localstrong\n",
      "convexity).Wesaythatafunctiong:K7?Rislocally?-stronglyconvexover\n",
      "adomainK?Rdatxwithrespecttoanormk?k,if?y?K,\n",
      "g(y)?g(x)+?g(x)?(y?x)+\n",
      "?ky?xk2.2\n",
      "6\n",
      "\n",
      "Inwords,afunctionislocallystrongly-convexatxifitcanbelowerbounded\n",
      "(globallyoveritsentiredomain)byaquadratictangenttothefunctionatx;the\n",
      "natureofthequadraticterminthislowerboundisdeterminedbyachoiceofa\n",
      "localnorm,whichistypicallyadaptedtothelocalpropertiesofthefunctionat\n",
      "thepointx.Withtheabovewecannowprovethefollowingstability\n",
      "resultforoptimaofconvexfunctions,thatunderliesourstabilityanalysisfor\n",
      "exp-concavefunctions.5\n",
      "Lemma5.Letg1,g2:K7?Rbetwoconvexfunctionsovera\n",
      "closedandconvexdomainK?Rd,andletx1?argminx?Kg1(x)andx2\n",
      "?argminx?Kg2(x).Assumethatg2islocally?-strongly-convexatx1with\n",
      "respecttoanormk?k.Then,forh=g2?g1wehavekx2?x1k?\n",
      "2k?h(x1)k?.?\n",
      "Furthermore,ifhisconvexthen22k?h(x1)k?.?\n",
      "0?h(x1)?h(x2)?Proof.Thelocalstrongconvexityofg2atx1implies\n",
      "?g2(x1)?(x1?x2)?g2(x1)?g2(x2)+\n",
      "?kx2?x1k2.2\n",
      "Noticethatg2(x1)?g2(x2)?0,sincex2isaminimizerofg2.Also,\n",
      "sincex1isaminimizerofg1,optimalityconditionsimplythat?g1\n",
      "(x1)?(x1?x2)?0,whence?g2(x1)?(x1?x2)=?g1(x1)?(x1?x2)+\n",
      "?h(x1)?(x1?x2)??h(x1)?(x1?x2).Combiningtheobservationsyields\n",
      "?kx2?x1k2??h(x1)?(x1?x2)?k?h(x1)k??kx1?x2k,2wherewe\n",
      "haveusedH?older?sinequalityinthelastinequality.Thisgivestheclaim\n",
      "ofthelemma.Toobtainthesecondclaim,weobservethatg1(x2)+h(x2\n",
      ")?g1(x1)+h(x1)?g1(x2)+h(x1)whereweusedthefactthatx2is\n",
      "theminimizerofg2=g1+hfortheinequality,andthefactthatx1isthe\n",
      "minimizerofg1forthesecond.Thisestablishesthelowerbound0?h(x1)?\n",
      "h(x2).Fortheupperbound,weusetheassumedconvexityofhtowriteh(x1\n",
      ")?h(x2)??h(x1)?(x1?x2)?k?h(x1)k??kx1?x2k?\n",
      "22k?h(x1)k?,?\n",
      "wherethesecondinequalityfollowsfromH?older?sinequality,andthe\n",
      "onefromtheclaimofthelemma.3.2\n",
      "AverageStabilityAnalysis\n",
      "WithLemma5athand,wenowturntoproveTheorem3.First,afew\n",
      "areneeded.Forbrevity,wehenceforthdenote(?)=f(?,zi)for\n",
      "allPi.Welethi=(w)bbethePgradientofnatthepointwbed\n",
      "inEq.(3),andletH=?1Id+i=1hihTiandHi=?1Id+j6=ihjhTjfor\n",
      "1alli,where?=12min\n",
      "f\n",
      "4C,?\n",
      "g\n",
      ".Finally,wewillusek?kMtodenotethe\n",
      "norminducedbyapositive?matrixM,?i.e.,kxkM=xTMx.In\n",
      "thiscase,thedualnormkxk?MinducedbyMsimplyequalskxkM?1=xT\n",
      "M?1x.Inordertoobtainanupperboundovertheaveragestability,we\n",
      "boundeachoftheindividualstabilityexpressions(wbi(w)binterms\n",
      "ofacertainnormofthegradienthiofthecorrespondingfunction.Asthe\n",
      "proofbelowreveals,thisnormisthelocalnormatwbwithrespecttowhich\n",
      "theleave-one-outriskFbiislocallystronglyconvex.Lemma6.Foralli=1,.\n",
      "..,nitholdsthat(wbi)?(w)b?\n",
      "26?khik?Hi.?\n",
      "7\n",
      "\n",
      "Noticethattheexpressionontheright-handsidemightbequitelargefor\n",
      "aparticularfunction;indeed,uniformstabilitydoesnotholdinourcase.\n",
      "However,asweshowbelow,theaverageoftheseexpressionsissmall.Theproof\n",
      "ofLemma6reliesonLemma5aboveandthefollowingpropertyofexp-concave\n",
      "functions,establishedbyHazanetal.[8].6\n",
      "Lemma7(Hazanetal.[8],Lemma3).Letf:K7?Rbean?-exp-concave\n",
      "functionoveraconvex1domainK?Rdsuchthat|f(x)?f(y)|?Cforany\n",
      "x,y?K.Thenforany??21min\n",
      "f\n",
      "4C,?\n",
      "g\n",
      "itholdsthat2??x,y?K,f(y)\n",
      "?f(x)+?f(x)?(y?x)+(6)?f(x)?(y?x).2ProofofLemma6.Weapply\n",
      "Lemma5withg1=Fbandg2=Fbi(sothath=?n1).Weshould\n",
      "verifythatFbiisindeed(?/n)-strongly-convexatwbwithrespecttothenorm\n",
      "k?kHi.Sinceeachis?-exp-concave,Lemma7showsthatforallw?W,2?\n",
      ",(7)(w)?(w)b+(w)?(wb?w)b+hi?(w?w)b2withourchoice\n",
      "of?=\n",
      "12\n",
      "1min\n",
      "f\n",
      "4C,?\n",
      "g\n",
      ".Also,thestrongconvexityoftheregularizerRimpliesthat\n",
      "1R(w)?R(w)b+?R(w)?(wb?w)b+kw?wkb22.2SummingEq.\n",
      "(7)overallj6=iwithEq.(8)anddividingthroughbyngives2?X1Fbi(w)\n",
      "?Fbi(w)b+?Fbi(w)?(wb?w)b+hi?(w?w)b+kw?wkb222n2n\n",
      "(8)\n",
      "j6=i\n",
      "?kw?wkb2Hi,=Fbi(w)b+?Fbi(w)?(wb?w)b+2nwhich\n",
      "establishesthestrongconvexity.Now,applyingLemma5gives2n2k?h(w)kb\n",
      "?Hi=khik?Hi.??Ontheotherhand,sinceisconvex,wehavekwbi?wk\n",
      "bHi?\n",
      "(9)\n",
      "(wbi)?(w)b?(wbi)?(wbi?w)b\n",
      "=(w)?(bwbi?w)b+(wbi)?(w)b?(wbi?w)b.\n",
      "(10)\n",
      "ThetermcanbeboundedusingH?older?sinequalityandEq.(9)as2\n",
      "2khik?Hi.?Also,sinceis?-smooth(withrespecttotheEuclideannorm),\n",
      "wecanboundthesecondterminEq.(10)asfollows:\n",
      "(wbi)?(w)b?(wbi?w)b?(wbi)?(w)kb2?kwbi?\n",
      "wkb2??kwbi?wkb22,(wbi)?(wbi?w)b=hi?(wbi?w)b?khi\n",
      "k?Hi?kwbi?wkbHi?\n",
      "andsinceHi(1/?)Id,wecanfurtherboundusingEq.(9),24khik?Hi.?\n",
      "Combiningthebounds(andsimplifyingusingourassumption??1)givesthe\n",
      "lemma.kwbi?wkb22??kwbi?wkb2Hi?\n",
      "Next,weboundasuminvolvingthelocal-normtermsintroducedinLemma\n",
      "6.Lemma8.LetI=\n",
      "f\n",
      "i?[n]:khik?H>12\n",
      "g\n",
      ".Then|I|?2d,andwehave\n",
      "X2khik?Hi?2d.i?I/\n",
      "Proof.Denoteai=hTiH?1hiforalli=1,...,n.First,weclaimthat\n",
      "ai>0foralli,andP?1beingpositivForthesumoftheiai?d.\n",
      "Thefactthatai>0isevidentfromHai?s,wewrite:nXi=1\n",
      "ai=\n",
      "nXi=1\n",
      "8\n",
      "\n",
      "hTiH?1hi=\n",
      "nX\n",
      "tr(H?1hihTi)?tr(H?1H)=tr(Id)=d,\n",
      "i=1\n",
      "7\n",
      "(11)\n",
      "wherewehaveusedthelinearityofthetrace,andthefactthatH\n",
      "Pn\n",
      "i=1\n",
      "hihTi.\n",
      "Now,ourclaimthat|I|?2disevident:ifkhik?H>12formorethan2d\n",
      "terms,thenthesumPPT?1himustbelargerthand,whichisacontradiction\n",
      "toEq.(11).Toprovei?Iai=i?IhiHoursecondclaim,westwriteHi=H\n",
      "?hihTiandusetheSherman-Morrisonidentity[e.g.,7]toobtainHi?1=(H?\n",
      "hihTi)?1=H?1+\n",
      "H?1hihTiH?11?hTiH?1hi\n",
      "foralli?/I.Notethatfori?/IwehavehTiH?1hi<1,sothattheidentity\n",
      "appliesandtheinverseontheright-handsideiswellWethereforehave:\n",
      "2hTH?1hi2a2i=hTiHi?1hi=hTiH?1hi+iT?1khik?Hi=ai+\n",
      "?2ai,1?ai1?hiHhiwheretheinequalityfollowsfromthefactthat1?ai\n",
      "?aifori?/I.Summingthisinequalityoveri?/Iandrecallingthattheai?s\n",
      "arenonnegative,weobtainX\n",
      "khik?Hi\n",
      "2\n",
      "?2\n",
      "i?I/\n",
      "X\n",
      "ai?2\n",
      "nX\n",
      "ai=2d,\n",
      "i=1\n",
      "i?I/\n",
      "whichconcludestheproof.Theorem3isnowobtainedasanimmediate\n",
      "consequenceofourlemmasabove.ProofofTheorem3.Asaconsequenceof\n",
      "Lemmas6and8,wehave\n",
      "1XC|I|2Cd(wbi)?(w)b??,nnni?I\n",
      "and\n",
      "21X6?X12?d(wbi)?(w)b?khik?Hi.?n?n?ni?I/\n",
      "Summingtheinequalitiesandusing\n",
      "4\n",
      "i?I/\n",
      "1?\n",
      "=2max\n",
      "f\n",
      "4C,?1\n",
      "g\n",
      "?2(4C+?1)givestheresult.\n",
      "ConclusionsandOpenProblems\n",
      "WehaveprovedthefastconvergencerateforaregularizedERMpro-\n",
      "cedureforexp-concavelossfunctions.Ourboundsmatchtheexistinglower\n",
      "9\n",
      "\n",
      "boundsinthespcaseofthesquaredlossuptoconstants,andimprove\n",
      "byalogarithmicfactoruponthebestknownupperboundsachievedbyonline\n",
      "methods.Ourstabilityanalysisrequiredustoassumesmoothnessoftheloss\n",
      "functions,inadditiontotheirexp-concavity.Wenote,however,thattheOnline\n",
      "NewtonStepalgorithmofHazanetal.[8]foronlineexp-concaveoptimization\n",
      "doesnotrequiresuchanassumption.Eventhoughmostofthepopularexp-\n",
      "concavelossfunctionsarealsosmooth,itwouldbeinterestingtounderstand\n",
      "whethersmoothnessisindeedrequiredfortheconvergenceoftheERMesti-\n",
      "matorwestudyinthepresentpaper,orwhetheritissimplyalimitationof\n",
      "ouranalysis.Anotherinterestingissueleftopeninourworkishowtoobtain\n",
      "boundsontheexcessriskofERMthatholdwithhighprobability,andnot\n",
      "onlyinexpectation.Sincetheexcessriskisnon-negative,onecanalwaysapply\n",
      "Markov?sinequalitytoobtainaboundthatholdswithprobability1??but\n",
      "scaleslinearlywith1/?.Also,usingstandardconcentrationinequalitiesp(or\n",
      "successtechniques),wemayalsoobtainhighprobabilitybounds\n",
      "thatscalewithlog(1/?)/n,losingthefast1/nrate.Weleavetheproblemof\n",
      "obtainingboundsthatdependsbothlinearlyon1/nandlogarithmicallyon1/?\n",
      "forfuturework.8\n",
      "2References\n",
      "[1]J.D.Abernethy,E.Hazan,andA.Rakhlin.Interior-pointmethodsfor\n",
      "full-informationandbanditonlinelearning.InformationTheory,IEEETrans-\n",
      "actionson,58(7):4164?4175,2012.[2]M.AnthonyandP.L.Bartlett.Neural\n",
      "networklearning:Theoreticalfoundations.cambridgeuniversitypress,2009.\n",
      "[3]K.S.AzouryandM.K.Warmuth.Relativelossboundsforon-lineden-\n",
      "sityestimationwiththeexponentialfamilyofdistributions.MachineLearning,\n",
      "43(3):211?246,2001.[4]O.BousquetandA.Stabilityandgener-\n",
      "alization.TheJournalofMachineLearningResearch,2:499?526,2002.[5]\n",
      "N.Cesa-BianchiandG.Lugosi.Prediction,learning,andgames.Cambridge\n",
      "UniversityPress,2006.[6]N.Cesa-Bianchi,A.Conconi,andC.Gentile.On\n",
      "thegeneralizationabilityofon-linelearningalgorithms.IEEETransactionson\n",
      "InformationTheory,50(9):2050?2057,2004.[7]G.H.GolubandC.F.Van\n",
      "Loan.Matrixcomputations,volume3.JHUPress,2012.[8]E.Hazan,A.\n",
      "Agarwal,andS.Kale.Logarithmicregretalgorithmsforonlineconvexopti-\n",
      "mization.MachineLearning,69(2-3):169?192,2007.[9]D.Hsu,S.M.Kakade,\n",
      "andT.Zhang.Randomdesignanalysisofridgeregression.FoundationsofCom-\n",
      "putationalMathematics,14(3):569?600,2014.[10]R.JohnsonandT.Zhang.\n",
      "Acceleratingstochasticgradientdescentusingpredictivevariancereduction.In\n",
      "AdvancesinNeuralInformationProcessingSystems,pages315?323,2013.[11]\n",
      "S.M.Kakade,K.Sridharan,andA.Tewari.Onthecomplexityoflinearpredic-\n",
      "tion:Riskbounds,marginbounds,andregularization.InAdvancesinneural\n",
      "informationprocessingsystems,pages793?800,2009.[12]J.KivinenandM.K.\n",
      "Warmuth.Averagingexpertpredictions.InComputationalLearningTheory,\n",
      "pages153?167.Springer,1999.[13]T.Koren.Openproblem:Faststochastic\n",
      "10\n",
      "\n",
      "exp-concaveoptimization.InConferenceonLearningTheory,pages1073?1075,\n",
      "2013.[14]G.Lecu?eandS.Mendelson.Performanceofempiricalriskmini-\n",
      "mizationinlinearaggregation.arXivpreprintarXiv:1402.5763,2014.[15]M.\n",
      "Mahdavi,L.Zhang,andR.Jin.Lowerandupperboundsonthegeneralization\n",
      "ofstochasticexponentiallyconcaveoptimization.InProceedingsofThe28th\n",
      "ConferenceonLearningTheory,2015.[16]S.Shalev-ShwartzandT.Zhang.\n",
      "Stochasticdualcoordinateascentmethodsforregularizedloss.TheJournalof\n",
      "MachineLearningResearch,14(1):567?599,2013.[17]S.Shalev-Shwartzand\n",
      "T.Zhang.Acceleratedproximalstochasticdualcoordinateascentforregular-\n",
      "izedlossminimization.MathematicalProgramming,pages1?41,2014.[18]S.\n",
      "Shalev-Shwartz,O.Shamir,N.Srebro,andK.Sridharan.Learnability,sta-\n",
      "bilityanduniformconvergence.TheJournalofMachineLearningResearch,\n",
      "11:2635?2670,2010.[19]O.Shamir.Thesamplecomplexityoflearninglinear\n",
      "predictorswiththesquaredloss.arXivpreprintarXiv:1406.5143,2014.[20]\n",
      "N.Srebro,K.Sridharan,andA.Tewari.Smoothness,lownoiseandfastrates.\n",
      "InAdvancesinneuralinformationprocessingsystems,pages2199?2207,2010.\n",
      "[21]K.Sridharan,S.Shalev-Shwartz,andN.Srebro.Fastratesforregular-\n",
      "izedobjectives.InAdvancesinNeuralInformationProcessingSystems,pages\n",
      "1545?1552,2009.[22]V.Vovk.Competitiveon-linestatistics.International\n",
      "StatisticalReview,69(2):213?248,2001.\n",
      "9\n",
      "11\n",
      "\n",
      "PP7262.pdf\n",
      "PP7262.pdf 14\n",
      "yClustering:HierarchicalClusteringat\n",
      "Scale\n",
      "Authoredby:\n",
      "MohammadhosseinBateni\n",
      "SilvioLattanzi\n",
      "VahabMirrokni\n",
      "SoheilBehnezhad\n",
      "MahsaDerakhshan\n",
      "MohammadTaghiHajiaghayi\n",
      "RaimondasKiveris\n",
      "Abstract\n",
      "Graphclusteringisafundamentaltaskinmanydata-miningand\n",
      "machine-learningpipelines.Inparticular,identifyingagoodhierarchi-\n",
      "calstructureisatthesametimeafundamentalandchallengingproblem\n",
      "forseveralapplications.Theamountofdatatoanalyzeisincreasingat\n",
      "anastonishingrateeachday.Hencethereisaneedfornewsolutionsto\n",
      "tlycomputeehierarchicalclusteringsonsuchhugedata.\n",
      "Themainfocusofthispaperisonminimumspanningtree(MST)based\n",
      "clusterings.Inparticular,weproposey,anovelhierarchicalclus-\n",
      "teringbasedonBoruvka'sMSTalgorithm.Weprovecertaintheoretical\n",
      "guaranteesfory(aswellassomeotherclassicalgorithms)andshow\n",
      "thatinpracticeitissuperiortoseveralotherstate-of-the-artclusteringal-\n",
      "gorithms.Furthermore,wepresenttwoMapReduceimplementationsfor\n",
      "y.Theoneworksforthecasewheretheinputgraphisdense\n",
      "andtakesconstantrounds.ItisbasedonaMassivelyParallelMSTalgo-\n",
      "rithmfordensegraphsthatimprovesuponthestate-of-the-artalgorithm\n",
      "ofLattanzietal.(SPAA2011).Oursecondalgorithmhasnoassump-\n",
      "tiononthedensityoftheinputgraphandtheyclustering\n",
      "in$O(logn)$roundsusingDistributedHashTables(DHTs).Weshow\n",
      "experimentallythatouralgorithmsarescalableforhugedatasets,e.g.,\n",
      "forgraphswithtrillionsofedges.\n",
      "1PaperBody\n",
      "Clusteringisaclassicunsupervisedlearningproblemwithmanyapplicationsin\n",
      "informationretrieval,datamining,andmachinelearning.Inhierarchicalclus-\n",
      "teringthegoalistodetectanestedhierarchyofclustersthatunveilsthefull\n",
      "1\n",
      "\n",
      "clusteringstructureoftheinputdataset.Inthisworkwestudythehierarchical\n",
      "clusteringproblemonreal-worldgraphs.Thisproblemhasreceivedalotofat-\n",
      "tentioninrecentyears[13,16,41]andnewelegantformulationsandalgorithms\n",
      "havebeenintroduced.Neverthelessmanyofthenewlyproposedtechniquesare\n",
      "sequential,hencetoapplyonlargedatasets.?\n",
      "SupportedinpartbyNSFCAREERawardCCF-1053605,NSFBIGDATA\n",
      "grantIIS-1546108,NSFAF:MediumgrantCCF-1161365,DARPAGRAPHS/AFOSR\n",
      "grantFA9550-12-1-0423,andanotherDARPASIMPLEXgrant.31stConfer-\n",
      "enceonNeuralInformationProcessingSystems(NIPS2017),LongBeach,CA,\n",
      "USA.\n",
      "Withtheconstantincreaseinthesizeofdatasetstoanalyze,itiscrucial\n",
      "todesigntlarge-scalesolutionsthatcanbeeasilyimplementedindis-\n",
      "tributedcomputingplatforms(suchasSpark[45]andHadoop[43]aswellas\n",
      "MapReduceanditsextensionFlume[17]),andcloudservices(suchasAma-\n",
      "zonCloudorGoogleCloud).Forthisreasoninthepastdecadeseveralpapers\n",
      "proposednewdistributedalgorithmsforclassiccomputerscienceandmachine\n",
      "learningproblems[3,4,7,14,15,19].Despitethesenotmuchisknown\n",
      "aboutdistributedalgorithmsforhierarchicalclustering.Thereareonlytwo\n",
      "worksanalyzingtheseproblems[27,28],andneithergivesanytheoreticalguar-\n",
      "anteesonthequalityoftheiralgorithmsorontheroundcomplexityoftheir\n",
      "solutions.InthisworkweproposenewparallelalgorithmsintheMapReduce\n",
      "modeltocomputehierarchicalclusteringandweanalyzethemfromboththe-\n",
      "oreticalandexperimentalperspectives.Themainideabehindouralgorithms\n",
      "istoadaptclusteringtechniquesbasedonclassicminimumspanningtreealgo-\n",
      "rithmssuchasBor?uvka?salgorithm[11]andKruskal?salgorithm[33]torun\n",
      "tlyinparallel.Furthermorewealsoprovideanewtheoreticalframework\n",
      "tocomparederentclusteringalgorithmsbasedontheconceptofa\n",
      "andshownewinterestingpropertiesofouralgorithms.Wecansummarizeour\n",
      "contributioninfourmainpoints.First,wefocusonthedistributedimple-\n",
      "mentationsoftwoimportantclusteringtechniquesbasedonclassicminimum\n",
      "spanningtreealgorithms.Inparticularweconsiderlinkage-basedclusterings\n",
      "inspiredbyKruskal?salgorithmandanovelclusteringcalledyclustering\n",
      "basedonBor?uvka?salgorithm.Weprovidenewtheoreticalframeworksto\n",
      "comparetclusteringalgorithmsbasedontheconceptofa\n",
      "asaproofofhavingagoodclusteringandshownewinterestingpropertiesof\n",
      "bothyandsingle-linkageclusteringalgorithms.Then,usingaconnection\n",
      "betweenlinkage-basedclustering,yclusteringandtheminimumspanning\n",
      "treeproblem,wepresentnewtdistributedalgorithmsforthehierarchical\n",
      "clusteringprobleminaMapReducemodel.Inouranalysisweconsiderthemost\n",
      "restrictivemodelfordistributedcomputing,calledMassivelyParallelCommu-\n",
      "nication,amongpreviouslystudiedMapReduce-likemodels[10,23,30].Along\n",
      "theway,weobtainaconstantroundMapReducealgorithmforminimumspan-\n",
      "ningtree(MST)ofdensegraphs(inSection5).Ouralgorithmforgraphswith\n",
      "?(n1+c)edges?1+)spaceandforanygivenwith0<<c<1,theMSTin\n",
      "dlog(c/)e+1roundsusingO(npermachineandO(nc?)machines(i.e.,optimal\n",
      "totalspace).Thisimprovestheroundcomplexityofthestate-of-the-artMST\n",
      "2\n",
      "\n",
      "algorithmofLattanzietal.[34]fordensegraphswhichrequiresuptodc/e\n",
      "roundsusingthesamenumberofmachinesandspace.Priortoourwork,no\n",
      "hierarchicalclusteringalgorithmwasknowninthismodel.Thenweturnour\n",
      "attentiontorealworldapplicationsandweintroducetimplementations\n",
      "ofyclusteringaswellasclassicsingle-linkageclusteringthatleverageDis-\n",
      "tributedHashTables(DHTs)[12,31]tospeedupcomputationforhugedata\n",
      "sets.Lastbutnotleast,wepresentanexperimentalstudywhereweanalyzethe\n",
      "scalabilityandenessofournewlyintroducedalgorithmsandweobserve\n",
      "that,inmostcases,yclusteringoutperformsallstate-of-the-artalgorithms\n",
      "frombothqualityandscalabilitystandpoints.2\n",
      "2\n",
      "RelatedWork\n",
      "Clusteringand,inparticular,hierarchicalclusteringtechniqueshavebeen\n",
      "studiedbyhundredsofresearchers[16,20,22,32].Insocialnetworks,detect-\n",
      "ingthehierarchicalclusteringstructureisabasicprimitiveforstudyingthe\n",
      "interactionbetweennodes[36,39].Otherrelevantapplicationsofhierarchical\n",
      "clusteringcanbefoundinbioinformatics,imageanalysisandtext\n",
      "tion.Ourpaperiscloselyrelatedtotwomainlinesofresearch.The\n",
      "onefocusesonstudyingtheoreticalpropertiesofclusteringapproachesbased\n",
      "onminimumspanningtrees(MSTs).Linkagebasedclusterings(oftenbased\n",
      "onKruskal?salgorithm)havebeenextensivelystudiedasbasictechniquesfor\n",
      "clusteringdatasets.Themostcommonlinkage-basedclusteringalgorithmsare\n",
      "singlelinkage,average-linkageandcomplete-linkagealgorithms.In[44],Zadeh\n",
      "andBen-Davidgaveacharacterizationofthesingle-linkagealgorithm.Their\n",
      "resulthasbeenthengeneralizedtolinkagebasedalgorithmsin[1].Furthermore\n",
      "single-linkagealgorithmsareknowntoprovablyrecoveragroundtruthcluster-\n",
      "ingifthesimilarityfunctionhassomestabilityproperties[6].Inthispaperwe\n",
      "2\n",
      "Implementationsareavailableathttps://githyClustering.\n",
      "2\n",
      "introduceanewtechniquetocompareclusteringalgorithmsbasedon\n",
      "cates.?Furthermoreweintroduceandanalyzeanewy?based\n",
      "onBor?uvka?swell-knownalgorithm.Weshowthatyisnotonlyscalable\n",
      "forhugedatasetsbutalsoitsperformanceissuperiortoseveraluvka?salgo-\n",
      "rithmisastate-of-the-artclusteringalgorithms.Tothebestofourknowledge\n",
      "thoughBor?well-knownandclassicalgorithm,notmanyclusteringalgorithms\n",
      "havebeenconsideredbasedonBor?uvka?s.Thesecondlineofworkisclosely\n",
      "relatedtodistributedalgorithmsforclusteringproblems.Severalmodelsof\n",
      "MapReducecomputationhavebeenintroducedinthepastfewyears[10,23,\n",
      "30].ThepaperthatstudiedclusteringproblemsinthesemodelsisbyEne\n",
      "etal.[18],wheretheauthorsprovethatany?approximationalgorithmforthe\n",
      "k-centerork-medianproblemscanproduce4?+2and10?+3approximation\n",
      "factors,respectively,forthek-centerork-medianproblemsintheMapReduce\n",
      "model.Subsequentlyseveralpapers[5,7,8]studiedsimilarproblemsinthe\n",
      "MapReducemodel.Alotofalsowentintostudyingtalgorithms\n",
      "ongraphs[3,4,7,15,14,19].Howevertheproblemofhierarchicalclustering\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didnotreceivealotofattention.Tothebestofourknowledgethereareonly\n",
      "twopapers[27,28]onthistopic,andneitheranalyzestheproblemformallyor\n",
      "provesanyguaranteeinanyMapReducemodel.\n",
      "3\n",
      "MinimumSpanningTree-BasedClusterings\n",
      "Webeginbygoingovertwofamousalgorithmsforminimumspanningtree\n",
      "andthecorrespondingalgorithmsforclustering.uvka?salgorithm[11],\n",
      "publishedin1926,isBor?uvka?salgorithmandyclustering:Bor?\n",
      "analgorithmforaminimumspanningtree(MST)3.Thealgorithm\n",
      "wasrediscoveredafewtimes,inparticularbySollin[42]in1965intheparal-\n",
      "lelcomputingliterature.Initiallyeachvertexformsagroup(cluster)byitself.\n",
      "Thealgorithmbeginsbypickingthecheapestedgegoingoutofeachcluster,\n",
      "ineachround(inparallel)joinstheseclusterstoformlargerclustersandcon-\n",
      "tinuesjoininginasimilarmanneruntilatreespanningallverticesisformed.\n",
      "Sincethesizeofthesmallestclusteratleastdoubleseachtime,thenumberof\n",
      "roundsisatmostO(logn).Inyclustering,weuvka?salgorithmafterr\n",
      ">0roundswhenforthetimewehaveatmostkclustersforastopBor?\n",
      "desirednumberk>0.Incasethenumberofclustersisstrictlylessthank,we\n",
      "deletetheedgesthatweaddedinthelastroundinanon-increasingorder(i.e.,\n",
      "wedeletetheedgewiththehighestweighttoobtainexactlykclusters.To\n",
      "thebestofourknowledge,althoughBor?uvka?salgorithmisawell-knownand\n",
      "classicalgorithm,clusteringalgorithmsbasedonithavenotbeenconsidered\n",
      "much.uvka?salgorithm:eachclusterhereAnaturalhierarchyofnodescan\n",
      "beobtainedbycontinuingBor?willbeasubsetoffutureclusters.Wecall\n",
      "thishierarchicalyclustering.Wepresentdistributedimplementationsof\n",
      "Bor?uvkyinSection5andshowitsscalabilityevenforhugegraphs.\n",
      "Wealsoshowyclustering,inmostcases,worksmuchbetterthanseveral\n",
      "well-knownclusteringalgorithmsinSection6.Kruskal?salgorithmandsingle-\n",
      "linkageclustering:Kruskal?salgorithm[33]introducedin1956isanother\n",
      "famousalgorithmforMST.Thealgorithmishighlysequentialandit-\n",
      "erativelypicksanedgeoftheleastpossibleweightthatconnectsanytwotrees\n",
      "(clusters)intheforest.4ThoughthenumberofiterationsinKruskal?salgo-\n",
      "rithmisn?1(thenumberofedgesofanytreeonnnodes),thealgorithmcan\n",
      "beimplementedinO(mlogn)timewithsimpledatastructures(misthenum-\n",
      "berofedges)andinO(ma(n))timeusingamoresophisticateddisjoint-setdata\n",
      "structure,wherea(.)istheextremelyslowlygrowinginverseofthesingle-valued\n",
      "Ackermannfunction.Insingle-linkageclustering,westopKruskal?salgorithm\n",
      "whenwehaveatleastkclusters(trees)foradesirednumberk>0.Again\n",
      "ifwedesiretoobtainacorrespondinghierarchicalsingle-linkageclustering,by\n",
      "addingfurtheredgeswhichwillbeaddedinKruskal?salgorithmlater,wecan\n",
      "obtainanaturalhierarchicalclustering(eachclusterherewillbeasubsetof\n",
      "futureclusters).Asmentionedabove,Kruskal?sAlgorithmandsingle-linkage\n",
      "clusteringarehighlysequential,howeverasweshowinSection5thinkingback-\n",
      "wardoncewehaveantimplementationofBor?uvka?s3Moreprecisely\n",
      "thealgorithmworkswhenthereisauniqueMST,inparticular,whenalledge\n",
      "weightsaredistinct;howeverthiscanbeeasilyachievedbyeitherperturbing\n",
      "4\n",
      "\n",
      "theedgeweightsbyan>0amountorhaveatie-breakingorderingforedges\n",
      "withthesameweights4UnlikeBor?uvka?smethod,thisgreedyalgorithmhas\n",
      "nolimitationsonthedistinctnessofedgeweights.\n",
      "3\n",
      "(oranyMSTalgorithm)inMap-ReduceandusingDistributedHashTables\n",
      "(DHTs),wecanachieveantparallelimplementationofsingle-linkage\n",
      "clusteringaswell.Weshowscalabilityofthisimplementationevenforhuge\n",
      "graphsinSection5anditsperformanceinexperimentsinSection6.\n",
      "4\n",
      "GuaranteedPropertiesofClusteringAlgorithms\n",
      "Animportantpropertyofyclusteringisthatitproducesclustersthat\n",
      "areroughlyofthesamesize.Thisisintuitivelycorrectsinceateachround\n",
      "ofthealgorithm,eachclusterismergedtoatleastoneotherclusterandasa\n",
      "result,thesizeofeventhesmallestclusterisatleastdoubled.Infactlinkage\n",
      "basedalgorithms(andspeciallysinglelinkage)areoftencriticizedforproducing\n",
      "unevenclusters;thereforeitistemptingtogiveatheoreticalguaranteeforthe\n",
      "sizeratiooftheclustersthatyproduces.Unfortunately,asitisillustrated\n",
      "inFigure1,wecannotgiveanyworstcaseboundssinceeveninoneroundwe\n",
      "mayenduphavingaclusterofsize?(n)andanotherclusterofsizeO(1).As\n",
      "theproperty,weshowthatatleastintheround,thisdoesnothappen\n",
      "whentheobservationsarerandomlydistributed.Ourempiricalresultsonreal\n",
      "worlddatasetsinSection6.1,furtherthispropertyforallrounds,and\n",
      "onrealdatasets.\n",
      "Figure1:Anexampleofhowymayproducealargecomponentinone\n",
      "round.Westartbythenearestneighborgraph.1(Nearest\n",
      "NeighborGraph).LetSbeasetofpointsinametricspace.Thenearest\n",
      "neighborgraphofS,denotedbyGS,has|S|vertices,eachcorresponding\n",
      "toanelementinSandifa?Sisthenearestelementtob?SinS,graph\n",
      "GScontainsanedgebetweenthecorrespondingverticesofaandb.Ateach\n",
      "roundofyclustering,alltheverticesthatareinthesameconnected\n",
      "componentofthenearestneighborgraphwillbemergedtogether5.Thus,it\n",
      "toboundtheconnectedcomponents?size.Forarandommodelof\n",
      "points,consideraPoissonpointprocessXinRd(d?1)withdensity1.Ithas\n",
      "twomainproperties.First,thenumberofpointsinanyregionofvolume\n",
      "VisPoissondistributedwithmeanV.Second,thenumberofpointsinanytwo\n",
      "disjointregionsareindependentofeachother.Theorem1(H?ggstr?metal.\n",
      "[38]).Foranyd?2,considerthe(Euclideandistance)nearestneighborgraph\n",
      "GofarealizationofaPoissonpointprocessinRdwithdensity1.Allconnected\n",
      "componentsofGarealmostsurely.Theorem1impliesthatthesizeofthe\n",
      "maximumconnectedcomponentofthepointswithinanyregioninRdis\n",
      "boundedbyalmostaconstantnumber.Thisisaverysurprisingresultcompared\n",
      "totheworstcasescenarioofhavingaconnectedcomponentthatcontainsallthe\n",
      "points.Notethatalthoughtheaforementionedboundholdsfortheroundof\n",
      "y,aftertheconnectedcomponentsarecontracted,wecannotnecessarily\n",
      "assumethatthenewpointsarePoissondistributedandthesameargument\n",
      "cannotbeusedfortherestoftherounds.Nextwepresentfurtherproperties\n",
      "5\n",
      "\n",
      "ofyclustering.Letusbeginbyintroducingtheconceptof?cost?fora\n",
      "clusteringsolutiontobeabletocompareclusteringalgorithms.2.\n",
      "Thecostofaclusteristhesumofedgelengths(weights)ofaminimumSteiner\n",
      "treeconnectingallverticesinsidethecluster.Thecostofaclusteringisthe\n",
      "sumofthecostsofitsclusters.Finallyanon-singletonclusteringofagraphis\n",
      "apartitionofitsverticesintoclustersofsizeatleasttwo.Evenoneroundof\n",
      "yclusteringoftenproducesgoodsolutionsforseveralapplications.Now\n",
      "wearereadytopresentthefollowingextrapropertyoftheresultofthe\n",
      "roundoftyclustering.5\n",
      "Dependingonthevariantofythatweuse,thedistancefunctionwill\n",
      "beupdated.\n",
      "4\n",
      "Theorem2.Thecostofanynon-singletonclusteringisatleasthalfofthat\n",
      "oftheclusteringobtainedaftertheroundofyclustering.Before\n",
      "presentingtheproofofTheorem2,weneedtodemonstratetheconceptofdisc\n",
      "paintingintroducedpreviouslyin[29,2,21,9,25].Inthissetting,weconsidera\n",
      "topologicalstructureofagraphmetricinwhicheachedgeisacurveconnecting\n",
      "itsendpointswhoselengthisequaltoitsweight.Weassumeeachvertexhasits\n",
      "owncolor.Adiscpaintingissimplyasetofdisjointdiskscenteredatterminals\n",
      "(withthesamecolorsofthecentervertices).Adiskofradiusrcenteredat\n",
      "vertexvpaintsalledges(orportions)ofthemwhichareatdistancerfrom\n",
      "vertexvwiththecolorofv.Thuswepaint(portionsof)edgesbyt\n",
      "diskseachcorrespondingtoavertexandeachedgecanbepaintedbyatmost\n",
      "twodisks.Withthisofdiskpainting,wenowdemonstratetheproof\n",
      "ofTheorem2.Nextweturnourfocustoobtainstructuralpropertiesforsingle-\n",
      "linkageclustering.WedenotebyFkthesetofedgesaddedafterkiterationsof\n",
      "Kruskal,i.e.,whenwehaven?kclustersinsingle-linkageclustering.Notethat\n",
      "Fkisaforest,i.e.,asetofedgeswithnocycle.Firstwestartwithanimportant\n",
      "observationwhoseproofcomesdirectlyfromthedescriptionofthesingle-linkage\n",
      "algorithm.Proposition3.Supposewerunsingle-linkageclusteringuntilwehave\n",
      "n?kclusters.Letdoutsidebetheminimumdistancebetweenanytwoclusters\n",
      "anddinsidebethemaximumdistanceofanyedgeaddedtoforestFk.Then\n",
      "doutside?dinside.WenotethatProposition3demonstratesthefollowing\n",
      "importantpropertyofsingle-linkageclustering:Eachvertexofaclusteratany\n",
      "timehasaneighborinsidetowhichiscloserthananyothervertexoutsideof\n",
      "itsclusters.Nextweanothercriterionfordesirabilityofaclustering\n",
      "algorithm.ThisgeneralizesProposition3.3.Anfora\n",
      "clusteringalgorithm,where??1,isanassignmentofsharestoeachvertex\n",
      "ofthegraphwiththefollowingtwoproperties:(1)Thecostofeachcluster\n",
      "isatmost?timesthesumofsharesofverticesinsidethecluster;(2)For\n",
      "anysetSofverticescontainingatmostonefromeachclusterinoursolution,\n",
      "theimaginaryclusterScostsatleastthesumofsharesofverticesinS.Note\n",
      "thatintuitivelythepropertyguaranteesthatverticesinsideeachcluster\n",
      "canpaythecostoftheircorrespondingclusterandthatthereisnofree-rider.\n",
      "Thesecondpropertyintuitivelyimplieswecannotanybetterclusteringby\n",
      "combiningverticesfromtclustersinoursolution.Nextweshowthat\n",
      "6\n",
      "\n",
      "therealwaysexistsaforsingle-linkageclusteringguaranteeingits\n",
      "worst-caseperformance.Theorem4.Single-linkagealwaysproducesaclustering\n",
      "solutionthathasa\n",
      "55.1\n",
      "DistributedAlgorithmsConstantRoundAlgorithmForDenseGraphs\n",
      "Unsurprisingly,theyclusteringofagivengraphGisclosely\n",
      "relatedtotheproblemofitsMinimumSpanningTree(MST).Infact,we\n",
      "showthedatathatisencodedintheMSTofGistforitsy\n",
      "clustering(Theorem9).Thispropertyisalsoknowntobetrueforsinglelinkage\n",
      "[24].ForMapReducealgorithmsthisisparticularlyusefulbecausetheMST\n",
      "requiresasubstantiallysmallerspacethantheoriginalgraphandcanbestored\n",
      "inonemachine.Therefore,oncewehavetheMST,wecanobtainyor\n",
      "singlelinkageinoneround.Themaincontributionofthissectionisanalgorithm\n",
      "fortheMST(andthereforetheyclustering)ofdensegraphsin\n",
      "constantroundsofMapReducewhichimprovesuponpriorknowndensegraph\n",
      "MSTalgorithmsofetal.[30]andLattanzietal.[34].Theoretical\n",
      "Model.LetNdenotetheinputsize.ThereareatotalnumberofMmachines\n",
      "andeachofthemhasaspaceofsizeS.BothSandMmustbesubstantially\n",
      "sublinearinN.Ineachround,themachinescanrunanarbitrarypolynomial\n",
      "timealgorithmontheirlocaldata.Nocommunicationisallowedduringthe\n",
      "roundsbutanytwomachinescancommunicatewitheachotherbetweenthe\n",
      "roundsaslongasthetotalcommunicationsizeofeachmachinedoesnotexceed\n",
      "itsmemorysize.5\n",
      "Algorithm1MSTofDenseGraphsInput:AweightedgraphGOutput:The\n",
      "minimumspanningtreeofG1:functionMST(G=(V,E),)2:c?logn(m/n)\n",
      ".SinceGisassumedtobedenseweknowc>0.3:while|E|>O(n1+)do4:\n",
      "REDUCEEDGES(G,c)5:c?(c?)/26:Movealltheedgestoonemachine\n",
      "andMSTofGinthere.7:functionREDUCEEDGES(G=(V,E),c)8:\n",
      "k?n(c?)/29:Independentlyandu.a.r.partitionVintoksubsets\n",
      "f\n",
      "V1,...,\n",
      "Vk\n",
      "g\n",
      ".10:Independentlyandu.a.r.partitionVintoksubsets\n",
      "f\n",
      "U1,...,Uk\n",
      "g\n",
      ".11:LetGi,jbeasubgraphofGwithvertexsetVi?Ujcontaininganyedge\n",
      "(v,u)?E(G)wherev?Viandu?Uj.12:foranyi,j?\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      "do13:\n",
      "SendalltheedgesofGi,jtothesamemachineanditsMSTinthere.14:\n",
      "RemoveanedgeefromE(G),ife?Gi,janditisnotinMSTofGi,j.\n",
      "ThismodeliscalledMassivelyParallelCommunication(MPC)inthelit-\n",
      "eratureandis?arguablythemostpopularone?[26]amongMapReducelike\n",
      "models.Theorem5.LetG=(V,E)beagraphwithnverticesandn1+cedges\n",
      "foranyconstantc>0andletw:E7?R+beitsedgeweights.Foranygiven\n",
      "suchthat0<<c,thereexistsarandomizedalgorithmfortheMSTof\n",
      "Gthatrunsinatmostdlog(c/)e+1roundsofMPCwhere?1+)withhigh\n",
      "probabilityandthetotalnumberofrequiredeverymachineusesaspaceofsize\n",
      "O(nmachinesisO(nc?).?1+c))onallmachinestostoretheinput.Our\n",
      "algorithm,therefore,usesonlyenoughtotalspace(O(nThefollowingobserva-\n",
      "tionismainlyusedbyAlgorithm1toiterativelyremovetheedgesthatarenot\n",
      "partoftheMST.Lemma6.LetG0=(V0,E0)bea(notnecessarily\n",
      "connected)subgraphoftheinputgraphG.Ifanedgee?E0isnotintheMST\n",
      "7\n",
      "\n",
      "ofG0,thenitisnotintheMSTofGeither.Tobemorespweiteratively\n",
      "divideGintoitssubgraphs,suchthateachedgeofGisatleastinonesubgraph.\n",
      "Then,wehandleeachsubgraphinonemachineandthrowawaytheedgesthat\n",
      "arenotintheirMST.WerepeatthisuntilthereareonlyO(n1+)edgesleft\n",
      "inG.ThenwecanhandlealltheseedgesinonemachineandtheMSTof\n",
      "G.Algorithm1formalizesthisprocess.Lemma7.Algorithm1correctly\n",
      "theMSToftheinputgraphindlog(c/)e+1rounds.ByLemma6weknow\n",
      "anyedgethatisremovedfromisnotpartoftheMSTthereforeitto\n",
      "provethewhileloopinAlgorithm1takesdlog(c/)e+1iterations.?1+)with\n",
      "highprobability.Lemma8.InAlgorithm1,everymachineusesaspaceofsize\n",
      "O(nThecombinationofLemma7andLemma8impliesthatAlgorithm1is\n",
      "indeedinMPCandTheorem5holds.Seesupplementarymaterialforomitted\n",
      "proofs.Thenextstepistoprovealltheinformationthatisrequiredfory\n",
      "clusteringisindeedcontainedintheMST.Theorem9.LetG=(V,E)denote\n",
      "anarbitrarygraph,andletG0=(V,E0)denotetheminimumspanningtree\n",
      "ofG.RunningnityclusteringalgorithmonGgivesthesameclusteringofV\n",
      "asrunningthisalgorithmonG0.BycombiningtheMSTalgorithmgivenfor\n",
      "Theorem5andtheofMSTforcomputingyclustering(The-\n",
      "orem9)andsinglelinkage([24])wegetthefollowingcorollary.Corollary10.\n",
      "LetG=(V,E)beagraphwithnverticesandn1+cedgesforanyconstantc\n",
      ">0andletw:E7?R+beitsedgeweights.Foranygivensuchthat0<<c,\n",
      "thereexistsa6\n",
      "randomizedalgorithmforyclusteringandsinglelinkagethatrunsin\n",
      "dlog(c/)e+1roundsof?1+)withhighprobabilityandthetotalnumber\n",
      "MPCwhereeverymachineusesaspaceofsizeO(nc?ofrequiredmachinesis\n",
      "O(n).5.2\n",
      "LogarithmicRoundAlgorithmForSparseGraphs\n",
      "ConsideragraphG(V,E)onn=|V|vertices,withedgeweightsw:\n",
      "E7?R.Weassumethattheedgeweightsdenotedistances.(Thediscussion\n",
      "appliesmutatismutandistothecasewhereedgeweightssignifysimilarity.)The\n",
      "algorithmworksforanumberofsynchronousrounds,oruntilnofurther\n",
      "progressismade,say,byreachingasingleclusterofallvertices.Eachround\n",
      "consistsoftwosteps:First,everyvertexpicksitsbestedge(i.e.,thatofthe\n",
      "minimumweight)ateachround;andthenthegraphiscontractedalongthe\n",
      "selectededges.(SeeAlgorithm2intheappendix.)Foraconnectedgraph,\n",
      "thealgorithmcontinuesuntilasingleclusterofallverticesisobtained.The\n",
      "supernodesattroundscanbethoughtofasahierarchicalclusteringof\n",
      "thevertices.Whilethestepofeachroundhasatrivialimplementationin\n",
      "MapReduce,thelattermighttake?(logn)MapReduceroundstoimplement,as\n",
      "itisaninstanceoftheconnectedcomponentsproblem.UsingaDHTwasshown\n",
      "totlyimprovetherunningtimehere,byimplementingtheoperation\n",
      "inoneroundofMapReduce[31].Basicallywehavearead-onlyrandom-access\n",
      "tablemappingeachvertextoitsbestneighbor.Repeatedlookupsinthetable\n",
      "allowseachvertextofollowthechainofbestneighborsuntilaloop(oflength\n",
      "two)isencountered.Thisassignsauniquenameforeachconnectedcomponent;\n",
      "thenalltheverticesinthesamecomponentarereducedintoasupernode.Theo-\n",
      "8\n",
      "\n",
      "rem11.TheyclusteringalgorithmrunsinO(logn)roundsofMapReduce\n",
      "whenwehaveaccesstoadistributedhashtable(DHT).WithouttheDHT,the\n",
      "algorithmtakesO(log2n)rounds.\n",
      "6\n",
      "Experiments\n",
      "6.1\n",
      "QualityAnalysis\n",
      "Inthissection,wecomparewellknownhierarchicalandatclusteringal-\n",
      "gorithms,suchask-means,singlelinkage,completelinkageandaveragelinkage\n",
      "withtvariantsofyclustering,suchassingley,complete\n",
      "yandaveragey.Werunourexperimentsonseveraldatasetsfrom\n",
      "theUCIdatabase[37]anduseEuclideandistance6.Toevaluatetheoutputs\n",
      "ofthesealgorithmsweuseRandindexwhichisasfollows.\n",
      "4(Randindex[40]).GivenasetV=\n",
      "f\n",
      "v1,...,vn\n",
      "g\n",
      "ofnpointsandtwo\n",
      "clusteringsX=\n",
      "f\n",
      "X1,...,Xr\n",
      "g\n",
      "andY=\n",
      "f\n",
      "Y1,...,Ys\n",
      "g\n",
      "ofV.the\n",
      "following.?a:thenumberofpairsinVthatareinthesameclusterinXand\n",
      "inthesameclusterinY.?b:thenumberofpairsinVthatareint\n",
      "clustersinXandintclustersinY.\n",
      "theRandindexr(X,Y)istobe(a+b)/n2.Byhavingthe\n",
      "groundtruthclusteringTofadataset,wetheRandindexscoreofa\n",
      "clusteringX,tober(X,T).TheRandindexbasedscoresareinrange[0,1]\n",
      "andahighernumberimpliesabetterclustering.Forahierarchicalclustering,\n",
      "thelevelofitscorrespondingtreewiththehighestscoreisusedforevaluations.\n",
      "Figure2(a)comparestheRandindexscoreoftclusteringalgorithms\n",
      "fortdatasets.Weobservethatsingleygenerallyperformsreally\n",
      "wellandisamongthetoptwoalgorithmsformostofthedatasets(allexcept\n",
      "Glass).Averageyalsoseemstoperformwellandinsomecases(e.g.,for\n",
      "Soybeandataset)itproducesaveryhighqualityclusteringcomparedtoothers.\n",
      "Tosummarize,linkagebasedalgorithmsdonotseemtobeasgoodasy\n",
      "basedalgorithmsbutinsomecasesk-meanscouldbeclose.6\n",
      "WeconsiderIris,Wine,Soybean,DigitsandGlassdatasets.\n",
      "7\n",
      "1.00.8\n",
      "Singley\n",
      "0.8\n",
      "Clusters'SizeRatio\n",
      "RandIndexScore\n",
      "AlgorithmAverageyCompleteyCompleteLinkage\n",
      "0.6\n",
      "AverageLinkageSingleLinkage\n",
      "0.4\n",
      "AlgorithmSingley\n",
      "0.6\n",
      "AverageyCompletey\n",
      "0.4\n",
      "CompleteLinkageAverageLinkage\n",
      "9\n",
      "\n",
      "0.2\n",
      "SingleLinkage\n",
      "k-Means\n",
      "k-Means0.0\n",
      "Iris\n",
      "Soybean\n",
      "Wine\n",
      "Glass\n",
      "Iris\n",
      "Digits\n",
      "Datasets\n",
      "Soybean\n",
      "Wine\n",
      "Glass\n",
      "Digits\n",
      "Datasets\n",
      "(a)\n",
      "(b)\n",
      "Figure2:ComparisonofclusteringalgorithmsbasedontheirRandindex\n",
      "score(a)andclusterssizeratio(b).\n",
      "Table1:Statisticsaboutdatasetsused.(NumbersforImageGraphare\n",
      "approximate.)Thecolumnshowstherelativerunningtimeofy\n",
      "clustering,andthelastcolumnisthespeedupobtainedbyaten-foldincrease\n",
      "inparallelism.DatasetLiveJournalOrkutFriendsterImageGraph\n",
      "#nodes4,846,6093,072,44165,608,3662?1010\n",
      "#edges7,861,383,69042,687,055,6441,092,793,541,0141012\n",
      "maxdegree444,522893,0562,151,46214000\n",
      "runningtime1.02.454142\n",
      "speedup4.39.25.94.1\n",
      "Anotherpropertyofthealgorithmsthatwemeasureistheclusters?size\n",
      "ratio.LetX=\n",
      "f\n",
      "X1,...,Xr\n",
      "g\n",
      "beaclustering.WethesizeratioofXto\n",
      "bemini,j?[r]|Xi|/|Xj|.AsitisvisualizedinFigure2(b),ybased\n",
      "algorithmshaveamuchhighersizeratio(i.e.,theclustersaremorebalanced)\n",
      "comparedtolinkagebasedalgorithms.Thisthepropertythatwe\n",
      "provedforPoissondistributionsinSection4forrealworlddatasets.Hence\n",
      "webelieveyclusteringissuperiorto(oratleastasgoodas)theother\n",
      "methodswhenthedatasetunderconsiderationisnotextremelyunbalanced.\n",
      "6.2\n",
      "Scalability\n",
      "Herewedemonstratethescalabilityofourimplementationofyclus-\n",
      "tering.Acollectionofpublicandprivategraphsofvaryingsizesarestudied.\n",
      "Thesegraphshavebetween4millionand20billionverticesandfrom4billion\n",
      "toonetrillionedges.ThethreegraphsinTable1arebasedonpublic\n",
      "graphs[35].Asmostpublicgraphsareunweighted,weusethenumberofcom-\n",
      "monneighborsbetweenapairofnodesastheweightoftheedgebetweenthem.\n",
      "(Thisiscomputedforallpairs,whethertheyformapairintheoriginalgraph\n",
      "10\n",
      "\n",
      "ornot,andthennewedgesofweightzeroareremoved.)Thelastgraphis\n",
      "basedon(asubsetof)aninternalcorpusofpublicimagesfoundontheweband\n",
      "theirsimilarities.Wenotethatweusethe?maximum?spanningtreevariant\n",
      "ofyclustering;hereedgeweightsdenotesimilarityratherthandistance.\n",
      "Whilewecannotrevealtheexactrunningtimesandnumberofmachinesused\n",
      "intheexperiments,wereportthesequantitiesin?normalizedform.?Weonly\n",
      "runoneroundofyclustering(consistingofa?FindBestNeighbors?and\n",
      "a?ContractGraph?step).Twosettingsareusedintheexperiments.Weonce\n",
      "useWMapReduceworkersandDmachinesfortheDHT,andcomparethis\n",
      "tothecasewith10WMapReduceworkersandDmachinesfortheDHT.This\n",
      "ten-foldincreaseinthenumberofMapReduceworkersleadstofour-toten-fold\n",
      "decreaseinthetotalrunningtimefortdatasets.Eachrunningtimeis\n",
      "itselftheaverageoverthreerunstoreducethetofexternalnetworkevents.\n",
      "Table1alsoshowshowtherunningtimechangeswiththesizeofthegraph.\n",
      "WithamodestnumberofMapReduceworkers,yclusteringrunsinless\n",
      "thananhourforallthegraphs.8\n",
      "2References\n",
      "[1]MargaretaAckerman,ShaiBen-David,andDavidLoker.Characterization\n",
      "oflinkage-basedclustering.InCOLT2010-The23rdConferenceonLearning\n",
      "Theory,Haifa,Israel,June27-29,2010,pages270?281,2010.[2]AjitAgrawal,\n",
      "PhilipN.Klein,andR.Ravi.Whentreescollide:Anapproximationalgo-\n",
      "rithmforthegeneralizedsteinerproblemonnetworks.SIAMJ.Comput.,\n",
      "24(3):440?456,1995.[3]KookJinAhn,SudiptoGuha,andAndrewMcGre-\n",
      "gor.Analyzinggraphstructurevialinearmeasurements.InProceedingsofthe\n",
      "Twenty-ThirdAnnualACM-SIAMSymposiumonDiscreteAlgorithms,pages\n",
      "459?467,2012.[4]AlexandrAndoni,AleksandarNikolov,KrzysztofOnak,and\n",
      "GrigoryYaroslavtsev.Parallelalgorithmsforgeometricgraphproblems.In\n",
      "Proceedingsofthe46thAnnualACMSymposiumonTheoryofComputing,\n",
      "pages574?583.ACM,2014.[5]BahmanBahmani,BenjaminMoseley,Andrea\n",
      "Vattani,RaviKumar,andSergeiVassilvitskii.Scalablek-means++.PVLDB,\n",
      "5(7):622?633,2012.[6]Maria-FlorinaBalcan,AvrimBlum,andSantoshVem-\n",
      "pala.Adiscriminativeframeworkforclusteringviasimilarityfunctions.In\n",
      "Proceedingsofthe40thAnnualACMSymposiumonTheoryofComputing,\n",
      "Victoria,BritishColumbia,Canada,May17-20,2008,pages671?680,2008.[7]\n",
      "Maria-FlorinaBalcan,StevenEhrlich,andYingyuLiang.Distributedk-means\n",
      "andk-medianclusteringongeneralcommunicationtopologies.InAdvancesin\n",
      "NeuralInformationProcessingSystems26:27thAnnualConferenceonNeural\n",
      "InformationProcessingSystems2013.ProceedingsofameetingheldDecem-\n",
      "ber5-8,2013,LakeTahoe,Nevada,UnitedStates.,pages1995?2003,2013.\n",
      "[8]MohammadHosseinBateni,AdityaBhaskara,SilvioLattanzi,andVahabS.\n",
      "Mirrokni.Distributedbalancedclusteringviamappingcoresets.InAdvances\n",
      "inNeuralInformationProcessingSystems27:AnnualConferenceonNeural\n",
      "InformationProcessingSystems2014,December8-132014,Montreal,Quebec,\n",
      "11\n",
      "\n",
      "Canada,pages2591?2599,2014.[9]MohammadHosseinBateni,Mohammad\n",
      "TaghiHajiaghayi,andD?nielMarx.Approximationschemesforsteinerforest\n",
      "onplanargraphsandgraphsofboundedtreewidth.J.ACM,58(5):21:1?21:37,\n",
      "2011.[10]PaulBeame,ParaschosKoutris,andDanSuciu.Communication\n",
      "stepsforparallelqueryprocessing.InProceedingsofthe32ndACMSIGMOD-\n",
      "SIGACT-SIGAIsymposiumonPrinciplesofdatabasesystems,pages273?284.\n",
      "ACM,2013.[11]OktarBoruvka.Ojist?mprobl?muminim?ln?m.Pr?ce\n",
      "Moravsk?p?r?rodov?edeck?spole?cnosti.Mor.p?r?rodov?edeck?spole?cnost,\n",
      "1926.[12]FayChang,Dean,SanjayGhemawat,WilsonC.Hsieh,Debo-\n",
      "rahA.Wallach,MichaelBurrows,TusharChandra,AndrewFikes,andRobert\n",
      "E.Gruber.Bigtable:Adistributedstoragesystemforstructureddata.ACM\n",
      "Trans.Comput.Syst.,26(2):4:1?4:26,2008.[13]MosesCharikarandVaggos\n",
      "Chatziafratis.Approximatehierarchicalclusteringviasparsestcutandspread-\n",
      "ingmetrics.InProceedingsoftheTwenty-EighthAnnualACM-SIAMSympo-\n",
      "siumonDiscreteAlgorithms,SODA2017,Barcelona,Spain,HotelPortaFira,\n",
      "January16-19,pages841?854,2017.[14]RajeshChitnis,GrahamCormode,\n",
      "HosseinEsfandiari,MohammadTaghiHajiaghayi,AndrewMcGregor,Morteza\n",
      "Monemizadeh,andSofyaVorotnikova.Kernelizationviasamplingwithappli-\n",
      "cationstomatchingsandrelatedproblemsindynamicgraphstreams.\n",
      "InProceedingsoftheTwenty-SeventhAnnualACM-SIAMSymposiumonDis-\n",
      "creteAlgorithms,pages1326?1344,2016.[15]RajeshHemantChitnis,Graham\n",
      "Cormode,MohammadTaghiHajiaghayi,andMortezaMonemizadeh.Parame-\n",
      "terizedstreaming:Maximalmatchingandvertexcover.InProceedingsofthe\n",
      "Twenty-SixthAnnualACM-SIAMSymposiumonDiscreteAlgorithms,pages\n",
      "1234?1251,2015.[16]SanjoyDasgupta.Acostfunctionforsimilarity-based\n",
      "hierarchicalclustering.InProceedingsofthe48thAnnualACMSIGACTSym-\n",
      "posiumonTheoryofComputing,STOC2016,Cambridge,MA,USA,June\n",
      "18-21,2016,pages118?127,2016.[17]DeanandSanjayGhemawat.\n",
      "MapReduce:dataprocessingonlargeclusters.Communicationsof\n",
      "theACM,51(1):107?113,2008.\n",
      "9\n",
      "[18]AlinaEne,SungjinIm,andBenjaminMoseley.Fastclusteringusing\n",
      "mapreduce.InProceedingsofthe17thACMSIGKDDInternationalConfer-\n",
      "enceonKnowledgeDiscoveryandDataMining,SanDiego,CA,USA,Au-\n",
      "gust21-24,2011,pages681?689,2011.[19]HosseinEsfandiari,Mohammad\n",
      "TaghiHajiaghayi,VahidLiaghat,MortezaMonemizadeh,andKrzysztofOnak.\n",
      "Streamingalgorithmsforestimatingthematchingsizeinplanargraphsand\n",
      "beyond.InProceedingsoftheTwenty-SixthAnnualACM-SIAMSymposium\n",
      "onDiscreteAlgorithms,pages1217?1233,2015.[20]AssafGlazer,OmerWeiss-\n",
      "brod,MichaelLindenbaum,andShaulMarkovitch.Approximatinghierarchical\n",
      "mv-setsforhierarchicalclustering.InAdvancesinNeuralInformationProcess-\n",
      "ingSystems27:AnnualConferenceonNeuralInformationProcessingSystems\n",
      "2014,December8-132014,Montreal,Quebec,Canada,pages999?1007,2014.\n",
      "[21]MichelX.GoemansandDavidP.Williamson.Ageneralapproximation\n",
      "techniqueforconstrainedforestproblems.SIAMJ.Comput.,24(2):296?317,\n",
      "1995.[22]JacobGoldbergerandSamT.Roweis.Hierarchicalclusteringof\n",
      "12\n",
      "\n",
      "amixturemodel.InAdvancesinNeuralInformationProcessingSystems17\n",
      "[NeuralInformationProcessingSystems,NIPS2004,December13-18,2004,\n",
      "Vancouver,BritishColumbia,Canada],pages505?512,2004.[23]MichaelT\n",
      "Goodrich,NodariSitchinava,andQinZhang.Sorting,searching,andsimula-\n",
      "tioninthemapreduceframework.InInternationalSymposiumonAlgorithms\n",
      "andComputation,pages374?383.Springer,2011.[24]JohnCGowerand\n",
      "GJSRoss.Minimumspanningtreesandsinglelinkageclusteranalysis.Ap-\n",
      "pliedstatistics,pages54?64,1969.[25]MohammadTaghiHajiaghayi,Vahid\n",
      "Liaghat,andDebmalyaPanigrahi.Onlinenode-weightedsteinerforestandex-\n",
      "tensionsviadiskpaintings.In54thAnnualIEEESymposiumonFoundations\n",
      "ofComputerScience,FOCS2013,26-29October,2013,Berkeley,CA,USA,\n",
      "pages558?567,2013.[26]SungjinIm,BenjaminMoseley,andXiaoruiSun.Ef-\n",
      "tmassivelyparallelmethodsfordynamicprogramming.InProceedingsof\n",
      "the46thAnnualACMSymposiumonTheoryofComputing.ACM,2017.[27]\n",
      "ChenJin,RuoqianLiu,ZhengzhangChen,WilliamHendrix,AnkitAgrawal,\n",
      "andAlokN.Choudhary.Ascalablehierarchicalclusteringalgorithmusing\n",
      "spark.InFirstIEEEInternationalConferenceonBigDataComputingService\n",
      "andApplications,BigDataService2015,RedwoodCity,CA,USA,March30-\n",
      "April2,2015,pages418?426,2015.[28]ChenJin,MdMostofaAliPatwary,\n",
      "AnkitAgrawal,WilliamHendrix,Wei-kengLiao,andAlokChoudhary.Disc:\n",
      "Adistributedsingle-linkagehierarchicalclusteringalgorithmusingmapreduce.\n",
      "InProceedingsofthe4thInternationalSCWorkshoponDataIntensiveCom-\n",
      "putingintheClouds,2013.[29]MichaelJ?ngerandWilliamR.Pulleyblank.\n",
      "Newprimalanddualmatchingheuristics.Algorithmica,13(4):357?386,1995.\n",
      "[30]HowardSiddharthSuri,andSergeiVassilvitskii.Amodelofcom-\n",
      "putationformapreduce.InProceedingsofthetwentannualACM-SIAM\n",
      "symposiumonDiscreteAlgorithms,pages938?948.SocietyforIndustrialand\n",
      "AppliedMathematics,2010.[31]RaimondasKiveris,SilvioLattanzi,Vahab\n",
      "S.Mirrokni,VibhorRastogi,andSergeiVassilvitskii.Connectedcomponents\n",
      "inMapReduceandbeyond.InProceedingsoftheACMSymposiumonCloud\n",
      "Computing,Seattle,WA,USA,November03-05,2014,pages18:1?18:13,2014.\n",
      "[32]AkshayKrishnamurthy,SivaramanBalakrishnan,MinXu,andAartiSingh.\n",
      "tactivealgorithmsforhierarchicalclustering.InProceedingsofthe\n",
      "29thInternationalConferenceonMachineLearning,ICML2012,Edinburgh,\n",
      "Scotland,UK,June26-July1,2012,2012.[33]JosephB.Kruskal.Onthe\n",
      "shortestspanningsubtreeofagraphandthetravelingsalesmanproblem.In\n",
      "ProceedingsoftheAmericanMathematicalSociety,volume7,pages48?50,\n",
      "1956.[34]SilvioLattanzi,BenjaminMoseley,SiddharthSuri,andSergeiVas-\n",
      "silvitskii.Filtering:amethodforsolvinggraphproblemsinmapreduce.In\n",
      "Proceedingsofthetwenty-thirdannualACMsymposiumonParallelisminal-\n",
      "gorithmsandarchitectures,pages85?94.ACM,2011.[35]JureLeskovecand\n",
      "AndrejKrevl.SNAPDatasets:Stanfordlargenetworkdatasetcollection.http:\n",
      "//snap.stanford.edu/data,June2014.\n",
      "10\n",
      "[36]JureLeskovec,AnandRajaraman,andD.Ullman.Miningof\n",
      "MassiveDatasets,2ndEd.CambridgeUniversityPress,2014.[37]MosheLich-\n",
      "13\n",
      "\n",
      "man.UCImachinelearningrepository,2013.[38]RonaldMeesteretal.Nearest\n",
      "neighborandhardspheremodelsincontinuumpercolation.Randomstructures\n",
      "andalgorithms,9(3):295?315,1996.[39]MarkNewman.Networks:AnIntro-\n",
      "duction.OxfordUniversityPress,Inc.,NewYork,NY,USA,2010.[40]William\n",
      "MRand.Objectivecriteriafortheevaluationofclusteringmethods.Journal\n",
      "oftheAmericanStatisticalassociation,66(336):846?850,1971.[41]AurkoRoy\n",
      "andSebastianPokutta.Hierarchicalclusteringviaspreadingmetrics.InAd-\n",
      "vancesinNeuralInformationProcessingSystems29:AnnualConferenceon\n",
      "NeuralInformationProcessingSystems2016,December5-10,2016,Barcelona,\n",
      "Spain,pages2316?2324,2016.[42]M.Sollin.Letrac?decanalisation.Pro-\n",
      "gramming,Games,andTransportationNetworks(inFrench),1965.[43]Tom\n",
      "White.Hadoop:TheeGuide.O?ReillyMedia,Inc.,2012.[44]Reza\n",
      "ZadehandShaiBen-David.Auniquenesstheoremforclustering.InUAI2009,\n",
      "ProceedingsoftheTwenty-FifthConferenceonUncertaintyinIntel-\n",
      "ligence,Montreal,QC,Canada,June18-21,2009,pages639?646,2009.[45]\n",
      "MateiZaharia,MosharafChowdhury,MichaelJ.Franklin,ScottShenker,and\n",
      "IonStoica.Spark:Clustercomputingwithworkingsets.InProceedingsof\n",
      "the2NdUSENIXConferenceonHotTopicsinCloudComputing,pages10?10,\n",
      "2010.\n",
      "11\n",
      "14\n",
      "\n",
      "PP4756.pdf\n",
      "PP4756.pdf 14\n",
      "SymbolicDynamicProgrammingforContinuous\n",
      "StateandObservationPOMDPs\n",
      "Authoredby:\n",
      "PascalPoupart\n",
      "ScottSanner\n",
      "ZahraZamani\n",
      "KristianKersting\n",
      "Abstract\n",
      "Partially-observableMarkovdecisionprocesses(POMDPs)providea\n",
      "powerfulmodelforreal-worldsequentialdecision-makingproblems.In\n",
      "recentyears,point-basedvalueiterationmethodshaveproventobeex-\n",
      "tremelyetechniquesfor?nding(approximately)optimaldynamic\n",
      "programmingsolutionstoPOMDPswhenaninitialsetofbeliefstates\n",
      "isknown.However,nopoint-basedworkhasprovidedexactpoint-based\n",
      "backupsforbothcontinuousstateandobservationspaces,whichwetackle\n",
      "inthispaper.Ourkeyinsightisthatwhiletheremaybeanin?nitenum-\n",
      "berofpossibleobservations,thereareonlya?nitenumberofobservation\n",
      "partitioningsthatarerelevantforoptimaldecision-makingwhena?nite,\n",
      "?xedsetofreachablebeliefstatesisknown.Tothisend,wemaketwoim-\n",
      "portantcontributions:(1)weshowhowpreviousexactsymbolicdynamic\n",
      "pro-grammingsolutionsforcontinuousstateMDPscanbegeneralizedto\n",
      "continu-ousstatePOMDPswithdiscreteobservations,and(2)weshow\n",
      "howthissolutioncanbefurtherextendedviarecentlydevelopedsym-\n",
      "bolicmethodstocontinuousstateandobservationstoderivetheminimal\n",
      "relevantobservationpartitioningforpotentiallycorrelated,multivariate\n",
      "observationspaces.Wedemonstrateproof-of-conceptresultsonuni-and\n",
      "multi-variatestateandobservationsteamplantcontrol.\n",
      "1PaperBody\n",
      "Point-basedvalueiteration(PBVI)methodshaveprovenextremelyefor\n",
      "(approximately)optimaldynamicprogrammingsolutionstopartiallyob-\n",
      "servableMarkovdecisionprocesses(POMDPs)whenasetofinitialbeliefstates\n",
      "isknown.However,noPBVIworkhasprovidedexactpoint-basedbackupsfor\n",
      "bothcontinuousstateandobservationspaces,whichwetackleinthispaper.\n",
      "Ourkeyinsightisthatwhiletheremaybeannumberofobservations,\n",
      "thereareonlyanumberofcontinuousobservationpartitioningsthatare\n",
      "1\n",
      "\n",
      "relevantforoptimaldecision-makingwhenaxedsetofreachablebe-\n",
      "liefstatesisconsidered.Tothisend,wemaketwoimportantcontributions:\n",
      "(1)weshowhowpreviousexactsymbolicdynamicprogrammingsolutionsfor\n",
      "continuousstateMDPscanbegeneralizedtocontinuousstatePOMDPswith\n",
      "discreteobservations,and(2)weshowhowrecentlydevelopedsymbolicintegra-\n",
      "tionmethodsallowthissolutiontobeextendedtoPBVIforcontinuousstate\n",
      "andobservationPOMDPswithpotentiallycorrelated,multivariatecontinuous\n",
      "observationspaces.\n",
      "1\n",
      "Introduction\n",
      "Partially-observableMarkovdecisionprocesses(POMDPs)areapowerful\n",
      "modelingformalismforreal-worldsequentialdecision-makingproblems[3].In\n",
      "recentyears,point-basedvalueiterationmethods(PBVI)[5,10,11,7]have\n",
      "provedextremelysuccessfulatscaling(approximately)optimalPOMDPsolu-\n",
      "tionstolargestatespaceswhenasetofinitialbeliefstatesisknown.While\n",
      "PBVIhasbeenextendedtobothcontinuousstateandcontinuousobservation\n",
      "spaces,nopriorworkhastackledbothjointlywithoutsampling.[6]providesex-\n",
      "actpoint-basedbackupsforcontinuousstateanddiscreteobservationproblems\n",
      "(withapproximatesample-basedextensionstocontinuousactionsandobserva-\n",
      "tions),while[2]providesexactpoint-basedbackups(PBBs)fordiscretestate\n",
      "andcontinuousobservationproblems(wheremultivariateobservationsmustbe\n",
      "conditionallyindependent).Whilerestrictedtodiscretestates,[2]providesan\n",
      "importantinsightthatweexploitinthiswork:onlyanumberofpartition-\n",
      "ingsoftheobservationspacearerequiredtodistinguishbetweentheoptimal\n",
      "conditionalpolicyoverasetofbeliefstates.Weproposetwomajorcontri-\n",
      "butions:First,weextendsymbolicdynamicprogrammingforcontinuousstate\n",
      "MDPs[9]toPOMDPswithdiscreteobservations,arbitrarycontinuousreward\n",
      "andtransitionswithdiscretenoise(i.e.,amixtureofdeterministictran-\n",
      "sitions).Second,weextendthissymbolicdynamicprogrammingalgorithmto\n",
      "PBVIandthecaseofcontinuousobservations1\n",
      "(whilerestrictingtransitiondynamicstobepiecewiselinearwithdiscrete\n",
      "noise,rewardstobepiecewiseconstant,andobservationprobabilitiesandbeliefs\n",
      "tobeuniform)bybuildingon[2]toderiverelevantobservationpartitionsfor\n",
      "potentiallycorrelated,multivariatecontinuousobservations.\n",
      "2\n",
      "HybridPOMDPModel\n",
      "Ahybrid(discreteandcontinuous)partiallyobservableMDP(H-POMDP)\n",
      "isatuplehS,A,O,T,R,Z,?,hi.StatesSaregivenbyvector(ds,xs)=(ds1\n",
      ",...,dsn,xs1,...,xsm)whereeachdsi?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "(1?i?n)isbooleanand\n",
      "eachxsj?R(1?j?m)iscontinuous.Weassumeadiscreteactionspace\n",
      "A=\n",
      "f\n",
      "a1,...,ar\n",
      "g\n",
      ".ObservationsOaregivenbythevector(do,xo)=(do1\n",
      ",...,dop,xo1,...,xoq)whereeachdoi?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "(1?i?p)isboolean\n",
      "andeachxoj?R(1?j?q)iscontinuous.Threefunctionsarerequiredfor\n",
      "modelingH-POMDPs:(1)T:S?A?S?[0,1]aMarkoviantransitionmodel\n",
      "astheprobabilityofthenextstategiventheactionandpreviousstate;\n",
      "(2)R:S?A?Rarewardfunctionwhichreturnstheimmediaterewardof\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takinganactioninsomestate;and(3)anobservationfunctionasZ:S\n",
      "?A?O?[0,1]whichgivestheprobabilityofanobservationgiventheoutcome\n",
      "ofastateafterexecutinganaction.Adiscountfactor?,0???1isusedto\n",
      "discountrewardsttimestepsintothefutureby?t.WeuseadynamicBayes\n",
      "net(DBN)1tocompactlyrepresentthetransitionmodelToverthefactored\n",
      "statevariablesandweuseatwo-layerBayesnettorepresenttheobservation\n",
      "modelZ:T:p(x0s,d0s|xs,ds,a)=\n",
      "nY\n",
      "p(d0si|xs,ds,a)\n",
      "i=1\n",
      "Z:p(xo,do|x0s,d0s,a)=\n",
      "pY\n",
      "mY\n",
      "p(x0sj|xs,ds,d0s,a).\n",
      "(1)\n",
      "p(xoj|x0s,d0s,a).\n",
      "(2)\n",
      "j=1\n",
      "p(doi|x0s,d0s,a)\n",
      "i=1\n",
      "qYj=1\n",
      "Probabilitiesoverdiscretevariablesp(d0si|xs,ds,a)andp(doi|x0s,d0s\n",
      ",a)mayconditiononbothdiscretevariablesand(nonlinear)inequalitiesofcon-\n",
      "tinuousvariables;thisisfurtherrestrictedtolinearinequalitiesinthecaseof\n",
      "continuousobservations.Transitionsovercontinuousvariablesp(x0sj|xs,ds\n",
      ",d0s,a)mustbedeterministic(butarbitrarynonlinear)piecewisefunctions;in\n",
      "thecaseofcontinuousobservationstheyarefurtherrestrictedtobepiecewise\n",
      "linear;thispermitsdiscretenoiseinthecontinuoustransitionssincetheymay\n",
      "conditiononstochasticallysampleddiscretenext-statevariablesd0s.Obser-\n",
      "vationprobabilitiesovercontinuousvariablesp(xoj|x0s,d0s,a)onlyoccurin\n",
      "thecaseofcontinuousobservationsandarerequiredtobepiecewiseconstant\n",
      "(amixtureofuniformdistributions);thesamerestrictionholdsforbeliefstate\n",
      "representations.TherewardR(d,x,a)maybeanarbitrary(nonlinear)piece-\n",
      "wisefunctioninthecaseofdeterministicobservationsandapiecewiseconstant\n",
      "functioninthecaseofcontinuousobservations.Wenowprovideconcreteexam-\n",
      "ples.Example(PowerPlant)[1]Thesteamgenerationsystemofapowerplant\n",
      "evaporatesfeed-waterunderrestrictedpressureandtemperatureconditionsto\n",
      "turnasteamturbine.Arewardisobtainedwhenelectricityisgeneratedfrom\n",
      "theturbineandthesteampressureandtemperaturearewithinsaferanges.\n",
      "Mixingwaterandsteammakestherespectivepressureandtemperatureob-\n",
      "servationspo?Randto?Rontheunderlyingstateps?Randts?R\n",
      "highlyuncertain.ActionsA=\n",
      "f\n",
      "open,close\n",
      "g\n",
      "controltemperatureandpressure\n",
      "bymeansofapressurevalve.WeinitiallypresenttwoH-POMDPvariants\n",
      "labeled1D-PowerPlantusingasingletemperaturestatevariablets.Thetran-\n",
      "sitionandrewardarecommontoboth?temperatureincrements(decrements)\n",
      "withaclosed(opened)valve,alargenegativerewardisgivenforaclosedvalve\n",
      "3\n",
      "\n",
      "withtsexceedingcriticalthreshold15,andpositiverewardisgivenforasafe,\n",
      "electricity-producingstate:\"p(t0s|ts,a)=?t0s?\n",
      "(\n",
      "(a=open):ts?5(a=close):ts+7\n",
      "#\n",
      "??:?1?(a=open)R(ts,a)=(a=close)?(ts>15):?1000(3)??(a=\n",
      "close)??(t>15):100s\n",
      "NextweintroducetheDiscreteObs.1D-PowerPlantvariantwherewe\n",
      "anobservationspacewithasinglediscretebinaryvariableo?O=\n",
      "f\n",
      "high,low\n",
      "g\n",
      ":1Wedisallowgeneralsynchronicarcsforsimplicityofexpositionbutnote\n",
      "theirinclusiononlyplacesrestrictionsonthevariableeliminationorderingused\n",
      "duringthedynamicprogrammingbackupoperation.\n",
      "2\n",
      "b\n",
      "(1*x)>=50\n",
      "(1*x)<=39\n",
      "234+(1.5*x)\n",
      "(1*x)>=150\n",
      "250\n",
      "(1*x)<=139\n",
      "197+(2*x)\n",
      "121+(3*x)\n",
      "Figure1:(left)Exampleconditionalplan?hfordiscreteobservations;\n",
      "(right)example?-functionfor?hoverstateb?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",x?Rindecision\n",
      "diagramform:thetrue(1)branchissolid,thefalse(0)branchisdashed.(p(o\n",
      "=high|t0s,a=open)=\n",
      "t0s?15:0.9t0s>15:0.1\n",
      "(p(o=high|t0s,a=close)=\n",
      "t0s?15:0.7t0s>15:0.3\n",
      "(4)\n",
      "FinallyweintroducetheCont.Obs.1D-PowerPlantvariantwherewe\n",
      "anobservationspacewithasinglecontinuousvariabletouniformlydistributed\n",
      "onanintervalof10unitscenteredatt0s.(p(to|t0s,a\n",
      "=open)=\n",
      "U(to;t0s\n",
      "?\n",
      "5,t0s\n",
      "+5)=\n",
      "(to>t0s?5)?(to<t0s+5):0.1(to?t0s?5)?(to?t0s+5):0\n",
      "(5)\n",
      "Whilesimple,wenotenopriormethodcouldperformexactpoint-based\n",
      "backupsforeitherproblem.\n",
      "3\n",
      "ValueIterationforHybridPOMDPs\n",
      "InanH-POMDP,theagentdoesnotdirectlyobservethestatesandthus\n",
      "mustmaintainabeliefstateb(xs,ds)=p(xs,ds).Foragivenbeliefstateb\n",
      "4\n",
      "\n",
      "=b(xs,ds),aPOMDPpolicy?canberepresentedbyatreecorrespondingto\n",
      "aconditionalplan?.Anh-stepconditionalplan?hcanberecursively\n",
      "intermsof(h?1)-stepconditionalplansasshowninFig.1(left).Ourgoal\n",
      "istoapolicy?thatmaximizesthevaluefunction,asthesumof\n",
      "expecteddiscountedrewardsoverhorizonhstartingfrominitialbeliefstateb:\n",
      "V?h(b)=E?\n",
      "hXht=0\n",
      "i\n",
      "?t?rtb0=b\n",
      "(6)\n",
      "wherertistherewardobtainedattimetandb0isthebeliefstateatt=\n",
      "0.Forhandbeliefstateb,theoptimalpolicy?isgivenbyanh-step\n",
      "conditionalplan?h.Forh=?,theoptimaldiscounted(?<1)valuecan\n",
      "beapproximatedarbitrarilycloselybyatlylargeh[3].Evenwhenthe\n",
      "stateiscontinuous(buttheactionsandobservationsarediscrete),theoptimal\n",
      "POMDPvaluefunctionforhorizonhisapiecewiselinearandconvex\n",
      "functionofthebeliefstateb[6],henceVhisgivenbyamaximumoveranite\n",
      "setof??-functions??ih:h\n",
      "V(b)=max\n",
      "h?hi??\n",
      "h?ih,bi\n",
      "Z=max\n",
      "h?hi??\n",
      "X\n",
      "?ih(xs,ds)?b(xs,ds)dxs\n",
      "(7)\n",
      "xsds\n",
      "Lateronwhenwetacklecontinuousstateandobservations,wenotethatwe\n",
      "willdynamicallyderiveanoptimal,partitioningoftheobservationspace\n",
      "foragivenbeliefstateandhencereducethecontinuousobservationproblem\n",
      "backtoadiscreteobservationproblemateveryhorizon.The?hinthisop-\n",
      "timalh-stage-to-govaluefunctioncanbecomputedviaMonahan?sdynamic\n",
      "programmingapproachtovalueiteration(VI)[4].Initializing?10=0,?0=\n",
      "f\n",
      "?10\n",
      "g\n",
      ",andassumingdiscreteobservationso?Oh,?hisobtainedfrom?h?1\n",
      "asfollows:2hga,o,j(xs,ds)=\n",
      "Z\n",
      "X\n",
      "p(o|x0s,d0s,a)p(x0s,d0s|xs,ds,a)?jh?1(x0s,d0s)dxs0;??jh?1?\n",
      "?h?1\n",
      "(8)\n",
      "xs0ds0\n",
      "noh?ha=R(xs,ds,a)+?o?Oga,o,j(xs,ds)j[h?h=?a\n",
      "(9)(10)\n",
      "a2Theofsetsisas\n",
      "f\n",
      "p+q|p?P,q?Q\n",
      "g\n",
      ".\n",
      "j?\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "Sj\n",
      "=S1???Snwherethepairwisecross-sumPQ=\n",
      "5\n",
      "\n",
      "3\n",
      "Algorithm1:PBVI(H-POMDP,H,B=\n",
      "f\n",
      "bi\n",
      "g\n",
      ")??hVhi123456789\n",
      "1011121314151617\n",
      "beginV0:=0,h:=0,?0PBVI=\n",
      "f\n",
      "?10\n",
      "g\n",
      "whileh<Hdoh:=h+1,?h:=\n",
      "?,?hPBVI:=?foreachbi?Bdoforeacha?Ado?ha:=?if(continuous\n",
      "observations:q>0)then//DeriverelevantobservationpartitionsOihforbelief\n",
      "bihOih,p(Oih|x0s,d0s,a)i:=GenRelObs(?h?1PBVI,a,bi)else//\n",
      "DiscreteobservationsandmodelalreadyknownOih:=\n",
      "f\n",
      "do\n",
      "g\n",
      ";p(Oih|x0s,d0s\n",
      ",a):=seeEq(2)foreacho?Oihdoforeach?jh?1??h?1PBVIdo?jh?1:=\n",
      "Prime(?jh?1)//?di:di?d0iand?xi:xi?x0ihga,o,j:=seeEq(8)\n",
      "18\n",
      "?ha:=seeEq(9)?h:=?h??ha\n",
      "192021\n",
      "//Retainonly?-functionsoptimalateachbeliefpointforeachbi?Bdoh\n",
      "?b:=argmax?j??h?j?biihh?PBVI:=?hPBVI??bi\n",
      "222324252627\n",
      "//Terminateifearlyconvergenceif?hPBVI=?h?1PBVIthenbreak\n",
      "282930\n",
      "return?PBVI\n",
      "3132\n",
      "end\n",
      "Point-basedvalueiteration(PBVI)[5,11]computesthevaluefunctiononly\n",
      "forasetofbeliefstates\n",
      "f\n",
      "bi\n",
      "g\n",
      "wherebi:=p(xs,ds).Theideaisstraightforward\n",
      "andthemainmoneededtoMonahan?sVIapproachinAlgorithm1\n",
      "istheloopfromlines23?25whereonly?-functionsoptimalatsomebeliefstate\n",
      "areretainedforsubsequentiterations.Inthecaseofcontinuousobservation\n",
      "variables(q>0),wewillneedtoderivearelevantsetofobservationsonline\n",
      "10,akeycontributionofthisworkasdescribedinSection4.3.Otherwiseif\n",
      "theobservationsareonlydiscrete(q=0),thenasetofobservationsis\n",
      "alreadyknownandtheobservationfunctionasgiveninEq(2).Weremark\n",
      "thatAlgorithm1isagenericframeworkthatcanbeusedforbothPBVIand\n",
      "othervariantsofapproximateVI.IfusedforPBVI,antdirectbackup\n",
      "computationoftheoptimal?-functionforbeliefstatebishouldbeusedinline\n",
      "17thatislinearinthenumberofobservations[5,11]andwhichobviatesthe\n",
      "needforlines23?25.However,foranalternateversionofapproximatevalueit-\n",
      "erationthatwilloftenproducemoreaccuratevaluesforbeliefstatesotherthan\n",
      "thoseinB,onemayinsteadretainthefullcross-sumbackupofline17,but\n",
      "omitlines23?25?thisyieldsanapproximateVIapproach(usingdiscretized\n",
      "observationsrelevantonlytoachosensetofbeliefstatesBifcontinuousob-\n",
      "servationsarepresent)thatisnotrestrictedtoalpha-functionsonlyoptimalat\n",
      "B,henceallowinggreateryinapproximatingthevaluefunctionover\n",
      "allbeliefstates.WhereasPBVIisoptimalifallreachablebeliefstateswithin\n",
      "horizonHareenumeratedinB,intheH-POMDPsetting,thegenerationof\n",
      "continuousobservationswillmostoftenleadtoannumberofreachable\n",
      "beliefstates,evenwithhorizon?thismakesitquitedulttoprovide\n",
      "optimalityguaranteesinthegeneralcaseofPBVIforcontinuousobservation\n",
      "6\n",
      "\n",
      "settings.Nonetheless,PBVIhasbeenquitesuccessfulinpracticewithoutex-\n",
      "haustiveenumerationofallreachablebeliefs[5,10,11,7],whichmotivatesour\n",
      "useofPBVIinthiswork.4\n",
      "4\n",
      "SymbolicDynamicProgramming\n",
      "Inthissectionwetakeasymbolicdynamicprogramming(SDP)approach\n",
      "toimplementingVIandPBVIasinthelastsection.Todothis,we\n",
      "needonlyshowthatallrequiredoperationscanbecomputedtlyandin\n",
      "closed-form,whichwedonext,buildingonSDPforMDPs[9].4.1\n",
      "CaseRepresentationandExtendedADDs\n",
      "ThepreviousPowerPlantexamplesrepresentedallfunctionsincaseform,\n",
      "generallyas???:??1.f=..????:k\n",
      "f1...fk\n",
      "andthisistheformweusetorepresentallfunctionsinanH-POMDP.The?i\n",
      "aredisjointlogicalformulaeoverxs,dsand/orxo,dowithlogical(?,?,\n",
      "?)combinationsofbooleanvariablesandinequalities(?,>,?,<)overcontinuous\n",
      "variables.FordiscreteobservationH-POMDPs,theandinequalitiesmay\n",
      "useanyfunction(e.g.,sin(x1)>log(x2)?x3);forcontinuousobservations,\n",
      "theyarerestrictedtolinearinequalitiesandlinearorpiecewiseconstantas\n",
      "describedinSection2.Forunaryoperationssuchasscalarmultiplicationc?f\n",
      "(forsomeconstantc?R)ornegation?foncasestatementsissimplytoapply\n",
      "theoperationoneachcasepartition(1?i?k).Abinaryoperationontwo\n",
      "casestatements,takesthecross-productofthelogicalpartitionsofeachcase\n",
      "statementandperformsthecorrespondingoperationontheresultingpaired\n",
      "partitions.Thecross-sum?oftwocasesisasthefollowing:?((?1:f\n",
      "1?1:g1??2:f2?2:g2\n",
      "??1??1??????12=??2??1??????22\n",
      "::::\n",
      "f1+g1f1+g2f2+g1f2+g2\n",
      "Likewiseand?arebysubtractingormultiplyingpartitionvalues.\n",
      "Inconsistentpartitionscanbediscardedwhentheyareirrelevanttothefunction\n",
      "?value.Asymboliccasemaximizationisasbelow:??1??1?f1>g1\n",
      ":f1(casemax\n",
      "?1:f1,?2:f2\n",
      "(\n",
      "?1:g1?2:g2\n",
      "!\n",
      "???????1?f1?g1:g1??1=?1??2?f1>g2:f1???1??2\n",
      "?f1?g2:g2????..?....\n",
      "ThefollowingSDPoperationsoncasestatementsrequiremoredetailthan\n",
      "canbeprovidedhere,hencewereferthereadertotherelevantliterature:?\n",
      "Substitutionf?:Takesaset?ofvariablesandtheirsubstitutions(whichmay\n",
      "becasestatementsthemselves),andcarriesoutallvariablesubstitutions[9].R\n",
      "?Integrationx1fdx1:Therearetwoforms:Ifx1isinvolvedina?-function\n",
      "(cf.thetransitioninEq(3))thentheintegralisequivalenttoasymbolic\n",
      "substitutionandcanbeappliedtoanycasestatement(cf.[9]).Otherwise,iff\n",
      "7\n",
      "\n",
      "isinlinearlyconstrainedpolynomialcaseform,thentheapproachof[8]canbe\n",
      "appliedtoyieldaresultinthesameform.Caseoperationsyieldacombinatorial\n",
      "explosioninsizeifna??velyimplemented,henceweusethedatastructureofthe\n",
      "extendedalgebraicdecisiondiagram(XADD)[9]asshowninFigure1(right)\n",
      "tocompactlyrepresentcasestatementsandtlysupporttheabovecase\n",
      "operationswiththem.4.2\n",
      "VIforHybridStateandDiscreteObservations\n",
      "ForH-POMDPswithonlydiscreteobservationso?Oandobservation\n",
      "functionp(o|x0s,d0s,a)asintheformofEq(4),weintroduceasymbolic\n",
      "versionofMonahan?sVIalgorithm.Inbrief,wenotethatallVIoperations\n",
      "neededinSection3applydirectlytoH-POMDPs,e.g.,rewritingEq(8):Z\n",
      "hga,o,j(xs,ds)=\n",
      "\"Mxs0d\n",
      "s0\n",
      "p(o|x0s,d0s,a)?\n",
      "nO\n",
      "!p(d0si|xs,ds,a)\n",
      "i=1\n",
      "?\n",
      "mO\n",
      "!p(x0sj|xs,ds,d0s,a)\n",
      "#\n",
      "??jh?1(x0s,d0s)\n",
      "dxs0\n",
      "j=1\n",
      "(11)\n",
      "5\n",
      "Algorithm2:GenRelObs(?h?1,a,bi)??hOh,p(Oh|x0s,d0s,a)i123\n",
      "4567891011121314\n",
      "beginforeach?j(x0s,d0s)??h?1anda?Ado//Performexact1-\n",
      "stepRDPLbackupof?-functionsathorizonh?10000000?ja(xs,ds,\n",
      "xo,do):=x0d0sp(xo,do|xs,ds,a)?p(xs,ds|xs,ds,a)??j(xs,ds)\n",
      "dxssaforeach?j(xs,ds,xo,do)do//Generatevalueeach?-vectoratbelief\n",
      "pointbi(xs,ds)asafunctionofobservationsRofL?ja(xo,do):=xsdsbi\n",
      "(xs,ds)??ja(xs,ds,xo,do)dxs//Usingcasemax,generateobservation\n",
      "partitionsrelevanttoeachpolicy?seetextfordetailsOh:=extract-partition-\n",
      "constraints[casemax(?1a1(xo,do),?1a2(xo,do),...,?jar(xo,do))]foreach\n",
      "ok?Ohdo//Let?okbethepartitionconstraintsforobservationok?OhR\n",
      "Lp(Oh=ok|x0s,d0s,a):=xodop(xo,do|x0s,d0s,a)I[?ok]dxoreturn\n",
      "hOh,p(Oh|x0s,d0s,a)iend\n",
      "P(ts)\n",
      "(to)P(o)=0.0127\n",
      "b1\n",
      "0.250.2\n",
      "b\n",
      "7.50.10\n",
      "8\n",
      "\n",
      "2\n",
      "2\n",
      "P(o)=0.9831\n",
      "close\n",
      "-72.5-75\n",
      "2\n",
      "6\n",
      "ts\n",
      "open\n",
      "4\n",
      "11\n",
      "55.1\n",
      "8\n",
      "to\n",
      "1415\n",
      "18\n",
      "Figure2:(left)Beliefsb1,b2forCont.1D-PowerPlant;(right)derived\n",
      "observationpartitionsforb2ath=2.\n",
      "Cruciallywenotesincethecontinuoustransitioncpfsp(x0sj|xs,ds,d0s,a)\n",
      "aredeterministicandhenceRwithDirac??s(e.g.,Eq3)asdescribed\n",
      "inSection2,theintegralx0canalwaysbecomputedsinclosedcaseform\n",
      "asdiscussedinSection4.1.Inshort,nothingadditionalisrequiredforPBVI\n",
      "onH-POMDPsinthiscase?thekeyinsightissimplythat?-functionsare\n",
      "nowrepresentedbycasestatementsandcan?grow?withthehorizonasthey\n",
      "partitionthestatespacemoreandmore.4.3\n",
      "PBVIforHybridStateandHybridObservations\n",
      "Ingeneral,itwouldbeimpossibletoapplystandardVItoH-POMDPswith\n",
      "continuousobservationssincethenumberofobservationsisHowever,\n",
      "buildingonideasin[2],inthecaseofPBVI,itispossibletoderivea\n",
      "setofcontinuousobservationpartitionsthatpermitexactpoint-basedbackups\n",
      "atabeliefpoint.Thisadditionaloperation(GenRelObs)appearsonline10\n",
      "ofPBVIinAlgorithm1inthecaseofcontinuousobservationsandisformally\n",
      "inAlgorithm2.Todemonstratethegenerationofrelevantcontinuous\n",
      "observationpartitions,weusetheseconditerationoftheCont.Obs.1D-Power\n",
      "Plantalongwithtwobeliefpointsrepresentedasuniformdistributions:b1:U\n",
      "(ts;2,6)andb2:U(ts;6,11)asshowninFigure2(left).Lettingh=2,we\n",
      "willassumesimplyforexpositorypurposesthat|?1|=1(i.e.,itcontains\n",
      "onlyone?-function)andthatinlines2?4ofAlgorithm2wehavecomputedthe\n",
      "followingtwo?-functionsfora?\n",
      "f\n",
      "open,close\n",
      "g\n",
      ":?(??(ts<15)?(ts?10<to<\n",
      "ts):10(ts?10<to<ts):0.1openclose?1(ts,to)=(ts?15)?(ts?10<to\n",
      "<ts):?100?1(ts,to)=??(ts?10<to<ts):0??(t?10<t<t):0sos\n",
      "Wenowneedthe?-vectorsasafunctionoftheobservationspacefora\n",
      "particularbeliefstate,thusnextwemarginalizeoutxs,dsinlines5?7.The\n",
      "resulting?-functionsareshownasfollowswhereforbrevityfromthispoint\n",
      "forward,0partitionsaresuppressedinthecases:6\n",
      "???(14<to<18)?1close(to)=(8<to<14)??(4<t<8)o\n",
      "9\n",
      "\n",
      "???(15<to<18)????(14<to<15)open?1(to)=(8<to<14)???(5\n",
      "<to<8)???(4<to<5)\n",
      ":0.025to?0.45:?0.1:?0.025to?0.1\n",
      ":25to?450:?2.5to?37.5:?72.5:?25to+127.5:2.5to?10\n",
      "Both?1close(to)and?1open(to)aredrawngraphicallyinFigure2(right).\n",
      "Theseobservationdependent??sdividetheobservationspaceintoregionswhich\n",
      "canyieldtheoptimalpolicyaccordingtothebeliefstateb2.Following[2],\n",
      "weneedtotheoptimalboundariesorpartitionsoftheobservationspace;\n",
      "intheirwork,numericalsolutionsareproposedtotheseboundariesinone\n",
      "dimension(multipleobservationsarehandledthroughanindependenceassump-\n",
      "tion).Instead,hereweleveragethesymbolicpowerofthecasemaxoperator\n",
      "inSection4.1toallthepartitionswhereeachpotentiallycorrelated,\n",
      "multivariateobservation?isoptimal.Forthetwo??sabove,thefollowingpar-\n",
      "titionsoftheobservationspacearederivedbythecasemaxoperatorinline9:\n",
      "??o1???o?1\n",
      "?casemax?1close(to),?1open(to)=o1???o2???o2\n",
      ":(14<to?18):0.025to?0.45:(8<to?14):?0.1:(5.1<to?8):\n",
      "?0.025to?0.1:(5<to?5.1):?25to+127.5:(4<to?5):2.5to?10\n",
      "Herewehavelabeledwitho1theobservationswhere?1closeismaximal\n",
      "andwitho2theobservationswhere?1openismaximal.Whatwereallycare\n",
      "aboutthougharejusttheconstraintsidentifyingo1ando2andthisisthe\n",
      "taskofextract-partition-constraintsinline9.Thiswouldassociatewitho1the\n",
      "partitionconstraint?o1?(5.1<to?8)?(8<to?14)?(14<to?18)\n",
      "andwitho2thepartitionconstraint?o2?(4<to?5)?(5<to?5.1)?\n",
      "takingintoaccountthe0partitionsandthe1Dnatureofthisexample,wecan\n",
      "furthersimplify?o1?(to>5.1)and?o2?(to?5.1).Giventheserelevant\n",
      "observationpartitons,ourtaskinlines10-12istocomputetheprobabilities\n",
      "ofeachobservationpartition?ok.Thisissimplydonebymarginalizingover\n",
      "theobservationfunctionp(Oh|x0s,d0s,a)withineachregionby?ok\n",
      "(achievedbymultiplyingbyanindicatorfunctionI[?ok]overtheseconstraints).\n",
      "Tobetterunderstandwhatiscomputedhere,wecancomputetheprobability\n",
      "p(ok|bi,a)ofeachobservationforaparticularbelief,calculatedasfollows:\n",
      "Z\n",
      "Z\n",
      "MM\n",
      "p(ok|bi,a):=xs\n",
      "x0sds\n",
      "p(ok|x0s,d0s,a)?p(x0s,d0s|xs,ds,a)??j(x0s,d0s)?bi(xs,ds)dx0s\n",
      "dxs(12)\n",
      "d0s\n",
      "Sp,forb2,weobtainp(o1|b2,a=close)=0.0127andp(o2|b2\n",
      ",a=close)=0.933asshowninFigure2(right).Insummary,inthissection\n",
      "wehaveshownhowwecanextendtheexactdynamicprogrammingalgorithm\n",
      "forthecontinuousstate,discreteobservationPOMDPsettingfromSection4.2\n",
      "tocomputeexact1-steppoint-basedbackupsinthecontinuousobservationset-\n",
      "ting;thiswasaccomplishedthroughthecrucialinsightthatdespitethe\n",
      "10\n",
      "\n",
      "numberofobservations,usingAlgorithm2wecansymbolicallyderiveasetof\n",
      "relevantobservationsforeachbeliefpointthatdistinguishtheoptimalpolicy\n",
      "andhencevalueasgraphicallyillustratedinFigure2(right).Nextwepresent\n",
      "someempiricalresultsfor1-and2-dimensionalcontinuousstateandobservation\n",
      "spaces.\n",
      "5\n",
      "EmpiricalResults\n",
      "WeevaluatedourcontinuousPOMDPsolutionusingXADDsonthe1D-\n",
      "PowerPlantexampleandanothervariantofthisproblemwithtwovariables,\n",
      "describedbelow.32D-PowerPlant:Weconsiderthemorecomplexmodelof\n",
      "thepowerplantsimilarto[1]wherethepressureinsidethewatertankmust\n",
      "becontrolledtoavoidmixingwaterintothesteam(leadingtoexplosionof\n",
      "thetank).Wemodelanobservablepressurereadingpoasafunctionofthe\n",
      "underlyingpressurestateps.Againwehavetwoactionsforopeningand\n",
      "closingapressurevalve.Thecloseactionhastransition\"p(p0s|ps,a\n",
      "=close)=?\n",
      "(p0s\n",
      "?\n",
      "(p+10>20):20?(p+10>20):ps+10\n",
      "#\n",
      "p(t0s|ts,a=close)=?t0s?(ts+10)\n",
      "3FullproblemspandJavacodetoreproducetheseexperiments\n",
      "areavailableonlineinGoogleCode:http://code.google.com/p/cpomdp.\n",
      "7\n",
      "PowerPlant\n",
      "5\n",
      "PowerPlant\n",
      "10\n",
      "NumberofNodes\n",
      "Time(ms)\n",
      "1state&1observvar2state&2observvars4\n",
      "10\n",
      "3\n",
      "10\n",
      "2\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "70\n",
      "1state&1observvar2state&2observvars\n",
      "60\n",
      "50\n",
      "11\n",
      "\n",
      "40\n",
      "30\n",
      "20\n",
      "10\n",
      "01\n",
      "Horizon\n",
      "2\n",
      "3\n",
      "4\n",
      "Horizon\n",
      "5\n",
      "6\n",
      "Figure3:(left)timevs.horizon,and(right)space(total#XADDnodes\n",
      "in?-functions)vs.horizon.andyieldshighrewardforstayingwithin?thesafe\n",
      "temperatureandpressurerange:?(5?ps?15)?(95?ts?105):50???(5\n",
      "?p?15)?(t?95):?1ssR(ts,ps,a=close)=?(ps?15):?5???else:\n",
      "?3\n",
      "Alternately,fortheopenaction,thetransitionfunctionsreducethetem-\n",
      "peratureby5unitsandthepressureby10unitsaslongasthepressurestays\n",
      "abovezero.Fortheopenrewardfunction,weassumethatthereisalwaysa\n",
      "smallconstantpenalty(-1)sincenoelectricityisproduced.Observationsare\n",
      "distributeduniformlywithinaregiondependingontheirunderlyingstate:p(to\n",
      "|t0s)\n",
      "((ts+80<to<ts+105)=?(ts+80<to<ts+105)\n",
      ":0.04:0\n",
      "p(po|p0s)\n",
      "((ps<po<ps+10):0.1=?(ps<po<ps+10):0\n",
      "FinallyforPBVI,wetwouniformbeliefsasfollows:b1:U[ts;90,\n",
      "100]?U[ps;0,10]andb2:U[ts;90,130]?U[ps;10,30]InFigure3,atime\n",
      "andspaceanalysisofthetwoversionsofPowerPlanthavebeenperformedfor\n",
      "uptohorizonh=6.Thisexperimentalevaluationreliesononeadditionalap-\n",
      "proximationoverthePBVIapproachofAlgorithm1inthatitsubstitutesp(Oh\n",
      "|b,a)inplaceofp(Oh|x0s,d0s,a)?whilethisyieldscorrectobservation\n",
      "probabilitiesforapoint-basedbackupataparticularbeliefstateb,theresulting\n",
      "?-functionsrepresentanapproximationforotherbeliefstates.Ingeneral,the\n",
      "PBVIframeworkinthispaperdoesnotrequirethisapproximation,although\n",
      "whenappropriate,usingitshouldincreasecomputational.Figure3\n",
      "showsthatthecomputationtimerequiredperiterationgenerallyincreasessince\n",
      "morecomplex?-functionsleadtoalargernumberofobservationpartitionsand\n",
      "thusamoreexpensivebackupoperation.Whileanorderofmagnitudemore\n",
      "timeisrequiredtodoublethenumberofstateandobservationvariables,onecan\n",
      "seethatthePBVIapproachleadstoafairlyconstantamountofcomputation\n",
      "timeperhorizon,whichindicatesthatlonghorizonsshouldbecomputablefor\n",
      "anyproblemforwhichatleastonehorizoncanbecomputedinanacceptable\n",
      "amountoftime.\n",
      "6\n",
      "12\n",
      "\n",
      "Conclusion\n",
      "WepresentedtheexactsymbolicoperationsforPBVIinanexpressive\n",
      "subsetofH-POMDPswithcontinuousstateandobservations.Unlikerelated\n",
      "workthathasextendedtothecontinuousstateandobservationsetting[6],we\n",
      "donotapproachtheproblembysampling.Rather,following[2],thekeycontri-\n",
      "butionofthisworkwastoadiscretesetofobservationpartitionsonthe\n",
      "multivariatecontinuousobservationspaceviasymbolicmaximizationtechniques\n",
      "andderivetherelatedprobabilitiesusingsymbolicintegration.Animportant\n",
      "avenueforfutureworkistoextendthesetechniquestothecaseofcontinuous\n",
      "state,observation,andactionH-POMDPs.AcknowledgmentsNICTAisfunded\n",
      "bytheAustralianGovernmentasrepresentedbytheDepartmentofBroadband,\n",
      "CommunicationsandtheDigitalEconomyandtheARCthroughtheICTCentre\n",
      "ofExcellenceprogram.ThisworkwassupportedbytheFraunhoferATTRACT\n",
      "fellowshipSTREAMandbytheEC,FP7-248258-First-MM.\n",
      "8\n",
      "2References\n",
      "[1]MarioAguedaandPabloIbarguengoytia.Anarchitectureforplanninginun-\n",
      "certaindomains.InProceedingsoftheICTAI2002Conference,Dallas,Texas,\n",
      "2002.[2]JesseHoeyandPascalPoupart.Solvingpomdpswithcontinuous\n",
      "orlargediscreteobservationspaces.InProceedingsoftheInternationalJoint\n",
      "ConferenceonIntelligence(IJCAI),Edinburgh,Scotland,2005.[3]\n",
      "LeslieP.Kaelbling,MichaelL.Littman,andAnthonyR.Cassandra.Plan-\n",
      "ningandactinginpartiallyobservablestochasticdomains.Intelli-\n",
      "gence,101:99?134,1998.[4]G.E.Monahan.Surveyofpartiallyobservable\n",
      "markovdecisionprocesses:Theory,models,andalgorithms.ManagementSci-\n",
      "ence,28(1):1?16,1982.[5]JoellePineau,J.Gordon,andSebastian\n",
      "Thrun.Anytimepoint-basedapproximationsforlargepomdps.J.Artif.In-\n",
      "tell.Res.(JAIR),27:335?380,2006.[6]J.M.Porta,N.Vlassis,M.T.J.Spaan,\n",
      "andP.Poupart.Point-basedvalueiterationforcontinuouspomdps.Journal\n",
      "ofMachineLearningResearch,7:195220,2006.[7]PascalPoupart,Kee-Eung\n",
      "Kim,andDonghoKim.Closingthegap:Improvedboundsonoptimalpomdp\n",
      "solutions.InInProceedingsofthe21stInternationalConferenceonAutomated\n",
      "PlanningandScheduling(ICAPS-11),2011.[8]ScottSannerandEhsanAb-\n",
      "basnejad.Symbolicvariableeliminationfordiscreteandcontinuousgraphical\n",
      "models.InInProceedingsofthe26thAAAIConferenceonIntelli-\n",
      "gence(AAAI-12),Toronto,Canada,2012.[9]ScottSanner,KarinaValdivia\n",
      "Delgado,andLelianeNunesdeBarros.Symbolicdynamicprogrammingfor\n",
      "discreteandcontinuousstatemdps.InProceedingsofthe27thConferenceon\n",
      "UncertaintyinAI(UAI-2011),Barcelona,2011.[10]TreySmithandReidG.\n",
      "Simmons.Point-basedPOMDPalgorithms:Improvedanalysisandimplemen-\n",
      "tation.InProc.Int.Conf.onUncertaintyinIntelligence(UAI),\n",
      "2005.[11]M.SpaanandN.Vlassis.Perseus:Randomizedpoint-basedvalue\n",
      "iterationforpomdps.JournalofArticialIntelligenceResearch(JAIR),page\n",
      "13\n",
      "\n",
      "195220,2005.\n",
      "9\n",
      "14\n",
      "\n",
      "PP3367.pdf\n",
      "PP3367.pdf 12\n",
      "TheDistributionFamilyofSimilarityDistances\n",
      "Authoredby:\n",
      "GertjanBurghouts\n",
      "ArnoldSmeulders\n",
      "Jan-markGeusebroek\n",
      "Abstract\n",
      "Assessingsimilaritybetweenfeaturesisakeystepinobjectrecognition\n",
      "andscenecategorizationtasks.Wearguethatknowledgeonthedistribu-\n",
      "tionofdistancesgeneratedbysimilarityfunctionsiscrucialindeciding\n",
      "whetherfeaturesaresimilarornot.Intuitivelyonewouldexpectthat\n",
      "similaritiesbetweenfeaturescouldarisefromanydistribution.Inthis\n",
      "paper,wewillderivethecontrary,andreportthetheoreticalresultthat\n",
      "$L\n",
      "p$-norms{aclassofcommonlyapplieddistancemetrics{fromonefea-\n",
      "turevectortoothervectorsareWeibull-distributedifthefeaturevalues\n",
      "arecorrelatedandnon-identicallydistributed.Besidestheseassumptions\n",
      "beingrealisticforimages,weexperimentallyshowthemtoholdforvari-\n",
      "ouspopularfeatureextractionalgorithms,foradiverserangeofimages.\n",
      "Thisfundamentalinsightopensnewdirectionsintheassessmentoffeature\n",
      "similarity,withprojectedimprovementsinobjectandscenerecognition\n",
      "algorithms.\n",
      "Erratum:Theauthorsofpaperhavedeclaredthattheyhavebecome\n",
      "convincedthatthereasoninginthereferenceistoosimpleasaproofof\n",
      "theirclaims.Asaconsequence,theywithdrawtheirtheorems.\n",
      "1PaperBody\n",
      "Assessingsimilaritybetweenfeaturesisakeystepinobjectrecognitionand\n",
      "scenecategorizationtasks.Wearguethatknowledgeonthedistributionof\n",
      "distancesgeneratedbysimilarityfunctionsiscrucialindecidingwhetherfea-\n",
      "turesaresimilarornot.Intuitivelyonewouldexpectthatsimilaritiesbetween\n",
      "featurescouldarisefromanydistribution.Inthispaper,wewillderivethe\n",
      "contrary,andreportthetheoreticalresultthatLp-norms?aclassofcommonly\n",
      "applieddistancemetrics?fromonefeaturevectortoothervectorsareWeibull-\n",
      "distributedifthefeaturevaluesarecorrelatedandnon-identicallydistributed.\n",
      "Besidestheseassumptionsbeingrealisticforimages,weexperimentallyshow\n",
      "themtoholdforvariouspopularfeatureextractionalgorithms,foradiverse\n",
      "rangeofimages.Thisfundamentalinsightopensnewdirectionsintheassess-\n",
      "1\n",
      "\n",
      "mentoffeaturesimilarity,withprojectedimprovementsinobjectandscene\n",
      "recognitionalgorithms.\n",
      "1\n",
      "Introduction\n",
      "Measurementofsimilarityisacriticalassetofstateoftheartincomputer\n",
      "vision.Inallthreemajorstreamsofcurrentresearch-therecognitionofknown\n",
      "objects[13],assigninganobjecttoaclass[8,24],orassigningascenetoatype\n",
      "[6,25]-theproblemistransposedintotheequalityoffeaturesderivedfromsim-\n",
      "ilarityfunctions.Hence,besidestheissueoffeaturedistinctiveness,comparing\n",
      "twoimagesheavilyreliesonsuchsimilarityfunctions.Wearguethatknowledge\n",
      "onthedistributionofdistancesgeneratedbysuchsimilarityfunctionsiseven\n",
      "moreimportant,asitisthatknowledgewhichiscrucialindecidingwhetherfea-\n",
      "turesaresimilarornot.Forexample,NowakandJurie[21]establishwhether\n",
      "onecandrawconclusionsontwoneverseenobjectsbasedonthesimilaritydis-\n",
      "tancesfromknownobjects.Wheretheybuildandtraversearandomizedtree\n",
      "toestablishregioncorrespondence,onecouldalternativelyusethedistribution\n",
      "ofsimilaritydistancestoestablishwhetherfeaturescomefromthemodeorthe\n",
      "tailofthedistribution.Althoughthisindeedonlyhintsatanalgorithm,itis\n",
      "likelythatknowledgeofthedistancedistributionwillconsiderablyimproveor\n",
      "speed-upsuchtasks.Asasecondexample,considertheclusteringoffeatures\n",
      "basedontheirdistances.Betterclusteringalgorithmscantlyboostperfor-\n",
      "manceforobjectandscenecategorization[12].Knowledgeonthedistribution\n",
      "ofdistancesaidsintheconstructionofgoodclusteringalgorithms.Usingthis\n",
      "knowledgeallowsfortheexactdistributionshapetobeusedtodetermineclus-\n",
      "tersizeandcentroid,wherenowtheGaussianisoftengroundlesslyassumed.\n",
      "Wewillshowthatingeneraldistancedistributionswillstronglydeviatefrom\n",
      "theGaussianprobabilitydistribution.Athirdexampleisfromobjectandscene\n",
      "recognition.Usuallythisisdonebymeasuringinvariantfeaturesets[9,13,24]\n",
      "atarasterofregionsintheimageoratselectedkeypointsinthe\n",
      "image[11,13]asextensivelyevaluated[17].Typically,animagecontainsa\n",
      "hundredregionsora??\n",
      "Dr.BurghoutsisnowwithTNODefense,TheNetherlands,gertjan.burghouts@tno.nl.\n",
      "Correspondingauthor.Email:mark@science.uva.nl.\n",
      "1\n",
      "thousandkeypoints.Then,themostexpensivecomputationalstepisto\n",
      "comparethesefeaturesetstothefeaturesetsofthereferenceobjects,object\n",
      "classesorscenetypes.Usuallythisisdonebygoingoverallentriesintheimage\n",
      "toallentriesinthereferencesetandselectthebestmatchingpair.Knowledge\n",
      "ofthedistributionofsimilaritydistancesandhavingestablisheditsparameters\n",
      "enablesaremarkablespeed-upinthesearchformatchingreferencepointsand\n",
      "henceformatchingimages.Whenverifyingthatagivenreferencekey-point\n",
      "orregionisstatisticallyunlikelytooccurinthisimage,onecanmoveonto\n",
      "searchinthenextimage.Furthermore,thisknowledgecanwellbeappliedin\n",
      "theconstructionoffastsearchtrees,seee.g.[16].Hence,apartfromobtaining\n",
      "theoreticalinsightsinthegeneraldistributionofsimilarities,theresultsderived\n",
      "inthispaperaredirectlyapplicableinobjectandscenerecognition.Intuitively\n",
      "2\n",
      "\n",
      "onewouldexpectthatthesetofallsimilarityvaluestoakey-pointorregion\n",
      "inanimagewouldassumeanydistribution.Onewouldexpectthatthereisno\n",
      "preferredprobabilitydensitydistributionatstakeinmeasuringthesimilarities\n",
      "topointsorregionsinoneimage.Inthispaper,wewillderivethecontrary.We\n",
      "willprovethatunderbroadconditionsthesimilarityvaluestoagivenreference\n",
      "pointorregionadheretoaclassofdistributionsknownastheWeibulldistribu-\n",
      "tionfamily.Thedensityfunctionhasonlythreeparameters:mean,standard\n",
      "deviationandskewness.Wewillverifyexperimentallythattheconditionsun-\n",
      "derwhichthisresultfrommathematicalstatisticsholdsarepresentincommon\n",
      "setsofimages.Itappearsthetheorypredictstheresultingdensityfunctions\n",
      "accurately.Ourworkondensitydistributionsofsimilarityvaluescomparesto\n",
      "theworkbyPekalskaandDuin[23]assumingaGaussiandistributionforsim-\n",
      "ilarities.Itisbasedonanoriginalcombinationoftwofactsfromstatistical\n",
      "physics.Anoldfactregardsthestatisticsofextremevalues[10],asgenerated\n",
      "whenconsideringtheminimaandmaximaofmanymeasurements.Themajor\n",
      "resultoftheofextremevaluestatisticsisthattheprobabilitydensityin\n",
      "thiscasecanonlybeoneoutofthreettypes,independentoftheun-\n",
      "derlyingdataorprocess.Thesecondfactisanewresult,whichlinksthese\n",
      "extremevaluestatisticstosumsofcorrelatedvariables[2,3].Weexploitthese\n",
      "twofactsinordertoderivethedistributionfamilyofsimilaritymeasures.This\n",
      "paperisstructuredasfollows.InSection2,weoverviewliteratureonsimilarity\n",
      "distancesanddistancedistributions.InSection3,wediscussthetheoryofdis-\n",
      "tributionsofsimilaritydistancesfromonetootherfeaturevectors.InSection4,\n",
      "wevalidatetheresultingdistributionexperimentallyforimagefeaturevectors.\n",
      "Finally,conclusionsaregiveninSection5.\n",
      "22.1\n",
      "RelatedworkSimilaritydistancemeasures\n",
      "Tomeasurethesimilaritybetweentwofeaturevectors,manydistancemea-\n",
      "sureshavebeenproposed[15].AcommonmetricclassofmeasuresistheLp\n",
      "-norm[1].Thedistancefromonereferencefeaturevectorstooneotherfeature\n",
      "vectortcanbeformalizedas:nXd(s,t)=(|si?ti|p)1/p,\n",
      "(1)\n",
      "i=1\n",
      "wherenandiarethedimensionalityandindicesofthevectors.Letthe\n",
      "randomvariableDprepresentdistancesd(s,t)wheretisdrawnfromtherandom\n",
      "variableTrepresentingfeaturevectors.Independentofthereferencefeature\n",
      "vectors,theprobabilitydensityfunctionofLp-distanceswillbedenotedbyf\n",
      "(Dp=d).2.2\n",
      "Distancedistributions\n",
      "Ferenczetal.[7]haveconsideredtheGammadistributiontomodeltheL2\n",
      "-distancesfromimage1d??1e?d/?,where?istheshapeparameter,regions\n",
      "toonereferenceregion:f(D2=d)=???(?)and?thescaleparameter;?(?)\n",
      "denotestheGammafunction.In[7],thedistancefunctionwastly\n",
      "fromfewexamplesofimageregions.Althoughthedistributionwereshown\n",
      "torepresenttheregiondistancestosomeextent,themethodlacksatheoretical\n",
      "motivation.2\n",
      "3\n",
      "\n",
      "Basedonthecentrallimittheorem,PekalskaandDuin[23]assumedthat\n",
      "Lp-distancesbetween221featurevectorsarenormallydistributed:f(Dp=\n",
      "d)=?2?e?(d/?)/2.Astheauthorsargue,?theuseofthecentrallimit\n",
      "theoremistheoreticallyifthefeaturevaluesareindependent,identi-\n",
      "callydistributed,andhavelimitedvariance.Althoughfeaturevaluesgenerally\n",
      "havelimitedvariance,unfortunately,theycannotbeassumedtobeindepen-\n",
      "dentand/oridenticallydistributedaswewillshowbelow.Hence,analternative\n",
      "derivationofthedistancedistributionfunctionhastobefollowed.2.3\n",
      "Contributionofthispaper\n",
      "Ourcontributionisthetheoreticalderivationofaparameterizeddistribution\n",
      "forLp-normdistancesbetweenfeaturevectors.Intheexperiments,weestablish\n",
      "whetherdistancestoimagefeaturesadheretothisdistributionindeed.We\n",
      "considerSIFT-basedfeatures[17],computedfromvariousinterestregiontypes\n",
      "[18].\n",
      "3\n",
      "Statisticsofdistancesbetweenfeatures\n",
      "Inthissection,wederivethedistributionfunctionfamilyofLp-distances\n",
      "fromareferencefeaturevectortootherfeaturevectors.Weconsiderthenotation\n",
      "asusedintheprevioussection,withtafeaturevectordrawnfromtherandom\n",
      "variableT.Foreachvectort,weconsiderthevalueatindexi,ti,resultingin\n",
      "arandomvariableTi.Thevalueofthereferencevectoratindexi,si,canbe\n",
      "interpretedasasampleoftherandomvariableTi.Thecomputationofdistances\n",
      "fromonetoothervectorsinvolvesmanipulationsoftherandomvariableTi\n",
      "resultinginanewrandomvariable:Xi=|si?Ti|p.Furthermore,the\n",
      "computationofthedistancesDrequiresthesummationofrandomPIvariables,\n",
      "andareparameterization:D=(i=1Xi)1/p.Inordertoderivethedistribution\n",
      "ofD,westartwiththestatisticsofthesummationofrandomvariables,before\n",
      "turningtothepropertiesofXi.3.1\n",
      "Statisticsofsums\n",
      "AsastartingpointtoderivetheLp-distancedistributionfunction,wecon-\n",
      "sideralemmafromstatisticsaboutthesumofrandomvariables.PNLemma\n",
      "1Fornon-identicalandcorrelatedrandomvariablesXi,thesumi=1Xi,with\n",
      "N,isdistributedaccordingtothegeneralizedextremevaluedistribution,\n",
      "i.e.theGumbel,FrechetorWeibulldistribution.Foraproof,see[2,3].Note\n",
      "thatthelemmaisanextensionofthecentrallimittheoremtononidentically\n",
      "distributedrandomvariables.And,indeed,theprooffollowsthepathofthe\n",
      "centrallimittheorem.Hence,theresultingdistributionofsumsistfrom\n",
      "anormaldistribution,andratheroneoftheGumbel,FrechetorWeibulldistri-\n",
      "butionsinstead.Thislemmaisimportantforourpurposes,aslaterthefeature\n",
      "valueswillturnouttobenon-identicalandcorrelatedindeed.Tothe\n",
      "distributionfunctionfurther,wealsoneedthefollowinglemma.Lemma2If\n",
      "intheabovelemmatherandomvariableXiareupper-bounded,i.e.Xi<max,\n",
      "thesumofthevariablesisWeibulldistributed(andnotGumbelnorFrechet):\n",
      "y??y(2)f(Y=y)=()??1e?(?),??with?theshapeparameterand\n",
      "?thescaleparameter.Foraproof,see[10].Figure1illustratestheWeibull\n",
      "distributionforvariousshapeparameters?.Thislemmaisequallyimportant\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toourpurpose,aslaterthefeaturevalueswillturnouttobeupper-bounded\n",
      "indeed.ThecombinationofLemmas1and2yieldsthedistributionofsumsof\n",
      "non-identical,correlatedandupper-boundedrandomvariables,summarizedin\n",
      "thefollowingtheorem.3\n",
      "pshapeparameter\n",
      "0.8\n",
      "?=2\n",
      "0.6\n",
      "?=4?=6?=8\n",
      "0.4\n",
      "0.2\n",
      "distance1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Figure1:ExamplesoftheWeibulldistributionforvariousshapeparameters\n",
      "?.\n",
      "Theorem1Fornon-identical,correlatedandupper-boundedrandomvari-\n",
      "ablesXi,therandomPNvariableY=i=1Xi,withN,adherestothe\n",
      "Weibulldistribution.Theprooffollowstriviallyfromcombiningthet\n",
      "ofstatisticsaslaiddowninLemmas1and2.Theorem1isthestarting\n",
      "pointtoderivethedistributionofLp-normsfromonereferencevectortoother\n",
      "featurevectors.3.2\n",
      "Lp-distancesfromonetootherfeaturevectors\n",
      "Theorem1statesthatYisWeibull-distributed,giventhat\n",
      "f\n",
      "Xi=|si?\n",
      "Ti|p\n",
      "g\n",
      "i?[1,...,I]arenonidentical,correlatedandupper-boundedrandomvari-\n",
      "ables.WetransformYsuchthatitrepresentsLp-distances,achievedbythe\n",
      "transformation(?)1/p:NXY1/p=(|si?Ti|p)1/p.\n",
      "(3)\n",
      "i=1\n",
      "TheconsequenceofthesubstitutionZ=Y1/pforthedistributionofYis\n",
      "achangeofvariablesf(zp)z=y1/pinEquation2[22]:g(Z=z)=(1/p?1)z\n",
      "(1?p).ThistransformationyieldsatdistributionstilloftheWeibull\n",
      "type:g(Z=z)=\n",
      "zzp??1?(?1/p?1)p?()e,(1/p?1)?1/p?1/p\n",
      "(4)\n",
      "where??=p?isthenewshapeparameterand??=?1/pisthe\n",
      "newscaleparameter,respectively.Thus,alsoY1/pandhenceLp-distances\n",
      "areWeibull-distributedundertheassumedcase.Wearguethattherandom\n",
      "variablesXi=|si?Ti|pandXj(i6=j)areindeednon-identical,correlated\n",
      "andupper-boundedrandomvariableswhenconsideringasetofvaluesextracted\n",
      "fromfeaturevectorsatindicesiandj:?XiandXjareupper-bounded.Features\n",
      "areusuallyanabstractionofaparticulartypeofmeasurements,resulting\n",
      "inafeature.Hence,forgeneralfeaturevectors,thevaluesatindexi,Ti,\n",
      "areAnd,withp,itfollowstriviallythatXiis?XiandXj\n",
      "5\n",
      "\n",
      "arecorrelated.Theexperimentalvofthisassumptionispostponed\n",
      "toSection4.1.?XiandXjarenon-identicallydistributed.Theexperimental\n",
      "vofthisassumptionispostponedtoSection4.1.Wehaveobtained\n",
      "thefollowingresult.Corollary1Forfeaturevectorswithnon-\n",
      "identical,correlatedandupper-boundedvalues,Lpdistances,forlimitedp,\n",
      "fromonereferencefeaturevectortootherfeaturevectorsadheretotheWeibull\n",
      "distribution.4\n",
      "3.3\n",
      "Extendingtheclassoffeatures\n",
      "WeextendtheclassoffeaturesforwhichthedistancesareWeibull-distributed.\n",
      "Fromnowon,weallowthepossibilitythatthevectorsarepreprocessedbya\n",
      "PCAtransformation.WedenotethePCAtransformg(?)appliedtoasingle\n",
      "featurevectorass?=g(s).FortherandomvariableTi,weobtainTi?.We\n",
      "arestilldealingwithupper-boundedvariablesXi?=|s?i?Ti?|pasPCAis\n",
      "atransform.TheexperimentalvoftheassumptionthatPCA-\n",
      "transformedfeaturevaluesTi?andTj?,i6=jarenon-identicallydistributed\n",
      "ispostponedtoSection4.1.Ourpointhere,isthatwehaveassumedoriginally\n",
      "correlatingfeaturevalues,butafterthedecorrelatingPCAtransformweare\n",
      "nolongerdealingwithcorrelatedfeaturevaluesTi?andTj?.InSection4.1,\n",
      "wewillverifyexperimentallywhetherXi?andXj?correlate.Thefollowing\n",
      "observationishypothesized.PCAtranslatesthedatatotheorigin,beforeap-\n",
      "plyingantransformationthatyieldsdatadistributedalongorthogonal\n",
      "axes.Thetuples(Xi?,Xj?)willbeinthequadrantduetotheabsolute\n",
      "valuetransformation.Obviously,variances?(Xi?)and?(Xj?)arelimited\n",
      "andmeans?(Xi?)>0and?(Xj?)>0.Fordataconstrainedtothequad-\n",
      "rantanddistributedalongorthogonalaxes,anegativecovarianceisexpected\n",
      "tobeobserved.Undertheassumedcase,wehaveobtainedthefollowingresult.\n",
      "Corollary2Forfeaturevectorswithnon-identical,correlatedand\n",
      "upper-boundedvalues,andforPCA-transformationsthereof,Lpdistances,for\n",
      "limitedp,fromonetootherfeaturesadheretotheWeibulldistribution.3.4\n",
      "Heterogeneousfeaturevectordata\n",
      "Weextendthecorollarytoholdalsoforcompositedatasetsoffeaturevectors.\n",
      "Considerthecompositedatasetmodelledbyrandomvariables\n",
      "f\n",
      "Tt\n",
      "g\n",
      ",where\n",
      "eachrandomvariableTtrepresentsnonidenticalandcorrelatedfeaturevalues.\n",
      "Hence,fromCorollary2itfollowsthatfeaturevectorsfromeachoftheTtcan\n",
      "bebyaWeibullfunctionf?,?(d).However,thedistancestoeachofthe\n",
      "Ttmayhaveatrangeandmodus,aswewillverifybyexperimentation\n",
      "inSection4.1.Forheterogeneousdistancedata\n",
      "f\n",
      "Tt\n",
      "g\n",
      ",weobtainamixtureof\n",
      "Weibullfunctions[14].Corollary3(Distancedistribution)Forfeaturevectors\n",
      "thataredrawnfromamixtureofdatasets,ofwhicheachresultsinnon-identical\n",
      "andcorrelatedfeaturevalues,featurevectorswithnon-identical,\n",
      "correlatedandupper-boundedvalues,andforPCA-transformationsthereof,Lp\n",
      "distances,forlimitedp,fromonereferencefeaturevectortootherfeaturevectors\n",
      "adheretothePcWeibullmixturedistribution:f(D=d)=Pi=1?i?,?i\n",
      "(d),wherearetheWeibullfunctionscand?iaretheirrespectiveweightssuch\n",
      "thati=1?i=1.\n",
      "6\n",
      "\n",
      "4\n",
      "Experiments\n",
      "Inourexperiments,wevalidateassumptionsandWeibullgoodness-of-tfor\n",
      "theregion-basedSIFT,GLOH,SPIN,andPCA-SIFTfeaturesonCORELdata\n",
      "[5].Weincludethesefeaturesfortworeasonsas:a)theyareperformingwell\n",
      "forrealisticcomputervisiontasksandb)theyprovidetmechanismsto\n",
      "describeanimageregion[17].Theregionfeaturesarecomputedfromregions\n",
      "detectedbytheHarris-andregions,maximallystableregions\n",
      "(MSER),andintensityextrema-basedregions(IBR)[18].Also,weconsider\n",
      "PCA-transformedversionsforeachofthedetector/featurecombinations.For\n",
      "reasonofitsextensiveuse,theexperimentationisbasedontheL2-distance.\n",
      "Weconsiderdistancesfrom1randomlydrawnreferencevectorto100other\n",
      "randomlydrawnfeaturevectors,whichwerepeat1,000timesforgeneralization.\n",
      "Inallexperiments,thefeaturesaretakenfrommultipleimages,exceptforthe\n",
      "illustrationinSection4.1.2toshowtypicaldistributionsofdistancesbetween\n",
      "featurestakenfromsingleimages.4.14.1.1\n",
      "ValidationofthecorollaryassumptionsforimagefeaturesIntrinsicfeature\n",
      "assumptions\n",
      "Corollary2restsonafewexplicitassumptions.Herewewillverifywhether\n",
      "theassumptionsoccurinpractice.5\n",
      "betweenfeaturevaluesarecorrelated.Weconsiderasetoffea-\n",
      "turevectorsTjandtheatindexitoareferencevectors:Xi=|si?\n",
      "Tji|p.WedeterminetheofPearson?scorrelation[4]betweenthe\n",
      "valuesXiandXj,i6=j.Weestablishthepercentageoftly\n",
      "correlatingatalevelof0.05.Wereportforeachfeature\n",
      "theaveragepercentageofvaluesthatcorrelatetlywithdif-\n",
      "ferencevaluesatanotherfeaturevectorindex.Asexpected,thefeaturevalue\n",
      "correlate.ForSIFT,99%ofthevaluesaretly\n",
      "correlated.ForSPINandGLOH,weobtain98%and96%,respectively.Also\n",
      "PCASIFTcontainstlycorrelatingvalues:95%.Although\n",
      "thefeature?snamehintsatuncorrelatedvalues,itdoesnotachieveadecorrela-\n",
      "tionofthevaluesinpractice.Foreachofthefeatures,alowstandarddeviation\n",
      "<5%isfound.Thisexpressesthelowvariationofcorrelationsacrosstheran-\n",
      "domsamplingsandacrossthevariousregiontypes.Werepeattheexperiment\n",
      "forPCA-transformedfeaturevalues.Althoughtheresultingvaluesareuncor-\n",
      "relatedbyconstruction,theiraretlycorrelated.ForSIFT,\n",
      "SPIN,GLOH,andPCA-SIFT,thepercentagesoftlycorrelatingdif-\n",
      "ferencevaluesare:94%,86%,95%,and75%,respectively.between\n",
      "featurevaluesarenon-identicallydistributed.Werepeatthesameprocedure\n",
      "asabove,butinsteadofmeasuringtheofcorrelation,weestab-\n",
      "lishthepercentageoftlytlydistributeddierencevaluesXiby\n",
      "theWilcoxonranksumtest[4]ataencelevelof0.05.ForSIFT,SPIN,\n",
      "GLOH,andPCA-SIFT,thepercentagesoftlytlydistributed\n",
      "valuesare:99%,98%,92%,and87%.ForthePCA-transformedver-\n",
      "sionsofSIFT,SPIN,GLOH,andPCA-SIFT,we62%,40%,64%,and\n",
      "51%,respectively.Notethatinallcases,correlationisttotheas-\n",
      "7\n",
      "\n",
      "sumptionsofCorollary2.Wehaveillustratedthatfeaturevalueare\n",
      "tlycorrelatedandcantlynon-identicallydistributed.Wecon-\n",
      "cludethattheassumptionsofCorollary2aboutpropertiesoffeaturevectors\n",
      "arerealisticinpractice,andthatWeibullfunctionsareexpectedtodistance\n",
      "distributionswell.4.1.2\n",
      "Inter-featureassumptions\n",
      "InCorollary3,wehaveassumedthatdistancesfromonetootherfeature\n",
      "vectorsaredescribedwellbyamixtureofWeibulls,ifthefeaturesaretakenfrom\n",
      "tclustersinthedata.Here,weillustratethatclustersoffeaturevectors,\n",
      "andclustersofdistances,occurinpractice.Figure2ashowsregions\n",
      "fromanaturalscenewhicharedescribedbytheSIFTfeature.Thedistances\n",
      "aredescribedwellbyasingleWeibulldistribution.Thesameholdfordistances\n",
      "fromonetootherregionscomputedfromaman-madeobject,seeFigure2b.In\n",
      "Figure2c,weillustratethedistancesofonetootherregionscomputedfroma\n",
      "compositeimagecontainingtwotypesofregions.Thisresultsintwomodalitites\n",
      "offeaturevectorshenceofsimilaritydistances.Thedistancedistributionis\n",
      "thereforebimodal,illustratingthegeneralcaseofmultimodalitytobeexpected\n",
      "inrealistic,heterogeneousimagedata.Weconcludethattheassumptionsof\n",
      "Corollary3arerealisticinpractice,andthattheWeibullfunction,oramixture,\n",
      "distancedistributionswell.4.2\n",
      "ValidationofWeibull-shapeddistancedistributions\n",
      "Inthisexperiment,wevalidatethegofWeibulldistributionsofdis-\n",
      "tancesfromonereferencefeaturevectortoothervectors.Weconsiderthesame\n",
      "dataasbefore.Over1,000repetitionsweconsiderthegooofL2\n",
      "-distancesbytheWeibulldistribution.TheparametersoftheWeibulldistribu-\n",
      "tionfunctionareobtainedbymaximumlikelihoodestimation.Theestablished\n",
      "isassessedbytheAnderson-Darlingtestatalevelof?=0.05\n",
      "[20].TheAnderson-Darlingtesthasalsoproventobesuitedtomeasurethe\n",
      "gooofmixturedistributions[19].Table1indicatesthatformostof\n",
      "thefeaturetypescomputedfromvariousregions,morethan90%ofthedistance\n",
      "distributionsisbyasingleWeibullfunction.Asexpected,distancesbetween\n",
      "eachoftheSPIN,SIFT,PCA-SIFTandGLOHfeatures,arewellby\n",
      "Weibulldistributions.TheexceptionhereisthelownumberoffortheSIFT\n",
      "andSPINfeaturescomputedfromregions.Thedistributionsof\n",
      "distancesbetweenthesetworegion/featurecombinationstendtohavemultiple\n",
      "modes.Likewise,thereisalowpercentageofofL2-distancedistributions\n",
      "ofthe6\n",
      "0.014\n",
      "0.014\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.01\n",
      "0.01\n",
      "0.008\n",
      "0.006\n",
      "8\n",
      "\n",
      "0.008\n",
      "0.006\n",
      "0.004\n",
      "0.004\n",
      "0.002\n",
      "0.002\n",
      "0250\n",
      "300\n",
      "350\n",
      "400\n",
      "450500distances\n",
      "(a)\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "0.01\n",
      "probability\n",
      "probability\n",
      "probability\n",
      "0.014\n",
      "0250\n",
      "0.008\n",
      "0.006\n",
      "0.004\n",
      "0.002\n",
      "300\n",
      "350\n",
      "400\n",
      "450500distances\n",
      "(b)\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "0250\n",
      "300\n",
      "350\n",
      "400\n",
      "450500distances\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "(c)\n",
      "9\n",
      "\n",
      "Figure2:Distancedistributionsfromonerandomlyselectedimageregionto\n",
      "otherregions,eachdescribedbytheSIFTfeature.Thedistancedistributionis\n",
      "describedbyasingleWeibullfunctionforanaturalscene(a)andaman-made\n",
      "object(b).Foracompositeimage,thedistancedistributionisbimodal(c).\n",
      "Samplesfromeachofthedistributionsareshownintheupperimages.Table1:\n",
      "AcceptedWeibullforCORELdata[5].MSER\n",
      "IBRc=1c?2c=1c?2c=1c?2c=1c?2SIFT95%100%60%99%98%100%\n",
      "92%100%SIFT(g=PCA)95%99%60%98%98%100%92%99%PCA-SIFT\n",
      "89%100%96%100%94%100%95%100%PCA-SIFT(g=PCA)89%100%\n",
      "96%100%94%100%95%100%SPIN71%99%12%99%77%99%45%98%\n",
      "SPIN(g=PCA)71%100%12%97%77%99%45%98%GLOH87%100%91%\n",
      "100%82%99%86%100%GLOH(g=PCA)87%100%91%99%82%99%86%\n",
      "100%PercentagesofL2-distancedistributionsbyaWeibullfunction(c\n",
      "=1)andamixtureoftwoWeibullfunctions(c?2)aregiven.\n",
      "SPINfeaturecomputedfromIBRregions.Again,multiplemodesinthe\n",
      "distributionsareobserved.Forthesedistributions,amixtureoftwoWeibull\n",
      "functionsprovidesagood(?97%).\n",
      "5\n",
      "Conclusion\n",
      "Inthispaper,wehavederivedthatsimilaritydistancesbetweenoneand\n",
      "otherimagefeaturesindatabasesareWeibulldistributed.Indeed,forvarious\n",
      "typesoffeatures,i.e.theSPIN,SIFT,GLOHandPCA-SIFTfeatures,andfor\n",
      "alargevarietyofimagesfromtheCORELimagecollection,wehavedemon-\n",
      "stratedthatthesimilaritydistancesfromonetootherfeatures,computedfrom\n",
      "Lpnorms,areWeibull-distributed.Theseresultsareestablishedbytheexper-\n",
      "imentspresentedinTable1.Also,betweenPCA-transformedfeaturevectors,\n",
      "thedistancesareWeibull-distributed.TheMalahanobisdistanceisverysimilar\n",
      "totheL2-normcomputedinthePCA-transformedfeaturespace.Hence,we\n",
      "expectMahalanobisdistancestobeWeibulldistributedaswell.Furthermore,\n",
      "whenthedatasetisacomposition,amixtureoffew(typicallytwo)Weibull\n",
      "functionsasestablishedbytheexperimentspresentedinTable1.The\n",
      "resultingWeibulldistributionsaredistinctivelytfromthedistributions\n",
      "suggestedinliterature,astheyarepositivelyornegativelyskewedwhilethe\n",
      "Gamma[7]andnormal[23]distributionsarepositivelyandnon-skewed,respec-\n",
      "tively.WehavedemonstratedthattheWeibulldistributionisthepreferred\n",
      "choiceforestimatingpropertiesofsimilaritydistances.Theassumptionsun-\n",
      "derwhichthetheoryisvalidarerealisticforimages.Weexperimentallyhave\n",
      "shownthemtoholdforvariouspopularfeatureextractionalgorithms,andfora\n",
      "diverserangeofimages.Thisfundamentalinsightopensnewdirectionsinthe\n",
      "assessmentoffeaturesimilarity,withprojectedimprovementsandspeed-upsin\n",
      "object/scenerecognitionalgorithms.7\n",
      "AcknowledgmentsThisworkispartlysponsoredbytheEUfundedNEST\n",
      "projectPERCEPT,bytheDutchBSIKprojectMultimedian,andbytheEU\n",
      "NetworkofExcellenceMUSCLE.\n",
      "10\n",
      "\n",
      "2References\n",
      "[1]B.G.Batchelor.PatternRecognition:IdeasinPractice.PlenumPress,\n",
      "NewYork,1995.[2]E.Bertin.GlobalandGumbelstatistics.\n",
      "PhysicalReviewLetters,95(170601):1?4,2005.[3]E.BertinandM.Clusel.\n",
      "Generalisedextremevaluestatisticsandsumofcorrelatedvariables.Journalof\n",
      "PhysicsA,39:7607,2006.[4]W.J.Conover.Practicalnonparametricstatis-\n",
      "tics.Wiley,NewYork,1971.[5]CorelGallery.www.corel.com.[6]L.Fei-Fei\n",
      "andP.Perona.Abayesianhierarchicalmodelforlearningnaturalscenecat-\n",
      "egories.InCVPR,2005.[7]A.Ferencz,E.G.Learned-Miller,andJ.Malik.\n",
      "Buildingacascadeforvisualidenfromoneexample.In\n",
      "ProceedingsoftheInternationalConferenceComputerVision,pages286?293.\n",
      "IEEEComputerSociety,2003.[8]R.Fergus,P.Perona,andA.Zisserman.A\n",
      "sparseobjectcategorymodelfortlearningandexhaustiverecognition.\n",
      "InProceedingsoftheComputerVisionandPatternRecognition.IEEE,2005.\n",
      "[9]J.M.Geusebroek,R.vandenBoomgaard,A.W.M.Smeulders,andH.\n",
      "Geerts.Colorinvariance.IEEETransactionsonPatternAnalysisandMachine\n",
      "Intelligence,23(12):1338?1350,2001.[10]E.J.Gumbel.StatisticsofExtremes.\n",
      "ColumbiaUniversityPress,NewYork,1958.[11]C.HarrisandM.Stephans.\n",
      "Acombinedcornerandedgedetector.InProceedingsofthe4thAlveyVi-\n",
      "sionConference,pages189?192,Manchester,1988.[12]F.JurieandB.Triggs.\n",
      "Creatingtcodebooksforvisualrecognition.InICCV,pages604?610,\n",
      "2005.[13]D.G.Lowe.Distinctiveimagefeaturesfromscale-invariantkey-\n",
      "points.InternationalJournalofComputerVision,60(2):91?110,2004.[14]J.\n",
      "M.Marin,M.T.Rodriquez-Bernal,andM.P.Wiper.Usingweibullmixturedis-\n",
      "tributionstomodelheterogeneoussurvivaldata.Communicationsinstatistics,\n",
      "34(3):673?684,2005.[15]R.S.Michalski,R.E.Stepp,andE.Diday.Arecent\n",
      "advanceindataanalysis:Clusteringobjectsintoclassescharacterizedbycon-\n",
      "junctiveconcepts.InL.N.KanalandA.Rosenfeld,editors,ProgressinPattern\n",
      "Recognition,pages33?56.North-HollandPublishingCo.,Amsterdam,1981.\n",
      "[16]K.Mikolajczyk,B.Leibe,andB.Schiele.Multipleobjectclassdetection\n",
      "withagenerativemodel.InCVPR,2006.[17]K.MikolajczykandC.Schmid.\n",
      "Aperformanceevaluationoflocaldescriptors.IEEETransactionsonPattern\n",
      "AnalysisandMachineIntelligence,27(10):1615?1630,2005.[18]K.Mikolajczyk,\n",
      "T.Tuytelaars,C.Schmid,A.Zisserman,J.Matas,F.Sc,T.Kadir,\n",
      "andL.VanGool.Acomparisonofregiondetectors.InternationalJour-\n",
      "nalofComputerVision,65(1/2):43?72,2005.[19]K.Mosler.Mixturemodels\n",
      "ineconometricdurationanalysis.AppliedStochasticModelsinBusinessand\n",
      "Industry,19(2):91?104,2003.[20]NIST/SEMATECH.e-HandbookofStatisti-\n",
      "calMethods.NIST,http://www.itl.nist.gov/div898/handbook/,2006.[21]E.\n",
      "NowakandF.Jurie.Learningvisualsimilaritymeasuresforcomparingnever\n",
      "seenobjects.InCVPR,2007.[22]A.PapoulisandS.U.Pillai.Probabil-\n",
      "ity,RandomVariablesandStochasticProcesses.McGraw-Hill,NewYork,4\n",
      "edition,2002.[23]E.PekalskaandR.P.W.Duin.fordissimilarity-\n",
      "basedpatternrecognition.InProceedingsoftheInternationalConferenceon\n",
      "PatternRecognition,volume2,page2012,2000.[24]C.SchmidandR.Mohr.\n",
      "11\n",
      "\n",
      "Localgrayvalueinvariantsforimageretrieval.IEEETransactionsonPattern\n",
      "AnalysisandMachineIntelligence,19(5):530?535,1997.[25]J.C.vanGemert,\n",
      "J.M.Geusebroek,C.J.Veenman,C.G.M.Snoek,andArnoldW.M.Smeulders.\n",
      "Robustscenecategorizationbylearningimagestatisticsincontext.InCVPR\n",
      "WorkshoponSemanticLearningApplicationsinMultimedia(SLAM),2006.\n",
      "8\n",
      "12\n",
      "\n",
      "PP5981.pdf\n",
      "PP5981.pdf 14\n",
      "BoundingtheCostofSearch-BasedLifted\n",
      "Inference\n",
      "Authoredby:\n",
      "VibhavG.Gogate\n",
      "DavidB.Smith\n",
      "Abstract\n",
      "Recently,therehasbeengrowinginterestinsystematicsearch-based\n",
      "andimportancesampling-basedliftedinferencealgorithmsforstatistical\n",
      "relationalmodels(SRMs).Theseliftedalgorithmsachievetcom-\n",
      "plexityreductionsovertheirpropositionalcounterpartsbyusinglifting\n",
      "rulesthatleveragesymmetriesintherelationalrepresentation.Onedraw-\n",
      "backofthesealgorithmsisthattheyuseaninference-blindrepresentation\n",
      "ofthesearchspace,whichmakesitculttotlypre-computetight\n",
      "upperboundsontheexactcostofinferencewithoutrunningthealgorithm\n",
      "tocompletion.Inthispaper,wepresentaprincipledapproachtoaddress\n",
      "thisproblem.WeintroducealiftedanalogueofthepropositionalAnd/Or\n",
      "searchspaceframework,whichwecallaliftedAnd/Orschematic.Given\n",
      "aschematic-basedrepresentationofanSRM,weshowhowtotly\n",
      "computeatightupperboundonthetimeandspacecostofexactinfer-\n",
      "encefromacurrentassignmentandtheremainingschematic.Weshow\n",
      "howourboundingmethodcanbeusedwithinaliftedimportancesam-\n",
      "plingalgorithm,inordertoperformeRao-Blackwellisation,and\n",
      "demonstrateexperimentallythattheRao-Blackwellisedversionoftheal-\n",
      "gorithmyieldsmoreaccurateestimatesonseveralreal-worlddatasets.\n",
      "1PaperBody\n",
      "Amyriadofprobabilisticlogiclanguageshavebeenproposedinrecentyears[5,\n",
      "12,17].Theselanguagescanexpresselaboratemodelswithacompactsp\n",
      "cation.Unfortunately,performingtinferenceinthesemodelsremainsa\n",
      "challenge.Researchershaveattackedthisproblemby?lifting?propositionalin-\n",
      "ferencetechniques;liftedalgorithmsidentifyindistinguishablerandomvariables\n",
      "andtreatthemasasingleblockatinferencetime,whichcanyieldt\n",
      "reductionsincomplexity.SincetheoriginalproposalbyPoole[15],avarietyof\n",
      "liftedinferencealgorithmshaveemerged.Onepromisingapproachistheclassof\n",
      "search-basedalgorithms[8,9,16,19,20,21],whichliftpropositionalweighted\n",
      "modelcounting[4,18]tothelevelbytransformingthepropositional\n",
      "1\n",
      "\n",
      "searchspaceintoasmallerliftedsearchspace.Ingeneral,exactliftedinference\n",
      "remainsintractable.Asaresult,therehasbeenagrowinginterestindeveloping\n",
      "approximatealgorithmsthattakeadvantageofsymmetries.Inthispaper,we\n",
      "focusonaclassofsuchalgorithms,calledliftedsamplingmethods[9,10,13,\n",
      "14,22]andinparticularontheliftedimportancesampling(LIS)algorithm[10].\n",
      "LIScanbeunderstoodasasamplinganalogueofanexactliftedsearchalgo-\n",
      "rithmcalledprobabilistictheoremproving(PTP).PTPacceptsaSRMasinput\n",
      "(asaMarkovLogicNetwork(MLN)[17]),decidesuponaliftedinferencerule\n",
      "toapply(conditioning,decomposition,partialgrounding,etc.),constructsaset\n",
      "ofreducedMLNs,recursivelycallsitselfoneachreducedMLNinthisset,and\n",
      "combinesthereturnedvaluesinanappropriatemanner.AdrawbackofPTPis\n",
      "thattheMLNrepresentationofthesearchspaceisinferenceunaware;atany\n",
      "stepinPTP,thecostofinferenceovertheremainingmodelisunknown.This\n",
      "isproblematicbecauseunlike(propositional)importancesamplingalgorithms\n",
      "forgraphicalmodels,whichcanbeRao-Blackwellised[3]inaprincipledmanner\n",
      "bysamplingvariablesuntilthetreewidthoftheremainingmodelisboundedby\n",
      "asmallconstant(calledw-cutsetsampling[1]),itiscurrentlynotpossibleto\n",
      "Rao-BlackwelliseLISinaprincipledmanner.Toaddresstheselimitations,we\n",
      "makethefollowingcontributions:1\n",
      "1.Weproposeanalternate,inference-awarerepresentationofthelifted\n",
      "searchspacethatallowstcomputationofthecostofinferenceatany\n",
      "stepofthePTPalgorithm.OurapproachisbasedontheAnd/Orsearchspace\n",
      "perspective[6].PropositionalAnd/Orsearchassociatesacompactrepresenta-\n",
      "tionofasearchspacewithagraphicalmodel(calledapseudotree),andthen\n",
      "usesthisrepresentationtoguideaweightedmodelcountingalgorithmover\n",
      "thefullsearchspace.WeextendthisnotiontoLiftedAnd/Orsearchspaces.\n",
      "WeassociatewitheachSRMaschematic,whichdescribestheassociatedlifted\n",
      "searchspaceintermsofliftedOrnodes,whichrepresentbranchingoncounting\n",
      "assignments[8]togroupsofindistinguishablevariables,andliftedAndnodes,\n",
      "whichrepresentdecompositionsoverindependentand(possibly)identicalsub-\n",
      "problems.OurformalspofliftedAnd/Orsearchspacesersan\n",
      "intermediaterepresentationofSRMsthatbridgesthegapbetweenhigh-level\n",
      "probabilisticlogicssuchasMarkovLogic[17]andthesearchspacerepresen-\n",
      "tationthatmustbeexploredatinferencetime.2.Weusetheintermediate\n",
      "sptocharacterizethesizeofthesearchspaceassociatedwithanSRM\n",
      "withoutactuallyexploringit,providingtightupperboundsonthecomplexity\n",
      "ofPTP.Thisallowsus,inprinciple,todevelopadvancedapproximateliftedin-\n",
      "ferencealgorithmsthattakeadvantageofexactliftedinferencewheneverthey\n",
      "encountertractablesubproblems.3.Wedemonstratetheutilityofourlifted\n",
      "And/OrschematicandtightupperboundsbydevelopingaRao-Blackwellised\n",
      "liftedimportancesamplingalgorithm,enablingtheusertosystematicallyex-\n",
      "ploretheaccuracyversuscomplexityWedemonstrateexperimentally\n",
      "thatitvastlyimprovestheaccuracyofestimationonseveralreal-worlddatasets.\n",
      "2\n",
      "BackgroundandTerminology\n",
      "And/OrSearchSpaces.TheAnd/Orsearchspacemodelisageneralper-\n",
      "2\n",
      "\n",
      "spectiveforsearchingovergraphicalmodels,includingbothprobabilisticnet-\n",
      "worksandconstraintnetworks[6].And/Orsearchspacesallowformanyfa-\n",
      "miliargraphnotionstobeusedtocharacterizealgorithmiccomplexity.Given\n",
      "agraphicalmodel,M?xG,?y,whereG?xV,Eyisagraphand?isasetof\n",
      "featuresorpotentials,andarootedtreeTthatspansGinsuchamannerthat\n",
      "theedgesofGthatarenotinTareallback-edges(i.e.,Tisapseudotree[6]),\n",
      "thecorrespondingAnd/OrSearchSpace,denotedSTpRq,containsalternating\n",
      "levelsofAndnodesandOrnodes.OrnodesarelabeledwithXi,whereXi\n",
      "Pvarsp?q.Andnodesarelabeledwithxiandcorrespondtoassignmentsto\n",
      "Xi.TherootoftheAnd/OrsearchtreeisanOrnodecorrespondingtothe\n",
      "rootofT.Intuitively,thepseudotreecanbeviewedasaschematicforthe\n",
      "structureofanAnd/Orsearchspaceassociatedwithagraphicalmodel,which\n",
      "denotes(1)theconditioningorderonthesetvarsp?q,and(2)thelocations\n",
      "alongthisorderingatwhichthemodeldecomposesintoindependentsubprob-\n",
      "lems.Givenapseudotree,wecangeneratethecorrespondingAnd/Orsearch\n",
      "treeviaastraightforwardalgorithm[6]thataddsconditioningbranchestothe\n",
      "pseudotreerepresentationduringaDFSwalkoverthestructure.Addinga\n",
      "cachethatstoresthevalueofeachsubproblem(keyedbyanassignmenttoits\n",
      "context)allowseachsubproblemtobecomputedjustonce,andconvertsthe\n",
      "searchtreeintoasearchgraph.Thusthecostofinferenceisencodedinthe\n",
      "pseudotree.InSection3,wealiftedanaloguetothebackbonepseudo\n",
      "tree,calledaliftedAnd/Orschematic,andinSection3,weusetheto\n",
      "provecostofinferenceboundsforprobabilisticlogicmodels.FirstOrderLogic.\n",
      "Anentity(oraconstant)isanobjectinthemodelaboutwhichwewouldlike\n",
      "toreason.Eachentityhasanassociatedtype,?.Thesetofalluniquetypes\n",
      "formsthesetofbasetypesforthemodel.Adomainisasetofentitiesofthe\n",
      "sametype?;weassumethateachdomainisandisdisjointfromevery\n",
      "otherdomaininthemodel.Avariable,denotedbyalower-caseletter,isa\n",
      "symbolicplaceholderthatspwhereasubstitutionmaytakeplace.Each\n",
      "variableisassociatedwithatype?;avalidsubstitutionrequiresthatavariable\n",
      "bereplacedbyanobject(eitheranentityoranothervariable)withthesame\n",
      "type.Wedenotethedomainassociatedwithavariablevby?v.Wea\n",
      "predicate,denotedbyRpt1::?1,...,tk::?kq,tobeak-aryfunctorthat\n",
      "mapstypedentitiestobinary-valuedrandomvariables(alsocalledparameter-\n",
      "izedrandomvariable[15]).Asubstitutionisanexpressionoftheformtt1?x1\n",
      ",...,tk?xkuwheretiarevariablesoftype?iandxiareeitherentitiesor\n",
      "variablesoftype?i.GivenapredicateRandasubstitution??tt1?x1,...\n",
      ",tk?xku,theapplicationof?toRyieldsanotherk-aryfunctorfunctorwith\n",
      "eachtireplacedbyxi,calledanatom.Ifallthexiareentities,theapplication\n",
      "yieldsarandomvariable.Inthiscase,wereferto?asagroundingofR,and\n",
      "R?asagroundatom.Weadoptthenotation?itorefertothei-thassignment\n",
      "of?,i.e.?i?xi.2\n",
      "StatisticalRelationalModelscombinelogicandprobabilisticgraph-\n",
      "icalmodels.ApopularSRMisMarkovlogicnetworks(MLNs)[17].AnMLN\n",
      "isasetofweightedlogicclauses.Givenentities,theMLN\n",
      "aMarkovnetworkoverallthegroundatomsinitsHerbrandbase(cf.[7]),\n",
      "3\n",
      "\n",
      "withafeaturecorrespondingtoeachgroundclauseintheHerbrandbase.(We\n",
      "assumeHerbrandinterpretationsthroughoutthispaper.)Theweightofeach\n",
      "featureistheweightofthecorrespondingclause.?Theprobabil-\n",
      "itydistributionassociatedwiththeMarkovnetworkisgivenby:Ppxq?Z1\n",
      "exppiwinipxqqwhere?wiis?theweightoftheithclauseandnipxqis\n",
      "itsnumberoftruegroundingsinx,andZ?xexppiwinipxqqistheparti-\n",
      "tionfunction.Inthispaper,wefocusoncomputingZ.Itisknownthatmany\n",
      "inferenceproblemsoverMLNscanbereducedtocomputingZ.Probabilistic\n",
      "TheoremProving(PTP)[9]isanalgorithmforcomputingZinMLNs.Itlifts\n",
      "thetwomainstepsinpropositionalinference:conditioning(Ornodes)andde-\n",
      "composition(Andnodes).Inliftedconditioning,thesetoftruthassignmentsto\n",
      "groundatomsofapredicateRarepartitionedintomultiplepartssuchthatin\n",
      "eachpart(1)alltruthassignmenthavethesamenumberoftrueatomsand(2)\n",
      "theMLNsobtainedbyapplyingthetruthassignmentsareidentical.Thus,ifR\n",
      "hasngroundatoms,theliftedsearchprocedurewillsearchoverOpn`1qnew\n",
      "MLNswhilethepropositionalsearchprocedurewillsearchoverOp2nqMLNs,\n",
      "anexponentialreductionincomplexity.Inlifteddecomposition,theMLNis\n",
      "partitionedintoasetofMLNsthatarenotonlyidentical(uptoarenaming)\n",
      "butalsodisjointinthesensethattheydonotshareanygroundatoms.Thus,\n",
      "unlikethepropositionalprocedurewhichcreatesndisjointMLNsandsearches\n",
      "overeach,theliftedproceduresearchesoverjustoneofthenMLNs(since\n",
      "theyareidentical).Unfortunately,lifteddecompositionandliftedconditioning\n",
      "cannotalwaysbeappliedandinsuchcasesPTPresortstopropositionalcon-\n",
      "ditioninganddecomposition.AdrawbackofPTPisthatunlikepropositional\n",
      "And/Orsearchwhichhastightcomplexityguarantees(e.g.,exponentialinthe\n",
      "treewidthandpseudotreeheight),thereareno(tight)formalguaranteesonthe\n",
      "complexityofPTP.1Weaddressthislimitationinthenexttwosections.\n",
      "3\n",
      "LiftedAnd/OrSchematics\n",
      "Ourgoalinthissectionistoalifted(x,1,2)analoguethepseudotree\n",
      "notionemployedR1([x],1,2,UN)R1([x],1,2,UN)R1([x],1,2,UN)bytheproposi-\n",
      "tionalAnd/Orframework.Thestructuremustencode(1)allinfor(y,1,2)mation\n",
      "containedinapropositionalpseu(x,1,2)dotree(aconditioningorder,conditional\n",
      "S1([x,y],2,2,UN)S1([x,y],2,2,UN)S1([x],1,2,UN)independenceassumptions),\n",
      "aswellas(2)additionalinformationneededbythePTPalgorithminorderto\n",
      "exploitthesymme-Figure1:Possibleschematicsfor(a)Rpxq\n",
      "Spxq,(b)Rpxq\n",
      "triesoftheliftedmodel.Sincethesymme-\n",
      "Spx,yqand(c)Rpxq\n",
      "Rpyq\n",
      "Spx,\n",
      "yq,?x??y?2.UNstandsforunknown.Circlesanddiamondsrepresenttries\n",
      "thatcanbeexploitedhighlydependliftedOrandAndnodesrespectively.on\n",
      "theamountofevidence,weencodetheSRMafterevidenceisinstantiated,via\n",
      "aprocesscalledshattering[2].Thus,whileapseudotreeencodesagraphical\n",
      "model,aschematicencodesan(SRM,evidenceset)pair.Alifted\n",
      "Ornodeisavertexlabeledbya6?tuplexR,?,?,i,c,ty,where(1)Risa\n",
      "k-arypredicate,(2)?isasetofvalidsubstitutionsforR,(3)?Pt1,...,\n",
      "ku,representsthecountingargumentforthepredicateRpt1::?1,...,tk::\n",
      "?kqandspadomain??tobecountedover,(4)iisanidenofthe\n",
      "4\n",
      "\n",
      "blockofthepartitionbeingcountedover,(5)cPZ`isthenumberofentities\n",
      "inblocki,and(6)tPtTrue,False,Unknownuisthetruthvalueoftheset\n",
      "ofentitiesinblocki.AliftedAndnodeisavertexlabeledbyF,a\n",
      "(possiblyempty)setofformulas,whereaformulafisapairptpO,?,bqu,wq,\n",
      "inwhichOisaliftedOrnodexR,?,?,i,c,ty,?P?,bPtTrue,Falseu,\n",
      "andwPR.Formulasareassumedtobeinclausalform.Alifted\n",
      "And/Orschematic,S?xVS,ES,vry,isarootedtreecomprisedofliftedOr\n",
      "nodesandliftedAndnodes.Smustobeythefollowingproperties:?Every\n",
      "liftedOrnodeOPVShasasinglechildnodeNPVS.?EveryliftedAnd\n",
      "nodeAPVShasa(possiblyempty)setofchildrentN1,...,Nnu?VS\n",
      ".1Although,complexityboundsexistforrelatedinferencealgorithmssuchas\n",
      "decompositiontrees[20],theyarenotastightastheonespresented\n",
      "inthispaper.\n",
      "3\n",
      "?ForeachpairofliftedOrnodesO,O1PVS,withrespectivelabelsxR,\n",
      "?,?,i,c,ty,xR1,?1,?1,i1,c1,t1y,pR,iq?pR1,i1q.PairspR,\n",
      "iquniquelyidentifyliftedOrnodes.?ForeveryliftedOrnodeOPVSwith\n",
      "labelxR,?,?,i,c,ty,@?P?,@?1??,either(1)???1=1,or(2)??1P\n",
      "X,whereXhasappearedasthedecomposerlabel[9]ofsomeedgeinpathS\n",
      "pO,vrq.?Foreachformula?ptpO,?,bqu,wqappearingataliftedAnd\n",
      "nodeA,@OPtpO,?,bqu,OPpathSpvr,Aq.Wecallthesetofedges\n",
      "tpO,Aq|OPFormulaspAquthebackedgesofS.?Eachedgebetweena\n",
      "liftedOrnodeOanditschildnodeNisunlabeled.Eachedgebetweenalifted\n",
      "AndnodeAanditschildnodeNmaybe(1)unlabeledor(2)labeledwith\n",
      "apairpX,cq,whereXisasetofvariables,calledadecomposerset,andc\n",
      "PZ`isthethenumberofequivalententitiesintheblockofxrepresentedby\n",
      "thesubtreebelow.IfitislabeledwithadecomposersetXthen(a)forevery\n",
      "substitutionset?labelingaliftedOrnodeO1appearinginthesubtreerooted\n",
      "atN,Dis.t.@?P?,?iPXand(b)@decomposersetsYlabelingedges\n",
      "inthesubtreerootedatN,YXX?H.TheliftedAnd/OrSchematicisa\n",
      "generalstructureforspecifyingtheinferenceprocedureinSRMs.Itcanencode\n",
      "modelsspinmanyformats,suchasMarkovLogic[17]andPRVmodels\n",
      "[15].Givenamodelandevidenceset,constructingaschematicconversionintoa\n",
      "canonicalformisachievedviashattering[2,11],wherebyexchangeablevariables\n",
      "aregroupedtogether.Inferenceonlyrequiresinformationonthesizeofthese\n",
      "groups,sotherepresentationomitsinformationonthespvariablesina\n",
      "givengroup.Figure1showsAnd/OrschematicsforthreeMLNs.Algorithm1\n",
      "FunctionevalNode(And)\n",
      "Algorithm2FunctionevalNode(Or)\n",
      "1:Input:aschematic,TwithAndrootnode,acountingstorecs2:Output:\n",
      "arealnumber,w3:N?root(T)4:forformulafPNdo5:w?w?calcu-\n",
      "lateWeightpf,csq6:forchildN1ofTdo7:cs1?sumOutDoneAtomspcs,N\n",
      "q8:ifpN,N1qhaslabelxV,b,cbythen9:ifExpV,bq,ccyPcss.t.vP\n",
      "Vthen10:cs2?cs1YxpV,bq,xtu,tptu,cbqyy11:xP,My?getCC(V,b,\n",
      "cs2)//getccforV12:forassignmentpai,kiqPMdo13://givevitsown\n",
      "entryincs14:cs3?updateCCAtDecomposerpcs2,V,v,pai,1qq15:w?\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w?evalNodepN1,cs3qki16:else17:w?w?evalNodepN1,csq18:returnw\n",
      "1:Input:aschematic,TwithOrNoderoot,acountingstorecs2:Output:\n",
      "arealnumber,w3:ifpxroot(T),cs)y,wqPcachethenreturnw4:xR,?,?,b,\n",
      "c,t,Py=root(T)5:T1?child(xR,?,?,b,c,t,y,Tq6:V?tv|?P?,\n",
      "???vu7:xP,txai,kiyuy?getCC(V,b)8:w?09:iftPtTrue,Falseu\n",
      "then10:cs1=updateCC(xP,My,R,tv)11:w?evalNode(T1,cs1)12:else\n",
      "13:assigns=ttv1,...,vnu|viPt0,...,kiuu14:fortv1,...,vnu\n",
      "Passignsdo15:cs1=updateCC(xP,My,?R,tv1,...,vnu)????`k?ni\n",
      "16:w?w`evalNodepT1,cs1qi?1vi17:insertCache(xR,?,?,b,c,t,Py,w)\n",
      "18:returnw\n",
      "3.1LiftedNodeEvaluationFunctions-Wedescribetheinferenceprocedure\n",
      "inAlgorithms1and2.Werequirethenotionofacountingstoreinorderto\n",
      "trackcountingassignmentsoverthevariablesinthemodel.Acountingstoreis\n",
      "asetofpairsxpV,iq,ccy,whereVisasetofvariablesthatarecountedover\n",
      "together,iisablockidenandccisacountingcontext.Acountingcontext\n",
      "(introducedin[16]),isapairxPr,My,wherePrisalistofmpredicates\n",
      "andM:tTrue,Falseum?k,isamapfromtruthassignmentstoPrtoa\n",
      "non-negativeintegerdenotingthecountofthenumberofentitiesinthei-th\n",
      "blockofthepartitionofeachvPVthattakethatassignment.Weinitializethe\n",
      "algorithmbyacalltoAlgorithm1withanappropriateschematicSandempty\n",
      "countingstore.TheliftedAndnodefunction(Algorithm1)rstcomputesthe\n",
      "weightofanycompletelyconditionedformulas.ItthenmakesasetofevalNode\n",
      "callsforeachofitschildrenO;ifpA,OqhasdecomposerlabelV,itmakesa\n",
      "callforeachassignmentineachblockofthepartitionofV;otherwiseitmakes\n",
      "asinglecalltoO.Thealgorithmtakestheproductoftheresultingtermsalong\n",
      "withtheproductoftheweightsandreturnstheresult.TheliftedOrnode\n",
      "function(Algorithm2)retrievesthesetofallassignmentspreviouslymadeto\n",
      "itscountingargumentvariableset;itthenmakesanevalNodecalltoitschild\n",
      "foreachcompletiontoitsassignmentsetthatisconsistentwithitslabeled\n",
      "truthvalue,andtakestheirweightedsum,wheretheweightisthenumberof\n",
      "symmetricassignmentsrepresentedbyeachassignmentcompletion.Theoverall\n",
      "complexityofdependsonthenumberofentriesinthecountingstoreateachstep\n",
      "ofinference.NotethatAlgorithm1reducesthesizeofthestorebysumming\n",
      "outoveratomsthatleavecontext.Algorithm2increasesthesizeofthestoreat\n",
      "atomswithunknowntruthvaluebysplittingthecurrentassignmentintoTrue\n",
      "andFalseblocksw.r.t.itsatompredicate.Atomswithknowntruthvalueleave\n",
      "thesizeofthestoreunchanged.4\n",
      "4\n",
      "ComplexityAnalysis\n",
      "Algorithms1and2describeaDFS-styletraversaloftheliftedsearchspace\n",
      "associatedwithS.Asournotionofcomplexity,weareinterestedinspecifying\n",
      "themaximumnumberoftimesanynodeVSPSisreplicatedduringinstanti-\n",
      "ationofthesearchspace.WedescribethisquantityasSSNpSq.Ourgoalin\n",
      "thissectionistothefunctionSSNpSq,whichwerefertoastheinduced\n",
      "liftedwidthofS.4.1ComputingtheInducedLiftedWidthofaSchematic-\n",
      "InthepropositionalAnd/Orframework,theinferencecostofapseudotreeT\n",
      "6\n",
      "\n",
      "isdeterminedbyDR,thetreedecompositionofthegraphG?xNodespT\n",
      "q,BackEdgespTqyinducedbythevariableorderingattainedbytraversing\n",
      "TalonganyDFSorderingfromroottoleaves.[6].InferenceisOpexppwqq,\n",
      "wherewisthesizeofthelargestclusterinDR.Theanalogousprocedurein\n",
      "liftedAnd/Orrequiresadditionalinformationbestoredateachcluster.Lifted\n",
      "treedecompositionsareidenticaltotheirpropositionalcounterpartswithtwo\n",
      "exceptions.First,eachclusterCirequirestheorderingofitsnodesinduced\n",
      "bytheoriginalorderofS.Second,eachclusterCithatcontainsanodewhich\n",
      "occursafteradecomposerlabelrequirestheinclusionofthedecomposerlabel.\n",
      "Formally:ThetreesequenceTSassociatedwithschematicSisa\n",
      "partiallyorderedsetsuchthat:(1)OPNodespSq?OPTS,(2)pA,Nq\n",
      "withlabellPEdgespSq?pA,lqPTS,and(3)AncpN1,N2,Sq?N1?\n",
      "N2PTS.ThepathsequencePassociatedwithtreesequenceTS\n",
      "ofschematicSisanytotallyorderedsubsequenceofTS.Givena\n",
      "schematicSanditstreesequenceTS,theLiftedTreeDecompositionofTS,\n",
      "denotedDS,isapairpC,TqinwhichCisasetofpathsequencesandTisa\n",
      "treewhosenodesarethemembersofCsatisfyingthefollowingproperties:(1)\n",
      "@pO,AqPBackEdgespPq,Dis.t.O,APCi,(2)@i,j,ks.tCkPPathT\n",
      "pCi,Cjq,CiXCj?Ck,(3)@APTS,OPCi,A?O?APCi.Giventhe\n",
      "partialorderingofnodesbyS,eachschematicSinducesauniqueLifted\n",
      "TreeDecomposition,DS.ComputingSSNpSqrequirescomputingmaxCiPC\n",
      "SSCpCiq.ThereexistsatotalorderingoverthenodesineachCi;hencethe\n",
      "liftedstructureineachCiconstitutesapath.Wetaketheliftedsearchspace\n",
      "generatedbyeachclusterCtobeatree;hencecomputingthemaximumnode\n",
      "replicationisequivalenttocomputingthenumberofleavesinSSC.Inorder\n",
      "tocalculatetheinducedliftedwidthofagivenpath,wemustdetermine\n",
      "whichOrnodesarecountedoverdependently.LetVC?tv|xR,?,?,i,c,\n",
      "tyPC,?P?,???vubethesetofvariablesthatarecountedoverbyan\n",
      "OrnodeinclusterC.LetVCbeapartitionofVCintoitsdependentvariable\n",
      "countingsets;i.e.thebinaryrelationCS?tpv1,v2q|DxR,?,?,i,\n",
      "c,tyPVSs.tD?,?1P?,???v1,??1?v2u.ThenV?tv1|pv,v1q\n",
      "PCS`u,whereCS`isthetransitiveclosureofCS.LetVC?tVj|v1,v2P\n",
      "Vj??pv1,v2qPCS`u.VariablesthatappearinasetVjPVCrefertothe\n",
      "samesetofobjects;thusallhavethesametype?jandtheyallsharethesame\n",
      "partitionoftheentitiesofTj.LetPjdenotethepartitionoftheentitiesofTj\n",
      "w.r.tvariablesetVj.TheneachblockpijPPjiscountedoverindependently\n",
      "(werefertoeachpijasadependentcountingpath).Thuswecancalculate\n",
      "thetotalleavescorrespondingtoclusterCbytakingtheproductoftheleaves\n",
      "ofeachpijblock:??SSCpCq?VjPVCpijPPjSSpppijq(1)Analysisof\n",
      "liftedOrnodesthatcountoverthesameblockpijdependsonthestructureof\n",
      "thedecomposerssetsoverthestructure.First,weconsiderthecaseinwhichC\n",
      "containsnodecomposers.4.2LiftedOrNodeswithNoDecomposer-Consider\n",
      "ORC,Vj,i,thesequenceofnodesinCthatperformconditioningoverthei-th\n",
      "blockofthepartitionofthevariablesinVj.ThenodesinORC,Vj,icountover\n",
      "thesamesetofentities.AconditioningassignmentatOassignsctPt0...cu\n",
      "entitiestoTrueandcf?c?ctentitiestoFalsew.r.t.itspredicate,breaking\n",
      "7\n",
      "\n",
      "thesymmetryoverthecelementsintheblock.EachO1PORp,Vj,ithatoccurs\n",
      "afterOmustperformcountingovertwosetsofsizectandcfseparately.The\n",
      "numberofassignmentsforblocktVj,iugrowsexponentiallywiththenumber\n",
      "ofancestorscountingovertVj,iuwhosetruthvalueisunknown.Formally,let\n",
      "cijbethesizeofthei-thblockofthepartitionofVj,andletnij?|tO|OP\n",
      "ORC,Vj,i,N?xR,?,?,i,c,unknownyu|.Foraninitialdomainsizecijand\n",
      "predicatecountnij,wemustcomputethenumberofpossiblewaystorepresent\n",
      "cijasasumof2nijnon-negativeintegers.kij?2nij.Wecancountthe\n",
      "numberofleafnodesgeneratedbycountingthenumberofweakcompositions\n",
      "ofcijintokijparts.Thusthenumberofsearchspaceleavescorrespondingto\n",
      "pijgenerated`byijC?is:?1SSpppijq?Wpcij,kijq?cijk`k(2)ij?15\n",
      "ExampleConsidertheexampleinFigure1(a).Thereisasinglepathfrom\n",
      "theroottoaleaf.Thesetofvariablesappearingonthepath,V?txu,and\n",
      "hencethepartitionofVintovariablesthatarecountedovertogetheryields\n",
      "ttxuu.Thusn1,1?|tpR1p2,Unq,S1`p2,Unqu|??5!2,c1,1?2,and\n",
      "k1,1?4.Sowecancounttheleavesofthemodelbytheexpression2`4?1\n",
      "?3!2!?10.4?14.3LiftedOrNodeswithDecomposers-ToAlgorithm3\n",
      "FunctioncountPathLeavesdeterminethesizeofthesearchtreeinducedby1:\n",
      "Input:asubsequencepathP``asubsequencePthatcontainsdecomposers,we\n",
      "2:Output:fpxq:Z?Z,wherexisadomainsizeandfpxqisthenumberof\n",
      "searchspaceleavesgeneratedbyPmustconsiderwhetherthecountingargument\n",
      "3://werepresenttherecursivepolynomialapwc1-wc2qasatriplepa,wc1,\n",
      "wc2q,ofeachOrnodeisdecomposedon.4.3.1\n",
      "LiftedOrNodeswithDecomposersasNonCountingArguments\n",
      "4:5:6:7:8:9:\n",
      "whereaPZ,andwc1,wc2areeitherweakcompositions(basecase)ortriples\n",
      "ofthistype(recursivecase)typeWCP=WCINT|WCD(INT,WCP,WCP)\n",
      "//evalPolyconstructsthepolynomialfunctionMAKEPOLY((WCnq,pt,a,\n",
      "sq)n,WCn,WCpn?2t?aqqreturnWCD(t?a\n",
      "WeconsiderthecasewhenORC,Vj,icontainsdecomposervariables\n",
      "asnon-counting2functionMAKEPOLY((WCD(c,wc1,wc2qq,pt,a,sqq\n",
      "arguments.Foreachparent-to-childedgereturnWCDpa,makePolywc1pt,a,\n",
      "sq,makePolywc2pt?(A,N,labell),Algorithm1generatesachildfors,a?\n",
      "s,sqqeachnon-zeroassignmentinthecountingstore10://applyDecdivides\n",
      "outtheOrnodeswithcontainingthedecomposervariable.Ifapathcounting\n",
      "variablesthataredecomposersa))subsequenceovervariablevofinitialdomain\n",
      "c11:functionAPPLYDEC(d,(WC12:returnWCpa\n",
      "f\n",
      "p2dqqhasnOrnodes,\n",
      "kofwhichoccurbelowthede-13:functionAPPLYDEC(d,(WCD(a,b,c)))\n",
      "composerlabel,thenwecancomputethenum-14:returnWCD(a,applyDecd\n",
      "b,applyDecdc)berofassignmentsinthecountingstoreateach15://evalPoly\n",
      "createsafunctionthattakesadomainandcomputestheofthe\n",
      "decomposeras2n?k.Further,wecancomputeconstituentweakcomposi-\n",
      "tionsthenumberofnon-zeroleavesgeneratedbyeach16:functionEVALP\n",
      "OLY((WCD(a,b,c)),x)assignmentcanbecomputedasthe17:return\n",
      "a?(evalPolybx-evalPolycx)functionEVAL`POLY?((WCa),x)inleaves\n",
      "fromthemodelovernOrnodesand18:19:returnx`a?1a?1themodelover`k\n",
      "8\n",
      "\n",
      "Or?nodes.result>nHence?`the??20:t=totalOrNodes(P)c`2?1c`2k?1\n",
      "n?kingmodelhas2?2k?121:dv=orNodesWithDecomposerCountingArgu-\n",
      "ment(P)2n?122:poly=WC2t;orNodesAbove=0;orNodesBetween=0leaves.\n",
      "Thisprocedurecanberepeatedbyrecur-23:forNofPdosivelyapplyingthe\n",
      "ruletospliteachweakcom-24:ifN?pA,xv,p,cyqthenpoly=makePoly\n",
      "poly(t,orNodesAbove,orNodesBetween)positionintoaofweakcom-\n",
      "positions25:26:orNodesBetween=0foreachdecomposerlabelpresentinthe\n",
      "subse-27:elseorNodesAbove++;orNodesBetween++quenceunderconsidera-\n",
      "tion(Algorithm3).The28:return2dv?evalPoly(applyDecdvpoly)\n",
      "resultisapolynomialinc,which,whengivenadomainsize,returnsthenumber\n",
      "ofleavesgeneratedbythepathsubsequence.ExampleConsidertheexample\n",
      "inFigure1(c).Againthereisasinglepathfromtheroottoaleaf.Thesetof\n",
      "variablesappearingonthepathisV?tx,yu.ThepartitionofVintovariables\n",
      "thatarecountedovertogetheryieldsV?ttx,yuu.Algorithm3returns`?`2`2?1\n",
      "?thepolynomialfpxq?2pWpx,4q?Wpx,2qq.Sothesearchspacecontains\n",
      "2p2`4?1?4?12?1q?14leaves.4.3.2\n",
      "LiftedOrNodeswithDecomposersasCountingArguments\n",
      "TheprocedureissimilarforthecasewhenPcontainsOrnodesthatcount\n",
      "overvariablesthathavebeendecomposedoneaddition.Ornodesthatcount\n",
      "overavariablethathaspreviouslyappearedasthedecomposerlabelofan\n",
      "ancestorinthepathhaveadomainsizeof1andhencealwaysspawnWp1,\n",
      "2q?2childreninsteadofWpx,2qchildren.IftherearedOrnodesinP\n",
      "thatcountoverdecomposedvariables,wemustdividethektermofeachweak\n",
      "compositioninourpolynomialby2d.Lines11?14ofAlgorithm3perform\n",
      "thisoperation.ExampleConsidertheexampleshowninFigure1(b).Again\n",
      "thereisonepathfromtheroottoleaf,withV?tx,yu;partitioningVintosets\n",
      "ofvariablesthatarecountedovertogetheryieldsV?ttxu,tyuu.Thusn1,1?\n",
      "|tpR1p2,Unqu|?1,c1,1?2,andk1,1?2.Similarly,n2,1?|tS1p2,U\n",
      "nq|s|?1,c2,1?2,andk2,1?2.Algorithm3returnstheconstantfunctions\n",
      "f1pxq?f2pxq?2?Wpx,1q?2.Equation1indicatesthatwetakethe\n",
      "productofthesefunctions.Sothesearchspacecontains4leavesregardlessof\n",
      "thedomainsizesofxandy.4.4OverallComplexity-Detailedanalysis,aswell\n",
      "asaproofofcorrectnessofAlgorithm3isgiveninthesupplementalmaterial\n",
      "section.Herewegivegeneralcomplexityresults.6\n",
      "Theorem4.1GivenaliftedAnd/OrSchematicSwithassociatedTreeDe-\n",
      "compositionDS?pC,Tq,theoveralltimeandspacecomplexityofinference\n",
      "inSisOpmaxCiPCSSCpCiqq.\n",
      "5\n",
      "AnApplication:Rao-BlackwellisedImportanceSampling\n",
      "Rao-Blackwellisation[1,3]isavariance-reductiontechniquewhichcombines\n",
      "exactinferencewithsampling.Theideaistopartitionthegroundatomsinto\n",
      "twosets:asetofatoms,sayXthatwillbesampledandasetofatomsthatwill\n",
      "besummedoutanalyticallyusingexactinferencetechniques,sayY.Typically,\n",
      "theaccuracy(variancedecreases)improvesasthecardinalityofYisincreased.\n",
      "However,sodoesthecostofexactinference,whichinturndecreasestheaccu-\n",
      "racybecausefewersamplesaregenerated.Thus,thereisa\n",
      "9\n",
      "\n",
      "Algorithm4FunctionmakeRaoFunction1:Input:aschematicS2:Output:\n",
      "fpxq:CS?Z`3:theclustersofS4:pC,Tq=reeDecomposition(S)\n",
      "5:sizef?tu6:forCiofCdo7:P=dependentCountingPaths(Ci)8:cf?tu\n",
      "9:forpVj,PjqofPdo10:fj=countPathLeaves(Pj)11:cf.append(xVJ,fj\n",
      "y)12:sizef.append(cf)returnsizef\n",
      "Rao-Blackwellisationisparticularlyusefulinliftedsamplingschemesbe-\n",
      "causesubproblemsoverlargeAlgorithm5FunctionevalRaoFunctionsetsof\n",
      "randomvariablesareoftentractable(e.g.1:Input:acountingstore,cs,alist\n",
      "oflistofsizefunctions,sfsubproblemscontaining2nassignmentscanoften2:\n",
      "Output:sPZ`,thecostofexactinferencebesummedoutinOpnqtimevia\n",
      "liftedcondition-3:clusterCosts?tuforcfiofsfdoing,orinOp1qtimevia\n",
      "lifteddecomposition).The4:5:clusterCost?1approachpresentedinSection\n",
      "3isidealforthis6:forxVj,fjyofcfidoassigns?getCCpVjqtaskbecause\n",
      "Algorithm3returnsafunctionthat7:8:forskofassignsdoisspatthe\n",
      "schematiclevelratherthanthe9:clusterCost?clusterCost?fjpskqsearch\n",
      "spacelevel.Computingthesizeofthere-10:clusterCosts.append(clusterCost)\n",
      "returnmaxpclusterCostsqmainingsearchspacerequiresjusttheevaluationof\n",
      "asetofpolynomials.Inthissection,weintroduceoursamplingscheme,which\n",
      "addsRao-Blackwellisationtoliftedimportancesampling(LIS)(asdetailedin\n",
      "[9,10]).Technically,LISisaminormoofPTP,inwhichinsteadof\n",
      "searchingoverallpossibletruthassignmentstogroundatomsvialiftedcondi-\n",
      "tioning,thealgorithmgeneratesarandomtruthassignment(liftedsampling),\n",
      "andweighsitappropriatelytoyieldanunbiasedestimateofthepartitionfunc-\n",
      "tion.5.1Computingthesizeboundingfunction-GivenaschematicS?xVS,\n",
      "ES,vrytosample,weintroduceapreprocessingstepthatconstructsasize\n",
      "evaluationfunctionforeachvPVS.Algorithm4detailstheprocessofcreat-\n",
      "ingthefunctionforonenode.IttakesasinputtheschematicSrootedatv.It\n",
      "thetreedecompositionofS.Thealgorithmthenthedependent\n",
      "pathsineachcluster;,itappliesAlgorithm3toeachdependentpath\n",
      "andwrapstheresultingfunctionwiththevariabledependency.Itreturnsa\n",
      "listoflistof(variable,function)pairs.5.2ImportanceSamplingatliftedOr\n",
      "Nodes-ImportancesamplingatliftedOrnodesissimilartoitspropositional\n",
      "analogue.EachliftedOrnodeisnowspebyan8-tuplexR,?,?,i,c,t,\n",
      "Q,sfy,inwhichQistheproposaldistributionforpR,iq,andsfistheoutput\n",
      "ofAlgorithm4.Thesamplingalgorithmtakesanadditionalinput,cb,specify-\n",
      "ingthecomplexityboundforRao-Blackwellisation.GivenanorNodewheret\n",
      "?unknown,wecomputethecostofexactinference.Algorithm5describes\n",
      "theprocedure.Ittakesasinput(1)thelistoflistssfoutputbyAlgorithm4,\n",
      "and(2)thecountingstore,detailingthecountingassignmentsalreadymadeby\n",
      "thecurrentsample.Foreachsublistintheinputlist,thealgorithmevaluates\n",
      "each(variable,function)pairby(1)retrievingthelistofcurrentassignments\n",
      "fromthecountingstore,(2)evaluatingthefunctionforthedomainsizeofeach\n",
      "assignment,and(3)computingtheproductoftheresults.Eachofthesevalues\n",
      "representsaboundonthecostofinferenceforasinglecluster;Algorithm5\n",
      "returnsc,themaximumofthislist.Ifc??cbwecallevalNodepSq;otherwise\n",
      "wesampleassignmentifromQwithprobabilityqi,updatethecountingstore\n",
      "10\n",
      "\n",
      "withassignmenti,andcallsampleNodepS1q,whereS1isthechildschematic,\n",
      "yieldingestimatew?ofthepartitionfunctionofS1.Wethenreturn??S?\n",
      "qw?iastheestimateofthepartitionfunctionatS.5.3ImportanceSampling\n",
      "atliftedAndNodes-ImportancesamplingatliftedAndnodesfromits\n",
      "propositionalcounterpartinthatadecomposerlabelededgepA,Tqrepresents\n",
      "ddistributions7\n",
      "thatarenotonlyindependentbutalsoidentical.LetAbealiftedAndnode\n",
      "thatwewishtosample,withchildrenS1,...,Sk,withcorresponding\n",
      "decomposerlabelsd1...dk(foreachedgewithnodecomposerlabeltakedi\n",
      "?1).ThentheestimatorforthepartitionfunctionatAis:????A?iPt1..ku\n",
      "jPt1..diu?Ti.\n",
      "6\n",
      "ExperimentsTime(s)vsLogSampleVariance:Smooth-test.pdf2452\n",
      "0101001000\n",
      "24512450\n",
      "LogSampleVariance\n",
      "WeranourRao-BlackwellisedImportanceSampleronthreebenchmark\n",
      "SRMsanddatasets:(1)Thefriends,smokersandAsthmaMLNanddataset\n",
      "describedin[19],(2)ThewebKBMLNforcollectiveand(3)The\n",
      "ProteinMLN,inwhichthetaskistoinferproteininteractionsfrombiological\n",
      "data.Allmodelsareavailablefromwww.alchemy.cs.washington.edu.\n",
      "244924482447244624452444\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "Time(s)\n",
      "(a)FriendsandSmokers,Asthma2600objects,10%evidenceTime(s)vs\n",
      "LogSampleVariance:Smooth-test.pdf\n",
      "595\n",
      "0101001000\n",
      "594593\n",
      "LogSampleVariance\n",
      "Results.Figure2showsthesamplevarianceoftheestimatorsasafunction\n",
      "oftime.WeseethattheRao-Blackwellisedsamplerstypicallyhavesmaller\n",
      "variancethanLIS.However,increasingthecomplexityboundtypicallydoes\n",
      "notimprovethevarianceasafunctionoftime(butthevariancedoesimprove\n",
      "asafunctionofnumberofsamples).Ourresultsindicatethatthestructure\n",
      "ofthemodelplaysaroleindeterminingthemosttcomplexitybound\n",
      "forsampling.Ingeneral,modelswithlargedecomposers,especiallynearthe\n",
      "bottomoftheschematic,willbfromalargercomplexitybound,because\n",
      "itisoftenmoreienttoperformexactinferenceoveradecomposernode.\n",
      "2443\n",
      "592591590589588587586\n",
      "11\n",
      "\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "Time(s)\n",
      "(b)webKB410objects,10%evidenceTime(s)vsLogSampleVariance:Smooth-\n",
      "test.pdf\n",
      "1115\n",
      "0101001000\n",
      "1110\n",
      "LogSampleVariance\n",
      "Setup.Foreachmodel,weset10%randomlyselectedgroundatomsas\n",
      "evidence,anddesignatedthemtohaveTruevalue.Wethenestimatedthe\n",
      "partitionfunctionviaourRao-Blackwellisedsamplerwithcomplexitybounds\n",
      "t0,10,100,1000u(boundof0yieldstheLISalgorithm).Weusedtheuniform\n",
      "distributionasourproposal.Weraneachsampler50timesandcomputedthe\n",
      "samplevarianceoftheestimates.\n",
      "1105\n",
      "1100\n",
      "1095\n",
      "7\n",
      "ConclusionsandFutureWork\n",
      "10900\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "Time(s)\n",
      "(c)protein550objects,10%evidenceFigure2:Logvarianceasafunction\n",
      "oftime.\n",
      "Inthiswork,wehavepresentedaninference-awarerepresentationofSRMs\n",
      "basedontheAnd/Orframework.Usingthisframework,wehaveproposedan\n",
      "accurateandtmethodforboundingthecostofinferenceforthefamily\n",
      "ofliftedconditioningbasedalgorithms,suchasProbabilisticTheoremProving.\n",
      "GivenashatteredSRM,wehaveshownhowthemethodcanbeusedtoquickly\n",
      "identifytractablesubproblemsofthemodel.Wehavepresentedoneimmediate\n",
      "applicationoftheschemebydevelopingaRao-BlackwellisedLiftedImportance\n",
      "SamplingAlgorithm,whichusesourboundingschemeasavariancereducer.Ac-\n",
      "knowledgmentsWegratefullyacknowledgethesupportoftheDefenseAdvanced\n",
      "ResearchProjectsAgency(DARPA)ProbabilisticProgrammingforAdvanced\n",
      "MachineLearningProgramunderAirForceResearchLaboratory(AFRL)prime\n",
      "12\n",
      "\n",
      "contractno.FA8750-14-C-0005.Anyopinions,andconclusionsorrec-\n",
      "ommendationsexpressedinthismaterialarethoseoftheauthor(s)anddonot\n",
      "necessarilyttheviewofDARPA,AFRL,ortheUSgovernment.8\n",
      "2References\n",
      "[1]B.BidyukandR.Dechter.CutsetSamplingforBayesianNetworks.Journal\n",
      "ofIntelligenceResearch,28:1?48,2007.[2]RBraz,EyalAmir,and\n",
      "DanRoth.Liftedprobabilisticinference.InProceedingsofthe19th\n",
      "internationaljointconferenceonintelligence,pages1319?1325.Cite-\n",
      "seer,2005.[3]GeorgeCasellaandChristianPRobert.Rao-blackwellisation\n",
      "ofsamplingschemes.Biometrika,83(1):81?94,1996.[4]M.ChaviraandA.\n",
      "Darwiche.Onprobabilisticinferencebyweightedmodelcounting.\n",
      "Intelligence,172(6-7):772?799,2008.[5]LucDeRaedtandKristianKersting.\n",
      "Probabilisticinductivelogicprogramming.Springer,2008.[6]RinaDechter\n",
      "andRobertMateescu.And/orsearchspacesforgraphicalmodels.\n",
      "intelligence,171(2):73?106,2007.[7]MichaelR.GeneserethandEricKao.In-\n",
      "troductiontoLogic,SecondEdition.Morgan&ClaypoolPublishers,2013.\n",
      "[8]VibhavGogateandPedroDomingos.Exploitinglogicalstructureinlifted\n",
      "probabilisticinference.InStatisticalRelationalIntelligence,2010.\n",
      "[9]VibhavGogateandPedroDomingos.Probabilistictheoremproving.In\n",
      "ProceedingsoftheTwenty-SeventhConferenceAnnualConferenceonUncer-\n",
      "taintyinIntelligence(UAI11),pages256?265,Corvallis,Oregon,2011.\n",
      "AUAIPress.[10]VibhavGogate,AbhayKumarJha,andDeepakVenugopal.\n",
      "Advancesinliftedimportancesampling.InAAAI,2012.[11]AbhayJha,Vib-\n",
      "havGogate,AlexandraMeliou,andDanSuciu.Liftedinferenceseenfromthe\n",
      "otherside:Thetractablefeatures.InAdvancesinNeuralInformationProcess-\n",
      "ingSystems,pages973?981,2010.[12]BrianMilch,BhaskaraMarthi,Stuart\n",
      "Russell,DavidSontag,DanielLOng,andAndreyKolobov.Blog:Probabilistic\n",
      "modelswithunknownobjects.Statisticalrelationallearning,page373,2007.\n",
      "[13]M.Niepert.Liftedprobabilisticinference:AnMCMCperspective.In\n",
      "UAI2012WorkshoponStatisticalRelationalIntelligence,2012.[14]\n",
      "M.Niepert.Symmetry-awaremarginaldensityestimation.InTwenty-Seventh\n",
      "AAAIConferenceonIntelligence,pages725?731,2013.[15]David\n",
      "Poole.First-orderprobabilisticinference.InIJCAI,volume3,pages985?991.\n",
      "Citeseer,2003.[16]DavidPoole,FahiemBacchus,andJacekKisynski.To-\n",
      "wardscompletelyliftedsearch-basedprobabilisticinference.arXivpreprint\n",
      "arXiv:1107.4035,2011.[17]MatthewRichardsonandPedroDomingos.Markov\n",
      "logicnetworks.Machinelearning,62(12):107?136,2006.[18]T.Sang,P.Beame,\n",
      "andH.Kautz.SolvingBayesiannetworksbyweightedmodelcounting.InPro-\n",
      "ceedingsoftheTwentiethNationalConferenceonIntelligence,pages\n",
      "475?482,2005.[19]DanSuciu,AbhayJha,VibhavGogate,andAlexandraMe-\n",
      "liou.Liftedinferenceseenfromtheotherside:Thetractablefeatures.InNIPS,\n",
      "2010.[20]NimaTaghipour,JesseDavis,andHendrikBlockeel.First-order\n",
      "decompositiontrees.InAdvancesinNeuralInformationProcessingSystems,\n",
      "13\n",
      "\n",
      "pages1052?1060,2013.[21]GuyVandenBroeck,NimaTaghipour,Wannes\n",
      "Meert,JesseDavis,andLucDeRaedt.Liftedprobabilisticinferenceby\n",
      "orderknowledgecompilation.InProceedingsoftheTwentySecondinterna-\n",
      "tionaljointconferenceonIntelligence-VolumeVolumeThree,pages\n",
      "2178?2185.AAAIPress,2011.[22]DeepakVenugopalandVibhavGogate.\n",
      "Onliftingthegibbssamplingalgorithm.InAdvancesinNeuralInformation\n",
      "ProcessingSystems,pages1655?1663,2012.9\n",
      "14\n",
      "\n",
      "PP3664.pdf\n",
      "PP3664.pdf 12\n",
      "tRecoveryofJointlySparseVectors\n",
      "Authoredby:\n",
      "JiepingYe\n",
      "LiangSun\n",
      "JunLiu\n",
      "JianhuiChen\n",
      "Abstract\n",
      "Weconsiderthereconstructionofsparsesignalsinthemultiplemea-\n",
      "surementvector(MMV)model,inwhichthesignal,representedasama-\n",
      "trix,consistsofasetofjointlysparsevectors.MMVisanextension\n",
      "ofthesinglemeasurementvector(SMV)modelemployedinstandard\n",
      "compressivesensing(CS).Recenttheoreticalstudiesfocusontheconvex\n",
      "relaxationoftheMMVproblembasedonthe$(2,1)$-normminimization,\n",
      "whichisanextensionofthewell-known$1$-normminimizationemployed\n",
      "inSMV.However,theresultingconvexoptimizationprobleminMMVis\n",
      "tlymuchmoretosolvethantheoneinSMV.Existing\n",
      "algorithmsreformulateitasasecond-orderconeprogramming(SOCP)\n",
      "orprogramming(SDP),whichiscomputationallyexpensive\n",
      "tosolveforproblemsofmoderatesize.Inthispaper,weproposeanew\n",
      "(dual)reformulationoftheconvexoptimizationprobleminMMVandde-\n",
      "velopanientalgorithmbasedontheprox-method.Interestingly,our\n",
      "theoreticalanalysisrevealsthecloseconnectionbetweentheproposedre-\n",
      "formulationandmultiplekernellearning.Oursimulationstudiesdemon-\n",
      "stratethescalabilityoftheproposedalgorithm.\n",
      "1PaperBody\n",
      "Compressivesensing(CS),alsoknownascompressivesampling,hasrecently\n",
      "receivedincreasingattentioninmanyareasofscienceandengineering[3].In\n",
      "CS,anunknownsparsesignalisreconstructedfromasinglemeasurementvec-\n",
      "tor.Recenttheoreticalstudiesshowthatonecanrecovercertainsparsesignals\n",
      "fromfarfewersamplesormeasurementsthantraditionalmethods[4,8].Inthis\n",
      "paper,weconsidertheproblemofreconstructingsparsesignalsinthemultiple\n",
      "measurementvector(MMV)model,inwhichthesignal,representedasama-\n",
      "trix,consistsofasetofjointlysparsevectors.MMVisanextensionofthesingle\n",
      "measurementvector(SMV)modelemployedinstandardcompressivesensing.\n",
      "TheMMVmodelwasmotivatedbytheneedtosolvetheneuromagneticinverse\n",
      "1\n",
      "\n",
      "problemthatarisesinMagnetoencephalography(MEG),whichisamodality\n",
      "forimagingthebrain[7].Itarisesfromavarietyofapplications,suchasDNA\n",
      "microarrays[11],equalizationofsparsecommunicationchannels[6],echocancel-\n",
      "lation[9],magenetoencephalography[12],computingsparsesolutionstolinear\n",
      "inverseproblems[7],andsourcelocalizationinsensornetworks[17].Unlike\n",
      "SMV,thesignalintheMMVmodelisrepresentedasasetofjointlysparse\n",
      "vectorssharingtheircommonnonzerosoccurringinasetoflocations[5,7].It\n",
      "hasbeenshownthattheadditionalblock-sparsestructurecanleadtoimproved\n",
      "performanceinsignalrecovery[5,10,16,21].Severalrecoveryalgorithmshave\n",
      "beenproposedfortheMMVmodelinthepast[5,7,18,24,25].Sincethe\n",
      "sparserepresentationproblemisacombinatorialoptimizationproblemandis\n",
      "ingeneralNP-hard[5],thealgorithmsin[18,25]employthegreedystrategyto\n",
      "recoverthesignalusinganiterativescheme.Onealternativeistorelaxitinto\n",
      "aconvexoptimizationproblem,fromwhichthe1\n",
      "globaloptimalsolutioncanbeobtained.Themostwidelystudiedapproach\n",
      "istheonebasedonthe(2,1)-normminimization[5,7,10].Asimilarrelaxation\n",
      "technique(viathe1-normminimization)isemployedintheSMVmodel.Recent\n",
      "studieshaveshownthatmostoftheoreticalresultsontheconvexrelaxation\n",
      "oftheSMVmodelcanbeextendedtotheMMVmodel[5],althoughfurther\n",
      "theoreticalinvestigationisneeded[26].UnliketheSMVmodelwherethe1-\n",
      "normminimizationcanbesolvedtly,theresultingconvexoptimization\n",
      "probleminMMVismuchmoretosolve.Existingalgorithmsformulate\n",
      "itasasecond-orderconeprogramming(SOCP)orsemdeniteprogramming\n",
      "(SDP)[16]problem,whichcanbesolvedusingstandardsoftwarepackagessuch\n",
      "asSeDuMi[23].However,forproblemsofmoderatesize,solvingeitherSOCP\n",
      "orSDPiscomputationallyexpensive,whichlimitstheiruseinpractice.Inthis\n",
      "paper,wederiveadualreformulationofthe(2,1)-normminimizationproblem\n",
      "inMMV.Moreespecially,weshowthatthe(2,1)-normminimizationproblem\n",
      "canbereformulatedasamin-maxproblem,whichcanbesolvedtlyvia\n",
      "theprox-methodwithanearlydimensionindependentconvergencerate[19].\n",
      "Comparedwithexistingalgorithms,ouralgorithmcanscaletolargerproblems\n",
      "whileachievinghighaccuracy.Interestingly,ourtheoreticalanalysisrevealsthe\n",
      "closerelationshipbetweentheresultingmin-maxproblemandmultiplekernel\n",
      "learning[14].Wehaveperformedsimulationstudiesandourresultsdemonstrate\n",
      "thescalabilityoftheproposedalgorithmincomparisonwithexistingalgorithms.\n",
      "Notations:Allmatricesareboldfaceuppercase.Vectorsareboldfacelowercase.\n",
      "Setsandspacesaredenotedwithcalligraphicletters.Thep-normofthevector\n",
      "v=(v1,???,vd)T?IRdis?P?1dppaskvkp:=.The\n",
      "innerproductonIRm?disashX,Yi=tr(XTY).For|v|ii=1\n",
      "matrixA?IRm?d,wedenotebyaiandaitheithrowandtheithcolumnof\n",
      "A,respectively.The(r,p)-normofAisedas:?m!p1XkAkr,p:=kai\n",
      "kpr.(1)i=1\n",
      "2\n",
      "TheMultipleMeasurementVectorModel\n",
      "IntheSMVmodel,oneaimstorecoverthesparsesignalwfromamea-\n",
      "surementvectorb=AwforagivenmatrixA[3].TheSMVmodelcanbe\n",
      "2\n",
      "\n",
      "extendedtothemultiplemeasurementvector(MMV)model,inwhichthesig-\n",
      "nalisrepresentedasasetofjointlysparsevectorssharingacommonsetof\n",
      "nonzeros[5,7].TheMMVmodelaimstorecoverthesparserepresentations\n",
      "forSMVssimultaneously.IthasbeenshownthattheMMVmodelprovably\n",
      "improvesthestandardCSrecoverybyexploitingtheblock-sparsestructure[10,\n",
      "21].Sp,intheMMVmodelweconsiderthereconstructionofthesig-\n",
      "nalrepresentedbyamatrixW?IRd?n,whichisgivenbyadictionary(or\n",
      "measurementmatrix)A?IRm?dandmultiplemeasurementvectorB?IRm?n\n",
      "suchthatB=AW.\n",
      "(2)\n",
      "EachcolumnofAisassociatedwithanatom,andasetofatomiscalled\n",
      "adictionary.AsparserepresentationmeansthatthematrixWhasasmall\n",
      "numberofrowscontainingnonzeroentries.Usually,wehavem?dandd>n.\n",
      "SimilartoSMV,wecanusekWkp,0tomeasurethenumberofrowsinWthat\n",
      "containnonzeroentries.Thus,theproblemofthesparsestrepresentation\n",
      "ofthesignalWinMMVisequivalenttosolvingthefollowingproblem,a.k.a.\n",
      "thesparserepresentationproblem:(P0):\n",
      "minkWkp,0,W\n",
      "s.t.\n",
      "AW=B.\n",
      "(3)\n",
      "Sometypicalchoicesofpincludep=?andp=2[25].However,solving\n",
      "(P0)requiresenumeratingallsubsetsoftheset\n",
      "f\n",
      "1,2,???,d\n",
      "g\n",
      ",whichis\n",
      "essentiallyacombinatorialoptimizationproblemandisingeneralNP-hard[5].\n",
      "Similartotheuseofthe1-normminimizationintheSMVmodel,onenatural\n",
      "alternativeistousekWkp,1insteadofkWkp,0,resultinginthefollowingconvex\n",
      "optimizationproblem(P1):(P1):minkWkp,1,s.t.AW=B.(4)W\n",
      "2\n",
      "Therelationshipbetween(P0)and(P1)fortheMMVmodelhasbeenstud-\n",
      "iedin[5].Forp=2,theoptimalWisgivenbysolvingthefollowingconvex\n",
      "optimizationproblem:1minkWk22,1W2\n",
      "s.t.AW=B.\n",
      "(5)\n",
      "ExistingalgorithmsformulateEq.(5)asasecond-orderconeprogramming\n",
      "(SOCP)problemoraprogramming(SDP)problem[16].Recall\n",
      "thattheoptimizaitonprobleminEq.(5)isequivalenttothefollowingproblem\n",
      "byremovingthesquareintheobjective:1minkWk2,1W2\n",
      "s.t.AW=B.\n",
      "Byintroducingauxiliaryvariableti(i=1,???,d),thisproblemcanbe\n",
      "reformulatedinthestandardsecond-orderconeprogramming(SOCP)formula-\n",
      "tion:d\n",
      "min\n",
      "1Xti2i=1\n",
      "s.t.\n",
      "kWik2?ti,ti?0,i=1,???,d,\n",
      "W,t1,???,td\n",
      "3\n",
      "\n",
      "(6)AW=B.\n",
      "BasedonthisSOCPformulation,itcanalsobetransformedintothestan-\n",
      "dardprogramming(SDP)formulation:d\n",
      "min\n",
      "W,t1,???,td\n",
      "s.t.\n",
      "1Xti2i=1??TtiIWi?0,t?0,i=1,???,d,iWiti\n",
      "(7)AW=B.\n",
      "Theinteriorpointmethod[20]andthebundlemethod[13]canbeapplied\n",
      "tosolveSOCPandSDP.However,theydonotscaletoproblemsofmoderate\n",
      "size,whichlimitstheiruseinpractice.\n",
      "3\n",
      "TheProposedDualFormulation\n",
      "Inthissectionwepresentadualreformulationoftheoptimizationproblem\n",
      "inEq.(5).First,somepreliminaryresultsaresummarizedinLemmas1and\n",
      "2:Lemma1.LetAandXbem-by-dmatrices.Thenthefollowingholds:?1?\n",
      "hA,Xi?kXk22,1+kAk22,?.(8)2Whentheequalityholds,wehavekXk2,1\n",
      "=kAk2,?.PmiProof.Itfollowsfromtheofthe(r,p)-norminEq.\n",
      "(1)thatkXk2,1=i=1kxk2,ikandkAk2,?=max1?i?mkak2.Withoutloss\n",
      "ofgenerality,weassumethatkak2=max1?i?mkaik2for1?k?m.Thus,\n",
      "kAk2,?=kakk2,andwehavehA,Xi=\n",
      "mX\n",
      "T\n",
      "aixi?\n",
      "i=1\n",
      "?\n",
      "?\n",
      "1?k2kak2+2\n",
      "mX\n",
      "kaik2kxik2?\n",
      "i=1\n",
      "mX\n",
      "kakk2kxik2=kakk2\n",
      "i=1\n",
      "!2??1?kAk22,?+kXk22,1.kxik2?=2i=1\n",
      "?mX\n",
      "Clearly,thelastinequalitybecomesequalitywhenkXk2,1=kAk2,?.\n",
      "Lemma2.LetAandXbeasinLemma1.Thenthefollowingholds:?\n",
      "?112maxhA,Xi?kXk2,1=kAk22,?.X223\n",
      "mXi=1\n",
      "kxik2\n",
      "kProof.DenotethesetQ=\n",
      "f\n",
      "k:1?k?m,kak2=max1?i?mkaik2\n",
      "g\n",
      ".\n",
      "Let\n",
      "f\n",
      "?k\n",
      "g\n",
      "mk=1besuchPm/Q,?k?0fork?Q,andk=1?k=1.Clearly,\n",
      "allinequalitiesintheproofthat?k=0fork?ofLemma1becomeequalities\n",
      "ifandonlyifweconstructthematrixXasfollows:??kak,ifk?Qxk=(9)\n",
      "0,otherwise.\n",
      "4\n",
      "\n",
      "Thus,themaximumofhA,Xi?12kXk22,1is21kAk22,?,whichisachieved\n",
      "whenXisconstructedasinEq.(9).BasedontheresultsestablishedinLemmas\n",
      "1and2,wecanderivethedualformulationoftheoptimizationprobleminEq.\n",
      "(5)asfollows.FirstweconstructtheLagrangianL:11kWk22,1?hU,AW?\n",
      "Bi=kWk22,1?hU,AWi+hU,Bi.22Thedualproblemcanbeformulated\n",
      "asfollows:L(W,U)=\n",
      "1maxminkWk22,1?hU,AWi+hU,Bi.UW2\n",
      "(10)\n",
      "ItfollowsfromLemma2that????11122TminkWk2,1?hU,AWi\n",
      "=minkWk2,1?hAU,Wi=?kATUk22,?.WW222Notethatfrom\n",
      "Lemma2,theequalityholdsifandonlyiftheoptimalW?canberepresented\n",
      "asW?=diag(?)ATU,\n",
      "(11)\n",
      "where?=[?1,???,?d]T?IRd,?i?0ifk(ATU)ik2=kATUk2,?,?i\n",
      "=0ifk(ATU)ik2<PdkATUk2,?,andi=1?i=1.Thus,thedualproblem\n",
      "canbesimplintothefollowingform:1max?kATUk22,?+hU,Bi.U2\n",
      "(12)\n",
      "Followingtheofthe(2,?)-norm,wecanreformulatethedual\n",
      "probleminEq.(12)asamin-maxproblem,assummarizedinthefollowing\n",
      "theorem:Theorem1.TheoptimizationprobleminEq.(5)canbeformulated\n",
      "equivalentlyas:()ndX1XTTmaxujbj??iujGiuj,(13)Pdminu1,???\n",
      ",un2i=1i=1?i=1,?i?0j=1wherethematrixGiisasGi=aiaTi(1\n",
      "?i?d),andaiistheithcolumnofA.Proof.NotethatkATUk22,?canbe\n",
      "reformulatedasfollows:??kATUk22,?=maxkaTiUk22=max\n",
      "f\n",
      "tr(UTai\n",
      "aTiU)\n",
      "g\n",
      "=max\n",
      "f\n",
      "tr(UTGiU)\n",
      "g\n",
      "1?i?d\n",
      "=\n",
      "?i?0,\n",
      "1?i?d\n",
      "maxPd\n",
      "i=1\n",
      "dX?i=1\n",
      "1?i?d\n",
      "?itr(UTGiU).\n",
      "(14)\n",
      "i=1\n",
      "SubstitutingEq.(14)intoEq.(12),weobtainthefollowingproblem:d\n",
      "11Xmax?kATUk22,?+hU,Bi?maxPmin?itr(UTGiU).hU,Bi?\n",
      "dUU22i=1i=1?i=1,?i?0\n",
      "(15)\n",
      "SincetheSlater?scondition[2]isstheminimizationandmaximiza-\n",
      "tioninEq.(15)canbeexchanged,resultinginthemin-maxprobleminEq.\n",
      "(13).Corollary1.Let(??,U?)betheoptimalsolutiontoEq.(13)where?\n",
      "?=(?1?,???,?d?)T.If?i?>0,thenk(ATU?)ik2=kATU?k2,?.4\n",
      "BasedonthesolutiontothedualprobleminEq.(13),wecanconstructthe\n",
      "optimalsolutiontotheprimalprobleminEq.(5)asfollows.LetW?bethe\n",
      "optimalsolutionofEq.(5).ItfollowsfromLemma2thatwecanconstruct\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W?basedonATU?asinEq.(11).RecallthatW?mustsatisfytheequality\n",
      "constraintAW?=B.Themainresultissummarizedinthefollowingtheorem:\n",
      "Theorem2.GivenW?=diag(?)ATU?,where?=[?1,???,?d]?IRd\n",
      ",?i?0,?i>0onlyif??iPdkATU?k2=kATU?k2,?,andi=1?i=1.\n",
      "Then,AW?=Bifandonlyif(?,U?)istheoptimalsolutiontotheproblem\n",
      "inEq.(13).Proof.Firstweassumethat(?,U?)istheoptimalsolutionto\n",
      "theprobleminEq.(13).Itfollowsthatthepartialderivativeoftheobjective\n",
      "functionwithrespecttoU?inEq.(13)is0,thatis,B?Adiag(?)ATU?=0\n",
      "?AW?=B.NextweprovethereversedirectionbyassumingAW?=B.Since\n",
      "W?=diag(?)ATU?,wehave0=B?AW?=B?Adiag(?1,???,?d)AT\n",
      "U?.(16)thefunction?(?1,???,?d,U)as()dndX1X1XTTT\n",
      "?(?1,???,?d,U)=hU,Bi??itr(UGiU)=ujbj??iujGiuj.2i=12\n",
      "i=1j=1Weconsiderthefunction?(?1,???,?d,U)with?i=?i(1?\n",
      "i?d).NotethatthisfunctionisconcavewithrespecttoU,thusitsmaximum\n",
      "isachievedwhenitspartialderivativewithrespect??toUiszero.Itfollows\n",
      "fromEq.(16)that?UiszerowhenU=U?.Thus,wehave?U,?(?1,???,\n",
      "?d,U)??(?1,???,?d,U?).?WithaU=U,?(?1,???,?d,\n",
      "U?)isalinearcombinationof?i(1?i?d)as:d1X?(?1,???,?d,U?)\n",
      "=hU?,Bi??ik(ATU?)ik22.2i=1Bytheassumption,wehavek(ATU?\n",
      ")ik=kATU?k2,?,if?i>0.Thus,wehavedX?i=1,?i?0.?(?1,???,\n",
      "?d,U?)??(?1,???,?d,U?),??1,???,?dsatisfyingi=1\n",
      "Pd\n",
      "Therefore,foranyU,?1,???,?dsuchthati=1?i=1,?i?0,we\n",
      "have?(?1,???,?d,U)??(?1,???,?d,U?)??(?1,???,\n",
      "?d,U?),(17)whichimpliesthat(?1,???,?d,U?)isasaddlepoint\n",
      "ofthemin-maxprobleminEq.(13).Thus,(?,U?)istheoptimalsolution\n",
      "totheprobleminEq.(13).Theorem2showsthatwecanreconstructthe\n",
      "solutiontotheprimalproblembasedonthesolutiontothedualprobleminEq.\n",
      "(13).Itpavesthewayforthetimplementationbasedonthemin-max\n",
      "formulationinEq.(13).Inthispaper,theprox-method[19],whichisdiscussed\n",
      "indetailinthenextsection,isemployedtosolvethedualprobleminEq.(13).\n",
      "Aninterestingobservationisthattheresultingmin-maxprobleminEq.(13)is\n",
      "closelyrelatedtotheoptimizationprobleminmultiplekernellearning(MKL)\n",
      "[14].Themin-maxprobleminEq.(13)canbereformulatedas?n?X1TT\n",
      "maxujbj?ujGuj,(18)Pdminu1,???,un2i=1?i=1,?i?0j=1wherethe\n",
      "positive(kernel)matrixGisconstrainedasalinearcombinationof\n",
      "asetofonPdTdasG=i=1?iGi.basekernelsGi=aiaii=1\n",
      "TheformulationinEq.(18)connectstheMMVproblemtoMKL.Many\n",
      "talgorithms[14,22,27]havebeendevelopedinthepastforMKL,which\n",
      "canbeappliedtosolve(13).In[27],anextendedlevelsetmethodwasproposed\n",
      "tosolveMKL,whichwasshowntooutperformtheonebasedonthe\n",
      "linearprogrammingformulation[22].However,theextendedlevelsetmethod\n",
      "involvesalinearprogrammingineachiterationanditstheoreticalconvergence\n",
      "rateof?O(1/N)(Ndenotesthenumberofiterations)isslowerthanthe\n",
      "proposedalgorithmpresentedinthenextsection.5\n",
      "4\n",
      "6\n",
      "\n",
      "TheMainAlgorithm\n",
      "Weproposetoemploytheprox-method[19]tosolvethemin-maxformu-\n",
      "lationinEq.(13),whichhasatiableandconvex-concaveobjective\n",
      "function.Thealgorithmiscalled?MMVprox?.Theprox-methodisa\n",
      "ordermethod[1,19]whichisspecializedforsolvingthesaddlepointproblem\n",
      "andhasanearlydimension-independentconvergencerateofO(1/N)(Nde-\n",
      "notesthenumberofiterations).WeshowthateachiterationofMMVproxhas\n",
      "alowcomputationalcost,thusitscalestolarge-sizeproblems.Thekeyideais\n",
      "toconvertthemin-maxproblemtotheassociatedvariationalinequality(v.i.)\n",
      "problem,whichistheniterativelysolvedbyaseriesofv.i.problems.Letz=\n",
      "(?,U).TheprobleminEq.(13)isequivalenttothefollowingassociatedv.i.\n",
      "problem[19]:Findz?=(??,U?)?S:hF(z?),z?z?i?0,?z?S,S=X\n",
      "?Y,where\n",
      "(19)\n",
      "????(?,U),??(?,U)(20)???Uisanoperatorconstitutedbythe\n",
      "gradientof?(?,?),X=\n",
      "f\n",
      "??IRd:k?k1=1,?i?0\n",
      "g\n",
      ",andY=IRm?n.?\n",
      "F(z)=\n",
      "Insolvingthev.i.probleminEq.(19),onekeybuildingblockisthefollowing\n",
      "projectionproblem:??1??zi,zk22+h?Pz(?z)=argmink?z,z(21)\n",
      "??S2z?U)?U).?andz?Denote(??,U?)=Pz(??=(?,?=(?,wherez\n",
      "z).Itiseasytoverifythat1??2,??=argmink??(???)k2?2??Xand\n",
      "?U?=U?U.\n",
      "(22)(23)\n",
      "Following[19],wepresentthepseudocodeoftheproposedMMVproxal-\n",
      "gorithminAlgorithm1.Ineachiteration,wecomputetheprojection(21)\n",
      "sothatwt,sistlyclosetowt,s?1(controlledbytheparameter?).It\n",
      "hasbeenshownin[19]that,when???12L[LdenotestheLipschitzcon-\n",
      "tinuousconstantoftheoperatorF(?)],theinneriterationconvergeswithin\n",
      "twoiterations,i.e.,wt,2=wt,1alwaysholds.Moreover,Algorithm1hasa\n",
      "globaldimension-independentconvergencerateofO(1/N).Algorithm1The\n",
      "MMVproxAlgorithmInput:A,B,?,z0=(?0,U0),and?Output:?,Uand\n",
      "W.Stept(t?1):Setwt,0=zt?1andthesmallests=1,2,...such\n",
      "thatwt,s=Pzt?1(?F(wt,s?1)),kwt,s?wt,s?1k2??.Setzt=wt,sFinal\n",
      "Step:Set?=\n",
      "Pti=1\n",
      "t\n",
      "?i\n",
      ",U=\n",
      "Pti=1\n",
      "t\n",
      "Ui\n",
      ",W=diag(?)ATU.\n",
      "TimeComplexityItcostsO(dmn)toevaluatetheoperatorF(?)atagiven\n",
      "point.??inEq.(22)involvestheEuclideanprojectionontothesimplex[1],\n",
      "whichcanbesolvedinlineartime,i.e.,inO(d);andU?inEq.(23)canbe\n",
      "analyticallycomputedinO(mn)time.Recallthatateachiterationt,theinner\n",
      "7\n",
      "\n",
      "iterationisatmost2.Thus,thetimecomplexityforanygivenouteriteration\n",
      "isO(dmn).OuranalysisshowsthatMMVproxscalestolarge-sizeproblems.\n",
      "Incomparison,thesecond-ordermethodssuchasSOCPhaveamuchhigher\n",
      "complexityperiteration.Accordingto[15],theSOCPinEq.(6)costsO(d3\n",
      "(n+1)3)periteration.InMMV,distypicallylargerthanm.Inthiscase,\n",
      "theproposedMMVproxalgorithmhasamuchsmallercostperiterationthan\n",
      "SOCP.ThisexplainswhyMMVproxscalesbetterthanSOCP,asshowninour\n",
      "experimentsinthenextsection.6\n",
      "Table1:Theaveragedrecoveryresultsover10experiments(d=100,m=\n",
      "50,andn=80).Dataset12345678910MeanStd\n",
      "5\n",
      "pkW?Wpk2F/(dn)3.2723e-63.4576e-62.6971e-62.4099e-62.9611e-6\n",
      "2.5701e-62.0884e-62.3454e-62.6807e-62.7172e-62.7200e-64.1728e-7\n",
      "pkAWp?Bk2F/(mn)1.4467e-51.8234e-51.4464e-51.4460e-51.4463e-5\n",
      "1.4459e-51.4469e-51.4475e-51.4461e-51.4481e-51.4843e-51.1914e-6\n",
      "Experiments\n",
      "Inthissection,weconductsimulationstoevaluatetheproposedMMVprox\n",
      "algorithmintermsoftherecoveryqualityandscalability.ExperimentSetup\n",
      "Wegeneratedasetofsyntheticdatasets(byvaryingthevaluesofm,n,and\n",
      "d)forourexperiments:theentriesinA?IRm?dwereindependentlygenerated\n",
      "fromthestandardnormaldistributionN(0,1);W?IRd?n(thegroundtruthof\n",
      "therecoveryproblems)wasgeneratedintwosteps:(1)randomlyselectkrows\n",
      "withnonzeroentries;(2)randomlygeneratetheentriesofthosekrowsfromN\n",
      "(0,1).WedenotebyWpthesolutionobtainedfromtheproposedMMVprox\n",
      "algorithm.Ideally,WpshouldbeclosetoW.Ourexperimentswereperformed\n",
      "onaPCwithIntelCore2DuoT95002.6GCPUand4GRAM.Weemployedthe\n",
      "optimizationpackageSeDuMi[23]forsolvingtheSOCPformulation.Allcodes\n",
      "wereimplementedinMatlab.Inallexperiments,weterminateMMVproxwhen\n",
      "thechangeoftheconsecutiveapproximatesolutionsislessthan1e-6.Recovery\n",
      "QualityInthisexperiment,weevaluatetherecoveryqualityoftheproposed\n",
      "MMVproxalgorithm.WeappliedMMVproxonthedatasetsofsized=100,m\n",
      "=50,n=80,andreportedtheaveragedexperimentalresultspover10random\n",
      "repetitions.Wemeasuredptherecoveryqualityintermsofthemeansquared\n",
      "error:kW?Wpk2F/(dn).WealsoreportedkAWp?Bk2F/(mn),which\n",
      "measurestheviolationoftheconstraintinEq.(5).Theexperimentalresults\n",
      "arepresentedinTable1.WecanobservefromthetablethatMMVproxrecovers\n",
      "thesparsesignalsuccessfullyinallcases.Next,westudyhowtherecoveryerror\n",
      "changesasthesparsityofWvaries.Sp,weappliedMMVproxonthe\n",
      "datasetsofsized=100,m=400,andn=10withk(thenumberofnonzero\n",
      "prowsofW)varyingfrom0.05dto0.7d,andusedkW?Wpk2F/(dn)asthe\n",
      "recoveryqualitymeasure.Theaveragedexperimentalresultsover20random\n",
      "repetitionsarepresentedinFigure1.Wecanobservefromthethat\n",
      "MMVproxworkswellinallcases,andalargerk(lesssparseW)tendstoresult\n",
      "inalargerrecoveryerror.?6\n",
      "p\n",
      "kW?Wpk2F/(dn)\n",
      "8\n",
      "\n",
      "2\n",
      "x10\n",
      "1.510.500.05\n",
      "0.2\n",
      "0.35k/d\n",
      "0.5\n",
      "0.7\n",
      "Figure1:Theincreaseoftherecoveryerrorasthesparsityleveldecreases\n",
      "7\n",
      "ScalabilityInthisexperiment,westudythescalabilityoftheproposed\n",
      "MMVproxalgorithm.Wegeneratedacollectionofdatasetsbyvaryingm\n",
      "from10to200withastepsizeof10,andsettingn=2mandd=4mac-\n",
      "cordingly.WeappliedSOCPandMMVproxonthedatasetsandrecorded\n",
      "theircomputationtime.TheexperimentalresultsarepresentedinFigure2\n",
      "(a),wherethex-axiscorrespondstothevalueofm,andthey-axiscorresponds\n",
      "tolog(t),wheretdenotesthecomputationtime(inseconds).Wecanobserve\n",
      "fromthethatthecomputationtimeofbothalgorithmsincreasesasm\n",
      "increasesandSOCPisfasterthanMMVproxonsmallproblems(m?40);when\n",
      "m>40,MMVproxoutperformsSOCP;whenthevalueofmislarge(m>80),\n",
      "theSOCPformulationcannotbesolvedbySeDuMi,whileMMVproxcanstill\n",
      "beapplied.Thisexperimentalresultdemonstratesthegoodscalabilityofthe\n",
      "proposedMMVproxalgorithmincomparisonwiththeSOCPformulation.108\n",
      "4SOCPMMVprox\n",
      "0\n",
      "log(t)\n",
      "6\n",
      "log(t)\n",
      "SOCPMMVprox\n",
      "2\n",
      "42\n",
      "?2?4?6\n",
      "0\n",
      "?8\n",
      "?2\n",
      "?10\n",
      "50\n",
      "100m\n",
      "150\n",
      "200\n",
      "(a)\n",
      "50\n",
      "100m\n",
      "150\n",
      "200\n",
      "(b)\n",
      "9\n",
      "\n",
      "Figure2:ScalabilitycomparisonofMMVproxandSOCP:(a)thecompu-\n",
      "tationtimeforbothalgorithmsastheproblemsizevaries;and(b)theaverage\n",
      "computationtimeofeachiterationforbothalgorithmsastheproblemsize\n",
      "varies.Thex-axisdenotesthevalueofm,andthey-axisdenotesthecomputa-\n",
      "tiontimeinseconds(inlogscale).\n",
      "Tofurtherexaminethescalabilityofbothalgorithms,wecomparetheexe-\n",
      "cutiontimeofeachiterationforbothSOCPandtheproposedalgorithm.We\n",
      "usethesamesettingasinthelastexperiment,i.e.,n=2m,d=4m,andm\n",
      "rangesfrom10to200withastepsizeof10.ThetimecomparisonofSOCP\n",
      "andMMVproxispresentedinFigure2(b).WeobservethatMMVproxhasa\n",
      "tlylowercostthanSOCPineachiteration(notethatSOCPisnotap-\n",
      "plicableform>80).ThisisconsistentwithourcomplexityanalysisinSection\n",
      "4.WecanobservefromFigure2thatwhenmissmall,thecomputationtime\n",
      "ofSOCPandMMVproxiscomparable,althoughMMVproxismuchfasterin\n",
      "eachiteration.ThisisbecauseMMVproxisamethod,whichhasa\n",
      "slowerconvergenceratethanthesecond-ordermethodSOCP.Thus,thereisa\n",
      "betweenscalabilityandconvergencerate.Ourexperimentsshowthe\n",
      "advantageofMMVproxforlarge-sizeproblems.\n",
      "6ConclusionsInthispaper,weconsiderthe(2,1)-normminimizationfor\n",
      "thereconstructionofsparsesignalsinthemultiplemeasurementvector(MMV)\n",
      "model,inwhichthesignalconsistsofasetofjointlysparsevectors.Exist-\n",
      "ingalgorithmsformulateitassecond-orderconeprogrammingor\n",
      "programming,whichiscomputationallyexpensivetosolveforproblemsofmod-\n",
      "eratesize.Inthispaper,weproposeanequivalentdualformulationforthe(2,\n",
      "1)-normminimizationintheMMVmodel,anddeveloptheMMVproxalgo-\n",
      "rithmforsolvingthedualformulationbasedontheproxmethod.Inaddition,\n",
      "ourtheoreticalanalysisrevealsthecloseconnectionbetweentheproposeddual\n",
      "formulationandmultiplekernellearning.Oursimulationstudiesdemonstrate\n",
      "theenessoftheproposedalgorithmintermsofrecoveryqualityand\n",
      "scalability.Inthefuture,weplantocompareexistingsolversformultipleker-\n",
      "nellearning[14,22,27]withtheproposedMMVproxalgorithm.Inaddition,\n",
      "weplantoexaminetheoftheprox-methodforsolvingvariousMKL\n",
      "formulations.\n",
      "AcknowledgementsThisworkwassupportedbyNSFIIS-0612069,IIS-0812551,\n",
      "CCF-0811790,NIHR01-HG002516,NGAHM1582-08-1-0016,andNSFC60905035.\n",
      "8\n",
      "2References\n",
      "[1]A.Ben-TalandA.Nemirovski.Non-Euclideanrestrictedmemorylevel\n",
      "methodforlarge-scaleconvexoptimization.MathematicalProgramming,102(3):407?56,\n",
      "2005.[2]S.BoydandL.Vandenberghe.ConvexOptimization.Cambridge\n",
      "UniversityPress,Cambridge,UK,2004.[3]E.Cand`es.Compressivesam-\n",
      "pling.InInternationalCongressofMathematics,number3,pages1433?1452,\n",
      "Madrid,Spain,2006.[4]E.Cand`es,J.Romberg,andT.Tao.Robustun-\n",
      "10\n",
      "\n",
      "certaintyprinciples:exactsignalreconstructionfromhighlyincompletefre-\n",
      "quencyinformation.IEEETransactionsonInformationTheory,52(2):489?509,\n",
      "2006.[5]J.ChenandX.Huo.Theoreticalresultsonsparserepresentations\n",
      "ofmultiple-measurementvectors.IEEETransactionsonSignalProcessing,\n",
      "54(12):4634?4643,2006.[6]S.F.CotterandB.D.Rao.Sparsechannelestima-\n",
      "tionviamatchingpursuitwithapplicationtoequalization.IEEETransactions\n",
      "onCommunications,50(3):374?377,2002.[7]S.F.Cotter,B.D.Rao,Kjersti\n",
      "Engan,andK.Kreutz-Delgado.Sparsesolutionstolinearinverseproblems\n",
      "withmultiplemeasurementvectors.IEEETransactionsonSignalProcessing,\n",
      "53(7):2477?2488,2005.[8]D.L.Donoho.Compressedsensing.IEEETransac-\n",
      "tionsonInformationTheory,52(4):1289?1306,2006.[9]D.L.Duttweiler.Pro-\n",
      "portionatenormalizedleast-mean-squaresadaptationinechocancelers.IEEE\n",
      "TransactionsonSpeechandAudioProcessing,8(5):508?518,2000.[10]Y.C.\n",
      "EldarandM.Mishali.Robustrecoveryofsignalsfromastructuredunionof\n",
      "subspaces.ToAppearinIEEETransactionsonInformationTheory,2009.[11]\n",
      "S.EricksonandC.Sabatti.Empiricalbayesestimationofasparsevectorof\n",
      "geneexpressionchanges.StatisticalApplicationsinGeneticsandMolecular\n",
      "Biology,4(1):22,2008.[12]I.F.Gorodnitsky,J.S.George,andB.D.Rao.Neu-\n",
      "romagneticsourceimagingwithfocuss:arecursiveweightedminimumnorm\n",
      "algorithm.ElectroencephalographyandClinicalNeurophysiology,95(4):231?\n",
      "251,1995.[13]H.Jean-BaptisteandC.Lemarechal.ConvexAnalysisand\n",
      "MinimizationAlgorithmsI:Fundamentals(GrundlehrenDerMathematischen\n",
      "Wissenschaften).Springer,Berlin,1993.[14]G.R.G.Lanckriet,N.Cristianini,\n",
      "P.Bartlett,L.ElGhaoui,andM.I.Jordan.Learningthekernelmatrixwith\n",
      "programming.JouranlofMachineLearningResearch,5:27?72,\n",
      "2004.[15]M.Lobo,L.Vandenberghe,S.Boyd,andH.Lebret.Applicationsof\n",
      "second-orderconeprogramming.LinearAlgebraanditsApplications,284(1-\n",
      "3):193?228,1998.[16]F.ParvareshM.StojnicandB.Hassibi.Onthere-\n",
      "constructionofblock-sparsesignalswithanoptimalnumberofmeasurements.\n",
      "CoRR,2008.[17]D.Malioutov,M.Cetin,andA.Willsky.Sourcelocaliza-\n",
      "tionbyenforcingsparsitythroughalaplacian.InIEEEWorkshoponStatis-\n",
      "ticalSignalProcessing,pages553?556,2003.[18]M.MishaliandY.C.Eldar.\n",
      "Reduceandboost:Recoveringarbitrarysetsofjointlysparsevectors.IEEE\n",
      "TransactionsonSignalProcessing,56(10):4692?4702,2008.[19]A.Nemirovski.\n",
      "Prox-methodwithrateofconvergenceo(1/t)forvariationalinequalitieswith\n",
      "Lipschitzcontinuousmonotoneoperatorsandsmoothconvex-concavesaddle\n",
      "pointproblems.SIAMJournalonOptimization,15(1):229?251,2005.[20]\n",
      "Y.E.NesterovandA.S.Nemirovskii.Interior-pointPolynomialAlgorithmsin\n",
      "ConvexProgramming.SIAMPublications,Philadelphia,PA,1994.[21]M.\n",
      "DuarteR.G.Baraniuk,V.CevherandC.Hegde.Model-basedcompressive\n",
      "sensing.SubmittedtoIEEETransactionsonInformationTheory,2008.[22]\n",
      "S.Sonnenburg,G.R?atsch,C.Sch?afer,andB.Sch?olkopf.Largescalemulti-\n",
      "plekernellearning.JournalofMachineLearningResearch,7:1531?1565,2006.\n",
      "[23]J.F.Sturm.Usingsedumi1.02,aMATLABtoolboxforoptimizationover\n",
      "symmetriccones.OptimizationMethodsandSoftware,11(12):625?653,1999.\n",
      "[24]J.A.Tropp.Algorithmsforsimultaneoussparseapproximation.PartII:\n",
      "11\n",
      "\n",
      "Convexrelaxation.SignalProcessing,86(3):589?602,2006.[25]J.A.Tropp,\n",
      "A.C.Gilbert,andM.J.Strauss.Algorithmsforsimultaneoussparseapproxi-\n",
      "mation.PartI:Greedypursuit.SignalProcessing,86(3):572?588,2006.[26]\n",
      "E.vandenBergandM.P.Friedlander.Joint-sparserecoveryfrommultiple\n",
      "measurements.TechnicalReport,DepartmentofComputerScience,University\n",
      "ofBritishColumbia,2009.[27]Z.Xu,R.Jin,I.King,andM.R.Lyu.Anex-\n",
      "tendedlevelmethodfortmultiplekernellearning.InAdvancesinNeural\n",
      "InformationProcessingSystems,pages1825?1832,2008.\n",
      "9\n",
      "12\n",
      "\n",
      "PP6495.pdf\n",
      "PP6495.pdf 13\n",
      "Sortingouttypicalitywiththeinversemoment\n",
      "matrixSOSpolynomial\n",
      "Authoredby:\n",
      "EdouardPauwels\n",
      "JeanB.Lasserre\n",
      "Abstract\n",
      "Westudyasurprisingphenomenonrelatedtotherepresentationof\n",
      "acloudofdatapointsusingpolynomials.Westartwiththepreviously\n",
      "unnoticedempiricalobservationthat,givenacollection(acloud)ofdata\n",
      "points,thesublevelsetsofacertaindistinguishedpolynomialcapturethe\n",
      "shapeofthecloudveryaccurately.Thisdistinguishedpolynomialisa\n",
      "sum-of-squares(SOS)derivedinasimplemannerfromtheinverseofthe\n",
      "empiricalmomentmatrix.Infact,thisSOSpolynomialisdirectlyrelated\n",
      "toorthogonalpolynomialsandthefunction.Thisallowsto\n",
      "generalizeandinterpretextremalitypropertiesoforthogonalpolynomials\n",
      "andtoprovideamathematicalrationalefortheobservedphenomenon.\n",
      "Amongdiversepotentialapplications,weillustratetherelevanceofour\n",
      "resultsonanetworkintrusiondetectiontaskforwhichweobtainperfor-\n",
      "mancessimilartoexistingdedicatedmethodsreportedintheliterature.\n",
      "1PaperBody\n",
      "Capturingandsummarizingtheglobalshapeofacloudofpointsisattheheart\n",
      "ofmanydataprocessingapplicationssuchasnoveltydetection,outlierdetection\n",
      "aswellasrelatedunsupervisedlearningtaskssuchasclusteringanddensityes-\n",
      "timation.Oneofthemainistoaccountforpotentiallycomplicated\n",
      "shapesinmultidimensionalspaces,orequivalentlytoaccountfornonstandard\n",
      "dependencerelationsbetweenvariables.Suchrelationsbecomecriticalinap-\n",
      "plications,forexampleinfrauddetectionwhereafraudulentactionmaybethe\n",
      "dishonestcombinationofseveralactions,eachofthembeingreasonablewhen\n",
      "consideredontheirown.Accountingforcomplicatedshapesisalsorelatedto\n",
      "computationalgeometryandnonlinearalgebraapplications,forexampleinte-\n",
      "gralcomputation[11]andreconstructionofsetsfrommomentsdata[6,7,12].\n",
      "Someoftheseproblemshaveconnectionsandpotentialapplicationsinmachine\n",
      "learning.Theworkpresentedinthispaperbringstogetherideasfromboth\n",
      "disciplines,leadingtoamethodwhichallowstoencodeinasimplemanner\n",
      "theglobalshapeandspatialconcentrationofpointswithinacloud.Westart\n",
      "1\n",
      "\n",
      "withasurprising(andapparentlyunnoticed)empiricalobservation.Givena\n",
      "collectionofpoints,onemaybuildupadistinguishedsum-of-squares(SOS)\n",
      "polynomialwhosecots(orGrammatrix)istheinverseoftheempirical\n",
      "momentmatrix(seeSection3).Itsdegreedependsonhowmanymomentsare\n",
      "considered,achoicelefttotheuser.Remarkablyitssublevelsetscapturemuch\n",
      "oftheglobalshapeofthecloudasillustratedinFigure3.Thisphenomenon\n",
      "isnotincidentalasillustratedinmanyadditionalexamplesinAppendixA.To\n",
      "thebestofourknowledge,thisobservationhasremainedunnoticedandthe\n",
      "purposeofthispaperistoreportthisempiricaltothemachinelearning\n",
      "communityandprovideelementstowardamathematicalunderstanding\n",
      "aswellaspotentialmachinelearningapplications.30thConferenceonNeural\n",
      "InformationProcessingSystems(NIPS2016),Barcelona,Spain.\n",
      "14637067380\n",
      "30670\n",
      "3067673800146370\n",
      "35\n",
      "138106860\n",
      "3570\n",
      "1850\n",
      "950460\n",
      "340\n",
      "210\n",
      "333\n",
      "8010\n",
      "13\n",
      "7018509581006860\n",
      "333340\n",
      "3015\n",
      "138\n",
      "10\n",
      "35706860\n",
      "185\n",
      "0\n",
      "950\n",
      "Figure1:Left:1000pointsinR2andthelevelsetsofthecorresponding\n",
      "inversemomentmatrixSOSpolynomialQ?,d(d=4).Thelevelsetp+dd,\n",
      "whichcorrespondstotheaveragevalueofQ?,d,isrepresentedinred.Right:\n",
      "1040pointsinR2withsizeandcolorproportionaltothevalueofinversemo-\n",
      "mentmatrixSOSpolynomialQ?,d(d=8).Theproposedmethodisbased\n",
      "onthecomputationofthecotsofaverysppolynomialwhichde-\n",
      "pendssolelyontheempiricalmomentsassociatedwiththedatapoints.From\n",
      "apracticalperspective,thiscanbedoneviaasinglepassthroughthedata,or\n",
      "eveninanonlinefashionviaasequenceoftWoodburyupdates.Fur-\n",
      "thermorethecomputationalcostofevaluatingthepolynomialdoesnotdepend\n",
      "onthenumberofdatapointswhichisacrucialwithexistingnon-\n",
      "parametricmethodssuchasnearestneighborsorkernelbasedmethods[3].On\n",
      "2\n",
      "\n",
      "theotherhand,thiscomputationrequirestheinversionofamatrixwhosesize\n",
      "dependsonthedimensionoftheproblem(seeSection3).Therefore,thepro-\n",
      "posedframeworkissuitedformoderatedimensionsandpotentiallyverylarge\n",
      "numberofobservations.InSection4wedescribeaninvarianceresult\n",
      "whichsuggeststhatthedistinguishedSOSpolynomialcapturesveryintrinsic\n",
      "propertiesofcloudsofpoints.Inasecondstep,weprovideamathematical\n",
      "interpretationthatsupportsourempiricalbasedonconnectionswith\n",
      "orthogonalpolynomials[5].Weproposeageneralizationofawellknownex-\n",
      "tremalityresultfororthogonalunivariatepolynomialsontherealline(orthe\n",
      "complexplane)[16,Theorem3.1.2].Asaconsequence,thedistinguishedSOS\n",
      "polynomialofinterestinthispaperisunderstoodastheuniqueoptimalsolution\n",
      "ofaconvexoptimizationproblem:minimizinganaveragevalueoverastruc-\n",
      "turedsetofpositivepolynomials.Inaddition,werevisit[16,Theorem3.5.6]\n",
      "abouttheChelfunction.Themathematicsbehindprovideasimpleand\n",
      "intuitiveexplanationforthephenomenonthatweempiricallyobserved.Finally,\n",
      "inSection5weperformnumericalexperimentsonKDDcupnetworkintrusion\n",
      "dataset[13].EvaluationofthedistinguishedSOSpolynomialprovidesascore\n",
      "thatweuseasameasureofoutlyingnesstodetectnetworkintrusions(assuming\n",
      "thattheycorrespondtooutlierobservations).Wereferthereaderto[3]fora\n",
      "discussionofavailablemethodsforthistask.Forthesakeofafaircomparison\n",
      "wehavereproducedtheexperimentsperformedin[18]forthesamedataset.\n",
      "Wereportresultssimilarto(andsometimesbetterthan)thosedescribedin[18]\n",
      "whichsuggeststhatthemethodiscomparabletootherdedicatedapproaches\n",
      "fornetworkintrusiondetection,includingrobustestimationandMahalanobis\n",
      "distance[8,10],mixturemodels[14]andrecurrentneuralnetworks[18].\n",
      "2\n",
      "Multivariatepolynomials,momentsandsumsofsquares\n",
      "Notations:Wetheambientdimensiontobepthroughoutthetext.For\n",
      "example,wewillmanipulatevectorsinRpaswellasp-variatepolynomialswith\n",
      "realcoets.WedenotebyXasetofpvariablesX1,...,Xpwhichwewill\n",
      "useinmathematicalexpressionsgpolynomials.Weidentifymonomials\n",
      "fromthecanonicalbasisofp-variatepolynomialswiththeirexponentsin?p?1\n",
      "?2p?Np:weassociatePpto?=(?i)i=1...p?NthemonomialX:=X1\n",
      "X2...Xpwhichdegreeisdeg(?):=i=1?i.Weusetheexpressions<gl\n",
      "and?gltodenotethegradedlexicographicorder,awellorderingoverp-variate\n",
      "monomials.Thisamountsto,usethecanonicalorderonthe2\n",
      "degreeand,second,breaktiesinmonomialswiththesamedegreeusingthe\n",
      "lexicographicorderwithX1=a,X2=b...Forexample,themonomialsin\n",
      "twovariablesX1,X2,ofdegreelessorequalto3listedinthisorderaregiven\n",
      "by:1,X1,X2,X12,X1X2,X22,X13,X12X2,X1X22,X23.Wedenote\n",
      "byNpd,theset\n",
      "f\n",
      "??Np;deg(?)?d\n",
      "g\n",
      "orderedby?gl.R[X]denotesthesetof\n",
      "p-variatepolynomials:linearcombinationsofmonomialswithrealcots.\n",
      "Thedegreeofapolynomialisthehighestofthedegreesofitsmonomialswith\n",
      "nonzerocots1.Weusethesamenotation,deg(?),todenotethedegree\n",
      "ofapolynomialorofanelementofNp.Ford?N,Rd[X]denotesthesetof\n",
      "p-variatepolynomialsofdegreelessorequaltod.Wesets(d)=p+dd,the\n",
      "3\n",
      "\n",
      "numberofmonomialsofdegreelessorequaltod.Wewilldenotebyvd(X)the\n",
      "vectorofmonomialsofdegreelessorequaltodsortedby?gl.Weletvd(X)\n",
      ":=(X?)??Np?Rd[X]s(d).Withthisnotation,dwecanwriteapolynomial\n",
      "P?Rd[X]asfollowsP(X)=hp,vd(X)iforsomerealvectorofcotsp\n",
      "=(p?)??Np?Rs(d)orderedusing?gl.Givenx=(xi)i=1...p?Rp,P(x)\n",
      "denotesdtheevaluationofPwiththeassignmentsX1=x1,X2=x2,...\n",
      "Xp=Rxp.GivenaBorelprobabilitymeasure?and??Np,y?(?)denotes\n",
      "themoment?of?:y?(?)=Rpx?d?(x).Throughoutthepaper,wewill\n",
      "onlyconsidermeasuresofwhichallmomentsareMomentmatrix:Given\n",
      "aBorelprobabilitymeasure?onRp,themomentmatrixof?,Md(?),isa\n",
      "matrixindexedbymonomialsofdegreeatmostdorderedby?gl.For?,??\n",
      "Npd,thecorrespondingentryinMd(?)isbyMd(?)?,?:=y?+?(?),\n",
      "themoment?+?of?.Whenp=2,lettingy?=y?(?)for??N24,we\n",
      "have\n",
      "M2(?):\n",
      "1X1X2X12X1X2X22\n",
      "1\n",
      "X1\n",
      "X2\n",
      "X12\n",
      "X1X2\n",
      "1y10y01y20y11y02\n",
      "y10y20y11y30y21y12\n",
      "y01y11y02y21y12y03\n",
      "y20y30y21y40y31y22\n",
      "y11y21y12y31y22y13\n",
      "X22y02y12y03.y22y13y04\n",
      "Md(?)ispositivesforalld?N.Indeed,foranyRp?Rs(d),let\n",
      "P?Rd[X]bethepolynomialwithvectorofcotsp,wehavepTMd(?)p\n",
      "=RpP2(x)d?(x)?0.Furthermore,RwehavetheidentityMd(?)=Rpvd\n",
      "(x)vd(x)Td?(x)wheretheintegralisunderstoodelementwise.Sumofsquares\n",
      "(SOS):Wedenoteby?[X]?R[X](resp.?d[X]?Rd[X]),thesetofpolynomials\n",
      "(resp.polynomialsofdegreeatmostd)whichcanbewrittenasasumofsquares\n",
      "ofpolynomials.LetP?R2m[X]forsomem?N,thenPbelongsto?2m[X]P\n",
      "ifthereexistsaJ?NandafamilyofpolynomialsPj?Rm[X],j?J,such\n",
      "thatP=j?JPj2.Itisobviousthatsumofsquarespolynomialsarealways\n",
      "nonnegative.Afurtherinterestingpropertyisthatthisclassofpolynomialsis\n",
      "connectedwithpositivesemi.Indeed,Pbelongsto?2m[X]ifand\n",
      "onlyif?Q?Rs(m)?s(m),Q0,P(x)=vd(x)TQvd(x),?x?Rp.Asa\n",
      "consequence,everypositivematrixQ?R?2m[X]byusingthe\n",
      "representationin(1).\n",
      "3\n",
      "s(m)?s(m)\n",
      "(1)\n",
      "apolynomialin\n",
      "EmpiricalobservationsontheinversemomentmatrixSOSpolynomial\n",
      "4\n",
      "\n",
      "Theinversemoment-matrixSOSpolynomialisassociatedtoameasure?\n",
      "whichthefollowing.Assumption1?isaBorelprobabilitymeasureon\n",
      "RpwithallitsmomentsandMd(?)ispositiveforagivend?N.\n",
      "1Let?,dsatisfyAssumption1.WecalltheSOSpolynomialQ?,d?\n",
      "?2d[X]bytheapplication:x7?\n",
      "Q?,d(x):=vd(x)TMd(?)?1vd(x),\n",
      "1\n",
      "x?Rp,\n",
      "(2)\n",
      "Forthenullpolynomial,weusetheconventionthatitsdegreeis0anditis\n",
      "?glsmallerthanallothermonomials.\n",
      "3\n",
      "theinversemoment-matrixSOSpolynomialofdegree2dassociatedto?.\n",
      "Actually,connectiontoorthogonalpolynomialswillshowthattheinversefunc-\n",
      "tionx7?Q?,d(x)?1iscalledthefunctionintheliterature[16,5]\n",
      "(seealsoSection4).Intheremainderofthissection,wefocusonthesituation\n",
      "when?correspondstoanempiricalmeasurePovernpointsinRpwhichare\n",
      "Soletx1,...,xn?Rpbeasetofpointsandletn1?:=ni=1\n",
      "?xiwhere?xcorrespondstotheDiracmeasureatx.Insuchacasethepolyno-\n",
      "mialQ?,din(2)isdeterminedonlybytheempiricalmomentsuptodegree2d\n",
      "ofourcollectionofpoints.NotethatwealsorequirethatMd(?)0.Inother\n",
      "words,thepointsx1,...,xndonotbelongtoanalgebraicsetbya\n",
      "polynomialofdegreelessorequaltod.Wedescribeempiricalpropertiesof\n",
      "inversemomentmatrixSOSpolynomialinthiscontextofempiricalmeasures.\n",
      "Amathematicalintuitionandfurtherpropertiesbehindtheseobservationsare\n",
      "developpedinSection4.3.1\n",
      "Sublevelsets\n",
      "Thestartingpointofourinvestigationsisthefollowingphenomenonwhichto\n",
      "thebestofourknowledgehasremainedunnoticedintheliterature.Forthesake\n",
      "ofclarityandsimplicityweprovideanillustrationintheplane.Considerthe\n",
      "followingexperimentinR2forad?N:representonthesamegraphic,the\n",
      "cloudofpoints\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1...nandthesublevelsetsofSOSpolynomialQ?,dinR2\n",
      "(equivalently,thesuperlevelsetsofthefunction).Thisisillustrated\n",
      "intheleftpanelofFigure3.Thecollectionofpointsconsistsof500simulations\n",
      "oftwotGaussiansandthevalueofdis4.Thestrikingfeatureofthis\n",
      "plotisthatthelevelsetscapturetheglobalshapeofthecloudofpointsquite\n",
      "accurately.Inparticular,thelevelset\n",
      "f\n",
      "x:Q?,d(x)?p+dd\n",
      "g\n",
      "capturesmost\n",
      "ofthepoints.Wecouldreproduceverysimilarobservationsontshapes\n",
      "withvariousnumberofpointsinR2anddegreed(seeAppendixA).3.2\n",
      "Measuringoutlyingness\n",
      "AnadditionalremarkinasimilarlineisthatQ?,dtendstotakehighervalues\n",
      "onpointswhichareisolatedfromotherpoints.IndeedintheleftpanelofFigure\n",
      "3,thevalueofthepolynomialtendstobesmallerontheboundaryofthecloud.\n",
      "Thisextendstosituationswherethecollectionofpointscorrespondtoshape\n",
      "withahighdensityofpointswithafewadditionaloutliers.Wereproduce\n",
      "asimilarexperimentontherightpanelofFigure3.Inthisexample,1000\n",
      "5\n",
      "\n",
      "pointsaresampledclosetoaringshapeand40additionalpointsaresampled\n",
      "uniformlyonalargersquare.WedonotrepresentthesublevelsetsofQ?,dhere.\n",
      "Instead,thecolorandshapeofthepointsaretakenproportionallytothevalue\n",
      "ofQ?,d,withd=8.First,theresultstheobservationoftheprevious\n",
      "paragraph,pointsthatfallclosetotheringshapetendtobesmallerandpoints\n",
      "ontheboundaryoftheringshapearelarger.Second,thereisaclearincrease\n",
      "inthesizeofthepointsthatarerelativelyfarawayfromtheringshape.This\n",
      "highlightthefactthatQ?,dtendstotakehighervalueinlesspopulatedareas\n",
      "ofthespace.3.3\n",
      "Relationtomaximumlikelihoodestimation\n",
      "Ifwed=1,werecoverthemaximumPnlikelihoodestimationPnfor\n",
      "theGaussian,uptoaconstantadditivefactor.Toseethis,set?=n1i=1\n",
      "xiandS=n1i=1xixTi.Withthisnotation,wehavethefollowingblock\n",
      "representationofthemomentmatrix,\n",
      "1+?TV?1???TV?11?T?1Md(?)=Md(?)=,?S?V?1?V?1\n",
      "whereV=S???Tistheempiricalcovariancematrixandtheexpressionforthe\n",
      "inverseisgivenbySchurcomplement.Inthiscase,wehaveQ?,1(x)=1+(x?\n",
      "?)TV?1(x??)forallx?Rp.Werecognizethequadraticformthatappears\n",
      "inthedensityfunctionofthemultivariateGaussianwithparametersestimated\n",
      "bymaximumlikelihood.ThissuggestsaconnectionbetweentheinverseSOS\n",
      "momentpolynomialandmaximumlikelihoodestimation.Unfortunately,this\n",
      "connectionistogeneralizeforhighervaluesofdandwedonotpur-\n",
      "suetheideaofinterpretingtheempiricalobservationsofthissectionthrough\n",
      "theprismofmaximumlikelihoodestimationandleaveitforfurtherresearch.\n",
      "Instead,weproposeanalternativeviewinSection4.4\n",
      "3.4\n",
      "Computationalaspects\n",
      "Recallthats(d)=p+disthenumberofp-variatemonomialsofdegree\n",
      "uptod.ThecomputationdofQ?,drequiresO(ns(d)2)operationsforthe\n",
      "computationofthemomentmatrixandO(s(d)3)operationsforthematrix\n",
      "inversion.TheevaluationofQ?,drequiresO(s(d)2)operations.Estimating\n",
      "thecotsofQ?,dhasacomputationalcostthatdependsonlylinearlyin\n",
      "thenumberofpointsn.ThecostofevaluatingQ?,disconstantwithrespect\n",
      "tothenumberofpointsn.Thisisanimportantcontrastwithkernelbased\n",
      "ordistancebasedmethods(suchasnearestneighborsandoneclassSVM)for\n",
      "densityestimationoroutlierdetectionsincetheyusuallyrequireatleastO(n2\n",
      ")operationsfortheevaluationofthemodel[3].Moreover,thisiswellsuitedfor\n",
      "onlinesettingswhereinversemomentmatrixcomputationcanbedoneusing\n",
      "rankoneWoodburyupdates[15,Section2.7.1].Thedependenceinthedimen-\n",
      "sionpisoftheorderofpdforad.Similarly,thedependenceindisof\n",
      "theorderofdpforadimensionpandthejointdependenceisexponential.\n",
      "Furthermore,Md(?)hasaHankelstructurewhichisknowntoproduceill\n",
      "conditionedmatrices.Thissuggeststhatthedirectcomputationandevaluation\n",
      "ofQ?,dwillmostlymakesenseformoderatedimensionsanddegreed.Inour\n",
      "experiments,forlarged,theevaluationofQ?,dremainsquitestable,butthe\n",
      "inversionleadstonumericalerrorforhighervalues(around20).\n",
      "6\n",
      "\n",
      "4\n",
      "Invarianceandinterpretationthroughorthogonalpolynomials\n",
      "Thepurposeofthissectionistoprovideamathematicalrationalethatex-\n",
      "plainstheempiricalobservationsmadeinSection3.Alltheproofsarepost-\n",
      "ponedtoAppendixB.WeaBorelprobabilitymeasure?onRpwhich\n",
      "Assumption1.NotethatMd(?)isalwayspositiveif?isnotsupported\n",
      "onthezerosetofapolynomialofdegreeatmostd.UnderAssumption1,Md\n",
      "(?)inducesaninnerproductonRs(d)andbyextensiononRd[X](seeSection\n",
      "2).Thisinnerproductisdenotedbyh?,?i?andforanypolynomials\n",
      "P,Q?Rd[X]withcotsp,q?Rs(d),ZhP,Qi?:=hp,Md(?)qiRs(d)\n",
      "=P(x)Q(x)d?(x).Rp\n",
      "WewillalsousethecanonicalinnerproductoverRd[X]whichwewritehP,\n",
      "QiRd[X]:=hp,qiRs(d)foranypolynomialsP,Q?Rd[X]withcotsp,\n",
      "q?Rs(d).Wewillomitthesubscriptsforthiscanonicalinnerproductand\n",
      "useh?,?iforbothproducts.4.1\n",
      "invariance\n",
      "Itisworthnoticingthatthemappingx7?Q?,d(x)doesnotdependonthe\n",
      "particularchoiceofvd(X)asabasisofRd[X],anyotherbasiswouldleadto\n",
      "thesamemapping.ThisleadstotheresultthatQ?,dcapturesinvariant\n",
      "propertiesof?.Lemma1Let?satisfyAssumption1andA?Rp?p,b?Rp\n",
      "aninvertiblemappingonRp,A:x?Ax+b.Then,thepush\n",
      "fowardmeasure,by??(S)=?(A?1(S))forallBorelsetsS?Rp,\n",
      "Assumption1(withthesamedas?)andforallx?Rp,Q?,d(x)=\n",
      "Q??,d(Ax+b).PnLemma1isprobablybetterunderstoodwhen?=1/n\n",
      "i=1?xiasinSection3.Inthiscase,wePnhave??=1/ni=1?Axi+band\n",
      "Lemma1assertsthatthelevelsetsofQ??,daresimplytheimagesofthose\n",
      "ofQ?,dunderthetransformationx7?Ax+b.Thisisillustratedin\n",
      "AppendixD.4.2\n",
      "Connectionwithorthogonalpolynomials\n",
      "Weaclassical[16,5]familyoforthonormalpolynomials,\n",
      "f\n",
      "P?\n",
      "g\n",
      "??Np\n",
      "orderedaccordingto?gldwhichsforall??NpdhP?,X?i=0if?\n",
      "<gl?,hP?,P?i?=1,hP?,X?i?=0if?<gl?,hP?,X?i?>0.\n",
      "(3)\n",
      "Itfollowsfrom(3)thathP?,P?i?=0if?6=?.Existenceanduniqueness\n",
      "ofsuchafamilyisguaranteedbytheGram-Schmidtorthonormalizationprocess\n",
      "followingthe?glorder,andbythe5\n",
      "positivityofthemomentmatrix,seeforinstance[5,Theorem3.1.11].There\n",
      "existdeterminantalformulae[9]andmoreprecisedescriptioncanbemadefor\n",
      "measureswhichhaveadditionalgeometricproperties,see[5]formanyexamples.\n",
      "LetDd(?)bethelowertriangularmatrixwhoserowsarethecotsofthe\n",
      "polynomialsP?in(3)orderedby?gl.ItcanbeshownthatDd(?)=\n",
      "Ld(?)?T,whereLd(?)istheCholeskyfactorizationofMd(?).Furthermore,\n",
      "thereisadirectrelationwiththeinversemomentmatrixasMd(?)?1=Dd\n",
      "(?)TDd(?)[9,ProofofTheorem3.1].Thishasthefollowingconsequence.P\n",
      "Lemma2Let?satisfyAssumption1,thenQ?,d=P?2,wherethefamily\n",
      "f\n",
      "P?\n",
      "g\n",
      "??Npis??NpddRby(3)andRpQ?,d(x)d?(x)=s(d).Thatis,Q?,d\n",
      "7\n",
      "\n",
      "isaveryspanddistinguishedSOSpolynomial,thesumofsquaresofthe\n",
      "orthonormalbasiselements\n",
      "f\n",
      "P?\n",
      "g\n",
      "??NpofRd(X)(w.r.t.?).Furthermore,the\n",
      "averagevalueofQ?,ddwithrespectto?iss(d)whichcorrespondstothered\n",
      "levelsetinleftpanelofFigure3.4.3\n",
      "AvariationalformulationfortheinversemomentmatrixSOSpolynomial\n",
      "Inthissection,weshowthatthefamilyofpolynomials\n",
      "f\n",
      "P?\n",
      "g\n",
      "??Np\n",
      "in(3)istheuniquedsolution(uptoamultiplicativeconstant)ofaconvex\n",
      "optimizationproblemoverpolynomials.ThisfactcombinedwithLemma2\n",
      "providesamathematicalrationalefortheempiricalobservationsoutlinedin\n",
      "Section3.Considerthefollowingoptimizationproblem.ZX1minpQ?(x)2\n",
      "d?(x)(4)Q?,??,??Nd2Rpp??NdXs.t.q???exp(??),q??=0,?,??\n",
      "Npd,?<gl?,??=0,??Npd\n",
      "PwhereQ?(x)=??Npq??x?isapolynomialand??isarealvariable\n",
      "foreach??Npd.WedPcommentonproblem(4).LetP=??Np\n",
      "Q2?betheSOSpolynomialappearingintheobjectivedfunctionof(4).The\n",
      "objectiveof(4)simplyinvolvestheaveragevalueofPwithrespectto?.Let\n",
      "Sd??d[X]bethesetofsuchSOSpolynomialsPwhichhaveasumofsquare\n",
      "decompositionsatisfyingtheconstraintsof(4)(forsomearbitraryvalueofthe\n",
      "realvariables\n",
      "f\n",
      "??\n",
      "g\n",
      "??Np).WiththisdRnotation,problem(4)hasthesimple\n",
      "formulationminP?Sd21Pd?.Basedonthisformulation,problem(4)canbe\n",
      "interpretedasbalancingtwoantagonisttargets.Ononehandtheminimization\n",
      "oftheaveragevalueoftheSOSpolynomialPwithrespectto?,ontheother\n",
      "handtheavoidanceofthetrivialpolynomial,enforcedbytheconstraintthat\n",
      "P?Sd.TheconstraintP?Sdissimpleandnatural.ItensuresthatPisa\n",
      "sumofsquaresofpolynomials\n",
      "f\n",
      "Q?\n",
      "g\n",
      "??Np,wheredtheleadingtermofeach\n",
      "Q?(accordingtotheordering?gl)isq??x?withq??>0(andhencedoesnot\n",
      "vanish).Inversely,usingCholeskyfactorization,foranySOSpolynomialQof\n",
      "degree2dwhichcotmatrix(seeequation(1))ispositivethere\n",
      "existsa>0suchthataQ?Sd.ThissuggeststhatSdisaquitegeneralclass\n",
      "ofnonvanishingSOSpolynomials.Thefollowingresult,whichgivesarelation\n",
      "betweenQ?,dandsolutionsof(4),usesageneralizationof[16,Theorem3.1.2]\n",
      "toseveralorthogonalpolynomialsofseveralvariables.Theorem1:Under\n",
      "Assumption1,problem(4)is?aconvexoptimizationproblemwithaunique?\n",
      "optimalsolution(Q??,???),whichQNpd,forsome?>0.In\n",
      "particular,?,??P?=?PPthedistinguishedSOSpolynomialQ?,d=P?2\n",
      "=?1??Np(Q??)2,is(partof)theunique??Npddoptimalsolutionof\n",
      "(4).Theorem1statesthatuptothescalingfactor?,thedistinguishedSOS\n",
      "polynomialQ?,distheuniqueoptimalsolutionofproblem(4).Adetailedproof\n",
      "isprovidedintheAppendixBandweonlysketchthemainideashere.First,\n",
      "itisremarkablethatforeach??Npd(andagainup?istheuniqueo\n",
      "optimalsolutionoftheproblem:nRtoascalingfactor)thepolynomialPP2?\n",
      "minQQd?:Q?Rd[X],Q(x)=x+?<gl?q?x?.Thisfactiswell-knownin\n",
      "theunivariatecase[16,Theorem3.1.2]anddoesnotseemtohavebeenexploited\n",
      "intheliterature,at6\n",
      "leastforpurposessimilartoours.Sointuitively,P?2shouldbeascloseto0\n",
      "aspossibleonthesupportof?.Problem(4)hassimilarpropertiesandtheR\n",
      "8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraintonthevectorofweights?enforcesthat,atanoptimalsolution,the\n",
      "contributionof(Q??)2d?totheoverallsuminthecriterionisthesamefor\n",
      "all?.UsingLemma2yields(uptoamultiplicativeconstant)thepolynomial\n",
      "Q?,d.Otherconstraintson?wouldyieldtweightedsumofthesquares\n",
      "P?2.Thiswillbeasubjectoffurtherinvestigations.Tosumup,Theorem1\n",
      "providesarationaleforourobservations.Indeedwhensolving(4),intuitively,\n",
      "Q?,dshouldbecloseto0onaveragewhileremaininginaclassofnonvanishing\n",
      "SOSpolynomials.4.4\n",
      "functionandoutlierdetection\n",
      "Thefollowingresultfrom[5,Theorem3.5.6]drawsadirectconnectionbe-\n",
      "tweenQ?,dandthefunction(therighthandsideof(5)).Theorem2\n",
      "([5])LetAssumption1holdandletz?Rpbearbitrary.ThenZ\n",
      "?12Q?,d(z)=minP(x)d?(x):P(z)=1.P?Rd[X]\n",
      "(5)\n",
      "Rp\n",
      "Theorem2providesamathematicalrationalefortheuseofQ?,dforoutlier\n",
      "ornoveltydetectionpurposes.Indeed,fromLemma2andequation(3),wehave\n",
      "Q?,d?1onRp.Furthermore,thesolutionoftheminimizationproblemin(5)\n",
      "P(z)2=1and?x?Rp:P(x)2?1?inequality).Hence,forhigh\n",
      "valuesofQ?,d(z),thesublevelset1?Q?,d(z)?1(byMarkov?s\n",
      "x?Rp:P(x)2?1containsmostofthemassof?whileP(z)2=1.\n",
      "AnillustrationofthisdiscussionisgiveninappendixE.Againtheresultof\n",
      "Theorem2doesnotseemtohavebeeninterpretedforpurposessimilartoours.\n",
      "5\n",
      "Experimentsonnetworkintrusiondatasets\n",
      "Inadditiontohavingitsownmathematicalinterest,Theorem1canbe\n",
      "exploitedforvariouspurposes.\n",
      "p+dpForinstance,thesub-levelsetsofQ?,d,andinparticular\n",
      "f\n",
      "x?R:\n",
      "Q?,d(x)?d\n",
      "g\n",
      ",canbeusedtoencodeacloudofpointsinasimpleandcompact\n",
      "form.Howeverinthissectionwefocusonanotherpotentialapplicationin\n",
      "anomalydetection.EmpiricaldescribedinSection3suggestthatthe\n",
      "polynomialQ?,dcanbeusedtodetectoutliersinacollectionofrealvectors\n",
      "(with?theempiricalaverage).Thisisbackedupbytheresultspresentedin\n",
      "Section4.Weillustratethesepropertiesonarealworldexample.Wechoose\n",
      "theKDDcup99networkintrusiondataset[13]consistingofnetworkconnection\n",
      "data,labeledasnormalornetworkintrusions.Wefollow[19]and[18]\n",
      "andconstructedatasetsconsistingoflabeledvectorsinR3withthefollowing\n",
      "propertiesDatasetNumberofexamplesProportionsofattacks\n",
      "http5674980.004\n",
      "smtp951560.0003\n",
      "ftp-data304640.023\n",
      "ftp40910.077\n",
      "others58580.016\n",
      "Thedetailsonthedatasetsconstructionareavailablein[19,18]andre-\n",
      "producedinAppendixC.Themainideaistocomputeanoutlyingnessscore\n",
      "9\n",
      "\n",
      "(independantofthelabel)andcompareoutlierspredictedbythescoreandnet-\n",
      "workintrusionlabels.Theunderlyingassumptionisthatnetworkintrusions\n",
      "correspondtoinfrequentabnormalbehaviorsandcouldbeconsideredasout-\n",
      "liers.Wereproducethesameexperimentasin[18,Section5.4]usingthevalue\n",
      "ofQ?,dfrom1asanoutlyingnessscore(withd=3).Theauthorsof\n",
      "[18]havecomparedtmethodsinthesameexperimentalsetting:robust\n",
      "estimationandMahalanobisdistance[8,10],mixturemodels[14]andrecurrent\n",
      "neuralnetworks.Theresultsaregatheredin[18,Figure7].Intheleftpanel\n",
      "ofFigure2werepresentthesameperformancemeasureforourapproach:we\n",
      "computethevalueofQ?,dforeachdatapointanduseitasanoutlyingness\n",
      "score.Wethendisplaytheproportionofcorrectlyidenoutliers,withscore\n",
      "aboveagiventhreshold,asafunctionoftheproportionofexampleswithscore\n",
      "abovethethreshold(forntvaluesofthethreshold).Themaincomments\n",
      "areasfollows.7\n",
      "d(AUPR)\n",
      "dataset\n",
      "0.8\n",
      "http0.6\n",
      "smtpftp\n",
      "data\n",
      "0.4\n",
      "ftp\n",
      "2(0.18)3(0.18)\n",
      "0.50\n",
      "4(0.16)5(0.15)\n",
      "0.25\n",
      "others\n",
      "0.2\n",
      "1(0.08)\n",
      "0.75\n",
      "Precision\n",
      "%correctlyidenoutliers\n",
      "1.00\n",
      "1.0\n",
      "6(0.13)\n",
      "0.0\n",
      "0.000.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.0\n",
      "0.0\n",
      "%topoutlyingnessscore\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "10\n",
      "\n",
      "0.8\n",
      "1.0\n",
      "Recall\n",
      "Figure2:Left:reproductionoftheresultsdescribedin[18]withtheeval-\n",
      "uationofQ?,dasanoutlyingnessscore(d=3).Right:precision-recallcurves\n",
      "fortvaluesofd(dataset?others?).?TheinversemomentmatrixSOS\n",
      "polynomialdoesdetectnetworkintrusionswithvaryingperformancesonthee\n",
      "datasets.?Exceptforthe?ftp-datadataset?,theglobalshapeofthesecurves\n",
      "areverysimilartoresultsreportedin[18,Figure7]indicatingthattheproposed\n",
      "approachiscomparabletootherdedicatedmethodsforintrusiondetectionin\n",
      "thesefourdatasets.Inasecondexperiment,weinvestigatetheofchanging\n",
      "thevalueofdontheperformances.Wefocusonthe?others?datasetbecause\n",
      "itisthemostheterogeneous.Weadoptaslightlytmeasureofperfor-\n",
      "manceanduseprecisionrecall(seeforexample[4])tomeasureperformances\n",
      "inidentifyingnetworkintrusions(thehigherthecurve,thebetter).Wecallthe\n",
      "areaundersuchcurvestheAUPR.TherightpanelofFigure2representsthese\n",
      "results.First,thecased=1,whichcorrespondstovanillaMahalanobisdistance\n",
      "asoutlinedinSection3.3,givespoorperformances.Second,theglobalperfor-\n",
      "mancesrapidlyincreasewithdandthendecreaseandstabilize.Thissuggests\n",
      "thatdcanbeusedasatuningparametertocontrolthe?complexity?ofQ?,d\n",
      ".Indeed,2disthedegreeofthepolynomialQ?,danditisexpectedthatmore\n",
      "complexmodelswillidentifymorediverseclassesofexamplesasoutliers.In\n",
      "ourcase,thismeansidentifyingregularasoutlierswhileitactuallydoes\n",
      "notcorrespondtointrusions.Ingeneral,agoodheuristicregardingthetun-\n",
      "ingofdistoinvestigateperformancesonawellspecitaskinapreliminary\n",
      "experiment.\n",
      "6\n",
      "Futurework\n",
      "Animportantquestionistheasymptoticregimewhend??.Currentstate\n",
      "ofknowledgesuggeststhat,uptoacorrectscaling,thelimitofthe\n",
      "functions(whenknowntoexist)involvesanedgeterm,relatedtothe\n",
      "supportofthemeasure,andthedensityof?withrespecttoLebesguemeasure,\n",
      "seeforexample[2]fortheEuclideanball.Italsosuggestsconnectionswith\n",
      "thenotionofequilibriummeasureinpotentialtheory[17,1,7].Generalization\n",
      "andinterpretationoftheseresultsinourcontextwillbeinvestigatedinfuture\n",
      "work.Eventhoughgoodapproximationsareobtainedwithlowdegree(atleast\n",
      "indimension2or3),theapproachinvolvestheinversionoflargeillconditioned\n",
      "Hankelmatriceswhichreducesconsiderablytheapplicabilityforhigherdegrees\n",
      "anddimensions.Apromisingresearchlineistodevelopapproximationproce-\n",
      "duresandadvancedoptimizationandalgebratoolssothattheapproachcould\n",
      "scalecomputationallytohigherdimensionsanddegrees.Finally,wedidnot\n",
      "touchthequestionofstatisticalaccuracy.Inthecontextofempiricalprocesses,\n",
      "thiswillbeveryrelevanttounderstandfurtherpotentialapplicationsinmachine\n",
      "learningandreducethegapbetweentheabstractorthogonalpolynomialthe-\n",
      "oryandpracticalmachinelearningapplications.AcknowledgmentsThiswork\n",
      "waspartlysupportedbyprojectERC-ADGTAMING666981,ERC-Advanced\n",
      "11\n",
      "\n",
      "GrantoftheEuropeanResearchCouncilandgrantnumberFA9550-15-1-0500\n",
      "fromtheAirForceofScienResearch,AirForceMaterialCommand.\n",
      "8\n",
      "2References\n",
      "[1]R.J.Berman(2009).Bergmankernelsforweightedpolynomialsandweighted\n",
      "equilibriummeasuresofCn.IndianaUniversityMathematicsJournal,58(4):1921?1946.\n",
      "[2]L.Bos,B.DellaVecchiaandG.Mastroianni(1998).Ontheasymptotics\n",
      "offunctionsforcentrallysymmetricweightsfunctionsontheballin\n",
      "Rn.RendicontidelCircoloMatematicodiPalermo,52:277?290.[3]V.Chan-\n",
      "dola,A.BanerjeeandV.Kumar(2009).Anomalydetection:Asurvey.ACM\n",
      "computingsurveys(CSUR)41(3):15.[4]J.DavisandM.Goadrich(2006).The\n",
      "relationshipbetweenPrecision-RecallandROCcurves.Proceedingsofthe23rd\n",
      "internationalconferenceonMachinelearning(pp.233-240).ACM.[5]C.F.\n",
      "DunklandY.Xu(2001).Orthogonalpolynomialsofseveralvariables.Cam-\n",
      "bridgeUniversityPress.MR1827871.[6]G.HGolub,P.MilanfarandJ.Varah\n",
      "(1999).Astablenumericalmethodforinvertingshapefrommoments.SIAM\n",
      "JournalonScienComputating21(4):1222?1243(1999).[7]B.Gustafsson,\n",
      "M.Putinar,E.andN.Stylianopoulos(2009).Bergmanpolynomialsonan\n",
      "archipelago:estimates,zerosandshapereconstruction.AdvancesinMathe-\n",
      "matics222(4):1405?1460.[8]A.S.Hadi(1994).Amodofamethod\n",
      "forthedetectionofoutliersinmultivariatesamples.JournaloftheRoyalSta-\n",
      "tisticalSociety.SeriesB(Methodological),56(2):393-396.[9]J.W.Helton,J.B.\n",
      "LasserreandM.Putinar(2008).Measureswithzerosintheinverseoftheir\n",
      "momentmatrix.TheAnnalsofProbability,36(4):1453-1471.[10]E.M.Knorr,\n",
      "R.T.NgandR.H.Zamar(2001).Robustspacetransformationsfordistance-\n",
      "basedoperations.ProceedingsoftheinternationalconferenceonKnowledge\n",
      "discoveryanddatamining(pp.126-135).ACM.[11]J.B.Lasserre(2015).\n",
      "LevelSetsandNonGaussianIntegralsofPositivelyHomogeneousFunctions.\n",
      "InternationalGameTheoryReview,17(01):1540001.[12]J.B.Lasserreand\n",
      "M.Putinar(2015).Algebraic-exponentialDataRecoveryfromMoments.Dis-\n",
      "crete&ComputationalGeometry,54(4):993-1012.[13]M.Lichman(2013).UCI\n",
      "MachineLearningRepository,http://archive.ics.uci.edu/mlUniversityofCali-\n",
      "fornia,Irvine,SchoolofInformationandComputerSciences.[14]J.J.Oliver,\n",
      "R.A.BaxterandC.S.Wallace(1996).UnsupervisedlearningusingMML.Pro-\n",
      "ceedingsoftheInternationalConferenceonMachineLearning(pp.364-372).\n",
      "[15]W.H.Press,S.A.Teukolsky,W.T.VetterlingandB.P.Flannery(2007).\n",
      "NumericalRecipes:TheArtofScienComputing(3rdEdition).Cambridge\n",
      "UniversityPress.[16]G.Szeg?(1974).Orthogonalpolynomials.InColloquium\n",
      "publications,AMS,(23),fourthedition.[17]V.Totik(2000).Asymptoticsfor\n",
      "functionsforgeneralmeasuresontherealline.Journald?Analyse\n",
      "Math?matique,81(1):283-303.[18]G.Williams,R.Baxter,H.He,S.Hawkins\n",
      "andL.Gu(2002).AComparativeStudyofRNNforOutlierDetectionin\n",
      "DataMining.IEEEInternationalConferenceonDataMining(p.709).IEEE\n",
      "12\n",
      "\n",
      "ComputerSociety.[19]K.Yamanishi,J.I.Takeuchi,G.WilliamsandP.Milne\n",
      "(2004).On-lineunsupervisedoutlierdetectionusingmixtureswithdis-\n",
      "countinglearningalgorithms.DataMiningandKnowledgeDiscovery,8(3):275-\n",
      "300.\n",
      "9\n",
      "13\n",
      "\n",
      "PP6641.pdf\n",
      "PP6641.pdf 12\n",
      "PhaseTransitionsinthePooledDataProblem\n",
      "Authoredby:\n",
      "VolkanCevher\n",
      "JonathanScarlett\n",
      "Abstract\n",
      "Inthispaper,westudythe\n",
      "f\n",
      "empooleddata\n",
      "g\n",
      "problemofidentifying\n",
      "thelabelsassociatedwithalargecollectionofitems,basedonasequence\n",
      "ofpooledtestsrevealingthecountsofeachlabelwithinthepool.In\n",
      "thenoiselesssetting,weidentifyanexactasymptoticthresholdonthe\n",
      "requirednumberoftestswithoptimaldecoding,andprovea\n",
      "f\n",
      "emphase\n",
      "transition\n",
      "g\n",
      "betweencompletesuccessandcompletefailure.Inaddition,\n",
      "wepresentanovel\n",
      "f\n",
      "emnoisy\n",
      "g\n",
      "variationoftheproblem,andprovidean\n",
      "information-theoreticframeworkforcharacterizingtherequirednumber\n",
      "oftestsforgeneralrandomnoisemodels.Ourresultsrevealthatnoise\n",
      "canmaketheproblemconsiderablymorecult,withstrictincreasesin\n",
      "thescalinglawsevenatlownoiselevels.Finally,wedemonstratesimilar\n",
      "behaviorinan\n",
      "f\n",
      "emapproximaterecovery\n",
      "g\n",
      "setting,whereagivennumber\n",
      "oferrorsisallowedinthedecodedlabels.\n",
      "1PaperBody\n",
      "Considerthefollowingsetting:Thereexistsalargepopulationofitems,eachof\n",
      "whichhasanassociatedlabel.Thelabelsareinitiallyunknown,andaretobe\n",
      "estimatedbasedonpooledtests.Eachpoolconsistsofsomesubsetofthepop-\n",
      "ulation,andthetestoutcomerevealsthetotalnumberofitemscorresponding\n",
      "toeachlabelthatarepresentinthepool(butnottheindividuallabels).This\n",
      "problem,whichwerefertoasthepooleddataproblem,wasrecentlyintroduced\n",
      "in[1,2],andfurtherstudiedin[3,4].Itisofinterestinapplicationssuchas\n",
      "medicaltesting,genetics,andlearningwithprivacyconstraints,andhascon-\n",
      "nectionstothegrouptestingproblem[5]anditslinearvariants[6,7].Thebest\n",
      "knownboundsontherequirednumberoftestsunderoptimaldecodingwere\n",
      "givenin[3];however,theupperandlowerboundsthereindonotmatch,and\n",
      "canexhibitalargegap.Inthispaper,wecompletelyclosethesegapsbypro-\n",
      "vidinganewlowerboundthatexactlymatchestheupperboundof[3].These\n",
      "resultscollectivelyrevealaphasetransitionbetweensuccessandfailure,with\n",
      "theprobabilityoferrorvanishingwhenthenumberoftestsexceedsagiven\n",
      "threshold,buttendingtoonebelowthatthreshold.Inaddition,weexplore\n",
      "1\n",
      "\n",
      "thenovelaspectofrandomnoiseinthemeasurements,andshowthatthiscan\n",
      "tlyincreasetherequirednumberoftests.Beforesummarizingthese\n",
      "contributionsinmoredetail,weformallyintroducetheproblem.1.1\n",
      "Problemsetup\n",
      "Weconsideralargepopulationofitems[p]=\n",
      "f\n",
      "1,...,p\n",
      "g\n",
      ",eachofwhich\n",
      "hasanassociatedlabelin[d]=\n",
      "f\n",
      "1,...,d\n",
      "g\n",
      ".Welet?=(?1,...,?d)denote\n",
      "avectorcontainingtheproportionsofitemshavingeachlabel,andweassume\n",
      "thatthevectoroflabelsitself,=(1,...,p),isuniformlydistributedover\n",
      "thesequencesconsistentwiththeseproportions:?Uniform(B(?)),\n",
      "whereB(?)isthesetoflength-psequenceswhoseempiricaldistributionis\n",
      "?.\n",
      "(1)\n",
      "Thegoalistorecoverbasedonasequenceofpooledtests.Thei-thtestis\n",
      "representedbya(i)(possiblyrandom)vectorX(i)2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "p,whosej-thentry\n",
      "Xjindicateswhetherthej-thitemis31stConferenceonNeuralInformation\n",
      "ProcessingSystems(NIPS2017),LongBeach,CA,USA.\n",
      "NecessaryforPe6!1(thispaper)pp1p?maxf(r)?f(1)?maxf(r)\n",
      "logpr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "logp2logpr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "Table1:Necessaryandnt\n",
      "conditionsonthenumberoftestsninthenoiselesssetting.Thefunctionf(r)is\n",
      "in(5).Asymptoticmultiplicative1+o(1)termsareomitted.t\n",
      "forPe!0[3]\n",
      "NecessaryforPe6!1[3]\n",
      "NoisytestingNoisytestingNoisytestingNoiselesstesting(SNR=?(1))\n",
      "(SNR=(logp)?(1))(SNR=p?(1))?p??p???p????p\n",
      "logplogplogploglogpTable2:Necessaryandtconditionsonthe\n",
      "numberoftestsninthenoisysetting.SNRdenotesthesignal-to-noiseratio,\n",
      "andthenoisemodelisgiveninSection2.2.includedinthei-thtest.We\n",
      "ameasurementmatrixX2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "n?pwhosei-throwisgivenbyX(i)fori=\n",
      "1,...,n,wherendenotesthetotalnumberoftests.Wefocusonthenon-\n",
      "adaptivetestingscenario,wheretheentirematrixXmustbesppriorto\n",
      "performinganytests.(i)\n",
      "(i)\n",
      "Inthenoiselesssetting,thei-thtestoutcomeisavectorY(i)=(Y1,...\n",
      ",Yd),witht-thentry(i)\n",
      "=Nt(,X(i)),(2)Pwherefort=1,...,d,weletNt(,X)=j2[p]\n",
      "1\n",
      "f\n",
      "j=tXj=1\n",
      "g\n",
      "denotethenumberofitemswithlabeltthatareincludedin\n",
      "thetestdescribedbyX2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "p.Moregenerally,inthepossiblepresenceof\n",
      "noise,thei-thobservationisrandomlygeneratedaccordingtoYt\n",
      "Y(i)|X(i),?PY|N1(,X(i))...Nd(,X(i))(3)forsomeconditional\n",
      "probabilitymassfunctionPY|N1,...,Nd(ordensityfunctioninthecaseof\n",
      "continuousobservations).WeassumethattheobservationsY(i)(i=1,...,\n",
      "n)areconditionallyindependentgivenX,butotherwisemakenoassumptions\n",
      "onPY|N1,...,Nd.Clearly,thenoiselessmodel(2)fallsunderthismore\n",
      "generalsetup.SimilarlytoX,weletYdenoteann?dmatrixofobservations,\n",
      "withthei-throwbeingY(i).GivenXandY,adecoderoutputsanestimate\n",
      "?of,andtheerrorprobabilityisgivenbyPe=P[?6=],(4)\n",
      "2\n",
      "\n",
      "wheretheprobabilityiswithrespectto,X,andY.Weseektoconditions\n",
      "onthenumberoftestsnunderwhichPeattainsacertaintargetvalueinthe\n",
      "limitasp!1,andourmainresultsprovidenecessaryconditions(i.e.,lower\n",
      "boundsonn)forthistooccur.Asin[3],wefocusonthecasethatdand?are\n",
      "anddonotdependonp.11.2\n",
      "Contributionsandcomparisonstoexistingbounds\n",
      "Ourfocusinthispaperisoninformation-theoreticboundsontherequired\n",
      "numberofteststhatholdregardlessofpracticalconsiderationssuchascompu-\n",
      "tationandstorage.Amongtheexistingworksintheliterature,theonemost\n",
      "relevanttothispaperis[3],whoseboundsstrictlyimproveontheinitialbounds\n",
      "in[1].Thesameauthorsalsoprovedaphasetransitionforapracticalalgorithm\n",
      "basedonapproximatemessagepassing[4],buttherequirednumberoftestsis\n",
      "infacttlylargerthantheinformation-theoreticthreshold(sp,\n",
      "linearinpinsteadofsub-linear).Table1givesasummaryoftheboundsfrom\n",
      "[3]andourcontributionsinthenoiselesssetting.Tothefunctionf(r)\n",
      "therein,weintroducetheadditionalnotationthatforr=\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      ",(r)\n",
      "(r)?(r)=(?1,...,?r)isavectorwhoseentrysumsthelargestdr+1\n",
      "entriesof?,andwhoseremainingentriescoincidewiththeremainingr1entries\n",
      "of?.Wehave2(H(?)H(?(r))),drr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "meaningthattheentriesin\n",
      "Table1correspondingtotheresultsof[3]aregivenasfollows:f(r)=\n",
      "max\n",
      "1\n",
      "(5)\n",
      "Moreprecisely,?shouldberoundedtothenearestempiricaldistribution\n",
      "(e.g.,in`1-norm)forsequences2[d]poflengthp;weleavesuchrounding\n",
      "implicitthroughoutthepaper.\n",
      "2\n",
      "1.4Random:Uniform:Highlynon-uniform:\n",
      "1.2\n",
      "f(r)\n",
      "10.80.60.40.20\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "r\n",
      "Figure1:Thefunctionf(r)in(5),forseveralchoicesof?,withd=10.\n",
      "Therandom?aredrawnuniformlyontheprobabilitysimplex,andthe\n",
      "highlynon-uniformchoiceof?isgivenby?=(0.49,0.49,0.0025,...,\n",
      "0.0025).Whenthemaximumisachievedatr=1,theboundsof[3]coincideup\n",
      "3\n",
      "\n",
      "toafactoroftwo,whereasifthemaximumisachievedforr>1thenthegapis\n",
      "larger.\n",
      "?(Achievability)WhentheentriesofXarei.i.d.onBernoulli(q)forsome\n",
      "q2(0,1)(notdependingonp),thereexistsadecodersuchthatPe!0asp!\n",
      "1with??p2(H(?)H(?(r)))n?max(1+?)(6)logpr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "drfor\n",
      "arbitrarilysmall?>0.?(Converse)InordertoachievePe6!1asp!1,itis\n",
      "necessarythat??pH(?)n(1?)logpd1\n",
      "(7)\n",
      "forarbitrarilysmall?>0.\n",
      "Unfortunately,theseboundsdonotcoincide.Ifthemaximumin(6)is\n",
      "achievedbyr=1(whichoccurs,forexample,when?isuniform[3]),then\n",
      "thegaponlyamountstoafactoroftwo.However,asweshowinFigure1,if\n",
      "wecomputetheboundsforsome?random?choicesof?thenthegapistypi-\n",
      "callylarger(i.e.,r=1doesnotachievethemaximum),andwecanconstruct\n",
      "choiceswherethegapistlylarger.Closingthesegapswasposedasa\n",
      "keyopenproblemin[3].Wecannowsummarizeourcontributionsasfollows:\n",
      "1.Wegivealowerboundthatexactlymatches(6),thuscompletelyclosing\n",
      "theabove-mentionedgapsintheexistingboundsandsolvingtheopenproblem\n",
      "raisedin[3].Moresp,(r)))weshowthatPe!1whenevern?logpp\n",
      "maxr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "2(H(?)dH(?(1?)forrsome?>0,thusidentifyinganexact\n",
      "phasetransition?athresholdabovewhichtheerrorprobabilityvanishes,but\n",
      "belowwhichtheerrorprobabilitytendstoone.2.Wedevelopaframeworkfor\n",
      "understandingvariationsoftheproblemconsistingofrandomnoise,andgivean\n",
      "exampleofanoisemodelwherethescalinglawsarestrictlyhighercomparedto\n",
      "thenoiselesscase.AsummaryisgiveninTable2;thecaseSNR=(logp)?(1)\n",
      "revealsastrictincreaseinthescalinglawsevenwhenthesignal-to-noiseratio\n",
      "growsunbounded,andthecaseSNR=?(1)revealsthattherequirednumberof\n",
      "testsincreasesfromsub-lineartosuper-linearinthedimensionwhenthesignal-\n",
      "to-noiseratioisconstant.3.Inthesupplementarymaterial,wediscusshow\n",
      "ourlowerboundsextendreadilytotheapproximaterecoverycriterion,where\n",
      "weonlyrequiretobeidenuptoacertainHammingdistance.However,\n",
      "forclarity,wefocusonexactrecoverythroughoutthepaper.Inarecentinde-\n",
      "pendentwork[8],anadversarialnoisesettingwasintroduced.Thisturnsoutto\n",
      "befundamentallyttoournoisysetting.Inparticular,theresultsof[8]\n",
      "statethatexactrecoveryisimpossible,andevenwithapproximaterecovery,a\n",
      "hugenumberoftests(i.e.,higherthan1/2+o(1)polynomial)isneededunless=\n",
      "Oqmax,whereqmaxisthemaximumallowedreconstructionerrormeasured\n",
      "bytheHammingdistance,andismaximumadversarialnoiseamplitude.Of\n",
      "course,bothrandomandadversarialnoiseareoftinterest,depending\n",
      "ontheapplication.3\n",
      "Notation.Forapositiveintegerd,wewrite[d]=\n",
      "f\n",
      "1,...,d\n",
      "g\n",
      ".We\n",
      "usestandardinformation-theoreticnotationsforthe(conditional)entropyand\n",
      "mutualinformation,e.g.,H(X),H(Y|X),I(X;Y|Z)[9].Alllogarithmshave\n",
      "basee,andaccordingly,alloftheprecedinginformationmeasuresareinunits\n",
      "ofnats.TheGaussiandistributionwithmean?andvariance2isdenotedby\n",
      "N(?,2).WeusethestandardasymptoticnotationsO(?),o(?),?(?),!(?)and\n",
      "4\n",
      "\n",
      "?(?).\n",
      "2\n",
      "Mainresults\n",
      "Inthissection,wepresentourmainresultsforthenoiselessandnoisyset-\n",
      "tings.TheproofsaregiveninSection3,aswellasthesupplementarymaterial.\n",
      "2.1\n",
      "Phasetransitioninthenoiselesssetting\n",
      "Thefollowingtheoremprovesthattheupperboundgivenin(6)istight.\n",
      "Recallthatforr=(r)(r)\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      ",?(r)=(?1,...,?r)is\n",
      "avectorwhoseentrysumsthelargestdr+1entriesof?,andwhose\n",
      "remainingentriescoincidewiththeremainingr1entriesof?.Theorem1.\n",
      "(Noiselesssetting)ConsiderthepooleddataproblemdescribedinSection1.1\n",
      "withagivennumberoflabelsdandlabelproportionvector?(notdepending\n",
      "onthedimensionp).Foranydecoder,inordertoachievePe6!1asp!1,itis\n",
      "necessarythat??p2(H(?)H(?(r)))nmax(1?)(8)logpr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "dr\n",
      "forarbitrarilysmall?>0.\n",
      "Combinedwith(6),thisresultrevealsanexactphasetransitiononthere-\n",
      "quirednumberofmeasurer))ments:Denotingn?=logppmaxr2\n",
      "f\n",
      "1,...,d1\n",
      "g\n",
      "2(H(?)dH(?,theerrorprobabilityvanishesforr??nn(1+?),tendsto\n",
      "oneforn?n(1?),regardlessofhowsmall?ischosentobe.Remark1.Our\n",
      "modelassumesthatisuniformlydistributedoverthesequenceswithempirical\n",
      "distribution?,whereas[3]assumesthatisi.i.d.on?.However,Theorem1\n",
      "readilyextendstothelattersetting:Underthei.i.d.model,oncewecondition\n",
      "onagivenempiricaldistribution,theconditionaldistributionofisuniform.As\n",
      "aresult,theconverseboundforthei.i.d.modelfollowsdirectlyfromTheorem\n",
      "1bybasicconcentrationandthecontinuityoftheentropyfunction.2.2\n",
      "Information-theoreticframeworkforthenoisysetting\n",
      "Wenowturntogeneralnoisemodelsoftheform(3),andprovidenecessary\n",
      "conditionsforthenoisypooleddataproblemintermsofthemutualinformation.\n",
      "Generalcharacterizationsofthisformwereprovidedpreviouslyforgrouptesting\n",
      "[10,11]andothersparserecoveryproblems[12,13].Ourgeneralresultisstated\n",
      "intermsofamaximizationoveravectorparameter`=(`1,...,`d)with\n",
      "`t2\n",
      "f\n",
      "0,...,?tp\n",
      "g\n",
      "forallt.Wewillseeintheproofthat`trepresents\n",
      "thenumberofitemsoftypetthatareunknowntothedecoderafterp?t`t\n",
      "arerevealedbyagenie.Wethefollowing:?Given`and,weletS`\n",
      "bearandomsetofindicesin[p]suchthatforeacht2[d],thesetcontains`t\n",
      "indicescorrespondingtoentrieswhereequalst.Sp,weS`tobe\n",
      "uniformlydistributedoverallsuchsets.Moreover,weS`c=[p]S`.?\n",
      "Giventheabovewe?j2S`cjc(9)S`=?otherwise,\n",
      "where?canbethoughtofasrepresentinganunknownvalue.Hence,know-\n",
      "ingS`camountstoknowingthelabelsofallitemsinthesetS`c.?We\n",
      "|B`(?)|tobethenumberofsequences2[d]pthatcoincidewithagivenS`c\n",
      "ontheentriesnotequaling?,whilealsohavingempiricaldistribution?overall.\n",
      "ThisnumberdoesnotdependonthespchoiceofS`c.Asanexample,\n",
      "when`t=p?tforallt,wehaveS`=[p],S`c=(?,...,?),and|B`(?)|\n",
      "=|B(?)|,following(1)?Weletk`k0denotethenumberofvaluesin\n",
      "5\n",
      "\n",
      "(`1,...,`d)thatarepositive.4\n",
      "Withtheses,wehavethefollowingresultforgeneralrandomnoise\n",
      "models.Theorem2.(Noisysetting)Considerthepooleddataproblemdescribed\n",
      "inSection1.1underageneralobservationmodeloftheform(3),withagiven\n",
      "numberoflabelsdandlabelproportionvector?.Foranydecoder,inorderto\n",
      "achievePe?foragiven2(0,1),itisnecessarythatn\n",
      "max\n",
      "`:k`k0\n",
      "log|B`(?)|(1)log2Pn.(i)|S`c,X(i))i=1I(;Y\n",
      "(10)\n",
      "12n\n",
      "Inordertoobtainmoreexplicitboundsonnfrom(10),oneneedstochar-\n",
      "acterizethemutualinformationterms,ideallyforminganupperboundthat\n",
      "doesnotdependonthedistributionofthemeasurementmatrixX.Wedothis\n",
      "forsomespmodelsbelow;however,ingeneralitcanbeatask.\n",
      "ThefollowingcorollaryrevealsthatiftheentriesofXarei.i.d.onBernoulli(q)\n",
      "forsomeq2(0,1)(aswasassumedin[3]),thenwecansimplifythebound.\n",
      "Corollary1.(NoisysettingwithBernoullitesting)Supposethattheentriesof\n",
      "Xarei.i.d.onBernoulli(q)forsomeq2(0,1).UnderthesetupofTheorem2,\n",
      "itisnecessarythatn\n",
      "max\n",
      "`:k`k02\n",
      "log|B`(?)|(1)log2,I(X0,`;Y|X1,`)\n",
      "(11)\n",
      "where(X0,`,X1,`,Y)aredistributedasfollows:(i)X0,`(respectively,\n",
      "X1,`)isaconcatenationofthevectorsX0,`(1),...,X0,`(d)(respectively,\n",
      "X1,`(1),...,X1,`(d)),thet-thofwhichcontains`t(respectively,?tp`t\n",
      ")entriesindependentlydrawnfromBernoulli(q);(ii)LettingeachNt(t=1,\n",
      "...,d)bethetotalnumberofonesinX0,`(t)andX1,`(t)combined,the\n",
      "randomvariableYisdrawnfromPY|N1,...,Ndaccordingto(3).Aswellas\n",
      "beingsimplertoevaluate,thiscorollarymaybeofinterestinscenarioswhere\n",
      "onedoesnothavecompletefreedomindesigningX,andoneinsteadinsistson\n",
      "usingBernoullitesting.Forinstance,onemaynotknowhowtooptimizeX,and\n",
      "accordinglyresorttogeneratingitatrandom.Example1:Applicationtothe\n",
      "noiselesssetting.Inthesupplementarymaterial,weshowthatinthenoiseless\n",
      "setting,Theorem2recoversaweakenedversionofTheorem1with1?replaced\n",
      "by1o(1)in(8).Hence,whileTheorem2doesnotestablishaphasetransition,\n",
      "itdoesrecovertheexactthresholdonthenumberofmeasurementsrequiredto\n",
      "obtainPe!0.\n",
      "Anoverviewoftheproofofthisclaimisasfollows.Werestrictthemax-\n",
      "imumin(10)tochoicesof`whereeach`tequalseitheritsminimumvalue0\n",
      "oritsmaximumvaluep?t.Sinceweareinthenoiselesssetting,eachmutual\n",
      "informationtermreducestotheconditionalentropyof(i)(i)(i)Y(i)=(Y1,\n",
      "...,Yd)givenS`candX(i).Forthevaluesoftsuchthat`t=0,thevalue\n",
      "Ytis(i)\n",
      "6\n",
      "\n",
      "deterministic(i.e.,ithaszeroentropy),whereasforthevaluesoftsuchthat\n",
      "`t=p?t,thevalueYtfollowsahypergeometricdistribution,whoseentropy\n",
      "behavesas12logp(1+o(1)).\n",
      "InthecasethatXisi.i.d.onBernoulli(q),wecanuseCorollary1toobtain\n",
      "thefollowingnecessaryconditionforPe?asasp!1,provedinthesupplemen-\n",
      "tarymaterial:??p2(H(?)H(?r))nmax(1o(1))(12)log(pq(1q))r2\n",
      "f\n",
      "1,...,d\n",
      "1\n",
      "g\n",
      "dr\n",
      "foranyq=q(p)suchthatbothqand1qbehaveas!p1.Hence,while\n",
      "q=?(1)recoversthethresholdin(8),therequirednumberoftestsstrictly\n",
      "increaseswhenq=o(1),albeitwithamildlogarithmicdependence.Example\n",
      "2:Grouptesting.TohighlighttheversatilityofTheorem2andCorollary1,\n",
      "weshowthatthelatterrecoversthelowerboundsgiveninthegrouptesting\n",
      "frameworkof[11].Setd=2,andletlabel1represent?defective?items,and\n",
      "label2represent?non-defective?items.LetPY|N1N2beoftheformPY\n",
      "|N1withY2\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",meaningtheobservationsarebinaryanddependonlyon\n",
      "thenumberofdefectiveitemsinthetest.Forbrevity,letk=p?1denotethe\n",
      "totalnumberofdefectiveitems,sothatp?2=pkisthenumberofnon-defective\n",
      "items.Letting`2=p\n",
      "kin(11),andletting`1remainarbitrary,weobtainthenecessarycondition\n",
      "n\n",
      "max\n",
      "`12\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      "log\n",
      "pk+`1`1\n",
      "(1\n",
      ")\n",
      "I(X0,`1;Y|X1,`1)5\n",
      "log2\n",
      ",\n",
      "(13)\n",
      "whereX0,`1isashorthandforX0,`with`=(`1,pk),andsimilarlyforX1,`1\n",
      ".Thismatchesthelowerboundgivenin[11]forBernoullitestingwithgeneral\n",
      "noisemodels,forwhichseveralcorollariesforspmodelswerealsogiven.\n",
      "Example3:Gaussiannoise.Togiveaconcreteexampleofanoisysetting,\n",
      "considerthecasethatweobservethevaluesin(2),butwitheachsuchvalue\n",
      "corruptedbyindependentGaussiannoise:(i)\n",
      "Yt\n",
      "(i)\n",
      "=Nt(,X(i))+Zt,\n",
      "(14)\n",
      "(i)Zt\n",
      "where?N(0,p2)forsome2>0.NotethatgivenX(i),thevaluesNt\n",
      "themselveshavevarianceatmostproportionaltop(e.g.,seeAppendixC),so\n",
      "2=?(1)canbethoughtofastheconstantsignal-to-noiseratio(SNR)regime.\n",
      "Inthesupplementarymaterial,weprovethefollowingboundsforthismodel:\n",
      "?Bylettingeach`tin(10)equalitsminimumormaximumvalueanalogously\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tothenoiselesscaseabove,weobtainthefollowingnecessaryconditionforPe\n",
      "?asp!1:??pGH(?G)Pnmax(1o(1)),(15)?t1G?[d]:|G|2t2G2\n",
      "log1+42)PwherepG:=t2G?tp,and?GhasentriesP0?t?0fort2G.\n",
      "Hence,wehavethefollowing:t2G\n",
      "t\n",
      "?Inthecasethat2=pcforsomec2(0,1),eachsummandinthe\n",
      "denominatorto2clogp(1+o(1)),andwededucethatcompared\n",
      "tothenoiselesscase(cf.,(8)),theasymptoticnumberoftestsincreasesbyat\n",
      "leastaconstantfactorof1c.?Inthecasethat2=(logp)cforsomec>\n",
      "0,eachsummandinthedenominatorto2cloglogp(1+o(1)),and\n",
      "wededucethatcomparedtothenoiselesscase,theasymptoticlogpnumberof\n",
      "testsincreasesbyatleastafactorofcloglogp.Hence,weobserveastrict\n",
      "increaseinthescalinglawsdespitethefactthattheSNRgrowsunbounded.?\n",
      "While(15)alsoprovidesan?(p)lowerboundforthecase2=?(1),wecanin\n",
      "factdobetterviaatchoiceof`(seebelow).?Byletting`1=p?1,`2=\n",
      "1,and`t=0fort=3,...,d,weobtainthenecessaryconditionn4p2logp(1\n",
      "o(1))(16)forPe?asp!1.Hence,if2=?(1),werequiren=?(plogp);thisis\n",
      "super-linearinthedimension,incontrastwiththesub-linear?logppbehavior\n",
      "observedinthenoiselesscase.Notethatthischoiceof`essentiallycapturesthe\n",
      "yinidentifyingasingleitem,namely,theonecorrespondingto`2=1.\n",
      "ThesearesummarizedinTable2;seealsothesupplementarymaterial\n",
      "forextensionstotheapproximaterecoverysetting.Remark2.Whileitmay\n",
      "seemunusualtoaddcontinuousnoisetodiscreteobservations,thisstillcaptures\n",
      "theessenceofthenoisypooleddataproblem,andtheevaluationofthe\n",
      "mutualinformationtermsin(10).Moreover,thisconverseboundimmediately\n",
      "impliesthesameboundforthediscretemodelinwhichthenoiseconsistsof\n",
      "addingaGaussianterm,rounding,andclippingto\n",
      "f\n",
      "0,...,p\n",
      "g\n",
      ",sincethe\n",
      "decodercouldalwayschoosetoperformtheseoperationsaspre-processing.\n",
      "3\n",
      "Proofs\n",
      "HereweprovidetheproofofTheorem1,alongwithanoverviewoftheproof\n",
      "ofTheorem2.Theremainingproofsaregiveninthesupplementarymaterial.\n",
      "3.1\n",
      "ProofofTheorem1\n",
      "Step1:Countingtypicaloutcomes.Weclaimthatittoconsiderthe\n",
      "casethatXisdeterministicand?isadeterministicfunctionofY;toseethis,\n",
      "wenotethatwheneitherofthesearerandomwehavePe=EX,?[P[error]],\n",
      "andtheaverageislowerboundedbytheminimum.(i)Thefollowinglemma,\n",
      "provedinthesupplementarymaterial,showspthatforanyX,eachentryof(i)\n",
      "thecorrespondingoutcomeYliesinanintervaloflengthOplogpwithhigh\n",
      "probability.\n",
      "6\n",
      "Lemma1.ForanydeterministictestvectorX2\n",
      "f\n",
      "0,1\n",
      "g\n",
      "p,andforuniformly\n",
      "distributedonB(?),wehaveforeacht2[d]thathip2PNt(,X)E[Nt(,\n",
      "X)]>plogp?2.(17)p(i)ByLemma1andtheunionbound,wehavewith\n",
      "probabilityatleast12ndp2thatNt(,X)p(i)E[Nt(,X)]?plogpforall\n",
      "8\n",
      "\n",
      "i2[n]andt2[d].LettingthiseventbedenotedbyA,wehave\n",
      "Pe\n",
      "P[Anoerror]\n",
      "P[A]\n",
      "1\n",
      "2ndp2\n",
      "P[Anoerror].\n",
      "(18)\n",
      "Next,lettingY()2[p]n?ddenoteYexplicitlyasafunctionofandsimilarly\n",
      "for?(Y)2[d]p,andlettingYAdenotethesetofmatricesYunderwhichthe\n",
      "eventAoccurs,wehaveX1P[Anoerror]=1\n",
      "f\n",
      "Y(b)2YA?(Y(b))=b\n",
      "g\n",
      "(19)\n",
      "|B(?)|b2B(?)\n",
      "|YA|?,|B(?)|\n",
      "(20)\n",
      "where(20)followssinceeacheachY2YAcanonlybecountedonceinthe\n",
      "summationof(19),duetothecondition?(Y(b))=b.Step2:Boundingtheset\n",
      "cardinalities.Byastandardcombinatorialargument(e.g.,[14,Ch.2])andthe\n",
      "factthat?isasp!1,wehave|B(?)|=ep(H(?)+o(1)).\n",
      "(21)\n",
      "Tobound|YA|,notethattheentriesofeachY(i)2[p]dsumto\n",
      "adeterministicvalue,namely,thenumberofonesinX(i).Hence,eachY\n",
      "2YAisuniquelydescribedbyasub-matrixofY2[p]n?dofsizen?(d1).\n",
      "Moreover,sinceYAonlypincludesmatricesunderwhichAoccurs,eachvaluein\n",
      "thissub-matrixonlytakesoneofatmost2plogp+1values.Asaresult,we\n",
      "havepn(d1)|YA|?2plogp+1,(22)andcombining(18)?(22)gives\n",
      "pn(d2plogp+1ep(H(?)+o(1))\n",
      "Pe\n",
      "1)\n",
      "2nd.p2\n",
      "(23)\n",
      "pH(?)pSincedisconstant,itimmediatelyfollowsthatPe!1whenevern\n",
      "?(d1)log(2(1?)plogp+1)p1forsome?>0.Applyinglog(2plogp+1)\n",
      "=2logp(1+o(1)),weobtainthefollowingnecessaryconditionforPe6!1:\n",
      "n\n",
      "(d\n",
      "2pH(?)(11)logp\n",
      "(24)\n",
      "?).\n",
      "Thisyieldsthetermin(8)correspondingtor=1.Step3:Genieargument.\n",
      "LetGbeasubsetof[d]ofcardinalityatleasttwo,andGc=[d]G.\n",
      "Moreover,Gctobealength-pvectorwith?cjj2G(Gc)j=(25)?j\n",
      "2G,\n",
      "wherethesymbol?canbethoughtofasrepresentinganunknownvalue.\n",
      "WeconsideramodidsettinginwhichagenierevealsGctothedecoder,i.e.,\n",
      "thedecoderknowsthelabelsofallitemsforwhichthelabelliesinGc,andis\n",
      "onlylefttoestimatethoseinG.Thisadditionalknowledgecanonlymakethe\n",
      "9\n",
      "\n",
      "pooleddataproblemeasier,andhence,anylowerboundinthismosetting\n",
      "remainsvalidintheoriginalsetting.(i)\n",
      "(i)\n",
      "Inthegenie-aidedsetting,insteadofreceivingthefullobservationvectorY\n",
      "(i)=(Y1,...,Yd),(i)itisequivalenttoonlybegiven\n",
      "f\n",
      "Yj:j2G\n",
      "g\n",
      ",since\n",
      "thevaluesinGcareuniquelydetermined7\n",
      "fromGcandX(i).Thismeansthatthegenie-aidedPsettingcanbecast\n",
      "intheoriginalsettingwithmoparameters:(i)pisreplacedbypG=t2G\n",
      "?tp,thenumberofitemswithunknownlabels;(ii)disreplacedby|G|,the\n",
      "numberofdistinctremaininglabels;(iii)?isreplacedby?G,tobea\n",
      "|G|-dimensionalprobabilityvectorwithentriesequalingP0?t?0(t2G).\n",
      "t2G\n",
      "Duetothisequivalence,thecondition(24)yieldsthenecessaryconditionn\n",
      "andmaximizingoverallGwith|G|2gives2pGH(?G)nmax1?.1)log\n",
      "pG?[d]:|G|2(|G|\n",
      "t\n",
      "2pGH(?G)(|G|1)logp(1\n",
      "?),\n",
      "(26)\n",
      "Step4:r=d|G|+1.Werestrictthemaximumin\n",
      "(26)tosetsGindexingthehighest|G|=dr+1valuesof?,andconsiderthe\n",
      "followingprocessforsamplingfrom?:?Drawasamplevfrom?(r)\n",
      "aboveTheorem1);\n",
      "?Ifvcorrespondstotheentryof?(r),thendrawarandomsample\n",
      "from?Gandoutputitasalabel(i.e.,thelabelshaveconditionalprobability\n",
      "proportionaltothetop|G|entriesof?);?Otherwise,ifvcorrespondsto\n",
      "oneoftheotherentriesof?(r),thenoutputvasalabel.\n",
      "ByShannon?spropertyofPentropyforsequentially-generatedrandomvari-\n",
      "ables[15,p.10],wePthatH(?)=H(?(r))+?H(?).Moreover,since\n",
      "p=p??,thiscanbewrittentGGjt2Gt2GaspGH(?G)=pH(?)H(?\n",
      "(r)).Substitutinginto(26),notingthat|G|1=drbytheofr,\n",
      "andmaximizingoverr=1,...,d1,weobtainthedesiredresult(8).3.2\n",
      "OverviewofproofofTheorem2\n",
      "Wecaninterpretthepooleddataproblemasacommunicationproblemin\n",
      "whicha?message?(i)(i)issentovera?channel?PY|N1,...,Ndvia?code-\n",
      "words?oftheform\n",
      "f\n",
      "(N1,...,Nd)\n",
      "g\n",
      "ni=1thatareconstructedbysumming\n",
      "variouscolumnsofX.Asaresult,itisnaturaltouseFano?sinequality[9,Ch.\n",
      "7]tolowerboundtheerrorprobabilityintermsofinformationcontent(entropy)\n",
      "ofandtheamountofinformationthatYrevealsabout(mutualinformation).\n",
      "However,anaiveapplicationofFano?sinequalityonlyrecoverstheboundin\n",
      "(10)with`=p?.Tohandletheotherpossiblechoicesof`,weagainconsidera\n",
      "genie-aidedsettinginwhich,foreacht2[d],thedecoderisinformedofp?t`tof\n",
      "theitemswhoselabelequalst.Hence,itonlyremainstoidentifytheremaining\n",
      "`titemsofeachtype.Thisgenieargumentisageneralizationofthatusedinthe\n",
      "proofofTheorem1,inwhicheach`twaseitherequaltoitsminimumvaluezero\n",
      "10\n",
      "\n",
      "oritsmaximumvaluep?t.InExample3ofSection2,wesawthatthisgen-\n",
      "eralizationcanleadtoastrictlybetterlowerboundincertainnoisyscenarios.\n",
      "ThecompleteproofofTheorem2isgiveninthesupplementarymaterial.\n",
      "4\n",
      "Conclusion\n",
      "Wehaveprovidednovelinformation-theoreticlowerboundsforthepooled\n",
      "dataproblem.Inthenoiselesssetting,weprovidedamatchinglowerbound\n",
      "totheupperboundof[3],establishinganexactthresholdindicatingaphase\n",
      "transitionbetweensuccessandfailure.Inthenoisysetting,weprovidedachar-\n",
      "acterizationofgeneralnoisemodelsintermsofthemutualinformation.Inthe\n",
      "specialcaseofGaussiannoise,weprovedaninherentaddedycompared\n",
      "tothenoiselesssetting,withstrictincreasesinthescalinglawsevenwhenthe\n",
      "signal-to-noiseratiogrowsunbounded.Aninterestingdirectionforfuturere-\n",
      "searchistoprovideupperboundsforthenoisysetting,potentiallyestablishing\n",
      "thetightnessofTheorem2forgeneralnoisemodels.Thisappearstobechal-\n",
      "lengingusingexistingtechniques;forinstance,thepooleddataproblembears\n",
      "similaritytogrouptestingwithlinearsparsity,whereasexistingmutualinforma-\n",
      "tionbasedupperboundsforgrouptestingarelimitedtothesub-linearregime\n",
      "[10,11,16].Inparticular,theproofsofsuchboundsarebasedonconcentration\n",
      "inequalitieswhich,whenappliedtothelinearregime,leadtoadditionalrequire-\n",
      "mentsonthenumberofteststhatpreventtightperformancecharacterizations.\n",
      "Acknowledgment:ThisworkwassupportedinpartbytheEuropeanCommis-\n",
      "sionunderGrantERCFutureProof,SNFSinergiaprojectCRSII2-147633,SNF\n",
      "200021-146750,andEPFLFellowsHorizon2020grant665667.8\n",
      "2References\n",
      "[1]I.-H.Wang,S.L.Huang,K.Y.Lee,andK.C.Chen,?Dataextractionvia\n",
      "histogramandarithmeticmeanqueries:Fundamentallimitsandalgorithms,?\n",
      "inIEEEInt.Symp.Inf.Theory,July2016,pp.1386?1390.[2]I.-H.Wang,S.\n",
      "L.Huang,andK.Y.Lee,?Extractingsparsedataviahistogramqueries,?in\n",
      "AllertonConf.Comm.,Control,andComp.,2016.[3]A.E.Alaoui,A.Ram-\n",
      "das,F.Krzakala,L.Zdeborova,andM.I.Jordan,?Decodingfrompooleddata:\n",
      "Sharpinformation-theoreticbounds,?2016,http://arxiv.org/abs/1611.09981.\n",
      "[4]??,?Decodingfrompooleddata:Phasetransitionsofmessagepassing,?\n",
      "2017,http://arxiv.org/abs/1702.02279.[5]D.-Z.DuandF.K.Hwang,Combi-\n",
      "natorialgrouptestinganditsapplications,ser.SeriesonAppliedMathematics.\n",
      "WorldScien1993.[6]A.Seb?o,?Ontworandomsearchproblems,?J.Stat.\n",
      "Plan.Inf.,vol.11,no.1,pp.23?31,1985.[7]M.MalyutovandH.Sadaka,\n",
      "?MaximizationofESI.Jaynesprinciplefortestingtinputsoflinear\n",
      "model,?Rand.Opt.Stoch.Eq.,vol.6,no.4,pp.339?358,1998.[8]W.-N.\n",
      "ChenandI.-H.Wang,?Partialdataextractionvianoisyhistogramqueries:In-\n",
      "formationtheoreticbounds,?inIEEEInt.Symp.Inf.Theory(ISIT),2017.\n",
      "[9]T.M.CoverandJ.A.Thomas,ElementsofInformationTheory.John\n",
      "Wiley&Sons,Inc.,2006.[10]M.Malyutov,?Theseparatingpropertyofran-\n",
      "11\n",
      "\n",
      "dommatrices,?Math.NotesAcad.Sci.USSR,vol.23,no.1,pp.84?91,\n",
      "1978.[11]G.AtiaandV.Saligrama,?Booleancompressedsensingandnoisy\n",
      "grouptesting,?IEEETrans.Inf.Theory,vol.58,no.3,pp.1880?1901,\n",
      "March2012.[12]C.Aksoylar,G.K.Atia,andV.Saligrama,?Sparsesignal\n",
      "processingwithlinearandnonlinearobservations:AShannon-theoretic\n",
      "approach,?IEEETrans.Inf.Theory,vol.63,no.2,pp.749?776,Feb.2017.\n",
      "[13]J.ScarlettandV.Cevher,?Limitsonsupportrecoverywithprobabilistic\n",
      "models:Aninformation-theoreticframework,?IEEETrans.Inf.Theory,vol.\n",
      "63,no.1,pp.593?620,2017.[14]I.Csisz?randJ.K?rner,InformationThe-\n",
      "ory:CodingTheoremsforDiscreteMemorylessSystems,2nded.Cambridge\n",
      "UniversityPress,2011.[15]C.E.Shannon,?Amathematicaltheoryofcom-\n",
      "munication,?BellSyst.Tech.Journal,vol.27,pp.379?423,JulyandOct.\n",
      "1948.[16]J.ScarlettandV.Cevher,?Phasetransitionsingrouptesting,?in\n",
      "Proc.ACM-SIAMSymp.Disc.Alg.(SODA),2016.[17]W.Ho?Prob-\n",
      "abilityinequalitiesforsumsofboundedrandomvariables,?J.Amer.Stat.\n",
      "Assoc.,vol.58,no.301,pp.13?30,1963.[18]J.Massey,?Ontheentropyof\n",
      "integer-valuedrandomvariables,?inInt.WorkshoponInf.Theory,1988.[19]\n",
      "G.ReevesandM.Gastpar,?Thesamplingrate-distortionforsparsity\n",
      "patternrecoveryincompressedsensing,?IEEETrans.Inf.Theory,vol.58,no.\n",
      "5,pp.3065?3092,May2012.[20]??,?Approximatesparsitypatternrecovery:\n",
      "Information-theoreticlowerbounds,?IEEETrans.Inf.Theory,vol.59,no.\n",
      "6,pp.3451?3465,June2013.[21]J.ScarlettandV.Cevher,?Howlittledoes\n",
      "non-exactrecoveryhelpingrouptesitng??inIEEEInt.Conf.Acoust.Sp.Sig.\n",
      "Proc.(ICASSP),NewOrleans,2017.[22]??,?Ontheyofselecting\n",
      "Isingmodelswithapproximaterecovery,?IEEETrans.Sig.Inf.Proc.over\n",
      "Networks,vol.2,no.4,pp.625?638,2016.[23]J.C.DuchiandM.J.Wain-\n",
      "wright,?Distance-basedandcontinuumFanoinequalitieswithapplicationsto\n",
      "statisticalestimation,?2013,http://arxiv.org/abs/1311.2669.\n",
      "9\n",
      "12\n",
      "\n",
      "PP6899.pdf\n",
      "PP6899.pdf 29\n",
      "TomographyoftheLondonUnderground:a\n",
      "ScalableModelforOrigin-DestinationData\n",
      "Authoredby:\n",
      "RicardoSilva\n",
      "Nicol?Colombo\n",
      "SoongMoonKang\n",
      "Abstract\n",
      "Thepaperaddressestheclassicalnetworktomographyproblemofin-\n",
      "ferringlocalgivenorigin-destinationobservations.Focussingon\n",
      "largecomplexpublictransportationsystems,webuildascalablemodel\n",
      "thatexploitsinput-outputinformationtoestimatetheunobservedlink/station\n",
      "loadsandtheuserspathpreferences.Basedonthereconstructionofthe\n",
      "users'traveltimedistribution,themodelisenoughtocapture\n",
      "possibletpath-choicestrategiesandcorrelationsbetweenusers\n",
      "travellingonsimilarpathsatsimilartimes.Thecorrespondinglikelihood\n",
      "functionisintractableformediumorlarge-scalenetworksandwepropose\n",
      "twodistinctstrategies,namelytheexactmaximum-likelihoodinferenceof\n",
      "anapproximatebuttractablemodelandthevariationalinferenceofthe\n",
      "originalintractablemodel.Asanapplicationofourapproach,weconsider\n",
      "theemblematiccaseoftheLondonUndergroundnetwork,whereatap-\n",
      "in/tap-outsystemtracksthestart/exittimeandlocationofalljourneysin\n",
      "aday.AsetofsyntheticsimulationsandrealdataprovidedbyTransport\n",
      "ForLondonareusedtovalidateandtestthemodelonthepredictionsof\n",
      "observableandunobservablequantities.\n",
      "1PaperBody\n",
      "Inthelastdecades,networkshavebeenplayinganincreasinglyimportantrole\n",
      "inourall-daylives[1,2,3,4,5,6].Mostofthetime,networkscannotbe\n",
      "inspecteddirectlyandtheirpropertiesshouldbereconstructedformend-point\n",
      "orpartialandlocalobservations[7,8].Theproblemhasbeenreferredtoas\n",
      "network?tomography?,amedicalwordtodenoteclinicaltechniquesthatpro-\n",
      "ducedetailedimagesoftheinteriorofthebodyfromexternalsignals[9,10].\n",
      "Nowadaystheconceptoftomographyhasgainedwidermeaningsandtheidea\n",
      "applies,intforms,tomanykindsofcommunicationandtransportation\n",
      "networks[11,12,13].Inparticular,astheavailabilityofhugeamountsofdata\n",
      "hasgrownexponentially,networktomographyhasbecomeanimportantbranch\n",
      "1\n",
      "\n",
      "ofstatisticalmodelling[14,15,16,17,8].However,duetothecomplexityof\n",
      "thetask,existingmethodsareusuallyonlydesignedforsmall-sizenetworksand\n",
      "becomeintractableformostreal-worldapplications(see[7,18]foradiscussion\n",
      "onthispoint).Thecaseoflargepublictransportationnetworkshasattracted\n",
      "specialattentionsincemassivedatasetsofinput-outputsingle-userdatahave\n",
      "beenproducedbytap-inandtap-outsystemsinstalledinbigcityasLondon,\n",
      "SingaporeandBeijing[19,20,18,21].31stConferenceonNeuralInformation\n",
      "ProcessingSystems(NIPS2017),LongBeach,CA,USA.\n",
      "Dependingontheavailablemeasurements,twocomplementaryformulations\n",
      "ofnetworktomographyhavebeenconsidered:(i)thereconstructionoforigin-\n",
      "destinationdistributionsfromlocalandpartialobservations[11,14,9,\n",
      "15,16]and(ii)theestimationofthelinkandnodeloadsfrominputoutput\n",
      "information[22,23,24].Inpractice,theknowledgeoftheunobservedquantities\n",
      "mayhelpdesignstructuralimprovementsofthenetworkorbeusedtopredict\n",
      "thesystem?sbehaviourincaseofdisruptions[25,26,13,27,28].Focusingon\n",
      "thesecond(alsoreferredtoas?dual?)formulationofthetomographyproblem,\n",
      "thispaperaddressesthechallengingcasewhereboththeamountofdataand\n",
      "thesizeofthenetworkarelarge.Whenonlyaggregateddataareobservable,\n",
      "wsoveragivennetworkcanalsobeanalysedbymethodssuchas\n",
      "collectivegraphicalmodelsfordynamics[29,30].Animportantreal-\n",
      "worldapplicationofdualnetworktomographyisreconstructingthetcofbits\n",
      "sentfromasourcenodetoadestinationnodeinanetworkofservers,terminals\n",
      "androuters.Theusualassumption,inthosecases,isthetreestructureof\n",
      "thenetworkandmodelsinferthebitstrajectoriesfromaseriesoflocaldelays,\n",
      "i.e.lossfunctionsateachlocationinthenetwork[22,23,24].The\n",
      "posteriorofthetraveltimedistributionateachintermediatepositionalongthe\n",
      "pathisthenusedtoreconstructtheunobservedlocalloads,i.e.thenumber\n",
      "ofpacketsatagivennodeandtime.Weextendandapplythisgeneralidea\n",
      "tourbanpublictransportationsystems.Thetobeestimatedisthew\n",
      "ofpeopletravellingacrossthesystemduringaday,i.e.thenumberofpeople\n",
      "atagivenlocationandtime(station/linkload).Thenodesofthenetwork\n",
      "are(>100)undergroundstations,connectedvia(?10)partiallyoverlapping\n",
      "underground?lines?,whichcanbelookatasinteracting?layers?ofconnectivity\n",
      "[31].Theobservationsaresingle-userrecordswithinformationabouttheorigin,\n",
      "destination,startingtimeandexittimeofeachjourney.Twokeyunobserved\n",
      "quantitiestobeestimatedare(i)theusers?pathpreferencesforagivenorigin-\n",
      "destinationpair[32,28]and(ii)thestation/linkloads[33,34,35].Puttogether,\n",
      "amodelfortheusers?pathpreferencesandapreciseestimationofthelocal\n",
      "trainloadscanhelpdetectnetworkanomaliesorpredictthebehaviourofthe\n",
      "systemincaseofpreviouslyunobserveddisruptions[18,27,21].Respectto\n",
      "theclassicalcommunicationnetworkcase,modellingacomplextransportation\n",
      "systemrequiresthreechallengingextensions:(i)thenetworkstructureisa\n",
      "multi-layer(loopy)network,whereusersareallowedto?changeline?onthose\n",
      "nodesthataresharedbytlayers;(ii)theuser?schoicebetweenmany\n",
      "feasiblepathsfollowsrulesthatcangofarbeyondsimplelength-relatedschemes;\n",
      "(iii)harderphysicalconstraints(thetraintimescheduleforexample)maycreate\n",
      "2\n",
      "\n",
      "highcorrelationsbetweenuserstravellingonthesamepathatsimilartimes.\n",
      "Takingintoaaccountsuchpeculiarfeaturesoftransportationnetworks,while\n",
      "keepingthemodelscalablerespecttoboththesizeofthenetworkandthe\n",
      "dataset,isthemaincontributionofthiswork.ModeloutlineWerepresentthe\n",
      "transportationsystembyasparsegraph,whereeachnodeisassociatedwith\n",
      "anundergroundstationandeachedgewithaphysicalconnectionbetweentwo\n",
      "stations.Thefullnetworkisthesumofsimplesub-graphs(lines)connectedby\n",
      "setsofsharednodes(wheretheusersareallowedtochangeline)[31].Foragiven\n",
      "origin-destinationpair,theremayexistanumberofpossiblesimple(non\n",
      "redundant)trajectories,correspondingtodistinctline-changestrategies.The\n",
      "unobserveduser?schoiceistreatedasalatentvariabletakingvaluesoverthe\n",
      "setofallfeasiblepathsbetweentheoriginanddestination.Thecorresponding\n",
      "probabilitydistributionmaydependonthelengthofthepath,i.e.thenumber\n",
      "ofnodescrossedbythepath,oranyotherarbitraryfeatureofthepath.Inour\n",
      "multi-layerssetup,forexample,itisnaturaltoincludea?depth?parameter\n",
      "takingintoaccountthenumberoflayersvisited,i.e.thenumberoflineschanges.\n",
      "Foranyfeasiblepath?=[?1,...,>],thetraveltimeattheintermediate\n",
      "stationsisbytherecursiverelationt(?i)?t(?i?1)+Poisson(a(?i?1,\n",
      "so+t(?i?1),?))\n",
      "i=1,...,`\n",
      "(1)\n",
      "wheret(x)theistraveltimeatlocationx?\n",
      "f\n",
      "?1,...,>\n",
      "g\n",
      ",soisthestarting\n",
      "time,a=a(x,so+t(x),?)arelocaldelaysthatdependonthelocation,x,the\n",
      "absolutetimeso+t(x)andthepath?.ThechoiceofthePoissondistribution\n",
      "isconvenient1inthisframeworkduetoitssimplesingle-parameterformand\n",
      "thefactthatt(x)isanintegerinthedatasetthatmotivatesthiswork(travel\n",
      "timeisrecordedinminutes).Thedependenceon?allowsincludingglobal\n",
      "path-relatedfeatures,suchas,forexample,anextradelayassociatedtoeach\n",
      "linechangealongthepathorthetimespentbytheuserwhilewalkingthrough\n",
      "theoriginanddestinationstations.Thedependenceonsoandt(x)iswhat\n",
      "ensures1\n",
      "Otheroptionsincludenegativebinomialandshiftedgeometricdistributions\n",
      "2\n",
      "thescalabilityofthemodelbecausealluserscanbetreatedindependently\n",
      "giventheirstartingtime.Thelikelihoodassociatedwithalljourneysinaday\n",
      "hasafactorisedform(1)\n",
      "(N)\n",
      "(N)p(td,...,td|s(1)o,...,so)=\n",
      "NY\n",
      "(n)\n",
      "p(td|s(n)o)\n",
      "(2)\n",
      "n=1(n)\n",
      "wheretdisthetotaltraveltimeofthenthuserandNthetotalnumber\n",
      "ofusersinadayandeach(n)(n)p(td|so)dependsonlylocallyonthe\n",
      "modelparameters,i.e.onthedelayfunctionsassociatedwiththenodescrossed\n",
      "3\n",
      "\n",
      "bythecorrespondingpath.Thedrawbackisthatanexactcomputationof\n",
      "(2)isintractableandoneneedsapproximateinferencemethodstoidentifythe\n",
      "modelparametersfromthedata.Weaddresstheinferenceproblemintwo\n",
      "complementaryways.Theoneisamodel-approximationmethod,where\n",
      "weperformtheexactinferenceoftheapproximate(tractable)modelt(?i)?\n",
      "t(?i?1)+Poisson(a(?i?1,so+t?i?1,?))\n",
      "i=1,...,`\n",
      "(3)\n",
      "wheret?i?1isadeterministicfunctionofthemodelparametersthatisde-\n",
      "bytheequationt?i=t?i?1+a(?i?1,so+t?i?1,?)\n",
      "i=1,...,`\n",
      "(4)\n",
      "Thesecondoneisavariationalinferenceapproachwherewemaximisea\n",
      "lowerboundoftheintractablelikelihoodassociatedwith(1).Inbothcases,\n",
      "weusestochasticgradientupdatestosolveiterativelythecorrespondingnon-\n",
      "convexoptimization.Sincetheclosedformsolutionof(4)isingeneralnot\n",
      "available,thegradientsoftheobjectivefunctionscannotbecomputedexplic-\n",
      "itly.Ateachiteration,theyareobtainedrecursivelyfromasetof\n",
      "equationsderivedfrom(4),followingaschemethatcanbeseenasasimplever-\n",
      "sionoftheback-propagationmethodusedtotrainneuralnetworks.Finally,we\n",
      "initializetheiterativealgorithmsbymeansofamethodofmomentsestimation\n",
      "ofthetime-independentpartofthedelayfunctions.Choosingarandomdistri-\n",
      "butionoverthefeasiblepaths,thisisobtainedfromtheempiricalmomentsof\n",
      "thetraveltimedistribution(oftheapproximatemodel(10))bysolvingaconvex\n",
      "optimizationproblem.LondonundergroundexperimentsThepredictivepower\n",
      "ofourmodelistestedviaaseriesofsyntheticandreal-worldexperimentsbased\n",
      "ontheLondonundergroundnetwork.Alldetailsofthemulti-layerstructure\n",
      "ofthenetworkcanbefoundin[36].Inthetrainingstepweuseinput-output\n",
      "datathatcontaintheorigin,thedestination,thestartingtimeandtheexit\n",
      "timeofeach(pseudonymised)userofthesystem.Thiskindofdataarepro-\n",
      "ducednowadaysbytap-in/tap-outsmartcardsystemssuchastheOysterCard\n",
      "systemsinLondon[19].Thetrainedmodelscanthenusedtopredicttheun-\n",
      "observednumberofpeopletravellingthroughagivenstationatagiventime\n",
      "intheday,aswellastheuser?spathpreferencesforgivenorigin-destination\n",
      "pair.Inthesyntheticexperiments,wecomparedthemodelestimationswith\n",
      "thevaluesproducedbythe?ground-truth?(asetofrandomparametersusedto\n",
      "generatethesyntheticdata)andtesttheperformanceofthetwoproposedin-\n",
      "ferencemethods.Inthereal-worldexperiment,weusedoriginalpseudonymised\n",
      "dataprovidedbyTransportforLondon.Thedatasetconsistedofmorethan\n",
      "500000origindestinationrecords,fromjourneysrealisedinasingledayonthe\n",
      "busiestpartoftheLondonundergroundnetwork(Zone1and2,see[36]),and\n",
      "asubsetofNetMISrecords[37]fromthesameday.NetMISdatacontainre-\n",
      "altimeinformationaboutthetrainstransitingthroughagivenstationand,for\n",
      "anhandfulofmajorundergroundstations(allofthemontheVictorialine),\n",
      "includequantitativeestimationoftherealtimetrainweights.Thelattercanbe\n",
      "interpretedasaproxyoftherealtime(unobserved)numberofpeopletravel-\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lingthroughthecorrespondingnodesofthenetworkandusedtoevaluatethe\n",
      "model?spredictionsinaquantitativeway.Themodelhasalsobeentestedona\n",
      "out-of-sampleOyster-carddatasetbycomparingexpectedandobservedtravel\n",
      "timebetweenaselectionofstationpairs.Unfortunately,wearenotawareof\n",
      "anyexistingalgorithmthatcouldbeapplicableforafaircomparisononsimilar\n",
      "settings.\n",
      "2\n",
      "Traveltimemodel\n",
      "Leto,dandsobetheorigin,thedestinationandthestartingtimeofauser\n",
      "travellingthroughthesystem.Let?odbethesetofallfeasiblepathsbetween\n",
      "oandd.Thentheprobabilityofobservinga3\n",
      "traveltimetdisamixtureofprobabilitydistributionsX\n",
      "p(td)=\n",
      "e?L(?)?L(?)???ode\n",
      "ppath(?)p(td|?)\n",
      "ppath(?)=P\n",
      "???od\n",
      "(5)\n",
      "wheretheconditionalp(td|?)canbeinterpretedasthetraveltimeprob-\n",
      "abilityoveraparticularpath,ppath(?)istheprobabilityofchoosingthat\n",
      "particularpathandL(?)issomearbitraryelength?ofthepath?.\n",
      "Accordingto(1),theconditionalprobabilitiesp(td|?)arecomplicatedcon-\n",
      "volutionsofPoissondistributions.Anequivalentbutmoreintuitiveformulation\n",
      "istd=\n",
      "`(?)X\n",
      "ri?Poisson(a(?i?1,so+\n",
      "ri\n",
      "i=2\n",
      "`X\n",
      "rk,?))\n",
      "??Ppath(L(?))\n",
      "(6)\n",
      "k=2\n",
      "wherethetraveltimetdisexplicitlyexpressedasthesumofthelocaldelays,\n",
      "ri=t(?i)?t(?i?1),alongafeasiblepath???od.Sincethetimeatthe\n",
      "intermediatepositions,i.e.t(?i)fori6=1,`,isnotobserved,thelocaldelays\n",
      "r2,...,r`(?)aretreatedashiddenvariables.Letting`?=max???od`(?),\n",
      "thecompletelikelihoodisp(r1,...,r`?,?)=p(r1,...,r`?|?)ppath(?)\n",
      "p(r1,...,r`?|?)=\n",
      "`?Ye??i?rii\n",
      "i=1\n",
      "ri!\n",
      "(7)\n",
      "Pi?1where?i=a(?i?1,so+k=2rk,?)ifi?`(?)and?i=0ifi>\n",
      "`(?).Marginalizingoverallhiddenvariablesoneobtainstheexplicitformofthe\n",
      "conditionalprobabilitydistributionsinthemixture(5),i.e.p(td|?)=\n",
      "5\n",
      "\n",
      "?X\n",
      "???\n",
      "r2=0\n",
      "?X\n",
      "?(td?\n",
      "r`?=0\n",
      "`?X\n",
      "ri)\n",
      "i=2\n",
      "`?Ye??i?rii\n",
      "i=2\n",
      "ri!\n",
      "(8)\n",
      "Since?i=?i(ri?1,...,r2)foreachi=2,...,`,theevaluationof\n",
      "eachconditionalprobabilitiesrequiresperforminga(`?1)-dimensional\n",
      "sum,whichisnumericallyintractableandmakesanexactmaximumlikelihood\n",
      "approachinfeasible.2\n",
      "3\n",
      "Inference\n",
      "Anexactmaximumlikelihoodestimationofthemodelparametersina(x,\n",
      "s,?)andL(?)isinfeasibleduetotheintractabilityoftheevidence(8).One\n",
      "possibilityistouseaMonteCarloapproximationoftheexactevidence(8)by\n",
      "samplingfromthenestedPoissondistributions.Inthissectionweproposetwo\n",
      "alternativemethodsthatdonotrequiresamplingfromthetargetdistribution.\n",
      "Themethodisbasedontheexactinferenceofanapproximatebuttractable\n",
      "model.Thelatterdependsonthesameparametersastheoriginalone(the?ref-\n",
      "erence?model(6))butissuchthatthelocaldelaysbecomeindependentgiven\n",
      "thepathandthestartingtime.Thesecondapproachconsistsofanapproximate\n",
      "variationalinferenceof(6)withthevariationalposteriordistributionin\n",
      "termsofthedeterministicmodel(4).3.1\n",
      "Exactinferenceofanapproximatemodel\n",
      "Weconsidertheapproximationofthereferencemodel(6)bytd=\n",
      "`(?)X\n",
      "ri\n",
      "ri?Poisson(a(?i?1,so+t?i?1,?))\n",
      "??Ppath(L(?))\n",
      "(10)\n",
      "i=22\n",
      "Anexactevaluationofthemomentshtndi\n",
      "=\n",
      "?Xt=0\n",
      "n\n",
      "tp(t)=\n",
      "X???od\n",
      "?X`?`?XYe??i?riinppath(?)???(ri)ri!r=0r=0i=2i=2?X2\n",
      "isalsointractable.\n",
      "6\n",
      "\n",
      "4\n",
      "?`\n",
      "(9)\n",
      "wherethet?iareobtainedrecursivelyfrom(4).Inthiscase,the`(?)?1\n",
      "localdelaysriaredecoupledandthecompletelikelihoodisgivenbyp(r1,...\n",
      ",r`?,?)=p(r1,...,r`?|?)ppath(?)\n",
      "p(r1,...,r`?|?)=\n",
      "`?Ye??i?rii\n",
      "ri!\n",
      "i=1\n",
      "(11)\n",
      "where?i=a(?i?1,so+t?i?1(?),?)ifi?`(?)and?i=0ifi>`(?).Noting\n",
      "thattdisthesumofindependentPoissonrandomvariables,wehavep(td)=\n",
      "X\n",
      "ppath(?)\n",
      "???od\n",
      "tdX\n",
      "...,\n",
      "r2=0P`?i=2?i\n",
      "tdX\n",
      "?(td?\n",
      "r`?=0\n",
      "`?X\n",
      "ri)\n",
      "i=2\n",
      "`?Ye??i?rii\n",
      "i=2\n",
      "ri!\n",
      "=\n",
      "X\n",
      "ppath(?)\n",
      "???od\n",
      "e?t>?t>t?dtd!\n",
      "(12)\n",
      "wherewehaveused=t>?.TheparametersinthemodelfunctionaandLcan\n",
      "thenbeidenwiththesolutionofthefollowingnon-convexmaximization\n",
      "problemDXDT?1XTXXmaxa,LN(o,d,so,sd)logp(sd?so)(13)\n",
      "o=1d=1so=0sd=so\n",
      "whereN(o,d,so,sd)isthenumberofuserstravellingfromotodwith\n",
      "enterandexittimesoandsdrespectively.3.2\n",
      "Variationalinferenceofmodeltheoriginalmodel\n",
      "Wetheapproximateposteriordistribution?\n",
      "q(r,?)=q(r|?)qpath(?)\n",
      "q(r|?)=pmulti(r;td,?)\n",
      "q(?)=P\n",
      "e?L(?,td)\n",
      "7\n",
      "\n",
      "(14)\n",
      "?\n",
      "???ode?L(?,td)\n",
      "???wherewehaver=[r2,...,r`?],?i=ti?t?t?i?1,with\n",
      "t?i=t?i?1forall`(?)<i?`,`rP`?Q`??ii?td)dependsonthepath,?,\n",
      "pmulti(r;td,?)=?(td?i=2ri)td!i=2ri!andthefunctionL(?,?td),\n",
      "thevariationaldistributionandtheobservedtraveltime,td.Exceptforthe\n",
      "correctedlengthL(?,(14)sharethesameparametersoveralldatapointsand\n",
      "canbeuseddirectlytoevaluatethelikelihoodlowerbound(ELBO)L=Eq\n",
      "(logp(td))?Eq(logq)3.Onehas\n",
      "X\n",
      "L(o,d,so,td)=?logtd!+\n",
      "qpath(?)log\n",
      "???od\n",
      "Li(?)=\n",
      "tdX\n",
      "...,\n",
      "r2=1\n",
      "tdX\n",
      "???od\n",
      "pmulti(r;td,?)\n",
      "r`?=1\n",
      "`?XXppath(?)+qpath(?)Li(?)qpath(?)i=2\n",
      "`?X\n",
      "(??i+rilog\n",
      "i=2a(?i?1,so+t?i?1)t>?\n",
      "?i)?i\n",
      "(15)\n",
      "Pi?1with?i=a(?i?1,so+k=2rk)and?i=ifi?`(?)and?i=0=\n",
      "?iifi>`(?).TheexactevaluationofeachLi(?)isstillintractableduetothe\n",
      "multidimensionalsum.However,sinceforany?andi=2,...,`,?idepends\n",
      "onlyonthe?previous?delaysandwecant?i?1t???t?i?past=?future\n",
      "=`?i=a(?i?1,so+rpast)(16)t>?t>?whererpast=r2+???+ri?1and\n",
      "rfuture=ri+1+???+r`?,andbythegroupingpropertyofthemultinomial\n",
      "distributionweobtaintdtdXX?iLi(?)=pmulti(r(i),td,?(i))(??i+ri\n",
      "log)(17)?ir=1r=1future\n",
      "i\n",
      "wherer(i)=[rpast,ri,rfuture]and?(i)=[?future,?i,?past].Every\n",
      "Li(?)cannowbecomputedinO(t3d)operationsandthemodelparameter\n",
      "idenwiththesolutionofthefollowingnon-convexoptimizationproblemD\n",
      "XDT?1XTXXmaxa,L,L?N(o,d,so,sd)L(o,d,so,sd?so)(18)o=1\n",
      "d=1so=0sd=so3\n",
      "Similar?amortised?approacheshavebeenusedelsewheretomaketheap-\n",
      "proximateinferencescalable[38,39]\n",
      "5\n",
      "optimization\n",
      "8\n",
      "\n",
      "pathchoiceprobability\n",
      "0.50.8\n",
      "VIML\n",
      "1.96.9770.7\n",
      "0.45\n",
      "0.60.4\n",
      "|popt-ptrue|\n",
      "predictionerror\n",
      "0.50.35\n",
      "0.3\n",
      "0.4\n",
      "0.3\n",
      "0.250.2\n",
      "0.20.1\n",
      "0\n",
      "0.150\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "10\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "|uniform-ptrue|\n",
      "log(runtime)\n",
      "Figure1:Ontheleft,stochasticiterativesolutionof(18)(VI)and(13)(ML)\n",
      "forthesyntheticdataset.Ateachiteration,thepredictionerrorisobtainedon\n",
      "asmallout-of-sampledataset.Ontheright,distancefromtheground-truth\n",
      "oftheuniformdistribution(x-axis)andthemodels?pathprobability(y-axis)\n",
      "forvariousorigin-destinationpairs.Inthelegendbox,totaldistancefromthe\n",
      "ground-truth.\n",
      "StochasticgradientdescentBoth(13)and(18)consistofO(D2T2)terms\n",
      "andtheestimationoftheexactgradientateachiterationcanbeexpansivefor\n",
      "largenetworksD>>1ortimeresolutionsT>>1.Acommonpracticeinthis\n",
      "9\n",
      "\n",
      "caseistouseastochasticapproximationofthegradientwhereonlyarandom\n",
      "selectionoforigin-destinationpairsandstartingtimesareused.Notethateach\n",
      "L(o,d,so,td)dependsona(x,s,?)onlyifthelocationxiscrossedbyat\n",
      "leastoneofthefeasiblepathsbetweenoandd.P?InitializationTheanalytic\n",
      "formofthemomentsof(12),htdiso=td=1tdp(td)=P????odppath\n",
      "(?)t`(?),canbeusedtoobtainapartialinitializationoftheiterativealgorithms\n",
      "viaasimplemoment-matchingtechnique.Weassumethat,averagingoverall\n",
      "possiblestartingtime,thesystembehaveslikeasimplecommunicationnetwork\n",
      "withconstantdelaysateachnodesor,equivaPTlently,thata(x,s,?)=?(x)\n",
      "+V(x,s,?),withs=0V(x,s,?)=0.Inthiscaseaninitializationof?(x)is\n",
      "obtainedbysolvingmin?\n",
      "`(?)?1DXDXXX(tod?ppath(?)?(?k))2o=1d=1\n",
      "???od\n",
      "(19)\n",
      "k=1\n",
      "PT?1PTPT?1PTwheretod=Z1so=0sd=soN(o,d,so,sd)(sd\n",
      "?so),withZ=so=0sd=soN(o,d,so,sd),isthe?averaged?empirical\n",
      "momentscomputedfromthedata.Notethat(19)isconvexforany1\n",
      "choiceofppath(?).TotalderivativesAlltermsin(13)and(18)areintheform\n",
      "g=g(?,t?i),where?denotesthemodelparametersandt?i=t?i(?)isdened\n",
      "bythedrenceequation(4).Sincet?iisnotavailableasanexplicitfunction\n",
      "of?itisnotpossibletowriteg=g(?)orcomputedirectlyitsgradient??g.\n",
      "Awayoutistocomputethetotalderivativeofthefunctiongwithrespectto\n",
      "?,i.e.dg(?,t?i)?g(?,t?i)?g(?,t?i)dt?i=+d????t?id?where\n",
      "(20)\n",
      "dt?id?,\n",
      "fori=1,...,`,canbeobtainedfromtheiterativeintegrationof\n",
      "dt?idt?i?1?a(x,s,?))?a(x,s,?))dt?i?1=++i=1,...,`\n",
      "d?d????ss=t?i?1d?\n",
      "(21)\n",
      "whichisimpliedby(4).\n",
      "4\n",
      "Experiments\n",
      "Themethoddescribedintheprevioussectionsiscompletelygeneraland,\n",
      "exceptfortheinitializationstep,nospecialformofthemodelfunctionsisas-\n",
      "sumed.Inordertocapturesfewkeyfeaturesof6\n",
      "OxfordCircustoWaterlooLU\n",
      "20\n",
      "15\n",
      "10\n",
      "35\n",
      "#ofpeople\n",
      "25\n",
      "true0.091520.09095\n",
      "40\n",
      "3025\n",
      "10\n",
      "\n",
      "50\n",
      "40\n",
      "40\n",
      "302010\n",
      "20\n",
      "0200\n",
      "2010\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "3020100\n",
      "0\n",
      "200\n",
      "time0.0165\n",
      "10\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "0\n",
      "200\n",
      "time0.0151\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "time0.01355\n",
      "50\n",
      "50\n",
      "50\n",
      "40\n",
      "40\n",
      "40\n",
      "1000\n",
      "1200\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "startingtime\n",
      "WaterlooLUtoPaddingtonLU\n",
      "PaddingtonLUtoKingsCrossLU\n",
      "11\n",
      "\n",
      "80\n",
      "5045\n",
      "true0.11920.1131\n",
      "40\n",
      "50403020\n",
      "35\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "startingtime\n",
      "2010\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "30\n",
      "3020100\n",
      "0\n",
      "200\n",
      "time0.01263\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "0\n",
      "200\n",
      "time0.01293\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "time0.01341\n",
      "50\n",
      "50\n",
      "50\n",
      "40\n",
      "40\n",
      "40\n",
      "252015\n",
      "302010\n",
      "00\n",
      "30\n",
      "12\n",
      "\n",
      "00\n",
      "5\n",
      "0\n",
      "100\n",
      "1010\n",
      "20\n",
      "true0.17150.1486\n",
      "#ofpeople\n",
      "60\n",
      "exptraveltime\n",
      "70\n",
      "30\n",
      "#ofpeople\n",
      "800\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "0\n",
      "1200\n",
      "3020100\n",
      "0\n",
      "startingtime\n",
      "#ofpeople\n",
      "600\n",
      "startingtime\n",
      "#ofpeople\n",
      "400\n",
      "#ofpeople\n",
      "200\n",
      "#ofpeople\n",
      "00\n",
      "exptraveltime\n",
      "30\n",
      "00\n",
      "15\n",
      "5\n",
      "PaddingtonLU\n",
      "50\n",
      "40\n",
      "5\n",
      "0\n",
      "OxfordCircus\n",
      "50\n",
      "13\n",
      "\n",
      "#ofpeople\n",
      "45\n",
      "exptraveltime\n",
      "exptraveltime\n",
      "KingsCrossLU\n",
      "50\n",
      "true0.29910.2376\n",
      "30\n",
      "#ofpeople\n",
      "KingsCrossLUtoOxfordCircus35\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "time\n",
      "10001200\n",
      "3020100\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "time\n",
      "10001200\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "10001200\n",
      "time\n",
      "Figure2:Ontheleft,traveltimepredictedbytheVImodel(inblue)andthe\n",
      "MLmodel(inred)ofFigure1andtheground-truthmodel(ingreen)plotted\n",
      "againstthestartingtimeforaselectionoforigin-destinationpairs.Inthelegend\n",
      "box,normalisedtotaldistance(kvexp?vtruek/kvtruek)betweenmodel?s\n",
      "andground-truth?spredictions.Ontheright,stationloadspredictedbythe\n",
      "ground-truth(ingreen)andtheVImodel(inblue)andMLmodel(inred)of\n",
      "Figure1.ThethreemodelsandareduceddatasetofN=10000trueorigin,\n",
      "destinationandstartingtimerecordshasbeenusedtosimulatethetrajectories\n",
      "ofNsyntheticusers.Foreachmodel,theNsimulatedtrajectoriesgivetheusers\n",
      "expectedpositionsatalltimes(thepositionissetto0iftheusersisnotyetinto\n",
      "thesystemorhashisjourney)thathavebeenusedtocomputethetotal\n",
      "numberofpeoplebeingatagivenstationatagiventime.Thereportedscoreis\n",
      "thetotaldistancebetweenmodel?sandground-truth?snormalisedpredictions.\n",
      "Forstationx,thenormalisedloadvectorisvx/1Tvxwherevx(s)isthenumber\n",
      "ofpeoplebeingatstationxattimes.\n",
      "14\n",
      "\n",
      "alargetransportationsystemandapplythemodeltothetomographyof\n",
      "theLondonunderground,wehavechosenthespparametrizationofthe\n",
      "functionL(?)anda(x,s,?)giveninSection4.1.Theparametrisedmodelhas\n",
      "thenbeentrainedandtestedonaseriesofsyntheticandreal-worlddatasetsas\n",
      "describedinSection4.2.4.1\n",
      "Parametrization\n",
      "Foreachoriginoandthedestinationd,wehavereducedthesetofallfeasible\n",
      "paths,?od,toasmallsetincludingtheshortestpathandfewperturbations\n",
      "oftheshortestpath(byforcingtchoicesattheline-changepoints).\n",
      "LetC(?)?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "`suchthatC(?i)=1iftheuserchangeslineat?iandzero\n",
      "otherwise.ToPparametrizethepathprobability(5)wechoseL(?)=?1`(?)+\n",
      "?2c(?)where`(?)=|?|,c(?)=iC(?i)and?1,?2?Rarefreeparameters.\n",
      "Theposterior-correctede?td)in(14)wasaslengthL(?,?L(?)\n",
      "=?>`(?)+??cc(?)\n",
      "?2??i=?i1+?i2u+?i3u?1u=t??2i=`,c(22)d(td?td)Pwheretd\n",
      "istheobservedtraveltime,t?d=o,d,so,sdN(o,d,so,sd)(sd?so)and?ij\n",
      "?R,i=`,cPandj=1,2,3,areextrafreeparameters.Aregularizationterm\n",
      "?(k?k2+i=`,ck?ik2),with?=1/80,hasbeenaddedtohelptheconvergence\n",
      "ofthestochasticalgorithm.Weletthelocaltime-dependentdelayatlocation\n",
      "xandtimesbea(x,s,?)=softplus(?(x)+V(x,s)+W(x,?))withV=\n",
      "N?N?XXi=1j=1\n",
      "?ij(x)cos(?is+?j)\n",
      "W1=\n",
      "`X\n",
      "?(x)?x,?iC(?i)+?(x)(?x,?1+?x,>)\n",
      "(23)\n",
      "i=1\n",
      "where?(x),?(x),?(x)?Rand?(x)?RN??N?arefreeparametersand\n",
      "f\n",
      "?1\n",
      ",...?N?\n",
      "g\n",
      "and\n",
      "f\n",
      "?1,...?N?\n",
      "g\n",
      "twosetsoflibraryfrequenciesandphases.In\n",
      "thesyntheticsimulation,wehaverestrictedtheLondonundergroundnetwork\n",
      "[36]toZone1(63stations),chosenN?=5=N?andsetW=0.Forthe\n",
      "real-dataexperimentswehaveconsideredZone1and2(131stations),N?=10,\n",
      "N?=5andW6=0.7\n",
      "1.0873\n",
      "0.9043\n",
      "80\n",
      "0.59661\n",
      "0.898\n",
      "120\n",
      "120\n",
      "120\n",
      "100\n",
      "100\n",
      "100\n",
      "50403020\n",
      "80\n",
      "15\n",
      "\n",
      "60\n",
      "40\n",
      "20\n",
      "predictedtraveltime\n",
      "60\n",
      "predictedtraveltime\n",
      "predictedtraveltime\n",
      "predictedtraveltime\n",
      "70\n",
      "80\n",
      "60\n",
      "40\n",
      "20\n",
      "80\n",
      "60\n",
      "40\n",
      "20\n",
      "100\n",
      "010\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "00\n",
      "10\n",
      "20\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "00\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "0\n",
      "50\n",
      "0.35173\n",
      "16\n",
      "\n",
      "0.263480\n",
      "70\n",
      "70\n",
      "50403020\n",
      "605040302010\n",
      "030\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "605040302010\n",
      "020\n",
      "predictedtraveltime\n",
      "80\n",
      "70\n",
      "predictedtraveltime\n",
      "80\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "0.20544\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "0.18855\n",
      "0\n",
      "3020\n",
      "6050403020\n",
      "10\n",
      "10\n",
      "10\n",
      "0\n",
      "0\n",
      "0\n",
      "30\n",
      "40\n",
      "17\n",
      "\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "predictedtraveltime\n",
      "predictedtraveltime\n",
      "predictedtraveltime\n",
      "70\n",
      "truetraveltime\n",
      "30\n",
      "40\n",
      "50\n",
      "70\n",
      "80\n",
      "0.230880\n",
      "20\n",
      "20\n",
      "0.3599970\n",
      "20\n",
      "10\n",
      "truetraveltime\n",
      "80\n",
      "40\n",
      "60\n",
      "20\n",
      "80\n",
      "70\n",
      "50\n",
      "80\n",
      "30\n",
      "80\n",
      "30\n",
      "70\n",
      "40\n",
      "70\n",
      "40\n",
      "60\n",
      "18\n",
      "\n",
      "50\n",
      "80\n",
      "50\n",
      "80\n",
      "60\n",
      "truetraveltime\n",
      "60\n",
      "70\n",
      "00\n",
      "truetraveltime\n",
      "60\n",
      "60\n",
      "10\n",
      "00\n",
      "truetraveltime\n",
      "10\n",
      "40\n",
      "0.22488\n",
      "60\n",
      "0\n",
      "30\n",
      "truetraveltime\n",
      "0.2869370\n",
      "10\n",
      "20\n",
      "truetraveltime\n",
      "80\n",
      "0\n",
      "10\n",
      "truetraveltime\n",
      "10\n",
      "predictedtraveltime\n",
      "30\n",
      "truetraveltime\n",
      "predictedtraveltime\n",
      "predictedtraveltime\n",
      "0\n",
      "6050403020100\n",
      "0\n",
      "10\n",
      "truetraveltime\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "19\n",
      "\n",
      "70\n",
      "80\n",
      "0\n",
      "truetraveltime\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "truetraveltime\n",
      "Figure3:Traveltimespredictedbyarandommodel(top),theinitialization\n",
      "model(middle)obtainedfrom(19)andtheMLmodel(bottom)arescattered\n",
      "againsttheobservedtraveltimesofanout-of-sampletestdataset(realdata).\n",
      "Theplotsinthethreecolumnsshowtheprediction-errorofeachmodel\n",
      "onthreesubsetsofthetestsample,Sshortcolumn),Smedium(second\n",
      "column)andSlong(thirdcolumn),consistingrespectivelyofshort,medium-\n",
      "lengthandlongjourneys.Theplotsinthelastcolumnshowtheprediction\n",
      "errorofeachmodelonthewholetestdatasetSall=Sshort+Smedium+\n",
      "SlongThereportedscoreistherelativepredictionerrorforthecorresponding\n",
      "modelandsubsetofjourneysaskvexp?vtruek/kvtruek,withvexp(n)\n",
      "andvtrue(n)beingtheexpectedandobservedtraveltimesforthenthjourney\n",
      "inSi,i?\n",
      "f\n",
      "short,medium,long,all\n",
      "g\n",
      ".\n",
      "600\n",
      "8001000120014001600\n",
      "400\n",
      "600\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "0400\n",
      "#10-4\n",
      "600\n",
      "8001000120014001600\n",
      "#10-4\n",
      "600\n",
      "4\n",
      "2\n",
      "0600\n",
      "4\n",
      "2\n",
      "8001000120014001600\n",
      "400\n",
      "600\n",
      "#10\n",
      "#10\n",
      "20\n",
      "\n",
      "#10\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "0400\n",
      "600\n",
      "8001000120014001600\n",
      "time\n",
      "4\n",
      "2\n",
      "0400\n",
      "600\n",
      "8001000120014001600\n",
      "time\n",
      "400\n",
      "#10-4\n",
      "2\n",
      "600\n",
      "600\n",
      "8001000120014001600\n",
      "time\n",
      "8001000120014001600\n",
      "timeVauxhallLU\n",
      "6\n",
      "4\n",
      "2\n",
      "8001000120014001600\n",
      "400\n",
      "600\n",
      "time#10\n",
      "8001000120014001600\n",
      "time\n",
      "0.677\n",
      "-4\n",
      "#10\n",
      "0.6172\n",
      "-4\n",
      "8\n",
      "6\n",
      "4\n",
      "2\n",
      "0400\n",
      "600\n",
      "0400\n",
      "8\n",
      "21\n",
      "\n",
      "6\n",
      "2\n",
      "8\n",
      "4\n",
      "0.7161\n",
      "-4\n",
      "4\n",
      "8001000120014001600\n",
      "6\n",
      "8001000120014001600\n",
      "0.6311\n",
      "6\n",
      "timePimlico\n",
      "#10-4\n",
      "8\n",
      "6\n",
      "600\n",
      "time\n",
      "predictedload\n",
      "4\n",
      "600\n",
      "8001000120014001600\n",
      "0400\n",
      "0400\n",
      "8\n",
      "predictedload\n",
      "8\n",
      "6\n",
      "2\n",
      "600\n",
      "time\n",
      "8\n",
      "4\n",
      "0.5859\n",
      "-4\n",
      "2\n",
      "-4\n",
      "time\n",
      "1.453\n",
      "400\n",
      "#10-48\n",
      "4\n",
      "timeWarrenStreet#10\n",
      "8001000120014001600\n",
      "8001000120014001600\n",
      "6\n",
      "22\n",
      "\n",
      "8001000120014001600\n",
      "6\n",
      "2\n",
      "0.5959\n",
      "#10-4\n",
      "0\n",
      "time-4\n",
      "600\n",
      "4\n",
      "time\n",
      "8\n",
      "6\n",
      "600\n",
      "0400\n",
      "0400\n",
      "2\n",
      "timeVictoriaLU\n",
      "observedload\n",
      "6\n",
      "4\n",
      "6\n",
      "0400\n",
      "8\n",
      "6\n",
      "8001000120014001600\n",
      "8\n",
      "observedload\n",
      "8\n",
      "8001000120014001600\n",
      "0400\n",
      "timeStockwell\n",
      "2\n",
      "0.9311\n",
      "#10-4\n",
      "predictedload\n",
      "4\n",
      "600\n",
      "8\n",
      "6\n",
      "4\n",
      "time\n",
      "8\n",
      "predictedload\n",
      "predictedload\n",
      "400\n",
      "0.7982\n",
      "23\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#10-4\n",
      "8\n",
      "observedload\n",
      "8001000120014001600\n",
      "6\n",
      "0\n",
      "time\n",
      "0.6986\n",
      "6\n",
      "2\n",
      "0\n",
      "time#10-4\n",
      "4\n",
      "predictedload\n",
      "2\n",
      "6\n",
      "observedload\n",
      "4\n",
      "OxfordCircus\n",
      "#10-48\n",
      "predictedload\n",
      "6\n",
      "0400\n",
      "KingsCrossLU\n",
      "#10-48\n",
      "predictedload\n",
      "2\n",
      "GreenPark\n",
      "observedload\n",
      "4\n",
      "observedload\n",
      "observedload\n",
      "observedload\n",
      "6\n",
      "0\n",
      "predictedload\n",
      "#10-48\n",
      "observedload\n",
      "FinsburyPark\n",
      "#10-48\n",
      "observedload\n",
      "EustonLU\n",
      "predictedload\n",
      "#10-48\n",
      "6\n",
      "4\n",
      "24\n",
      "\n",
      "2\n",
      "0400\n",
      "600\n",
      "8001000120014001600\n",
      "time\n",
      "400\n",
      "600\n",
      "8001000120014001600\n",
      "time\n",
      "Figure4:StationloadsobtainedfromNetMISdata(inblue)andpredicted\n",
      "bythemodel(inred).NetMISdatacontaininformationaboutthetimeperiod\n",
      "duringwhichatrainwasatthestationandanapproximateweight-scoreofthe\n",
      "train.Attimes,aproxyoftheloadatagivenstationisobtainedbysumming\n",
      "thescoreofalltrainspresentatthatstationattimes.Tomaketheweight\n",
      "scoresandthemodelpredictionscomparablewehavedividedbothquantities\n",
      "bytheareaunderthecorrespondingplots(proportionaltothenumberofpeople\n",
      "travellingthroughtheselectedstationsduringtheday).Thereportedscoreis\n",
      "therelativepredictionerrorkvexp?vtruek/kvtruek,withvexp(s)beingthe\n",
      "(normalised)expectednumberofpeoplebeingatthestationattimesandvtrue\n",
      "(s)the(normalised)weight-scoreobtainedfromtheNetMISdata.\n",
      "8\n",
      "4.2\n",
      "Methodsanddiscussion\n",
      "Syntheticandreal-worldnumericalexperimentshavebeenperformedto:(i)\n",
      "understandhowreliableistheproposedapproximationmethodcomparedto\n",
      "morestandardapproach(variationalinference),(ii)providequantitativetests\n",
      "ofourinferencealgorithmonthepredictionofkeyunobservablequantitiesfrom\n",
      "aground-truthmodeland(iii)assessthescalabilityandapplicabilityofour\n",
      "methodbymodellingtheofalarge-scalereal-worldsystem.Bothsyn-\n",
      "theticandreal-worldexperimentswerearebasedontheLondonunderground\n",
      "network[36].Syntheticdataweregeneratedfromthetrueorigins,destinations\n",
      "andstartingtimesbysimulatingthetrajectorieswiththeground-truth(ran-\n",
      "dom)modeldescribedinSection4.1.Onsuchdataset,wehavecomparedthe\n",
      "trainingperformanceofthevariationalinferenceandthemaximumlikelihood\n",
      "approachesbymeasuringthepredictionerroronanout-of-sampledatasetat\n",
      "eachstochasticiteration(Figure1,right).Thetwotrainedmodelshavethen\n",
      "beentestedagainsttheground-truthonpredicting(i)thetotaltraveltime(Fig-\n",
      "ure2,left),(ii)theshapeoftheusers?pathpreferences(Figure1,right)and(iii)\n",
      "thelocalloads(Figure2,right).Inthereal-worldexperiments,wehavetrained\n",
      "themodelonadatasetofsmart-cardorigin-destinationdata(pseudonymised\n",
      "OysterCardrecordsfrom21stOctober2013providedbyTransportforLondon4\n",
      ")andthentestedthepredictionofthetotaltraveltimeonasmallout-of-sample\n",
      "setofjourneys(Figure3).Inthiscasewehavecomparedthemodelpredic-\n",
      "tionwithitsindirectestimationobtainedfromNetMISrecordsofthesameday\n",
      "(Figure4).NetMISdatacontainapartialreconstructionoftheactualposition\n",
      "andweightsofthetrainsanditispossibletocombinethemtoestimatetheload\n",
      "25\n",
      "\n",
      "ofagivenstationananygiventimeintheday.Sincefulltraininformationwas\n",
      "recordedonlyononeofthe11undergroundlinesofthenetwork(theVictoria\n",
      "Line),wehaverestrictedthecomparisontoasmallsetofstations.Thetwo\n",
      "inferencemethods(VIfor(18)andMLfor(13))haveobtainedgoodandstatis-\n",
      "ticallysimilarscoresonrecoveringtheground-truthmodelpredictions(Figure\n",
      "2).MLhasbeentrainedordersofmagnitudefasterandwasalmostasaccurate\n",
      "asVIonreproducingtheusers?pathpreferences(seeFigure1).Sincethe\n",
      "performanceofMLandVIhaveshowntobestatisticallyequivalent.OnlyML\n",
      "hasbeenusedinthereal-dataexperiments.Onthepredictionofout-of-sample\n",
      "traveltimes,MLoutperformedbotharandommodelandtheconstantmodel\n",
      "usedfortheinitialization(a(x,s,?)=?(x)with?(x)obtainedfrom(19)with\n",
      "uniformppath).Inparticular,whenalljourneysinthetestdatasetarecon-\n",
      "sidered,MLoutperformsthebaselinemethodwitha24%improvement.The\n",
      "onlysub-casewhereMLdoesworse(8%lessaccurate)isonthesmallsubset\n",
      "oflongjourneys(seeFigure3).Thesearejourneyswherei)somethingunusual\n",
      "happenstotheuserorii)theuservisitslotofstations.Inthelattercase,a\n",
      "constant-delaymodel(asourinitializationmodel)mayperformwellbecause\n",
      "wecanexpectsomeaveragingprocessbetweenthetimevariabilityofallvis-\n",
      "itedstations.Figure4showsthatMLwasabletoreproducetheshapeand\n",
      "relativemagnitudeofthe?true?timedistributionsobtainedfromtheNetMIS\n",
      "data.Foramorequantitativecomparison,wehavecomputedthenormalised\n",
      "distance(reportedonthetopoftheredplotsinFigure4)betweenobserved\n",
      "andpredictedloadsovertheday.\n",
      "5\n",
      "Conclusions\n",
      "Wehaveproposedanewscalablemethodforthetomographyoflarge-scale\n",
      "networksfrominputoutputdata.Basedonthepredictionoftheusers?travel\n",
      "time,themodelallowsanestimationoftheunobservedpathpreferencesand\n",
      "stationloads.Sincetheoriginalmodelisintractable,wehaveproposedand\n",
      "comparedtwotapproximateinferenceschemes.Themodelhesbeen\n",
      "testedonbothsyntheticandrealdatafromtheLondonunderground.Onsyn-\n",
      "theticdata,wehavetrainedtwodistinctmodelswiththeproposedapproximate\n",
      "inferencetechniquesandcomparetheirperformanceagainsttheground-truth.\n",
      "Bothofthemcouldsuccessfullyreproducetheoutputsoftheground-truthon\n",
      "observableandunobservablequantities.Trainedonrealdataviastochastic\n",
      "gradientdescent,themodeloutperformsasimpleconstant-delaymodelonpre-\n",
      "dictingout-of-sampletraveltimesandproducesreasonableestimationofthe\n",
      "unobservedstationloads.Ingeneral,thetrainingstepcouldbemademore\n",
      "cientbyacarefuldesignofthemini-batchesusedinthestochasticoptimization.\n",
      "Moreprecisely,sinceeachtermin(13)or(18)involvesonlyaveryrestrictedset\n",
      "ofparameters(dependingonthesetfeasiblepathsbetweenthecorresponding\n",
      "originanddestination),theinferencecouldberadicallyimprovedby\n",
      "samplingtechniquesasdescribedforexamplein[40,41,42].4\n",
      "ThedatashowninFigure3and4arenotpubliclyavailable,butareduced\n",
      "databasecontainingsimilarrecordscanbedownloadedfrom[19]\n",
      "9\n",
      "26\n",
      "\n",
      "AcknowledgmentsWethankTransportforLondonforkindlyprovidingac-\n",
      "cesstodata.ThisworkhasbeenfundedbyaEPSRCgrantEP/N020723/1.\n",
      "RSalsoacknowledgessupportbyTheAlanTuringInstituteundertheEPSRC\n",
      "grantEP/N510129/1andtheAlanTuringInstitute-Lloyd?sRegisterFounda-\n",
      "tionprogrammeonData-CentricEngineering.\n",
      "2References\n",
      "[1]EverettMRogersandDLawrenceKincaid.Communicationnetworks:to-\n",
      "wardanewparadigmforresearch.1981.[2]StanleyWassermanandKatherine\n",
      "Faust.Socialnetworkanalysis:Methodsandapplications,volume8.Cam-\n",
      "bridgeuniversitypress,1994.[3]MichaelGHBellandYasunoriIida.Trans-\n",
      "portationnetworkanalysis.1997.[4]MarkEJNewman.Thestructureand\n",
      "functionofcomplexnetworks.SIAMreview,45(2):167?256,2003.[5]Mark\n",
      "Newman,Albert-LaszloBarabasi,andDuncanJWatts.Thestructureand\n",
      "dynamicsofnetworks.PrincetonUniversityPress,2011.[6]NicholasAChris-\n",
      "takisandJamesHFowler.Socialcontagiontheory:examiningdynamicsocial\n",
      "networksandhumanbehavior.Statisticsinmedicine,32(4):556?577,2013.[7]\n",
      "MarkCoates,AlfredHero,RobertNowak,andBinYu.Largescaleinference\n",
      "andtomographyfornetworkmonitoringanddiagnosis.IEEESignalProcessing\n",
      "Magazine,2001.[8]EdoardoMAiroldiandAlexanderWBlocker.Estimating\n",
      "latentprocessesonanetworkfromindirectmeasurements.JournaloftheAmeri-\n",
      "canStatisticalAssociation,108(501):149?164,2013.[9]YehudaVardi.Network\n",
      "tomography:Estimatingsource-destinationintensitiesfromlinkdata.\n",
      "JournaloftheAmericanstatisticalassociation,91(433):365?377,1996.[10]Rui\n",
      "Castro,MarkCoates,GangLiang,RobertNowak,andBinYu.Networktomog-\n",
      "raphy:Recentdevelopments.Statisticalscience,pages499?517,2004.[11]Luis\n",
      "GWillumsen.Estimationofanodmatrixfromcounts?areview.1978.\n",
      "[12]NathanEagle,AlexSandyPentland,andDavidLazer.Inferringfriend-\n",
      "shipnetworkstructurebyusingmobilephonedata.Proceedingsofthenational\n",
      "academyofsciences,106(36):15274?15278,2009.[13]YuZheng,LiciaCapra,\n",
      "OuriWolfson,andHaiYang.Urbancomputing:concepts,methodologies,and\n",
      "applications.ACMTransactionsonIntelligentSystemsandTechnology(TIST),\n",
      "5(3):38,2014.[14]RobertJVanderbeiandJamesIannone.Anemapproachto\n",
      "odmatrixestimation.Technicalreport,TechnicalReportSOR94-04,Princeton\n",
      "University,1994.[15]ClaudiaTebaldiandMikeWest.Bayesianinferenceon\n",
      "networkusinglinkcountdata.JournaloftheAmericanStatisticalAsso-\n",
      "ciation,93(442):557?573,1998.[16]JinCao,DrewDavis,ScottVanderWiel,\n",
      "andBinYu.Time-varyingnetworktomography:routerlinkdata.Journal\n",
      "oftheAmericanstatisticalassociation,95(452):1063?1075,2000.[17]Yolanda\n",
      "Tsang,MarkCoates,andRobertNowak.Nonparametricinternettomography.\n",
      "InAcoustics,Speech,andSignalProcessing(ICASSP),2002IEEEInternational\n",
      "Conferenceon,volume2,pagesII?2045.IEEE,2002.[18]RicardoSilva,Soong\n",
      "MoonKang,andEdoardoMAiroldi.Predictingvolumesandestimat-\n",
      "ingtheofshocksinmassivetransportationsystems.Proceedingsofthe\n",
      "27\n",
      "\n",
      "NationalAcademyofSciences,112(18):5643?5648,2015.10\n",
      "[19]TransportForLondon.website.hv.uk/.[20]Camille\n",
      "Roth,SoongMoonKang,MichaelBatty,andMarcBarth?lemy.Structureof\n",
      "urbanmovements:polycentricactivityandentangledhierarchicalws.PloS\n",
      "one,6(1):e15923,2011.[21]ChenZhong,MichaelBatty,EdManley,Jiaqiu\n",
      "Wang,ZijiaWang,FengChen,andGerhardSchmitt.Variabilityinregular-\n",
      "ity:Miningtemporalmobilitypatternsinlondon,singaporeandbeijingusing\n",
      "smart-carddata.PloSone,11(2):e0149222,2016.[22]Ram?nC?ceres,Nick\n",
      "GJosephHorowitz,andDonaldFTowsley.Multicast-basedinfer-\n",
      "enceofnetwork-internallosscharacteristics.IEEETransactionsonInformation\n",
      "theory,45(7):2462?2480,1999.[23]MarkJCoatesandRobertDavidNowak.\n",
      "Networklossinferenceusingunicastend-to-endmeasurement.InITCConfer-\n",
      "enceonIPTModelingandManagement,pages28?1,2000.[24]FLo\n",
      "Presti,NickGJosephHorowitz,andDonTowsley.Multicast-based\n",
      "inferenceofnetwork-internaldelaydistributions.IEEE/ACMTransactionsOn\n",
      "Networking,10(6):761?775,2002.[25]LlewellynMichaelKrausBoelterand\n",
      "MelvilleCampbellBranch.Urbanplanning,transportation,andsystemsanal-\n",
      "ysis.ProceedingsoftheNationalAcademyofSciences,46(6):824?831,1960.\n",
      "[26]JayanthRBanavar,AmosMaritan,andAndreaRinaldo.Sizeandform\n",
      "inttransportationnetworks.Nature,399(6732):130?132,1999.[27]\n",
      "HaodongYin,BaomingHan,DeweiLi,JianjunWu,andHuijunSun.Mod-\n",
      "elingandsimulatingpassengerbehaviorforastationclosureinarailtransit\n",
      "network.PLoSone,11(12):e0167126,2016.[28]JunboZhang,YuZheng,and\n",
      "DekangQi.Deepspatio-temporalresidualnetworksforcitywidecrowdws\n",
      "prediction.arXivpreprintarXiv:1610.00081,2016.[29]AkshatKumar,Daniel\n",
      "Sheldon,andBiplavSrivastava.Collectiveovernetworks:Models\n",
      "andinference.arXivpreprintarXiv:1309.6841,2013.[30]JialiDu,Akshat\n",
      "Kumar,andPradeepVarakantham.Onunderstandingdynamicsof\n",
      "patronsatathemepark.InProceedingsofthe2014internationalconference\n",
      "onAutonomousagentsandmulti-agentsystems,pages1501?1502.Interna-\n",
      "tionalFoundationforAutonomousAgentsandMultiagentSystems,2014.[31]\n",
      "MaciejKurantandPatrickThiran.Layeredcomplexnetworks.Physicalreview\n",
      "letters,96(13):138701,2006.[32]YuZhengandXiaofangZhou.Computing\n",
      "withspatialtrajectories.SpringerScienceandBusinessMedia,2011.[33]A\n",
      "Nuzzolo,UCrisalli,LRosati,andAIbeas.Stop:ashorttermtransitoccu-\n",
      "pancypredictiontoolforaptisandrealtimetransitmanagementsystems.In\n",
      "IntelligentTransportationSystems(ITSC),201316thInternationalIEEECon-\n",
      "ferenceon,pages1894?1899.IEEE,2013.[34]BoFriisNielsen,LauraFr?lich,\n",
      "OttoAnkerNielsen,andDorteFilges.Estimatingpassengernumbersintrains\n",
      "usingexistingweighingcapabilities.TransportmetricaA:TransportScience,\n",
      "10(6):502?517,2014.[35]GillesVandewiele,PieterColpaert,OlivierJanssens,\n",
      "JoachimVanHerwegen,RubenVerborgh,ErikMannens,FemkeOngenae,and\n",
      "FilipDeTurck.Predictingtrainoccupanciesbasedonquerylogsandexternal\n",
      "datasources.InProceedingsofthe26thInternationalConferenceonWorld\n",
      "WideWebCompanion,pages1469?1474.InternationalWorldWideWebCon-\n",
      "ferencesSteeringCommittee,2017.[36]TransportForLondon.Tubemap.\n",
      "28\n",
      "\n",
      "hv.uk/cdn/static/cms/documents/standard-tubemap.pdf.11\n",
      "[37]TransportForLondon.Netmisdataset.http://lu.uat.cds.co.uk/Ops\n",
      "maintenance/Library\n",
      "tools/Apps\n",
      "tools/696.html.\n",
      "[38]DiederikPKingmaandMaxWelling.Auto-encodingvariationalbayes.\n",
      "arXivpreprintarXiv:1312.6114,2013.[39]SamuelGershmanandNoahGood-\n",
      "man.Amortizedinferenceinprobabilisticreasoning.InCogSci,2014.[40]\n",
      "PremKGopalan,SeanGerrish,MichaelFreedman,DavidMBlei,andDavidM\n",
      "Mimno.Scalableinferenceofoverlappingcommunities.InAdvancesinNeural\n",
      "InformationProcessingSystems,pages2249?2257,2012.[41]PeilinZhaoand\n",
      "TongZhang.Stochasticoptimizationwithimportancesamplingforregularized\n",
      "lossminimization.InProceedingsofthe32ndInternationalConferenceonMa-\n",
      "chineLearning(ICML-15),pages1?9,2015.[42]OlivierCan?vet,CijoJose,\n",
      "andFrancoisFleuret.Importancesamplingtreeforlarge-scaleempiricalex-\n",
      "pectation.InInternationalConferenceonMachineLearning,pages1454?1462,\n",
      "2016.\n",
      "12\n",
      "29\n",
      "\n",
      "PP4687.pdf\n",
      "PP4687.pdf 13\n",
      "LargeScaleDistributedDeepNetworks\n",
      "Authoredby:\n",
      "AndrewY.Ng\n",
      "KeYang\n",
      "QuocV.Le\n",
      "Marc'aurelioRanzato\n",
      "Dean\n",
      "GregCorrado\n",
      "RajatMonga\n",
      "KaiChen\n",
      "MatthieuDevin\n",
      "MarkMao\n",
      "AndrewSenior\n",
      "PaulTucker\n",
      "Abstract\n",
      "Recentworkinunsupervisedfeaturelearninganddeeplearninghas\n",
      "shownthatbeingabletotrainlargemodelscandramaticallyimprove\n",
      "performance.Inthispaper,weconsidertheproblemoftrainingadeep\n",
      "networkwithbillionsofparametersusingtensofthousandsofCPUcores.\n",
      "WehavedevelopedasoftwareframeworkcalledDistBeliefthatcanuti-\n",
      "lizecomputingclusterswiththousandsofmachinestotrainlargemodels.\n",
      "Withinthisframework,wehavedevelopedtwoalgorithmsforlarge-scale\n",
      "distributedtraining:(i)DownpourSGD,anasynchronousstochasticgra-\n",
      "dientdescentproceduresupportingalargenumberofmodelreplicas,and\n",
      "(ii)Sandblaster,aframeworkthatsupportsforavarietyofdistributed\n",
      "batchoptimizationprocedures,includingadistributedimplementation\n",
      "ofL-BFGS.DownpourSGDandSandblasterL-BFGSbothincreasethe\n",
      "scaleandspeedofdeepnetworktraining.Wehavesuccessfullyusedour\n",
      "systemtotrainadeepnetwork100xlargerthanpreviouslyreportedin\n",
      "theliterature,andachievesstate-of-the-artperformanceonImageNet,a\n",
      "visualobjectrecognitiontaskwith16millionimagesand21kcategories.\n",
      "Weshowthatthesesametechniquesdramaticallyacceleratethetraining\n",
      "ofamoremodestlysizeddeepnetworkforacommercialspeechrecognition\n",
      "service.Althoughwefocusonandreportperformanceofthesemethods\n",
      "asappliedtotraininglargeneuralnetworks,theunderlyingalgorithms\n",
      "areapplicabletoanygradient-basedmachinelearningalgorithm.\n",
      "1\n",
      "\n",
      "1PaperBody\n",
      "Deeplearningandunsupervisedfeaturelearninghaveshowngreatpromisein\n",
      "manypracticalapplications.State-of-the-artperformancehasbeenreportedin\n",
      "severaldomains,rangingfromspeechrecognition[1,2],visualobjectrecognition\n",
      "[3,4],totextprocessing[5,6].Ithasalsobeenobservedthatincreasingthescale\n",
      "ofdeeplearning,withrespecttothenumberoftrainingexamples,thenumber\n",
      "ofmodelparameters,orboth,candrasticallyimproveultimate\n",
      "accuracy[3,4,7].Theseresultshaveledtoasurgeofinterestinscalingupthe\n",
      "trainingandinferencealgorithmsusedforthesemodels[8]andinimproving\n",
      "applicableoptimizationprocedures[7,9].TheuseofGPUs[1,2,3,8]isa\n",
      "tadvanceinrecentyearsthatmakesthetrainingofmodestlysized\n",
      "deepnetworkspractical.AknownlimitationoftheGPUapproachisthat\n",
      "thetrainingspeed-upissmallwhenthemodeldoesnotinGPUmemory\n",
      "(typicallylessthan6gigabytes).TouseaGPUely,researchersoften\n",
      "reducethesizeofthedataorparameterssothatCPU-to-GPUtransfersare\n",
      "notatbottleneck.Whiledataandparameterreductionworkwellfor\n",
      "smallproblems(e.g.acousticmodelingforspeechrecognition),theyareless\n",
      "attractiveforproblemswithalargenumberofexamplesanddimensions(e.g.,\n",
      "high-resolutionimages).Inthispaper,wedescribeanalternativeapproach:\n",
      "usinglarge-scaleclustersofmachinestodistributetrainingandinferencein\n",
      "deepnetworks.WehavedevelopedasoftwareframeworkcalledDistBeliefthat\n",
      "enablesmodelparallelismwithinamachine(viamultithreading)andacross\n",
      "machines(via1\n",
      "messagepassing),withthedetailsofparallelism,synchronizationandcom-\n",
      "municationmanagedbytheframework.Inadditiontosupportingmodelparal-\n",
      "lelism,theDistBeliefframeworkalsosupportsdataparallelism,wheremultiple\n",
      "replicasofamodelareusedtooptimizeasingleobjective.Withinthisframe-\n",
      "work,wehavedesignedandimplementedtwonovelmethodsforlarge-scale\n",
      "distributedtraining:(i)DownpourSGD,anasynchronousstochasticgradient\n",
      "descentprocedurewhichleveragesadaptivelearningratesandsupportsalarge\n",
      "numberofmodelreplicas,and(ii)SandblasterL-BFGS,adistributedimple-\n",
      "mentationofL-BFGSthatusesbothdataandmodelparallelism.1BothDown-\n",
      "pourSGDandSandblasterL-BFGSenjoycantspeedgainscomparedto\n",
      "moreconventionalimplementationsofSGDandL-BFGS.Ourexperimentsre-\n",
      "vealseveralsurprisingresultsaboutlarge-scalenonconvexoptimization.Firstly,\n",
      "asynchronousSGD,rarelyappliedtononconvexproblems,worksverywellfor\n",
      "trainingdeepnetworks,particularlywhencombinedwithAdagrad[10]adap-\n",
      "tivelearningrates.Secondly,weshowthatgivensucientresources,L-BFGSis\n",
      "competitivewithorfasterthanmanyvariantsofSGD.Withregardtosp\n",
      "applicationsindeeplearning,wereporttwomainthatourdistributed\n",
      "optimizationapproachcanbothgreatlyacceleratethetrainingofmodestlysized\n",
      "models,andthatitcanalsotrainmodelsthatarelargerthancouldbecontem-\n",
      "platedotherwise.Toillustratethepoint,weshowthatwecanuseacluster\n",
      "ofmachinestotrainamodestlysizedspeechmodeltothesameclassiation\n",
      "accuracyinlessthan1/10ththetimerequiredonaGPU.Toillustratethesec-\n",
      "2\n",
      "\n",
      "ondpoint,wetrainedalargeneuralnetworkofmorethan1billionparameters\n",
      "andusedthisnetworktodrasticallyimproveonstate-of-the-artperformanceon\n",
      "theImageNetdataset,oneofthelargestdatasetsincomputervision.\n",
      "2\n",
      "Previouswork\n",
      "Inrecentyearscommercialandacademicmachinelearningdatasetshave\n",
      "grownatanunprecedentedpace.Inresponse,agreatmanyauthorshaveex-\n",
      "ploredscalingupmachinelearningalgorithmsthroughparallelizationanddis-\n",
      "tribution[11,12,13,14,15,16,17].Muchofthisresearchhasfocusedonlinear,\n",
      "convexmodels,wheredistributedgradientcomputationisthenaturalstep.\n",
      "Withinthisarea,somegroupshaverelaxedsynchronizationrequirements,ex-\n",
      "ploringdelayedgradientupdatesforconvexproblems[12,17].Inparallel,other\n",
      "groupsworkingonproblemswithsparsegradients(problemswhereonlyatiny\n",
      "fractionofthecoordinatesofthegradientvectorarenon-zeroforanygiven\n",
      "trainingexample)haveexploredlock-lessasynchronousstochasticgradientde-\n",
      "scentonshared-memoryarchitectures(i.e.singlemachines)[5,18].Weare\n",
      "interestedinanapproachthatcapturesthebestofbothworlds,allowingthe\n",
      "useofaclusterofmachinesasynchronouslycomputinggradients,butwithout\n",
      "requiringthattheproblembeeitherconvexorsparse.Inthecontextofdeep\n",
      "learning,mostworkhasfocusedontrainingrelativelysmallmodelsonasingle\n",
      "machine(e.g.,Theano[19]).Suggestionsforscalingupdeeplearninginclude\n",
      "theuseofafarmofGPUstotrainacollectionofmanysmallmodelsandsubse-\n",
      "quentlyaveragingtheirpredictions[20],ormodifyingstandarddeepnetworksto\n",
      "maketheminherentlymoreparallelizable[21].Ourfocusisscalingdeeplearning\n",
      "techniquesinthedirectionoftrainingverylargemodels,thosewithafewbillion\n",
      "parameters,butwithoutintroducingrestrictionsontheformofthemodel.In\n",
      "specialcaseswhereonelayerdominatescomputation,someauthorshavecon-\n",
      "sidereddistributingcomputationinthatonelayerandreplicatingcomputation\n",
      "intheremaininglayers[5].Butinthegeneralcasewheremanylayersofthe\n",
      "modelarecomputationallyintensive,fullmodelparallelisminaspiritsimilar\n",
      "to[22]isrequired.Tobesuccessful,however,webelievethatmodelparallelism\n",
      "mustbecombinedwithcleverdistributedoptimizationtechniquesthatleverage\n",
      "dataparallelism.Weconsideredanumberofexistinglarge-scalecomputational\n",
      "toolsforapplicationtoourproblem,MapReduce[23]andGraphLab[24]being\n",
      "notableexamples.WeconcludedthatMapReduce,designedforparalleldata\n",
      "processing,wasill-suitedfortheiterativecomputationsinherentindeepnet-\n",
      "worktraining;whereasGraphLab,designedforgeneral(unstructured)graph\n",
      "computations,wouldnotexploitcomputingavailableinthestruc-\n",
      "turedgraphstypicallyfoundindeepnetworks.1WeimplementedL-BFGS\n",
      "withintheSandblasterframework,butthegeneralapproachisalsosuitablefor\n",
      "avarietyofotherbatchoptimizationmethods.\n",
      "2\n",
      "Machine1\n",
      "Machine2\n",
      "Machine3\n",
      "Machine4\n",
      "3\n",
      "\n",
      "Figure1:AnexampleofmodelparallelisminDistBelief.Aelayerdeep\n",
      "neuralnetworkwithlocalconnectivityisshownhere,partitionedacrossfour\n",
      "machines(bluerectangles).Onlythosenodeswithedgesthatcrosspartition\n",
      "boundaries(thicklines)willneedtohavetheirstatetransmittedbetweenma-\n",
      "chines.Evenincaseswhereanodehasmultipleedgescrossingapartition\n",
      "boundary,itsstateisonlysenttothemachineontheothersideofthatbound-\n",
      "aryonce.Withineachpartition,computationforindividualnodeswillthe\n",
      "parallelizedacrossallavailableCPUcores.\n",
      "3\n",
      "Modelparallelism\n",
      "Tofacilitatethetrainingofverylargedeepnetworks,wehavedevelopeda\n",
      "softwareframework,DistBelief,thatsupportsdistributedcomputationinneural\n",
      "networksandlayeredgraphicalmodels.Theuserthecomputationthat\n",
      "takesplaceateachnodeineachlayerofthemodel,andthemessagesthatshould\n",
      "bepassedduringtheupwardanddownwardphasesofcomputation.2Forlarge\n",
      "models,theusermaypartitionthemodelacrossseveralmachines(Figure1),\n",
      "sothatresponsibilityforthecomputationfortnodesisassignedtodif-\n",
      "ferentmachines.Theframeworkautomaticallyparallelizescomputationineach\n",
      "machineusingallavailablecores,andmanagescommunication,synchronization\n",
      "anddatatransferbetweenmachinesduringbothtrainingandinference.The\n",
      "performancebofdistributingadeepnetworkacrossmultiplemachines\n",
      "dependsontheconnectivitystructureandcomputationalneedsofthemodel.\n",
      "Modelswithalargenumberofparametersorhighcomputationaldemandstyp-\n",
      "icallybfromaccesstomoreCPUsandmemory,uptothepointwhere\n",
      "communicationcostsdominate.Wehavesuccessfullyrunlargemodelswithup\n",
      "to144partitionsintheDistBeliefframeworkwithtspeedups,while\n",
      "moremodestlysizedmodelsshowdecentspeedupsforupto8or16partitions.\n",
      "(SeeSection5,undertheheadingModelParallelismBenchmarks,forexperi-\n",
      "mentalresults.)Obviously,modelswithlocalconnectivitystructurestendtobe\n",
      "moreamenabletoextensivedistributionthanfully-connectedstructures,given\n",
      "theirlowercommunicationrequirements.Thetypicalcauseofless-than-ideal\n",
      "speedupsisvarianceinprocessingtimesacrossthetmachines,leading\n",
      "tomanymachineswaitingforthesingleslowestmachinetoagivenphase\n",
      "ofcomputation.Nonetheless,forourlargestmodels,wecantlyuse32\n",
      "machineswhereeachmachineachievesanaverageCPUutilizationof16cores,\n",
      "foratotalof512CPUcorestrainingasinglelargeneuralnetwork.When\n",
      "combinedwiththedistributedoptimizationalgorithmsdescribedinthenext\n",
      "section,whichutilizemultiplereplicasoftheentireneuralnetwork,itispossi-\n",
      "bletousetensofthousandsofCPUcoresfortrainingasinglemodel,leading\n",
      "totreductionsinoveralltrainingtimes.\n",
      "4\n",
      "Distributedoptimizationalgorithms\n",
      "ParallelizingcomputationwithintheDistBeliefframeworkallowsustoin-\n",
      "stantiateandrunneuralnetworksconsiderablylargerthanhavebeenpreviously\n",
      "reported.Butinordertotrainsuchlargemodelsinareasonableamountof\n",
      "time,weneedtoparallelizecomputationnotonlywithinasingle2Inthecase\n",
      "4\n",
      "\n",
      "ofaneuralnetwork?upward?and?downward?mightequallywellbecalled\n",
      "?feedforward?and?backprop?,whileforaHiddenMarkovModel,theymight\n",
      "bemorefamiliaras?forward?and?backward?.\n",
      "3\n",
      "ParameterServer\n",
      "w\n",
      "w?=w-??w\n",
      "ParameterServerCoordinator(smallmessages)\n",
      "?wModelReplicas\n",
      "ModelReplicasDataShards\n",
      "Data\n",
      "Figure2:Left:DownpourSGD.Modelreplicasasynchronouslyfetchpa-\n",
      "rameterswandpushgradients?wtotheparameterserver.Right:Sandblaster\n",
      "L-BFGS.Asingle?coordinator?sendssmallmessagestoreplicasandthepa-\n",
      "rameterservertoorchestratebatchoptimization.instanceofthemodel,butto\n",
      "distributetrainingacrossmultiplemodelinstances.Inthissectionwedescribe\n",
      "thissecondlevelofparallelism,whereweemployasetofDistBeliefmodelin-\n",
      "stances,orreplicas,tosimultaneouslysolveasingleoptimizationproblem.We\n",
      "presentacomparisonoftwolarge-scaledistributedoptimizationprocedures:\n",
      "DownpourSGD,anonlinemethod,andSandblasterL-BFGS,abatchmethod.\n",
      "Bothmethodsleveragetheconceptofacentralizedshardedparameterserver,\n",
      "whichmodelreplicasusetosharetheirparameters.Bothmethodstakead-\n",
      "vantageofthedistributedcomputationDistBeliefallowswithineachindividual\n",
      "replica.Butmostimportantly,bothmethodsaredesignedtotoleratevariance\n",
      "intheprocessingspeedoftmodelreplicas,andeventhewholesalefail-\n",
      "ureofmodelreplicaswhichmaybetakenorrestartedatrandom.In\n",
      "asense,thesetwooptimizationalgorithmsimplementanintelligentversionof\n",
      "dataparallelism.Bothapproachesallowustosimultaneouslyprocessdistinct\n",
      "trainingexamplesineachofthemanymodelreplicas,andperiodicallycombine\n",
      "theirresultstooptimizeourobjectivefunction.4.1\n",
      "DownpourSGD\n",
      "Stochasticgradientdescent(SGD)isperhapsthemostcommonlyusedopti-\n",
      "mizationprocedurefortrainingdeepneuralnetworks[25,26,3].Unfortunately,\n",
      "thetraditionalformulationofSGDisinherentlysequential,makingitimprac-\n",
      "ticaltoapplytoverylargedatasetswherethetimerequiredtomovethrough\n",
      "thedatainanentirelyserialfashionisprohibitive.ToapplySGDtolargedata\n",
      "sets,weintroduceDownpourSGD,avariantofasynchronousstochasticgradi-\n",
      "entdescentthatusesmultiplereplicasofasingleDistBeliefmodel.Thebasic\n",
      "approachisasfollows:Wedividethetrainingdataintoanumberofsubsets\n",
      "andrunacopyofthemodeloneachofthesesubsets.Themodelscommuni-\n",
      "cateupdatesthroughacentralizedparameterserver,whichkeepsthecurrent\n",
      "stateofallparametersforthemodel,shardedacrossmanymachines(e.g.,if\n",
      "wehave10parameterservershards,eachshardisresponsibleforstoringand\n",
      "applyingupdatesto1/10thofthemodelparameters)(Figure2).Thisapproach\n",
      "isasynchronousintwodistinctaspects:themodelreplicasrunindependently\n",
      "ofeachother,andtheparameterservershardsalsorunindependentlyofone\n",
      "5\n",
      "\n",
      "another.Inthesimplestimplementation,beforeprocessingeachmini-batch,\n",
      "amodelreplicaaskstheparameterserverserviceforanupdatedcopyofits\n",
      "modelparameters.BecauseDistBeliefmodelsarethemselvespartitionedacross\n",
      "multiplemachines,eachmachineneedstocommunicatewithjustthesubsetof\n",
      "parameterservershardsthatholdthemodelparametersrelevanttoitsparti-\n",
      "tion.Afterreceivinganupdatedcopyofitsparameters,theDistBeliefmodel\n",
      "replicaprocessesamini-batchofdatatocomputeaparametergradient,and\n",
      "sendsthegradienttotheparameterserver,whichthenappliesthegradientto\n",
      "thecurrentvalueofthemodelparameters.Itispossibletoreducethecommu-\n",
      "nicationoverheadofDownpourSGDbylimitingeachmodelreplicatorequest\n",
      "updatedparametersonlyeverynfetchstepsandsendupdatedgradientvalues\n",
      "onlyeverynpushsteps(wherenfetchmightnotbeequaltonpush).Infact,\n",
      "theprocessoffetching4\n",
      "parameters,pushinggradients,andprocessingtrainingdatacanbecar-\n",
      "riedoutinthreeonlyweaklysynchronizedthreads(seetheAppendixforpseu-\n",
      "docode).Intheexperimentsreportedbelowwenfetch=npush=1for\n",
      "simplicityandeaseofcomparisontotraditionalSGD.DownpourSGDismore\n",
      "robusttomachinesfailuresthanstandard(synchronous)SGD.Forsynchronous\n",
      "SGD,ifonemachinefails,theentiretrainingprocessisdelayed;whereasfor\n",
      "asynchronousSGD,ifonemachineinamodelreplicafails,theothermodel\n",
      "replicascontinueprocessingtheirtrainingdataandupdatingthemodelpa-\n",
      "rametersviatheparameterservers.Ontheotherhand,themultipleformsof\n",
      "asynchronousprocessinginDownpourSGDintroduceagreatdealofadditional\n",
      "stochasticityintheoptimizationprocedure.Mostobviously,amodelreplicais\n",
      "almostcertainlycomputingitsgradientsbasedonasetofparametersthatare\n",
      "slightlyoutofdate,inthatsomeothermodelreplicawilllikelyhaveupdated\n",
      "theparametersontheparameterserverinthemeantime.Butthereareseveral\n",
      "othersourcesofstochasticitybeyondthis:Becausetheparameterservershards\n",
      "actindependently,thereisnoguaranteethatatanygivenmomenttheparam-\n",
      "etersoneachshardoftheparameterserverhaveundergonethesamenumber\n",
      "ofupdates,orthattheupdateswereappliedinthesameorder.Moreover,\n",
      "becausethemodelreplicasarepermittedtofetchparametersandpushgradi-\n",
      "entsinseparatethreads,theremaybeadditionalsubtleinconsistenciesinthe\n",
      "timestampsofparameters.Thereislittletheoreticalgroundingforthesafety\n",
      "oftheseoperationsfornonconvexproblems,butinpracticewefoundrelaxing\n",
      "consistencyrequirementstoberemarkablye.Onetechniquethatwe\n",
      "havefoundtogreatlyincreasetherobustnessofDownpourSGDistheuseof\n",
      "theAdagrad[10]adaptivelearningrateprocedure.Ratherthanusingasin-\n",
      "glelearningrateontheparametersever(?inFigure2),Adagraduses\n",
      "aseparateadaptivelearningrateforeachparameter.Let?i,Kbethelearning\n",
      "rateofthei-thparameteratiterationKand?wi,Kitsgradient,qPK2then\n",
      "weset:?i,K=?/j=1?wi,j.Becausetheselearningratesarecomputedonly\n",
      "fromthesummedsquaredgradientsofeachparameter,Adagradiseasilyimple-\n",
      "mentedlocallywithineachparameterservershard.Thevalueof?,theconstant\n",
      "scalingfactorforalllearningrates,isgenerallylarger(perhapsbyanorderof\n",
      "magnitude)thanthebestlearningrateusedwithoutAdagrad.Theuseof\n",
      "6\n",
      "\n",
      "Adagradextendsthemaximumnumberofmodelreplicasthatcanproductively\n",
      "worksimultaneously,andcombinedwithapracticeof?warmstarting?model\n",
      "trainingwithonlyasinglemodelreplicabeforeunleashingtheotherreplicas,\n",
      "ithasvirtuallyeliminatedstabilityconcernsintrainingdeepnetworksusing\n",
      "DownpourSGD(seeresultsinSection5).4.2\n",
      "SandblasterL-BFGS\n",
      "Batchmethodshavebeenshowntoworkwellintrainingsmalldeepnetworks\n",
      "[7].Toapplythesemethodstolargemodelsandlargedatasets,weintroduce\n",
      "theSandblasterbatchoptimizationframeworkanddiscussanimplementation\n",
      "ofL-BFGSusingthisframework.AkeyideainSandblasterisdistributedpa-\n",
      "rameterstorageandmanipulation.Thecoreoftheoptimizationalgorithm(e.g\n",
      "L-BFGS)residesinacoordinatorprocess(Figure2),whichdoesnothavedi-\n",
      "rectaccesstothemodelparameters.Instead,thecoordinatorissuescommands\n",
      "drawnfromasmallsetofoperations(e.g.,dotproduct,scaling,cot-wise\n",
      "addition,multiplication)thatcanbeperformedbyeachparameterservershard\n",
      "independently,withtheresultsbeingstoredlocallyonthesameshard.Ad-\n",
      "ditionalinformation,e.gthehistorycacheforL-BFGS,isalsostoredonthe\n",
      "parameterservershardonwhichitwascomputed.Thisallowsrunninglarge\n",
      "models(billionsofparameters)withoutincurringtheoverheadofsendingallthe\n",
      "parametersandgradientstoasinglecentralserver.(SeetheAppendixforpseu-\n",
      "docode.)IntypicalparallelizedimplementationsofL-BFGS,dataisdistributed\n",
      "tomanymachinesandeachmachineisresponsibleforcomputingthegradient\n",
      "onaspsubsetofdataexamples.Thegradientsaresentbacktoacentral\n",
      "server(oraggregatedviaatree[16]).Manysuchmethodswaitfortheslowest\n",
      "machine,andthereforedonotscalewelltolargesharedclusters.Toaccountfor\n",
      "thisproblem,weemploythefollowingloadbalancingscheme:Thecoordinator\n",
      "assignseachoftheNmodelreplicasasmallportionofwork,muchsmallerthan\n",
      "1/Nthofthetotalsizeofabatch,andassignsreplicasnewportionswhenever\n",
      "theyarefree.Withthisapproach,fastermodelreplicasdomoreworkthan\n",
      "slowerreplicas.Tofurthermanageslowmodelreplicasattheendofabatch,\n",
      "thecoordinatorschedulesmultiplecopiesoftheoutstandingportionsanduses\n",
      "theresultfromwhichevermodelreplicaThisschemeissimilarto\n",
      "theuseof?backuptasks?intheMapReduceframework[23].Prefetchingof\n",
      "data,alongwithsupportingdataybyassigningsequential5\n",
      "portionsofdatatothesameworkermakesdataaccessanon-issue.In\n",
      "contrastwithDownpourSGD,whichrequiresrelativelyhighfrequency,high\n",
      "bandwidthparametersynchronizationwiththeparameterserver,Sandblaster\n",
      "workersonlyfetchparametersatthebeginningofeachbatch(whentheyhave\n",
      "beenupdatedbythecoordinator),andonlysendthegradientseveryfewcom-\n",
      "pletedportions(toprotectagainstreplicafailuresandrestarts).\n",
      "5\n",
      "Experiments\n",
      "Weevaluatedouroptimizationalgorithmsbyapplyingthemtotrainingmod-\n",
      "elsfortwotdeeplearningproblems:objectrecognitioninstillimages\n",
      "andacousticprocessingforspeechrecognition.Thespeechrecognitiontaskwas\n",
      "toclassifythecentralregion(orframe)inashortsnippetofaudioasoneof\n",
      "7\n",
      "\n",
      "severalthousandacousticstates.Weusedadeepnetworkwithelayers:four\n",
      "hiddenlayerwithsigmoidalactivationsand2560nodeseach,andasoftmax\n",
      "outputlayerwith8192nodes.Theinputrepresentationwas11consecutive\n",
      "overlapping25msframesofspeech,eachrepresentedby40log-energyvalues.\n",
      "Thenetworkwasfully-connectedlayer-to-layer,foratotalofapproximately42\n",
      "millionmodelparameters.Wetrainedonadatasetof1.1billionweaklyla-\n",
      "beledexamples,andevaluatedonaholdouttestset.See[27]forsimilardeep\n",
      "networkandtrainingprocedures.Forvisualobjectrecognition\n",
      "wetrainedalargerneuralnetworkwithlocally-connectedreceptiveon\n",
      "theImageNetdatasetof16millionimages,eachofwhichwescaledto100x100\n",
      "pixels[28].Thenetworkhadthreestages,eachcomposedofpooling\n",
      "andlocalcontrastnormalization,whereeachnodeinthelayerwascon-\n",
      "nectedtoa10x10patchinthelayerbelow.Ourinfrastructureallowsmany\n",
      "nodestoconnecttothesameinputpatch,andweranexperimentsvaryingthe\n",
      "numberofidenticallyconnectednodesfrom8to36.Theoutputlayerconsisted\n",
      "of21thousandone-vs-alllogisticclasernodes,oneforeachoftheImageNet\n",
      "objectcategories.See[29]forsimilardeepnetworkandtraining\n",
      "procedures.Modelparallelismbenchmarks:Toexplorethescalingbehaviorof\n",
      "DistBeliefmodelparallelism(Section3),wemeasuredthemeantimetopro-\n",
      "cessasinglemini-batchforsimpleSGDtrainingasafunctionofthenumberof\n",
      "partitions(machines)usedinasinglemodelinstance.InFigure3wequantify\n",
      "theimpactofparallelizingacrossNmachinesbyreportingtheaveragetraining\n",
      "speed-up:theratioofthetimetakenusingonlyasinglemachinetothetime\n",
      "takenusingN.Speedupsforinferencestepsinthesemodelsaresimilarandare\n",
      "notshownhere.Themoderatelysizedspeechmodelrunsfasteston8machines,\n",
      "computing2.2?fasterthanusingasinglemachine.(Modelswereto\n",
      "usenomorethan20corespermachine.)Partitioning\n",
      "Trainingspeed?up\n",
      "15\n",
      "Speech:42MparametersImages:80MparametersImages:330Mparameters\n",
      "Images:1.7Bparameters\n",
      "10\n",
      "5\n",
      "01\n",
      "16\n",
      "3264Machinespermodelinstance\n",
      "128\n",
      "Figure3:Trainingspeed-upforfourtdeepnetworksasafunction\n",
      "ofmachinesallocatedtoasingleDistBeliefmodelinstance.Modelswithmore\n",
      "parametersbmorefromtheuseofadditionalmachinesthandomodels\n",
      "withfewerparameters.6\n",
      "AccuracyonTrainingSet\n",
      "AccuracyonTestSet25\n",
      "AverageFrameAccuracy(%)\n",
      "AverageFrameAccuracy(%)\n",
      "25\n",
      "8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "15\n",
      "10\n",
      "SGD[1]DownpourSGD[20]DownpourSGD[200]w/AdagradSandblaster\n",
      "L?BFGS[2000]\n",
      "5\n",
      "00\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      "00\n",
      "120\n",
      "Time(hours)\n",
      "SGD[1]GPU[1]DownpourSGD[20]DownpourSGD[20]w/AdagradDown-\n",
      "pourSGD[200]w/AdagradSandblasterL?BFGS[2000]20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "Time(hours)\n",
      "Figure4:Left:Trainingaccuracy(onaportionofthetrainingset)fordif-\n",
      "ferentoptimizationmethods.Right:accuracyontheholdout\n",
      "testsetasafunctionoftrainingtime.DownpourandSandblasterexperiments\n",
      "initializedusingthesame?10hourwarmstartofsimpleSGD.themodelon\n",
      "morethan8machinesactuallyslowstraining,asnetworkoverheadstartsto\n",
      "dominateinthefully-connectednetworkstructureandthereislessworkfor\n",
      "eachmachinetoperformwithmorepartitions.Incontrast,themuchlarger,\n",
      "locally-connectedimagemodelscanbfromusingmanymoremachinesper\n",
      "modelreplica.Thelargestmodel,with1.7billionparametersbthemost,\n",
      "givingaspeedupofmorethan12?using81machines.Fortheselargemodels\n",
      "usingmoremachinescontinuestoincreasespeed,butwithdiminishingreturns.\n",
      "Optimizationmethodcomparisons:Toevaluatetheproposeddistributedopti-\n",
      "mizationprocedures,weranthespeechmodeldescribedaboveinavarietyof\n",
      "Weconsidertwobaselineoptimizationprocedures:traininga\n",
      "DistBeliefmodel(on8partitions)usingconventional(singlereplica)SGD,and\n",
      "trainingtheidenticalmodelonaGPUusingCUDA[27].Thethreedistributed\n",
      "optimizationmethodswecomparetothesebaselinemethodsare:Downpour\n",
      "SGDwithalearningrate,DownpourSGDwithAdagradlearningrates,\n",
      "9\n",
      "\n",
      "andSandblasterL-BFGS.Figure4showsperformanceasafunc-\n",
      "tionoftrainingtimeforeachofthesemethodsonboththetrainingandtest\n",
      "sets.Ourgoalistoobtainthemaximumtestsetaccuracyintheminimum\n",
      "amountoftrainingtime,regardlessofresourcerequirements.Conventionalsin-\n",
      "glereplicaSGD(blackcurves)istheslowesttotrain.DownpourSGDwith20\n",
      "modelreplicas(bluecurves)showsatimprovement.DownpourSGD\n",
      "with20replicasplusAdagrad(orangecurve)ismodestlyfaster.SandblasterL-\n",
      "BFGSusing2000modelreplicas(greencurves)isconsiderablyfasteryetagain.\n",
      "Thefastest,however,isDownpourSGDplusAdagradwith200modelreplicas\n",
      "(redcurves).GivenaccesstotCPUresourses,bothSandblasterL-\n",
      "BFGSandDownpourSGDwithAdagradcantrainmodelssubstantiallyfaster\n",
      "thanahighperformanceGPU.Thoughwedidnottheaboveexperi-\n",
      "mentstoaresourcebudget,itisinterestingtoconsiderhowthevarious\n",
      "methodstraderesourceconsumptionforperformance.Weanalyzethisby\n",
      "arbitrarilychoosingatestsetaccuracy(16%),andmeasuringthetime\n",
      "eachmethodtooktoreachthataccuracyasafunctionofmachinesandutilized\n",
      "CPUcores,Figure5.Oneofthefourpointsoneachtracescorrespondstoa\n",
      "trainingshowninFigure4,theotherthreepointsarealternative\n",
      "Inthisplot,pointsclosertotheoriginarepreferableinthatthey\n",
      "takelesstimewhileusingfewerresources.InthisregardDownpourSGDusing\n",
      "AdagradappearstobethebestForanybudgetofmachines\n",
      "orcores,DownpourSGDwithAdagradtakeslesstimetoreachtheaccuracy\n",
      "targetthaneitherDownpourSGDwithalearningrateorSandblasterL-\n",
      "BFGS.Foranyallottedtrainingtimetoreachtheaccuracytarget,Downpour\n",
      "SGDwithAdagradusedfewresourcesthanSandblasterL-BFGS,andinmany\n",
      "casesDownpourSGDwithalearningratecouldnotevenreachthetarget\n",
      "withinthedeadline.TheSandblasterL-BFGSsystemdoesshowpromisein\n",
      "terms7\n",
      "Timeto16%accuracy\n",
      "Timeto16%accuracy\n",
      "80\n",
      "80\n",
      "DownpourSGDDownpourSGDw/AdagradSandblasterL?BFGSGPU\n",
      "70\n",
      "60\n",
      "Time(hours)\n",
      "Time(hours)\n",
      "605040\n",
      "5040\n",
      "30\n",
      "30\n",
      "20\n",
      "20\n",
      "101\n",
      "DownpourSGDDownpourSGDw/AdagradSandblasterL?BFGSGPU\n",
      "(CUDAcores)\n",
      "10\n",
      "\n",
      "70\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "101\n",
      "6000\n",
      "Machines\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Cores\n",
      "Figure5:Timetoreachaaccuracy(16%)forderentoptimization\n",
      "strategiesasafunctionofnumberofthemachines(left)andcores(right).of\n",
      "itsscalingwithadditionalcores,suggestingthatitmayultimatelyproducethe\n",
      "fastesttrainingtimesifusedwithanextremelylargeresourcebudget(e.g.,\n",
      "30kcores).ApplicationtoImageNet:Thepreviousexperimentsdemonstrate\n",
      "thatourtechniquescanacceleratethetrainingofneuralnetworkswithtensof\n",
      "millionsofparameters.However,themoretadvantageofourcluster-\n",
      "basedapproachtodistributedoptimizationisitsabilitytoscaletomodelsthat\n",
      "aremuchlargerthancanbecomfortablyonsinglemachine,letalonea\n",
      "singleGPU.Asasteptowardexploringthecapabilitiesofverylargeneural\n",
      "networks,weusedDownpourSGDtotrainthe1.7billionparameterimage\n",
      "modeldescribedaboveontheImageNetobjecttask.Asdetailed\n",
      "in[29],thisnetworkachievedacross-validatedaccuracyofover\n",
      "15%,arelativeimprovementover60%fromthebestperformanceweareaware\n",
      "ofonthe21kcategoryImageNettask.\n",
      "6\n",
      "Conclusions\n",
      "InthispaperweintroducedDistBelief,aframeworkforparalleldistributed\n",
      "trainingofdeepnetworks.Withinthisframework,wediscoveredseverale\n",
      "distributedoptimizationstrategies.WefoundthatDownpourSGD,ahighly\n",
      "asynchronousvariantofSGDworkssurprisinglywellfortrainingnonconvex\n",
      "deeplearningmodels.SandblasterL-BFGS,adistributedimplementationof\n",
      "L-BFGS,canbecompetitivewithSGD,anditsmoretuseofnetwork\n",
      "bandwidthenablesittoscaletoalargernumberofconcurrentcoresfortraining\n",
      "asinglemodel.Thatsaid,thecombinationofDownpourSGDwiththeAdagrad\n",
      "adaptivelearningrateprocedureemergesastheclearlydominantmethodwhen\n",
      "workingwithacomputationalbudgetof2000CPUcoresorless.Adagrad\n",
      "wasnotoriginallydesignedtobeusedwithasynchronousSGD,andneither\n",
      "methodistypicallyappliedtononconvexproblems.Itissurprising,therefore,\n",
      "thattheyworksowelltogether,andonhighlynonlineardeepnetworks.We\n",
      "11\n",
      "\n",
      "conjecturethatAdagradautomaticallystabilizesvolatileparametersintheface\n",
      "oftheofasynchronousupdates,andnaturallyadjustslearningratesto\n",
      "thedemandsoftlayersinthedeepnetwork.Ourexperimentsshowthat\n",
      "ournewlarge-scaletrainingmethodscanuseaclusterofmachinestotraineven\n",
      "modestlysizeddeepnetworkstlyfasterthanaGPU,andwithoutthe\n",
      "GPU?slimitationonthemaximumsizeofthemodel.Todemonstratethevalue\n",
      "ofbeingabletotrainlargermodels,wehavetrainedamodelwithover1billion\n",
      "parameterstoachievebetterthanstate-of-the-artperformanceontheImageNet\n",
      "objectrecognitionchallenge.AcknowledgmentsTheauthorswouldliketothank\n",
      "SamyBengio,TomDean,JohnDuchi,YuvalNetzer,PatrickNguyen,Yoram\n",
      "Singer,SebastianThrun,andVincentVanhouckefortheirindispensableadvice,\n",
      "support,andcomments.\n",
      "8\n",
      "2References\n",
      "[1]G.Dahl,D.Yu,L.Deng,andA.Acero.Context-dependentpre-traineddeep\n",
      "neuralnetworksforlargevocabularyspeechrecognition.IEEETransactionson\n",
      "Audio,Speech,andLanguageProcessing,2012.[2]G.Hinton,L.Deng,D.\n",
      "Yu,G.Dahl,A.Mohamed,N.Jaitly,A.Senior,V.Vanhoucke,P.Nguyen,\n",
      "T.Sainath,andB.Kingsbury.Deepneuralnetworksforacousticmodelingin\n",
      "speechrecognition.IEEESignalProcessingMagazine,2012.[3]D.C.Ciresan,\n",
      "U.Meier,L.M.Gambardella,andJ.Schmidhuber.Deepbigsimpleneural\n",
      "netsexcelonhandwrittendigitrecognition.CoRR,2010.[4]A.Coates,H.\n",
      "Lee,andA.Y.Ng.Ananalysisofsingle-layernetworksinunsupervisedfeature\n",
      "learning.InAISTATS14,2011.[5]Y.Bengio,R.Ducharme,P.Vincent,\n",
      "andC.Jauvin.Aneuralprobabilisticlanguagemodel.JournalofMachine\n",
      "LearningResearch,3:1137?1155,2003.[6]R.CollobertandJ.Weston.A\n",
      "architecturefornaturallanguageprocessing:Deepneuralnetworkswith\n",
      "multitasklearning.InICML,2008.[7]Q.V.Le,J.Ngiam,A.Coates,A.\n",
      "Lahiri,B.Prochnow,andA.Y.Ng.Onoptimizationmethodsfordeeplearning.\n",
      "InICML,2011.[8]R.Raina,A.Madhavan,andA.Y.Ng.Large-scaledeep\n",
      "unsupervisedlearningusinggraphicsprocessors.InICML,2009.[9]J.Martens.\n",
      "Deeplearningviahessian-freeoptimization.InICML,2010.[10]J.C.Duchi,\n",
      "E.Hazan,andY.Singer.Adaptivesubgradientmethodsforonlinelearningand\n",
      "stochasticoptimization.JournalofMachineLearningResearch,12:2121?2159,\n",
      "2011.[11]Q.Shi,J.Petterson,G.Dror,J.Langford,A.Smola,A.Strehl,\n",
      "andV.Vishwanathan.Hashkernels.InAISTATS,2009.[12]J.Langford,A.\n",
      "Smola,andM.Zinkevich.Slowlearnersarefast.InNIPS,2009.[13]G.Mann,\n",
      "R.McDonald,M.Mohri,N.Silberman,andD.Walker.tlarge-scale\n",
      "distributedtrainingofconditionalmaximumentropymodels.InNIPS,2009.\n",
      "[14]R.McDonald,K.Hall,andG.Mann.Distributedtrainingstrategiesfor\n",
      "thestructuredperceptron.InNAACL,2010.[15]M.Zinkevich,M.Weimer,\n",
      "A.Smola,andL.Li.Parallelizedstochasticgradientdescent.InNIPS,2010.\n",
      "[16]A.Agarwal,O.Chapelle,M.Dudik,andJ.Langford.Areliablee\n",
      "12\n",
      "\n",
      "terascalelinearlearningsystem.InAISTATS,2011.[17]A.AgarwalandJ.\n",
      "Duchi.Distributeddelayedstochasticoptimization.InNIPS,2011.[18]F.\n",
      "Niu,B.Retcht,C.Re,andS.J.Wright.Hogwild!Alock-freeapproachto\n",
      "parallelizingstochasticgradientdescent.InNIPS,2011.[19]J.Bergstra,O.\n",
      "Breuleux,F.Bastien,P.Lamblin,R.Pascanu,G.Desjardins,J.Turian,D.\n",
      "Warde-Farley,andY.Bengio.Theano:aCPUandGPUmathexpression\n",
      "compiler.InSciPy,2010.[20]D.Ciresan,U.Meier,andJ.Schmidhuber.\n",
      "Multi-columndeepneuralnetworksforimageTechnicalreport,\n",
      "IDSIA,2012.[21]L.Deng,D.Yu,andJ.Platt.Scalablestackingandlearning\n",
      "forbuildingdeeparchitectures.InICASSP,2012.[22]A.Krizhevsky.Learning\n",
      "multiplelayersoffeaturesfromtinyimages.Technicalreport,U.Toronto,2009.\n",
      "[23]J.DeanandS.Ghemawat.Map-Reduce:dataprocessingonlarge\n",
      "clusters.CACM,2008.[24]Y.Low,J.Gonzalez,A.Kyrola,D.Bickson,C.\n",
      "Guestrin,andJ.Hellerstein.DistributedGraphLab:Aframeworkformachine\n",
      "learninginthecloud.InVLDB,2012.[25]L.Bottou.Stochasticgradient\n",
      "learninginneuralnetworks.InProceedingsofNeuro-N??mes91,1991.[26]\n",
      "Y.LeCun,L.Bottou,G.Orr,andK.Muller.tbackprop.InNeural\n",
      "Networks:Tricksofthetrade.Springer,1998.[27]V.Vanhoucke,A.Senior,\n",
      "andM.Z.Mao.Improvingthespeedofneuralnetworksoncpus.InDeep\n",
      "LearningandUnsupervisedFeatureLearningWorkshop,NIPS2011,2011.[28]\n",
      "J.Deng,W.Dong,R.Socher,L.-J.Li,K.Li,andL.Fei-Fei.ImageNet:A\n",
      "Large-ScaleHierarchicalImageDatabase.InCVPR,2009.[29]Q.V.Le,M.A.\n",
      "Ranzato,R.Monga,M.Devin,K.Chen,G.S.Corrado,J.Dean,andA.Y.Ng.\n",
      "Buildinghigh-levelfeaturesusinglargescaleunsupervisedlearning.InICML,\n",
      "2012.\n",
      "9\n",
      "13\n",
      "\n",
      "PP4877.pdf\n",
      "PP4877.pdf 13\n",
      "Recurrentlinearmodelsof\n",
      "simultaneously-recordedneuralpopulations\n",
      "Authoredby:\n",
      "ManeeshSahani\n",
      "BiljanaPetreska\n",
      "MariusPachitariu\n",
      "Abstract\n",
      "Populationneuralrecordingswithlong-rangetemporalstructureare\n",
      "oftenbestunderstoodintermsofasharedunderlyinglow-dimensionaldy-\n",
      "namicalprocess.Advancesinrecordingtechnologyprovideaccesstoan\n",
      "everlargerfractionofthepopulation,butthestandardcomputationalap-\n",
      "proachesavailabletoidentifythecollectivedynamicsscalepoorlywiththe\n",
      "sizeofthedataset.Herewedescribeanew,scalableapproachtodiscover-\n",
      "ingthelow-dimensionaldynamicsthatunderliesimultaneouslyrecorded\n",
      "spiketrainsfromaneuralpopulation.Ourmethodisbasedonrecur-\n",
      "rentlinearmodels(RLMs),andrelatescloselytotimeseriesmodelsbased\n",
      "onrecurrentneuralnetworks.WeformulateRLMsforneuraldataby\n",
      "generalisingthelikelihoodcalculationforlatentlin-\n",
      "eardynamicalsystems(LDS)modelstoincorporateageneralised-linear\n",
      "observationprocess.WeshowthatRLMsdescribemotor-corticalpopu-\n",
      "lationdatabetterthaneitherdirectly-coupledgeneralised-linearmodels\n",
      "orlatentlineardynamicalsystemmodelswithgeneralised-linearobser-\n",
      "vations.Wealsointroducethecascadedlinearmodel(CLM)tocapture\n",
      "low-dimensionalinstantaneouscorrelationsinneuralpopulations.The\n",
      "CLMdescribesthecorticalrecordingsbetterthaneitherIsingorGaus-\n",
      "sianmodelsand,liketheRLM,canbeexactlyandquickly.TheCLM\n",
      "canalsobeseenasageneralizationofalow-rankGaussianmodel,in\n",
      "thiscasefactoranalysis.ThecomputationaltractabilityoftheRLMand\n",
      "CLMallowbothtoscaletoveryhigh-dimensionalneuraldata.\n",
      "1PaperBody\n",
      "Manyessentialneuralcomputationsareimplementedbylargepopulationsof\n",
      "neuronsworkinginconcert,andrecentstudieshavesoughtbothtomonitor\n",
      "increasinglylargegroupsofneurons[1,2]andtocharacterisetheircollective\n",
      "behaviour[3,4].Inthispaperweintroduceanewcomputationaltooltomodel\n",
      "coordinatedbehaviourinverylargeneuraldatasets.Whileweexplicitlydiscuss\n",
      "1\n",
      "\n",
      "onlymulti-electrodeextracellularrecordings,thesamemodelcanbereadily\n",
      "usedtocharacterise2-photoncalcium-markerimagedata,EEG,fMRIoreven\n",
      "large-scalebiologically-faithfulsimulations.Populationalneuraldatamaybe\n",
      "representedateachtimepointbyavectorytwithasmanydimensionsas\n",
      "neurons,andasmanyindicestastimepointsintheexperiment.Forspiking\n",
      "neurons,ytwillhavepositiveintegerelementscorrespondingtothenumberof\n",
      "spikesbyeachneuroninthetimeintervalcorrespondingtothet-thbin.\n",
      "Asothershavebefore[5,6],weassumethatthecoordinatedactivity\n",
      "inthemeasurementytarisesfromalow-dimensionalsetofprocesses,collected\n",
      "intoavectorxt,whichisnotdirectlyobserved.However,unliketheprevious\n",
      "studies,weconstructarecurrentmodelinwhichthehiddenprocessesxtare\n",
      "drivendirectlyandexplicitlybythemeasuredneuralsignalsy1...yt?1.This\n",
      "assumptiontheestimationprocess.Weassumeforsimplicitythatxt\n",
      "evolveswithlineardynamicsandthefuturestateoftheneuralsignal\n",
      "ytinageneralised-linearmanner,althoughbothassumptionsmayberelaxed.\n",
      "Asinthelatentdynamicalsystem,theresultingmodelenforcesa?bottleneck?,\n",
      "wherebypredictionsofytbasedony1...yt?1mustbecarriedbythe\n",
      "low-dimensionalxt.1\n",
      "StatepredictionintheRLMisrelatedtotheKalman[7]andweshow\n",
      "inthenextsectionaformalequivalencebetweenthelikelihoodsoftheRLM\n",
      "andthelatentdynamicalmodelwhenobservationnoiseisGaussiandistributed.\n",
      "However,spikingdataisnotwellmodelledasGaussian,andthegeneralisation\n",
      "ofourapproachtoPoissonnoiseleadstoadeparturefromthelatentdynamical\n",
      "approach.UnlikelatentlinearmodelswithconditionallyPoissonobservations,\n",
      "theparametersofourmodelcanbeestimatedtlyandwithoutapproxi-\n",
      "mation.Weshowthat,perhapsinconsequence,theRLMcanprovidesuperior\n",
      "descriptionsofneuralpopulationdata.\n",
      "2\n",
      "FromtheKalmantotherecurrentlinearmodel(RLM)\n",
      "Consideralatentlineardynamicalsystem(LDS)modelwithlinear-Gaussian\n",
      "observations.ItsgraphicalmodelisshowninFig.1A.Thelatentprocess\n",
      "isparametrisedbyadynamicsmatrixAandinnovationscovarianceQthat\n",
      "describetheevolutionofthelatentstatext:P(xt|xt?1)=N(xt|Axt?1\n",
      ",Q),whereN(x|?,?)representsanormaldistributiononxwithmean?\n",
      "and(co)variance?.Forbrevity,weomithereandbelowthespecialcaseof\n",
      "thersttime-step,inwhichx1isdrawnfromamultivariateGaussian.The\n",
      "outputdistributionisdeterminedbyanobservationloadingmatrixCanda\n",
      "noisecovarianceRoftentakentobediagonalsothatallcovarianceismodelled\n",
      "bythelatentprocess:P(yt|xt)=N(yt|Cxt,R).IntheLDS,thejoint\n",
      "likelihoodoftheobservations\n",
      "f\n",
      "yt\n",
      "g\n",
      "canbewrittenastheproduct:TY\n",
      "P(y1...yT)=P(y1)\n",
      "P(yt|y1...yt?1)\n",
      "t=2\n",
      "andintheGaussiancasecanbecomputedusingtheusualKalman\n",
      "approachtotheconditionaldistributonattimetiteratively:ZP(yt+1\n",
      "|y1...yt)=dxt+1P(yt+1|xt+1)P(xt+1|y1...yt)Z?t,Vt+1\n",
      "2\n",
      "\n",
      ")=dxt+1N(yt+1|Cxt+1,R)N(xt+1|Ax?t,CVt+1C>+R),=\n",
      "N(yt+1|CAx?t=E[xt|y1...yt]and(predictive)unwherewehave\n",
      "introducedtheered)stateestimatex\n",
      "?t)2|y1...yt.Bothquantitiesarecomputedrecursivelyusingthe\n",
      "certaintyVt+1=E(xt+1?AxKalmangainKt=VtC>(CVtC>+R)?1\n",
      ",givingthefollowingrecursiverecipetocalculatetheconditionallikelihoodof\n",
      "yt+1:?t=Ax?t?1+Kt(yt?y?t)xVt+1=A(I?KtC)VtA>+Q?t\n",
      "y?t+1=CAxP(yt+1|y1...yt)=N(yt+1|y?t+1,CVt+1C>+R)\n",
      "FortheGaussianLDS,theKalmangainKtandstateuncertaintyVt+1(and\n",
      "thustheoutputcovarianceCVt+1C>+R)dependonthemodelparameters\n",
      "(A,C,R,Q)andonthetimestep?althoughastimegrowstheybothconverge\n",
      "tostationaryvalues.Neitherdependsontheobservations.Thus,wemight\n",
      "considerarelaxationoftheGaussianLDSmodelinwhichthesematricesare\n",
      "takentobestationaryfromtheoutset,andareparametrisedindependentlyso\n",
      "thattheyarenolongerconstrainedtotakeonthe?correct?valuesascomputed\n",
      "forKalmaninference.LetuscallthisparametricformoftheKalmangainWand\n",
      "theparametricformoftheoutputcovarianceS.Thentheconditionallikelihood\n",
      "iterationbecomes?t=Ax?t?1+W(yt?y?t)x?ty?t+1=CAxP(yt+1\n",
      "|y1...yt)=N(yt+1|y?t+1,S).2\n",
      "A\n",
      "A\n",
      "x1C\n",
      "C\n",
      "y1\n",
      "Bx0\n",
      "y1\n",
      "x1\n",
      "x2\n",
      "CAy1\n",
      "?2\n",
      "W\n",
      "CAy2\n",
      "xTC\n",
      "y3\n",
      "x1\n",
      "A\n",
      "???\n",
      "C\n",
      "y2\n",
      "A\n",
      "A\n",
      "x3\n",
      "y2\n",
      "?1\n",
      "Cx0\n",
      "A\n",
      "3\n",
      "\n",
      "x2\n",
      "yT\n",
      "xT-1\n",
      "????3\n",
      "?T-1\n",
      "y3\n",
      "AW\n",
      "x2CA\n",
      "yT\n",
      "A\n",
      "???\n",
      "W\n",
      "AW\n",
      "y3\n",
      "xT-1CAyT\n",
      "Figure1:Graphicalrepresentationsofthelatentlineardynamicalsystem\n",
      "(LDS:A,B)andrecurrentlinearmodel(RLM:C).ShadedLDSvariablesare\n",
      "observed,unshaded???circlesarelatentrandomvariables????and\n",
      "squaresarevariablesthatdependdeterministicallyontheirparents.InBthe\n",
      "LDSisredrawnintermsoftherandominnovations?t=xt?Axt?1,facilitating\n",
      "thetransitiontowardstheRLM.TheRLMRLMisthenobtainedbyreplacing\n",
      "?twithadeterministicallyderivedestimateW(yt?y?t).????????\n",
      "TheparametersofthisnewmodelareA,C,WandS.Thisisarelaxation\n",
      "oftheGaussianlatentLDSmodelbecauseWhasmoredegreesoffreedomthan\n",
      "Q,asdoesSthanR(atleastifRisconstrainedtobediagonal).Thenew\n",
      "modelhasarecurrentlinearstructureinthattherandom?t.observationytis\n",
      "fedbacklinearlytoperturbtheotherwisedeterministicevolutionofthestate\n",
      "xAgraphicalrepresentationofthismodelisshowninFig.1C,alongwitha\n",
      "redrawngraphoftheLDSmodel.TheRLMcanbeviewedasreplacingthe\n",
      "randominnovationvariables?t=xt?Axt?1withdata-derivedestimatesW\n",
      "(yt?y?t);estimateswhicharemadepossiblebythefactthat?tcontributes\n",
      "tothevariabilityofytaroundy?t.\n",
      "3\n",
      "RecurrentlinearmodelswithPoissonobservations\n",
      "Thediscussionabovehastransformedastochastic-latentLDSmodelwith\n",
      "GaussianoutputtoanRLMwithdeterministiclatent,butstillwithGaussian\n",
      "output.Ourgoal,however,istoamodelwithanoutputdistributionbetter\n",
      "suitedtothebinnedpoint-processesthatcharacteriseneuralspiking.Both\n",
      "linearstepsaboveandtheeventualstationarityoftheinference\n",
      "parametersdependonthejointGaussianstructureoftheassumedLDSmodel.\n",
      "TheywouldnotapplyifweweretobeginasimilarderivationfromanLDS\n",
      "withPoissonoutput.However,atractableapproachtomodellingpoint-process\n",
      "datawithlow-dimensionaltemporalstructuremaybeprovidedbyintroducing\n",
      "ageneralised-linearoutputstagedirectlytotheRLM.Thismodelisgivenby:\n",
      "?t=Ax?t?1+W(yt?y?t)x?tg(y?t+1)=CAxP(yt+1|y1...yt)\n",
      "=ExpFam(yt+1|y?t+1)\n",
      "4\n",
      "\n",
      "(1)\n",
      "whereExpFamisanexponential-familydistributionsuchasPoisson,and\n",
      "theelement-wiselinkfunctiongallowsforanonlinearmappingfromxttothe\n",
      "predictedmeany?t+1.Inthefollowing,we?t).willwriteffortheinverse-\n",
      "linkasismorecommonforneuralmodels,sothaty?t+1=f(CAxThesimplest\n",
      "Poisson-basedgeneralised-linearRLMmighttakeasitsoutputdistributionY?\n",
      "t?1)),P(yt|y?t)=Poisson(yti|?yti);y?t=f(CAxi\n",
      "whereytiisthespikecountoftheithcellinbintandthefunctionfisnon-\n",
      "negative.However,comparisonwiththeoutputdistributionderivedforthe\n",
      "GaussianRLMsuggeststhatthischoicewouldfailtocapturetheinstantaneous\n",
      "covariancethattheLDSformulationtransferstotheoutputdistribution(and\n",
      "whichappearsinthelow-rankstructureofSabove).Wecanaddressthis\n",
      "concernintwoways.Oneoptionistobinthedatamore,thusdiminishing\n",
      "theoftheinstantaneouscovariance.Thealternativeistoreplacethe\n",
      "independentPoissonswithacorrelatedoutputdistributiononspikecounts.The\n",
      "cascadedgeneralised-linearmodelintroducedbelowisanaturalchoice,andwe\n",
      "willshowthatitcapturesinstantaneouscorrelationsfaithfullywithveryfew\n",
      "hiddendimensions.3\n",
      "Inpractice,wealsosometimesaddainput?ttoequation1thatvariesin\n",
      "timeanddeterminestheaveragebehaviorofthepopulationortheperi-stimulus\n",
      "timehistogram(PSTH).y?t+1=f(?t+CAxt)NotethatthematricesAand\n",
      "CretaintheirinterpretationfromtheLDSmodels.ThematrixAcontrolsthe\n",
      "evolutionofthedynamicalprocessxt.Thephenomenologyofitsdynamicsis\n",
      "determinedbythecomplexeigenvaluesofA.Eigenvalueswithmodulicloseto\n",
      "1correspondtolongtimescalesofaroundthePSTH.Eigenvalues\n",
      "withnon-zeroimaginarypartcorrespondtooscillatorycomponents.Finally,\n",
      "thedynamicswillbestablealltheeigenvaluesliewithintheunitdisc.The\n",
      "matrixCdescribesthedependenceofthehigh-dimensionalneuralsignalsonthe\n",
      "lowdimensionallatentprocessesxt.Inparticular,equation2determinesthe\n",
      "rateoftheneurons.Thisgeneralised-linearstageensuresthatthe\n",
      "ratesarepositivethroughthelinkfunctionf,andtheobservationprocessis\n",
      "Poisson.Forothertypesofdata,thegeneralised-linearstagemightbereplaced\n",
      "byotherappropriatelinkfunctionsandoutputdistributions.3.1\n",
      "Relationshiptoothermodels\n",
      "RLMsarerelatedtorecurrentneuralnetworks[8].Thedierenceslieinthe\n",
      "stateevolution,whichintheneuralnetworkisnonlinear:xt=h(Axt?1+W\n",
      "yt?1);andintherecurrenttermwhichdependsontheobservationratherthan\n",
      "thepredictionerror.Onthedataconsideredhere,wefoundthatusingsigmoidal\n",
      "orthreshold-linearfunctionshresultedinmodelscomparableinlikelihoodto\n",
      "theRLM,andsowerestrictedourattentiontosimplelineardynamics.Wealso\n",
      "foundthatusingthepredictionerrortermW(yt?1?y?t)resultedinbetter\n",
      "modelsthanthesimpleneural-netformulation,andweattributethis\n",
      "tothelinkbetweentheRLMandKalmaninference.Itisalsopossibletowork\n",
      "withinthestochaticlatentLDSframework,replacingtheGaussianoutputdis-\n",
      "tributionwithageneralised-linearPoissonoutput(e.g.[6]).Themainy\n",
      "hereistheintractabilityoftheestimationprocedure.Foranunobservedlatent\n",
      "5\n",
      "\n",
      "processxt,aninferenceprocedureneedstobedevisedtoestimatetheposterior\n",
      "distributionontheentiresequencex1...xt.Forlinear-Gaussianobservations,\n",
      "thisinferenceistractableandisprovidedbyKalmansmoothing.However,with\n",
      "generalised-linearobservations,inferencebecomesintractableandthenecessary\n",
      "approximations[6]arecomputationallyintenseandcanjeopardizethequality\n",
      "ofthemodels.Bycontrast,intheRLMxtisadeterministicfunction\n",
      "ofdata.IntheKalmanhasbeenbuiltintothemodelastheac-\n",
      "curateestimationprocedure,andtispossiblebydirectgradient\n",
      "ascentonthelog-likelihood.Empiricallywedidnotencounterwith\n",
      "localminimaduringoptimization,ashasbeenreportedforLDSmodelsby\n",
      "approximateEM[9].Multiplerestartsfromtrandomvaluesofthepa-\n",
      "rametersalwaysledtomodelswithsimilarlikelihoods.Notethattoestimate\n",
      "thematricesAandWthegradientmustbebackpropagatedthroughsuccessive\n",
      "iterationsofequation1.Thistechnique,knownasbackpropagation-through-\n",
      "time,wasdescribedby[10]asatechniquetorecurrentneuralnetwork\n",
      "models.Recentimplementationshavedemonstratedstate-of-the-artlanguage\n",
      "models[11].Backpropagation-through-timeisthoughttobeinherentlyunsta-\n",
      "blewhenpropagatedpastmanytimestepsandoftenthegradientistruncated\n",
      "prematurely[11].Wefoundthatusinglargevaluesofmomentuminthegradi-\n",
      "entascentalleviatedtheseinstabilitiesandallowedustousebackpropagation\n",
      "withoutthetruncation.\n",
      "4\n",
      "Thecascadedgeneralised-linearmodel(CGLM)\n",
      "ThelinkbetweentheRLMandtheLDSraisesthepossibilitythatamodel\n",
      "forsimultaneouslyrecordedcorrelatedspikecountsmightbederivedinasimi-\n",
      "larway,startingfromanon-dynamical,butlow-dimensional,Gaussianmodel.\n",
      "Stationarymodelsofpopulationactivityhaveattractedrecentinterestfortheir\n",
      "ownsake(e.g.[1]),andwouldalsoprovideawaymodelcorrelationsintroduced\n",
      "bycommoninnovationsthatwereneglectedbythesimplePoissonformofthe\n",
      "RLM.Thus,weconsidervectorsyofspikecountsfromNneurons,without\n",
      "explicitreferencetothetimeatwhichtheywerecollected.AGaussianmodel\n",
      "forycancertainlydescribecorrelationsbetweenthecells,butisill-matched\n",
      "todiscretecountobservations.Thus,aswiththederivationoftheRLMfrom\n",
      "theKalmanwederivehereanewgeneralisationofalow-dimensional,\n",
      "structuredGaussianmodeltospikecountdata.4\n",
      "Thedistributionofanymultivariatevariableycanbefactorizedintoa?cas-\n",
      "caded?productofmultipleone-dimensionaldistributions:P(y)=\n",
      "NY\n",
      "P(yn|y<n).\n",
      "(2)\n",
      "n=1\n",
      "HerenindexestheneuronsuptothelastneuronN,andy<nisthe(n?1)-\n",
      "vector[y1...yn?1].ForaGaussian-distributedy,theconditionalsP(yn|y<n\n",
      ")wouldbelinear-Gaussian.Thus,weproposethe?cascadedgeneralisedlinear\n",
      "model?(CGLM)inwhicheachsuchone-dimensionalconditionaldistribution\n",
      "isageneralised-linearmodel:\n",
      "6\n",
      "\n",
      "y?n=f?n+SnTy<n(3)P(yn|y<n)=ExpFam(?yn)andinwhich\n",
      "thelinearweightsSntakeonastructuredformdevelopedbelow.\n",
      "(4)\n",
      "Theequations3and4subsumetheGaussiandistributionwitharbitraryco-\n",
      "varianceinthecasethatfislinear,andtheExpFamconditionalsareGaussian.\n",
      "Inthiscase,forajointcovarianceof?,itisstraightforwardtoderivetheexpres-\n",
      "sion1?1Sn=(5)?1(??n,?n)n,<n.(??n,?n)n,nwherethesubscripts<nand?\n",
      "nrestrictthematrixtothe(n?1)andnrowsand/orcolumnsrespectively.\n",
      "Thus,wemightconstructsuitablystructuredlinearweightsfortheCGLMby\n",
      "applyingthisresulttothecovariancematrixinducedbythelow-dimensional\n",
      "Gaussianmodelknownasfactoranalysis[12].Factoranalysisassumesthat\n",
      "dataaregeneratedfromaK-dimensionallatentprocessx?N(0,I),whereI\n",
      "istheK?Kidentitymatrix,andyhastheconditionaldistributionP(y|x)=\n",
      "N(?x,?)with?adiagonalmatrixand?anN?Kloadingmatrix.This\n",
      "leadstoacovarianceofygivenby?=?+??T.Ifwerepeatthederivation\n",
      "ofequations3,4and5forthiscovariancematrix,weobtainanexpressionfor\n",
      "Snviathematrixinversionlemma:?11TSn=?1??n,?n+??n,???n,?n,<n\n",
      "(??n,?n)n,n\n",
      "1?1?1T?1=????(???)??(6)<n,?<n,?<n,<n?n,?n?n,?n?1n,<n\n",
      "(??n,?n)n,n\n",
      "T\n",
      "1??1??n,?(???)???1?n,?=??1n,<n(??n,?n)n,nwheretheomitted\n",
      "factor(???)isaK?Kmatrix.Theterminequation6vanishes\n",
      "becauseitinvolvesonlytheentriesof?.Thesurvivingfactorshows\n",
      "thatSnisformedbytakingalinearcombinationofthecolumnsof??1?and\n",
      "thentruncatingtothen?1elements.Thus,ifwearrangeallSnas\n",
      "theuppercolumnsofanN?NmatrixS,wecanwriteS=upperzwTfor\n",
      "somelow-dimensionalmatricesz=??1?andw,wheretheoperationupper\n",
      "extractsthestrictlyuppertriangularpartofamatrix.Thisisthenatural\n",
      "structureimposedonthecascadedconditionalsbyfactoranalysis.Thus,we\n",
      "adoptthesameconstraintonSinthecaseofgeneralisedlinearobservations.\n",
      "Theresulting(CGLM)isshownbelowtoprovidebettertobinarizedneural\n",
      "datathanstandardIsingmodels(seetheResultssection),evenwithasfew\n",
      "asthreelatentdimensions.AnotherusefulpropertyoftheCGLMisthatit\n",
      "allowsstimulus-dependentinputsinequation3.TheCGLMcanalsobeused\n",
      "incombinationwiththegeneralised-linearRLM,withtheCGLMreplacingthe\n",
      "otherwiseindependentobservationmodel.Thisapproachcanbeusefulwhen\n",
      "largebinsareusedtodiscretizespiketrains.Inbothcasesthemodelcanbe\n",
      "estimatedquicklywithstandardgradientascenttechniques.\n",
      "55.1\n",
      "AlternativemodelsAlternativefortemporalinteractions:causally-coupled\n",
      "generalisedlinearmodel\n",
      "Onepopularandsimplemodelofsimultaneouslyrecordedneuronalpopula-\n",
      "tions[3]constructstemporaldependenciesbetweenunitsbydirectlycoupling\n",
      "eachneuron?sprobabilityofingtothepast5\n",
      "spikesintheentirepopulation:yt?Poisson(f(?t+\n",
      "7\n",
      "\n",
      "NX\n",
      "Bi(hi?yt)))\n",
      "i=1\n",
      "Here,hi?ytareconvolutionsofthespiketrainswithasetofbasisfunctions\n",
      "hi,andBiarepairwiseinteractionweights.EachmatrixBihasN2parameters\n",
      "whereNisthenumberofneurons,sothenumberofparametersgrowsquadrati-\n",
      "callywiththepopulationsize.Thistypeofscalingmakesthemodelprohibitive\n",
      "tousewithverylarge-scalearrayrecordings.Evenwithaggresiveregulariza-\n",
      "tiontechniques,themodel?sparametersarediculttoidentifywithlimited\n",
      "amountsofdata.Perhapsmoreimportantly,themodeldoesnothaveaphysi-\n",
      "calinterpretation.Neuronsrecordedincortexarerarelydirectly-connectedand\n",
      "retinalganglioncellsalmostneverdirectlyconnecttoeachother.Instead,such\n",
      "directly-coupledGLMsareusedtodescribeso-called?functional?interactions\n",
      "betweenneurons[3].Webelieveamuchbetterinterpretationforthecorrela-\n",
      "tionsobservedbetweenpairsofneuronsisthattheyarecausedbycommon\n",
      "inputstotheseneuronswhichseemoftentobetoasmallnumberof\n",
      "dimensions.Themodelsweproposehere,theRLMandtheCGLM,areaimed\n",
      "atdiscoveringsuchinputs.5.2\n",
      "Alternativeforinstantaneousinteractions:theIsingmodel\n",
      "Instantaneousinteractionsbetweenbinarydata(aswouldbeobtainedby\n",
      "countingspikesinshortintervals)canbemodelledintermsoftheirpairwise\n",
      "interactions[1]embodiedintheIsingmodel:1yTJye.(7)ZwhereJisa\n",
      "pairwiseinteractionmatrixandZisthepartitionfunction,orthenormalization\n",
      "constantofthemodel.Themodel?sattractivenessisthatforagivencovariance\n",
      "structureitmakestheweakestpossibleassumptionsaboutthedistributionofy,\n",
      "thatis,likeaGaussianforcontinuousdata,ithasthelargestpossibleentropy\n",
      "underthecovarianceconstraint.However,theIsingmodelandtheso-called\n",
      "functionalinteractionsJhavenophysicalinterpretationwhenappliedtoneural\n",
      "data.Furthermore,Isingmodelsaretoastheyrequireestimates\n",
      "ofthegradientsofthepartitionfunctionZ;theyalsofromthesame\n",
      "quadraticscalinginnumberofparamtersasdoesthedirectly-coupledGLM.\n",
      "Isingmodelsareevenhardertoestimatewhenstimulus-dependentinputsare\n",
      "addedinequation7,butfordatacollectedintheretinaorothersensoryareas\n",
      "[1],muchofthecovariationinymaybeexpectedtoarisefromcommonstim-\n",
      "ulusinput.Anothershort-comingoftheIsingmodelisthatitcanonlymodel\n",
      "binarizeddataandcannotbenormalizedforintegery-s[6],soeitherthetime\n",
      "binsneedtobereducedtoensurenoneuronmorethanonespikeinasingle\n",
      "binorthespikecountsmustbecappedat1.P(y)=\n",
      "66.1\n",
      "ResultsSimulateddata\n",
      "WebeganbyevaluatingRLMmodelstosimulateddatawherethetrue\n",
      "generativeparameterswereknown.Twoaspectsoftheestimatedmodelswereof\n",
      "particularinterest:thephenomenologyofthedynamics(capturedbytheeigen-\n",
      "valuesofthedynamicsmatrixA)andtherelationshipbetweenthedynamical\n",
      "subspaceandmeasuredneuralactivity(capturedbytheoutputmatrixC).We\n",
      "evaluatedtheagreementbetweentheestimatedandgenerativeoutputmatri-\n",
      "8\n",
      "\n",
      "cesbymeasuringtheprincipalanglesbetweenthecorrespondingsubspaces.\n",
      "Thesereport,insuccession,thesmallestangleachievablebetweenalineinone\n",
      "subspaceandalineinthesecondsubspace,onceallprevioussuchvectorsof\n",
      "maximalagreementhavebeenprojectedout.Exactlyalignedn-dimensional\n",
      "subspaceshaveallnprincipalanglesequalto0?.Unrelatedlow-dimensional\n",
      "subspacesembeddedinhighdimensionsareclosetoorthogonalandsohave\n",
      "principalanglesnear90?.Wevtherobustnessofmaximisation\n",
      "ofthegeneralised-linearRLMlikelihoodbymodelstosimulateddata\n",
      "generatedbyaknownRLM.Fig.2(a)showseigenvaluesfromseveralsimulated\n",
      "RLMsandtheeigenvaluesrecoveredbyparameterstosimulateddata.\n",
      "Theagreementisgenerallygood.Inparticular,thequalitativeaspectsofthe\n",
      "dynamicsintheabsolutevaluesandimaginarypartsoftheeigenvalues\n",
      "arewellcharacterised.Fig.2(d)showsthattheRLM6\n",
      "RLMidentitheeigenvaluesofdiversePLDSmodels\n",
      "RLMrecoverseigenvaluesofsimulateddynamics0.4\n",
      "0.4\n",
      "GenerativePLDSIdenbyRLM\n",
      "GenerativePLDSIdenbyPLDSIdenbyRLM\n",
      "0.05\n",
      "GroundtruthIden\n",
      "0\n",
      "Imaginary\n",
      "0.2Imaginary\n",
      "Imaginary\n",
      "0.2\n",
      "RLMidentitheeigenvaluesofaPLDSmodeltorealdata0.1\n",
      "0?0.2\n",
      "?0.2\n",
      "?0.40\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0\n",
      "?0.05\n",
      "?0.40.2\n",
      "0.4\n",
      "0.6Real\n",
      "Real\n",
      "(a)\n",
      "0.8\n",
      "?0.10.85\n",
      "1\n",
      "0.9\n",
      "(b)\n",
      "9\n",
      "\n",
      "Principalanglesbetweengroundtruth(RLM)andidensubspaces\n",
      "0.95\n",
      "1\n",
      "Real\n",
      "(c)\n",
      "Principalanglesbetweentrueandidensubspaces\n",
      "PrincipalanglesbetweenPLDStodataandidensubspaces90\n",
      "90\n",
      "45\n",
      "0\n",
      "PCA\n",
      "GLDS\n",
      "(d)\n",
      "RLM\n",
      "Degrees\n",
      "Degrees\n",
      "Degrees\n",
      "90\n",
      "45\n",
      "0\n",
      "PCA\n",
      "LDS\n",
      "(e)\n",
      "RLM\n",
      "PLDS\n",
      "45\n",
      "0\n",
      "PCA\n",
      "GLDS\n",
      "RLM\n",
      "(f)\n",
      "Figure2:Experimentson100-dimensionalsimulateddatageneratedfrom\n",
      "a5-dimensionallatentprocess.GeneratingmodelswerePoissonRLM(ad),\n",
      "PoissonLDSwithrandomparameters(cf)andPoissonLDSmodelwithpa-\n",
      "rameterstoneuraldata(cf).ThemodelswerePCA,LDSwithGaus-\n",
      "sian(LDS/GLDS)orPoisson(PLDS)output,andRLMwithPoissonoutput\n",
      "(RLM).Intheupperplots,eigenvaluesfromtrunsareshownindif-\n",
      "ferentcolors.alsorecoverthesubspacebytheloadingmatrixC,and\n",
      "dososubstantiallymoreaccuratelythaneitherprincipalcomponentsanalysis\n",
      "(PCA)orGLDSmodels.ItisimportanttonotethatthelikelihoodsofLDS\n",
      "modelswithPoissonobservationsaretooptimise,andsomayyield\n",
      "poorresultsevenwhentowithin-classdata.Inpracticewedidnotobserve\n",
      "localoptimawiththeRLMorCGLM.WealsoaskedwhethertheRLMcould\n",
      "recoverthedynamicalpropertiesandlatentsubspaceofdatageneratedbya\n",
      "latentLDSmodelwithPoissonobservations.Fig.2(b)showsthatthedynam-\n",
      "icaleigenvaluesofthemaximum-likelihoodRLMareclosetotheeigenvaluesof\n",
      "10\n",
      "\n",
      "generativeLDSdynamics,whilstFig.2(e)showsthatthedynamicalsubspace\n",
      "isalsocorrectlyrecovered.Parametersforthesesimulationswerechosenran-\n",
      "domly.Wethenaskedwhetherthequalityofparameteridenextended\n",
      "toPoisson-outputLDSmodelswithrealisticparameters,bygeneratingdata\n",
      "fromaPoisson-outputLDSmodelthathadbeentoaneuralrecording.As\n",
      "seenin2(c)and2(f),theRLMremainaccurateinthisregime,yielding\n",
      "bettersubspaceestimatesthaneitherPCAoraGaussianLDS.6.2\n",
      "Arrayrecordeddata\n",
      "Wenextcomparedtheperformanceofthenovelmodelsonneuraldata.\n",
      "TheRLMwascomparedtothedirected-coupledGLMbygradient-based\n",
      "likelihoodoptimisation)aswellasLDSmodelswithGaussianorPoissonoutputs\n",
      "byEM,withaLaplaceapproximationE-step).TheCGLMwascompared\n",
      "totheIsingmodel.Weusedadatasetof92neuronsrecordedwithaUtaharray\n",
      "implantedinthepremotorandmotorcorticesofarhesusmacaquemonkey\n",
      "performingadelayedcenter-outreachtask.Forallcomparisonsbelowweuse\n",
      "datasetsof108trialsinwhichthemonkeymademovementstothesametarget.\n",
      "Wediscretizedspiketrainsintotimebinsof10ms.Thedirected-coupledGLM\n",
      "neededsubstantialregularizationinordertomakegoodpredictionsonheld-out\n",
      "testdata.Figure3(a)showsonlythebestcross-validationresultfortheGLM,\n",
      "butresultswithoutregularizationformodelswith7\n",
      "FilteringpredictionontestdataLikelihoodperspike?baseline(bits)\n",
      "13\n",
      "MSEbaseline?MSE\n",
      "12111098765\n",
      "GLM?SCGLMPLDS10LDS10LDS20RLM10RLM20RLM3+PSTH\n",
      "baseline=PSTH(lowrank)\n",
      "(a)\n",
      "0.070.060.050.040.030.020.010\n",
      "Isingrank=1r=2\n",
      "r=3\n",
      "r=4\n",
      "r=5\n",
      "(b)\n",
      "Figure3:a.Predictiveperformanceofvariousmodelsontestdata(higher\n",
      "isbetter).GLM-typemodelsarehelpedgreatlybyself-coupling(which\n",
      "theothermodelsdonothave).ThebestmodelisanRLMwiththreelatent\n",
      "dimensionsandalow-rankmodelofthePSTH(seethesupplementarymate-\n",
      "rialformoreinformationaboutthismodel).Addingself-couplingtothis\n",
      "modelfurtherincreasesitspredictiveperformanceby5(notshown).b.The\n",
      "likelihoodperspikeofIsingmodelsaswellasCGLMmodelswithsmallnumbers\n",
      "ofhiddendimensions.TheCGLMsaturatesatthreedimensionsandperforms\n",
      "betterthanIsingmodels.low-dimensionalparametrisation.Performancewas\n",
      "measuredbythecausalmean-squared-errorinpredictionsubtractedfromthe\n",
      "errorofalow-ranksmoothedPSTHmodel(basedonasingularvaluedecom-\n",
      "positionofthematrixofallsmoothedPSTHs).Thenumberofdimensions(5)\n",
      "11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andthestandarddeviationoftheGaussiansmoothing(20ms)werecross-\n",
      "validatedtothebestpossiblePSTHperformance.Thus,ourevaluation\n",
      "isfocusesoneachmodel?sabilitytopredicttrial-to-trialco-variationin\n",
      "aroundthemean.AsecondmeasureofperformancefortheRLMwasobtained\n",
      "bystudyingprobabilisticsamplesobtainedfromthemodel.Figure4\n",
      "inthesupplementalmaterialshowsaveragednoisecrosscorrelogramsobtained\n",
      "fromalargesetofsamples.NotethatthePSTHshavebeensubtractedfrom\n",
      "eachtrialtorevealonlytheextracorrelationstructurethatisnotrepeated\n",
      "amongsttrials.Evenwithfewhiddendimensions,themodelcaptureswellthe\n",
      "fulltemporalstructureofthenoisecorrelations.InthecaseoftheIsingmodel\n",
      "webinarizedthedatabyreplacingallspikecountslargerthan1with1.The\n",
      "log-likelihoodoftheIsingmodelcouldonlybeestimatedforsmallnumbers\n",
      "ofneurons,soforcomparisonwetookonlythe30mostactiveneurons.The\n",
      "measureofperformancereportedin3(b)istheextralog-likelihoodper\n",
      "spikeobtainedabovethatofamodelthatmakesconstantpredictionsequalto\n",
      "themeanrateofeachneuron.TheCGLMmodelwithonlythreehidden\n",
      "dimensionsachievesthebestgeneralisationperformance,surpassingtheIsing\n",
      "model.SimilarresultsfortheperformanceoftheCGLMcanbeseenonthe\n",
      "fulldatasetof92neuronswithnon-binarizeddata,indicatingthatthreelatent\n",
      "dimensionstodescribethefullspacevisitedbytheneuronalpopulation\n",
      "onatrial-by-trialbasis.\n",
      "7\n",
      "Discussion\n",
      "Thegeneralised-linearRLMmodel,whilesharingmotivationwithlatent\n",
      "LDSmodel,canbemoreetlyandwithoutapproximationtonon-\n",
      "Gaussiandata.Wehaveshownimprovedperformanceonbothsimulateddata\n",
      "andonpopulationrecordingsfromthemotorcortexofbehavingmonkeys.The\n",
      "modeliseasilyextendedtootheroutputdistributions(suchasBernoulliorneg-\n",
      "ativebinomial),tomixedcontinuousanddiscretedata,tononlinearoutputs,\n",
      "andtononlineardynamics.Forthemotordataconsideredhere,thegeneralised-\n",
      "linearmodelperformedaswellasmodelswithfurthernon-linearites.However,\n",
      "preliminaryresultsondatafromsensorycorticalareassuggeststhatnonlinear\n",
      "modelsmaybeofgreatervalueinothersettings.\n",
      "8\n",
      "Acknowledgments\n",
      "WethankKrishnaShenoyandmembersofhislabforgenerouslyproviding\n",
      "accesstodata.FundingfromtheGatsbyCharitableFoundationandDARPA\n",
      "REPAIRN66001-10-C-2010.8\n",
      "2References\n",
      "[1]ESchneidman,MJBerry,RSegev,andWBialek.Weakpairwisecorre-\n",
      "lationsimplystronglycorrelatednetworkstatesinaneuralpopulation.Na-\n",
      "ture,440:1007?1012,2005.[2]GyorgyBuzsaki.Large-scalerecordingofneu-\n",
      "ronalensembles.NatNeurosci,7(5):446?51,2004.[3]J.W.Pillow,J.Shlens,\n",
      "12\n",
      "\n",
      "L.Paninski,A.Sher,A.M.Litke,E.J.Chichilnisky,andE.P.Simoncelli.\n",
      "Spatiotemporalcorrelationsandvisualsignallinginacompleteneuronalpop-\n",
      "ulation.Nature,454(7207):995?999,2008.[4]MarkM.Churchland,Byron\n",
      "M.Yu,ManeeshSahani,andKrishnaV.Shenoy.Techniquesforextracting\n",
      "single-trialactivitypatternsfromlarge-scaleneuralrecordings.CurrOpinNeu-\n",
      "robiol,17(5):609?618,2007.[5]BMYu,AAfshar,GSanthanam,SIRyu,KV\n",
      "Shenoy,andMSahani.Extractingdynamicalstructureembeddedinneural\n",
      "activity.AdvancesinNeuralInformationProcessingSystems,18:1545?1552,\n",
      "2006.[6]JHMacke,LBsing,JPCunningham,BMYu,KVShenoy,andM\n",
      "Sahani.Empiricalmodelsofspikinginneuralpopulations.AdvancesinNeural\n",
      "InformationProcessingSystems,24:1350?1358,2011.[7]R.E.Kalman.Anew\n",
      "approachtolinearandpredictionproblems.JournalofBasicEngineer-\n",
      "ing,82(1):35?45,1960.[8]JLElman.Findingstructureintime.Cognitive\n",
      "Science,14:179?211,1990.[9]LBuesing,JHMacke,andMSahani.Spectral\n",
      "learningoflineardynamicsfromgeneralised-linearobservationswithapplication\n",
      "toneuralpopulationdata.AdvancesinNeuralInformationProcessingSystems,\n",
      "25,2012.[10]DERumelhart,GEHinton,andRJWilliams.Learninginternal\n",
      "representationsbyerrorpropagation.MitPressComputationalModelsOfCog-\n",
      "nitionAndPerceptionSeries,pages318?462,1986.[11]TMikolov,ADeoras,\n",
      "SKombrink,LBurget,andJHCernocky.Empiricalevaluationandcombina-\n",
      "tionofadvancedlanguagemodelingtechniques.ConferenceoftheInternational\n",
      "SpeechCommunicationAssociation,2011.[12]ChristopherM.Bishop.Pattern\n",
      "RecognitionandMachineLearning.Springer,2006.\n",
      "9\n",
      "13\n",
      "\n",
      "PP5016.pdf\n",
      "PP5016.pdf 16\n",
      "Amessage-passingalgorithmformulti-agent\n",
      "trajectoryplanning\n",
      "Authoredby:\n",
      "JonathanS.Yedidia\n",
      "JoseBento\n",
      "NateDerbinsky\n",
      "JavierAlonso-Mora\n",
      "Abstract\n",
      "Wedescribeanovelapproachforcomputingcollision-freeemph\n",
      "f\n",
      "global\n",
      "g\n",
      "trajectoriesfor$p$agentswithspinitialand\n",
      "basedonanimprovedversionofthealternatingdirectionmethodofmul-\n",
      "tipliers(ADMM)algorithm.Comparedwithexistingmethods,ourap-\n",
      "proachisnaturallyparallelizableandallowsforincorporatingt\n",
      "costfunctionalswithonlyminoradjustments.Weapplyourmethodto\n",
      "classicalchallenginginstancesandobservethatitscomputationalrequire-\n",
      "mentsscalewellwith$p$forseveralcostfunctionals.Wealsoshowthata\n",
      "specializationofouralgorithmcanbeusedfor\n",
      "f\n",
      "emlocal\n",
      "g\n",
      "motionplanning\n",
      "bysolvingtheproblemofjointoptimizationinvelocityspace.\n",
      "1PaperBody\n",
      "Robotnavigationreliesonatleastthreesub-tasks:localization,mapping,and\n",
      "motionplanning.Thelattercanbedescribedasanoptimizationproblem:\n",
      "computethelowest-costpath,ortrajectory,betweenaninitialandcon-\n",
      "Thispaperfocusesontrajectoryplanningformultipleagents,an\n",
      "importantprobleminrobotics[1,2],computeranimation,andcrowdsimu-\n",
      "lation[3].CentralizedplanningformultipleagentsisPSPACEhard[4,5].\n",
      "Tocontendwiththiscomplexity,traditionalmulti-agentplanningprioritizes\n",
      "agentsandcomputestheirtrajectoriessequentially[6],leadingtosuboptimal\n",
      "solutions.Bycontrast,ourmethodplansforallagentssimultaneously.Tra-\n",
      "jectoryplanningisalsoifagentsarenon-distinctandcanbedynam-\n",
      "icallyassignedtoasetofgoalpositions[1].Weconsidertheharderproblem\n",
      "whererobotshaveauniqueidentityandtheirgoalpositionsarestaticallypre-\n",
      "spBothmixed-integerquadraticprogramming(MIQP)[7]and[more\n",
      "t,althoughlocal]sequentialconvexprogramming[8]approacheshave\n",
      "beenappliedtotheproblemofcomputingcollision-freetrajectoriesformultiple\n",
      "1\n",
      "\n",
      "agentswithpre-spgoalpositions;however,duetothenon-convexityof\n",
      "theproblem,theseapproaches,especiallytheformer,donotscalewellwiththe\n",
      "numberofagents.Alternatively,trajectoriesmaybefoundbysamplingintheir\n",
      "jointspace[9].Thisapproachisprobabilisticand,alone,only\n",
      "givesasymptoticguarantees.SeeAppendixAforfurthercommentsondiscrete\n",
      "searchmethods.Duetothecomplexityofplanningcollision-freetrajectories,\n",
      "real-timerobotnavigationiscommonlydecoupledintoaglobalplannerand\n",
      "afastlocalplannerthatperformscollision-avoidance.Manysingle-agentre-\n",
      "activecollision-avoidancealgorithmsarebasedeitheronpotential[10],\n",
      "whichtypicallyignorethevelocityofotheragents,or?velocityobstacles?[11],\n",
      "whichprovideimprovedperformanceindynamicenvironmentsbyformulating\n",
      "theoptimizationinvelocityspaceinsteadofCartesianspace.Buildingonan\n",
      "extensionofthevelocity-obstaclesapproach,recentworkoncentralizedcolli-\n",
      "sionavoidance[12]computescollision-freelocalmotionsforallagentswhilst\n",
      "maximizingajointutilityusingeitheracomputationallyexpensiveMIQPor\n",
      "ant,thoughlocal,QP.Whilenotthemainfocusofthispaper,weshow\n",
      "thataspecializationofourapproach?\n",
      "ThisauthorwouldliketothankEmilyHupfandNoaGhersinfortheir\n",
      "supportwhilewritingthispaper.\n",
      "1\n",
      "toglobal-trajectoryoptimizationalsoappliesforlocal-trajectoryoptimiza-\n",
      "tion,andournumericalresultsdemonstrateimprovementsinboth\n",
      "andscalingperformance.Inthispaperweformalizetheglobaltrajectoryplan-\n",
      "ningtaskasfollows.Givenpagentsoftradii\n",
      "f\n",
      "ri\n",
      "g\n",
      "pi=1withgiven\n",
      "desiredinitialandpositions,\n",
      "f\n",
      "xi(0)\n",
      "g\n",
      "pi=1and\n",
      "f\n",
      "xi(T)\n",
      "g\n",
      "pi=1,alongwitha\n",
      "costfunctionalovertrajectories,computecollision-freetrajectoriesforallagents\n",
      "thatminimizethecostfunctional.Thatis,asetofintermediatepoints\n",
      "f\n",
      "xi\n",
      "(t)\n",
      "g\n",
      "pi=1,t2(0,T),thatthe?hard?collision-freeconstraintsthat\n",
      "kxi(t)xj(t)k>ri+rj,foralli,jandt,andthatinsofaraspossible,minimizes\n",
      "thecostfunctional.Themethodweproposesearchesforasolutionwithinthe\n",
      "spaceofpiece-wiselineartrajectories,whereinthetrajectoryofanagentiscom-\n",
      "pletelyspbyasetofpositionsatasetoftimeinstants\n",
      "f\n",
      "ts\n",
      "g\n",
      "?s=0\n",
      ".Wecallthesetimeinstantsbreak-pointsandtheyarethesameforallagents,\n",
      "whichgreatlythemathematicsofourmethod.Allotherintermedi-\n",
      "atepointsofthetrajectoriesarecomputedbyassumingthateachagentmoves\n",
      "withconstantvelocityinbetweenbreak-points:ift1andt2>t1areconsecutive\n",
      "break-points,thenxi(t)=t21t1((t2t)xi(t1)+(tt1)xi(t2))fort2[t1,t2\n",
      "].Alongwiththesetofinitialandthenumberofinterior\n",
      "break-points(?1)isaninputtoourmethod,withacorresponding\n",
      "increasing?yieldstrajectoriesthataremoreandsmooth,withpossibly\n",
      "higherquality;butincreasing?enlargestheproblem,leadingtopotentiallyin-\n",
      "creasedcomputation.Themaincontributionsofthispaperareasfollows:i)We\n",
      "formulatetheglobaltrajectoryplanningtaskasadecomposableoptimization\n",
      "problem.Weshowhowtosolvetheresultingsub-problemsexactlyand\n",
      "ciently,despitetheirnonconvexity,andhowtocoordinatetheirsolutionsusing\n",
      "message-passing.Ourmethod,basedonthe?three-weight?versionofADMM\n",
      "2\n",
      "\n",
      "[13],iseasilyparallelized,doesnotrequireparametertuning,andwepresent\n",
      "empiricalevidenceofgoodscalabilitywithp.ii)Withinourdecomposable\n",
      "framework,wedescribetsub-problems,calledminimizers,eachensur-\n",
      "ingthetrajectoriessatisfyaseparatecriterion.Ourmethodisandcan\n",
      "considertcombinationsofminimizers.Aparticularlycrucialminimizer\n",
      "ensurestherearenointer-agentcollisions,butwealsoderiveotherminimizers\n",
      "thatallowfortrajectorieswithminimaltotalenergy,avoidingstatic\n",
      "obstacles,orimposingdynamicconstraints,suchasmaximum/minimumagent\n",
      "velocity.iii)Weshowthatourmethodcanspecializetoperformlocalplan-\n",
      "ningbysolvingtheproblemofjointoptimizationinvelocityspace[12].Our\n",
      "workisamongthefewexampleswherethesuccessofapplyingADMMto\n",
      "approximatesolutionstoalargenon-convexproblemscanbejudgedwiththe\n",
      "nakedeye,bythegracefulnessofthetrajectoriesfound.Thispaperalsore-\n",
      "inforcestheclaimin[13]thatsmall,yetimportant,motoADMM\n",
      "canbringanorderofmagnitudeincreaseinspeed.Weemphasizetheimpor-\n",
      "tanceofthesemoinournumericalexperiments,wherewecompare\n",
      "theperformanceofourmethodusingthethree-weightalgorithm(TWA)versus\n",
      "thatofstandardADMM.Therestofthepaperisorganizedasfollows.Sec-\n",
      "tion2providesbackgroundonADMMandtheTWA.Section3formulatesthe\n",
      "global-trajectory-planningtaskasanoptimizationproblemanddescribesthe\n",
      "separateblocksnecessarytosolveit(themathematicaldetailsofsolvingthese\n",
      "subproblemsarelefttoappendices).Section4evaluatestheperformanceofour\n",
      "solution:itsscalabilitywithp,sensitivitytoinitialconditions,andthe\n",
      "ofrentcostfunctionals.Section5explainshowtoimplementavelocity-\n",
      "obstaclemethodusingourmethodandcomparesitsperformancewithprior\n",
      "work.Finally,Section6drawsconclusionsandsuggestsdirectionsforfuture\n",
      "work.\n",
      "2\n",
      "MinimizersintheTWA\n",
      "InthissectionweprovideashortdescriptionoftheTWA[13],and,inpartic-\n",
      "ular,theroleoftheminimizerbuildingblocksthatitneedstosolveaparticular\n",
      "optimizationproblem.SectionBofthesupplementarymaterialincludesafull\n",
      "descriptionoftheTWA.AsasmallillustrativeexampleofhowtheTWAis\n",
      "usedtosolveoptimizationproblems,supposewewanttosolveminx2R3f(x)\n",
      "=min\n",
      "f\n",
      "x1,x2,x3\n",
      "g\n",
      "f1(x1,x3)+f2(x1,x2,x3)+f3(x3),where(.)22\n",
      "R[\n",
      "f\n",
      "+1\n",
      "g\n",
      ".Thefunctionscanrepresentsoftcosts,forexamplef3(x3)=(x3\n",
      "1)2,orhardequalityorinequalityconstraints,suchasf1(x1,x3)=J(x1?\n",
      "x3),whereweareusingthenotationJ(.)=0if(.)istrueor+1if(.)isfalse.\n",
      "TheTWAsolvesthisoptimizationproblemiterativelybypassingmessagesona\n",
      "bipartitegraph,intheformofaForneyfactorgraph[14]:oneminimizer-node\n",
      "perfunctionfb,oneequality-nodepervariablexjandanedge(b,j),connecting\n",
      "bandj,iffbdependsonxj(seeFigure1-left).1\n",
      "g\n",
      "=\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "g\n",
      "=\n",
      "2\n",
      "3\n",
      "g\n",
      "=\n",
      "3\n",
      "?n1,1,?1,1?n1,3,?1,3\n",
      "g1\n",
      "?x1,1,?1,1?x1,3,?1,3\n",
      "?n2,1,?2,1?n2,2,?2,2?n2,3,?2,3\n",
      "g2\n",
      "?x2,1,?2,1?x2,2,??2,2x2,3,?2,3\n",
      "?n3,3,?3,3\n",
      "g3\n",
      "?x3,3,?3,3\n",
      "Figure1:Left:bipartitegraph,withoneminimizer-nodeontheleftforeach\n",
      "functionmakinguptheoverallobjectivefunction,andoneequality-nodeonthe\n",
      "rightpervariableintheproblem.Right:Theinputandoutputvariablesfor\n",
      "eachminimizerblock.Apartfromthemessagevalues,andtwo\n",
      "internalparameters1thatwespecifyinSection4,thealgorithmisfullysp\n",
      "bythebehavioroftheminimizersandthetopologyofthegraph.Whatdoesa\n",
      "minimizerdo?Theminimizer-nodeg1,forexample,solvesasmalloptimization\n",
      "problemoveritslocalvariablesx1andx3.Withoutgoingintothefulldetail\n",
      "presentedin[13]andthesupplementarymaterial,theestimatesx1,1andx1,3\n",
      "arethencombinedwithrunningsumsofthebetweentheminimizer\n",
      "estimatesandtheequality-nodeconsensusestimatestoobtainmessagesm1,1\n",
      "andm1,3oneachneighboringedgethataresenttotheneighboringequality-\n",
      "nodesalongwithcorrespondingcertaintyweights,!?1,2and!?1,3.All\n",
      "otherminimizersactsimilarly.Theequality-nodesreceivetheselocalmessages\n",
      "andweightsandproduceconsensusestimatesforallvariablesbycomputingan\n",
      "averageoftheincomingmessages,weightedbytheincomingcertaintyweights\n",
      "!?.Fromtheseconsensusestimates,correctingmessagesarecomputedand\n",
      "communicatedbacktotheminimizerstohelpthemreachconsensus.Acer-\n",
      "taintyweightforthecorrectingmessages,?,isalsocommunicatedbacktothe\n",
      "minimizers.Forexample,theminimizerg1receivescorrectingmessagesn1,1\n",
      "andn1,3withcorrespondingcertaintyweights?1,1and?1,3(seeFigure1-\n",
      "right).Whenproducingnewlocalestimates,thebthminimizernodecomputes\n",
      "itslocalestimates\n",
      "f\n",
      "xj\n",
      "g\n",
      "bychoosingapointthatminimizesthesumofthelocal\n",
      "functionfbandweightedsquareddistancefromtheincomingmessages(tiesare\n",
      "brokenrandomly):23X1\n",
      "f\n",
      "xb,j\n",
      "g\n",
      "j=gb\n",
      "f\n",
      "nb,j\n",
      "g\n",
      "j,\n",
      "f\n",
      "?kb,j\n",
      "g\n",
      "j?argmin4fb\n",
      "(\n",
      "f\n",
      "xj\n",
      "g\n",
      "j)+?b,j(xjnb,j)25,(1)2j\n",
      "f\n",
      "xj\n",
      "g\n",
      "j\n",
      "Pwhere\n",
      "fg\n",
      "jandjrunoverallequality-nodesconnectedtob.IntheTWA,\n",
      "thecertaintyweights\n",
      "f\n",
      "!?b,j\n",
      "g\n",
      "thatthisminimizeroutputsmustbe0(uncer-\n",
      "tain);1(certain);or?0,settosomevalue.Thelogicforsettingweights\n",
      "fromminimizer-nodesdependsontheproblem;asweshallsee,intrajectory\n",
      "4\n",
      "\n",
      "planningproblems,weonlyuse0or?0weights.Ifwechoosethatallminimiz-\n",
      "ersalwaysoutputweightsequalto?0,theTWAreducestostandardADMM;\n",
      "however,0-weightsallowsequality-nodestoignoreinactiveconstraints,travers-\n",
      "ingthesearchspacemuchfaster.Finally,noticethatallminimizerscanoperate\n",
      "simultaneously,andthesameistruefortheconsensuscalculationperformedby\n",
      "eachequality-node.Thealgorithmisthuseasytoparallelize.\n",
      "3\n",
      "Globaltrajectoryplanning\n",
      "Wenowturntodescribingourdecompositionoftheglobaltrajectoryplan-\n",
      "ningoptimizationproblemindetail.Webeginbythevariablestobe\n",
      "optimizedinouroptimizationproblem.In1\n",
      "Thesearethestep-sizeand?0constants.SeeSectionBinthesupplementary\n",
      "materialformoredetail.\n",
      "3\n",
      "ourformulation,wearenottrackingthepointsofthetrajectoriesbya\n",
      "continuous-timevariabletakingvaluesin[0,T].Rather,ourvariablesarethe\n",
      "positions\n",
      "f\n",
      "xi(s)\n",
      "g\n",
      "i2[p],wherethetrajectoriesareindexedbyiandbreak-points\n",
      "areindexedbyadiscretevariablestakingvaluesbetween1and?1.Notethat\n",
      "f\n",
      "xi(0)\n",
      "g\n",
      "i2[p]and\n",
      "f\n",
      "xi(?)\n",
      "g\n",
      "i2[p]aretheinitialandsetsof\n",
      "values,notvariablestooptimize.3.1\n",
      "Formulationasunconstrainedoptimizationwithoutstaticobstacles\n",
      "Intermsofthesevariables,thenon-collisionconstraints2arek(?xi(s+1)\n",
      "+(1?)xi(s))(?xj(s+1)+(1foralli,j2[p],s2\n",
      "f\n",
      "0,...,?1\n",
      "g\n",
      "and?2[0,1].\n",
      "?)xj(s))k\n",
      "ri+rj,\n",
      "(2)\n",
      "Theparameter?isusedtotraceouttheconstant-velocitytrajectoriesof\n",
      "agentsiandjbetweenbreak-pointss+1ands.Theparameter?hasno\n",
      "units,itisanormalizedtimeratherthananabsolutetime.Ift1istheabsolute\n",
      "timeofthebreak-pointwithintegerindexsandt2istheabsolutetimeof\n",
      "thebreak-pointwithintegerindexs+1andtparametrizesthetrajectoriesin\n",
      "absolutetimethen?=(tt1)/(t2t1).Notethatintheaboveformulation,\n",
      "absolutetimedoesnotappear,andanysolutionissimplyasetofpathsthat,\n",
      "whentravelledbyeachagentatconstantvelocitybetweenbreak-points,leads\n",
      "tonocollisions.Whenconvertingthissolutionintotrajectoriesparameterized\n",
      "byabsolutetime,thebreak-pointsdonotneedtobechosenuniformlyspacedin\n",
      "absolutetime.Theconstraintsrepresentedin(2)canbeformallyincorporated\n",
      "intoanunconstrainedoptimizationproblemasfollows.Wesearchforasolution\n",
      "totheproblem:minfcost(\n",
      "f\n",
      "xi(s)\n",
      "g\n",
      "i,s)+\n",
      "f\n",
      "xi(s)\n",
      "g\n",
      "i,s\n",
      "nX1X\n",
      "frcoll(xi(s),xi(s+1),xj(s),xj(s+1)),i,rj\n",
      "(3)\n",
      "s=0i>j\n",
      "where\n",
      "f\n",
      "xi(0)\n",
      "g\n",
      "pand\n",
      "f\n",
      "xi(?)\n",
      "g\n",
      "pareconstantsratherthanoptimizationvari-\n",
      "ables,andwherethefunctionfcostisafunctionthatrepresentssomecostto\n",
      "5\n",
      "\n",
      "beminimized(e.g.theintegratedkineticenergycollorthemaximumvelocity\n",
      "overalltheagents)andthefunctionfr,r0isas,coll00fr,r0(x,x,x,\n",
      "x)=J(k?(x\n",
      "x0)+(1\n",
      "?)(x\n",
      "x0)k\n",
      "r+r08?2[0,1]).\n",
      "(4)\n",
      "Inthissection,xandxrepresentthepositionofanarbitraryagentofradiusr\n",
      "attwoconsecutivebreak-pointsandx0andx0thepositionofasecondarbitrary\n",
      "agentofradiusr0atthesamebreakpoints.IntheexpressionaboveJ(.)takes\n",
      "thevalue0wheneveritsargument,aclause,istrueandcolltakesthevalue\n",
      "+1otherwise.Intuitively,wepayancostinfr,r0wheneverthereisa\n",
      "collision,andwepayzerootherwise.In(3)wecansetfcost(.),toenforcea\n",
      "preferencefortrajectoriessatisfyingspproperties.Forexample,wemight\n",
      "prefertrajectoriesforwhichthetotalkineticenergyspentbythesetofagents\n",
      "issmall.Inthiscase,fCcost(x,x)=Ckxxk2,wehave,pn1\n",
      "fcost(\n",
      "f\n",
      "xi(s)\n",
      "g\n",
      "i,s)=\n",
      "1XXcostf(xi(s),xi(s+1)).pni=1s=0Ci,s\n",
      "(5)\n",
      "wherethecots\n",
      "f\n",
      "Ci,s\n",
      "g\n",
      "canaccountforagentswithdrentmasses,\n",
      "tabsolute-timeintervalsbetween-breakpointsortpreferences\n",
      "regardingwhichagentswewanttobelessactiveandwhichagentsareallowed\n",
      "tomovefaster.Moresimply,wemightwanttoexcludetrajectoriesinwhich\n",
      "agentsmovefasterthanacertainamount,butwithoutdistinguishingamong\n",
      "allremainingtrajectories.Forthiscasewecanwrite,fCcost(x,x)=J(kx\n",
      "xk?C).\n",
      "(6)\n",
      "Inthiscase,associatingeachbreak-pointtoatimeinstant,thecots\n",
      "f\n",
      "Ci,s\n",
      "g\n",
      "inexpression(5)wouldrepresenttlimitsonthevelocityof\n",
      "tagentsbetweentsectionsofthetrajectory.Ifwewanttoforce\n",
      "allagentstohaveaminimumvelocitywecansimplyreversetheinequalityin\n",
      "(6).2Wereplacedthestrictinequalityintheconditionfornon-collisionbya\n",
      "simpleinequality??toavoidtechnicalitiesinformulatingtheoptimization\n",
      "problem.Sincetheagentsareround,thisallowsforasinglepointofcontact\n",
      "betweentwoagentsanddoesnotreducepracticalrelevance.\n",
      "4\n",
      "3.2\n",
      "Formulationasunconstrainedoptimizationwithstaticobstacles\n",
      "Inmanyscenariosagentsshouldalsoavoidcollisionswithstaticobstacles.\n",
      "Giventwopointsinspace,xLandxR,wecanforbidallagentsfromcrossing\n",
      "thelinesegmentfromxLtoxRbyaddingPpPn1thefollowingtermtothe\n",
      "function(3):i=1s=0fxwall(xi(s),xi(s+1)).WerecallthatriisL,xR,ri\n",
      "theradiusofagentiandfxwall(x,x)=J(k(?x+(1L,xR,r\n",
      "Noticethatf\n",
      "coll\n",
      "6\n",
      "\n",
      "?)x)\n",
      "canbeexpressedusingf\n",
      "(xR+(1\n",
      "wall\n",
      "coll00fr,r0(x,x,x,x)\n",
      ")xL)k\n",
      "rforall?,\n",
      ".Inparticular,\n",
      "wall0=f0,0,r+r0(x\n",
      "x,x0\n",
      "2[0,1]).\n",
      "x).\n",
      "(7)(8)\n",
      "Weusethisfactlatertoexpresstheminimizerassociatedwithagent-agent\n",
      "collisionsusingtheminimizerassociatedwithagent-obstaclecollisions.When\n",
      "agentsmoveintheplane,i.e.xi(s)2R2foralli2[p]ands+12[?+1],being\n",
      "abletoavoidcollisionswithageneralstaticlinesegmentallowstoautomatically\n",
      "avoidcollisionswithmultiplestaticobstaclesofarbitrarypolygonalshape.Our\n",
      "numericalexperimentsonlyconsideragentsintheplaneandso,inthispaper,\n",
      "weonlydescribetheminimizerblockforwallcollisionfora2Dworld.Inhigher\n",
      "dimensions,tobstacleprimitivesneedtobeconsidered.3.3\n",
      "Message-passingformulation\n",
      "Tosolve(3)usingtheTWA,weneedtospecifythetopologyofthebipar-\n",
      "titegraphassociatedwiththeunconstrainedformulation(3)andtheoperation\n",
      "performedbyeveryminimizer,i.e.the!?weightupdatelogicandx-variable\n",
      "updateequations.Wepostponedescribingthechoiceofinitialvaluesandin-\n",
      "ternalparametersuntilSection4.Wedescribethebipartitegraph.To\n",
      "beconcrete,letusassumethatthecostfunctionalhastheformof(5).The\n",
      "unconstrainedformulation(3)thentellsusthattheglobalobjectivefunction\n",
      "isthesumof?p(p+1)/2terms:?p(p1)/2functionsfcolland?pfunctions\n",
      "fCcost.Thesefunctionsinvolveatotalof(?+1)pvariablesoutofwhichonly\n",
      "(?1)parefree(sincetheinitialandionsareCorrespond-\n",
      "ingly,thebipartitegraphalongwhichmessagesarepassedhas?p(p+1)/2\n",
      "minimizer-nodesthatconnecttothe(?+1)pequality-nodes.Inparticular,\n",
      "theequalitynodeassociatedwiththebreak-pointvariablexi(s),?>s>0,is\n",
      "connectedto2(p1)tcostgcollminimizer-nodesandtwotgC\n",
      "minimizer-nodes.Ifs=0ors=?theequality-nodecostonlyconnectstohalf\n",
      "asmanygcollnodesandgCnodes.Wenowdescribethetminimizers.\n",
      "Everyminimizerbasicallyisaspecialcaseof(1).3.3.1\n",
      "Agent-agentcollisionminimizer\n",
      "Westartwiththeminimizerassociatedwiththefunctionsfcoll,thatwe\n",
      "denotedbygcoll.Thisminimizerreceivesasparameterstheradius,randr0,\n",
      "ofthetwoagentswhosecollisionitisavoiding.Theminimizertakesasinputa\n",
      "setofincomingn-messages,\n",
      "f\n",
      "n,n,n0,n0\n",
      "g\n",
      ",andassociated?-weights,\n",
      "f\n",
      "?,?\n",
      ",?0,?0\n",
      "g\n",
      ",andoutputsasetofupdatedx-variablesaccordingtoexpression\n",
      "(9).Messagesnandncomefromthetwoequality-nodesassociatedwiththe\n",
      "7\n",
      "\n",
      "positionsofoneoftheagentsattwoconsecutivebreak-pointsandn0andn0\n",
      "fromthecorrespondingequality-nodesfortheotheragent.gcoll(n,n,n0,n0\n",
      ",?,?,?0,?0,r,r0)=arg\n",
      "min\n",
      "f\n",
      "x,x,x0,x0\n",
      "g\n",
      "coll00fr,r0(x,x,x,x)\n",
      "??00??00kxnk2+kxnk2+kxn0k2+kxn0k2.(9)2222The\n",
      "updatelogicfortheweights!?forthisminimizerissimple.Ifthetrajectory\n",
      "fromntonforanagentofradiusrdoesnotcollidewiththetrajectoryfrom\n",
      "n0ton0foranagentofradiusr0thensetalltheoutgoingweights!?to\n",
      "zero.Otherwisesetthemallto?0.Theoutgoingzeroweightsindicatetothe\n",
      "receivingequality-nodesinthebipartitegraphthatthecollisionconstraintfor\n",
      "thispairofagentsisinactiveandthatthevaluesitreceivesfromthisminimizer-\n",
      "nodeshouldbeignoredwhencomputingtheconsensusvaluesofthereceiving\n",
      "equality-nodes.+\n",
      "Thesolutionto(9)isfoundusingtheagent-obstaclecollisionminimizerthat\n",
      "wedescribenext.5\n",
      "3.3.2\n",
      "Agent-obstaclecollisionminimizer\n",
      "Theminimizerforfwallisdenotedbygwall.Itisparameterizedbythe\n",
      "obstacleposition\n",
      "f\n",
      "xL,xR\n",
      "g\n",
      "aswellastheradiusoftheagentthatneedstoavoid\n",
      "theobstacle.Itreceivestwon-messages,\n",
      "f\n",
      "n,n\n",
      "g\n",
      ",andcorrespondingweights\n",
      "f\n",
      "?\n",
      ",?\n",
      "g\n",
      ",fromtheequality-nodesassociatedwithtwoconsecutivepositionsofan\n",
      "agentthatneedstoavoidtheobstacle.Itsoutput,thex-variables,are\n",
      "asgwall(n,n,r,xL,xR,?,?)=argminfxwall(x,x)+L,xR,r\n",
      "f\n",
      "x,x\n",
      "g\n",
      "?kx2\n",
      "nk2+\n",
      "?kx2\n",
      "nk2.\n",
      "(10)\n",
      "Whenagentsmoveintheplane(2D),thisminimizercanbesolvedbyrefor-\n",
      "mulatingtheoptimizationin(10)asamechanicalprobleminvolvingasystem\n",
      "ofspringsthatwecansolveexactlyandtly.Thisreductionisexplained\n",
      "inthesupplementarymaterialinSectionDandthesolutiontothemechanical\n",
      "problemisexplainedinSectionI.Theupdatelogicforthe!?-weightsissimilar\n",
      "tothatofthegcollminimizer.Ifanagentofradius\n",
      "rgoingfromnandndoesnotcollidewiththelinesegmentfromxLtoxR\n",
      "thensetalloutgoingweightstozerobecausetheconstraintisinactive;otherwise\n",
      "setalltheoutgoingweightsto?0.Noticethat,from(8),itfollowsthatthe\n",
      "agent-agentminimizergcollcanbeexpressedusinggwall.Moreconcretely,\n",
      "asprovedinthesupplementarymaterial,SectionC,??gcoll(n,n,n0,n0,?\n",
      ",?,?0,?0,r,r0)=M2gwallM1.\n",
      "f\n",
      "n,n,n0,n0,?,?,?0,?0,r,r0\n",
      "g\n",
      ",foraconstantrectangularmatrixM1andamatrixM2thatdependon\n",
      "f\n",
      "n,n,\n",
      "n0,n0,?,?,?0,?0\n",
      "g\n",
      ".3.3.3\n",
      "Minimumenergyandmaximum(minimum)velocityminimizer\n",
      "8\n",
      "\n",
      "Whenfcostcanbedecomposedasin(5),theminimizerassociatedwiththe\n",
      "functionsfcostisdenotedbygcostandreceivesasinputtwon-messages,\n",
      "f\n",
      "n,\n",
      "n\n",
      "g\n",
      ",andcorrespondingweights,\n",
      "f\n",
      "?,?\n",
      "g\n",
      ".Themessagescomefromtwoequality-\n",
      "nodesassociatedwithtwoconsecutivepositionsofanagent.Theminimizeris\n",
      "alsoparameterizedbyacostfactorc.Itoutputsasetofupdatedx-messages\n",
      "asgcost(n,n,?,?,c)=argminfccost(x,x)+\n",
      "f\n",
      "x,x\n",
      "g\n",
      "?kx2\n",
      "nk2+\n",
      "?kx2\n",
      "nk2.\n",
      "(11)\n",
      "Theupdatelogicforthe!?-weightsoftheminimumenergyminimizeris\n",
      "verysimply:alwayssetalloutgoingweights!?to?0.Theupdatelogicfor\n",
      "the!?-weightsofthemaximumvelocityminimizeristhefollowing.Ifknnk\n",
      "?csetalloutgoingweightstozero.Otherwise,setthemto?0.Theupdate\n",
      "logicfortheminimumvelocityminimizerissimilar.Ifknnkc,setallthe!\n",
      "?-weightstozero.Otherwisesetthemto?0.Thesolutiontotheminimum\n",
      "energy,maximumvelocityandminimumvelocityminimizeriswritteninthe\n",
      "supplementarymaterialinSectionsE,F,andGrespectively.\n",
      "4\n",
      "Numericalresults\n",
      "Wenowreportontheperformanceofouralgorithm(seeAppendixJfor\n",
      "animportantcommentontheanytimepropertiesofouralgorithm).Notethat\n",
      "thelackofopen-sourcescalablealgorithmsforglobaltrajectoryplanningin\n",
      "theliteraturemakesittobenchmarkourperformanceagainstother\n",
      "methods.Also,inapaperitistoappreciatethegracefulnessofthe\n",
      "discoveredtrajectoryoptimizations,soweincludeavideointhesupplementary\n",
      "materialthatshowsoptimizedtrajectoriesaswellasintermediateresults\n",
      "asthealgorithmprogressesforavarietyofadditionalscenarios,includingthose\n",
      "withobstacles.Allthetestsdescribedhereareforagentsinatwodimensional\n",
      "plane.Alltestsbutthelastwereperformedusingsixcoresofa3.4GHzi7\n",
      "CPU.Thettestsdidnotrequireanyspecialtuningofparameters.In\n",
      "particular,thestep-sizein[13](their?variable)isalways0.1.Inorderto\n",
      "quicklyequilibratethesystemtoareasonablesetofvariablesandtowashout\n",
      "theimportanceofinitialconditions,thedefaultweight?0wassetequaltoa\n",
      "smallvalue(?p?105)forthe20iterationsandthensetto1forallfurther\n",
      "iterations.6\n",
      "ThetestconsidersscenarioCONF1:p(even)agentsofradiusr,equally\n",
      "spacedaroundonacircleofradiusR,areeachrequiredtoexchangeposition\n",
      "withthecorrespondingantipodalagent,r=(5/4)Rsin(?/2(p4)).Thisisa\n",
      "classicaltestscenariobecausethestraightlinemotionofallagents\n",
      "totheirgoalwouldresultinthemallcollidinginthecenterofthecircle.We\n",
      "comparetheconvergencetimeoftheTWAwithasimilarversionusingstandard\n",
      "ADMMtoperformtheoptimizations.Inthistest,thealgorithm?sinitialvalue\n",
      "foreachvariableintheproblemwassettothecorrespondinginitialposition\n",
      "ofeachagent.Theobjectiveistominimizethetotalkineticenergy(Cinthe\n",
      "9\n",
      "\n",
      "energyminimizerissetto1).Figure2-leftshowsthattheTWAscalesbetter\n",
      "withpthanclassicADMMandtypicallygivesanorderofmagnitudespeed-up.\n",
      "PleaseseeAppendixKforafurthercommentonthescalingoftheconvergence\n",
      "timeofADMMandTWAwithp.Convergencetime(sec)?\n",
      "Numberofoccurrences\n",
      "?\n",
      "?=4?\n",
      "?\n",
      "1500\n",
      "?=8?\n",
      "??\n",
      "0\n",
      "?\n",
      "0\n",
      "??\n",
      "20\n",
      "????\n",
      "?\n",
      "??\n",
      "?\n",
      "????\n",
      "??\n",
      "?\n",
      "40\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "2500\n",
      "60\n",
      "?=?6\n",
      "25\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      "?=?4\n",
      "80\n",
      "100\n",
      "p=1002000\n",
      "1500\n",
      "?\n",
      "1000\n",
      "??500\n",
      "?\n",
      "10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0100\n",
      "200\n",
      "Numberofagents,p\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "Physicalcores(?12)\n",
      "?\n",
      "500\n",
      "2\n",
      "Convergencetime(sec)\n",
      "?=6\n",
      "2000\n",
      "1000\n",
      "1\n",
      "?\n",
      "?=8\n",
      "0\n",
      "0\n",
      "p=80\n",
      "?\n",
      "?\n",
      "?\n",
      "p?=60??p????40???\n",
      "?\n",
      "?\n",
      "?5\n",
      "Objectivevalueoftrajectories\n",
      "?\n",
      "??\n",
      "??\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "???\n",
      "10\n",
      "???\n",
      "??\n",
      "???\n",
      "15\n",
      "???\n",
      "11\n",
      "\n",
      "??\n",
      "???\n",
      "??\n",
      "???\n",
      "20\n",
      "Numberofcores\n",
      "Figure2:Left:ConvergencetimeusingstandardADMM(dashedlines)\n",
      "andusingTWA(solidlines).Middle:Distributionoftotalenergyandtime\n",
      "forconvergencewithrandominitialconditions(p=20and?=5).Right:\n",
      "Convergencetimeusingatnumberofcores(?=5).Thesecondtest\n",
      "forCONF1analyzesthesensitivityoftheconvergencetimeandobjectivevalue\n",
      "whenthevariables?valueattheiterationarechosenuniformlyatrandom\n",
      "inthesmallestspacetimeboxthatincludestheinitialand\n",
      "oftherobots.Figure2-middleshowsthat,althoughthereissomespreadon\n",
      "theconvergencetime,ouralgorithmseemstoreliablyconvergetorelatively\n",
      "similar-costlocalminima(otherexperimentsshowthattheobjectivevalueof\n",
      "theseminimaisaround5timessmallerthanthatfoundwhenthealgorithm\n",
      "isrunusingonlythecollisionavoidanceminimizerswithoutakineticenergy\n",
      "costterm).Aswouldbeexpected,theprecisetrajectoriesfoundvarywidely\n",
      "betweentrandomruns.StillforCONF1,andinitialconditions,we\n",
      "parallelizeourmethodusingseveralcoresofa2.66GHzi7processorandavery\n",
      "primitivescheduling/synchronizationscheme.Althoughthisschemedoesnot\n",
      "fullyexploitparallelization,Figure2-rightdoesshowaspeed-upasthenumber\n",
      "ofcoresincreasesandthelargerpis,thegreaterthespeed-up.Westallwhen\n",
      "wereachthetwelvephysicalcoresavailableandstartusingvirtualcores.\n",
      "Convergencetime,oneepoch(sec)\n",
      "Finally,Figure3-leftcomparestheconvergencetimetooptimizethetotal\n",
      "energywiththetimetosimplyafeasible(i.e.collision-free)solution.The\n",
      "agentsinitialandisrandomlychosenintheplane(CONF2).\n",
      "Errorbarsindicate?onestandarddeviation.Minimizingthekineticenergy\n",
      "isordersofmagnitudecomputationallymoreexpensivethanafeasible\n",
      "solution,asisclearfromthetmagnitudeoftheleftandrightscaleof\n",
      "Figure3-left.?\n",
      "?=8\n",
      "12\n",
      "?=810\n",
      "1500\n",
      "?=6?\n",
      "?=4\n",
      "8\n",
      "1200?\n",
      "6\n",
      "??\n",
      "?\n",
      "4?\n",
      "20\n",
      "12\n",
      "\n",
      "?\n",
      "0\n",
      "?\n",
      "20\n",
      "??\n",
      "???\n",
      "40\n",
      "?\n",
      "?????\n",
      "?????\n",
      "?????\n",
      "60\n",
      "????\n",
      "???\n",
      "600\n",
      "?\n",
      "?=6?\n",
      "900\n",
      "?300\n",
      "?=4\n",
      "Minimumenergy\n",
      "Feasible\n",
      "1800\n",
      "Convergencetime(sec)\n",
      "Convergencetime(sec)\n",
      "Convergencetime(sec)\n",
      "30\n",
      "?\n",
      "080\n",
      "3.0\n",
      "2.5\n",
      "Pink:MIQP\n",
      "2.0\n",
      "Lightblue:TWA\n",
      "1.5\n",
      "1.0\n",
      "0.5\n",
      "0.08\n",
      "100\n",
      "Numberofagents,p\n",
      "10*12\n",
      "14*16\n",
      "18*20\n",
      "24*24\n",
      "30*32\n",
      "40*40\n",
      "13\n",
      "\n",
      "50*52\n",
      "Numberofagents,p\n",
      "Figure3:Left:Convergencetimewhenminimizingenergy(bluescale/dashed\n",
      "lines)andtosimplyafeasiblesolution(redscale/solidlines).Right:(For\n",
      "Section5).Convergence-timedistributionforeachepochusingourmethod\n",
      "(bluebars)andusingtheMIQPof[12](redbarsandstar-values).\n",
      "7\n",
      "5\n",
      "Localtrajectoryplanningbasedonvelocityobstacles\n",
      "Inthissectionweshowhowthejointoptimizationpresentedin[12],which\n",
      "isbasedontheconceptofvelocityobstacles[11](VO),canbealsosolvedvia\n",
      "themessage-passingTWA.InVO,giventhecurrentposition\n",
      "f\n",
      "xi(0)\n",
      "g\n",
      "i2[p]and\n",
      "radius\n",
      "f\n",
      "ri\n",
      "g\n",
      "ofallagents,anewvelocitycommandiscomputedjointlyforall\n",
      "agentsminimizingthedistancetotheirpreferredvelocity\n",
      "f\n",
      "viref\n",
      "g\n",
      "i2[p].This\n",
      "newvelocitycommandmustguaranteethatthetrajectoriesofallagentsremain\n",
      "collision-freeforatleastatimehorizon?.Newcollision-freevelocitiesarecom-\n",
      "putedevery??seconds,?<1,untilallagentsreachtheir\n",
      "Following[12],andassuminganobstacle-freeenvironmentandorderdy-\n",
      "namics,thecollision-freevelocitiesaregivenby,XminimizeCikvivirefk2s.t.\n",
      "k(xi(0)+vit)(xj(0)+vjt)kri+rj8i2[p],t2[0,?].\n",
      "f\n",
      "vi\n",
      "g\n",
      "i2[p]\n",
      "i2[p]\n",
      "Sincethevelocities\n",
      "f\n",
      "vi\n",
      "g\n",
      "i2[p]arerelatedlinearlytothepositionofeach\n",
      "objectafter?seconds,\n",
      "f\n",
      "xi(?)\n",
      "g\n",
      "i2[p],asimplechangeofvariablesallowsusto\n",
      "reformulatetheaboveproblemas,X2minimizeCi0kxixrefik\n",
      "f\n",
      "xi\n",
      "g\n",
      "i2[p]\n",
      "i2[p]\n",
      "s.t.k(1?)(xi(0)xj(0))+?(xixj)kri+rj8j>i2[p],?2[0,1](12)2\n",
      "refrefwhere=Ci/?,xi=xi(0)+vi?andwehavedroppedthe?inxi\n",
      "(?).Theaboveproblem,extendedtoaccountforcollisionswiththestaticline\n",
      "segments\n",
      "f\n",
      "xRk,xLk\n",
      "g\n",
      "k,canbeformulatedinanunconstrainedformusingthe\n",
      "functionsfcost,fcollandfwall.Namely,XXXXrefminfCcostfrcoll(xi\n",
      "(0),xi,xj(0),xj)+fxwall(xi(0),xi).(13)0(xi,xi)+i,rjRk,xLk,ri\n",
      "Ci0\n",
      "f\n",
      "xi\n",
      "g\n",
      "i\n",
      "i\n",
      "i2[p]\n",
      "i>j\n",
      "i2[p]k\n",
      "f\n",
      "xrefi\n",
      "g\n",
      "i\n",
      "Notethat\n",
      "f\n",
      "xi(0)\n",
      "g\n",
      "iandareconstants,notvariablesbeingoptimized.Given\n",
      "thisformulation,theTWAcanbeusedtosolvetheoptimization.Allcor-\n",
      "respondingminimizersarespecialcasesofminimizersderivedintheprevious\n",
      "sectionforglobaltrajectoryplanning(seeSectionHinthesupplementaryma-\n",
      "terialfordetails).Figure3-rightshowsthedistributionofthetimetosolve(12)\n",
      "forCONF1.Wecomparethemixedintegerquadraticprogramming(MIQP)\n",
      "approachfrom[12]withours.Ourmethodalocalminimaofexactly(13),\n",
      "while[12]aglobalminimaofanapproximationto(13).Sp,[12]\n",
      "14\n",
      "\n",
      "requiresapproximatingthesearchdomainbyhyperplanesandanadditional\n",
      "branch-and-boundalgorithmwhileoursdoesnot.Bothapproachesuseamech-\n",
      "anismforbreakingthesymmetryfromCONF1andavoiddeadlocks:theirsuses\n",
      "apreferentialrotationdirectionforagents,whileweuseagentswithslightlydif-\n",
      "ferentCcotsintheirenergyminimizers(Cithagent=1+0.001i).Both\n",
      "simulationsweredoneonasingle2.66GHzcore.Theresultsshowtheorderof\n",
      "magnitudeissimilar,but,becauseourimplementationisdoneinJavawhile[12]\n",
      "usesMatlab-mexinterfaceofCPLEX11,theresultsarenotexactlycomparable.\n",
      "6\n",
      "Conclusionandfuturework\n",
      "Wehavepresentedanovelalgorithmforglobalandlocalplanningofthetra-\n",
      "jectoryofmultipledistinctagents,aproblemknowntobehard.Thesolution\n",
      "isbasedonsolvinganon-convexoptimizationproblemusingTWA,amodi-\n",
      "ADMM.ItssimilaritytoADMMbringsscalabilityandeasyparallelization.\n",
      "However,usingTWAimprovesperformanceconsiderably.Ourimplementation\n",
      "ofthealgorithminJavaonaregulardesktopcomputer,usingabasicsched-\n",
      "uler/synchronizationoveritsfewcores,alreadyscalestohundredsofagentsand\n",
      "achievesreal-timeperformanceforlocalplanning.Thealgorithmcan\n",
      "accountforobstaclesandtcostfunctionals.Foragentsintheplane,\n",
      "wederivedexplicitexpressionsthataccountforstaticobstacles,movingobsta-\n",
      "cles,anddynamicconstraintsonthevelocityandenergy.Futureworkshould\n",
      "considerotherrestrictionsonthesmoothnessofthetrajectory(e.g.accelera-\n",
      "tionconstraints)andprovidefastsolverstoourminimizersforagentsin3D.\n",
      "Themessage-passingnatureofouralgorithmhintsthatitmightbepossible\n",
      "toadaptouralgorithmtodoplanninginadecentralizedfashion.Forexam-\n",
      "ple,minimizerslikegcollcouldbesolvedbymessageexchangebetweenpairs\n",
      "ofagentswithinamaximumcommunicationradius.Itisanopenproblemto\n",
      "buildapracticalcommunication-synchronizationschemeforsuchanapproach.\n",
      "8\n",
      "2References\n",
      "[1]JavierAlonso-Mora,AndreasBreitenmoser,MartinRuRolandSiegwart,\n",
      "andPaulBeardsley.Imageandanimationdisplaywithmultiplemobilerobots.\n",
      "31(6):753?773,2012.[2]PeterR.Wurman,D?Andrea,andMick\n",
      "Mountz.Coordinatinghundredsofcooperative,autonomousvehiclesinware-\n",
      "houses.AIMagazine,29(1):9?19,2008.[3]StephenJ.Guy,JatinChhugani,\n",
      "ChangkyuKim,NadathurSatish,MingLin,DineshManocha,andPradeep\n",
      "Dubey.Clearpath:highlyparallelcollisionavoidanceformulti-agentsimula-\n",
      "tion.InProceedingsofthe2009ACMSIGGRAPH/EurographicsSymposium\n",
      "onComputerAnimation,pages177?187,2009.[4]JohnH.Reif.Complexity\n",
      "ofthemover?sproblemandgeneralizations.InIEEEAnnualSymposiumon\n",
      "FoundationsofComputerScience,pages421?427,1979.[5]JohnE.Hopcroft,\n",
      "JacobT.Schwartz,andMichaSharir.Onthecomplexityofmotionplanningfor\n",
      "multipleindependentobjects;pspace-hardnessofthe?warehouseman?sprob-\n",
      "15\n",
      "\n",
      "lem?.TheInternationalJournalofRoboticsResearch,3(4):76?88,1984.[6]\n",
      "MarenBennewitz,WolframBurgard,andSebastianThrun.Findingandop-\n",
      "timizingsolvablepriorityschemesfordecoupledpathplanningtechniquesfor\n",
      "teamsofmobilerobots.RoboticsandAutonomousSystems,41(2?3):89?99,\n",
      "2002.[7]DanielMellinger,AlexKushleyev,andVijayKumar.Mixed-integer\n",
      "quadraticprogramtrajectorygenerationforheterogeneousquadrotorteams.In\n",
      "IEEEInternationalConferenceonRoboticsandAutomation,pages477?483,\n",
      "2012.[8]FedericoAugugliaro,AngelaP.Schoellig,andD?Andrea.\n",
      "Generationofcollision-freetrajectoriesforaquadrocopterAsequen-\n",
      "tialconvexprogrammingapproach.InIEEE/RSJInternationalConference\n",
      "onIntelligentRobotsandSystems,pages1917?1922,2012.[9]StevenM.\n",
      "LaValleandJamesJ.Randomizedkinodynamicplanning.TheIn-\n",
      "ternationalJournalofRoboticsResearch,20(5):378?400,2001.[10]Oussama\n",
      "Khatib.Real-timeobstacleavoidanceformanipulatorsandmobilerobots.The\n",
      "InternationalJournalofRoboticsResearch,5(1):90?98,1986.[11]PaoloFior-\n",
      "iniandZviShiller.Motionplanningindynamicenvironmentsusingveloc-\n",
      "ityobstacles.TheInternationalJournalofRoboticsResearch,17(7):760?772,\n",
      "1998.[12]JavierAlonso-Mora,MartinRolandSiegwart,andPaulBeard-\n",
      "sley.Collisionavoidanceformultipleagentswithjointutilitymaximization.\n",
      "InIEEEInternationalConferenceonRoboticsandAutomation,2013.[13]\n",
      "NateDerbinsky,Jos?eBento,VeitElser,andJonathanS.Yedidia.Anim-\n",
      "provedthree-weightmessagepassingalgorithm.arXiv:1305.1961[cs.AI],2013.\n",
      "[14]G.DavidForneyJr.Codesongraphs:Normalrealizations.IEEETrans-\n",
      "actionsonInformationTheory,47(2):520?548,2001.[15]SertacKaramanand\n",
      "EmilioFrazzoli.Incrementalsampling-basedalgorithmsforoptimalmotion\n",
      "planning.arXivpreprintarXiv:1005.0416,2010.[16]R.GlowinskiandA.Mar-\n",
      "rocco.Surl?approximation,pare?l?ementsd?ordreun,etlar?esolution,\n",
      "parp?enalisization-dualit?e,d?uneclassdeprobl`emsdeDirichletnonlin?eare.\n",
      "RevueFranc?aised?Automatique,Informatique,etRechercheOp?erationelle,\n",
      "9(2):41?76,1975.[17]DanielGabayandBertrandMercier.Adualalgorithm\n",
      "forthesolutionofnonlinearvariationalproblemsviaelementapproxima-\n",
      "tion.Computers&MathematicswithApplications,2(1):17?40,1976.[18]Hugh\n",
      "EverettIII.Generalizedlagrangemultipliermethodforsolvingproblemsofop-\n",
      "timumallocationofresources.OperationsResearch,11(3):399?417,1963.[19]\n",
      "MagnusR.Hestenes.Multiplierandgradientmethods.JournalofOptimization\n",
      "TheoryandApplications,4(5):303?320,1969.[20]MagnusR.Hestenes.Multi-\n",
      "plierandgradientmethods.InL.A.Zadehetal.,editor,ComputingMethodsin\n",
      "OptimizationProblems2.AcademicPress,NewYork,1969.[21]M.J.D.Powell.\n",
      "Amethodfornonlinearconstraintsinminimizationproblems.InR.Fletcher,\n",
      "editor,Optimization.AcademicPress,London,1969.[22]StephenBoyd,Neal\n",
      "Parikh,EricChu,BorjaPeleato,andJonathanEckstein.Distributedoptimiza-\n",
      "tionandstatisticallearningviathealternatingdirectionmethodofmultipliers.\n",
      "FoundationsandTrendsinMachineLearning,3(1):1?122,2011.\n",
      "9\n",
      "16\n",
      "\n",
      "PP5941.pdf\n",
      "PP5941.pdf 13\n",
      "LearningwithSymmetricLabelNoise:The\n",
      "ImportanceofBeingUnhinged\n",
      "Authoredby:\n",
      "RobertC.Williamson\n",
      "BrendanvanRooyen\n",
      "AdityaMenon\n",
      "Abstract\n",
      "Convexpotentialminimisationisthedefactoapproachtobinaryclas-\n",
      "However,LongandServedio[2008]provedthatundersym-\n",
      "metriclabelnoise(SLN),minimisationofanyconvexpotentialovera\n",
      "linearfunctionclasscanresultinclassiperformanceequivalentto\n",
      "randomguessing.ThisostensiblyshowsthatconvexlossesarenotSLN-\n",
      "robust.Inthispaper,weproposeaconvex,on-calibratedloss\n",
      "andprovethatitisSLN-robust.ThelossavoidstheLongandServedio\n",
      "[2008]resultbyvirtueofbeingnegativelyunbounded.Thelossisamod-\n",
      "ofthehingeloss,whereonedoesnotclampatzero;hence,we\n",
      "callittheunhingedloss.Weshowthattheoptimalunhingedsolution\n",
      "isequivalenttothatofastronglyregularisedSVM,andisthelimiting\n",
      "solutionforanyconvexpotential;thisimpliesthatstrongl2regularisa-\n",
      "tionmakesmoststandardlearnersSLN-robust.Experimentsthe\n",
      "unhingedloss?SLN-robustness.\n",
      "1PaperBody\n",
      "Convexpotentialminimisationisthedefactoapproachtobinary\n",
      "However,LongandServedio[2010]provedthatundersymmetriclabelnoise\n",
      "(SLN),minimisationofanyconvexpotentialoveralinearfunctionclasscan\n",
      "resultinperformanceequivalenttorandomguessing.Thisosten-\n",
      "siblyshowsthatconvexlossesarenotSLN-robust.Inthispaper,wepropose\n",
      "aconvex,lossandprovethatitisSLN-robust.The\n",
      "lossavoidstheLongandServedio[2010]resultbyvirtueofbeingnegatively\n",
      "unbounded.Thelossisamoofthehingeloss,whereonedoesnot\n",
      "clampatzero;hence,wecallittheunhingedloss.Weshowthattheoptimal\n",
      "unhingedsolutionisequivalenttothatofastronglyregularisedSVM,andis\n",
      "thelimitingsolutionforanyconvexpotential;thisimpliesthatstrong`2regu-\n",
      "larisationmakesmoststandardlearnersSLN-robust.Experimentsthe\n",
      "1\n",
      "\n",
      "unhingedloss?SLN-robustnessisborneoutinpractice.So,withapologiesto\n",
      "Wilde[1895],whilethetruthisrarelypure,itcanbesimple.\n",
      "1\n",
      "Learningwithsymmetriclabelnoise\n",
      "Binaryisthecanonicalsupervisedlearningproblem.Givenan\n",
      "instancespaceX,andsamplesfromsomedistributionDoverX?\n",
      "f\n",
      "?1\n",
      "g\n",
      ",thegoal\n",
      "istolearnascorers:X?Rwithlowerroronfuturesamples\n",
      "drawnfromD.Ourinterestisinthemorerealisticscenariowherethelearner\n",
      "observessamplesfromsomecorruptionDofD,wherelabelshavesomeconstant\n",
      "probabilityofbeinged,andthegoalisstilltoperformwellwithrespectto\n",
      "D.Thisproblemisknownaslearningfromsymmetriclabelnoise(SLNlearning)\n",
      "[AngluinandLaird,1988].LongandServedio[2010]showedthatthereexist\n",
      "linearlyseparableDwhere,whenthelearnerobservessomecorruptionDwith\n",
      "symmetriclabelnoiseofanynonzerorate,minimisationofanyconvexpotential\n",
      "overalinearfunctionclassresultsinclasscationperformanceonDthatis\n",
      "equivalenttorandomguessing.Ostensibly,thisestablishesthatconvexlosses\n",
      "arenot?SLN-robust?andmotivatestheuseofnon-convexlosses[Stempfeland\n",
      "Ralaivola,2009,Masnadi-Shirazietal.,2010,DingandVishwanathan,2010,\n",
      "Denchevetal.,2012,ManwaniandSastry,2013].Inthispaper,weproposea\n",
      "convexlossandprovethatitisSLN-robust.ThelossavoidstheresultofLong\n",
      "andServedio[2010]byvirtueofbeingnegativelyunbounded.Thelossisa\n",
      "moofthehingelosswhereonedoesnotclampatzero;thus,wecallit\n",
      "theunhingedloss.Thislosshasseveralappealingproperties,suchasbeingthe\n",
      "uniqueconvexlosssatisfyinganotionof?strong?SLN-robustness(Proposition\n",
      "5),being(Proposition6),consistentwhenminimisedon\n",
      "D(Proposition7),andhavingansimpleoptimalsolutionthatisthe\n",
      "oftwokernelmeans(Equation8).Finally,weshowthatthisoptimalsolution\n",
      "isequivalenttothatofastronglyregularisedSVM(Proposition8),andany\n",
      "ttiableconvexpotential(Proposition9),implyingthatstrong`2\n",
      "regularisationendowsmoststandardlearnerswithSLN-robustness.1\n",
      "Theresultingfromminimisingtheunhingedlossisnotnew[De-\n",
      "vroyeetal.,1996,Chapter10],[Sch?olkopfandSmola,2002,Section1.2],\n",
      "[Shawe-TaylorandCristianini,2004,Section5.1].However,establishingthis\n",
      "(strong)SLN-robustness,uniquenessthereof,anditsequivalenceto\n",
      "ahighlyregularisedSVMsolution,toourknowledgeisnovel.\n",
      "2\n",
      "Backgroundandproblemsetup\n",
      "FixaninstancespaceX.WedenotebyDadistributionoverX?\n",
      "f\n",
      "?1\n",
      "g\n",
      ",with\n",
      "randomvariables(X,Y)?D.AnyDmaybeexpressedviatheclass-conditionals\n",
      "(P,Q)=(P(X|Y=1),P(X|Y=?1))andbaserate?=P(Y=1),orvia\n",
      "themarginalM=P(X)andclass-probabilityfunction?:x7?P(Y=1|X\n",
      "=x).WeinterchangeablywriteDasDP,Q,?orDM,?.2.1\n",
      "scorers,andrisks\n",
      "Ascorerisanyfunctions:X?R.Alossisanyfunction`:\n",
      "f\n",
      "?1\n",
      "g\n",
      "?R?R.\n",
      "Weuse`?1,`1toreferto`(?1,?)and`(1,?).The`-conditionalriskL`:[0,1]\n",
      "?R?RisdenedasL`:(?,v)7???`1(v)+(1??)?`?1(v).Givena\n",
      "2\n",
      "\n",
      "distributionD,the`-riskofascorersisas.\n",
      "LD`(s)=\n",
      "[`(Y,s(X))],\n",
      "E\n",
      "(X,Y)?D\n",
      "(1)\n",
      "DsothatLD`(s)=E[L`(?(X),s(X))].ForasetS,L`(S)isthesetof\n",
      "`-risksforallscorersinS.X?M\n",
      "AfunctionclassisanyF?RX.GivensomeF,thesetofrestrictedBayes-\n",
      "optimalscorersforaloss`arethosescorersinFthatminimisethe`-risk:.\n",
      "SD,F,?=ArgminLD`(s).`s?F\n",
      "Thesetof(unrestricted)Bayes-optimalscorersisSD,?=SD,F,?forF=\n",
      "RX.Therestricted```-regretofascorerisitsexcessriskoverthatofany\n",
      "restrictedBayes-optimalscorer:.\n",
      "DregretD,F(s)=LD`(s)?infL`(t).`t?F\n",
      "Binaryisconcernedwiththezero-oneloss,`01:(y,v)7?Jyv\n",
      "<0K+21Jv=0K.Aloss`isifallitsBayes-optimal\n",
      "scorersarealsooptimalforzero-oneloss:(?D)SD,??SD,?01.Aconvex\n",
      "potentialisanyloss`:(y,v)7??(yv),where?:R?R+is`convex,non-\n",
      "increasing,tiablewith?0(0)<0,and?(+?)=0[LongandServedio,\n",
      "2010,1].Allconvexpotentialsare[Bartlett\n",
      "etal.,2006,Theorem2.1].2.2\n",
      "Learningwithsymmetriclabelnoise(SLNlearning)\n",
      "Theproblemoflearningwithsymmetriclabelnoise(SLNlearning)isthe\n",
      "following[AngluinandLaird,1988,Kearns,1998,BlumandMitchell,1998,\n",
      "Natarajanetal.,2013].Forsomenotional?clean?distributionD,whichwe\n",
      "wouldliketoobserve,weinsteadobservesamplesfromsomecorrupteddis-\n",
      "tributionSLN(D,?),forsome??[0,1/2).ThedistributionSLN(D,?)is\n",
      "suchthatthemarginaldistributionofinstancesisunchanged,buteachlabel\n",
      "isindependentlyedwithprobability?.Thegoalistolearnascorerfrom\n",
      "thesecorruptedsamplessuchthatLD01(s)issmall.ForanyquantityinD,\n",
      "wedenoteitscorruptedcounterpartsinSLN(D,?)withabar,e.g.Mforthe\n",
      "corruptedmarginaldistribution,and?forthecorruptedclass-probabilityfunc-\n",
      "tion;additionally,when?isclearfromcontext,wewilloccasionallyreferto\n",
      "SLN(D,?)byD.ItiseasytocheckthatthecorruptedmarginaldistributionM\n",
      "=M,and[Natarajanetal.,2013,Lemma7](?x?X)?(x)=(1?2?)??(x)\n",
      "+?.\n",
      "3\n",
      "(2)\n",
      "SLN-robustness:formalisation\n",
      "Weconsiderlearners(`,F)foraloss`andafunctionclassF,withlearning\n",
      "beingthesearchforsomes?Fthatminimisesthe`-risk.Informally,(`,F)is\n",
      "?robust?tosymmetriclabelnoise(SLNrobust)ifminimising`overFgivesthe\n",
      "sameconboththecleandistributionD,which2\n",
      "thelearnerwouldliketoobserve,andSLN(D,?)forany??[0,1/2),which\n",
      "thelearneractuallyobserves.Wenowformalisethisnotion,andreviewwhat\n",
      "3\n",
      "\n",
      "isknownaboutSLN-robustlearners.3.1\n",
      "SLN-robustlearners:aformal\n",
      "ForsomeinstancespaceX,let?denotethesetofdistributionsonX\n",
      "?\n",
      "f\n",
      "?1\n",
      "g\n",
      ".Givenanotional?clean?distributionD,Nsln:??2?returnstheset\n",
      "ofpossiblecorruptedversionsofDthelearnermayobserve,wherelabelsare\n",
      "edwithunknownprobability?:\n",
      "1Nsln:D7?SLN(D,?)|??0,.2Equippedwiththis,we\n",
      "ournotionofSLN-robustness.ition1(SLN-robustness).Wesaythata\n",
      "learner(`,F)isSLN-robustifD,F,?D,F,?(?D??)(?D?Nsln(D))LD)=\n",
      "LD).01(S`01(S`\n",
      "(3)\n",
      "Thatis,SLN-robustnessrequiresthatforanyleveloflabelnoiseinthe\n",
      "observeddistributionD,theperformance(wrtD)ofthelearneris\n",
      "thesameasifthelearnerdirectlyobservesD.Unfortunately,awidelyadopted\n",
      "classoflearnersisnotSLN-robust,aswewillnowsee.3.2\n",
      "ConvexpotentialswithlinearfunctionclassesarenotSLN-robust\n",
      "FixX=Rd,andconsiderlearnerswithaconvexpotential`,andafunction\n",
      "classoflinearscorersFlin=\n",
      "f\n",
      "x7?hw,xi|w?Rd\n",
      "g\n",
      ".Thiscapturese.g.\n",
      "thelinearSVMandlogisticregression,whicharewidelystudiedintheoryand\n",
      "appliedinpractice.Disappointingly,theselearnersarenotSLN-robust:Long\n",
      "andServedio[2010,Theorem2]giveanexamplewhere,whenlearningunder\n",
      "symmetriclabelnoise,foranyconvexpotential`,thecorrupted`-riskminimiser\n",
      "overFlinhasperformanceequivalenttorandomguessingonD.\n",
      "Thisimpliesthat(`,Flin)isnotSLN-robust1asper1.Proposition\n",
      "1(LongandServedio[2010,Theorem2]).LetX=Rdforanyd?2.Pickany\n",
      "convexpotential`.Then,(`,Flin)isnotSLN-robust.3.3\n",
      "Thefallout:whatlearnersareSLN-robust?\n",
      "InlightofProposition1,therearetwowaystoproceedinordertoobtain\n",
      "SLN-robustlearners:eitherwechangetheclassoflosses`,orwechangethe\n",
      "functionclassF.Theapproachhasbeenpursuedinalargebodyofwork\n",
      "thatembracesnon-convexlosses[StempfelandRalaivola,2009,Masnadi-Shirazi\n",
      "etal.,2010,DingandVishwanathan,2010,Denchevetal.,2012,Manwaniand\n",
      "Sastry,2013].WhilesuchlossesavoidtheconditionsofProposition1,thisdoes\n",
      "notautomaticallyimplythattheyareSLN-robustwhenusedwithFlin.In\n",
      "AppendixB,wepresentevidencethatsomeoftheselossesareinfactnotSLN-\n",
      "robustwhenusedwithFlin.Thesecondapproachistoconsidersuitablyrich\n",
      "FthatcontainstheBayes-optimalscorerforD,e.g.byemployingauniversal\n",
      "kernel.Withthischoice,onecanstilluseaconvexpotentialloss,andinfact,\n",
      "owingtoEquation2,anyloss.Proposition2.Pick\n",
      "any`.Then,(`,RX)isSLN-robust.Bothapproaches\n",
      "havedrawbacks.Theapproachhasacomputationalpenalty,asitrequires\n",
      "optimisinganon-convexloss.Thesecondapproachhasastatisticalpenalty,as\n",
      "estimationrateswitharichFwillrequirealargersamplesize.Thus,itappears\n",
      "thatSLN-robustnessinvolvesacomputational-statisticalHowever,\n",
      "thereisavariantoftheoption:pickalossthatisconvex,butnota\n",
      "convexpotential.Suchalosswouldordthecomputationalandstatistical\n",
      "4\n",
      "\n",
      "advantagesofminimisingconvexriskswithlinearscorers.ManwaniandSastry\n",
      "[2013]demonstratedthatsquareloss,`(y,v)=(1?yv)2,isonesuchloss.We\n",
      "willshowthatthereisasimplerlossthatisconvexandSLN-robust,butisnot\n",
      "intheclassofconvexpotentialsbyvirtueofbeingnegativelyunbounded.To\n",
      "derivethisloss,were-interpretrobustnessviaanoise-correctionprocedure.\n",
      "1Evenifwewerecontentwithaof?[0,1/2]betweentheclean\n",
      "andcorruptedminimisers?performance,LongandServedio[2010,Theorem2]\n",
      "impliesthatintheworstcase=1/2.\n",
      "3\n",
      "4\n",
      "Anoise-correctedlossperspectiveonSLN-robustness\n",
      "Wenowre-expressSLN-robustnesstoreasonaboutoptimalscorersonthe\n",
      "samedistribution,butwithtwotlosses.Thiswillhelpcharacterisea\n",
      "setof?stronglySLN-robust?losses.4.1\n",
      "ReformulatingSLN-robustnessvianoise-correctedlosses\n",
      "Givenany??[0,1/2),Natarajanetal.[2013,Lemma1]showedhowto\n",
      "associatewithaloss`aDnoise-correctedcounterpart`suchthatLD`(s)=L`\n",
      "(s).Theloss`isasfollows.2(Noise-correctedloss).Given\n",
      "anyloss`and??[0,1/2),thenoise-correctedloss`is(?y?\n",
      "f\n",
      "?1\n",
      "g\n",
      ")(?v?R)`(y,\n",
      "v)=\n",
      "(1??)?`(y,v)???`(?y,v).1?2?\n",
      "(4)\n",
      "Since`dependsontheunknownparameter?,itisnotdirectlyusableto\n",
      "designanSLN-robustlearner.Nonetheless,itisausefultheoreticaldevice,\n",
      "since,byconstruction,foranyF,SD,F,?=`SD,F,?=SD,F,?.Thismeans\n",
      "thatatconditionfor(`,F)tobeSLN-robustisforSD,F,?.```Ghosh\n",
      "etal.[2015,Theorem1]provedatconditionon`suchthatthisholds,\n",
      "namely,(?C?R)(?v?R)`1(v)+`?1(v)=C.(5)Interestingly,Equation5is\n",
      "necessaryforastrongernotionofrobustness,whichwenowexplore.4.2\n",
      "CharacterisingastrongernotionofSLN-robustness\n",
      "Asthesteptowardsastrongernotionofrobustness,werewrite(witha\n",
      "slightabuseofnotation)LD`(s)=\n",
      "E\n",
      "(X,Y)?D\n",
      "[`(Y,s(X))]=\n",
      "E\n",
      "(Y,S)?R(D,s)\n",
      ".\n",
      "[`(Y,S)]=L`(R(D,s)),\n",
      "whereR(D,s)isadistributionoverlabelsandscores.StandardSLN-\n",
      "robustnessrequiresthatlabelnoisedoesnotchangethe`-riskminimisers,i.e.\n",
      "thatifsissuchthatL`(R(D,s))?L`(R(D,s0))foralls0,thesamerelation\n",
      "holdswithDinplaceofD.StrongSLN-robustnessstrengthensthisnotionby\n",
      "requiringthatlabelnoisedoesnottheorderingofallpairsofjointdistri-\n",
      "butionsoverlabelsandscores.(ThisofcoursetriviallyimpliesSLN-robustness.)\n",
      "AswiththeofD,givenadistributionRoverlabelsandscores,let\n",
      "5\n",
      "\n",
      "Rbethecorrespondingdistributionwherelabelsareedwithprobability\n",
      "?.StrongSLN-robustnesscanthenbemadepreciseasfollows.3\n",
      "(StrongSLN-robustness).Callaloss`stronglySLN-robustifforevery??[0,\n",
      "1/2),(?R,R0)L`(R)?L`(R0)??L`(R)?L`(R0).Wenowre-expressstrong\n",
      "SLN-robustnessusinganotionoforderequivalenceoflosspairs,whichsimply\n",
      "requiresthattwolossesorderalldistributionsoverlabelsandscoresidentically.\n",
      "?orderequivalentif4(Orderequivalentlosspairs).Callapairof\n",
      "losses(`,`)(?R,R0)L`(R)?L`(R0)??L`?(R)?L`?(R0).Clearly,order\n",
      "equivalenceof(`,`)impliesSD,F,?=SD,F,?,whichinturnimpliesSLN-\n",
      "robustness.``Itisthusnotsurprisingthatwecanrelateorderequivalenceto\n",
      "strongSLN-robustnessof`.Proposition3.Aloss`isstronglySLN-robust\n",
      "forevery??[0,1/2),(`,`)areorderequivalent.Thisconnectionnowletsus\n",
      "exploitaclassicalresultindecisiontheoryaboutorderequivalentlossesbeing\n",
      "transformationsofeachother.Combinedwiththeof`,this\n",
      "letsusconcludethatthetconditionofEquation5isalsonecessaryfor\n",
      "strongSLN-robustnessof`.Proposition4.Aloss`isstronglySLN-robustifand\n",
      "onlyifitEquation5.Wenowreturntoouroriginalgoal,whichwasto\n",
      "aconvex`thatisSLN-robustforFlin(andideallymoregeneralfunction\n",
      "classes).Theabovesuggeststhattodoso,itisreasonabletoconsiderthose\n",
      "lossesthatsatisfyEquation5.Unfortunately,itisevidentthatif`isconvex,\n",
      "non-constant,andboundedbelowbyzero,thenitcannotpossiblybeadmissi-\n",
      "bleinthissense.Butwenowshowthatremovingtheboundednessrestriction\n",
      "allowsfortheexistenceofaconvexadmissibleloss.4\n",
      "5\n",
      "Theunhingedloss:aconvex,stronglySLN-robustloss\n",
      "Considerthefollowingsimple,butnon-standardconvexloss:unh`unh1(v)\n",
      "=1?vand`?1(v)=1+v.\n",
      "Comparedtothehingeloss,thelossdoesnotclampatzero,i.e.itdoes\n",
      "nothaveahinge.(Thus,peculiarly,itisnegativelyunbounded,anissuewe\n",
      "discussin?5.3.)Thus,wecallthistheunhingedloss2.Thelosshasanumber\n",
      "ofattractiveproperties,themostimmediatebeingisitsSLN-robustness.5.1\n",
      "TheunhingedlossisstronglySLN-robust\n",
      "unhunhSince`unhisstronglySLN-robust,andthusthat1(v)+`?1(v)\n",
      "=2,Proposition4impliesthat`unh(`,F)isSLN-robustforanyF.Further,\n",
      "thefollowinguniquenesspropertyisnothardtoshow.Proposition5.Pickany\n",
      "convexloss`.Then,\n",
      "(?C?R)`1(v)+`?1(v)=C??(?A,B,D?R)`1(v)=?A?v+B,`?1(v)\n",
      "=A?v+D.Thatis,uptoscalingandtranslation,`unhistheonlyconvexloss\n",
      "thatisstronglySLN-robust.Returningtothecaseoflinearscorers,theabove\n",
      "impliesthat(`unh,Flin)isSLN-robust.ThisdoesnotcontradictProposition\n",
      "1,since`unhisnotaconvexpotentialasitisnegativelyunbounded.Intuitively,\n",
      "thispropertyallowsthelosstothepenaltyincurredbyinstancesthatare\n",
      "withhighmarginbyawardinga?gain?forinstancesthatcorrectly\n",
      "withhighmargin.5.2\n",
      "Theunhingedlossiscalibrated\n",
      "SLN-robustnessisbyitselftforalearnertobeuseful.Forex-\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ample,alossthatisuniformlyzeroisstronglySLN-robust,butisuselessasit\n",
      "isnotFortunately,theunhingedlossisclassi\n",
      "calibrated,aswenowestablish.Fortechnicalreasons(see?5.3),weoperate\n",
      "withFB=[?B,+B]X,thesetofscorerswithrangeboundedbyB?[0,?).\n",
      "Proposition6.Fix`=`unh.ForanyDM,?,B?[0,?),S`D,FB,?=\n",
      "f\n",
      "x7?\n",
      "B?sign(2?(x)?1)\n",
      "g\n",
      ".Thus,foreveryB?[0,?),therestrictedBayes-optimal\n",
      "scoreroverFBhasthesamesignastheBayes-optimalfor0-1loss.In\n",
      "thelimitingcasewhereF=RX,theoptimalscorerisattainableifweoperate\n",
      "overtheextendedrealsR?\n",
      "f\n",
      "??\n",
      "g\n",
      ",sothat`unhis5.3\n",
      "Enforcingboundednessoftheloss\n",
      "Whiletheof`unhisencouraging,Proposition6\n",
      "impliesthatits(unrestricted)Bayes-riskis??.Thus,theregretofeverynon-\n",
      "optimalscorersisidentically+?,whichhampersanalysisofconsistency.In\n",
      "orthodoxdecisiontheory,analogoustheoreticalissuesarisewhenattemptingto\n",
      "establishbasictheoremswithunboundedlosses[Ferguson,1967,pg.78].We\n",
      "canside-stepthisissuebyrestrictingattentiontoboundedscorers,sothat`unh\n",
      "iselybounded.ByProposition6,thisdoesnotthec\n",
      "calibrationoftheloss.Inthecontextoflinearscorers,boundednessofscorers\n",
      "canbeachievedbyregularisation:insteadofwork?ingwithFlin,onecan\n",
      "insteaduseFlin,?=\n",
      "f\n",
      "x7?hw,xi|||w||2?1/?\n",
      "g\n",
      ",where?>0,so\n",
      "thatFlin,??FR/??forR=supx?X||x||2.Observethatas(`unh,F)\n",
      "isSLN-robustforanyF,(`unh,Flin,?)isSLN-robustforany?>0.Aswe\n",
      "shallseein?6.3,workingwithFlin,?alsoletsusestablishSLN-robustnessof\n",
      "thehingelosswhen?islarge.5.4\n",
      "Unhingedlossminimisationoncorrupteddistributionisconsistent\n",
      "Usingboundedscorersmakesitpossibletoestablishasurrogateregretbound\n",
      "fortheunhingedloss.Thisshowsconsistencyofunhingedloss\n",
      "minimisationonthecorrupteddistribution.2Thislosshasbeenconsidered\n",
      "inSriperumbuduretal.[2009],ReidandWilliamson[2011]inthecontext\n",
      "ofmaximummeandiscrepancy;seetheAppendix.TheanalysisofitsSLN-\n",
      "robustnessistoourknowledgenovel.\n",
      "5\n",
      "Proposition7.Fix`=`unh.Then,foranyD,??[0,1/2),B?[1,?),and\n",
      "scorers?FB,1D,FBregretD(s)=?regret`D,FB(s).01(s)?regret`1?\n",
      "2?Standardratesofconvergenceviageneralisationboundsarealsotrivialto\n",
      "derive;seetheAppendix.\n",
      "6\n",
      "Learningwiththeunhingedlossandkernels\n",
      "Wenowshowthattheoptimalsolutionfortheunhingedlosswhenemploying\n",
      "regularisationandkernelisedscorershasasimpleform.Thisshedsfurtherlight\n",
      "onSLN-robustnessandregularisation.6.1\n",
      "Thecentroidoptimisestheunhingedloss\n",
      "Considerminimisingtheunhingedriskovertheclassofkernelisedscorers\n",
      "FH,?=\n",
      "f\n",
      "s:x7??hw,?(x)iH|||w||H?1/?\n",
      "g\n",
      "forsome?>0,where\n",
      "?:X?HisafeaturemappingintoareproducingkernelHilbertspaceHwith\n",
      "kernelk.Equivalently,givenadistribution3D,wewant??wunh,?=argmin\n",
      "7\n",
      "\n",
      "E[1?Y?hw,?(X)i]+hw,wiH.(6)2(X,Y)?Dw?HTheoptimality\n",
      "conditionimpliesthat1?(7)wunh,?=?E[Y??(X)],?(X,Y)?Dwhichis\n",
      "thekernelmeanmapofD[Smolaetal.,2007],andthustheoptimalunhinged\n",
      "scoreris\n",
      "11s?unh,?:x7??E[Y?k(X,x)]=x7????E[k(X,x)]?(1?\n",
      "?)?E[k(X,x)].X?PX?Q?(X,Y)?D?(8)FromEquation8,theunhinged\n",
      "solutionisequivalenttoanearestcentroid[Manningetal.,2008,pg.\n",
      "181][Tibshiranietal.,2002][Shawe-TaylorandCristianini,2004,Section5.1].\n",
      "Equation8givesasimplewaytounderstandtheSLN-robustnessof(`unh,FH,?\n",
      "),astheoptimalscorersonthecleanandcorrupteddistributionsonlyby\n",
      "ascaling(seetheAppendix):\n",
      "1?EY?k(X,x).(9)(?x?X)E[Y?k(X,x)]=1?2?(X,Y)?D\n",
      "(X,Y)?DInterestingly,Servedio[1999,Theorem4]establishedthatanearest\n",
      "centroid(whichtheytermed?AVERAGE?)isrobusttoageneral\n",
      "classoflabelnoise,butrequiredtheassumptionthatMisuniformoverthe\n",
      "unitsphere.OurresultestablishesthatSLNrobustnessoftheholds\n",
      "withoutanyassumptionsonM.Infact,Ghoshetal.[2015,Theorem1]lets\n",
      "onequantifytheunhingedloss?performanceunderamoregeneralnoisemodel;\n",
      "seetheAppendixfordiscussion.6.2\n",
      "Practicalconsiderations\n",
      "Wenoteseveralpointsrelatingtopracticalusageoftheunhingedlosswith\n",
      "kernelisedscorers.First,cross-validationisnotrequiredtoselect?,sincechang-\n",
      "ing?onlychangesthemagnitudeofscores,nottheirsign.Thus,forthe\n",
      "purposesofonecansimplyuse?=1.Second,wecaneasily\n",
      "extendthescorerstouseabiasregularisedwithstrength0<?b6=?.Tun-\n",
      "ing?bisequivalenttocomputings?unh,?asperEquation8,andtuninga\n",
      "thresholdonaholdoutset.?Third,whenH=Rdfordsmall,wecanstore\n",
      "wunh,?explicitly,andusethistomakepredictions.Forhigh(ordi-\n",
      "mensionalH,wecaneithermakepredictionsdirectlyviaEquation8,oruse\n",
      "randomFourierfeatures[RahimiandRecht,2007]to(approximately)embed\n",
      "Hintosomelow?dimensionalRd,andthenstorewunh,?asusual.(The\n",
      "latterrequiresatranslation-invariantkernel.)?Wenowshowthatundersome\n",
      "assumptions,wunh,?coincideswiththesolutionoftwoestablishedmethods;\n",
      "theAppendixdiscussessomefurtherrelationships,e.g.tothemaximummean\n",
      "discrepancy.3\n",
      "GivenatrainingsampleS?Dn,wecanusepluginestimatesasappropriate.\n",
      "6\n",
      "6.3\n",
      "EquivalencetoahighlyregularisedSVMandotherconvexpotentials\n",
      "Thereisaninterestingequivalencebetweentheunhingedsolutionandthat\n",
      "ofahighlyregularisedSVM.Thishasbeennotedine.g.Hastieetal.[2004,\n",
      "Section6],whichshowedhowSVMsapproachanearestcentroidwhich\n",
      "isofcoursetheoptimalunhingedsolution.Proposition8.PickanyDand?:\n",
      "X?HwithR=supx?X||?(x)||H<?.Forany?>0,let?whinge,?=\n",
      "argminw?H\n",
      "E\n",
      "8\n",
      "\n",
      "(X,Y)?D\n",
      "[max(0,1?Y?hw,?(x)iH)]+\n",
      "?hw,wiH2\n",
      "??bethesoft-marginSVMsolution.Then,if??R2,whinge,?=wunh,?\n",
      ".\n",
      "Since(`unh,FH,?)isSLN-robust,itfollowsthatfor`hinge:(y,v)7?\n",
      "max(0,1?yv),(`hinge,FH,?)issimilarlySLN-robustprovided?isntly\n",
      "large.Thatis,strong`2regularisation(andaboundedfeaturemap)endows\n",
      "thehingelosswithSLN-robustness4.Proposition8canbegeneralised?to\n",
      "showthatwunh,?isthelimitingsolutionofanytwicedrentiableconvex\n",
      "potential.Thisshowsthatstrong`2regularisationendowsmostlearnerswith\n",
      "SLN-robustness.Intuitively,withstrongregularisation,oneonlyconsidersthe\n",
      "behaviourofalossnearzero;sinceaconvexpotential?has?0(0)<0,itwill\n",
      "behavesimilarlytoitslinearapproximationaroundzero,viz.theunhinged\n",
      "loss.Proposition9.PickanyD,boundedfeaturemapping?:X?H,andtwice\n",
      "tiableconvex?potential?with?00([?1,1])bounded.Letw?,?bethe\n",
      "minimiseroftheregularised?risk.Then,\n",
      "2?w?\n",
      "wunh,?\n",
      "?,?lim??=0.????||w?,?||H||wunh,?||HH\n",
      "6.4\n",
      "EquivalencetoFisherLinearDiscriminantwithwhiteneddata\n",
      "ForbinaryonDM,?,theFisherLinearDiscriminant(FLD)\n",
      "aweightvectorproportionaltotheminimiserofsquareloss`sq:(y,v)7?\n",
      "(1?yv)2[Bishop,2006,Section4.1.5],?wsq,?=(EX?M[XXT]+?I)?1?\n",
      "E(X,Y)?D[Y?X].\n",
      "(10)\n",
      "?wsq,?\n",
      "isonlychangedbyascalingByEquation9,andthefactthatthecorrupted\n",
      "marginalM=M,factorunderlabelnoise.Thisprovidesanalternateproofof\n",
      "thefactthat(`sq,Flin)isSLN-robust5?[ManwaniandSastry,2013,Theorem\n",
      "2].Clearly,theunhingedlosssolutionwunh,?isequivalenttoT?theFLDand\n",
      "squarelosssolutionwsq,?whentheinputdataiswhitenedi.e.EXX=I.With\n",
      "X?M\n",
      "awell-spF,e.g.withauniversalkernel,boththeunhingedandsquare\n",
      "lossasymptoticallyrecovertheoptimalclaser,buttheunhingedlossdoes\n",
      "notrequireamatrixinversion.WithamisspF,onecannotingeneral\n",
      "argueforthesuperiorityoftheunhingedlossoversquareloss,orvice-versa,\n",
      "asthereisnouniversallygoodsurrogatetothe0-1loss[ReidandWilliamson,\n",
      "2010,AppendixA];theAppendixillustrateexampleswherebothlossesmay\n",
      "underperform.\n",
      "7\n",
      "SLN-robustnessofunhingedloss:empiricalillustration\n",
      "Wenowillustratethattheunhingedloss?SLN-robustnessisempirically\n",
      "manifest.Wereiteratethatwithhighregularisation,theunhingedsolution\n",
      "isequivalenttoanSVM(andinthelimitanyloss)\n",
      "9\n",
      "\n",
      "solution.Thus,wedonotaimtoassertthattheunhingedlossis?better?than\n",
      "otherlosses,butrather,todemonstratethatitsSLN-robustnessisnotpurely\n",
      "theoretical.Weshowthattheunhingedriskminimiserperformswellon\n",
      "theexampleofLongandServedio[2010](henceforthLS10).Figure1shows\n",
      "thedistributionD,whereX=\n",
      "f\n",
      "(1,0),(?,5?),(?,??)\n",
      "g\n",
      "?R2,withmarginal\n",
      "distributionM=\n",
      "f\n",
      "14,14,12\n",
      "g\n",
      "andallthreeinstancesaredeterministically\n",
      "positive.Wepick?=1/2.Theunhingedminimiserperfectlyallthree\n",
      "points,regardlessoftheleveloflabelnoise(Figure1).Thehingeminimiseris\n",
      "perfectwhenthereisnonoise,butwithevenasmallamountofnoise,achieves\n",
      "a50%errorrate.45\n",
      "LongandServedio[2010,Section6]showthat`1regularisationdoesnot\n",
      "endowSLN-robustness.SquarelossescapestheresultofLongandServedio\n",
      "[2010]sinceitisnotmonotonedecreasing.\n",
      "7\n",
      "1\n",
      "UnhingedHinge0%noiseHinge1%noise\n",
      "0.5\n",
      "0.5\n",
      "??????\n",
      "1\n",
      "?0.5\n",
      "======\n",
      "00.10.20.30.40.49\n",
      "Hinge\n",
      "t-logistic\n",
      "Unhinged\n",
      "0.00?0.000.15?0.270.21?0.300.38?0.370.42?0.360.47?0.38\n",
      "0.00?0.000.00?0.000.00?0.000.22?0.080.22?0.080.39?0.23\n",
      "0.00?0.000.00?0.000.00?0.000.00?0.000.00?0.000.34?0.48\n",
      "Table1:Meanandstandarddeviationofthe01errorover125trialson\n",
      "LS10.Grayedcellsdenotethebestperformeratthatnoiserate.\n",
      "?1\n",
      "Figure1:LS10dataset.\n",
      "Wenextconsiderempiricalriskminimisersfromarandomtrainingsample:\n",
      "weconstructatrainingsetof800instances,injectedwithvaryinglevelsoflabel\n",
      "noise,andevaluateperformanceonatestsetof1000instances.\n",
      "Wecomparethehinge,t-logistic(fort=2)[DingandVishwanathan,2010]and\n",
      "unhingedminimisersusingalinearscorerwithoutabiasterm,andregularisation\n",
      "strength?=10?16.FromTable1,evenat40%labelnoise,theunhinged\n",
      "isabletoaperfectsolution.Bycontrast,bothotherlosses\n",
      "atevenmoderatenoiserates.WenextreportresultsonsomeUCIdatasets,\n",
      "whereweadditionallytuneathresholdsoastoensurethebesttrainingset\n",
      "0-1accuracy.Table2summarisesresultsonasampleoffourdatasets.(The\n",
      "Appendixcontainsresultswithmoredatasets,performancemetrics,andlosses.)\n",
      "Evenatnoisecloseto50%,theunhingedlossisoftenabletolearnac\n",
      "withsomediscriminativepower.\n",
      "10\n",
      "\n",
      "??????\n",
      "======\n",
      "00.10.20.30.40.49\n",
      "Hinge\n",
      "t-Logistic\n",
      "Unhinged\n",
      "0.00?0.000.01?0.030.06?0.120.17?0.200.35?0.240.60?0.20\n",
      "0.00?0.000.01?0.030.04?0.050.09?0.110.24?0.160.49?0.20\n",
      "0.00?0.000.00?0.000.00?0.010.02?0.070.13?0.220.45?0.33\n",
      "??????\n",
      "======\n",
      "00.10.20.30.40.49\n",
      "Hinge\n",
      "t-Logistic\n",
      "Unhinged\n",
      "0.05?0.000.06?0.010.06?0.010.08?0.040.14?0.100.45?0.26\n",
      "0.05?0.000.07?0.020.08?0.030.11?0.050.24?0.130.49?0.16\n",
      "0.05?0.000.05?0.000.05?0.000.05?0.010.09?0.100.46?0.30\n",
      "(a)iris.\n",
      "??????\n",
      "======\n",
      "00.10.20.30.40.49\n",
      "(b)housing.\n",
      "Hinge\n",
      "t-Logistic\n",
      "Unhinged\n",
      "0.00?0.000.10?0.080.19?0.110.31?0.130.39?0.130.50?0.16\n",
      "0.00?0.000.11?0.020.15?0.020.22?0.030.33?0.040.48?0.04\n",
      "0.00?0.000.00?0.000.00?0.000.01?0.000.02?0.020.34?0.21\n",
      "??????\n",
      "(c)usps0v7.\n",
      "======\n",
      "00.10.20.30.40.49\n",
      "Hinge\n",
      "t-Logistic\n",
      "Unhinged\n",
      "0.05?0.000.15?0.030.21?0.030.25?0.030.31?0.050.48?0.09\n",
      "0.04?0.000.24?0.000.24?0.000.24?0.000.24?0.000.40?0.24\n",
      "0.19?0.000.19?0.010.19?0.010.19?0.030.22?0.050.45?0.08\n",
      "(d)splice.\n",
      "Table2:Meanandstandarddeviationofthe0-1errorover125trialson\n",
      "UCIdatasets.\n",
      "8\n",
      "Conclusionandfuturework\n",
      "Weproposedaconvex,catedloss,provedthatisrobustto\n",
      "symmetriclabelnoise(SLN-robust),showeditistheuniquelossthata\n",
      "11\n",
      "\n",
      "notionofstrongSLN-robustness,establishedthatitisoptimisedbythenearest\n",
      "centroidandshowedthatmostconvexpotentials,suchastheSVM,\n",
      "arealsoSLN-robustwhenhighlyregularised.So,withapologiestoWilde[1895]:\n",
      "Whilethetruthisrarelypure,itcanbesimple.AcknowledgmentsNICTAis\n",
      "fundedbytheAustralianGovernmentthroughtheDepartmentofCommunica-\n",
      "tionsandtheAustralianResearchCouncilthroughtheICTCentreofExcellence\n",
      "Program.TheauthorsthankChengSoonOngforvaluablecommentsonadraft\n",
      "ofthispaper.8\n",
      "2References\n",
      "DanaAngluinandPhilipLaird.Learningfromnoisyexamples.MachineLearn-\n",
      "ing,2(4):343?370,1988.PeterL.Bartlett,MichaelI.Jordan,andJonD.\n",
      "Convexity,andriskbounds.JournaloftheAmeri-\n",
      "canStatisticalAssociation,101(473):138?156,2006.ChristopherMBishop.\n",
      "PatternRecognitionandMachineLearning.Springer-VerlagNewYork,Inc.,\n",
      "2006.AvrimBlumandTomMitchell.Combininglabeledandunlabeleddata\n",
      "withco-training.InConferenceonComputationalLearningTheory(COLT),\n",
      "pages92?100,1998.VasilDenchev,NanDing,HartmutNeven,andS.V.N.\n",
      "Vishwanathan.Robustwithadiabaticquantumoptimization.In\n",
      "InternationalConferenceonMachineLearning(ICML),pages863?870,2012.\n",
      "LucDevroye,L?aszl?o,andG?aborLugosi.AProbabilisticTheory\n",
      "ofPatternRecognition.Springer,1996.NanDingandS.V.N.Vishwanathan.\n",
      "t-logisticregression.InAdvancesinNeuralInformationProcessingSystems\n",
      "(NIPS),pages514?522.CurranAssociates,Inc.,2010.ThomasS.Ferguson.\n",
      "MathematicalStatistics:ADecisionTheoreticApproach.AcademicPress,\n",
      "1967.AritraGhosh,NareshManwani,andP.S.Sastry.Makingriskmini-\n",
      "mizationtoleranttolabelnoise.Neurocomputing,160:93?107,2015.Trevor\n",
      "Hastie,SaharonRosset,RobertTibshirani,andJiZhu.Theentireregular-\n",
      "izationpathforthesupportvectormachine.JournalofMachineLearning\n",
      "Research,5:1391?1415,December2004.ISSN1532-4435.MichaelKearns.Ef-\n",
      "tnoise-tolerantlearningfromstatisticalqueries.JournaloftheACM,\n",
      "5(6):392?401,November1998.PhilipM.LongandRoccoA.Servedio.Ran-\n",
      "domnoisedefeatsallconvexpotentialboosters.MachineLearn-\n",
      "ing,78(3):287?304,2010.ISSN0885-6125.ChristopherD.Manning,Prab-\n",
      "hakarRaghavan,andHinrichSch?utze.IntroductiontoInformationRetrieval.\n",
      "CambridgeUniversityPress,NewYork,NY,USA,2008.ISBN0521865719,\n",
      "9780521865715.NareshManwaniandP.S.Sastry.Noisetoleranceunderrisk\n",
      "minimization.IEEETransactionsonCybernetics,43(3):1146?1151,June2013.\n",
      "HamedMasnadi-Shirazi,VijayMahadevan,andNunoVasconcelos.Onthe\n",
      "designofrobustforcomputervision.InIEEEConferenceonCom-\n",
      "puterVisionandPatternRecognition(CVPR),2010.NagarajanNatarajan,\n",
      "InderjitS.Dhillon,PradeepD.Ravikumar,andAmbujTewari.Learningwith\n",
      "noisylabels.InAdvancesinNeuralInformationProcessingSystems(NIPS),\n",
      "pages1196?1204,2013.AliRahimiandBenjaminRecht.Randomfeaturesfor\n",
      "12\n",
      "\n",
      "large-scalekernelmachines.InAdvancesinNeuralInformationProcessingSys-\n",
      "tems(NIPS),pages1177?1184,2007.MarkD.ReidandRobertC.Williamson.\n",
      "Compositebinarylosses.JournalofMachineLearningResearch,11:2387?2422,\n",
      "December2010.MarkDReidandRobertCWilliamson.Information,diver-\n",
      "genceandriskforbinaryexperiments.JournalofMachineLearningResearch,\n",
      "12:731?817,Mar2011.BernhardSch?olkopfandAlexanderJSmola.Learn-\n",
      "ingwithkernels,volume129.MITPress,2002.RoccoA.Servedio.OnPAC\n",
      "learningusingWinnow,Perceptron,andaPerceptron-likealgorithm.InCon-\n",
      "ferenceonComputationalLearningTheory(COLT),1999.JohnShawe-Taylor\n",
      "andNelloCristianini.KernelMethodsforPatternAnalysis.CambridgeUni.\n",
      "Press,2004.AlexSmola,ArthurGretton,LeSong,andBernhardSch?olkopf.\n",
      "AHilbertspaceembeddingfordistributions.InAlgorithmicLearningTheory\n",
      "(ALT),2007.BharathK.Sriperumbudur,KenjiFukumizu,ArthurGretton,\n",
      "GertR.G.Lanckriet,andBernhardSch?olkopf.Kernelchoiceand\n",
      "ityforRKHSembeddingsofprobabilitydistributions.InAdvancesinNeural\n",
      "InformationProcessingSystems(NIPS),2009.GuillaumeStempfelandLiva\n",
      "Ralaivola.LearningSVMsfromsloppilylabeleddata.InNeuralNet-\n",
      "works(ICANN),volume5768,pages884?893.SpringerBerlinHeidelberg,2009.\n",
      "RobertTibshirani,TrevorHastie,BalasubramanianNarasimhan,andGilbert\n",
      "Chu.Diagnosisofmultiplecancertypesbyshrunkencentroidsofgeneexpres-\n",
      "sion.ProceedingsoftheNationalAcademyofSciences,99(10):6567?6572,\n",
      "2002.OscarWilde.TheImportanceofBeingEarnest,1895.\n",
      "9\n",
      "13\n",
      "\n",
      "PP5772.pdf\n",
      "PP5772.pdf 15\n",
      "LearningStationaryTimeSeriesusingGaussian\n",
      "ProcesseswithNonparametricKernels\n",
      "Authoredby:\n",
      "ThangD.Bui\n",
      "RichardE.Turner\n",
      "FelipeTobar\n",
      "Abstract\n",
      "WeintroducetheGaussianProcessConvolutionModel(GPCM),a\n",
      "two-stagenonparametricgenerativeproceduretomodelstationarysig-\n",
      "nalsastheconvolutionbetweenacontinuous-timewhite-noiseprocess\n",
      "andacontinuous-timelineardrawnfromGaussianprocess.The\n",
      "GPCMisacontinuous-timenonparametric-windowmovingaveragepro-\n",
      "cessand,conditionally,isitselfaGaussianprocesswithanonparametric\n",
      "kernelinaprobabilisticfashion.Thegenerativemodelcanbe\n",
      "equivalentlyconsideredinthefrequencydomain,wherethepowerspec-\n",
      "traldensityofthesignalisspusingaGaussianprocess.Oneof\n",
      "themaincontributionsofthepaperistodevelopanovelvariationalfree-\n",
      "energyapproachbasedoninter-domaininducingvariablesthattly\n",
      "learnsthecontinuous-timelinearandinfersthedrivingwhite-noise\n",
      "process.Inturn,thisschemeprovidesclosed-formprobabilisticestimates\n",
      "ofthecovariancekernelandthenoise-freesignalbothindenoisingandpre-\n",
      "dictionscenarios.Additionally,thevariationalinferenceprocedurepro-\n",
      "videsclosed-formexpressionsfortheapproximateposteriorofthespectral\n",
      "densitygiventheobserveddata,leadingtonewBayesiannonparametric\n",
      "approachestospectrumestimation.TheproposedGPCMisvalidated\n",
      "usingsyntheticandreal-worldsignals.\n",
      "1PaperBody\n",
      "Gaussianprocess(GP)regressionmodelshavebecomeastandardtoolinBayesian\n",
      "signalestimationduetotheirexpressiveness,robustnesstoovand\n",
      "tractability[1].GPregressionbeginswithapriordistributionoverfunctions\n",
      "thatencapsulatesaprioriassumptions,suchassmoothness,stationarityorpe-\n",
      "riodicity.Theprioristhenupdatedbyincorporatinginformationfromobserved\n",
      "datapointsviatheirlikelihoodfunctions.Theresultisaposteriordistribution\n",
      "overfunctionsthatcanbeusedforprediction.Criticallyforthiswork,the\n",
      "posteriorandthereforetheresultantpredictions,issensitivetothechoiceof\n",
      "1\n",
      "\n",
      "priordistribution.Theformofthepriorcovariancefunction(orkernel)ofthe\n",
      "GPisarguablythecentralmodellingchoice.Employingasimpleformofco-\n",
      "variancewilllimittheGP?scapacitytogeneralise.Theubiquitousradialbasis\n",
      "functionorsquaredexponentialkernel,forexample,impliespredictionisjust\n",
      "alocalsmoothingoperation[2,3].Expressivekernelsareneeded[4,5],but\n",
      "althoughkerneldesigniswidelyacknowledgedaspivotal,ittypicallyproceeds\n",
      "viaa?blackart?inwhichaparticularfunctionalformishand-craftedusingin-\n",
      "tuitionsabouttheapplicationdomaintobuildakernelusingsimplerprimitive\n",
      "kernelsasbuildingblocks(e.g.[6]).Recently,somesophisticatedautomated\n",
      "approachestokerneldesignhavebeendevelopedthatconstructkernelmixtures\n",
      "onthebasisofincorporatingtmeasuresofsimilarity[7,8],ormore\n",
      "generallybybothaddingandmultiplyingkernels,thusmimickingthewayin\n",
      "whichahumanwouldsearchforthebestkernel[5].Alternatively,a\n",
      "parametrickernelcanbeusedasinthecaseofthespectralmixturekernels,\n",
      "wherethepowerspectraldensity(PSD)oftheGPisparametrisedbyamixture\n",
      "ofGaussians[4].1\n",
      "Weseetwoproblemswiththisgeneralapproach:Theisthatcomputa-\n",
      "tionaltractabilitylimitsthecomplexityofthekernelsthatcanbedesignedin\n",
      "thisway.Suchconstraintsareproblematicwhensearchingoverkernelcombi-\n",
      "nationsandtoalesserextentwhenpotentiallylargenumbersofkernel\n",
      "hyperparameters.Indeed,manynaturallyoccurringsignalscontainmorecom-\n",
      "plexstructurethancancomfortablybeentertainedusingcurrentmethods,time\n",
      "serieswithcomplexspectralikesoundsbeingacaseinpoint[9,10].Thesecond\n",
      "limitationisthathyperparametersofthekernelaretypicallybymaximisation\n",
      "ofthemodelmarginallikelihood.Forcomplexkernelswithlargenumbersof\n",
      "hyperparameters,thiscaneasilyresultinovrearingitsuglyheadonce\n",
      "more(seesec.4.2).Thispaperattemptstoremedytheexistinglimitations\n",
      "ofGPsinthetimeseriessettingusingthesamerationalebywhichGPswere\n",
      "originallydeveloped.Thatis,kernelsthemselvesaretreatednonparametrically\n",
      "toenableformswhosecomplexitycangrowasmorestructureisrevealed\n",
      "inthedata.Moreover,approximateBayesianinferenceisusedforestimation,\n",
      "thusside-steppingproblemswithmodelstructuresearchandprotectingagainst\n",
      "overThesebareachievedbymodellingtimeseriesastheout-\n",
      "putofalinearandtime-invariantsystembyaconvolutionbetweena\n",
      "white-noiseprocessandacontinuous-timelinearByconsideringthe\n",
      "tobedrawnfromaGP,theexpectedsecond-orderstatistics(and,asaconse-\n",
      "quence,thespectraldensity)oftheoutputsignalareinanonparametric\n",
      "fashion.Thenextsectionpresentstheproposedmodel,itsrelationshiptoGPs\n",
      "andhowtosamplefromit.InSection3wedevelopananalyticapproximate\n",
      "inferencemethodusingstate-of-the-artvariationalfree-energyapproximations\n",
      "forperforminginferenceandlearning.Section4showssimulationsusingboth\n",
      "syntheticandreal-worlddatasets.Finally,Section5presentsadiscussionofour\n",
      "\n",
      "2\n",
      "Regressionmodel:Convolvingalinearandawhite-noiseprocess\n",
      "WeintroducetheGaussianProcessConvolutionModel(GPCM)whichcan\n",
      "2\n",
      "\n",
      "beviewedasconstructingadistributionoverfunctionsf(t)usingatwo-stage\n",
      "generativemodel.Inthestage,acontinuousfunctionh(t):R7?\n",
      "RisdrawnfromaGPwithcovariancefunctionKh(t1,t2).Inthesecond\n",
      "stage,thefunctionf(t)isproducedbyconvolvingthewithcontinuous\n",
      "timewhitenoisex(t).Thewhite-noisecanbetreatedinformallyasadrawfrom\n",
      "aGPwithadelta-functioncovariance,1Z2h(t)?GP(0,Kh(t1,t2)),x(t)\n",
      "?GP(0,?x?(t1?t2)),f(t)=h(t??)x(?)d?.(1)R\n",
      "Thisfamilyofmodelscanbemotivatedfromseveraltperspectives\n",
      "duetotheubiquityofcontinuous-timelinearsystems.First,themodelrelates\n",
      "tolineartime-invariant(LTI)systems[12].Theprocessx(t)istheinputto\n",
      "theLTIsystem,thefunctionh(t)isthesystem?simpulseresponse(whichis\n",
      "modelledasadrawfromaGP)andf(t)isitsoutput.Inthissetting,asan\n",
      "LTIsystemisentirelycharacterisedbyitsimpulseresponse[12],modeldesign\n",
      "boilsdowntoidentifyingasuitablefunctionh(t).Asecondperspectiveviews\n",
      "themodelthroughthelensoftialequations,inwhichcaseh(t)canbe\n",
      "consideredtobetheGreen?sfunctionofasystembyalineartial\n",
      "equationthatisdrivenbywhite-noise.Inthisway,theprioroverh(t)implicitly\n",
      "aprioroverthecotsoflineartialequationsofpotentially\n",
      "order[13].Third,theGPCMcanbethoughtofasacontinuous-time\n",
      "generalisationofthediscrete-timemovingaverageprocessinwhichthewindow\n",
      "ispotentiallyinextentandisproducedbyaGPprior[14].Afourth\n",
      "perspectiverelatestheGPCMtostandardGPmodels.Considertheh(t)\n",
      "tobeknown.Inthiscasetheprocessf(t)|hisdistributedaccordingtoaGP,\n",
      "sincef(t)isalinearcombinationofGaussianrandomvariables.Themean\n",
      "functionmf|h(f(t))andcovariancefunctionKf|h(t1,t2)Roftherandom\n",
      "variablef|h,t?R,arethenstationaryandgivenbymf|h(f(t))=E[f\n",
      "(t)|h]=h(t??)E[x(?)]d?=0andRZKf|h(t1,t2)=Kf|h(t)=\n",
      "h(s)h(s+t)ds=(h(t)?h(?t))(t)(2)R1\n",
      "HereweuseinformalnotationcommonintheGPliterature.Amoreformal\n",
      "treatmentwouldusestochasticintegralnotation[11],whichreplacesthe\n",
      "entialelementx(?)d?=dW(?),sothateq.(1)becomesastochasticintegral\n",
      "equation(w.r.t.theBrownianmotionW).\n",
      "2\n",
      "thatis,theconvolutionbetweentheh(t)anditsmirroredversionwith\n",
      "respecttot=0?seesec.1ofthesupplementarymaterialforthefullderivation.\n",
      "Sinceh(t)isitselfisdrawnfromanonparametricprior,thepresentedmodel\n",
      "(throughtherelationshipabove)inducesapriorovernonparametrickernels.\n",
      "Aparticularcaseisobtainedwhenh(t)ischosenasthebasisexpansionofa\n",
      "reproducingkernelHilbertspace[15]withparametrickernel(e.g.,thesquared\n",
      "exponentialkernel),wherebyKf|hbecomessuchakernel.Aperspective\n",
      "considersthemodelinthefrequencydomainratherthanthetimedomain.Here\n",
      "thecontinuous-timelinearshapesthespectralcontentoftheinputprocess\n",
      "x(t).Asx(t)iswhite-noise,ithaspositivePSDatallfrequencies,whichcan\n",
      "potentiallyf(t).Moreprecisely,sincethePSDoff|hisgivenbythe\n",
      "Fouriertransformofthecovariancefunction(bytheWiener?Khinchintheorem\n",
      "[12]),themodelplacesanonparametricRRprioroverthePSD,given2??by\n",
      "3\n",
      "\n",
      "F(Kf|h(t))(?)=RKf|h(t)e?j?tdt=|h(?)|,whereh(?)=Rh(t)e?j?t\n",
      "dtistheFouriertransformoftheArmedwiththesettheoretical\n",
      "perspectivesontheGPCMgenerativemodel,wenextfocusonhowtodesign\n",
      "appropriatecovariancefunctionsforthe2.1\n",
      "Sensibleandtractablepriorsoverthefunction\n",
      "Real-worldsignalshavepower(whichrelatestothestabilityofthe\n",
      "system)andpotentiallycomplexspectralcontent.Howcansuchknowledgebe\n",
      "builtintothecovariancefunctionKh(t1,t2)?Totheseconditions,\n",
      "wemodelthelinearh(t)asadrawfromasquaredexponentialGPthat\n",
      "ismultipliedbyaGaussianwindow(centredonzero)inordertorestrictits\n",
      "extent.Theresultingdecayingsquaredexponential(DSE)covariancefunction\n",
      "isgivenbyasquared22exponential(SE)covariancepre-andpost-multiplied\n",
      "bye??t1ande??t2respectively,thatis,2\n",
      "2\n",
      "2\n",
      "Kh(t1,t2)=KDSE(t1,t2)=?h2e??t1e??(t1?t2)e??t2,?,?,?h>0.\n",
      "(3)2\n",
      "WithptheGPpriorsforx(t)andh(t),f(t)iszero-mean,stationaryand\n",
      "hasavarianceE[f(t)]=?x2?h2?/(2?).Consequently,byChebyshev?sin-\n",
      "equality,f(t)isstochasticallybounded,thatis,p22Pr(|f(t)|?T)?\n",
      "?x?h?/(2?)T?2,T?R.Hence,theexponentialdecayofKDSE(controlled\n",
      "by?)playsakeyroleintheoftheintegralineq.(1)?and,con-\n",
      "sequently,off(t).Additionally,theDSEmodelfortheh(t)providesa\n",
      "priordistributionoverlinearsys2tems,?wherethehyperparameters\n",
      "havephysicalmeaning:?hcontrolsthepoweroftheoutputf(t);1/?isthe\n",
      "characteristictimescaleoverwhichthevariesthat,inturn,determinesthe\n",
      "typical?frequencycontentofthesystem;,1/?isthetemporalextent\n",
      "ofthewhichcontrolsthelengthoftimecorrelationsintheoutputsignal\n",
      "and,equivalently,thebandwidthcharacteristicsinthefrequencydomain.Al-\n",
      "thoughthecovariancefunctionisitsGaussianformfacilitatesanalytic\n",
      "computationthatwillbeleveragedwhen(approximately)samplingfromthe\n",
      "DSE-GPCMandperforminginference.Inprinciple,itisalsopossibleinthe\n",
      "frameworkthatfollowstoaddcausalstructureintothecovariancefunctionso\n",
      "thatonlycausalreceivenon-zeropriorprobabilitydensity,butweleave\n",
      "thatextensionforfuturework.2.2\n",
      "Samplingfromthemodel\n",
      "Exactsamplingfromtheproposedmodelineq.(1)isnotpossible,sinceit\n",
      "requirescomputationoftheconvolutionbetweennitedimensionalprocesses\n",
      "h(t)andx(t).Itispossibletomakesomeanalyticprogressbyconsidering,\n",
      "instead,theGPformulationoftheGPCMineq.(2)andnotingthatsamplingf\n",
      "(t)|h?GP(0,Kf|h)onlyrequiresknowledgeofKf|h=h(t)?h(?t)and\n",
      "thereforeavoidsexplicitrepresentationofthetroublesomewhite-noiseprocess\n",
      "x(t).Furtherprogressrequiresapproximation.Thekeyinsightisthath(t)\n",
      "canbesampledatanumberoflocationsh=h(t)=[h(t1),...,h(tNh\n",
      ")]usingamultivariateGaussianandthenexactanalyticinferencecanbeper-\n",
      "formedtoinfertheentirefunctionh(t)(vianoiselessGPregression).Moreover,\n",
      "4\n",
      "\n",
      "sincetheisdrawnfromtheDSEkernelh(t)?GP(0,KDSE)itis,with\n",
      "highprobability,temporallylimitedinextentandsmoothlyvarying.There-\n",
      "fore,arelativelysmallnumberofsamplesNhcanpotentiallyenableaccurate\n",
      "estimatesofh(t).Thesecondkeyinsightisthatitispossible,3\n",
      "whenusingtheDSEkernel,toanalyticallycomputetheexpectedvalueof\n",
      "thecovarianceoff(t)|h,Kf|h=E[Kf|h|h]=E[h(t)?h(?t)|h]aswell\n",
      "astheuncertaintyinthisquantity.Themorevaluesthelatentprocesshwe\n",
      "consider,thelowertheuncertaintyinhand,asaconsequence,Kf|h?Kf|h\n",
      "almostsurely.ThisisanexampleofaBayesiannumericalintegrationmethod\n",
      "sincetheapproachmaintainsknowledgeofitsowninaccuracy[16].Inmore\n",
      "detail,thekernelapproximationKf|h(t1,t2)isgivenby:ZZ\n",
      "E[Kf|h(t1,t2)|h]=Eh(t1??)h(t2??)d?h=E[h(t1??)h(t2?\n",
      "?)|h]d?R\n",
      "R\n",
      "Ng\n",
      "ZKDSE(t1??,t2??)d?+\n",
      "=R\n",
      "X\n",
      "ZKDSE(t1??,tr)KDSE(ts,t2??)d?\n",
      "Mr,sR\n",
      "r,s=1\n",
      "whereMr,sisthe(r,s)thentryofthematrix(K?1hhTK?1?K?1),K=\n",
      "KDSE(t,t).ThekernelapproximationanditsFouriertransform,i.e.,thePSD,\n",
      "canbecalculatedinclosedform(seesec.2inthesupplementarymaterial).Fig.\n",
      "1illustratesthegenerativeprocessoftheproposedmodel.KernelKf|h(\n",
      "t)=h(t)?h(?t)\n",
      "Filterh(t)?GP(0,Kh)\n",
      "F(Kf|h)(?)\n",
      "LatentprocesshObservationsh\n",
      "0.5\n",
      "Approx.Kf|h=E[Kf|h|h]\n",
      "2\n",
      "3\n",
      "TruekernelKf|h\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "?0.5?1?10\n",
      "Signalf(t)?GP(0,Kf|h)\n",
      "4\n",
      "1\n",
      "10?5\n",
      "05Time[samples]\n",
      "10\n",
      "5\n",
      "\n",
      "?2?10\n",
      "0?2\n",
      "010Time[samples]\n",
      "?1\n",
      "01Frequency[hertz]\n",
      "2\n",
      "?50\n",
      "0Time[samples]\n",
      "50\n",
      "Figure1:Samplingfromtheproposedregressionmodel.Fromlefttoright:\n",
      "kernel,powerspectraldensityandsampleoftheoutputf(?).\n",
      "3\n",
      "Inferenceandlearningusingvariationalmethods\n",
      "Oneofthemaincontributionsofthispaperistodeviseacomputationally\n",
      "tractablemethodforlearningtheh(t)(knownassystemidencationin\n",
      "thecontrolcommunity[17])andinferringthewhite-noiseprocessx(t)froma\n",
      "noisydatasety?RNproducedbytheirconvolutionandadditiveRGaussian\n",
      "noise,y(t)=f(t)+(t)=Rh(t??)x(?)d?+(t),(t)?N(0,?2).Performing\n",
      "inferenceandlearningischallengingforthreereasons:First,theconvolution\n",
      "meansthateachobserveddatapointdependsontheentireunknownand\n",
      "white-noiseprocess,whicharefunctions.Second,themodel\n",
      "isnon-linearintheunknownfunctionssincetheandthewhite-noisemul-\n",
      "tiplyoneanotherintheconvolution.Third,continuous-timewhite-noisemust\n",
      "behandledwithcaresinceformallyitisonlywell-behavedinsideintegrals.We\n",
      "proposeavariationalapproachthataddressesthesethreeproblems.First,the\n",
      "convolutionismadetractablebyusingvariationalinducingvariablesthatsum-\n",
      "marisethetedimensionallatentfunctionsintotedimensionalinducing\n",
      "points.ThisisthesameapproachthatisusedforscalingGPregression[18].\n",
      "Second,theproductnon-linearityismadetractablebyusingastructuredmean-\n",
      "approximationandleveragingthefactthattheposteriorisconditionallya\n",
      "GPwhenx(t)orh(t)isThird,thedirectrepresentationofwhite-noise\n",
      "processisavoidedbyconsideringasetofinducingvariablesinstead,whichare\n",
      "relatedtox(t)viaanintegraltransformation(so-calledinter-domaininducing\n",
      "variables[19]).Weoutlinetheapproachbelow.Inordertoformthevariational\n",
      "inter-domainapproximation,weexpandthemodelwithadditionalvari-\n",
      "ables.WeuseXtodenotethesetofallintegraltransformationsofx(t)with\n",
      "membersRux(t)=w(t,?)x(?)d?(whichincludestheoriginalwhite-noise\n",
      "processwhenw(t,?)=?(t??))RandidenticallythesetHwith\n",
      "membersuh(t)=w(t,?)h(?)d?.Thevariationallowerboundofthemodel\n",
      "evidencecanbeappliedtothisaugmentedmodel2usingJensen?sinequalityZ\n",
      "Zp(y,H,X)dHdX=F(4)L=logp(y)=logp(y,H,X)dHdX?q(H,X)log\n",
      "q(H,X)2Thisformulationcanbemadetechnicallyrigorousforlatentfunctions\n",
      "[20],butwedonotelaborateonthatheretosimplifytheexposition.\n",
      "4\n",
      "hereq(H,X)isanyvariationaldistributionoverthesetsofprocessesXand\n",
      "H.Theboundcanbewrittenasthebetweenthemodelevidence\n",
      "6\n",
      "\n",
      "andtheKLdivergencebetweenthevariationaldistributionoverallintegral\n",
      "transformedprocessesandthetrueposterior,F=L?KL[q(H,X)||p(X,\n",
      "H|y)].Theboundisthereforesaturatedwhenq(H,X)=p(X,H|y),but\n",
      "thisisintractable.Instead,wechooseasimplerparameterisedform,similarin\n",
      "spirittothatusedintheapproximatesamplingprocedure,thatallowsusto\n",
      "side-steptheseInordertoconstructthevariationaldistribution,\n",
      "wepartitionthesetXintotheoriginalwhite-noiseprocess,asetof\n",
      "variablescalledinter-domaininducingpointsuxthatwillbeusedtoparame-\n",
      "terisetheapproximationandtheremainingvariablesX6=x,ux,sothatX=\n",
      "f\n",
      "x,ux,X6=x,ux\n",
      "g\n",
      ".ThesetHispartitionedidenticallyH=\n",
      "f\n",
      "h,uh,H6=h,uh\n",
      "g\n",
      ".Wethenchooseavariationaldistributionq(H,X)thatmirrorstheformof\n",
      "thejointdistribution,p(y,H,X)=p(x,X6=x,ux|ux)p(h,H6=h,uh|uh\n",
      ")p(ux)p(uh)p(y|h,x)q(H,X)=p(x,X6=x,ux|ux)p(h,H6=h,uh|uh\n",
      ")q(ux)q(uh)=q(H)q(X).Thisisastructuredapproximation[21].\n",
      "Theapproximatingdistributionovertheinducingpointsq(ux)q(uh)ischosen\n",
      "tobeamultivariateGaussian(theoptimalparametricformgiventheassumed\n",
      "factorisation).Intuitively,thevariationalapproximationimplicitlyconstructsa\n",
      "surrogateGPregressionproblem,whoseposteriorq(ux)q(uh)inducesapredic-\n",
      "tivedistributionthatbestcapturesthetrueposteriordistributionasmeasured\n",
      "bytheKLdivergence.Critically,theresultingboundisnowtractableaswe\n",
      "willnowshow.First,notethatthesharedpriortermsinthejointandapprox-\n",
      "imationcancelleadingtoanelegantform,Zp(y|h,x)p(uh)p(ux)F=q(h,\n",
      "x,uh,ux)logdhdxduhdux(5)q(uh)q(ux)=Eq[logp(y|h,x)]?KL[q(uh\n",
      ")||p(uh)]?KL[q(ux)||p(ux)].(6)Thelasttwotermsintheboundare\n",
      "simpletocomputebeingKLdivergencesbetweenmultivariateGaussians.The\n",
      "term,theaverageofthelog-likelihoodtermswithrespecttothevariational\n",
      "distribution,ismorecomplex,\"2#ZN1XN2Eqy(ti)?h(ti??)x(?\n",
      ")d?.Eq[logp(y|h,x)]=?log(2??)?222?i=1RComputationof\n",
      "thevariationalboundthereforerequirestheandsecondmomentsofthe\n",
      "convolutionunderthevariationalapproximation.However,thesecanbecom-\n",
      "putedanalyticallyforparticularchoicesofcovariancefunctionsuchastheDSE,\n",
      "bytakingtheexpectationsinsidetheintegral(thisisanalogoustovariational\n",
      "inferencefortheGaussianProcessLatentVariableModel[22]).Forexample,\n",
      "themomentoftheconvolutionisZZEqh(ti??)x(?)d?=Eq(h,uh)\n",
      "[h(ti??)]Eq(x,ux)[x(?)]d?(7)R\n",
      "R\n",
      "wheretheexpectationstaketheformofthepredictivemeaninGPregression,\n",
      "?andEq(x,ux)[x(?)]=Kx,ux(?)Ku?1Eq(h,uh)[h(ti??)]=\n",
      "Kh,uh(ti??)Ku?1?x,uxuxh,uhuhwhere\n",
      "f\n",
      "Kh,uh,Kuh,uh,Kx,ux\n",
      ",Kux,ux\n",
      "g\n",
      "arethecovariancefunctionsand\n",
      "f\n",
      "?uh,?ux\n",
      "g\n",
      "arethemeansof\n",
      "theapproximatevariationalposterior.Crucially,theintegralistractableifthe\n",
      "covarianceRfunctionscanbeconvolvedanalytically,RKh,uh(ti??)Kx,ux\n",
      "(?)d?,whichisthecasefortheSEandDSEcovariances-seesec.4of\n",
      "thesupplementarymaterialforthederivationofthevariationallowerbound.\n",
      "Thefactthatitispossibletocomputetheandsecondmomentsofthe\n",
      "convolutionundertheapproximateposteriortractabletocomputethemeanof\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theposteriordistributionmeansthatitisalsoRoverthekernel,EqKf|h(t1,\n",
      "t2)=EqRh(t1??)h(t2??)d?andtheassociatederror-bars.Themethod\n",
      "thereforesupportsfullprobabilisticinferenceandlearningfornonparametric\n",
      "kernels,inadditiontoextrapolation,interpolationanddenoisinginatractable\n",
      "manner.Thenextsectiondiscussessensiblechoicesfortheintegraltransforms\n",
      "thattheinducingvariablesuhandux.3.1\n",
      "Choiceoftheinducingvariablesuhandux\n",
      "Inordertochoosethedomainoftheinducingvariables,itisusefultocon-\n",
      "siderinferenceforthewhite-noiseprocessgivenawindowh(t).Typically,\n",
      "weassumethatthewindowh(t)is5\n",
      "smoothlyvarying,inwhichcasethedatay(t)areonlydeterminedbythe\n",
      "low-frequencycontentofthewhite-noise;converselyininference,thedatacan\n",
      "onlyrevealthelowfrequenciesinx(t).Infact,sinceacontinuoustimewhite-\n",
      "noiseprocesscontainspoweratallfrequenciesandpowerintotal,most\n",
      "ofthewhite-noisecontentwillbeundeterminable,asitissuppressedbythe\n",
      "(orout).However,forthesamereason,thesecomponentsdonot\n",
      "predictionoff(t).Sincewecanonlylearnthelow-frequencycontent\n",
      "ofthewhite-noiseandthisisallthatisimportantformakingpredictions,we\n",
      "considerinter-domaininducingpointsformedbyaGaussianintegral\n",
      "Rtransform,ux=Rexp?2l12(tx??)2x(?)d?.Theseinduc-\n",
      "ingvariablesrepresentalocalestimateofthewhite-noiseprocessxaroundthe\n",
      "inducinglocationtxconsideringaGaussianwindow,andhaveasquaredexpo-\n",
      "nentialcovariancebyconstruction(thesecovariancesareshowninsec.3ofthe\n",
      "supplementarymaterial).Inspectralterms,theprocessuxisalow-passversion\n",
      "ofthetrueprocessx.Thevariationalparameterslandtxecttheapproximate\n",
      "posteriorandcanbeoptimisedusingthefree-energy,althoughthiswasnotin-\n",
      "vestigatedheretominimisecomputationaloverhead.Fortheinducingvariables\n",
      "uhwechosenottousetheyoftheinter-domainparameterisationand,\n",
      "instead,placethepointsinthesamedomainasthewindow.\n",
      "4\n",
      "Experiments\n",
      "TheDSE-GPCMwastestedusingsyntheticdatawithknownstatistical\n",
      "propertiesandreal-worldsignals.Theaimoftheseexperimentswastovalidate\n",
      "thenewapproachtolearncovariancefunctionsandPSDswhilealsoproviding\n",
      "errorbarsfortheestimates,andtocompareitagainstalternativeparametric\n",
      "andnonparametricapproaches.4.1\n",
      "Learningknownparametrickernels\n",
      "WeconsideredGaussianprocesseswithstandard,parametriccovarianceker-\n",
      "nelsandvthatourmethodisabletoinfersuchkernels.Gaussianpro-\n",
      "cesseswithsquaredexponential(GP-SE)andspectralmixture(GP-SM)kernels,\n",
      "bothofunitvariance,wereusedtogeneratetwotimeseriesontheregion[-44,\n",
      "44]uniformlysampledat10Hz(i.e.,880samples).Wethenconstructedthe\n",
      "observationsignalbyaddingunit-variancewhite-noise.Theexperimentthen\n",
      "consistedof(i)learningtheunderlyingkernel,(ii)estimatingthelatentprocess\n",
      "and(iii)performingimputationbyremovingobservationsintheregion[-4.4,\n",
      "4.4](10%oftheobservations).Fig.2showstheresultsfortheGP-SEcase.We\n",
      "8\n",
      "\n",
      "chose88inducingpointsforux,thatis,1/10ofthesamplestoberecovered\n",
      "and30foruh;thehyperparametersineq.(2)weresetto?=0.45and?=\n",
      "0.1,soastoallowforanuninformativeprioronh(t).Thevariationalobjec-\n",
      "tiveFwasoptimisedwithrespecttothehyperparameter?handthevariational\n",
      "parameters?h,?x(means)andtheCholeskyfactorsofCh,Cx(covariances)\n",
      "usingconjugategradients.ThetrueSEkernelwasreconstructedfromthenoisy\n",
      "datawithanaccuracyof5%,whiletheestimationmeansquarederror(MSE)\n",
      "waswithin1%ofthe(unit)noisevarianceforboththetrueGP-SEandthe\n",
      "proposedmodel.Fig.3showstheresultsfortheGP-SMtimeseries.Along\n",
      "thelinesoftheGP-SEcase,thereconstructionofthetruekernelandspectrum\n",
      "isremarkablyaccurateandtheestimateofthelatentprocesshasvirtuallythe\n",
      "samemeansquareerror(MSE)asthetrueGP-SMmodel.Thesetoyresultsin-\n",
      "dicatethatthevariationalinferenceprocedurecanworkwell,inspiteofknown\n",
      "biases[23].4.2\n",
      "Learningthespectrumofreal-worldsignals\n",
      "TheabilityoftheDSE-GPCMtoprovideBayesianestimatesofthePSDof\n",
      "real-worldsignalswasvnext.Thiswasachievedthroughacomparisonof\n",
      "theproposedmodelto(i)thespectralmixturekernel(GP-SM)[4],(ii)tracking\n",
      "theFouriercotsusingaKalman(KalmanFourier[24]),(iii)theYule-\n",
      "Walkermethodand(iv)theperiodogram[25].WeanalysedtheMaunaLoa\n",
      "monthlyCO2concentration(de-trended).WeconsideredtheGPSMwith4and\n",
      "10components,Kalman-Fourierwithapartitionof500pointsbetweenzeroand\n",
      "theNyquistfrequency,Yule-Walkerwith250lagsandtherawperiodogram.\n",
      "AllmethodsusedallthedataandeachPSDestimatewasnormalisedw.r.tits\n",
      "maximum(shownin4).Allmethodsidenthethreemainfrequency\n",
      "peaksat[0,year?1,2year?1];however,noticethattheKalmanFouriermethod\n",
      "doesnotprovidesharppeaksandthatGP-SMplacesGaussiansonfrequencies\n",
      "with6\n",
      "Filterh(t)\n",
      "Pos4teriormeanInducingpoints\n",
      "32\n",
      "Kernels(normalised).Discrepancy:5.4%\n",
      "Processux1\n",
      "2PosteriormeanInducingpoints\n",
      "1\n",
      "TrueSEkernel0.5-GPCMkernelDSE\n",
      "0\n",
      "0\n",
      "0?5\n",
      "0\n",
      "?2?40\n",
      "5\n",
      "?20\n",
      "0\n",
      "20\n",
      "40\n",
      "9\n",
      "\n",
      "?5\n",
      "0\n",
      "5\n",
      "Observations,latentprocessandkernelestimates4Latent\n",
      "processObservationsSEkernelestimate(MSE=0.9984)DSE-GP\n",
      "CMestimate(MSE=1.0116)\n",
      "20?2?4?40\n",
      "?30\n",
      "?20\n",
      "?10\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "Figure2:JointlearningofanSEkernelanddataimputationusingthepro-\n",
      "posedDSE-GPCMapproach.Top:lterh(t)andinducingpointsuh(left),\n",
      "white-noiseprocessux(centre)andlearntkernel(right).Bottom:La-\n",
      "tentsignalanditsestimatesusingboththeDSE-GPCMandthetruemodel\n",
      "(GP-SE).intervalsareshowninlightblue(DSE-GPCM)andinbe-\n",
      "tweendashedredlines(GP-SE)andtheycorrespondto99.7%forthekernel\n",
      "and95%otherwise.Kernels(normalised).Discrepancy:18.6%.20\n",
      "1.5\n",
      "GroundtruthDSE-GPCMposterior\n",
      "Dataimputation\n",
      "PSD(normalised).Discrepancy:15.8%.\n",
      "8\n",
      "DSE-GPCMTrueSMkernel\n",
      "18\n",
      "6\n",
      "161\n",
      "GroundtruthObservationsSMestimate(MSE=1.0149)DSE-\n",
      "GPCMestimate(MSE=1.0507)\n",
      "14\n",
      "4\n",
      "120.5\n",
      "10\n",
      "2\n",
      "80\n",
      "0\n",
      "64\n",
      "?2\n",
      "2\n",
      "?0.5\n",
      "?4?20\n",
      "?10\n",
      "10\n",
      "\n",
      "0Time\n",
      "10\n",
      "20\n",
      "0\n",
      "0.1\n",
      "0.20.3Frequency\n",
      "0.4\n",
      "0.5\n",
      "?10\n",
      "?5\n",
      "0Time\n",
      "5\n",
      "10\n",
      "Figure3:JointlearningofanSMkernelanddataimputationusinganon-\n",
      "parametrickernel.Trueandlearntkernel(left),trueandlearntspectra(centre)\n",
      "anddataimputationregion(right).negligiblepower?thisisaknowndrawback\n",
      "oftheGP-SMapproach:itissensitivetoinitialisationandgetstrappedinnoisy\n",
      "frequencypeaks(inthisexperiment,thecentresoftheGP-SMwereinitialised\n",
      "asmultiplesofonetenthoftheNyquistfrequency).Thisexampleshowsthat\n",
      "theGP-SMcanovnoiseintrainingdata.Conversely,observehowthepro-\n",
      "posedDSE-GPCMapproach(withNh=300andNx=150)notonlycaptured\n",
      "thethreepeaksbutalsothespectralorandplacedmeaningfulerrorbars\n",
      "(90%)wheretherawperiodogramlaid.0\n",
      "0\n",
      "10\n",
      "10\n",
      "?5\n",
      "?5\n",
      "10\n",
      "10\n",
      "Spectralmix.(4comp)Spectralmix.(10comp)Kalman-Four\n",
      "ierYule-WalkerPeriodogram\n",
      "DSE-GPCMPeriodogram?10\n",
      "10\n",
      "?10\n",
      "1/year\n",
      "2/year3/year4/yearFrequency[year?1]\n",
      "10\n",
      "5/year\n",
      "1/year\n",
      "2/year3/year4/yearFrequency[year?1]\n",
      "5/year\n",
      "Figure4:SpectralestimationoftheMaunaLoaCO2concentration.DSE-\n",
      "GPCMwitherrorbars(90%)isshownwiththeperiodogramattheleftand\n",
      "allothermethodsattherightforclarity.Thenextexperimentconsistedof\n",
      "recoveringthespectrumofanaudiosignalfromtheTIMITcorpus,composedof\n",
      "11\n",
      "\n",
      "1750samples(at16kHz),onlyusinganirregularly-sampled20%oftheavailable\n",
      "data.WecomparedtheproposedDSE-GPCMmethodtoGP-SM(again4and\n",
      "10components)andKalman-Fourier;weusedtheperiodogramandtheYule-\n",
      "Walkermethodasbenchmarks,sincethese7\n",
      "methodscannothandleunevenly-sampleddata(therefore,theyusedallthe\n",
      "data).BesidesthePSD,wealsocomputedthelearntkernel,shownalongside\n",
      "theautocorrelationfunctionin5(left).Duetoitssensitivitytoinitialcon-\n",
      "ditions,thecentresoftheGP-SMwereinitialisedevery100Hz(theharmonics\n",
      "ofthesignalareapproximatelyevery114Hz);however,itwasonlywith10com-\n",
      "ponentsthattheGP-SMwasabletothefourmainlobesofthePSD.Notice\n",
      "alsohowtheDSE-GPCMaccuratelythemainlobes,bothinlocationand\n",
      "width,togetherwiththe90%errorbars.\n",
      "1.210.80.6\n",
      "Powerspectraldensity\n",
      "Covariancekernel\n",
      "0\n",
      "Powerspectraldensity0\n",
      "10DSE-GPCMSpectralMix.(4comp)SpectralMix.(10c\n",
      "omp)Autocorrelationfunction\n",
      "10\n",
      "?2\n",
      "?2\n",
      "10\n",
      "10\n",
      "0.40.20\n",
      "?4\n",
      "?4\n",
      "10\n",
      "10\n",
      "?0.2?0.4\n",
      "DSE-GPCMPeriodogram\n",
      "?0.6\n",
      "?6\n",
      "?6\n",
      "100\n",
      "1020Time[miliseconds]\n",
      "30\n",
      "SpectralMix.(4comp)SpectralMix.(10comp)Kalman-Four\n",
      "ierYule-WalkerPeriodogram\n",
      "10114228342456570684798Frequency[hertz]\n",
      "114228342456570684798Frequency[hertz]\n",
      "Figure5:AudiosignalfromTIMIT.InducedkernelofDSE-GPCMandGP-\n",
      "SMalongsideautocorrelationfunction(left).PSDestimateusingDSE-GPCM\n",
      "andrawperiodogram(centre).PSDestimateusingGP-SM,Kalman-Fourier,\n",
      "Yule-Walkerandrawperiodogram(right).\n",
      "5\n",
      "12\n",
      "\n",
      "Discussion\n",
      "TheGaussianProcessConvolutionModel(GPCM)hasbeenproposedasa\n",
      "generativemodelforstationarytimeseriesbasedontheconvolutionbetween\n",
      "afunctionandawhite-noiseprocess.Learningthemodelfromdatais\n",
      "achievedviaanovelvariationalfree-energyapproximation,whichinturnallows\n",
      "ustoperformpredictionsandinferenceonboththecovariancekernelandthe\n",
      "spectruminaprobabilistic,analyticallyandcomputationallytractablemanner.\n",
      "TheGPCMapproachwasvalidatedintherecoveryofspectraldensityfromnon-\n",
      "uniformlysampledtimeseries;toourknowledge,thisistheprobabilistic\n",
      "approachthatplacesnonparametricprioroverthespectraldensityitselfand\n",
      "whichrecoversaposteriordistributionoverthatdensitydirectlyfromthetime\n",
      "series.Theencouragingresultsforbothsyntheticandreal-worlddatashown\n",
      "insec.4serveasaproofofconceptforthenonparametricdesignofcovari-\n",
      "ancekernelsandPSDsusingconvolutionprocesses.Inthisregard,extensions\n",
      "ofthepresentedmodelcanbeidenedinthefollowingdirections:First,for\n",
      "theproposedGPCMtohaveadesiredperformance,thenumberofinducing\n",
      "pointsuhanduxneedstobeincreasedwiththe(i)highfrequencycontent\n",
      "and(ii)rangeofcorrelationsofthedata;therefore,toavoidthecomputational\n",
      "overheadassociatedtolargequantitiesofinducingpoints,theprioror\n",
      "theinter-domaintransformationcanbedesignedtohaveaspharmonic\n",
      "structureandthereforefocusonatargetspectrum.Second,thealgorithmcan\n",
      "beadaptedtohandlelongertimeseries,forinstance,throughtheuseoftree-\n",
      "structuredapproximations[26].Third,themethodcanalsobeextendedbeyond\n",
      "timeseriestooperateonhigher-dimensionalinputspaces;thiscanbeachieved\n",
      "bymeansofafactorisationofthelatentkernel,wherebythenumberofinducing\n",
      "pointsfortheonlyincreaseslinearlywiththedimension,ratherthanexpo-\n",
      "nentially.AcknowledgementsPartofthisworkwascarriedoutwhenF.T.was\n",
      "withtheUniversityofCambridge.F.T.thanksCONICYT-PAIgrant82140061\n",
      "andBasal-CONICYTCenterforMathematicalModeling(CMM).R.T.thanks\n",
      "EPSRCgrantsEP/L000776/1andEP/M026957/1.T.B.thanksGoogle.We\n",
      "thankMarkRowland,ShaneGuandtheanonymousreviewersforinsightful\n",
      "feedback.8\n",
      "2References\n",
      "[1]C.E.RasmussenandC.K.I.Williams,GaussianProcessesforMachine\n",
      "Learning.TheMITPress,2006.RinMachineLearning,vol.2,[2]Y.Bengio,\n",
      "?LearningdeeparchitecturesforAI,?Foundationsandtrendsno.1,pp.1?127,\n",
      "2009.\n",
      "[3]D.J.C.MacKay,?IntroductiontoGaussianprocesses,?inNeural\n",
      "NetworksandMachineLearning(C.M.Bishop,ed.),NATOASISeries,pp.\n",
      "133?166,KluwerAcademicPress,1998.[4]A.G.WilsonandR.P.Adams,\n",
      "?Gaussianprocesskernelsforpatterndiscoveryandextrapolation,?inProc.of\n",
      "InternationalConferenceonMachineLearning,2013.[5]D.Duvenaud,J.R.\n",
      "Lloyd,R.Grosse,J.B.Tenenbaum,andZ.Ghahramani,?Structurediscovery\n",
      "13\n",
      "\n",
      "innonparametricregressionthroughcompositionalkernelsearch,?inProc.of\n",
      "InternationalConferenceonMachineLearning,pp.1166?1174,2013.[6]D.Du-\n",
      "venaud,H.Nickisch,andC.E.Rasmussen,?AdditiveGaussianprocesses,?in\n",
      "AdvancesinNeuralInformationProcessingSystems24,pp.226?234,2011.[7]\n",
      "M.G?onenandE.Alpaydin,?Multiplekernellearningalgorithms,?TheJournal\n",
      "ofMachineLearningResearch,vol.12,pp.2211?2268,2011.[8]F.Tobar,S.-Y.\n",
      "Kung,andD.Mandic,?Multikernelleastmeansquarealgorithm,?IEEETrans.\n",
      "onNeuralNetworksandLearningSystems,vol.25,no.2,pp.265?277,2014.\n",
      "[9]R.E.Turner,StatisticalModelsforNaturalSounds.PhDthesis,Gatsby\n",
      "ComputationalNeuroscienceUnit,UCL,2010.[10]R.TurnerandM.Sahani,\n",
      "?Time-frequencyanalysisasprobabilisticinference,?IEEETrans.onSignal\n",
      "Processing,vol.62,no.23,pp.6171?6183,2014.[11]B.Oksendal,Stochastic\n",
      "tialEquations.Springer,2003.[12]A.V.OppenheimandA.S.Willsky,\n",
      "SignalsandSystems.Prentice-Hall,1997.[13]C.Archambeau,D.Cornford,\n",
      "M.Opper,andJ.Shawe-Taylor,?Gaussianprocessapproximationsofstochastic\n",
      "tialequations,?JournalofMachineLearningResearchWorkshopand\n",
      "ConferenceProceedings,vol.1,pp.1?16,2007.[14]S.F.Gull,?Develop-\n",
      "mentsinmaximumentropydataanalysis,?inMaximumEntropyandBayesian\n",
      "Methods(J.Skilling,ed.),vol.36,pp.53?71,SpringerNetherlands,1989.[15]\n",
      "B.Sch?olkopfandA.J.Smola,LearningwithKernels:SupportVectorMa-\n",
      "chines,Regularization,Optimization,andBeyond.MITPress,2001.[16]T.\n",
      "P.Minka,?DerivingquadraturerulesfromGaussianprocesses,?tech.rep.,\n",
      "StatisticsDepartment,CarnegieMellonUniversity,2000.[17]A.H.Jazwinski,\n",
      "StochasticProcessesandFilteringTheory.NewYork,AcademicPress.,1970.\n",
      "[18]M.K.Titsias,?VariationallearningofinducingvariablesinsparseGaussian\n",
      "processes,?inProc.ofInternationalConferenceonIntelligenceand\n",
      "Statistics,pp.567?574,2009.[19]A.Figueiras-VidalandM.L?azaro-Gredilla,\n",
      "?Inter-domainGaussianprocessesforsparseinferenceusinginducingfeatures,?\n",
      "inAdvancesinNeuralInformationProcessingSystems,pp.1087?1095,2009.\n",
      "[20]A.G.d.G.Matthews,J.Hensman,R.E.Turner,andZ.Ghahramani,\n",
      "?OnsparsevariationalmethodsandtheKullback-Leiblerdivergencebetween\n",
      "stochasticprocesses,?arXivpreprintarXiv:1504.07027,2015.[21]D.J.C.\n",
      "MacKay,InformationTheory,Inference,andLearningAlgorithms.Cambridge\n",
      "UniversityPress,2003.[22]M.K.TitsiasandN.D.Lawrence,?Bayesian\n",
      "Gaussianprocesslatentvariablemodel,?inProc.ofInternationalConference\n",
      "onIntelligenceandStatistics,pp.844?851,2010.[23]R.E.Turner\n",
      "andM.Sahani,?Twoproblemswithvariationalexpectationmaximisationfor\n",
      "time-seriesmodels,?inBayesiantimeseriesmodels(D.Barber,T.Cemgil,\n",
      "andS.Chiappa,eds.),ch.5,pp.109?130,CambridgeUniversityPress,2011.\n",
      "[24]Y.Qi,T.Minka,andR.W.Picara,?Bayesianspectrumestimationofun-\n",
      "evenlysamplednonstationarydata,?inProc.ofIEEEICASSP,vol.2,pp.\n",
      "II?1473?II?1476,2002.[25]D.B.PercivalandA.T.Walden,SpectralAnalysis\n",
      "forPhysicalApplications.CambridgeUniversityPress,1993.CambridgeBooks\n",
      "Online.[26]T.D.BuiandR.E.Turner,?Tree-structuredGaussianprocessap-\n",
      "proximations,?inAdvancesinNeuralInformationProcessingSystems27,pp.\n",
      "2213?2221,2014.\n",
      "14\n",
      "\n",
      "9\n",
      "15\n",
      "\n",
      "PP3698.pdf\n",
      "PP3698.pdf 11\n",
      "CompressedLeast-SquaresRegression\n",
      "Authoredby:\n",
      "R?miMunos\n",
      "OdalricMaillard\n",
      "Abstract\n",
      "Weconsidertheproblemoflearning,fromKinputdata,aregression\n",
      "functioninafunctionspaceofhighdimensionNusingprojectionsonto\n",
      "arandomsubspaceoflowerdimensionM.Fromanylinearapproxima-\n",
      "tionalgorithmusingempiricalriskminimization(possiblypenalized),we\n",
      "provideboundsontheexcessriskoftheestimatecomputedinthepro-\n",
      "jectedsubspace(compresseddomain)intermsoftheexcessriskofthe\n",
      "estimatebuiltinthehigh-dimensionalspace(initialdomain).Weapply\n",
      "theanalysistotheordinaryLeast-Squaresregressionandshowthatby\n",
      "choosingM=O(sqrt\n",
      "f\n",
      "K\n",
      "g\n",
      "),theestimationerror(forthequadraticloss)of\n",
      "the\\CompressedLeastSquaresRegressionisO(1/sqrt\n",
      "f\n",
      "K\n",
      "g\n",
      ")uptolog-\n",
      "arithmicfactors.Wealsodiscussthenumericalcomplexityofseveral\n",
      "algorithms(bothininitialandcompresseddomains)asafunctionofN,\n",
      "K,andM.\n",
      "1PaperBody\n",
      "Weconsidertheproblemoflearning,fromKdata,aregressionfunctionina\n",
      "linearspaceofhighdimensionNusingprojectionsontoarandomsubspaceof\n",
      "lowerdimensionM.Fromanyalgorithmminimizingthe(possiblypenalized)\n",
      "empiricalrisk,weprovideboundsontheexcessriskoftheestimatecomputed\n",
      "intheprojectedsubspace(compresseddomain)intermsoftheexcessriskof\n",
      "theestimatebuiltinthehigh-dimensionalspace(initialdomain).Weshowthat\n",
      "solvingtheprobleminthecompresseddomaininsteadoftheinitialdomain\n",
      "reducestheestimationerroratthepriceofanincreased(butcontrolled)ap-\n",
      "proximationerror.WeapplytheanalysistoLeast-Squares(LS)regressionand\n",
      "discusstheexcessriskandnumericalcomplexityoftheresulting?Compressed\n",
      "LeastSquaresRe?gression?(CLSR)intermsofN,K,andM.Whenwe\n",
      "chooseM=O(K),we?showthatCLSRhasanestimationerroroforder\n",
      "O(logK/K).\n",
      "1\n",
      "Problemsetting\n",
      "WeconsideraregressionproblemwhereweobservedataDK=(\n",
      "f\n",
      "xk,yk\n",
      "g\n",
      "k?K)(wherexk?Xandyk?R)areassumedtobeindependentlyand\n",
      "1\n",
      "\n",
      "identicallydistributed(i.i.d.)fromsomedistributionP,wherexk?PXand\n",
      "yk=f?(xk)+?k(xk),wheref?isthe(unknown)targetfunction,and?ka\n",
      "centeredindependentnoiseofvariance?2(xk).Foragivenclassoffunctions\n",
      "F,andf?F,wetheempirical(quadratic)errordef\n",
      "LK(f)=\n",
      "K1X[yk?f(xk)]2,Kk=1\n",
      "andthegeneralization(quadratic)errordef\n",
      "L(f)=\n",
      "E(X,Y)?P[(Y?f(X))2].\n",
      "Ourgoalistoreturnaregressionfunctionfb?Fwithlowestpossible\n",
      "generalizationerrorL(fb).Notations:Inthesequelwewillmakeuseofthe\n",
      "followingnotationsaboutnorms:forh:X7?R,wewrite||h||Pforthe\n",
      "L2normofhwithrespectto(w.r.t.)themeasureP,||h||PKfortheL2\n",
      "norm\n",
      "Pn21/2ofhw.r.t.theempiricalmeasurePK,andforu?Rn,||u||\n",
      "denotesbydefault.i=1uiThemeasurablefunctionminimizingthegeneral-\n",
      "izationerrorisf?,butitmaybethecasethatf??/F.Foranyregression\n",
      "functionfb,wetheexcessriskL(fb)?L(f?)=||fb?f?||2P,\n",
      "whichdecomposesasthesumoftheestimationerrorL(fb)?inff?FL(f)and\n",
      "theapproximationerrorinff?FL(f)?L(f?)=inff?F||f?f?||2P\n",
      "whichmeasuresthedistancebetweenf?andthefunctionspaceF.1\n",
      "InthispaperweconsideraclassoflinearfunctionsFNasthespan\n",
      "ofasetofNfunctionsdefdefPN\n",
      "f\n",
      "?n\n",
      "g\n",
      "1?n?Ncalledfeatures.Thus:FN=\n",
      "f\n",
      "f?=n=1?n?n,??RN\n",
      "g\n",
      ".WhenthenumberofdataKislargerthanthe\n",
      "numberoffeaturesN,theordinaryLeast-SquaresRegression(LSR)provides\n",
      "theLSsolutionf?bwhichistheminimizeroftheempiricalriskLK(f)1in\n",
      "FN.NotethathereLK(f?)rewritesK||???Y||Kwhere?isthe\n",
      "K?Nmatrixwithelements(?n(xk))1?n?N,1?k?KandYtheK-vectorwith\n",
      "components(yk)1?k?K.Usualresultsprovideboundontheestimationerror\n",
      "asafunctionofthecapacityofthefunctionspaceandthenumberofdata.\n",
      "Inthecaseoflinearapproximation,thecapacitymeasures(suchascovering\n",
      "numbers[23]orthepseudo-dimension[16])dependonthenumberoffeatures\n",
      "(forexamplethepseudo-dimensionisatmostN+1).Forexample,letf?bbe\n",
      "aLSestimate(minimizerofLKinFN),then(amoreprecisestatementwillbe\n",
      "statedlaterinSubsection3)theexpectedestimationerrorisboundedas:\n",
      "NlogKEL(f?b)?infL(f)?c?2,(1)f?FNKdef\n",
      "wherecisauniversalconstant,?=supx?X?(x),andtheexpectationis\n",
      "takenwithrespecttoP.Now,theexcessriskisthesumofthisestimation\n",
      "errorandtheapproximationerrorinff?FN||f?f?||PoftheclassS\n",
      "FN.SincethelaterusuallydecreaseswhenthenumberoffeaturesNincreases\n",
      "[13](e.g.whenNFNisdenseinL2(P)),weseetheusualbetween\n",
      "smallestimationerror(lowN)andsmallapproximationerror(largeN).In\n",
      "thispaperweareinterestedinthesettingwhenNislargesothattheapprox-\n",
      "imationerrorissmall.WheneverNislargerthanKwefacetheov\n",
      "problemsincetherearemoreparametersthanactualdata(morevariablesthan\n",
      "constraints),whichisillustratedinthebound(1)whichprovidesnoinformation\n",
      "2\n",
      "\n",
      "aboutthegeneralizationabilityofanyLSestimate.Inaddition,therearemany\n",
      "minimizers(infactavectorspaceofsamedimensionasthenullspaceof?T?)\n",
      "oftheempiricalrisk.Toovercometheproblem,severalapproacheshavebeen\n",
      "proposedintheliterature:?LSsolutionwithminimalnorm:Thesolution\n",
      "istheminimizeroftheempiricalerrorwithminimal(l1orl2)-norm:?b=\n",
      "argmin??=Y||?||1or2,(orarobustsolutionargmin||???Y||2\n",
      "??||?||1).Thechoiceof`2-normyieldstheordinaryLSsolution.The\n",
      "choiceof`1-normhasbeenusedforgeneratingsparsesolutions(e.g.theBasis\n",
      "Pursuit[10]),andassumingthatthetargetfunctionadmitsasparsedecompo-\n",
      "sition,theofCompressedSensing[9,21]providestconditionsfor\n",
      "recoveringtheexactsolution.However,suchconditions(e.g.that?possessesa\n",
      "RestrictedIsometricProperty(RIP))doesnotholdingeneralinthisregression\n",
      "setting.Onanotheraspect,solvingtheseproblems(bothforl1orl2-norm)\n",
      "whenNislargeisnumericallyexpensive.?Regularization.Thesolutionisthe\n",
      "minimizeroftheempiricalerrorplusapenaltyterm,forexamplefb=argmin\n",
      "LK(f)+?||f||pp,forp=1or2.f?FN\n",
      "where?isaparameterandusualchoicesforthenormare`2(ridge-regression\n",
      "[20])and`1(LASSO[19]).AclosealternativeistheDantzigselector[8,5]which\n",
      "solves:?b=argmin||?||1??||?T(Y???)||?.Thenumerical\n",
      "complexityandgeneralizationboundsofthosemethodsdependonthesparsity\n",
      "ofthetargetfunctiondecompositioninFN.Nowifwepossessasequenceof\n",
      "functionclasses(FN)N?1withincreasingcapacity,wemayperformstructural\n",
      "riskminimization[22]bysolvingineachmodeltheempiricalriskpenalizedby\n",
      "atermthatdependsonthesizeofthemodel:fbN=argminf?FN,N?1LK(f\n",
      ")+pen(N,K),wherethepenaltytermmeasuresthecapacityofthefunction\n",
      "space.Inthispaperwefollowanotherapproachwhereinsteadofsearchingin\n",
      "thelargespaceFN(whereN>K)forasolutionthatminimizestheempirical\n",
      "errorplusapenaltyterm,wesimplysearchfortheempiricalerrorminimizer\n",
      "ina(randomlygenerated)lowerdimensionalsubspaceGM?FN(whereM<\n",
      "K).Ourcontribution:WeconsiderasetofMrandomlinearcombinationsof\n",
      "theinitialNfeaturesandperformourfavoriteLSregressionalgorithm(possibly\n",
      "regularized)usingthose?compressed2\n",
      "features?.ThisisequivalenttoprojectingtheKpoints\n",
      "f\n",
      "?(xk)?RN,k=\n",
      "1..K\n",
      "g\n",
      "fromtheinitialdomain(ofsizeN)ontoarandomsubspaceofdimension\n",
      "M,andthenperformingtheregressioninthe?compresseddomain?(i.e.span\n",
      "ofthecompressedfeatures).Thisismadepossiblebecauserandomprojections\n",
      "approximatelypreserveinnerproductsbetweenvectors(byavariantofthe\n",
      "Johnson-LindenstraussLemmastatedinProposition1.Ourmainresultisa\n",
      "boundontheexcessriskofalinearestimatorbuiltinthecompresseddomainin\n",
      "termsoftheexcessriskofthelinearestimatorbuiltintheinitialdomain(Section\n",
      "2).WefurtherdetailthecaseofordinaryLeast-SquaresRegression(Section\n",
      "3)anddiscuss,intermsofM,N,K,thetconcerningthe\n",
      "excessrisk(reducedestimationerrorinthecompresseddomainversusincreased\n",
      "approximationerrorintroducedbytherandomprojection)andthenumerical\n",
      "complexity(reducedcomplexityofsolvingtheLSRinthecompresseddomain\n",
      "versustheadditionalloadofperformingtheprojection).?Asaconsequence,\n",
      "3\n",
      "\n",
      "weshowthatbychoosingM=O(K)projectionsweaCompressedLeast-\n",
      "SquaresRegressionwhichusesO(NK3/2)elementaryoperationstocompute\n",
      "aregression?functionwithestimationerror(relativelytotheinitialfunction\n",
      "spaceFN)oforderlogK/Kuptoamultiplicativefactorwhichdepends\n",
      "onthebestapproximationoff?inFN.Thisiscompetitivewiththebest\n",
      "methods,uptoourknowledge.Relatedworks:Usingdimensionreductionand\n",
      "randomprojectionsinvariouslearningareashasreceivedconsiderableinterest\n",
      "overthepastfewyears.In[7],theauthorsuseaSVMalgorithminacompressed\n",
      "spaceforthepurposeofclascationandshowthattheirresultingalgorithm\n",
      "hasgoodgeneralizationproperties.In[25],theauthorsconsideranotionof\n",
      "compressedlinearregression.FordataY=X?+?,where?isthetargetand?\n",
      "astandardnoise,theyusecompressionofthesetofdata,thusconsideringAY\n",
      "=AX?+A?,whereAhasaRestrictedIsometricProperty.Theyprovidean\n",
      "analysisoftheLASSOestimatorbuiltfromthesecompresseddata,anddiscuss\n",
      "apropertycalledsparsistency,i.e.thenumberofrandomprojectionsneeded\n",
      "torecover?(withhighprobability)whenitissparse.Theseworksfrom\n",
      "ourapproachinthefactthatwedonotconsideracompressed(inputand/or\n",
      "output)dataspacebutacompressedfeaturespaceinstead.In[11],theauthors\n",
      "discusshowcompressedmeasurementsmaybeusefultosolvemanydetection,\n",
      "andestimationproblemswithouthavingtoreconstructthesignal\n",
      "ever.Interestingly,theymakenoassumptionaboutthesignalbeingsparse,like\n",
      "inourwork.In[6,17],theauthorsshowhowtomapakernelk(x,y)=?(x)\n",
      "??(y)intoalow-dimensionalspace,whilestillapproximatelypreservingthe\n",
      "innerproducts.Thustheybuildalow-dimensionalfeaturespacespfor\n",
      "(translationinvariant)kernels.\n",
      "2\n",
      "Linearregressioninthecompresseddomain\n",
      "Weremindthattheinitialsetoffeaturesis\n",
      "f\n",
      "?n:X7?R,1?n?N\n",
      "g\n",
      "and\n",
      "theinitialdomainPNdefFN=\n",
      "f\n",
      "f?=n=1?n?n,??RN\n",
      "g\n",
      "isthespanofthose\n",
      "features.Wewrite?(x)theN-vectorofcomponents(?n(x))n?N.Letusnow\n",
      "therandomprojection.LetAbeaM?Nmatrixofi.i.d.elementsdrawn\n",
      "forsomedistribution?.Examplesofdistributionsare:?Gaussianrandom\n",
      "variablesN(0,1/M),\n",
      "???Bernoullidistributions,i.e.whichtakesvalues?1/Mwithequal\n",
      "probability1/2,p?Distributiontakingvalues?3/Mwithprobability1/6and0\n",
      "withprobability2/3.Thefollowingresult(proofinthesupplementarymaterial)\n",
      "statesthepropertythatinner-productareapproximatelypreservedthrough\n",
      "randomprojections(thisisasimpleconsequenceoftheJohnsonLindenstrauss\n",
      "Lemma):Proposition1Let(uk)1?k?KandvbevectorsofRN.LetAbe\n",
      "aM?Nmatrixofi.i.d.elementsdrawnfromoneofthepreviously\n",
      "distributions.Forany?>0,?>0,forM??21?3log4K?,wehave,with\n",
      "probabilityatleast1??,forallk?K,4\n",
      "?\n",
      "6\n",
      "|Auk?Av?uk?v|??||uk||||v||.3\n",
      "def\n",
      "4\n",
      "\n",
      "WenowintroducethesetofMcompressedfeatures(?m)1?m?Msuchthat\n",
      "?m(x)=PNWealsowrite?(x)theM-vectorofcomponents(?m(x))m?M\n",
      ".Thusn=1Am,n?n(x).PMdef?(x)=A?(x).Wethecompressed\n",
      "domainGM=\n",
      "f\n",
      "g?=m=1?m?m,??RM\n",
      "g\n",
      "thespanofthecompressed\n",
      "features(vectorspaceofdimensionatmostM).Notethateach?m?FN,thus\n",
      "GMisasubspaceofFN.2.1\n",
      "Approximationerror\n",
      "Wenowcomparetheapproximationerrorassessedinthecompresseddomain\n",
      "GMversusintheinitialspaceFN.Thisappliestothelinearalgorithmsmen-\n",
      "tionedintheintroductionsuchasordinaryLSregression(analyzedindetails\n",
      "inSection3),butalsoitspenalizedversions,e.g.LASSOandridgeregression.\n",
      "?+=argmin??RNL(f?)?L(f?)theparameterofthebestregression\n",
      "functioninFN.Theorem1Forany?>0,anyM?15log(8K/?),letAbea\n",
      "randomM?NmatrixlikeinProposition1,andGMbethecompressed\n",
      "domainresultingfromthischoiceofA.Thenwithprobabilityatleast1??,r\n",
      "8log(8K/?)+2log4/??222inf||g?f||P?||?||E\n",
      "||?(X)||+2sup||?(x)||+inf||f?f?||2P.g?GMf?FN\n",
      "M2Kx?X(2)Thistheoremshowstheintermsofestimationand\n",
      "approximationerrorsforanestimatorgbobtainedinthecompresseddomain\n",
      "comparedtoanestimatorfbobtainedintheinitialdomain:?Boundsonthe\n",
      "estimationerrorofgbinGMareusuallysmallerthanthatoffbinFNwhen\n",
      "M<N(sincethecapacityofFNislargerthanthatofGM).?Theorem1says\n",
      "thattheapproximationerrorassessedinGMincreasesbyatmostO(log(K/?)\n",
      ")||?+||2E||?(X)||2comparedtothatinFN.Mdef\n",
      "def\n",
      "Proof:Letuswritef+=f?+=argminf?FN||f?f?||Pandg+\n",
      "=gA?+.TheapproximationerrorassessedinthecompresseddomainGMis\n",
      "boundedasinf||g?f?||2P\n",
      "g?GM\n",
      "?\n",
      "||g+?f?||2P=||g+?f+||2P+||f+?f?||2P,\n",
      "(3)\n",
      "sincef+istheorthogonalprojectionoff?onFNandg+belongstoFN.\n",
      "Wenowbound||g+?def\n",
      "def\n",
      "f+||2Pusingconcentrationinequalities.Z(x)=A?+?A?(x)?\n",
      "?+??(x).?2=log(8K/?)8Mlog(8K/?).ForM?15log(8K/?)we\n",
      "have?<3/4thusM??2/4??3/6.Proposition1appliesandsaysthatonan\n",
      "eventEofprobabilityatleast1??/2,wehaveforallk?K,def\n",
      "|Z(xk)|??||?+||||?(xk)||??||?+||sup||?(x)||\n",
      "=C\n",
      "(4)\n",
      "x?X\n",
      "OntheeventE,wehavewithprobabilityatleast1??0,+\n",
      "||g?\n",
      "f+||2P\n",
      "5\n",
      "\n",
      "=\n",
      "??\n",
      "K1XEX?PX|Z(X)|?|Z(xk)|2+C2K\n",
      "r\n",
      "log(2/?0)2Kk=1rK1Xlog(2/?0)?2||?+||2||?(xk)||2\n",
      "+sup||?(x)||2K2Kx?Xk=1r\n",
      "log(2/?0)?2||?+||2E||?(X)||2+2sup||?(x)||2.2K\n",
      "x?X2\n",
      "whereweappliedtwotimesinequality.Combining\n",
      "with(3),unconditioning,andsetting?0=?/2thenwithprobabilityatleast\n",
      "(1??/2)(1??0)?1??wehave(2).\n",
      "4\n",
      "2.2\n",
      "Computationalissues\n",
      "Wenowdiscusstherelativecomputationalcostsofagivenalgorithmapplied\n",
      "eitherintheinitialorinthecompresseddomain.LetuswriteCx(DK,FN,\n",
      "P)thecomplexity(e.g.numberofelementaryoperations)ofanalgorithmA\n",
      "tocomputetheregressionfunctionfbwhenprovidedwiththedataDKand\n",
      "functionspaceFN.Weplotinthetablebelow,bothfortheinitialandthe\n",
      "compressedversionsofthealgorithmA,theorderofcomplexityfor(i)thecost\n",
      "forbuildingthefeaturematrix,(ii)thecostforcomputingtheestimator,(iii)the\n",
      "costformakingoneprediction(i.e.computingfb(x)foranyx):Construction\n",
      "ofthefeaturematrixComputingtheregressionfunctionMakingoneprediction\n",
      "InitialdomainNKCx(DK,FN,P)N\n",
      "CompresseddomainNKMCx(DK,GM,P)NM\n",
      "Notethatthevaluesmentionedforthecompresseddomainareupper-bounds\n",
      "ontherealcomplexityanddonottakeintoaccountthepossiblesparsityofthe\n",
      "projectionmatrixA(whichwouldspeedupmatrixcomputations,seee.g.[2,\n",
      "1]).\n",
      "3\n",
      "CompressedLeast-SquaresRegression\n",
      "WenowanalyzethespcaseofLeast-SquaresRegression.3.1\n",
      "ExcessriskofordinaryLeastSquaresregression\n",
      "Inordertoboundtheestimationerror,wefollowtheapproachof[13]which\n",
      "truncates(uptothelevel?LwhereLisabound,assumedtobeknown,on\n",
      "||f?||?)thepredictionoftheLSregressionfunction.TheordinaryLS\n",
      "regressionprovidestheregressionfunctionf?bwhere?b=\n",
      "argmin\n",
      "||?||.\n",
      "??argmin?0?RN||Y???0||\n",
      "Notethat??T?b=?TY,hence?b=??Y?RNwhere??isthePenrose\n",
      "pseudo-inverseof?1.defThenthetruncatedpredictoris:fbL(x)=TL[f?b\n",
      "(x)],where\n",
      "uif|u|?L,defTL(u)=Lsign(u)otherwise.Truncationafterthecom-\n",
      "putationoftheparameter?b?RN,whichisthesolutionofanunconstrained\n",
      "optimizationproblem,iseasierthansolvinganoptimizationproblemunderthe\n",
      "6\n",
      "\n",
      "constraintthat||?||issmall(whichistheapproachfollowedin[23])and\n",
      "allowsforconsistencyresultsandpredictionbounds.Indeed,theexcessriskof\n",
      "fbLisboundedas1+logKE(||fb?f?||2P)?c0max\n",
      "f\n",
      "?2,L2\n",
      "g\n",
      "N+8\n",
      "inf||f?f?||2P(5)f?FNKwhereaboundonc0is9216(see[13]).We\n",
      "haveasimplerboundwhenweconsidertheexpectationEYconditionallyon\n",
      "theinputdata:NEY(||fb?f?||2PK)??2+inf||f?f?||2PK\n",
      "(6)Kf?FRemark:Notethatbecauseweusethequadraticlossfunction,by\n",
      "followingtheanalysisin[3],orbyderivingtightboundsontheRademacher\n",
      "complexity[14]andfollowingTheorem5.2ofKoltchinskii?sSaintFlourcourse,\n",
      "itisactuallypossibletostateassumptionsunderwhichwecanremovethelogK\n",
      "termin(5).Wewillnotfurtherdetailsuchboundssinceourmotivationhereis\n",
      "nottoprovidethetightestpossiblebounds,butrathertoshowhowtheexcess\n",
      "riskboundforLSregressionintheinitialdomainextendstothecompressed\n",
      "domain.1\n",
      "Inthefullrankcase,??=(?T?)?1?TwhenK?Nand??=?T(??T)?1\n",
      "whenK?N\n",
      "5\n",
      "3.2\n",
      "CompressedLeast-SquaresRegression(CLSR)\n",
      "CLSRisastheordinaryLSRinthecompresseddomain.Let?b=??\n",
      "Y?RM,where?istheK?Mmatrixwithelements(?m(xk))1?m?M,1?k?K\n",
      ".TheCLSRestimateisasdef\n",
      "gbL(x)=TL[g?b(x)].FromTheorem1,(5)and(6),wededucethefollowing\n",
      "excessriskboundsfortheCLSRestimate:?q||?+||E||?(X)||2\n",
      "Klog(8K/?)Corollary1Forany?>0,setM=8max(?,L)c0(1+logK).\n",
      "ThenwheneverM?15log(8K/?),withprobabilityatleast1??,theexpected\n",
      "excessriskoftheCLSRestimateisboundedasrp?(1+logK)log(8K/?)?\n",
      "2+E(||bgL?f||P)?16c0max\n",
      "f\n",
      "?,L\n",
      "g\n",
      "||?||E||?(X)||2Kr\n",
      "2log4/?supx||?(x)||+8inf||f?f?||2P.(7)?1+f\n",
      "?FNE||?(X)||22K?||?+||E||?(X)||2pNowsetM=8K\n",
      "log(8K/?).AssumeN>Kandthatthefeatures(?k)1?k?K?arelinearly\n",
      "independent.ThenwheneverM?15log(8K/?),withprobabilityatleast1?\n",
      "?,theexpectedexcessriskoftheCLSRestimateconditionallyontheinput\n",
      "samplesisupperboundedasrrp2log(8K/?)supx||?(x)||2log4/?\n",
      "?2+21+.EY(||bgL?f||PK)?4?||?||E||?(X)||\n",
      "KE||?(X)||22KProof:WheneverM?15log(8K/?)wededucefrom\n",
      "Theorem1and(5)thattheexcessriskofgbLisboundedas\n",
      "E(||bgL?f?||2P)?c0max\n",
      "f\n",
      "?2,L2\n",
      "g\n",
      "1+logKMK\n",
      "h8log(8K/?)\n",
      "+8||?+||2E||?(X)||2+2sup||?(x)||2Mx\n",
      "r\n",
      "ilog4/?+inf||f?f?||2P.f?FN2K\n",
      "ByoptimizingonM,wededuce(7).Similarly,using(6)wededucethe\n",
      "followingboundonEY(||bgL?f?||2PK):r\n",
      "7\n",
      "\n",
      "8log4/?+22M22+log(8K/?)||?||E||?(X)||+2sup\n",
      "||?(x)||+inf||f?f?||2PK.?f?FNKM2KxByoptimizingon\n",
      "Mandnoticingthatinff?FN||f?f?||2PK=0wheneverN>Kand\n",
      "thefeatures(?k)1?k?Karelinearlyindependent,wededucethesecondresult.\n",
      "Remark1Notethatthesecondtermintheparenthesisof(7)isnegligible\n",
      "wheneverKlog1/?.Thuswehavetheexpectedexcessrisk\n",
      "plogK/?E(||bgL?f?||2P)=O||?+||E||?(X)||2?+\n",
      "inf||f?f?||2P.(8)f?FNKThechoiceofMinthepreviouscorollary\n",
      "dependson||?+||andE||?(X)||whichareaprioriunknown(since\n",
      "f?andPXareunknown).IfwesetMindependentlyof||?+||,thenan\n",
      "additionalmultiplicativefactorof||?+||appearsinthebound,andifwe\n",
      "replaceE||?(X)||byitsboundsupx||?(x)||(whichisknown)then\n",
      "thislatterfactorwillappearinsteadoftheformerinthebound.Complexity\n",
      "ofCLSR:ThecomplexityofLSRforcomputingtheregressionfunctioninthe\n",
      "com2presseddomainonlydependsonMandK,andis(seee.g.[4])Cx(DK\n",
      ",GM,P)=O(M?K)which5/2isoforderO(K)whenwechoosethe\n",
      "optimizednumberofprojectionsM=O(K).Howevertheleadingtermwhen\n",
      "usingCLSRisthecostforbuildingthe?matrix:O(NK3/2).6\n",
      "44.1\n",
      "DiscussionpThefactor||?+||E||?(X)||2\n",
      "InlightofCorollary1,theimportantpfactorwhichwilldeterminewhether\n",
      "theCLSRprovideslowgeneralizationerrorornotis||?+||E||?(X)||2\n",
      ".Thisfactorindicatesthatagoodsetoffeatures(forCLSR)shouldbesuch\n",
      "thatthenormofthosefeaturesaswellasthenormoftheparameter?+ofthe\n",
      "projectionoff?ontothespanofthosefeaturesshouldbesmall.Anatural\n",
      "questioniswhetherthisproductcanbemadesmallforappropriatechoicesof\n",
      "features.Wenowprovidetwospcasesforwhichthisisactuallythecase:\n",
      "(1)whenthefeaturesarerescaledorthonormalbasisfunctions,and(2)when\n",
      "thefeaturesarespwaveletfunctions.Inbothcases,werelatetheboundto\n",
      "anassumptionofregularityonthefunctionf?,andshowthatthedependency\n",
      "w.r.t.Ndecreaseswhentheregularityincreases,andmayevenvanish.Rescaled\n",
      "OrthonormalFeatures:Considerasetoforthonormalfunctions(?i)i?1w.r.ta\n",
      "measure?,i.e.h?i,?ji?=?i,j.Inadditionweassumethatthelawofthe\n",
      "inputdataisdominatedby?,i.e.PX?C?whereCisaconstant.Forinstance,\n",
      "thisisthecasewhenthesetXiscompact,?istheuniformmeasureandPX\n",
      "hasboundeddensity.def\n",
      "WethesetofNfeaturesas:?i=ci?i,whereci>0,fori?\n",
      "f\n",
      "1,.\n",
      "..,N\n",
      "g\n",
      ".ThenPNPNbidefanyf?FNdecomposesasf=i=1hf,?ii?i\n",
      "=i=1ci?i,wherebi=hf,?ii.ThusPNbi2PN2R2PN22wehave:\n",
      "||?||2=i=1(ci)andE||?||=i=1ciX?i(x)dPX(x)?Ci=1ci\n",
      ".ThusPPNN||?+||2E||?||2?Ci=1(cbii)2i=1c2i.Now,\n",
      "linearapproximationtheory(Jackson-typetheorems)tellsusthatassuminga\n",
      "functionf??L2(?)issmooth,itmaybedecomposedontothespanofthe\n",
      "N(?i)i?\n",
      "f\n",
      "1,...,N\n",
      "g\n",
      "functionswithdecreasingcots|bi|?i??for\n",
      "some??0thatdependsonthesmoothnessoff?.Forexampletheclassof\n",
      "functionswithboundedtotalvariationmaybedecomposedwithFourierbasis\n",
      "8\n",
      "\n",
      "(indimension1)withcots|bi|?||f||V/(2?i).Thushere?=\n",
      "1.Otherclasses(suchasSobolevspaces)leadtolargervaluesof?relatedto\n",
      "theorderoftiability.p?PNBychoosingci=i??/2,wehave||?+\n",
      "||E||?||2?Ci=1i??.Thusif?>1,thenthistermisbounded\n",
      "byaconstantthatdoesnotdependonN.If?=1thenitisboundedby\n",
      "O(logN),andif0<?<1,thenitisboundedbyO(N1??).pHoweverany\n",
      "orthonormalbasis,evenrescaled,wouldnotnecessarilyyieldasmall||?+\n",
      "||E||?||2term(thisisallthemoretruewhenthedimensionofXis\n",
      "large).Thedesiredpropertythatthecots(?+)iofthedecompositionof\n",
      "f?rapidlydecreaseto0indicatesthathierarchicalbases,suchaswavelets,that\n",
      "woulddecomposethefunctionattscales,maybeinteresting.Wavelets:\n",
      "Consideranfamilyofwaveletsin[0,1]:(?0n)=(?0h,l)(indexedby\n",
      "n?1orequivalentlybythescaleh?0andtranslation0?l?2h?1)where\n",
      "?0h,l(x)=2h/2?0(2hx?l)and?0isthemotherwavelet.ThenconsiderN\n",
      "=2Hfeatures(?h,l)1?h?Hastherescaleddef\n",
      "wavelets?h,l=ch2?h/2?0h,l,wherech>0aresomecots.Assume\n",
      "themotherwaveletPisCp(forp?1),hasatleastpvanishingmoments,and\n",
      "thatforallh?0,supxl?0(2hx?l)2?1.Thenthefollowingpresult(proofin\n",
      "thesupplementarymaterial)providesaboundonsupx?X||?(x)||2(thus\n",
      "onE||?(X)||2)byaconstantindependentofN:Proposition2Assume\n",
      "thatf?is(L,?)-Lipschitz(i.e.forallv?Xthereexistsapolynomialpvof\n",
      "degreeb?csuchthatforallu?X,|f(u)?pv(u)|?L|u?v|?)with\n",
      "1/2<??p.ThensettingR1?ch=2h(1?2?)/4,wehave||?+||supx\n",
      "||?(x)||?L1?221/2??0|?0|,whichisindependentofN.Notice\n",
      "thattheHaarwalevetshasp=1vanishingmomentbutisnotC1,thusthe\n",
      "Propositiondoesnotapplydirectly.Howeverdirectcomputationsshowthatif\n",
      "f?isL-Lipschitz(i.e.?=1)then0?h,l?L2?3h/2?2,andthus||?+||\n",
      "supx||?(x)||?4(1?2L?1/2)withch=2?h/4.7\n",
      "4.2\n",
      "ComparisonwithothermethodspInthecasewhenthefactor||?+||\n",
      "E||?(X)||2doesnotdependonN(suchasinthepreviousexample),the\n",
      "bound(8)ontheexcesserror(assessedin?riskofCLSRstatesthatthe\n",
      "estimation?termsofFN)ofCLSRisO(logK/K).Itisclearthatwhenever\n",
      "N>K(whichisthecaseofinteresthere),thisisbetterthantheordinaryLSR\n",
      "intheinitialdomain,whoseestimationerrorisO(NlogK/K).Itis\n",
      "tocomparethisresultwithLASSO(ortheDantzigselectorthathassimilar\n",
      "properties[5])forwhichanimportantaspectistodesignsparseregression\n",
      "functionsortorecoverasolutionassumedtobesparse.From[12,15,24]one\n",
      "deducesthatundersomeassumptions,theestimationerrorofLASSOisoforder\n",
      "SlogKNwhereSisthesparsity(numberofnon-zerocots)ofthe?best\n",
      "regressorf+inFN.IfS<KthenLASSOismoreinterestingthanCLSRin\n",
      "termsofexcessrisk.OtherwiseCLSRmaybeaninterestingalternativealthough\n",
      "thismethoddoesnotmakeanyassumptionaboutthesparsityoff+andits\n",
      "goalisnottorecoverapossiblesparsef+butonlytomakegoodpredictions.\n",
      "However,insomesenseourmethodasparsesolutioninthefactthatthe\n",
      "regressionfunctiongbLliesinaspaceGMofsmalldimensionMNandcanthus\n",
      "9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beexpressedusingonlyMcots.Nowintermsofnumericalcomplexity,\n",
      "CLSRrequiresO(NK3/2)operationstobuildthematrixandcomputethe\n",
      "regressionfunction,whereasaccordingto[18],the(heuristical)complexityof\n",
      "theLASSOalgorithmisO(NK2)inthebestcases(assumingthatthenumber\n",
      "ofstepsrequiredforconvergenceisO(K),whichisnotprovedtheoretically).\n",
      "ThusCLSRseemstobeagoodandsimplecompetitortoLASSO.\n",
      "5\n",
      "Conclusion\n",
      "WeconsideredthecasewhenthenumberoffeaturesNislargerthanthe\n",
      "numberofdataK.TheresultstatedinTheorem1enablestoanalyzetheexcess\n",
      "riskofanylinearregressionalgorithm(LSoritspenalizedversions)performed\n",
      "inthecompresseddomainGMversusintheinitialspaceFN.Inthecompressed\n",
      "domaintheestimationerrorisreducedbutanadditional(controlled)approx-\n",
      "imationerror(whencomparedtothepbestregressorinFN)comesintothe\n",
      "picture.InthecaseofLS2hasamilddependencyonN,thenbychoosing\n",
      "aregression,whentheterm||?+||E||?(X)||?randomsubspace\n",
      "ofdimension?M=O(K),CLSRhasanestimationerror(assessedinterms\n",
      "ofFN)boundedbyO(logK/K)andhasnumericalcomplexityO(NK3/2).\n",
      "Inshort,CLSRprovidesanalternativetousualpenalizationtechniqueswhere\n",
      "oneselectsarandomsubspaceoflowerdimensionandthenperformsan\n",
      "empiricalriskminimizerinthissubspace.Furtherworkneedstobedonepto\n",
      "provideadditionalsettings(whenthespaceXisofdimension>1)forwhich\n",
      "theterm||?+||E||?(X)||2issmall.Acknowledgements:Theau-\n",
      "thorswishtothankLaurentJacquesfornumerouscommentsandAlessandro\n",
      "LazaricandMohammadGhavamzadehforexcitingdiscussions.Thisworkhas\n",
      "beensupportedbyFrenchNationalResearchAgency(ANR)throughCOSINUS\n",
      "program(projectEXPLO-RA,ANR-08-COSI-004).\n",
      "2References\n",
      "[1]DimitrisAchlioptas.Database-friendlyrandomprojections:Johnson-Lindenstrauss\n",
      "withbinarycoins.JournalofComputerandSystemSciences,66(4):671?687,\n",
      "June2003.[2]NirAilonandBernardChazelle.Approximatenearestneigh-\n",
      "borsandthefastJohnsonLindenstrausstransform.InSTOC?06:Proceed-\n",
      "ingsofthethirty-eighthannualACMsymposiumonTheoryofcomputing,\n",
      "pages557?563,NewYork,NY,USA,2006.ACM.[3]Jean-YvesAudibertand\n",
      "OlivierCatoni.Riskboundsinlinearregressionthroughpac-bayesiantrunca-\n",
      "tion.TechnicalReportHAL:hal-00360268,2009.[4]DavidBauIIIandLloyd\n",
      "N.Trefethen.Numericallinearalgebra.Philadelphia:SocietyforIndustrial\n",
      "andAppliedMathematics,1997.8\n",
      "[5]PeterJ.Bickel,Ya?acovRitov,andAlexandreB.Tsybakov.Simultane-\n",
      "ousanalysisofLassoandDantzigselector.ToappearinAnnalsofStatistics,\n",
      "2008.[6]AvrimBlum.Randomprojection,margins,kernels,andfeature-\n",
      "selection.Subspace,LatentStructureandFeatureSelection,pages52?68,2006.\n",
      "[7]RobertCalderbank,SinaJafarpour,andRobertSchapire.Compressedlearn-\n",
      "10\n",
      "\n",
      "ing:Universalsparsedimensionalityreductionandlearninginthemeasurement\n",
      "domain.TechnicalReport,2009.[8]EmmanuelCandesandTerenceTao.The\n",
      "Dantzigselector:Statisticalestimationwhenpismuchlargerthann.Annalsof\n",
      "Statistics,35:2313,2007.[9]EmmanuelJ.CandesandJustinK.Romberg.Sig-\n",
      "nalrecoveryfromrandomprojections.volume5674,pages76?86.SPIE,2005.\n",
      "[10]S.S.Chen,D.L.Donoho,andM.A.Saunders.Atomicdecomposition\n",
      "bybasispursuit.SIAMJournalonScienComputing,20:33?61,1998.[11]\n",
      "MarkA.Davenport,MichaelB.Wakin,andRichardG.Baraniuk.Detection\n",
      "andestimationwithcompressivemeasurements.TechnicalReportTREE0610,\n",
      "DepartmentofElectricalandComputerEngineering,RiceUniversity,2006.[12]\n",
      "E.GreenshteinandY.Ritov.Persistencyinhighdimensionallinearpredictor-\n",
      "selectionandthevirtueofover-parametrization.Bernoulli,10:971?988,2004.\n",
      "[13]L.M.Kohler,A.Krzy?zak,andH.Walk.Adistribution-freethe-\n",
      "oryofnonparametricregression.Springer-Verlag,2002.[14]ShamM.Kakade,\n",
      "KarthikSridharan,andAmbujTewari.Onthecomplexityoflinearpredic-\n",
      "tion:Riskbounds,marginbounds,andregularization.InDaphneKoller,Dale\n",
      "Schuurmans,YoshuaBengio,andLeonBottou,editors,NeuralInformation\n",
      "ProcessingSystems,pages793?800.MITPress,2008.[15]YuvalNardiand\n",
      "AlessandroRinaldo.OntheasymptoticpropertiesofthegroupLassoestima-\n",
      "torforlinearmodels.Electron.J.Statist.,2:605?633,2008.[16]D.Pollard.\n",
      "ConvergenceofStochasticProcesses.SpringerVerlag,NewYork,1984.[17]\n",
      "AliRahimiandBenjaminRecht.Randomfeaturesforlarge-scalekernelma-\n",
      "chines.NeuralInformationProcessingSystems,2007.[18]SaharonRosset\n",
      "andJiZhu.Piecewiselinearregularizedsolutionpaths.AnnalsofStatistics,\n",
      "35:1012,2007.[19]RobertTibshirani.Regressionshrinkageandselectionvia\n",
      "theLasso.JournaloftheRoyalStatisticalSociety,SeriesB,58:267?288,1994.\n",
      "[20]A.N.Tikhonov.Solutionofincorrectlyformulatedproblemsandthereg-\n",
      "ularizationmethod.SovietMathDokl4,pages1035?1038,1963.[21]Yaakov\n",
      "TsaigandDavidL.Donoho.Compressedsensing.IEEETrans.Inform.The-\n",
      "ory,52:1289?1306,2006.[22]VladimirN.Vapnik.Thenatureofstatistical\n",
      "learningtheory.Springer-VerlagNewYork,Inc.,NewYork,NY,USA,1995.\n",
      "[23]TongZhang.Coveringnumberboundsofcertainregularizedlinearfunc-\n",
      "tionclasses.JournalofMachineLearningResearch,2:527?550,2002.[24]Tong\n",
      "Zhang.SomesharpperformanceboundsforleastsquaresregressionwithL1\n",
      "regularization.ToappearinAnnalsofStatistics,2009.[25]ShuhengZhou,\n",
      "JohnD.y,andLarryA.Wasserman.Compressedregression.InJohn\n",
      "C.Platt,DaphneKoller,YoramSinger,andSamT.Roweis,editors,Neural\n",
      "InformationProcessingSystems.MITPress,2007.\n",
      "9\n",
      "11\n",
      "\n",
      "PP6045.pdf\n",
      "PP6045.pdf 11\n",
      "Learningshapecorrespondencewithanisotropic\n",
      "convolutionalneuralnetworks\n",
      "Authoredby:\n",
      "JonathanMasci\n",
      "DavideBoscaini\n",
      "EmanueleRodol?\n",
      "MichaelBronstein\n",
      "Abstract\n",
      "Convolutionalneuralnetworkshaveachievedextraordinaryresultsin\n",
      "manycomputervisionandpatternrecognitionapplications;however,their\n",
      "adoptioninthecomputergraphicsandgeometryprocessingcommunities\n",
      "islimitedduetothenon-Euclideanstructureoftheirdata.Inthispaper,\n",
      "weproposeAnisotropicConvolutionalNeuralNetwork(ACNN),agen-\n",
      "eralizationofclassicalCNNstonon-Euclideandomains,whereclassical\n",
      "convolutionsarereplacedbyprojectionsoverasetoforientedanisotropic\n",
      "kernels.WeuseACNNstoelylearnintrinsicdensecorre-\n",
      "spondencesbetweendeformableshapes,afundamentalproblemingeome-\n",
      "tryprocessing,arisinginawidevarietyofapplications.WetestedACNNs\n",
      "performanceinverychallengingsettings,achievingstate-of-the-artresults\n",
      "onsomeofthemostrecentcorrespondencebenchmarks.\n",
      "1PaperBody\n",
      "Ingeometryprocessing,computergraphics,andvision,intrinsiccorre-\n",
      "spondencebetween3Dshapesbydrenttransformationsisoneof\n",
      "thefundamentalproblemswithawidespectrumofapplicationsrangingfrom\n",
      "texturemappingtoanimation[25].Ofparticularinterestisthesettinginwhich\n",
      "theshapesareallowedtodeformnon-rigidly.Traditionalhand-craftedcorre-\n",
      "spondenceapproachesaredividedintotwomaincategories:point-wisecorre-\n",
      "spondencemethods[17],whichestablishthematchingbetween(asubsetof)\n",
      "thepointsontwoormoreshapesbyminimizingmetricdistortion,andsoft\n",
      "correspondencemethods[23],whichestablishacorrespondenceamongfunc-\n",
      "tionsovertheshapes,ratherthantheverticesthemselves.Recently,the\n",
      "emergenceof3Dsensingtechnologyhasbroughttheneedtodealwithacqui-\n",
      "sitionartifacts,suchasmissingparts,geometric,andtopologicalnoise,aswell\n",
      "asmatching3Dshapesintrepresentations,suchasmeshesandpoint\n",
      "1\n",
      "\n",
      "clouds.Withnewandbroaderclassesofartifacts,comestheneedoflearning\n",
      "fromdatainvariancethatisotherwiseimpossibletomodelaxiomatically.In\n",
      "thepastyears,wehavewitnessedtheemergenceoflearning-basedapproaches\n",
      "for3Dshapeanalysis.Theattemptswereaimedatlearninglocalshape\n",
      "descriptors[15,5,27],andshapecorrespondence[20].Thedramaticsuccessof\n",
      "deeplearning(inparticular,convolutionalneuralnetworks[8,14])incomputer\n",
      "vision[13]hasledtoarecentkeeninterestinthegeometryprocessingandgraph-\n",
      "icscommunitiestoapplysuchmethodologiestogeometricproblems[16,24,28,\n",
      "4,26].Extrinsicdeeplearning.Manymachinelearningtechniquessuccessfully\n",
      "workingonimagesweretried?asis?on3Dgeometricdata,representedforthis\n",
      "purposeinsomeway?digestible?bystandardframeworks.Suetal.[24]used\n",
      "CNNsappliedtorangeimagesobtainedfrommultipleviewsof3Dobjectsfor\n",
      "retrievalandtasks.Weietal.[26]usedview-basedrepresentation\n",
      "tocorrespondencebetweennon-rigidshapes.Wuetal.[28]usedvolumetric\n",
      "CNNsappliedtorasterizedvolumetricrepresentationof3Dshapes.Themain\n",
      "drawbackofsuchapproachesistheirtreatmentofgeometricdataasEuclidean\n",
      "structures.Suchrepresentationsarenotintrinsic,andvary30thConferenceon\n",
      "NeuralInformationProcessingSystems(NIPS2016),Barcelona,Spain.\n",
      "Figure1:Illustrationofthedrencebetweenextrinsic(left)andintrinsic\n",
      "(right)deeplearningmethodsongeometricdata.Intrinsicmethodsworkon\n",
      "themanifoldratherthanitsEuclideanrealizationandareisometry-invariant\n",
      "byconstruction.astheresultofposeordeformationoftheobject.Forin-\n",
      "stance,inFigure1,thethatrespondstofeaturesonastraightcylinder\n",
      "wouldnotrespondtoabentone.Achievinginvariancetoshapedeformations,\n",
      "acommonrequirementinmanyapplications,isextremelyhardwiththeafore-\n",
      "mentionedmethodsandrequirescomplexmodelsandhugetrainingsetsdueto\n",
      "thelargenumberofdegreesoffreedominvolvedindescribingnon-rigiddefor-\n",
      "mations.Intrinsicdeeplearningapproachestrytoapplylearningtechniques\n",
      "togeometricdatabygeneralizingthemainingredientssuchasconvolutionsto\n",
      "non-Euclideandomains.Inanintrinsicrepresentation,theisappliedto\n",
      "somedataonthesurfaceitself,thusbeinginvarianttodeformationsbyconstruc-\n",
      "tion(seeFigure1).Theintrinsicconvolutionalneuralnetworkarchitecture\n",
      "(GeodesicCNN)waspresentedin[16].Whileproducingimpressiveresultson\n",
      "severalshapecorrespondenceandretrievalbenchmarks,GCNNhasanumber\n",
      "oftdrawbacks.First,thechartingprocedureislimitedtomeshes,\n",
      "andsecond,thereisnoguaranteethatthechartisalwaystopologicallymean-\n",
      "ingful.AnotherintrinsicCNNconstruction(LocalizedSpectralCNN)usingan\n",
      "alternativechartingtechniquebasedonthewindowedFouriertransform[22]\n",
      "wasproposedin[4].Thismethodisageneralizationofapreviouswork[6]\n",
      "onspectraldeeplearningongraphs.OneofthekeyadvantagesofLSCNN\n",
      "isthatthesameframeworkcanbeappliedtotshaperepresentations,\n",
      "inparticular,meshesandpointclouds.Adrawbackofthisapproachisits\n",
      "memoryandcomputationrequirements,aseachwindowneedstobeexplicitly\n",
      "produced.Contributions.WepresentAnisotropicConvolutionalNeuralNet-\n",
      "works(ACNN),amethodforintrinsicdeeplearningonnon-Euclideandomains.\n",
      "Thoughitisagenericframeworkthatcanbeusedtohandlettasks,we\n",
      "2\n",
      "\n",
      "focushereonlearningcorrespondencebetweenshapes.Ourapproachisrelated\n",
      "totwopreviousmethodsfordeeplearningonmanifolds,GCNN[16]andADD\n",
      "[5].Comparedto[5],wherealearnedspectrallterappliedtotheeigenval-\n",
      "uesofanisotropicLaplaceBeltramioperator,weuseanisotropicheatkernelsas\n",
      "spatialweightingfunctionsallowingtoextractalocalintrinsicrepresentation\n",
      "ofafunctiononthemanifold.UnlikeADD,ourACNNisaconvolu-\n",
      "tionalneuralnetworkarchitecture.ComparedtoGCNN,ourconstructionofthe\n",
      "?patchoperator?ismuchsimpler,doesnotdependontheinjectivityradiusof\n",
      "themanifold,andisnotlimitedtotriangularmeshes.Overall,ACNNcombines\n",
      "allthebestpropertiesofthepreviousapproacheswithoutinheritingtheirdraw-\n",
      "backs.WeshowthattheproposedframeworkoutperformsGCNN,ADD,and\n",
      "otherstate-of-the-artapproachesonchallengingcorrespondencebenchmarks.\n",
      "2\n",
      "Background\n",
      "Wemodela3Dshapeasatwo-dimensionalcompactRiemannianmanifold\n",
      "(surface)X.LetTxXdenotethetangentplaneatx,modelingthesurfacelocally\n",
      "asaEuclideanspace.ARiemannianmetricisaninnerproducth?,?iTxX:\n",
      "TxX?TxX!Ronthetangentplane,dependingsmoothlyonx.Quantities\n",
      "whichareexpressibleentirelyintermsofRiemannianmetric,andtherefore\n",
      "independentonthewaythesurfaceisembedded,arecalledintrinsic.Such\n",
      "quantitiesareinvarianttoisometric(metric-preserving)deformations.Heat\n",
      "onmanifoldsisgovernedbytheheatequation,whichhasthemost\n",
      "generalformft(x,t)=\n",
      "divX(D(x)rXf(x,t)),\n",
      "(1)\n",
      "withappropriateboundaryconditionsifnecessary.HererXanddivXdenote\n",
      "theintrinsicgradientanddivergenceoperators,andf(x,t)isthetemperatureat\n",
      "pointxattimet.D(x)isthethermalconductivitytensor(2?2matrix)applied\n",
      "totheintrinsicgradientinthetangentplane.Thisformulationallowsmodeling\n",
      "heatwthatisposition-anddirection-dependent(anisotropic).Andreuxet2\n",
      "al.[1]consideredanisotropicdrivenbythesurfacecurvature.\n",
      "Boscainietal.[5],assumingthatateachpointxthetangentvectorsareex-\n",
      "pressedw.r.t.theorthogonalbasisvm,vMofprincipalcurvaturedirections,\n",
      "usedathermalconductivitytensoroftheform??D??(x)=R?(x)R>(2)\n",
      "?(x),1wherethe2?2matrixR?(x)performsrotationof?w.r.t.tothe\n",
      "maximumcurvaturedirectionvM(x),and?>0isaparametercontrollingthe\n",
      "degreeofanisotropy(?=1correspondstotheclassicalisotropiccase).We\n",
      "refertotheoperator??f(x)\n",
      "=\n",
      "divX(D??(x)rXf(x))\n",
      "astheanisotropicLaplacian,anddenoteby\n",
      "f\n",
      "??i,??i\n",
      "g\n",
      "i0itseigenfunctions\n",
      "andeigenvalues(computed,ifapplicable,withtheappropriateboundarycon-\n",
      "ditions)satisfying????i(x)=??i??i(x).Givensomeinitialheatdistribution\n",
      "f0(x)=f(x,0),thesolutionofheatequation(1)attimetistobtainedby\n",
      "applyingtheanisotropicheatoperatorH??=et??tof0,Ztf(x,t)=H??\n",
      "f0(x)=f0(?)h??t(x,?)d?,(3)X\n",
      "3\n",
      "\n",
      "whereh??t(x,?)istheanisotropicheatkernel,andtheaboveequationcan\n",
      "beinterpretedasanonshift-invariantversionofconvolution.Inthespectral\n",
      "domain,theheatkernelisexpressedasXh??t(x,?)=et??k??k(x)??k(?).\n",
      "(4)k0\n",
      "Appealingtothesignalprocessingintuition,theeigenvaluesplaytheroleof\n",
      "?frequencies?,etactsasalow-pass(largertcorrespondingtolongerdif-\n",
      "fusionresultsinawithanarrowerpassband).Thisconstructionwasused\n",
      "inADD[5]togeneralizetheOSDapproach[15]usinganisotropicheatkernels\n",
      "(consideringthediagonalh??t(x,x)andlearningasetofoptimaltasksp\n",
      "spectralreplacingthelow-passet??k).Discretization.Inthe\n",
      "discretesetting,thesurfaceXissampledatnpointsV=\n",
      "f\n",
      "x1,...,xn\n",
      "g\n",
      ".The\n",
      "pointsareconnectedbyedgesEandfacesF,formingamanifoldtriangular\n",
      "mesh(V,E,F).Toeachtriangleijk2F,weattachanorthonormalreference\n",
      "frame?m,n?),wheren?istheunitnormalvec-hUijk=(?uM,u?M,\n",
      "u?m2R3arethedirectionstortothetriangleanduofprincipalcurvature.\n",
      "Thethermalconductivitytensorforthetriangleijkoperatingontangentis??\n",
      "vectors?1expressedw.r.t.Uijkasa3?3matrix.\n",
      "?mR?uj\n",
      "?mnu?\n",
      "?hje?kje?\n",
      "ij\n",
      "?hie\n",
      "i\n",
      "?kie\n",
      "?MR?u?Mu?ij\n",
      "k\n",
      "0\n",
      "ThediscretizationoftheanisotropicLaplaciantakestheformofann?P\n",
      "nsparsematrixL=S1W.ThemassmatrixSisadiagonalmatrixofarea\n",
      "elementssi=13jk:ijk2FAijk,whereAijkdenotestheareaoftriangleijk.The\n",
      "matrixWiscomposedofweights8??h?ekj,?ekiiH?h?ehj,?ehi\n",
      "iH?><12+(i,j)2E;sinijPsin?ijwij=(5)wi=j;k6=iik>:0else,\n",
      "wheretheisaccordingtotheinsetandtheshearmatrixH?=??\n",
      "notation?>1R?UijkU>Rijk?encodestheanisotropicscalinguptoan\n",
      "orthogonalbasischange.Here0R?denotesthe3?3rotationmatrix,rotating\n",
      "thebasisvectorsUijkoneachtrianglearoundthe?byangle?.normaln3\n",
      "3\n",
      "Intrinsicdeeplearning\n",
      "Thispaperdealswiththeextensionofthepopularconvolutionalneuralnet-\n",
      "works(CNN)[14]tonon-Euclideandomains.ThekeyfeatureofCNNsisthe\n",
      "convolutionallayer,implementingtheideaof?weightsharing?,whereinasmall\n",
      "setoftemplatesisappliedtotpartsofthedata.Inimageanal-\n",
      "ysisapplications,theinputintotheCNNisafunctionrepresentingpixelvalues\n",
      "givenonaEuclideandomain(plane);duetoshift-invariancetheconvolution\n",
      "canbethoughtofaspassingatemplateacrosstheplaneandrecordingthecor-\n",
      "relationofthetemplatewiththefunctionatthatlocation.Oneofthemajor\n",
      "4\n",
      "\n",
      "problemsinapplyingthesameparadigmtonon-Euclideandomainsisthelack\n",
      "ofshift-invariance,thetemplatenowhastobelocation-dependent.Amongthe\n",
      "recentattemptstodevelopintrinsicCNNsonnon-Euclideandomain[6,4,16],\n",
      "themostrelatedtoourworkisGCNN[16].Thelatterapproachwasintro-\n",
      "ducedasageneralizationofCNNtotriangularmeshesbasedongeodesiclocal\n",
      "patches.Thecoreofthismethodistheconstructionoflocalgeodesicpolar\n",
      "coordinatesusingaprocedurepreviouslyemployedforintrinsicshapecontext\n",
      "descriptors[12].Thepatchoperator(D(x)f)(?,?)inGCNNmapsthevalues\n",
      "ofthefunctionfaroundvertexxintothelocalpolarcoordinates?,?,leading\n",
      "totheofthegeodesicconvolutionZ(f?a)(x)\n",
      "=\n",
      "max\n",
      "?2[0,2?)\n",
      "a(?+\n",
      "?,?)(D(x)f)(?,?)d?d?,\n",
      "(6)\n",
      "whichfollowstheideaofmultiplicationbytemplate,butisedupto\n",
      "arbitraryrotation?2[0,2?)duetotheambiguityintheselectionoftheorigin\n",
      "oftheangularcoordinate.Theauthorsproposetotakethemaximumoverall\n",
      "possiblerotationsofthetemplatea(?,?)toremovethisambiguity.Here,and\n",
      "inthefollowing,fissomefeaturevectorthatisedonthesurface(e.g.\n",
      "texture,geometricdescriptors,etc.)\n",
      "Thereareseveraldrawbackstothisconstruction.First,thechartingmethod\n",
      "reliesonafastmarchinglikeprocedurerequiringatriangularmesh.Whilerel-\n",
      "ativelyinsensitivetotriangulation[12],itmayfailifthemeshisveryirregular.\n",
      "Second,theradiusofthegeodesicpatchesmustbetlysmallcompared\n",
      "totheinjectivityradiusoftheshape,otherwisetheresultingpatchisnotguar-\n",
      "anteedtobeatopologicaldisk.Inpractice,thislimitsthesizeofthepatches\n",
      "onecansafelyuse,orrequiresanadaptiveradiusselectionmechanism.\n",
      "4\n",
      "Anisotropicconvolutionalneuralnetworks\n",
      "ThekeyideaoftheAnisotropicCNNpresentedinthispaperisthecon-\n",
      "structionofapatchoperatorusinganisotropicheatkernels.Weinterpretheat\n",
      "kernelsaslocalweightingfunctionsandconstructRh??t(x,?)f(?)d?(D?(x)f\n",
      ")(?,t)=XR,(7)h(x,?)d?X??tforsomeanisotropylevel?>1.Thisway,\n",
      "thevaluesoffaroundpointxaremappedtoalocalsystemofcoordinates(?,\n",
      "t)thatbehaveslikeapolarsystem(heretdenotesthescaleoftheheatkernel\n",
      "and?isitsorientation).WeintrinsicconvolutionasZ(f?a)(x)=a(?,\n",
      "t)(D?(x)f)(?,t)dtd?,(8)\n",
      "NotethatunlikethearbitrarilyorientedgeodesicpatchesinGCNN,necessi-\n",
      "tatingtotakeamaximumoverallthetemplaterotations(6),inourconstruction\n",
      "itisnaturaltousetheprincipalcurvaturedirectionasthereference?=0.Such\n",
      "anapproachhasafewmajoradvantagescomparedtopreviousintrinsicCNN\n",
      "models.First,beingaspectralconstruction,ourpatchoperatorcanbeapplied\n",
      "toanyshaperepresentation(likeLSCNNandunlikeGCNN).Second,being\n",
      "inthespatialdomain,thepatchesandtheresultingtershaveaclear\n",
      "5\n",
      "\n",
      "geometricinterpretation(unlikeLSCNN).Third,ourconstructionaccountsfor\n",
      "localdirectionalpatterns(likeGCNNandunlikeLSCNN).Fourth,theheat\n",
      "kernelsarealwayswellindependentlyoftheinjectivityradiusofthe\n",
      "manifold(unlikeGCNN).WesummarizethecomparativeadvantagesinTable\n",
      "1.ACNNarchitecture.SimilarlytoEuclideanCNNs,ourACNNconsistsof\n",
      "severallayersthatareappliedsubsequently,i.e.theoutputoftheprevious\n",
      "layerisusedastheinputintothesubsequentone.4\n",
      "MethodOSD[15]ADD[5]RF[20]GCNN[16]SCNN[6]LSCNN[4]ACNN\n",
      "Repr.AnyAnyAnyMeshAnyAnyAny\n",
      "InputGeometryGeometryAnyAnyAnyAnyAny\n",
      "GeneralizableYesYesYesYesNoYesYes\n",
      "FiltersSpectralSpectralSpectralSpatialSpectralSpectralSpatial\n",
      "ContextNoNoNoYesYesYesYes\n",
      "DirectionalNoYesNoYesNoNoYes\n",
      "TaskDescriptorsAnyCorrespondenceAnyAnyAnyAny\n",
      "Table1:Comparisonofdrentintrinsiclearningmodels.OurACNN\n",
      "modelcombinesallthebestpropertiesoftheothermodels.NotethatOSDand\n",
      "ADDarelocalspectraldescriptorsoperatingwithintrinsicgeometricinforma-\n",
      "tionoftheshapeandcannotbeappliedtoarbitraryinput,unliketheRandom\n",
      "Forest(RF)andconvolutionalmodels.ACNN,asanyconvolutionalnetwork,is\n",
      "appliedinapoint-wisemanneronafunctiondenedonthemanifolds,produc-\n",
      "ingapoint-wiseoutputthatisinterpretedassoftcorrespondence,asdescribed\n",
      "below.OurintrinsicconvolutionallayerICQ,withQoutputmaps,is\n",
      "asfollowsandreplacestheconvolutionallayerusedinclassicalEuclideanCNNs\n",
      "withtheconstruction(8).TheICQlayercontainsPQarrangedinbanks\n",
      "(PinQbanks);eachbankcorrespondstoanoutputdimension.The\n",
      "areappliedtotheinputasfollows,fqout(x)=\n",
      "PXp=1\n",
      "(fpin?aqp)(x),\n",
      "q=1,...,Q,\n",
      "(9)\n",
      "whereaqp(?,t)arethelearnablecotsofthepthintheqth\n",
      "bank.Avisualizationofsuchisavailableinthesupplementary\n",
      "material.Overall,theACNNarchitecturecombiningseverallayersoft\n",
      "type,actsasanon-linearparametricmappingoftheformf?(x)ateachpointx\n",
      "oftheshape,where?denotesthesetofalllearnableparametersofthenetwork.\n",
      "Thechoiceoftheparametersisdonebyanoptimizationprocess,minimizinga\n",
      "task-spcost,andcanthusberathergeneral.Here,wefocusonlearning\n",
      "shapecorrespondence.LearningcorrespondenceFindingcorrespondenceina\n",
      "collectionofshapescanbecastasalabellingproblem,whereonetriestolabel\n",
      "eachvertexofagivenqueryshapeXwiththeindexofacorrespondingpoint\n",
      "onsomereferenceshapeY[20].Letnandmdenotethenumberofverticesin\n",
      "XandY,respectively.Forapointxonaqueryshape,theoutputofACNN\n",
      "f?(x)ism-dimensionalandisinterpretedasaprobabilitydistribution(?soft\n",
      "correspondence?)onY.Theoutputofthenetworkatallthepointsofthe\n",
      "queryshaperepresentstheprobabilityofxmappedtoy.Letusdenotebyy?\n",
      "6\n",
      "\n",
      "(x)theground-truthcorrespondenceofxonthereferenceshape.Weassumeto\n",
      "beprovidedwithexamplesofpointsfromshapesacrossthecollectionandtheir\n",
      "ground-truthcorrespondence,T=\n",
      "f\n",
      "(x,y?(x))\n",
      "g\n",
      ".Theoptimalparametersof\n",
      "thenetworkarefoundbyminimizingthemultinomialregressionlossX`reg(?)\n",
      "=logf?(x,y?(x)).(10)(x,y?(x))2T\n",
      "5\n",
      "Results\n",
      "Inthissection,weevaluatetheproposedACNNmethodandcompareitto\n",
      "state-of-the-artapproaches.AnisotropicLaplacianswerecomputedaccording\n",
      "to(5).Heatkernelswerecomputedinthefrequencydomainusingallthe\n",
      "eigenpairs.Inallexperiments,weusedL=16orientationsandtheanisotropy\n",
      "parameter?=100.NeuralnetworkswereimplementedinTheano[2].The\n",
      "ADAM[11]stochasticoptimizationalgorithmwasusedwithinitiallearningrate\n",
      "of103,1=0.9,and2=0.999.Astheinputtothenetworks,weusedthelocal\n",
      "SHOTdescriptor[21]with544dimensionsandusingdefaultparameters.For\n",
      "allexperiments,trainingwasdonebyminimizingtheloss(10).Forshapeswith\n",
      "6.9Kvertices,Laplaciancomputationandeigendecompositiontook1secand4\n",
      "secondsperangle,respectivelyonadesktopworkstationwith64GbofRAMand\n",
      "i7-4820KCPU.Forwardpropagationofthetrainedmodeltakesapproximately\n",
      "0.5sectoproducethedensesoftcorrespondenceforallthevertices.5\n",
      "%correspondences\n",
      "1\n",
      "0\n",
      "10\n",
      "cm20\n",
      "30\n",
      "40\n",
      "0.80.6\n",
      "BIMLSCNNRFADDGCNNACNN\n",
      "0.40.20\n",
      "0\n",
      "0.050.10.15%geodesicdiameterGeodesicerror\n",
      "0.2\n",
      "1\n",
      "1\n",
      "0.8\n",
      "0.8\n",
      "0.6\n",
      "0.6\n",
      "0.4\n",
      "0.4RFPFMACNN\n",
      "0.20\n",
      "0.050.10.15%geodesicdiameterGeodesicerror\n",
      "RFPFMACNN\n",
      "0.20.2\n",
      "0\n",
      "7\n",
      "\n",
      "0.050.10.15%geodesicdiameterGeodesicerror\n",
      "0.2\n",
      "Figure2:Performanceoftcorrespondencemethods,lefttoright:\n",
      "FAUSTmeshes,SHREC?16Partialcutsandholes.Evaluationofthecor-\n",
      "respondencewasdoneusingthePrincetonprotocol.Fullmeshcorrespon-\n",
      "denceWeusedtheFAUSThumansdataset[3],containing100meshesof10\n",
      "scannedsubjects,eachin10tposes.Theshapesinthecollectionman-\n",
      "ifeststrongnon-isometricdeformations.Vertex-wisegroundtruthcorrespon-\n",
      "denceisknownbetweenalltheshapes.ThezerothFAUSTshapecontain-\n",
      "ing6890verticeswasusedasreference;foreachpointonthequeryshape,\n",
      "theoutputofthenetworkrepresentsthesoftcorrespondenceasa6890di-\n",
      "mensionalvectorwhichwasthenconvertedtopointcorrespondencewiththe\n",
      "techniqueexplainedinSection4.First80shapesfortrainingandthere-\n",
      "maining20fortesting,followingverbatimthesettingsof[16].Batchnor-\n",
      "malization[9]allowedtoeelytrainlargeranddeepernetworks.For\n",
      "thisexperiment,weadoptedthefollowingarchitectureinspiredbyGCNN[16]:\n",
      "FC64+IC64+IC128+IC256+FC1024+FC512+Softmax.Thesoftcorrespondences\n",
      "producedbythenetwereusingfunctionalmap[18].Werefertothe\n",
      "supplementarymaterialforthedetails.WecomparetoRandomForests(RF)\n",
      "[20],BlendedIntrinsicMaps(BIM)[10],LocalizedSpectralCNN(LSCNN)[4],\n",
      "andAnisotropicDescriptors(ADD)[5].Figure2(left)showsthe\n",
      "performanceoftmethods.Theperformancewasevaluatedusingthe\n",
      "Princetonprotocol[10],plottingthepercentageofmatchesthatareatmost\n",
      "r-geodesicallydistantfromthegroundtruthcorrespondenceonthereference\n",
      "shape.Twoversionsoftheprotocolconsiderintrinsicallysymmetricmatches\n",
      "ascorrect(symmetricsetting,solidcurves)orwrong(asymmetric,morechal-\n",
      "lengingsetting,dashedcurves).Somemethodsbasedonintrinsicstructures\n",
      "(e.g.LSCNNorRFappliedonWKSdescriptors)areinvariantunderintrin-\n",
      "sicsymmetriesandthuscannotdistinguishbetweensymmetricpoints.The\n",
      "proposedACNNmethodclearlyoutperformsallthecomparedapproachesand\n",
      "alsoperfectlydistinguishessymmetricpoints.Figure3showsthepointwise\n",
      "geodesicerroroftcorrespondencemethods(distanceofthecorrespon-\n",
      "denceatapointfromthegroundtruth).ACNNshowsdramaticallysmaller\n",
      "distortionscomparedtoothermethods.Over60%ofmatchesareexact(zero\n",
      "geodesicerror),whileonlyafewpointshavegeodesicerrorlargerthan10%\n",
      "ofthegeodesicdiameteroftheshape1.Pleaserefertothesupplementary\n",
      "materialforanadditionalvisualizationofthequalityofthecorrespondences\n",
      "obtainedwithACNNintermsoftexturetransfer.PartialcorrespondenceWe\n",
      "usedtherecentverychallengingSHREC?16PartialCorrespondencebenchmark\n",
      "[7],consistingofnearly-isometricallydeformedshapesfromeightclasses,with\n",
      "tpartsremoved.Twotypesofpartialityinthebenchmarkarecuts(re-\n",
      "movalofafewlargeparts)andholes(removalofmanysmallparts).Ineach\n",
      "class,thevertex-wisegroundtruthcorrespondencebetweenthefullshapeand\n",
      "itspartialversionsisgiven.Thedatasetwassplitintotrainingandtesting\n",
      "disjointsets.Forcuts,trainingwasdoneon15shapesperclass;forholes,\n",
      "trainingwasdoneon10shapesperclass.WeusedthefollowingACNNarchi-\n",
      "8\n",
      "\n",
      "tecture:IC32+FC1024+DO(0.5)+FC2048+DO(0.5)+Softmax.Thesoftcorre-\n",
      "spondencesproducedbythenetwereusingpartialfunctionalcorrespon-\n",
      "dence[19].Werefertothesupplementarymate1\n",
      "Persubjectleave-one-outproducescomparableresultswithmeanaccuracy\n",
      "of59.6?3.7%.\n",
      "6\n",
      "0.1\n",
      "BlendedIntrinsicMaps\n",
      "0\n",
      "GeodesicCNN\n",
      "AnisotropicCNN\n",
      "Figure3:Pointwisegeodesicerror(in%ofgeodesicdiameter)of\n",
      "entcorrespondencemethods(toptobottom:BlendedIntrinsicMaps,GCNN,\n",
      "ACNN)ontheFAUSTdataset.Errorvaluesaresaturatedat10%ofthe\n",
      "geodesicdiameter.Hotcolorscorrespondtolargeerrors.rialforthedetails.\n",
      "Thedropoutregularization,with?drop=0.5,wascrucialtoavoidov\n",
      "onsuchasmalltrainingset.WecomparedACNNtoRF[20]andPartialFunc-\n",
      "tionalMaps(PFM)[19].Fortheevaluation,weusedtheprotocolof[7],which\n",
      "closelyfollowsthePrincetonbenchmark.Figure2(middle)comparestheper-\n",
      "formanceoftpartialmatchingmethodsontheSHREC?16Partial(cuts)\n",
      "dataset.ACNNoutperformsotherapproacheswithatmargin.Fig-\n",
      "ure4(top)showsexamplesofpartialcorrespondenceonthehorseshapeaswell\n",
      "asthepointwisegeodesicerror.Weobservethattheproposedapproachpro-\n",
      "duceshigh-qualitycorrespondenceseveninsuchachallengingsetting.Figure2\n",
      "(right)comparestheperformanceoftpartialmatchingmethodsonthe\n",
      "SHREC?16Partial(holes)dataset.Inthissettingaswell,ACNNoutperforms\n",
      "otherapproacheswithatmargin.Figure4(bottom)showsexamples\n",
      "ofpartialcorrespondenceonthedogshapeaswellasthepointwisegeodesic\n",
      "error.\n",
      "6\n",
      "Conclusions\n",
      "WepresentedAnisotropicCNN,anewframeworkgeneralizingconvolutional\n",
      "neuralnetworkstonon-Euclideandomains,allowingtoperformdeeplearning\n",
      "ongeometricdata.Ourworkfollowstheveryrecenttrendinbringingmachine\n",
      "learningmethodstocomputergraphicsandgeometryprocessingapplications,\n",
      "andiscurrentlythemostgenericintrinsicCNNmodel.Ourexperimentsshow\n",
      "thatACNNoutperformspreviouslyproposedintrinsicCNNmodels,aswellas\n",
      "additionalstate-of-the-artmethodsintheshapecorrespondenceapplicationin\n",
      "challengingsettings.Beingagenericmodel,ACNNcanbeusedformanyother\n",
      "applications.ThemostpromisingfutureworkdirectionisapplyingACNNto\n",
      "learningongraphs.7\n",
      "0.1\n",
      "AnisotropicCNN\n",
      "0\n",
      "RandomForest\n",
      "0.1\n",
      "9\n",
      "\n",
      "0\n",
      "AnisotropicCNN\n",
      "RandomForest\n",
      "Figure4:ExamplesofpartialcorrespondenceontheSHREC?16Partialcuts\n",
      "(top)andholes(bottom)datasets.Rows1and4:correspondenceproducedby\n",
      "ACNN.Correspondingpointsareshowninsimilarcolor.Referenceshapeis\n",
      "shownontheleft.Rows2,5and3,6:pointwisegeodesicerror(in%of\n",
      "geodesicdiameter)oftheACNNandRFcorrespondence,respectively.Error\n",
      "valuesaresaturatedat10%ofthegeodesicdiameter.Hotcolorscorrespondto\n",
      "largeerrors.\n",
      "8\n",
      "AcknowledgmentsTheauthorswishtothankMatteoSalaforthetextured\n",
      "models.ThisresearchwassupportedbytheERCStartingGrantNo.307047\n",
      "(COMET),aGoogleFacultyResearchAward,andNvidiaequipmentgrant.\n",
      "2References\n",
      "[1]M.Andreux,E.Rodol`a,M.Aubry,andD.Cremers.AnisotropicLaplace-\n",
      "Beltramioperatorsforshapeanalysis.InProc.NORDIA,2014.[2]J.Bergstra\n",
      "etal.Theano:aCPUandGPUmathexpressioncompiler.InProc.SciPy,June\n",
      "2010.[3]F.Bogo,J.Romero,M.Loper,andM.J.Black.FAUST:Datasetand\n",
      "evaluationfor3Dmeshregistration.InProc.CVPR,2014.[4]D.Boscaini,\n",
      "J.Masci,S.Melzi,M.M.Bronstein,U.Castellani,andP.Vandergheynst.\n",
      "Learningclassspdescriptorsfordeformableshapesusinglocalizedspectral\n",
      "convolutionalnetworks.ComputerGraphicsForum,34(5):13?23,2015.[5]D.\n",
      "Boscaini,J.Masci,E.Rodol`a,M.M.Bronstein,andD.Cremers.Anisotropic\n",
      "descriptors.ComputerGraphicsForum,35(2),2016.[6]J.Bruna,W.\n",
      "Zaremba,A.Szlam,andY.LeCun.Spectralnetworksandlocallyconnectednet-\n",
      "worksongraphs.InProc.ICLR,2014.[7]L.Cosmo,E.Rodol`a,M.M.Bron-\n",
      "stein,A.Torsello,D.Cremers,andY.Sahillio?glu.Shrec?16:Partialmatching\n",
      "ofdeformableshapes.InProc.3DOR,2016.[8]K.Fukushima.Neocognitron:\n",
      "Aself-organizingneuralnetworkmodelforamechanismofpatternrecognition\n",
      "byshiftinposition.BiologicalCybernetics,36(4):193?202,1980.[9]\n",
      "S.andC.Szegedy.Batchnormalization:Acceleratingdeepnetworktrain-\n",
      "ingbyreducinginternalcovariateshift.InProc.ICML,pages448?456,2015.\n",
      "[10]V.G.Kim,Y.Lipman,andT.Funkhouser.Blendedintrinsicmaps.TOG,\n",
      "30(4):79,2011.[11]D.P.KingmaandJ.Ba.ADAM:Amethodforstochastic\n",
      "optimization.InICLR,2015.[12]I.Kokkinos,M.M.Bronstein,R.Litman,\n",
      "andA.M.Bronstein.Intrinsicshapecontextdescriptorsfordeformableshapes.\n",
      "InProc.CVPR,2012.[13]A.Krizhevsky,I.Sutskever,andG.E.Hinton.Im-\n",
      "ageNetwithdeepconvolutionalneuralnetworks.InProc.NIPS,\n",
      "2012.[14]Y.LeCun,B.Boser,J.S.Denker,D.Henderson,R.E.Howard,W.\n",
      "Hubbard,andL.D.Jackel.Backpropagationappliedtohandwrittenzipcode\n",
      "recognition.Neuralcomputation,1(4):541?551,1989.[15]R.LitmanandA.M.\n",
      "Bronstein.Learningspectraldescriptorsfordeformableshapecorrespondence.\n",
      "10\n",
      "\n",
      "PAMI,36(1):170?180,2014.[16]J.Masci,D.Boscaini,M.M.Bronstein,and\n",
      "P.Vandergheynst.Geodesicconvolutionalneuralnetworksonriemannianman-\n",
      "ifolds.InProc.3dRR,2015.[17]F.M?emoli.Gromov-WassersteinDistances\n",
      "andtheMetricApproachtoObjectMatching.FoundationsofComputational\n",
      "Mathematics,pages1?71,2011.[18]M.Ovsjanikov,M.Ben-Chen,J.Solomon,\n",
      "A.Butscher,andL.Guibas.Functionalmaps:arepresentationof\n",
      "mapsbetweenshapes.TOG,31(4):1?11,2012.[19]E.Rodol`a,L.Cosmo,M.\n",
      "M.Bronstein,A.Torsello,andD.Cremers.Partialfunctionalcorrespondence.\n",
      "ComputerGraphicsForum,2016.[20]E.Rodol`a,S.RotaBul`o,T.Wind-\n",
      "heuser,M.Vestner,andD.Cremers.Densenon-rigidshapecorrespondence\n",
      "usingrandomforests.InProc.CVPR,2014.[21]S.Salti,F.Tombari,and\n",
      "L.DiStefano.SHOT:uniquesignaturesofhistogramsforsurfaceandtexture\n",
      "description.CVIU,125:251?264,2014.[22]D.IShuman,B.Ricaud,andP.\n",
      "Vandergheynst.Vertex-frequencyanalysisongraphs.arXiv:1307.5708,2013.\n",
      "[23]J.Solomon,A.Nguyen,A.Butscher,M.Ben-Chen,andL.Guibas.Soft\n",
      "mapsbetweensurfaces.ComputerGraphicsForum,31(5):1617?1626,2012.[24]\n",
      "H.Su,S.Maji,E.Kalogerakis,andE.Learned-Miller.Multi-viewconvolutional\n",
      "neuralnetworksfor3Dshaperecognition.InProc.ICCV,2015.[25]O.van\n",
      "Kaick,H.Zhang,G.Hamarneh,andD.Cohen-Or.Asurveyonshapecorre-\n",
      "spondence.ComputerGraphicsForum,20:1?23,2010.[26]L.Wei,Q.Huang,\n",
      "D.Ceylan,E.Vouga,andH.Li.Densehumanbodycorrespondencesusingcon-\n",
      "volutionalnetworks.InProc.CVPR,2016.[27]T.Windheuser,M.Vestner,E.\n",
      "Rodol`a,R.Triebel,andD.Cremers.Optimalintrinsicdescriptorsfornon-rigid\n",
      "shapeanalysis.InProc.BMVC,2014.[28]Z.Wu,S.Song,A.Khosla,etal.\n",
      "3DShapeNets:Adeeprepresentationforvolumetricshapes.InProc.CVPR,\n",
      "2015.\n",
      "9\n",
      "11\n",
      "\n",
      "PP3920.pdf\n",
      "PP3920.pdf 13\n",
      "ReverseMulti-LabelLearning\n",
      "Authoredby:\n",
      "Tib?rioS.Caetano\n",
      "JamesPetterson\n",
      "Abstract\n",
      "Multi-labelisthetaskofpredictingpotentiallymultiple\n",
      "labelsforagiveninstance.Thisiscommoninseveralapplicationssuchas\n",
      "imageannotation,documentandgenefunctionprediction.\n",
      "Inthispaperwepresentaformulationforthisproblembasedonreverse\n",
      "prediction:wepredictsetsofinstancesgiventhelabels.Byviewingthe\n",
      "problemfromthisperspective,themostpopularqualitymeasuresfor\n",
      "assessingtheperformanceofmulti-labeladmitrelaxations\n",
      "thatcanbetlyoptimised.Weoptimisetheserelaxationswith\n",
      "standardalgorithmsandcompareourresultswithseveralstate-of-the-art\n",
      "methods,showingexcellentperformance.\n",
      "1PaperBody\n",
      "Recently,multi-labelclassiation(MLC)hasbeendrawingincreasingatten-\n",
      "tionfromthemachinelearningcommunity(e.g.,[1,2,3,4]).Unlikeinthecase\n",
      "ofmulti-classlearning,inMLCeachinstancemaybelongtomultipleclasses\n",
      "simultaneously.Thisthesituationinmanyrealworldproblems:indoc-\n",
      "umentonedocumentcancovermultiplesubjects;inbiology,a\n",
      "genecanbeassociatedwithasetoffunctionalclasses[5];inimageannotation,\n",
      "oneimagecanhaveseveraltags[6].Asdiverseastheapplications,however,\n",
      "aretheevaluationmeasuresusedtoassesstheperformanceoftmeth-\n",
      "ods.Thatisunderstandable,sincetapplicationshavetgoals.\n",
      "Ine-discoveryapplications[7]itismandatorythatallrelevantdocumentsare\n",
      "retrieved,sorecallisthemostrelevantmeasure.Inwebsearch,ontheother\n",
      "hand,precisionisalsoimportant,sotheF1-score,whichistheharmonicmean\n",
      "ofprecisionandrecall,mightbemoreappropriate.Inthispaperwepresenta\n",
      "methodforMLCwhichisabletooptimiseappropriatesurrogatesforavariety\n",
      "ofperformancemeasures.Thismeansthattheobjectivefunctionbeingopti-\n",
      "misedbythemethodistailoredtotheperformancemeasureonwhichwewant\n",
      "todowellinourspapplication.Thisisincontrastparticularlywithprob-\n",
      "abilisticapproaches,whichtypicallyaimformaximisationoflikelihoodscores\n",
      "ratherthantheperformancemeasureusedtoassessthequalityoftheresults.\n",
      "1\n",
      "\n",
      "Inaddition,themethodisbasedonwell-understoodfactsfromthedomainof\n",
      "structuredoutputlearning,whichgivesustheoreticalguaranteesregardingthe\n",
      "accuracyoftheresultsobtained.Finally,sourcecodeismadeavailablebyus.\n",
      "Aninterestingaspectofthemethodisthatweareonlyabletooptimisethe\n",
      "desiredperformancemeasuresbecauseweformulatethepredictionproblemina\n",
      "reversemanner,inthespiritof[8].Weposethepredictionproblemaspredict-\n",
      "ingsetsofinstancesgiventhelabels.Whenthisinsightisintomax-margin\n",
      "structuredoutputmethods,weobtainsurrogatelossesforthemostwidelyused\n",
      "performancemeasuresformulti-labelWeperformexperiments\n",
      "againststate-of-theartmethodsinepubliclyavailablebenchmarkdatasets\n",
      "forMLC,andtheproposedapproachisthebestperformingoverall.1.1Re-\n",
      "latedWorkTheliteratureinthistopicisvastandwecannotpossiblymake\n",
      "justiceheresinceacomprehensivereviewisclearlyimpractical.Instead,we\n",
      "focusparticularlyonsomestate-of-the-artapproaches1\n",
      "thathavebeentestedonpubliclyavailablebenchmarkdatasetsforMLC,\n",
      "whichfacilitatesafaircomparisonagainstourmethod.Astraightforwardway\n",
      "todealwithmultiplelabelsistosolveabinaryproblemforeach\n",
      "oneofthem,treatingthemindependently.ThisapproachisknownasBinary\n",
      "Method(BM)[9].Chains(CC)[4]extendsthatbybuildingachainof\n",
      "binaryoneforeachpossiblelabel,butwitheachaugmented\n",
      "byallpriorrelevancepredictions.Sincetheorderoftheinthechain\n",
      "isarbitrary,theauthorsalsoproposeanensemblemethod?EnsembleofClas-\n",
      "Chains(ECC)?whereseveralrandomchainsarecombinedwithavoting\n",
      "scheme.ProbabilisticChains(PCC)[1]extendsCCtotheprobabilis-\n",
      "ticsetting,withEPCC[1]beingitscorrespondingensemblemethod.Another\n",
      "wayofworkingwithmultiplelabelsistoconsidereachpossiblesetoflabelsas\n",
      "aclass,thusencodingtheproblemassingle-labelTheproblem\n",
      "withthatistheexponentiallylargenumberofclasses.RAndomK-labELsets\n",
      "(RAKEL)[10]dealswiththatbyproposinganensembleofeachone\n",
      "takingasmallrandomsubsetofthelabelsandlearningasingle-label\n",
      "forthepredictionofeachelementinthepowersetofthissubset.Otherproposed\n",
      "ensemblemethodsareEnsembleofBinaryMethod(EBM)[4],whichappliesa\n",
      "simplevotingschemetoasetofBMandEnsembleofPrunedSets\n",
      "(EPS)[11],whichcombinesasetofPrunedSets(PS)PSisessen-\n",
      "tiallyaproblemtransformationmethodthatmapssetsoflabelstosinglelabels\n",
      "whilepruningawayinfrequentlyoccurringsets.CanonicalCorrelationAnaly-\n",
      "sis(CCA)[3]exploitslabelrelatednessbyusingaprobabilisticinterpretation\n",
      "ofCCAasadimensionalityreductiontechniqueandapplyingittolearnuse-\n",
      "fulpredictivefeaturesformulti-labellearning.MetaStacking(MS)[12]also\n",
      "exploitslabelrelatednessbycombiningtextfeaturesandfeaturesindicatingre-\n",
      "lationshipsbetweenclassesinadiscriminativeframework.Twopapersclosely\n",
      "relatedtooursfromthemethodologicalpointofview,whicharehowevernot\n",
      "tailoredparticularlytothemulti-labellearningproblem,are[13]and[14].In\n",
      "[13]theauthorproposesasmoothbutnon-concaverelaxationoftheF-measure\n",
      "forbinaryproblemsusingalogisticregressionandop-\n",
      "timisationisperformedbytakingthemaximumacrossseveralrunsofBFGS\n",
      "2\n",
      "\n",
      "startingfromrandominitialvalues.In[14]theauthorproposesamethodfor\n",
      "optimisingmultivariateperformancemeasuresinageneralsettinginwhichthe\n",
      "lossfunctionisnotassumedtobeadditiveintheinstancesnorinthelabels.\n",
      "Themethodalsoconsistsofoptimisingaconvexrelaxationofthederivedlosses.\n",
      "Thekeyofourmethodisthatwehaveaspecialisedconvexrelaxation\n",
      "forthecaseinwhichthelossdoesnotdecomposeovertheinstances,butdoes\n",
      "decomposeoverthelabels.\n",
      "2\n",
      "TheModel\n",
      "Lettheinputx?Xdenotealabel(e.g.,atagofanimage),andtheoutput\n",
      "y?Ydenoteasetofinstances,(e.g.,asetoftrainingimages).LetN=|X|\n",
      "bethenumber!oflabelsandVbethenumberofinstances.Aninputlabelx\n",
      "isencodedasx?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "N,s.t.ixi=1.ForexampleifN=5thesecondlabel\n",
      "isdenotedasx=[01000].Anoutputinstanceyisencodedasy?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "V\n",
      "(Y:=\n",
      "f\n",
      "0,1\n",
      "g\n",
      "V),andyin=1instancexnwasannotatedwithlabeli.For\n",
      "exampleifV=10andonlyinstances1and3areannotatedwithlabel2,then\n",
      "theycorrespondingtox=[01000]isy=[1010000000].Weassumea\n",
      "giventrainingset\n",
      "f\n",
      "(xn,yn)\n",
      "g\n",
      "Nn=1,wherenNnN\n",
      "f\n",
      "xn\n",
      "g\n",
      "Nn=1comprises\n",
      "theentiretyoflabelsavailable(\n",
      "f\n",
      "x\n",
      "g\n",
      "n=1=X),and\n",
      "f\n",
      "y\n",
      "g\n",
      "n=1representsthesets\n",
      "ofinstancesassociatedtothoselabels.Thetaskconsistsofestimatingamapf\n",
      ":X?Ywhichreproduceswelltheoutputsofthetrainingset(i.e.,f(xn)?y\n",
      "n)butalsogeneraliseswelltonewtestinstances.2.1\n",
      "LossFunctions\n",
      "Thereasonforthisreversepredictionisthefollowing:mostwidelyaccepted\n",
      "performancemeasurestargetinformationretrieval(IR)applications?thatis,\n",
      "givenalabelwewanttoasetofrelevantinstances.Asaconsequence,the\n",
      "measuresareaveragedoverthesetofpossiblelabels.Thisisthecasefor,in\n",
      "particular,Macro-precision,Macro-recall,Macro-F?1andHammingloss[10]:\n",
      "NN1\"1\"Macro-precision=p(yn,y?n),Macro-recall=r(yn,y?n)\n",
      "Nn=1Nn=11Macro-F1istheparticularcaseofthiswhen?equalsto1.\n",
      "Macro-precisionandmacro-recallareparticularcasesofmacro-F?for??0and\n",
      "???,respectively.\n",
      "2\n",
      "Macro-F?=where\n",
      "N1\"p(yn,y?n)r(yn,y?n)(1+?2)2nn,Nn=1?p(y,y?)+r(y\n",
      "n,y?n)\n",
      "h(y,y?)=\n",
      "yT1+y?T1?2yTy?,V\n",
      "Hammingloss=\n",
      "p(y,y?)=\n",
      "yTy?,y?Ty?\n",
      "N1\"h(yn,y?n),Nn=1\n",
      "r(y,y?)=\n",
      "yTy?.yTy\n",
      "Here,y?nisourpredictionforinputlabeln,andynthecorresponding\n",
      "ground-truth.Sincethesemeasuresaverageoverthelabels,inordertoopti-\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misethemweneedtoaverageoverthelabelsaswell,andthishappensnatu-\n",
      "rallyinasettinginwhichtheempiricalriskisadditiveonthelabels.2Instead\n",
      "ofmaximisingaperformancemeasureweframetheproblemasminimisinga\n",
      "lossfunctionassociatedtotheperformancemeasure.Weassumeaknownloss\n",
      "function?:Y?Y?R+whichassignsanon-negativenumbertoeverypossible\n",
      "pairofoutputs.Thislossfunctionrepresentshowmuchwewanttopenalisea\n",
      "predictiony?whenthecorrectpredictionisy,i.e.,ithastheoppositesemantics\n",
      "ofaperformancemeasure.Asalreadymentioned,wewillbeabletodealwith\n",
      "avarietyoflossfunctionsinthisframework,butforconcretenessofexposition\n",
      "wewillfocusonalossderivedfromtheMacro-F?scoreabove,whose\n",
      "particularcasefor?equalto1(F1)isarguablythemostpopularperformance\n",
      "measureformulti-labelInournotation,theF?scoreofagiven\n",
      "predictionisF?(y,y?)=(1+?2)\n",
      "yTy?,+y?Ty?\n",
      "?2yTy\n",
      "(1)\n",
      "andsinceF?isascoreofalignmentbetweenyandy?,onepossiblechoice\n",
      "forthelossis?(y,y?)=1?F?(y,y?),whichistheonewefocusoninthis\n",
      "paper,?(y,y?)=1?(1+?2)2.2\n",
      "yTy?.+y?Ty?\n",
      "?2yTy\n",
      "(2)\n",
      "FeaturesandParameterization\n",
      "Ournextassumptionisthatthepredictionforagiveninputxreturnsthe\n",
      "maximiser(s)ofalinearscoreofthemodelparametervector?,i.e.,aprediction\n",
      "isgivenbyy?suchthat3y??argmax&?(x,y),?'.\n",
      "(3)\n",
      "y?Y\n",
      "Hereweassumethat?(x,y)islinearlycomposedoffeaturesoftheinstances\n",
      "encodedineachyv,!Vi.e.,?(x,y)=v=1yv(?v?x).Thevector?vis\n",
      "thefeaturerepresentationfortheinstancev.Themap?(x,y)willbethezero\n",
      "vectorwheneveryv=0,i.e.,wheninstancevdoesnothavelabelx.Thefeature\n",
      "map?(x,y)hasatotalofDNdimensions,whereDisthedimensionalityofour\n",
      "instancefeatures(?v)andNisthenumberoflabels.ThereforeDNisthe\n",
      "dimensionalityofourparameter?tobelearned.2.3\n",
      "OptimisationProblem\n",
      "Wearenowreadytoformulateourestimator.Weassumeaninitial,?ideal?\n",
      "estimatortakingtheform#$%&N1\"?2?nnn?=argmin?(?y\n",
      "(x;?),y)+)?).(4)Nn=12?Inotherwords,wewanttoamodel\n",
      "thatminimisestheaveragepredictionlossinthetrainingsetplusaquadratic\n",
      "regulariserthatpenalisescomplexsolutions(theparameter?determinesthe\n",
      "betweendataandgoodgeneralisation).Estimatorsofthistype\n",
      "areknownasregularisedriskminimisers[15].\n",
      "2TheHamminglossalsoaveragesovertheinstancessoitcanbeoptimised\n",
      "inthe?normal?(notreverse)directionaswell.3#A,B$denotestheinner\n",
      "productofthevectorizedversionsofAandB\n",
      "4\n",
      "\n",
      "3\n",
      "33.1\n",
      "OptimisationConvexRelaxation\n",
      "Theoptimisationproblem(4)isnon-convex.Evenmorecritical,thelossis\n",
      "apiecewiseconstantfunctionof?.4Asimilarproblemoccurswhenoneaimsat\n",
      "optimisinga0/1lossinbinaryinthatcase,atypicalworkaround\n",
      "consistsofminimisingasurrogateconvexlossfunctionwhichupperbounds\n",
      "the0/1loss,forexamplethehingeloss,whatgivesrisetothesupportvector\n",
      "machine.Hereweuseananalogousapproach,notablypopularisedin[16],which\n",
      "optimisesaconvexupperboundonthestructuredlossof(4).Theresulting\n",
      "optimisationproblemis#&N\"1?2[??,??]=argmin?n+)?)(5)N\n",
      "n=12?,?s.t.&?(xn,yn),?'?&?(xn,y),?'??(y,yn)??n,?n,y?Y.\n",
      "?n?0\n",
      "(6)\n",
      "Itiseasytoseethat?n?upperbounds?(?y?n,yn)(andthereforethe\n",
      "objectivein(5)upperboundsthatof(4)fortheoptimalsolution).Here,y??n\n",
      ":=argmaxy&?(xn,y),??'.Firstnotethatsincetheconstraints(6)holdfor\n",
      "ally,theyalsoholdfory??n.Second,thelefthandsideoftheinequalityfory\n",
      "=y?nmustbenon-positivefromtheofy?inequation(3).Itthen\n",
      "followsthat?n???(?y?n,yn).\n",
      "Theconstraints(6)basicallyenforcealoss-sensitivemargin:?islearnedso\n",
      "thatmispredictionsythatincursomelossendupwithascore&?(xn,y),?'\n",
      "thatissmallerthanthescore&?(xn,yn),?'ofthecorrectpredictionynbya\n",
      "marginequaltothatloss(minusslack?).Theformulationisageneralisationof\n",
      "supportvectormachinesforthecaseinwhichthereareanexponentialnumber\n",
      "ofclassesy.Itisinthissensethatourapproachissomewhatrelatedinspirit\n",
      "to[10],asmentionedintheIntroduction.However,asdescribedbelow,here\n",
      "wecanuseamethodforselectingapolynomialnumberofconstraintswhich\n",
      "provablyapproximateswelltheoriginalproblem.Theoptimisationproblem(5)\n",
      "hasn|Y|=n2Vconstraints.Naturally,thisnumberistoolargetoallowfor\n",
      "apracticalsolutionofthequadraticprogram.Hereweresorttoaconstraint\n",
      "generationstrategy,whichconsistsofstartingwithnoconstraintsanditeratively\n",
      "addingthemostviolatedconstraintforthecurrentsolutionoftheoptimisation\n",
      "problem.Suchanapproachisassuredtoan'-closeapproximationofthe\n",
      "solutionof(5)afterincludingonlyO('?2)constraints[16].Thekeyproblem\n",
      "thatneedstobesolvedateachiterationisconstraintgeneration,i.e.,to\n",
      "themaximiseroftheviolationmargin?n,yn??argmax[?(y,yn)+&?(xn,\n",
      "y),?'].\n",
      "(7)\n",
      "y?Y\n",
      "Theyinsolvingtheaboveoptimisationproblemdependsonthe\n",
      "choiceof?(x,y)and?.Nextweinvestigatehowthisproblemcanbesolvedfor\n",
      "ourparticularchoicesofthesequantities.3.2\n",
      "Constraintgeneration!VUsingeq.(2)and?(x,y)=v=1yv(?v?x),eq.\n",
      "(7)becomesyn??argmax&y,zn'.\n",
      "(8)\n",
      "5\n",
      "\n",
      "y?Y\n",
      "wherezn=??n?and\n",
      "(1+?2)yn2\n",
      ")y)+?2)yn)\n",
      "??isaV?Dmatrixwithrowvcorrespondingto?v;??nisthenth\n",
      "columnofmatrix?;\n",
      "2,\n",
      "(9)\n",
      "4Thereisacountablenumberoflossvaluesbutanuncountablenumberof\n",
      "parameters,sotherearelargeequivalenceclassesofparametersthatcorrespond\n",
      "topreciselythesameloss.\n",
      "4\n",
      "Algorithm1ReverseMulti-LabelLearning1:Input:trainingset\n",
      "f\n",
      "(xn,y\n",
      "n)\n",
      "g\n",
      "Nn=1,?,?,Output:?2:Initializei=1,?1=0,MAX=??3:repeat\n",
      "4:forn=1toNdo5:Computeyn?(Na??ve:Algorithm2.Improved:See\n",
      "Appendix)6:endfor7:Computegradientgi(equation(12))andobjectiveoi\n",
      "(equation(11))28:?i+1:=argmin??2)?)+max(0,max&gj,?'+oj);i?\n",
      "i+1j?i\n",
      "9:untilconverged(see[18])10:return?\n",
      "Algorithm2Na??veConstraintGeneration?1:Input:(xn,yn),?,?,?,\n",
      "V,Output:yn2:MAX=??3:fork=1toVdo2n(1+?)y4:zn=??n?\n",
      "k+?2%yn%2?5:y=argmaxy?Yk&y,zn'(i.e.topkentriesinznin\n",
      "O(V)time)6:CURRENT=maxy?Yk&y,zn'7:ifCURRENT>MAXthen\n",
      "8:MAX=CURRENT9:yn?=y?10:endif11:endfor?12:returnyn\n",
      "Wenowinvestigatehowtosolve(8)fora?.Forthepurposeofclarity,\n",
      "herewedescribeasimple,na??vealgorithm.Intheappendixwepresentamore\n",
      "involvedbutmuchfasteralgorithm.Asimplealgorithmcanbeobtainedby\n",
      "noticingthatzndependsonyonlythroughthenumberofitsnonzeroelements.\n",
      "Considerthesetofallywithpreciselyknonzeroelements,i.e.,Yk=:2\n",
      "f\n",
      "y:\n",
      ")y)=k\n",
      "g\n",
      ".Thentheobjectivein(8),ifthemaximisationisinsteadrestrictedto\n",
      "thedomainYk,istivelylineariny,sincezninthiscaseisaconstantw.r.t.\n",
      "y.ThereforewecansolveseparatelyforeachYkbyndingthetopkentriesin\n",
      "zn.FindingthetopkelementsofalistofsizeVcanbedoneinO(V)time\n",
      "[17].ThereforewehaveaO(V2)algorithm(foreverykfrom1toV,solve\n",
      "argmaxy?Yk&y,z'inO(V)expectedtime).Algorithm1describesindetail\n",
      "theoptimisation,assolvedbyBMRM[18],andAlgorithm2showsthena??ve\n",
      "constraintgenerationroutine.TheBMRMsolverrequiresboththevalueofthe\n",
      "objectivefunctionfortheslackcorrespondingtothemostviolatedconstraint\n",
      "anditsgradient.Thevalueoftheslackvariablecorrespondingtoyn?is?n?=\n",
      "?(yn?,yn)+&?(xn,yn?),?'?&?(xn,yn),?',(10)thustheobjective\n",
      "functionfrom(5)becomes?1\"2?(yn?,yn)+&?(xn,yn?),?'?&?(xn,\n",
      "yn),?'+)?),(11)Nn2whosegradient(withrespectto?)is???\n",
      "1\"(?(xn,yn)??(xn,yn?)).Nn\n",
      "(12)\n",
      "Weneedbothexpressions(11)and(12)inAlgorithm1.3.3\n",
      "PredictionatTestTime\n",
      "6\n",
      "\n",
      "Theproblemtobesolvedattesttime(eq.(3))hasthesameformasthe\n",
      "problemofconstraintgeneration(eq.(7)),theonlybeingthatzn=\n",
      "??n(i.e.,thesecondtermineq.(9),duetotheloss,isnotpresent).Sincezna\n",
      "constantvector,thesolutionyn?for(7)isthevectorthatindicatesthepositive\n",
      "entriesofzn,whichcanbetlyfoundinO(V).Thereforeinferenceat\n",
      "predictiontimeisveryfast.5\n",
      "Table1:Evaluationscoresandcorrespondinglossesscore?(y,y?)2)(yT\n",
      "y?)macro-F?1?(1+??2yTy+?yTy?macro-precision\n",
      "1?\n",
      "yTy?y?Ty?\n",
      "macro-recall\n",
      "1?\n",
      "yTy?yTy\n",
      "Hammingloss\n",
      "yT1+?yT1?2yTy?V\n",
      "3.4\n",
      "Table2:Datasets.#train/#testdenotesthenumberofobservationsused\n",
      "fortrainingandtestingrespectively;NisthenumberoflabelsandDthedimen-\n",
      "sionalityofthefeatures.datasetdomain#train#testNDyeastbiology1500\n",
      "91714103sceneimage121111966294medicaltext645333451449enron\n",
      "text1123579531001emotionsmusic391202672\n",
      "Otherscores\n",
      "UptonowwehavefocusedonoptimisingMacro-F?,whichalreadygivesus\n",
      "severalscores,inparticularMacro-F1,macro-recallandmacro-precision.We\n",
      "canhoweveroptimiseotherscores,inparticularthepopularHammingloss?\n",
      "Table1showsalistwiththecorrespondingloss,whichwethenplugineq.(4).\n",
      "NotethatforHamminglossandmacro-recallthedenominatorisconstant,and\n",
      "thereforeitisnotnecessarytosolve(8)multipletimesasdescribedearlier,which\n",
      "makesconstraintgenerationasfastastest-timeprediction(seesubsection3.3).\n",
      "4\n",
      "ExperimentalResults\n",
      "Inthissectionweevaluateourmethodinseveralrealworlddatasets,for\n",
      "bothmacro-F?andHammingloss.Thesescoreswerechosenbecausemacro-\n",
      "F?isageneralisationofthemostrelevantscores,andtheHamminglossisa\n",
      "generic,popularscoreinthemulti-labelliterature.DatasetsWe\n",
      "used5publiclyavailable5multi-labeldatasets:yeast,scene,medical,enronand\n",
      "emotions.Weselectedthesedatasetsbecausetheycoveravarietyofapplication\n",
      "domains?biology,image,textandmusic?andtherearepublishedresultsof\n",
      "competingmethodsonthemforsomeofthepopularevaluationmeasuresfor\n",
      "MLC(macro-F1andHammingloss).Table2describestheminmoredetail.\n",
      "ModelselectionOurmodelrequiresonlyoneparameter:?,thebe-\n",
      "tweendataandgoodgeneralisation.Foreachexperimentweselectedit\n",
      "with5-foldcross-validationusingonlythetrainingdata.ImplementationOur\n",
      "implementationisinC++,usingtheBundleMethodsforRiskMinimization\n",
      "(BMRM)of[18]asabase.Sourcecodeisavailable6undertheMozillaPublic\n",
      "7\n",
      "\n",
      "License.7ComparisontopublishedresultsonMacro-F1Inoursetofexper-\n",
      "imentswecomparedourmodeltopublishedresultsontheMacro-F1score.We\n",
      "strivedtomakeourcomparisonasbroadaspossible,butwelimitedourselves\n",
      "tomethodswithpublishedresultsonpublicdatasets,wheretheexperimental\n",
      "settingwasdescribedinenoughdetailtoallowustomakeafaircomparison.\n",
      "WethereforecomparedourmodeltoCanonicalCorrelationAnalysis[3](CCA),\n",
      "BinaryMethod[9](BM),Chains[4](CC),SubsetMapping[19](SM),\n",
      "MetaStacking[12](MS),EnsemblesofBinaryMethod[4](EBM),Ensembles\n",
      "ofChains[4](ECC),EnsemblesofPrunedSets[11](EPS)andRan-\n",
      "domKLabelSubsets[10](RAKEL).Table3summarizesourresults,alongwith\n",
      "competingmethods?whichweretakenfromcompilationsby[3]and[4].We\n",
      "canseethatourmodelhasthebestperformanceinyeast,medicalandenron.\n",
      "In5\n",
      "http://mulan.sourceforge.net/datasets.htmlhttp://users.cecs.anu.edu.au/?jpetterson/.\n",
      "7http://www.mozilla.org/MPL/MPL-1.1.html6\n",
      "6\n",
      "sceneitdoesn?tperformaswell?wesuspectthisisrelatedtothelabel\n",
      "cardinalityofthisdataset:almostallinstanceshavejustonelabel,makingthis\n",
      "essentiallyequivalenttoamulticlassdataset.Comparisontopublishedresults\n",
      "onHammingLossToillustratetheyofourmodelwealsoevaluatedit\n",
      "ontheHammingloss.Here,wecomparedourmodeltochains[4](CC),\n",
      "probabilisticclassichains[1](PCC),ensemblesofchains[4](ECC)\n",
      "andensembledprobabilisticchains[1](EPCC).Thesearethemethods\n",
      "forwhichwecouldHamminglossresultsonpubliclyavailabledata.Table\n",
      "4summarizesourresults,alongwithcompetingmethods?whichweretaken\n",
      "fromacompilationby[1].Ascanbeseen,ourmodelhasthebestperformance\n",
      "onbothdatasets.ResultsonF?Onestrengthofourmethodisthatitcan\n",
      "beoptimisedforthespeccmeasureweareinterestedin.InMacro-F?,for\n",
      "example,?isabetweenprecisionandrecall:when??0werecover\n",
      "precision,andwhen???wegetrecall.Unlikewithothermethods,givena\n",
      "desiredprecision/recallencodedinachoiceof?,wecanoptimiseour\n",
      "modelsuchthatitgetsthebestperformanceonMacro-F?.Toshowthisweran\n",
      "ourmethodonalledatasets,butthistimewithtchoicesof?,ranging\n",
      "from10?2to102.Inthiscase,however,wecouldnotndpublishedresultsto\n",
      "compareto,soweusedMulan8,anopen-sourcelibraryforlearningfrommulti-\n",
      "labeldatasets,totrainthreemodels:BM[9],RAKEL[10]andMLKNN[20].BM\n",
      "waschosenasasimplebaseline,andRAKELandMLKNNarethetwostate-\n",
      "of-the-artmethodsavailableinthepackage.MLKNNhastwoparameters:the\n",
      "numberofneighborskandasmoothingparameterscontrollingthestrengthof\n",
      "theuniformprior.Wekeptbothto10and1.0,respectively,aswasdone\n",
      "in[20].RAKELhasthreeparameters:thenumberofmodelsm,thesizeofthe\n",
      "labelsetkandthethresholdt.Sinceacompletesearchovertheparameterspace\n",
      "wouldbeimpractical,weadoptedthelibrary?sdefaultfortandm(respectively\n",
      "0.5and2?N)andsetktoN2assuggestedby[4].ForBMwekeptthelibrary?s\n",
      "defaults.InFigure1weplottheresults.WecanseethatBMtendstoprioritize\n",
      "recall(rightsideoftheplot),whileML-KNNandRAKELgivemoreemphasis\n",
      "8\n",
      "\n",
      "toprecision(leftside).Ourmethod,however,goeswellinbothsides,asitis\n",
      "trainedseparatelyforeachvalueof?.Inbothsceneandyeastitdominates\n",
      "therightsidewhileisstillcompetitiveontheleftside.Andintheotherthree\n",
      "datasets?medical,enronandemotions?itpracticallydominatesoverthe\n",
      "entirerangeof?.\n",
      "5\n",
      "ConclusionandFutureWork\n",
      "Wepresentedanewapproachtomulti-labellearningwhichconsistsofpre-\n",
      "dictingsetsofinstancesfromthelabels.Thisapparentunintuitiveapproachis\n",
      "infactnaturalsince,oncetheproblemisviewedfromthisperspective,many\n",
      "popularperformancemeasuresadmitconvexrelaxationsthatcanbedirectly\n",
      "andtlyoptimisedwithexistingmethods.Themethodonlyrequires\n",
      "oneparameter,asopposedtomostexistingmethods,whichhaveseveral.The\n",
      "methodleveragesonexistingtoolsfromstructuredoutputlearning,whichgives\n",
      "uscertaintheoreticalguarantees.Asimpleversionofconstraintgenerationis\n",
      "presentedforsmallproblems,butwealsodevelopedascalable,fastversionfor\n",
      "dealingwithlargedatasets.Wepresentedadetailedexperimentalcomparison\n",
      "againstseveralstate-of-the-artmethodsandoverallourperformanceisnotably\n",
      "superior.Afundamentallimitationofourcurrentapproachisthatitdoes\n",
      "nothandledependenciesamonglabels.Itishoweverpossibletoincludesuch\n",
      "dependenciesbyassumingforexampleabivariatefeaturemaponthelabels,\n",
      "ratherthanunivariate.Thishowevercomplicatesthealgorithmics,andisleft\n",
      "assubjectforfutureresearch.\n",
      "AcknowledgementsWethankMiroDud??kaswellastheanonymousre-\n",
      "viewersforinsightfulobservationsthathelpedtoimprovethepaper.NICTA\n",
      "isfundedbytheAustralianGovernmentasrepresentedbytheDepartmentof\n",
      "Broadband,CommunicationsandtheDigitalEconomyandtheAustralianRe-\n",
      "searchCouncilthroughtheICTCentreofExcellenceprogram.8\n",
      "http://mulan.sourceforge.net/\n",
      "7\n",
      "Table3:Macro-F1results.Boldfaceindicatesthebestperformance.We\n",
      "don?thaveresultsforCCAintheMedicalandEnrondatasets.DatasetOurs\n",
      "CCACCBMSMMSECCEBMEPSRAKELYeast0.4400.3460.3460.326\n",
      "0.3270.3310.3620.3640.4200.413Scene0.6710.3740.6960.6850.6660.694\n",
      "0.7420.7290.7630.750Medical0.4200.3770.3640.3210.3700.3860.3820.324\n",
      "0.377Enron0.2430.1980.1970.1440.1980.2010.2010.1550.206Table4:\n",
      "Hamminglossresults.Boldfaceindicatesthebestperformance.DatasetScene\n",
      "Emotions\n",
      "Ours0.12710.2252\n",
      "CC0.17800.2448\n",
      "PCC0.17800.2417\n",
      "ECC0.15030.2428\n",
      "EPCC0.14980.2372scene\n",
      "yeast1\n",
      "10.9\n",
      "0.9ML?KNN\n",
      "9\n",
      "\n",
      "0.8\n",
      "RaKEL\n",
      "0.8\n",
      "BM0.7?\n",
      "0.7\n",
      "macro?F\n",
      "macro?F?\n",
      "Ourmethod\n",
      "0.6\n",
      "0.60.5ML?KNN\n",
      "0.5\n",
      "0.4\n",
      "RaKELBM\n",
      "0.4\n",
      "?2\n",
      "0.3\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "0log(?)\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "Ourmethod\n",
      "0.2?2\n",
      "2\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "medical\n",
      "1\n",
      "1.5\n",
      "2\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "enron\n",
      "0.9\n",
      "0.8ML?KNN\n",
      "0.7\n",
      "ML?KNN\n",
      "0.8\n",
      "RaKEL\n",
      "RaKEL0.7\n",
      "BM\n",
      "10\n",
      "\n",
      "0.6\n",
      "?\n",
      "Ourmethod0.5\n",
      "macro?F\n",
      "macro?F?\n",
      "0.5\n",
      "1\n",
      "0.9\n",
      "0.40.3\n",
      "BMOurmethod\n",
      "0.60.50.40.3\n",
      "0.2\n",
      "0.2\n",
      "0.10?2\n",
      "0log(?)\n",
      "0.1?1.5\n",
      "?1\n",
      "?0.5\n",
      "0log(?)\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "0?2\n",
      "2\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "0log(?)\n",
      "emotions1\n",
      "0.9ML?KNNRaKEL\n",
      "0.8\n",
      "BM\n",
      "macro?F?\n",
      "Ourmethod0.7\n",
      "0.6\n",
      "0.5\n",
      "0.4\n",
      "?2\n",
      "?1.5\n",
      "?1\n",
      "?0.5\n",
      "0log(?)\n",
      "0.5\n",
      "1\n",
      "1.5\n",
      "2\n",
      "11\n",
      "\n",
      "Figure1:Macro-F?resultsonedatasets,with?rangingfrom10?2to102\n",
      "(i.e.,log10?rangingfrom-2to2).Thecenterpoint(log?=0)corresponds\n",
      "tomacro-F1.?controlsabetweenMacro-precision(leftside)and\n",
      "Macro-recall(rightside).\n",
      "8\n",
      "2References\n",
      "[1]KrzysztofDembczynski,WeiweiCheng,andEykeH?ullermeier.BayesOp-\n",
      "timalMultilabelviaProbabilisticChains.InProc.Intl.\n",
      "Conf.MachineLearning,2010.[2]XinhuaZhang,T.Graepel,andRalfHer-\n",
      "brich.BayesianOnlineLearningforMulti-labelandMulti-variatePerformance\n",
      "Measures.InProc.Intl.Conf.onIntelligenceandStatistics,volume\n",
      "9,pages956?963,2010.[3]PiyushRaiandHalDaume.Multi-LabelPredic-\n",
      "tionviaSparseiteCCA.InY.Bengio,D.Schuurmans,J.y,C.K.\n",
      "I.Williams,andA.Culotta,editors,AdvancesinNeuralInformationProcess-\n",
      "ingSystems22,pages1518?1526.2009.[4]JesseRead,BernhardPfahringer,\n",
      "Holmes,andEibeFrank.chainsformulti-label\n",
      "tion.InWrayL.Buntine,MarkoGrobelnik,DunjaMladenic,andJohnShawe-\n",
      "Taylor,editors,ECML/PKDD(2),volume5782ofLectureNotesinComputer\n",
      "Science,pages254?269.Springer,2009.[5]Andr?eandJasonWe-\n",
      "ston.Akernelmethodformulti-labelledInAnnualACMCon-\n",
      "ferenceonResearchandDevelopmentinInformationRetrieval,pages274?281,\n",
      "2005.[6]MatthieuGuillaumin,ThomasMensink,JakobVerbeek,andCordelia\n",
      "Schmid.TagProp:DiscriminativeMetricLearninginNearestNeighborMod-\n",
      "elsforImageAuto-Annotation.InProc.Intl.Conf.ComputerVision,2009.\n",
      "[7]DouglasW.OardandJasonR.Baron.OverviewoftheTREC2008Legal\n",
      "Track.[8]LinliXu,MarthaWhite,andDaleSchuurmans.Optimalreverse\n",
      "prediction.Proc.Intl.Conf.MachineLearning,pages1?8,2009.[9]Grigorios\n",
      "Tsoumakas,IoannisKatakis,andIoannisP.Vlahavas.MiningMulti-labelData.\n",
      "Springer,2009.[10]GrigoriosTsoumakasandIoannisP.Vlahavas.Random\n",
      "k-labelsets:AnensemblemethodformultilabelInProceedings\n",
      "ofthe18thEuropeanConferenceonMachineLearning(ECML2007),pages\n",
      "406?417,Warsaw,Poland,2007.[11]JesseRead,BernhardPfahringer,and\n",
      "Holmes.Multi-labelusingensemblesofprunedsets.In\n",
      "ICDM?08:Proceedingsofthe2008EighthIEEEInternationalConferenceon\n",
      "DataMining,pages995?1000,Washington,DC,USA,2008.IEEEComputer\n",
      "Society.[12]ShantanuGodboleandSunitaSarawagi.Discriminativemethods\n",
      "formulti-labeledInProceedingsofthe8thPConfer-\n",
      "enceonKnowledgeDiscoveryandDataMining,pages22?30.Springer,2004.\n",
      "[13]MartinJansche.MaximumexpectedF-measuretrainingoflogisticregres-\n",
      "sionmodels.HLT,pages692?699,2005.[14]T.Joachims.Asupportvector\n",
      "methodformultivariateperformancemeasures.InProc.Intl.Conf.Machine\n",
      "Learning,pages377?384,SanFrancisco,California,2005.MorganKaufmann\n",
      "Publishers.[15]V.Vapnik.StatisticalLearningTheory.JohnWileyandSons,\n",
      "12\n",
      "\n",
      "NewYork,1998.[16]I.Tsochantaridis,T.Joachims,T.Hofmann,andY.\n",
      "Altun.Largemarginmethodsforstructuredandinterdependentoutputvari-\n",
      "ables.J.Mach.Learn.Res.,6:1453?1484,2005.[17]D.E.Knuth.TheArtof\n",
      "ComputerProgramming:FundamentalAlgorithms,volume1.Addison-Wesley,\n",
      "Reading,Massachusetts,secondedition,1998.[18]ChoonHuiTeo,S.V.N.\n",
      "Vishwanathan,AlexJ.Smola,andQuocV.Le.Bundlemethodsforregu-\n",
      "larizedriskminimization.JournalofMachineLearningResearch,11:311?365,\n",
      "2010.[19]RobertE.SchapireandY.Singer.Improvedboostingalgorithmsus-\n",
      "ingpredictions.MachineLearning,37(3):297?336,1999.[20]\n",
      "Min-LingZhangandZhi-HuaZhou.ML-KNN:Alazylearningapproachto\n",
      "multi-labellearning.PatternRecognition,40(7):2038?2048,July2007.\n",
      "9\n",
      "13\n",
      "\n",
      "PP4083.pdf\n",
      "PP4083.pdf 16\n",
      "BatchBayesianOptimizationviaSimulation\n",
      "Matching\n",
      "Authoredby:\n",
      "AlanFern\n",
      "JavadAzimi\n",
      "XiaoliZ.Fern\n",
      "Abstract\n",
      "Bayesianoptimizationmethodsareoftenusedtooptimizeunknown\n",
      "functionsthatarecostlytoevaluate.Typically,thesemethodssequen-\n",
      "tiallyselectinputstobeevaluatedoneatatimebasedonaposterior\n",
      "overtheunknownfunctionthatisupdatedaftereachevaluation.There\n",
      "areanumberofesequentialpoliciesforselectingtheindividual\n",
      "inputs.Inmanyapplications,however,itisdesirabletoperformmul-\n",
      "tipleevaluationsinparallel,whichrequiresselectingbatchesofmultiple\n",
      "inputstoevaluateatonce.Inthispaper,weproposeanovelapproachto\n",
      "batchBayesianoptimization,providingapolicyforselectingbatchesof\n",
      "inputswiththegoalofoptimizingthefunctionastlyaspossible.\n",
      "Thekeyideaistoexploittheavailabilityofhigh-qualityandtse-\n",
      "quentialpolicies,byusingMonte-Carlosimulationtoselectinputbatches\n",
      "thatcloselymatchtheirexpectedbehavior.Tothebestofourknowledge,\n",
      "thisisthebatchselectionpolicyforBayesianoptimization.Ourex-\n",
      "perimentalresultsonsixbenchmarksshowthattheproposedapproach\n",
      "tlyoutperformstwobaselinesandcanleadtolargeadvantages\n",
      "overatopsequentialapproachintermsofperformanceperunittime.\n",
      "1PaperBody\n",
      "Bayesianoptimizationmethodsareoftenusedtooptimizeunknownfunctions\n",
      "thatarecostlytoevaluate.Typically,thesemethodssequentiallyselectinputsto\n",
      "beevaluatedoneatatimebasedonaposteriorovertheunknownfunctionthat\n",
      "isupdatedaftereachevaluation.Inmanyapplications,however,itisdesirable\n",
      "toperformmultipleevaluationsinparallel,whichrequiresselectingbatchesof\n",
      "multipleinputstoevaluateatonce.Inthispaper,weproposeanovelapproach\n",
      "tobatchBayesianoptimization,providingapolicyforselectingbatchesofinputs\n",
      "withthegoalofoptimizingthefunctionastlyaspossible.Thekeyidea\n",
      "istoexploittheavailabilityofhigh-qualityandtsequentialpolicies,by\n",
      "usingMonte-Carlosimulationtoselectinputbatchesthatcloselymatchtheir\n",
      "1\n",
      "\n",
      "expectedbehavior.Ourexperimentalresultsonsixbenchmarksshowthatthe\n",
      "proposedapproachtlyoutperformstwobaselinesandcanleadtolarge\n",
      "advantagesoveratopsequentialapproachintermsofperformanceperunit\n",
      "time.\n",
      "1\n",
      "Introduction\n",
      "Weconsidertheproblemofmaximizinganunknownfunctionf(x)wheneach\n",
      "evaluationofthefunctionhasahighcost.Insuchcases,standardoptimization\n",
      "techniquessuchasempiricalgradientmethodsarenotpracticalduetothehigh\n",
      "numberoffunctionevaluationsthattheydemand.Rather,Bayesianoptimiza-\n",
      "tion(BO)methods[12,4]havedemonstratedtpromiseintheirability\n",
      "toctivelyoptimizeafunctiongivenonlyasmallnumberofevaluations.BO\n",
      "gainsthisbyleveragingBayesianmodelsthattakeintoaccountallpre-\n",
      "viouslyobservedevaluationsinordertobetterinformfutureevaluationchoices.\n",
      "Inparticular,typicalBOmethodscontinuallymaintainaposterioroverf(x)\n",
      "thatisusedtoselectthenextinputtoevaluate.Theresultoftheevaluationis\n",
      "thenusedtoupdatetheposteriorandtheprocessrepeats.Thereareanumber\n",
      "ofwellestablishedpoliciesforselectingthenextinputtoevaluategiventhecur-\n",
      "rentposterior.Wewillrefertosuchpoliciesassequentialpoliciestostressthe\n",
      "factthattheyselectoneinputatatime.Inmanyapplicationsitispossibleand\n",
      "desirabletorunmultiplefunctionevaluationsinparallel.Thisisthecase,for\n",
      "example,whentheunderlyingfunctioncorrespondstoacontrolledlaboratory\n",
      "experimentwheremultipleexperimentalsetupsareexaminedsimultaneously,\n",
      "orwhentheunderlyingfunctionistheresultofacostlycomputersimulation\n",
      "andmultiplesimulationscanberunacrosstprocessorsinparallel.In\n",
      "suchcases,existingsequentialpoliciesarenott.Rather,batchmode\n",
      "BOismoreappropriate,wherepoliciesselectabatchofmultipleinputstobe\n",
      "evaluatedatonce.Tothebestofourknowledgeandasnotedin[4],thereisno\n",
      "establishedworkonBOthatconsidersthebatchselectionproblem,exceptfor\n",
      "abrieftreatmentin[21].Themaincontributionofthisworkistoproposean\n",
      "approachtobatchBOandtodemonstrateitseness.Thekeymotivation\n",
      "behindourapproachcomesfromthefactthatthesequentialmodeofBOhas\n",
      "afundamentaladvantageoverBOinbatchmode.Thisisbecauseinsequential\n",
      "mode,eachfunctionevaluationisimmediatelyusedtoobtainamoreaccurate\n",
      "posterioroff(x),whichinturnwillallow1\n",
      "aselectionpolicytomakemoreinformedchoicesaboutthenextinput.\n",
      "Givenaneesequentialselectionpolicy,ourgoalisthentodesignabatch\n",
      "policythatapproximatesitsbehavior.Inparticular,ourbatchpolicyattempts\n",
      "toselectabatchthat?matches?theexpectedbehaviorofasequentialpolicy\n",
      "ascloselyaspossible.TheapproachgeneratesMonte-Carlosimulationsofa\n",
      "sequentialpolicygiventhecurrentposterior,andthenderivesanoptimization\n",
      "problemoverpossiblebatchesaimedatminimizingthelossbetweenthesequen-\n",
      "tialpolicyandthebatch.Weconsidertwovariantsofthisoptimizationproblem\n",
      "thatyieldacontinuousweightedk-meansproblemandacombinatorialweighted\n",
      "k-medoidproblem.Wesolvethek-meansvariantviak-meansclusteringand\n",
      "showthatthek-medoidvariantcorrespondstominimizinganon-increasingsu-\n",
      "2\n",
      "\n",
      "permodularfunction,forwhichthereisantapproximationalgorithm\n",
      "[9].Weevaluateourapproachonacollectionofsixfunctionsandcompareitto\n",
      "randomandanotherbaselinebatchpolicybasedonsubmodularmaximization.\n",
      "Theresultsshowthatourapproachtlyoutperformsthesebaselines\n",
      "andcanleadtolargeadvantagesoveratopsequentialapproachintermsof\n",
      "performanceperunittime.\n",
      "2\n",
      "ProblemSetup\n",
      "LetX?Rnbeann-dimensionalinputspace,wherewewilloftenreferto\n",
      "elementsofXasanexperimentandassumethateachdimensioniisboundedin\n",
      "[Ai,Bi].Weassumeanunknownrealvaluedfunctionf:X?R,whichrepre-\n",
      "sentstheexpectedvalueofthedependentvariableafterrunninganexperiment.\n",
      "Forexample,f(x)mightcorrespondtotheresultofawet-labexperimentora\n",
      "computersimulationwithinputparametersx.Conductinganexperimentxpro-\n",
      "ducesanoisyoutcomey=f(x)+,whereisanoisetermthatmightbe0insome\n",
      "applications.Ourobjectiveistoanexperimentx?Xthatapproximately\n",
      "maximizesfbyrequestingalimitednumberofexperimentsandobservingtheir\n",
      "outcomes.Furthermoreweareinterestedinapplicationswhere(1)runningex-\n",
      "perimentsiscostly(e.g.intermsoflaboratoryorsimulationtime);and(2)it\n",
      "isdesirabletorunk>1experimentsinparallel.Thismotivatestheproblemof\n",
      "selectingasequenceofbatches,eachcontainingkexperiments,wherethechoice\n",
      "ofabatchcandependontheresultsobservedfromallpreviousexperiments.\n",
      "Wewillrefertotheruleforselectingabatchbasedonpreviousexperimentsas\n",
      "thebatchpolicy.Themaingoalofthispaperistodevelopabatchpolicythat\n",
      "optimizestheunknownfunctionastlyaspossible.Duetothehighcost\n",
      "ofexperiments,traditionaloptimizationtechniquessuchasempiricalgradient\n",
      "ascentarenotpracticalforoursetting,duetotheirhighdemandsonthenum-\n",
      "berofexperiments.Rather,webuildonBayesianoptimization(BO)[10,12,\n",
      "4],whichleveragesBayesianmodelinginanattempttoachievemorecient\n",
      "optimization.Inparticular,BOmaintainsaposteriorovertheunknownfunc-\n",
      "tionbasedonpreviouslyobservedexperiments,e.g.representedviaaGaussian\n",
      "Process(GP)[19].Thisposteriorisusedtoselectthenextexperimenttobe\n",
      "runinawaythatattemptstoexploringnewpartsoftheexperimental\n",
      "spaceandexploitingpartsthatlookpromising.WhiletheBOliteraturehas\n",
      "providedanumberofectivepolicies,theyareallsequentialpolicies,where\n",
      "onlyasingleexperimentisselectedandrunatatime.Thus,themainnovelty\n",
      "ofourworkisinabatchpolicyinthecontextofBO,whichisdescribed\n",
      "inthenextsection.\n",
      "3\n",
      "SimulationMatchingforBatchSelection\n",
      "GivenadatasetDofpreviouslyobservedexperiments,whichinducesa\n",
      "posteriordistributionovertheunknownfunction,wenowconsiderhowtose-\n",
      "lectthenextbatchofkexperiments.Akeyissueinmakingthischoiceisto\n",
      "managethebetweenexplorationandexploitation.Thepolicymust\n",
      "attempttoexplorebyrequestingexperimentsfromunexploredpartsofthein-\n",
      "putspace,atthesametimealsoattempttooptimizetheunknownfunction\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viaexperimentsthatlookpromisinggiventhecurrentdata.While,undermost\n",
      "measures,optimizingthisiscomputationallyintractable,therearea\n",
      "numberofheuristicsequentialpoliciesfromtheBOliteraturethatarecompu-\n",
      "tationallytandperformverywellinpractice.Forexample,onesuch\n",
      "policyselectsthenextexperimenttobetheonethathasthe?maximumex-\n",
      "pectedimprovement?accordingtothecurrentposterior[14,10].Themainidea\n",
      "behindourapproachistoleveragesuchsequentialpoliciesbyselectingabatch\n",
      "ofk>1experimentsthat?closelymatches?thesequentialpolicy?sexpected\n",
      "behavior.Moreformally,let?beasequentialpolicy.GivenadatasetDof\n",
      "priorexperimentalresults,?returnsthenextexperimentx?Xtobeselected.\n",
      "AsisstandardinBO,weassumewehaveaposterior2\n",
      "densityP(f|D)overtheunknownfunctionf,suchasaGaussianProcess.\n",
      "Giventhisdensitywecanadensityovertheoutcomesofexecutingpolicy\n",
      "?forksteps,eachoutcomeconsistingofasetofkselectedexperiments.LetS?k\n",
      "betherandomvariabledenotingthesetofkexperimentsresultingfromsuchk-\n",
      "stepexecutions,whichhasawelldeneddensityoverallpossiblesetsgiventhe\n",
      "posterioroff.Importantly,itisgenerallystraightforwardtouseMonteCarlo\n",
      "simulationtosamplevaluesofS?k.1Ourbatchpolicyisbasedongeneratinga\n",
      "numberofsamplesofS?k,whichareusedtoanobjectiveforoptimizing\n",
      "abatchofkexperiments.Belowwedescribethisobjectiveandavariant,\n",
      "followedbyadescriptionofhowweoptimizetheproposedobjectives.3.1Batch\n",
      "ObjectiveFunctionOurgoalistoselectabatchBofkexperimentsthatbest\n",
      "?matchestheexpectedbehavior?ofabasesequentialpolicy?conditionedon\n",
      "theobserveddataD.Moreprecisely,weconsiderabatchBtobeagoodmatch\n",
      "forapolicyexecutionifBcontainsanexperimentthatisclosetothebestofthe\n",
      "kexperimentsselectedbythepolicy.Tospecifythisobjectiveweintroduce\n",
      "somenotation.GivenafunctionfandasetofexperimentsS,wex?(f,\n",
      "S)=argmaxx?Sf(x)tobethemaximizeroffinS.Also,foranyexperiment\n",
      "xandsetBwenn(x,B)=argminx0?Bkx?x0ktobethenearest\n",
      "neighborofxinsetB.OurobjectivecannowbewrittenasselectingabatchB\n",
      "thatminimizes\n",
      "OBJ(B)=ES?kEf|S?kkx?(f,S?k)?nn(x?(f,S?k),B)k2|D\n",
      "|D.Notethatthisnestedexpectationistheresultofdecomposingthejoint\n",
      "posterioroverS?kandfasP(f,S?k|D)=P(f|S?k,D)?P(S?k|\n",
      "D).Ifweassumethattheunknownfunctionf(x)isLipschitzcontinuousthen\n",
      "minimizingthisobjectivecanbeviewedasminimizinganupperboundonthe\n",
      "expectedperformancebetweenthesequentialpolicyandtheselected\n",
      "batch.Heretheperformanceofapolicyorabatchisequaltotheoutputvalue\n",
      "ofthebestselectedexperiment.Wewillapproximatethisobjectivebyreplacing\n",
      "theouterexpectationoverS?kwithasampleaverageovernsamples\n",
      "f\n",
      "S1,..\n",
      ".,Sn\n",
      "g\n",
      "ofS?kasfollows,recallingthateachSiisasetofkexperiments:\n",
      "1XOBJ(B)?Ef|Sikx?(f,Si)?nn(x?(f,Si),B)k2|Dni1XX=\n",
      "Pr(x=x?(f,Si)|D,Si)?kx?nn(x,B)k2nix?Si1XX=?i,x?kx?\n",
      "nn(x,B)k2(1)nix?Si\n",
      "Thesecondstepfollowsbynotingthatx?(f,Si)mustbeoneofthek\n",
      "experimentsinSi.Wenowourobjectiveasminimizing(1)overbatch\n",
      "4\n",
      "\n",
      "B.Theobjectivecorrespondstoaweightedk-meansclusteringproblem,where\n",
      "wemustselectBtominimizetheweighteddistortionbetweenthesimulated\n",
      "pointsandtheirclosestpointsinB.Theweightoneachsimulatedexperiment\n",
      "?i,xcorrespondstotheprobabilitythattheexperimentx?Siachievesthe\n",
      "maximumvalueoftheunknownfamongtheexperimentsinSi,conditioned\n",
      "onDandthefactthatS?k=Si.Werefertothisobjectiveasthek-means\n",
      "objective.Wealsoconsideravariantofthisobjectivewherethegoalistonda\n",
      "Bthatminimizes(1)underStheconstraintthatBisrestrictedtoexperiments\n",
      "inthesimulations,i.e.B?iSis.t.|B|=k.Thisobjectivecorrespondsto\n",
      "theweightedk-medoidclusteringproblem,whichisoftenconsideredtoimprove\n",
      "robustnesstooutliersinclustering.Accordinglywewillrefertothisobjective\n",
      "asthek-medoidobjectiveandnotethatgivenasetofsimulationsthis\n",
      "correspondstoadiscreteoptimizationproblem.3.2OptimizationApproach\n",
      "Theabovek-meansandk-medoidobjectivesinvolvetheweights?i,x=P(x=\n",
      "x?i(f)|D,S?k=Si),foreachx?Si.Ingeneraltheseweightswillbe\n",
      "tocomputeexactly,particularly1Forexample,thiscanbedoneby\n",
      "startingwithDandselectingtheexperimentx1using?andthenusingP\n",
      "(f|D)tosimulatetheresulty1ofexperimentx1.Thissimulatedexperiment\n",
      "isaddedtoDandtheprocessrepeatsfork?1additionalexperiments.\n",
      "3\n",
      "Algorithm1GreedyWeightedk-MedoidAlgorithmInput:S=\n",
      "f\n",
      "(x1,w1),.\n",
      "..,(xm,wm)\n",
      "g\n",
      ",kOutput:BB?\n",
      "f\n",
      "x1,...,xm\n",
      "g\n",
      "//initializebatchtoall\n",
      "datapointswhile|B|>kdoPmx?argminx?Bj=1wj?kxj?nn(xj,B\n",
      "x)k//pointthatiobjectivetheleastB?BxendwhilereturnB\n",
      "duetotheconditioningonthesetSi.Inthiswork,weapproximatethose\n",
      "weightsbydroppingtheconditioningonSi,forwhichitisthenpossibletoderive\n",
      "aclosedformwhentheposterioroverfisrepresentedasaGaussianProcess\n",
      "(GP).Wehavefoundthatthisapproachleadstogoodempiricalperformance.\n",
      "Inparticular,insteadofusingtheweights?i,xweusetheweights??i,x=P\n",
      "(x=x?i(f)|D).WhentheposterioroverfisrepresentedasaGP,asinour\n",
      "experiments,thejointdistributionoverexperimentaloutcomesinSi=\n",
      "f\n",
      "xi,1,\n",
      "...,xi,k\n",
      "g\n",
      "isnormallydistributed.Thatis,therandomvectorhf(xi,1),.\n",
      "..,f(xi,k)i?N(?,?),wherethemean?andcovariance?havestandard\n",
      "closedformsgivenbytheGPconditionedonD.Fromthis,itisclearthatfor\n",
      "aGPthecomputationof??i,xisequivalenttocomputingtheprobability\n",
      "thattheithcomponentofanormallydistributedvectorislargerthantheother\n",
      "components.Aclosedformsolutionforthisprobabilityisgivenbythefollowing\n",
      "proposition.\n",
      "Proposition1.If(y1,y2,...,yk)?N?y,?ythenforanyi?\n",
      "f\n",
      "1,...\n",
      ",k\n",
      "g\n",
      ",P(yi?y1,yi?y2,...,yi?yk)=\n",
      "k?1Y\n",
      "(1??(??j))\n",
      "(2)\n",
      "j=1\n",
      "?1where?(.)isstandardnormalcdf,?=(?1,?2,???,?k?1)=A?y\n",
      "A02A?y,suchthatA?R(k?1)?kisasparsematrixthatforanyj=1,2,?\n",
      "5\n",
      "\n",
      "??,k?1wehaveAj,i=1,andforany1?p<iwehaveAp,p=?1,andfor\n",
      "anyi<p?kwehaveAp?1,p=?1.Usingthisapproachtocomputetheweights\n",
      "wecannowconsideroptimizingthek-meansandkmedoidobjectivesfrom(1),\n",
      "bothofwhichareknowntobeNP-hardproblems.Forthek-meansobjective\n",
      "wesolveSforSthesetBbysimplyapplyingthek-meansclusteringalgorithm\n",
      "[13]totheweighteddatasetix?Si\n",
      "f\n",
      "(x,??i,x)\n",
      "g\n",
      ".Thekclustercentersare\n",
      "returnedasourbatchB.Thek-medoidobjectiveiswellknown[22]andthe\n",
      "weightedk-medoidclusteringalgorithm[11]hasbeenshowntoperformwell\n",
      "andberobusttooutliersinthedata.Whilewehaveexperimentedwiththis\n",
      "algorithmandobtainedgoodresults,wehaveachievedresultsthatareasgood\n",
      "orbetterusinganalternativegreedyalgorithmthatprovidescertainapproxi-\n",
      "mationguarantees.Pseudo-codeforthisalgorithmisshowninFigure1.The\n",
      "inputtothealgorithmisthesetofweightedexperimentsandthebatchsizek.\n",
      "ThealgorithminitializesthebatchBtoincludealloftheinputexperiments,\n",
      "whichachievestheminimumobjectivevalueofzero.Thealgorithmtheniter-\n",
      "ativelyremovesoneexperimentfromBatatimeuntil|B|=k,eachtime\n",
      "removingtheelementwhoseremovalresultsinthesmallestincreaseinthek-\n",
      "medoidobjective.Thisgreedyalgorithmismotivatedbytheoreticalresultson\n",
      "theminimizationofnon-increasing,supermodularsetfunctions.1.\n",
      "SupposeSisaset,f:2S?R+isasupermodularsetfunctionifforallB1\n",
      "?B2?Sand\n",
      "f\n",
      "x\n",
      "g\n",
      "?SB2,itholdsthatf(B1)?f(B1?\n",
      "f\n",
      "x\n",
      "g\n",
      ")?f(B2)?f(B2\n",
      "?\n",
      "f\n",
      "x\n",
      "g\n",
      ").Thus,asetfunctionissupermodularifaddinganelementtoasmaller\n",
      "setprovidesnolessimprovementthanaddingtheelementtoalargerset.Also,\n",
      "asetfunctionisnon-increasingifforanysetSandelementxiff(S)?f(S?\n",
      "f\n",
      "x\n",
      "g\n",
      ").Itcanbeshownthatourk-medoidobjectivefunctionof(1)isbothSa\n",
      "non-increasingandsupermodularfunctionofBandachievesaminimumvalue\n",
      "ofzeroforB=iSi.Itfollowsthatwecanobtainanapproximationguarantee\n",
      "forthedescribedgreedyalgorithmin[9].4\n",
      "Theorem1.[9]Letfbeamonotonicnon-increasingsupermodularfunction\n",
      "oversubsetsofthesetS,|S|=mandf(S)=0.LetBbethesetof\n",
      "theelementsreturnedbythegreedyalgorithm1s.t|B|=k,q=m?kand\n",
      "B?=argminB0?S,|B0|=kf(B0),then\n",
      "q1q+tet?1f(B)??1f(B?)?f(B?)(3)tqtwheretisthe\n",
      "steepnessparameter[9]offunctionf.Noticethattheapproximationbound\n",
      "involvesthesteepnessparametertoff,whichcharacterizestherateofdecrease\n",
      "off.Thisisunavoidablesinceitisknownthatachievingaconstantfactor\n",
      "approximationguaranteeisnotpossibleunlessP=NP[17].Furtherthisbound\n",
      "hasbeenshowntobetightforanyt[9].Notethatthisisincontrastto\n",
      "guaranteesforgreedymaximizationofsubmodularfunctions[7]forwhichthere\n",
      "areconstantfactorguarantees.Alsonotethatthegreedyalgorithmweuseis\n",
      "qualitativelytfromtheoneusedforsubmodularmaximization,sinceit\n",
      "greedilyremoveselementsfromBratherthangreedilyaddingelementstoB.\n",
      "4\n",
      "ImplementationDetailsandBaselines\n",
      "GPPosterior.Ourbatchselectionapproachdescribedaboverequiresthat\n",
      "wemaintainaposteriorovertheunknownfunctionf.Forthispurposeweuse\n",
      "6\n",
      "\n",
      "azero-meanGPpriorwithazero-meanGaussiannoisemodelwithvariance\n",
      "equalto0.01.TheGPcovarianceisspbyaGaussian12kernelK(x,x0\n",
      ")=?exp?2wwhereymaxisthekx?x0k2,withsignalvariance?=ymax\n",
      "maximumvalueoftheunknownfunction.Inallofourexperimentsweuseda\n",
      "simpleruleofthumbPdtosetthekernelwidthwto0.01i=1liwhereliisthe\n",
      "inputspacelengthindimensioni.Wehavefoundthisruletoworkwellfora\n",
      "varietyofproblems.Analternativewouldbetouseavalidationbasedapproach\n",
      "forselectingthekernelparameters.IntheBOsetting,however,wehavefound\n",
      "thistobeunreliablesincethenumberofdatapointsisrelativelysmall.Base\n",
      "SequentialPolicy.Ourbatchselectionapproachalsorequiresabasesequential\n",
      "policy?tobeusedforsimulationmatching.Thispolicymustbeabletoselect\n",
      "thenextexperimentgivenanysetofpriorexperimentalobservationsD.Inour\n",
      "experiments,weuseapolicybasedontheMaximumExpectedImprovement\n",
      "(MEI)heuristic[14,10]whichisaverysuccessfulsequentialpolicyforBOand\n",
      "hasbeenshowntoconvergeinthelimittotheglobaloptimum.GivendataD\n",
      "theMEIpolicysimplyselectsthenextexperimenttobetheonethatmaximizes\n",
      "theexpectedimprovementoverthecurrentsetofexperimentswithrespectto\n",
      "maximizingtheunknownfunction.Moreformally,lety?bethevalueofthe\n",
      "best/largestexperimentaloutcomeobservedsofarinD.TheMEIvalueofan\n",
      "experimentxisgivenbyMEI(x)=Ef[max\n",
      "f\n",
      "f(x)?y?,0\n",
      "g\n",
      "|D].ForourGP\n",
      "posterioroverfwe???(x)canderiveaclosedformforthisgivenby:u=y\n",
      "?(x)wherey?isourbestcurrentlyobservedvalue.Foranygivenexamplex,\n",
      "theMEIcanbecomputedasfollows:MEI(x)\n",
      "=\n",
      "?(x)[?u?(?u)+?(u)],\n",
      "u=\n",
      "y???(x)?(x)\n",
      "where?and?arethestandardnormalcumulativedistributionanddensity\n",
      "functionsand?(x)and?(x)arethemeanandvarianceoff(x)accordingtothe\n",
      "GPgivenD,whichhavesimpleclosedforms.Notethatwehavealsoevaluated\n",
      "oursimulation-matchingapproachwithanalternativesequentialpolicyknown\n",
      "asMaximumProbabilityofImprovement[16,10].Theresults(notshownin\n",
      "thispaper)aresimilartothoseobtainedfromMEI,showingthatourgeneral\n",
      "approachworkswellfortbasepolicies.ThecomputationoftheMEI\n",
      "policyrequiresmaximizingMEI(x)overtheinputspaceX.Ingeneral,this\n",
      "functiondoesnothaveauniquelocalmaximumandvariousstrategieshave\n",
      "beentriedformaximizingit.Inourexperiments,we(approximately)maximize\n",
      "theMEIfunctionusingtheDIRECTblack-boxoptimizationprocedure,which\n",
      "hasshowngoodoptimizationperformanceaswellascomputationalin\n",
      "practice.BaselineBatchPolicies.Tothebestofourknowledgethereisnowell-\n",
      "knownbatchpolicyforBayesianoptimization.However,inourexperiments\n",
      "wewillcompareagainsttwobaselines.Thebaselineisrandomselection,\n",
      "whereabatchofkrandomexperimentsisreturnedateachstep.Interestingly,\n",
      "inthecaseofbatchactivelearningfortherandombatchselection\n",
      "strategy5\n",
      "FunctionCosinesRosenbrockMichalewicz\n",
      "7\n",
      "\n",
      "Table1:BenchmarkFunctions.Mathematicalrepresentation1?(u2+v2\n",
      "?0.3cos(3?u)?0.3cos(3?v))u=1.6x?0.5,v=1.6y?0.510?100(y?x2)2\n",
      "?(1?x)2220P5i.x?i=1sin(xi).sin?i\n",
      "hasbeensurprisinglyeandisoftentooutperformwithmore\n",
      "sophisticatedstrategies[8].However,asourexperimentswillshow,ourap-\n",
      "proachwilldominaterandom.Oursecond,moresophisticate,baselineisbased\n",
      "onselectingabatchofexperimentswhoseexpectedmaximumoutputisthe\n",
      "largest.Moreformally,weconsiderselectingasizekbatchBthatmaximizes\n",
      "theobjectiveEf[maxx?Bf(x)|D],whichwewillrefertoastheEMAXobjec-\n",
      "tive.ForourGPprior,eachsetB=\n",
      "f\n",
      "x1,...,xk\n",
      "g\n",
      "canbeviewedas\n",
      "anormallydistributedvectorhf(x1),...,f(xk)i?N(?,?).Eveninthis\n",
      "case,theoptimalsetBisknowntobeNP-hard.However,forthecase\n",
      "wherefisassumedtobenon-negative,theEMAXobjectiveisanon-negative,\n",
      "submodular,non-decreasingfunctionofB.Togetherthesepropertiesimplythat\n",
      "asimplegreedyalgorithmcanachieveanapproximationratioof1?e?1[7].The\n",
      "algorithmstartswithanemptyBandgreedilyaddsexperimentstoB,eachtime\n",
      "selectingtheonethatimprovestheEMAXobjectivethemost.Unfortunately,\n",
      "ingeneralthereisnoclosedformsolutionforevaluatingtheEMAXobjective,\n",
      "eveninourcaseofnormallydistributedvectors[20].Therefore,toimplement\n",
      "thegreedyalgorithm,whichrequiresmanyevaluationsoftheEMAXobjective,\n",
      "weuseMonteCarlosampling,whereforagivensetBwesamplethecorre-\n",
      "spondingnormallydistributedvectorandaveragethemaximumvaluesacross\n",
      "thesamples.\n",
      "5\n",
      "ExperimentalResults\n",
      "InthissectionweevaluateourproposedbatchBOapproachandthebaseline\n",
      "approachesonsixtbenchmarks.5.1BenchmarkFunctionsWeconsider\n",
      "threewell-knownsyntheticbenchmarkfunctions:CosinesandRosenbrock[1,\n",
      "5],whichareover[0,1]2,andMichalewicz[15],whichisover[0,?]5.Table\n",
      "1givestheformulasforeachofthesefunctions.Twoadditionalbenchmark\n",
      "functionsHydrogenandFuelCell,whichrangeover[0,1]2,arederivedfrom\n",
      "real-worldexperimentaldatasets.Inbothcases,thebenchmarkfunctionwas\n",
      "createdbyregressionmodelstodatasetsresultingfromrealexperiments.\n",
      "TheHydrogendatasetistheresultofdatacollectedaspartofastudyon\n",
      "biosolarhydrogenproduction[6],wherethegoalwastomaximizethehydrogen\n",
      "productionofaparticularbacteriabyoptimizingthePHandNitrogenlevels\n",
      "ofthegrowthmedium.TheFuelCelldatasetwascollectedaspartofastudy\n",
      "investigatingtheofanodes?nano-structureonthepoweroutputof\n",
      "microbialfuelcells[3].Theexperimentalinputsincludetheaverageareaand\n",
      "averagecircularityofthenano-particles[18].Contourplotsofthefour2-d\n",
      "functionsareshowninFigure1.Thelastbenchmarkfunctionisderivedfrom\n",
      "theCart-Pole[2]problem,whichisacommonlyusedreinforcementlearning\n",
      "problem.Thegoalistooptimizetheparametersofacontrollerforawheeled\n",
      "cartwiththeobjectiveofbalancingapole.Thecontrollerisparameterizedby\n",
      "fourparametersgivinga4-dspaceofexperimentsin[1,?1]4.Givenasettingfor\n",
      "theseparameters,thebenchmarkfunctionisimplementedbyusingthestandard\n",
      "8\n",
      "\n",
      "Cart-Polesimulatortoreturntherewardreceivedforthecontroller.5.2Results\n",
      "Figures2and3showtheperformanceofourmethodsonallsixbenchmark\n",
      "functionsforbatchsizes5and10respectively.Eachgraphcontains5curves,\n",
      "eachcorrespondingtoatBOapproach(seebelow).Eachcurveisthe\n",
      "resultoftakinganaverageof100independentruns.Thex-axisofeachgraph\n",
      "representsthetotalnumberofexperimentsandthey-axisrepresentstheregret\n",
      "values,wheretheregretofapolicyataparticularpointisthebetween\n",
      "thebestpossibleoutputvalue(oranupperboundifthevalueisnotknown)\n",
      "andthebestvaluefoundbythepolicy.Hencetheregretisalwayspositiveand\n",
      "smallervaluesarepreferred.Eachrunofapolicyinitializesthedatasetto\n",
      "contain5randomlyselectedexperimentsforthe2-dfunctionsand20random\n",
      "initialexperimentsforthehigherdimensionalfunctions.6\n",
      "1\n",
      "1\n",
      "1\n",
      "0.9\n",
      "0.9\n",
      "0.9\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.7\n",
      "0.7\n",
      "0.7\n",
      "0.6\n",
      "0.6\n",
      "0.6\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.4\n",
      "0.4\n",
      "0.3\n",
      "0.3\n",
      "0.3\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.1\n",
      "0.1\n",
      "0\n",
      "0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "9\n",
      "\n",
      "FuelCell\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "0\n",
      "1\n",
      "0.1\n",
      "0\n",
      "0.1\n",
      "Hydrogen\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "0\n",
      "1\n",
      "0\n",
      "0.1\n",
      "Cosines\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1\n",
      "Rosenbrock\n",
      "Figure1:Thecontourplotsforthefour2?dimensionproposedtestfunctions.\n",
      "0.65\n",
      "0.3\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "0.60.550.5\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "0.6\n",
      "0.5\n",
      "0.450.40.35\n",
      "Regret\n",
      "10\n",
      "\n",
      "0.2\n",
      "Regret\n",
      "Regret\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "0.25\n",
      "0.15\n",
      "0.4\n",
      "0.3\n",
      "0.1\n",
      "0.3\n",
      "0.2\n",
      "0.05\n",
      "0.250.210\n",
      "15\n",
      "2025#ofExperimets\n",
      "30\n",
      "010\n",
      "35\n",
      "15\n",
      "2025#ofExperimets\n",
      "FuelCell\n",
      "2025#ofExperimets\n",
      "0.35\n",
      "Cosines\n",
      "700\n",
      "Regret\n",
      "0.15\n",
      "300\n",
      "0.0520025\n",
      "35\n",
      "2.6\n",
      "500\n",
      "0.1\n",
      "30\n",
      "2.7\n",
      "600\n",
      "400\n",
      "2025#ofExperimets\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "2.8\n",
      "0.2\n",
      "35\n",
      "3\n",
      "800\n",
      "0.30.25\n",
      "30\n",
      "11\n",
      "\n",
      "2.9\n",
      "Regret\n",
      "0.4\n",
      "15\n",
      "15\n",
      "HydrogenSequentialk?medoidk?meansEMAXRandom\n",
      "0.45\n",
      "Regret\n",
      "0.110\n",
      "35\n",
      "900\n",
      "0.5\n",
      "010\n",
      "30\n",
      "2.52.42.3\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "50\n",
      "2.22.1\n",
      "75\n",
      "Rosenbrock\n",
      "100125#ofExperimets\n",
      "150\n",
      "175\n",
      "225\n",
      "200\n",
      "30\n",
      "35\n",
      "Cart-Pole\n",
      "40\n",
      "45505560#ofExperimets\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "Michalewicz\n",
      "Figure2:Performanceevaluationwithbatchsize5.0.25\n",
      "0.65Sequentialk?medoidk?meansEMAXRandom\n",
      "0.60.55\n",
      "0.6\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "0.2\n",
      "0.50.45\n",
      "0.4\n",
      "0.15\n",
      "Regret\n",
      "Regret\n",
      "12\n",
      "\n",
      "Regret\n",
      "0.50.45\n",
      "0.25\n",
      "0.3\n",
      "0.05\n",
      "0.2\n",
      "0.25\n",
      "0.1520\n",
      "25#ofExperimets\n",
      "30\n",
      "015\n",
      "35\n",
      "20\n",
      "FuelCell\n",
      "30\n",
      "0.115\n",
      "35\n",
      "20\n",
      "HydrogenSequentialk?medoidk?meansEMAXRandom\n",
      "0.30.25\n",
      "25#ofExperimets\n",
      "30\n",
      "35\n",
      "Cosines3Sequentialk?medoidk?meansEMAXRandom\n",
      "2.9\n",
      "800\n",
      "2.8700\n",
      "2.7600\n",
      "0.15\n",
      "500\n",
      "0.1\n",
      "400\n",
      "0.05\n",
      "300\n",
      "20\n",
      "25#ofExperimets\n",
      "Rosenbrock\n",
      "30\n",
      "35\n",
      "20030\n",
      "Regret\n",
      "0.2\n",
      "Regret\n",
      "Regret\n",
      "25#ofExperimets\n",
      "900\n",
      "13\n",
      "\n",
      "0.35\n",
      "015\n",
      "0.40.350.3\n",
      "0.1\n",
      "0.35\n",
      "0.215\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "0.55\n",
      "2.62.52.4\n",
      "Sequentialk?medoidk?meansEMAXRandom\n",
      "60\n",
      "2.32.290120#ofExperimets\n",
      "150\n",
      "180\n",
      "200\n",
      "2.130\n",
      "40\n",
      "Cart-PoleFigure3:Performanceevaluationwithbatchsize10.7\n",
      "5060#ofExperimets\n",
      "Michalewicz\n",
      "70\n",
      "80\n",
      "Eachgraphgivescurvesforfourbatchapproachesincludingourbaselines\n",
      "RandomandEMAX,alongwithourproposedapproachesbasedonthek-means\n",
      "andk-medoidobjectives,whichareoptimizedbyweightedk-meansclustering\n",
      "andthegreedyAlgorithm1respectively.Inaddition,forreferenceweplotthe\n",
      "performanceofthebaseSequentialMEIBOpolicy(k=1)oneachgraph.\n",
      "Notethatsincethebatchapproachesrequesteither5or10experimentsata\n",
      "time,theircurvesonlycontaindatapointsatthoseintervals.Forexample,\n",
      "forthebatchsize5resultsthepointonabatchcurvecorrespondsto10\n",
      "experiments,includingtheinitial5experimentsandtherequestedbatch.\n",
      "Thenextpointonthebatchcurveisfor15experimentswhichincludesthenext\n",
      "requestedbatchandsoon.RathertheSequentialpolicyhasapointatevery\n",
      "stepsinceitrequestsexperimentsoneatatime.Itisimportanttorealizethat\n",
      "wegenerallyexpectagoodsequentialpolicytodobetter,ornoworse,thana\n",
      "batchpolicywithrespecttoperformancepernumberofexperiments.Thus,the\n",
      "Sequentialcurvecanbetypicallyviewedasanupperperformanceboundand\n",
      "providesanindicationofhowmuchlossisincurredwhenmovingtoabatch\n",
      "settingintermsofperexperiment.ComparisontoBaselines.The\n",
      "majorobservationfromourresultsisthatforallbenchmarksandforbothbatch\n",
      "sizestheproposedk-meansandk-medoidapproachestlyoutperform\n",
      "thebaselines.Thisprovidesstrongvalidationforourproposedsimulation-\n",
      "matchingapproachtobatchselection.k-meansvs.k-medoid.Inmostcases,\n",
      "thek-meansandk-medoidapproachesperformsimilarly.However,forboth\n",
      "batchsizesk-medoidoftendoesshowsasmallimprovementoverk-meansand\n",
      "appearstohaveatadvantageinFuelCell.Theonlyexceptionis\n",
      "14\n",
      "\n",
      "inHydrogenwherekmeansshowsasmalladvantageoverk-medoidforsmall\n",
      "numbersofexperiments.Overall,bothapproachesappeartobeeandin\n",
      "thesedomainsk-medoidhasaslightedge.Batchvs.Sequential.Theadvantage\n",
      "ofSequentialoverourbatchapproachesvarieswiththebenchmark.However,in\n",
      "mostcases,ourproposedbatchapproachescatchuptoSequentialinarelatively\n",
      "smallnumberofexperimentsandinsomecases,thebatchpoliciesaresimilar\n",
      "toSequentialfromthestart.ThemainexceptionisCart-Poleforbatchsize\n",
      "10,wherethebatchpoliciesappeartobetlylesstintermsof\n",
      "performanceversusnumberofexperiments.Generally,weseethatthence\n",
      "betweenourbatchpoliciesandSequentialislargerforbatchsize10thanbatch\n",
      "size5,whichisexpected,sincelargerbatchsizesimplythatlessinformation\n",
      "perexperimentisusedinmakingdecisions.Itisclear,however,thatifwe\n",
      "evaluatetheperformanceofourbatchpoliciesintermsofexperimentaltime,\n",
      "thenthereisaverytadvantageoverSequential.Inparticular,the\n",
      "amountofexperimentaltimeforapolicyisapproximatelyequaltothenumber\n",
      "ofrequestedbatches,assumingthatthebatchsizeisselectedtoallowforall\n",
      "selectedexperimentstoberuninparallel.Thismeans,forexample,thatfor\n",
      "thebatchsize5results,5timestepsforthebatchapproachescorrespondto\n",
      "30totalexperiments(5initial+5batches).Wecancomparethispointto\n",
      "thepointontheSequentialcurve,whichalsocorrespondsto5timesteps\n",
      "(5experimentsbeyondtheinitial5).Inallcases,thebatchpoliciesyielda\n",
      "verylargeimprovementinregretreductionperunittime,whichistheprimary\n",
      "motivationforbatchselection.\n",
      "6\n",
      "SummaryandFutureWork\n",
      "InthispaperweintroducedanovelapproachtobatchBObasedontheidea\n",
      "ofsimulationmatching.Thekeyideaofourapproachistodesignbatchesofex-\n",
      "perimentsthatapproximatelymatchtheexpectedperformanceofhigh-quality\n",
      "sequentialpoliciesforBO.Weconsideredtwovariantsofthematchingprob-\n",
      "lemandshowedthatbothapproachestlyoutperformedtwobaselines\n",
      "includingrandombatchselectiononsixbenchmarkfunctions.Forfuturework\n",
      "weplantoconsiderthegeneralideaofsimulationmatchingforotherproblems,\n",
      "suchasactivelearning,wheretherearealsogoodsequentialpoliciesandbatch\n",
      "selectionisoftenwarranted.Inaddition,weplantoconsiderlessmyopicap-\n",
      "proachesforselectingeachbatchandtheproblemofbatchsizeselection,where\n",
      "thereisachoiceaboutbatchsizethatmusttakeintoaccountthecurrentdata\n",
      "andexperimentalbudget.\n",
      "AcknowledgmentsTheauthorsacknowledgethesupportoftheNSFunder\n",
      "grantsIIS-0905678.8\n",
      "2References\n",
      "[1]B.S.Anderson,A.W.More,andD.Cohn.Anonparametricapproachto\n",
      "noisyandcostlyoptimization.InICML,2000.[2]A.G.Barto,R.S.Sut-\n",
      "ton,andC.W.Anderson.Neuronlikeadaptiveelementsthatcansolve\n",
      "15\n",
      "\n",
      "learningcontrolproblems.13:835?846,1983.[3]D.BondandD.Lovley.Elec-\n",
      "tricityproductionbygeobactersulfurreducensattachedtoelectrodes.Appli-\n",
      "cationsofEnvironmentalMicrobiology,69:1548?1555,2003.[4]E.Brochu,M.\n",
      "Cora,andN.deFreitas.AtutorialonBayesianoptimizationofexpensivecost\n",
      "functions,withapplicationtoactiveusermodelingandhierarchicalreinforce-\n",
      "mentlearning.TechnicalReportTR2009-23,DepartmentofComputerScience,\n",
      "UniversityofBritishColumbia,2009.[5]M.Brunato,R.Battiti,andS.Pa-\n",
      "supuleti.Amemory-basedrashoptimizer.InAAAI-06WorkshoponHeuristic\n",
      "Search,MemoryBasedHeuristicsandTheirapplications,2006.[6]E.H.Bur-\n",
      "rows,W.-K.Wong,X.Fern,F.W.Chaplen,andR.L.Ely.Optimizationof\n",
      "phandnitrogenforenhancedhydrogenproductionbysynechocystissp.pcc\n",
      "6803viastatisticalandmachinelearningmethods.BiotechnologyProgress,\n",
      "25:1009?1017,2009.[7]M.F.GNemhauser,LWolsey.Ananalysisofthe\n",
      "approximationsformaximizingsubmodularsetfunctions.MathematicalPro-\n",
      "grammingn,14:265?294,1978.[8]Y.GuoandD.Schuurmans.Discriminative\n",
      "batchmodeactivelearning.ProceedingsofAdvancesinNeuralInformation\n",
      "ProcessingSystems(NIPS2007),6,2007.[9]V.P.Il?ev.Anapproximation\n",
      "guaranteeofthegreedydescentalgorithmforminimizingasupermodularset\n",
      "function.DiscreteAppliedMathematics,114(1-3):131?146,2001.[10]D.Jones.\n",
      "Ataxonomyofglobaloptimizationmethodsbasedonresponsesurfaces.Journal\n",
      "ofGlobalOptimization,21:345?383,2001.[11]L.KaufmanandP.J.Rousseeuw.\n",
      "Clusteringbymeansofmedoids.StatisticaldataanalysisbasedonL1norm,\n",
      "pages405?416,1987.[12]D.Lizotte.PracticalBayesianoptimization.PhD\n",
      "thesis,UniversityofAlberta,2008.[13]S.Lloyd.Leastsquaresquantization\n",
      "inPCM.IEEETransactionsonInformationTheory,28(2):129?137,1982.[14]\n",
      "M.Locatelli.Bayesianalgorithmsforone-dimensionalglobaloptimization.J.\n",
      "ofGlobalOptimization,10(1):57?76,1997.[15]Z.Michalewicz.Geneticalgo-\n",
      "rithms+datastructures=evolutionprograms(2nd,extendeded.).Springer-\n",
      "VerlagNewYork,Inc.,NewYork,NY,USA,1994.[16]A.MooreandJ.Schnei-\n",
      "der.Memory-basedstochasticoptimization.InNIPS,1995.[17]G.Nemhauser\n",
      "andL.Wolsey.Integerandcombinatorialoptimization.WileyNewYork,1999.\n",
      "[18]D.ParkandJ.Zeikus.Improvedfuelcellandelectrodedesignsforproduc-\n",
      "ingelectricityfrommicrobialdegradation.Biotechnol.Bioeng.,81(3):348?355,\n",
      "2003.[19]C.E.RasmussenandC.K.I.Williams.GaussianProcessesfor\n",
      "MachineLearning.MIT,2006.[20]A.M.Ross.ComputingBoundsonthe\n",
      "ExpectedMaximumofCorrelatedNormalVariables.MethodologyandCom-\n",
      "putinginAppliedProbability,2008.[21]M.Schonlau.ComputerExperiments\n",
      "andGlobalOptimization.PhDthesis,UniversityofWaterloo,1997.[22]H.\n",
      "D.Vinod.Integerprogrammingandthetheoryofgrouping.Journalofthe\n",
      "AmericanStatisticalAssociation,64(326):506?519,1969.\n",
      "9\n",
      "16\n",
      "\n",
      "PP3289.pdf\n",
      "PP3289.pdf 13\n",
      "GRIFT:Agraphicalmodelforinferringvisual\n",
      "featuresfromhumandata\n",
      "Authoredby:\n",
      "MichaelRoss\n",
      "AndrewCohen\n",
      "Abstract\n",
      "Thispaperdescribesanewmodelforhumanvisualthat\n",
      "enablestherecoveryofimagefeaturesthatexplainhumansubjects'per-\n",
      "formanceontvisualtasks.Unlikepreviousmethods,\n",
      "thisalgorithmdoesnotmodeltheirperformancewithasinglelinearclas-\n",
      "operatingonrawimagepixels.Instead,itmodelsas\n",
      "thecombinationofmultiplefeaturedetectors.Thisapproachextracts\n",
      "moreinformationabouthumanvisualthanhasbeenprevi-\n",
      "ouslypossiblewithothermethodsandprovidesafoundationforfurther\n",
      "exploration.\n",
      "1PaperBody\n",
      "Althoughagreatdealisknownaboutthelow-levelfeaturescomputedbythe\n",
      "humanvisualsystem,determiningtheinformationusedtomakehigh-levelvi-\n",
      "sualisanactiveareaofresearch.Whenapersondistinguishes\n",
      "betweentwofaces,forexample,whatimageregionsaremostsalient?Sincethe\n",
      "early1970s,oneofthemostimportantresearchtoolsforansweringsuchques-\n",
      "tionshasbeentheimage(orreversecorrelation)algorithm,which\n",
      "assumesalinearmodel[1].Thispaperdescribesanewapproach,\n",
      "GRIFT(GRaphicalmodelsforInferringFeatureTemplates).Insteadofrepre-\n",
      "sentinghumanvisualdiscriminationasasinglelinearGRIFTmodels\n",
      "itasthenon-linearcombinationofmultipleindependentlydetectedfeatures.\n",
      "ThisallowsGRIFTtoextractmoredetailedinformationabouthuman\n",
      "cation.ThispaperdescribesGRIFTandthealgorithmsforittodata,\n",
      "demonstratesthemodel?sonsimulatedandhumandata,andconcludes\n",
      "withadiscussionoffutureresearchdirections.\n",
      "2\n",
      "Relatedwork\n",
      "Ahumada?simagealgorithm[1]modelsanobserver?s\n",
      "cationsofvisualstimuliwithanoisylinear?asetofweightsand\n",
      "1\n",
      "\n",
      "anormallydistributedthreshold.Therandomthresholdaccountsforthefact\n",
      "thatmultiplepresentationsofthesamestimulusareofteninconsis-\n",
      "tently.Inatypicalimageexperiment,participantsarepresented\n",
      "withhundredsorthousandsofnoise-corruptedexamplesfromtwocategories\n",
      "andaskedtoclassifyeachone.Thenoiseensuresthatthesamplescoveralarge\n",
      "volumeofthesamplespaceinordertoallowrecoveryofauniquelinearclas-\n",
      "thatbestexplainsthedata.Althoughimagesareusefulin\n",
      "manycases,itiswellestablishedthattherearedomainsinwhichrecognition\n",
      "andaretheresultofcombiningthedetectionofpartsorfeatures,\n",
      "ratherthanapplyingasinglelineartemplate.Forexample,Pellietal.[10],\n",
      "haveconvincinglydemonstratedthathumansrecognizenoisywordimagesby\n",
      "parts,evenwhenwhole-wordtemplateswouldperformbetter.Similarly,Gold\n",
      "etal.[7]vthatsubjectsemployedfeature-basedclas1\n",
      "foursquare\n",
      "Sclass1\n",
      "?i?iN\n",
      "class1\n",
      "samples\n",
      "class2\n",
      "C\n",
      "samples\n",
      "light-darktargets\n",
      "?0\n",
      "faces\n",
      "class2\n",
      "?i\n",
      "class2\n",
      "Fi\n",
      "targets\n",
      "samplesclass1\n",
      "targets\n",
      "Figure1:Left:TheGRIFTmodelisaBayesnetthatdescribes\n",
      "tionastheresultofcombiningNfeaturedetectors.Right:Targetsandsample\n",
      "stimulifromthethreeexperiments.strategiesforsomesimple\n",
      "cialimageclasses.GRIFTtakesthenextstepandinfersfeatureswhichpredict\n",
      "humanperformancedirectlyfromclassitiondata.Mostworkonmodeling\n",
      "non-linear,feature-basedinhumanshasfocusedonverifyingthe\n",
      "useofasetoffeatures.RecentworkbyCohenetal.[4]demon-\n",
      "stratesthatGaussianmixturemodelscanbeusedtorecoverfeaturesfromhu-\n",
      "manclassidatawithoutspecifyingasetofpossiblefeatures.The\n",
      "GRIFTmodel,describedintheremainderofthispaper,hasthesamegoals\n",
      "asthepreviouswork,butremovesseverallimitationsoftheGaussianmixture\n",
      "modelapproach,includingtheneedtoonlyusestimulithesubjectsc\n",
      "withhighandthebiasthatthesignalscanexertontherecovered\n",
      "features.GRIFTachievestheseandotherimprovementsbygenerativelymod-\n",
      "elingtheentireprocesswithagraphicalmodel.Furthermore,the\n",
      "2\n",
      "\n",
      "similaritybetweensingle-featureGRIFTmodelsandtheimage\n",
      "process,describedinmoredetailbelow,makeGRIFTanaturalsuccessorto\n",
      "thetraditionalapproach.\n",
      "3\n",
      "GRIFTmodel\n",
      "GRIFTmodelsastheresultofcombiningNconditionallyin-\n",
      "dependentfeaturedetectors,F=\n",
      "f\n",
      "F1,F2,...,FN\n",
      "g\n",
      ".Eachfeaturedetector\n",
      "isbinaryvalued(1indicatesdetection),asistheC(1indicates\n",
      "oneclassand2theother).Thestimulus,S,isanarrayofcontinuouslyvalued\n",
      "pixelsrepresentingtheinputimage.ThestimulusonlyCthroughthe\n",
      "featuredetectors,thereforethejointprobabilityofastimulusand\n",
      "pairis!NXYP(C|F)P(S)P(Fi|S).P(C,S)=i\n",
      "F\n",
      "Figure1representsthecausalrelationshipbetweenthesevariables(C,F,\n",
      "andS)withaBayesiannetwork.Thenetworkalsoincludesnodesrepresenting\n",
      "modelparameters(?,?,and?),whoserolewillbedescribedbelow.Theboxed\n",
      "regionintheindicatesthepartsofthemodelthatarereplicatedwhen\n",
      "N>1?eachfeaturedetectorisrepresentedbyanindependentcopyofthose\n",
      "variablesandparameters.Thedistributionofthestimulus,P(S),isunder\n",
      "thecontroloftheexperimenter.Thealgorithmforthemodeltodata\n",
      "onlyassumesthatthestimuliareindependentandidenticallydistributedacross\n",
      "trials.Theconditionaldistributionofeachfeaturedetector?svalue,P(Fi|S),\n",
      "ismodeledwithalogisticregressionfunctiononthepixelvaluesofS.Logistic\n",
      "regressionisdesirablebecauseitisaprobabilisticlinearHumanscan\n",
      "successfullyclassifyimagesinthepresenceofextremelyhighadditivenoise,\n",
      "whichsuggeststheuseofaveragingandcontrast,linearcomputationswhich2\n",
      "areknowntoplayimportantrolesinhumanvisualperception[9].Justas\n",
      "theclasscationimageusedarandomthresholdtorepresentuncertaintyin\n",
      "theoutputofitssinglelinearclassilogisticregressionalsoallowsGRIFT\n",
      "torepresentuncertaintyintheoutputofeachofitsfeaturedetectors.The\n",
      "conditionaldistributionofCisrepresentedbylogisticregressiononthefeature\n",
      "outputs.EachFi?sdistributionhastwoparameters,aweightvector?ianda\n",
      "threshold?i,suchthatP(Fi=1|S,?i,?i)=(1+exp(?i+\n",
      "|S|X\n",
      "?ijSj))?1,\n",
      "j=1\n",
      "where|S|isthenumberofpixelsinastimulus.Similarly,theconditional\n",
      "distributionofCisdeterminedby?=\n",
      "f\n",
      "?0,?1,...,?N\n",
      "g\n",
      "whereP(C=\n",
      "1|F,?)=(1+exp(?0+\n",
      "NX\n",
      "?iFi))?1.\n",
      "i=1\n",
      "Detectingafeaturewithnegative?iincreasestheprobabilitythatthesub-\n",
      "jectwillrespond?class1,?thosewithpositive?iareassociatedwith?class\n",
      "2?responses.AGRIFTmodelwithNfeaturesappliedtotheof\n",
      "imageseachcontaining|S|pixelshasN(|S|+2)+1parameters.This\n",
      "3\n",
      "\n",
      "largenumberofparameters,coupledwiththefactthattheFvariablesareun-\n",
      "observable,makesthemodeltodataverychallenging.Therefore,GRIFT\n",
      "priordistributionsonitsparameters.Thesepriorsreasonableas-\n",
      "sumptionsabouttheparametervaluesand,iftheyarewrong,canbeoverturned\n",
      "ifenoughcontrarydataisavailable.Theprioroneachofthe?iparametersfor\n",
      "whichi>0isamixtureoftwonormaldistributions,1(?i?2)2(?i+2)2P(?i)\n",
      "=?(exp(?)+exp(?)).2222?Thispriortheassumptionthateach\n",
      "featuredetectorshouldhaveatimpactonthebutno\n",
      "singledetectorshouldmakeitdeterministic?asingle-featuremodelwith?0=\n",
      "0and?1=?2hasan88%chanceofchoosingclass1ifthefeatureisactive.The\n",
      "?0parameterhasanimpropernon-informativeprior,P(?0)=1,indicatingno\n",
      "preferenceforanyparticularvalue[5]becausethebest?0islargelydetermined\n",
      "bytheother?isandthedistributionsofFandS.Foranalogousreasons,P(?i\n",
      ")=1.The?iparameters,whicheachhavedimensionalityequaltothestimu-\n",
      "lus,presentthebiggestinferentialchallenge.Asmentionedpreviously,human\n",
      "visualprocessingissensitivetocontrastsbetweenimageregions.Ifoneimage\n",
      "regionisassignedpositive?ijsandanotherisassignednegative?ijs,thefeature\n",
      "detectorwillbesensitivetothecontrastbetweenthem.Thiscontrastbetween\n",
      "regionsrequiresallthepixelswithineachregiontosharesimilar?ijvalues.To\n",
      "encouragethislocalstructure,the?iparametershaveMarkovrandomprior\n",
      "distributions:????222YY(?ij+1)(?ij?1)??(?ij??ik)?P(?i)??\n",
      "(exp(?)+exp(?))),exp(?222j(j,k)?A\n",
      "whereAisthesetofneighboringpixellocations.Thefactorencourages\n",
      "weightvaluestobenearthe-1to1range,whilethesecondencouragesthe\n",
      "assignmentofsimilarweightstoneighboringpixels.Fittingthemodeltodata\n",
      "doesnotrequirethenormalizationofthisdistribution.TheBayesianjoint\n",
      "probabilitydistributionofalltheparametersandvariablesisP(C,F,S,?,?,\n",
      "?)=P(C|F,?)P(S)P(?0)\n",
      "NY\n",
      "P(Fi|S,?i,?i)P(?i)P(?i)P(?i).\n",
      "(1)\n",
      "i=1\n",
      "4\n",
      "GRIFTalgorithm\n",
      "Thegoalofthealgorithmistotheparametersthatsatisfytheprior\n",
      "distributionsandbestaccountforthe(S,C)samplesgatheredfromahuman\n",
      "subject.Mathematically,thisgoalcorrespondstothemodeofP(?,?,\n",
      "?|S,C),whereSandCrefertoalloftheobservedsamples.The3\n",
      "algorithmisderivedusingtheexpectation-maximization(EM)method[3],\n",
      "awidelyusedoptimizationtechniquefordealingwithunobservedvariables,in\n",
      "thiscaseF,thefeaturedetectoroutputsforallthetrials.Inordertodetermine\n",
      "themostprobableparameterassignments,thealgorithmchoosesrandominitial\n",
      "parameters??=(??,??,??)andthenthe?thatmaximizesX\n",
      "Q(?|??)=P(F|S,C,??)logP(C,F,S|?)+logP(?).F?\n",
      "Q(?|?)istheexpectedlogposteriorprobabilityoftheparameterscom-\n",
      "putedbyusingthecurrent??toestimatethedistributionofF,theunobserved\n",
      "4\n",
      "\n",
      "featuredetectoractivations.The?thatmaximizesQthenbecomes??forthe\n",
      "nextiteration,andtheprocessisrepeateduntilconvergence.Thepresenceof\n",
      "boththeP(C,F,S|?)andP(?)termsencouragesthealgorithmto\n",
      "parametersthatexplainthedataandmatchtheassumptionsencodedinthe\n",
      "parameterpriordistributions.Astheamountofavailabledataincreases,the\n",
      "ofthepriorsdecreases,soitispossibletodiscoverfeaturesthatare\n",
      "contrarytopriorbeliefgivenenoughevidence.Usingtheconditionalindepen-\n",
      "dencesfromtheBayesnet:?\n",
      "Q(?|?)?\n",
      "X\n",
      "?\n",
      "P(F|S,C,?)logP(C|F,?)+\n",
      "!logP(Fi|S,?i,?i)\n",
      "i=1\n",
      "F\n",
      "+\n",
      "NX\n",
      "NX\n",
      "(logP(?i)+logP(?i)),\n",
      "i=1\n",
      "droppingthelogP(S)term,whichisindependentoftheparameters,and\n",
      "thelogP(?0)andlogP(?i)terms,whichare0.Asmentionedbefore,\n",
      "thenormalizationtermsforthelogP(?i)elementscanbeignoredduring\n",
      "optimization?thelogmakesthemadditiveconstantstoQ.Thefunctional\n",
      "formofeveryadditivetermisdescribedinSection3,andP(F|S,C,??)can\n",
      "becalculatedusingthemodel?sjointprobabilityfunction(Equation1).Each\n",
      "iterationofEMrequiresmaximizingQ,butitisnotpossibletocomputethe\n",
      "maximizing?inclosedform.Fortunately,itisrelativelyeasytosearchforthe\n",
      "best?.BecauseQisseparableintomanyadditivecomponents,itispossibleto\n",
      "tlycomputeitsgradientwithrespecttoeachoftheelementsof?and\n",
      "usethisinformationtoalocallymaximum?assignmentusingthescaled\n",
      "conjugategradientalgorithm[2].Evenalocallymaximumvalueof?usually\n",
      "providesgoodEMresults?P(?,?,?|S,C)isstillguaranteedtoimprove\n",
      "aftereveryiteration.TheresultofanyEMprocedureisonlyguaranteedto\n",
      "bealocallyoptimalanswer,andthegloballyoptimal?ismademore\n",
      "challengingbythelargenumberofparameters.GRIFTadoptsthestandard\n",
      "solutionofrunningEMmanytimes,eachinstancestartingwitharandom??\n",
      ",andthenacceptingthe?fromtherunwhichproducedthemostprobable\n",
      "parameters.Forthismodelandthedatapresentedinthefollowingsections,\n",
      "20-30randomrestartsweret.\n",
      "5\n",
      "Experiments\n",
      "TheGRIFTmodelwastodatafrom3experiments.Ineachexperiment,\n",
      "humanparticipantsstimuliintotwoclasses.Eachclasscontained\n",
      "oneormoretargetstimuli.Ineachtrial,theparticipantsawastimulus(a\n",
      "samplefromS)thatconsistedofarandomlychosentargetwithhighlevelsof\n",
      "5\n",
      "\n",
      "independentidenticallydistributednoiseaddedtoeachpixel.Thenoisesamples\n",
      "weredrawnfromatruncatednormaldistributiontoensurethatthestimulus\n",
      "pixelvaluesremainedwithinthedisplay?soutputrange.Figure1showsthe\n",
      "classesandtargetsfromeachexperimentandasamplestimulusfromeach\n",
      "class.Inthefour-squareexperimentfourparticipantswereaskedtodistinguish\n",
      "betweentwostimulusclasses,oneinwhichtherewerebrightsquares\n",
      "intheupper-leftorupper-rightcornersandoneinwhichtherewerebright\n",
      "squaresinthelower-leftorlower-rightcorners.Inthelight-darkexperiment\n",
      "threeparticipantswereaskedtodistinguishbetweenthreestripsthateachhad\n",
      "twolightblobsandthreestripsthateachhadonlyonelightblob.Finally,inthe\n",
      "facesexperimentthreeparticipantswereaskedtodistinguishbetweentwofaces.\n",
      "Thefour-squaredatawerecollectedby[7]andwerealsoanalyzedin[4].The\n",
      "otherdataarenewlygathered.Eachdatasetconsistsofapproximately4000\n",
      "trialsfromeachsubject.Tomaintaintheirinterestinthetask,participants\n",
      "weregivenauditoryfeedbackaftereachtrialthatindicatedsuccessorfailure.4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "22\n",
      "0.2\n",
      "simulations\n",
      "0.15\n",
      "acornersbzACcdaEAbacbazJGdcbcRSdd\n",
      "0.1\n",
      "0.0510.25\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "humans\n",
      "0.20.150.10.051\n",
      "2\n",
      "3\n",
      "4\n",
      "N+Figure2:Themostprobable?parametersfoundforthefour-square\n",
      "experimentsfortvaluesofNandthe4mutualinformationbetweenthese\n",
      "featuredetectorsandtheobserved\n",
      "especiallysensitivetotherandominitializationprocedureusedtostart3\n",
      "FittingGRIFT4modelsisnot?\n",
      "23\n",
      "foursquare:mostprobable?ivaluesN=2N=3N=4mutualinformation\n",
      "simulationshumans\n",
      "2\n",
      "topv.bottom\n",
      "N=1\n",
      "6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "eachEMinstance.The?parameterswereinitializedbynormalrandom\n",
      "samplesandthenhalf\n",
      "89103were4sothefeatureswouldtendtostartevenlyassignedtothetwo\n",
      "classes,exceptfor??0,negated3whichwasinitialized4to0.Inthefour-square\n",
      "experiments,the??parameterswereinitializedby\n",
      "amixtureofnormaldistributionsandinthelight-darkexperimentsthey\n",
      "wereinitializedfromauniformdistribution.Inthefacesexperimentsthe?\n",
      "?wereinitializedbyaddingnormalnoisetothe8910optimallinearclassi-\n",
      "separatingthetwotargets.Becauseofthelargenumberofpixelsinthe\n",
      "facesstimuli,theotherinitializationproceduresfrequentlyproducedinitialas-\n",
      "signmentswithextremelylowprobabilities,whichledtonumericalprecision\n",
      "problems.Inthefour-squareexperiments,the??wereinitializedrandomly.\n",
      "Intheotherexperiments,theintentwastosetthemtotheoptimalthreshold\n",
      "fordistinguishingtheclassesusingtheinitial??asalinearbuta\n",
      "programmingerrorsetthemtothenegationofthatvalue.Inmostcases,the\n",
      "resultswereinsensitivetothechoiceofinitializationmethod.Inthefour-square\n",
      "experiment,thenoiselevelswerecontinuallyadjustedtokeeptheparticipants?\n",
      "performanceatapproximately71%usingthestair-casingalgorithm[8].This\n",
      "performancelevelishighenoughtokeeptheparticipantsengagedinthetask,\n",
      "butallowsfortnoisetoexploretheirresponsesinalargevolumeof\n",
      "thestimulusspace.Afteraninitialadaptationperiod,thenoiselevelremains\n",
      "relativelyconstantacrosstrials,sotheinter-trialdependenceintroducedby\n",
      "thestair-casingcanbesafelyignored.Twosimulatedobserverswerecreated\n",
      "tovalidateGRIFTonthefour-squaretask.EachusedaGRIFTmodelwith\n",
      "pre-spparameterstoprobabilisticallyclassifyfour-squaredataata\n",
      "noiselevel,whichwaschosentoproduceapproximately70%correctperfor-\n",
      "mance.Thecornersobserverusedfourfeaturedetectors,oneforeachbright\n",
      "corner,whereasthetop-v.-bottomobservercontrastedthebrightnessofthetop\n",
      "andbottompixels.TheresultofusingGRIFTtorecoverthefeaturedetectors\n",
      "aredisplayedinFigure2.Onlythe?parametersaredisplayedbecausethey\n",
      "arethemostinformative.Darkpixelsindicatenegativeweightsandbrightpix-\n",
      "elscorrespondtopositiveweights.Thepresenceofdarkandlightregionsin\n",
      "afeaturedetectorindicatesthecomputationofcontrastsbetweenthoseareas.\n",
      "Thesignoftheweightsisnott?givenanumberoffeatures,\n",
      "therearetypicallyseveralequivalentsetsoffeaturedetectorsthatonly\n",
      "fromeachotherinthesignsoftheir?termsandintheassociated?and?\n",
      "values.Becausetheoptimalnumberoffeaturesforhumansubjectsisunknown,\n",
      "GRIFTmodelswith1?4featuresweretothedatafromeachsubject.The\n",
      "correctnumberoffeaturescouldbedeterminedbyholdingoutatestsetorby\n",
      "performingcross-validation.Simulationdemonstratedthatareliabletestset\n",
      "7\n",
      "\n",
      "wouldneedtocontainnearlyallofthegatheredsamples,andcomputational\n",
      "expensemadecross-validationimpracticalwithourcurrentMATLABimple-\n",
      "mentation.Instead,afterrecoveringtheparameters,weestimatedthemutual\n",
      "informationbetweentheunobservedFvariablesandtheobservedclas\n",
      "C.Mutualinformationmeasureshowwellthefeaturedetectoroutputscan5\n",
      "predictthesubject?sdecision.Unliketheloglikelihoodofthe\n",
      "observations,whichisdependentonthechoicetomodelCwithalogisticre-\n",
      "gressionfunction,mutualinformationdoesnotassumeaparticularrelationship\n",
      "betweenFandCanddoesnotnecessarilyincreasewithN.Plottingthemutual\n",
      "informationasNincreasescanindicateifnewdetectorsaremakingasub-\n",
      "stantialcontributionorareovthedata.Onthesimulatedobservers?\n",
      "data,forwhichthetruevaluesofNwereknown,mutualinformationwasa\n",
      "moreaccuratemodelselectionindicatorthantraditionalstatisticssuchasthe\n",
      "BayesianorAkaikeinformationcriteria[3].FittingGRIFTtothesimulated\n",
      "observersdemonstratedthatifthemodelisaccurate,thecorrectfeaturescan\n",
      "berecoveredreliably.Thetop-v.-bottomobservershowednosubstantialin-\n",
      "creaseinmutualinformationasthenumberoffeaturesincreasedfrom1to4.\n",
      "Eachsetofrecoveredfeaturedetectorsincludedatop-bottomcontrastdetector\n",
      "andotherdetectorswithnoisy?isthatdidnotcontributemuchtopredicting\n",
      "C.Althoughtheobservertrulyusedtwodetectors,onetop-brighterdetector\n",
      "andonebottom-brighterdetector,therecoveryofonlyonetop-bottomcon-\n",
      "trastdetectorisasuccessbecauseonecontrastdetectorplusasuitable?0term\n",
      "islogicallyequivalenttotheoriginaltwo-featuremodel.Thecornersobserver\n",
      "showedasubstantialincreaseinmutualinformationasNincreasedfrom1to\n",
      "4andthe?valuesclearlyindicatefourcorner-sensitivefeaturedetectors.The\n",
      "cornersdatawasalsotestedwithae-featureGRIFTmodel(?notshown)\n",
      "whichproducedfourcornerdetectorsandonefeaturewithnoisy?i.Itsgain\n",
      "inmutualinformationwassmallerthanthatobservedonanyoftheprevious\n",
      "steps.Notethecornerareasinthe?isrecoveredfromthecornersdataare\n",
      "sometimesblackandsometimeswhite.Recallthatthesearenotimagepixel\n",
      "valuesthatthedetectorsareattemptingtomatch,butpositiveandnegative\n",
      "weightsindicatingthatthebrightnessinthecornerregionisbeingcontrasted\n",
      "tothebrightnessoftherestoftheimage.Eventhoughtargetsconsistedoffour\n",
      "bright-cornerstimuli,recoveringtheparametersfromthetopv.-bottomobserver\n",
      "neverproduced?valuesindicatingcorner-spfeaturedetectors.Animpor-\n",
      "tantadvantagesofGRIFToverpreviousmethodssuchas[4]isthattargets\n",
      "willnot?contaminate?therecovereddetectors.Thesimulationsdemonstrate\n",
      "thattherecovereddetectorsaredeterminedbythestrategy,not\n",
      "bythestructureofthetargetsandclasses.Thedataofthefourhumanpar-\n",
      "ticipantsrevealedsomeinteresting.ParticipantsEAandRSwere\n",
      "naive,whileACandJGwerenot.ThelargestdisparitywasbetweenEAand\n",
      "JG.EA?sdataindicatednoconsistentpatternofmutualinformationincrease\n",
      "aftertwofeatures,andthetwofeaturemodelappearstocontaintwotop-bottom\n",
      "contrastdetectors.Therefore,itisreasonabletoconcludethatEAwasnotex-\n",
      "plicitlydetectingthecorners.AttheotherextremeisparticipantJG,whose\n",
      "datashowsfourveryclearcornerdetectorsandasteadyincreaseinmutual\n",
      "8\n",
      "\n",
      "informationuptofourfeatures.Therefore,itseemsverylikelythatthispartic-\n",
      "ipantwasmatchingcornersandprobablyshouldbetestedwithae-feature\n",
      "modeltogainadditionalinsight.ACandRS?sdatasuggestthreecornerdetec-\n",
      "torsandatop-bottomcontrastdetector.GRIFT?soutputindicatesqualitative\n",
      "inthestrategiesusedbythefourhumanparticipants.\n",
      "Acrossallparticipants,thebestone-featuremodelwasbasedonthecontrast\n",
      "betweenthetopoftheimageandthebottom.Thisisextremelysimilarto\n",
      "theresultproducedbyaimageofthedata,reinforcingthestrong\n",
      "similaritybetweenone-featureGRIFTandthatapproach.Inthelight-dark\n",
      "andfacesexperiments,stair-casingwasusedtheadjustthenoiseleveltothe\n",
      "71%performancelevelatthebeginningofeachsessionandthenthenoiselevel\n",
      "wasfortheremainingtrialstoimprovetheindependenceofthesamples.\n",
      "Participantswerepaidandpromiseda$10rewardforachievingthehighest\n",
      "scoreonthetask.ParticipantsP1,P2,andP3thelight-darkstimuli.\n",
      "P1andP2achievedatorabovetheexpectedperformancelevel(82%and73%\n",
      "accuracy),whileP3?sperformancewasnearchance(55%).Becausethenoise\n",
      "levelswereafterthe101trials,aparticipantwithgoodluckattheend\n",
      "ofthatperiodcouldexperienceveryhighnoiselevelsfortheremainderofthe\n",
      "experiment,leadingtopoorperformance.Allthreeparticipantsappeartohave\n",
      "usedtmethods,providingaveryinformativecontrast.The\n",
      "resultsoftheGRIFTmodelareinFigure3.Themutualinformation\n",
      "graphandthepresenceofafeaturedetectorthresholdingtheoverallbright-\n",
      "nessforeachvalueofNindicatethatP1pursuedaone-feature,\n",
      "strategy.P2,ontheotherhand,clearlyemployedamulti-feature,non-linear\n",
      "strategy.ForN=1andN=2,themostinterpretablefeaturedetectorisan\n",
      "overallbrightnessdetector,whichdisappearswhenN=3andthebestmodel\n",
      "consistsofthreedetectorslookingforsppatterns,oneforeachpositiona\n",
      "6\n",
      "ablight-dark:mostprobable?ivaluesP1cP2aP3N=10.25dbN=2\n",
      "0.25c0.2dN=30.2\n",
      "9\n",
      "8\n",
      "7\n",
      "N=4\n",
      "5\n",
      "aabbcP5dc\n",
      "d\n",
      "0.1510.10.90.10.050.710.050.61\n",
      "P6\n",
      "2\n",
      "3\n",
      "N=5\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "9\n",
      "\n",
      "3\n",
      "mutualinformation\n",
      "3\n",
      "0.5\n",
      "2\n",
      "0.4\n",
      "2\n",
      "1\n",
      "z\n",
      "-\n",
      "0.8\n",
      "4\n",
      "0\n",
      "P4\n",
      "0.15\n",
      "6\n",
      "faces:mostprobable?ivaluesN=2N=3\n",
      "N=1\n",
      "z\n",
      "0.2\n",
      "light-dark\n",
      "4\n",
      "0.15\n",
      "4\n",
      "0.10.05\n",
      "01\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "mutualinformation\n",
      "1\n",
      "0.04\n",
      "+faces\n",
      "0.030.020.0101\n",
      "2\n",
      "3\n",
      "NN34+Figure3:Themostprobable?parametersfoundforthelight-dark\n",
      "andfacesexperimentsfor\n",
      "0.2themutualinformationbetweenthesefeaturedetectorsandtheobserved\n",
      "entNand\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "10\n",
      "\n",
      "6\n",
      "0.1\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0brightordarkspotThen123canappear.4567when8N9=410the\n",
      "overallbrightnessdetectorreappears,addedtothethreespotdetectors.Ap-\n",
      "parentlythespotdetectorsareonlyeiftheyareallpresent.Withonly\n",
      "threeavailabledetectors,theoverallbrightnessdetectorisexcluded,buttheop-\n",
      "timalassignmentincludesallfourdetectors.Thisisthebmodelbecause\n",
      "increasingtoN=5keepsthemutualinformationconstantandaddsadetector\n",
      "thatisactiveforeverystimulus.Alwaysactivedetectorsfunctionasconstant\n",
      "additionsto?0,thereforethisisequivalenttotheN=4solution.\n",
      "TheGRIFTmodelsofparticipantP3donotshowasubstantialincreasein\n",
      "mutualinformationasthenumberoffeaturesrises.Thislackofincreaseleads\n",
      "totheconclusionthattheone-featuremodelisprobablythebestandsince\n",
      "performancewasextremelylow,itcanbeassumedthatthesubjectwasreduced\n",
      "tonearrandomguessingmuchofthetime.Thecleardistinctionbetweenthe\n",
      "resultsforallthreesubjectsdemonstratestheenessofGRIFTandthe\n",
      "mutualinformationmeasureindistinguishingbetweenstrategies.\n",
      "Thefacespresentedthelargestcomputationalchallenges.Thetargetsweretwo\n",
      "facesfromGoldetal.?sdataset[6],down-sampledto128x128.After\n",
      "theexperiment,thestimuliweredown-sampledfurtherto32x32andtheback-\n",
      "groundsurroundingthefaceswasremovedbycropping,reducingthestimuli\n",
      "to26x17.Thesestepsmadethealgorithmcomputationallyfeasible,andre-\n",
      "ducedthenumberofparameterssotheywouldbetlyconstrainedby\n",
      "thesamples.Theresultsforthreeparticipants(P4,P5,andP6)areinFigure\n",
      "3.ParticipantsP4andP5?sdatawereclearlybestbyone-featureGRIFT\n",
      "models.Increasingthenumberoffeaturessimplycausedthealgorithmtoadd\n",
      "featuresthatwereneveroralwaysactive.Neveractivefeaturescannot\n",
      "theand,asexplainedpreviously,alwaysactivefeaturesarealso\n",
      "supP4?sonefeaturemodelclearlyplacescantweightnearthe\n",
      "eyebrows,nose,andotherfacialfeatures.P5?sone-featureweightsaremuch\n",
      "noisierandhardertointerpret.ThismightberelatedtoP5?spoorperformance\n",
      "onthetask?only53%accuracycomparedtoP4?s72%accuracy.Perhapsthe\n",
      "noiselevelwastoohighandP5wasguessingratherthanusingimageinforma-\n",
      "tionmuchofthetime.ParticipantP6?sdatadidproduceatwo-featureGRIFT\n",
      "model,albeitonethatistointerpretandwhichonlycausedasmall\n",
      "riseinmutualinformation.Insteadofrecoveringindependentpartdetectors,\n",
      "suchasanosedetectorandaneyedetector,GRIFTextractedtwosubtlydif-\n",
      "ferentholisticfeaturedetectors.GivenP6?spoorperformance(58%accuracy)\n",
      "thesefeaturesmay,likeP5?sresults,beindicativeofaguessingstrategythat\n",
      "wasnotstronglyinbytheimageinformation.Theresultsonfacessup-\n",
      "portthehypothesisthatfaceisholisticandratherthan\n",
      "theresultofpartespeciallywhenindividualfeaturedetectionis\n",
      "11\n",
      "\n",
      "[11].7\n",
      "Acrosstheseexperiments,thedatacollectedwerecompatiblewiththeorig-\n",
      "inalimagemethod.Infact,thefour-squarehumandatawere\n",
      "originallyanalyzedusingthatalgorithm.OneoftheadvantagesofGRIFTis\n",
      "thatitcanreanalyzeolddatatorevealnewinformation.Intheonefeature\n",
      "case,GRIFTenablestheuseofpriorprobabilitiesontheparameters,which\n",
      "mayimproveperformancewhendataistooscarcefortheimage\n",
      "approach.Mostimportantly,multi-featureGRIFTmodelscanreveal\n",
      "previouslyhiddennon-linearstrategies.\n",
      "6\n",
      "Conclusion\n",
      "ThispaperhasdescribedtheGRIFTmodelfordeterminingthefeatures\n",
      "usedinhumanimageGRIFTisanadvanceoverpreviousmeth-\n",
      "odsthatassumeasinglelinearonpixelsbecauseitdescribes\n",
      "tionasthecombinationofmultipleindependentlydetectedfeatures.Itprovides\n",
      "aprobabilisticmodelofhumanvisualclasthataccountsfordataand\n",
      "incorporatespriorbeliefsaboutthefeatures.Thefeaturedetectorsitare\n",
      "associatedwiththestrategyemployedbytheobserverandare\n",
      "nottheresultofstructureintheclasses?targetimages.GRIFT?svaluehas\n",
      "beendemonstratedbymodelingtheperformanceofhumansonthefour-square,\n",
      "light-dark,andfacestasksandbysuccessfullyrecoveringthepa-\n",
      "rametersofcomputersimulatedobserversinthefour-squaretask.Itsinability\n",
      "tondmultiplelocalfeatureswhenanalyzinghumanperformanceonthefaces\n",
      "taskagreeswithpreviousresults.Oneofthestrengthsofthegraphicalmodel\n",
      "approachisthatitallowseasyreplacementofmodelcomponents.Anexpert\n",
      "caneasilychangethepriordistributionsontheparameterstoknowledge\n",
      "gainedinpreviousexperiments.Forexample,itmightbedesirabletoencourage\n",
      "theformationofedgedetectors.Newresolution-independentfeatureparame-\n",
      "terizationscanbeintroduced,ascantransformationparameterstomakethe\n",
      "featurestranslationallyandrotationallyinvariant.Ifthefeatureshaveexplicitly\n",
      "parameterizedlocationsandorientations,themodelcouldbeextendedtomodel\n",
      "theirjointrelativepositions,whichmightprovidemoreinformationaboutdo-\n",
      "mainssuchasfaceThesuccessofthisversionofGRIFTprovides\n",
      "afoundationfortheseimprovements.AcknowledgmentsThisresearchwas\n",
      "supportedbyNSFGrantSES-0631602andNIMHgrantMH16745.Theauthors\n",
      "thankthereviewers,TomErikLearned-Miller,andAdamSanbornfor\n",
      "theirsuggestions.\n",
      "2References\n",
      "[1]A.J.Ahumada,Jr.imageweightsandinternalnoiseleveles-\n",
      "timation.JournalofVision,2(1),2002.[2]C.M.Bishop.NeuralNetworksfor\n",
      "PatternRecognition.OxfordUniversityPress,1995.[3]C.M.Bishop.Pat-\n",
      "ternRecognitionandMachineLearning.Springer,2006.[4]A.L.Cohen,R.M.\n",
      "J.M.Gold,D.A.Ross,andM.G.Ross.Inducingfeaturesfromvisual\n",
      "12\n",
      "\n",
      "noise.JournalofVision,7(8),2007.[5]A.Gelman,J.B.Carlin,H.S.Stern,\n",
      "andD.B.Rubin.BayesianDataAnalysis.Chapman&Hall/CRC,2003.[6]\n",
      "J.M.Gold,P.J.Bennett,andA.B.Sekuler.Idenofband-pass\n",
      "lettersandfacesbyhumanandidealobservers.VisionResearch,39,1999.[7]\n",
      "J.M.Gold,A.L.Cohen,andR.Visualnoiserevealscategoryrepresen-\n",
      "tations.PsychonomicsBulletin&Review,15(4),2006.[8]N.A.Macmillanand\n",
      "C.D.Creelman.DetectionTheory:AUser?sGuide.LawrenceErlbaumAsso-\n",
      "ciates,2005.[9]S.E.Palmer.VisionScience:PhotonstoPhenomenology.The\n",
      "MITPress,1999.[10]D.G.Pelli,B.Farell,andD.C.Moore.Theremarkable\n",
      "ofwordrecognition.Nature,425,2003.[11]J.Sergent.Aninves-\n",
      "tigationintocomponentandprocessesunderlyingfaceperception.\n",
      "BritishJournalofPsychology,75,1984.\n",
      "8\n",
      "13\n",
      "\n",
      "PP6518.pdf\n",
      "PP6518.pdf 12\n",
      "MoreSupervision,LessComputation:\n",
      "Statistical-ComputationalTinWeakly\n",
      "SupervisedLearning\n",
      "Authoredby:\n",
      "HanLiu\n",
      "ConstantineCaramanis\n",
      "ZhaoranWang\n",
      "ZhuoranYang\n",
      "XinyangYi\n",
      "Abstract\n",
      "Weconsidertheweaklysupervisedbinaryproblemwhere\n",
      "thelabelsarerandomlyedwithprobability$1-alpha$.Although\n",
      "thereexistnumerousalgorithmsforthisproblem,itremainstheoretically\n",
      "unexploredhowthestatisticalaccuraciesandcomputationaly\n",
      "ofthesealgorithmsdependonthedegreeofsupervision,whichisquan-\n",
      "by$alpha$.Inthispaper,wecharacterizetheof$alpha$\n",
      "byestablishingtheinformation-theoreticandcomputationalboundaries,\n",
      "namely,theminimax-optimalstatisticalaccuracythatcanbeachievedby\n",
      "allalgorithms,andpolynomial-timealgorithmsunderanoraclecompu-\n",
      "tationalmodel.Forsmall$alpha$,ourresultshowsagapbetweenthese\n",
      "twoboundaries,whichrepresentsthecomputationalpriceofachieving\n",
      "theinformation-theoreticboundaryduetothelackofsupervision.In-\n",
      "terestingly,wealsoshowthatthisgapnarrowsas$alpha$increases.In\n",
      "otherwords,havingmoresupervision,i.e.,morecorrectlabels,notonly\n",
      "improvestheoptimalstatisticalaccuracyasexpected,butalsoenhances\n",
      "thecomputationalforachievingsuchaccuracy.\n",
      "1PaperBody\n",
      "Practicalclassi?cationproblemsusuallyinvolvecorruptedlabels.Speci?cally,\n",
      "let\n",
      "f\n",
      "(xi,zi)\n",
      "g\n",
      "ni=1benindependentdatapoints,wherexi?Rdistheco-\n",
      "variatevectorandzi?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "istheuncorruptedlabel.Insteadofobserving\n",
      "f\n",
      "(xi,zi)\n",
      "g\n",
      "ni=1,weobserve\n",
      "f\n",
      "(xi,yi)\n",
      "g\n",
      "ni=1inwhichyiisthecorruptedlabel.\n",
      "Indetail,withprobability(1??),yiischosenuniformlyatrandomover\n",
      "f\n",
      "0,\n",
      "1\n",
      "g\n",
      ",andwithprobability?,yi=zi.Here??[0,1]quanti?esthedegreeof\n",
      "1\n",
      "\n",
      "supervision:alarger?indicatesmoresupervisionsincewehavemoreuncor-\n",
      "ruptedlabelsinthiscase.Inthispaper,weareparticularlyinterestedinthe\n",
      "of?onthestatisticalaccuracyandcomputationalef?ciencyforparam-\n",
      "eterestimationinthisproblem,particularlyinthehighdimensionalsettings\n",
      "wherethedimensiondismuchlargerthanthesamplesizen.Thereexistsa\n",
      "vastbodyofliteratureonbinaryclassi?cationproblemswithcorruptedlabels.\n",
      "Inparticular,thestudyofrandomlyperturbedlabelsdatesbackto[1]inthe\n",
      "contextofrandomclassi?cationnoisemodel.See,e.g.,[12,20]forasurvey.\n",
      "Also,classi?cationproblemswithmissinglabelsarealsoextensivelystudiedin\n",
      "thecontextofsemi-supervisedorweaklysupervisedlearningby[14,17,21],\n",
      "amongothers.Despitetheextensivestudyonthisproblem,itsinformation-\n",
      "theoreticandcomputationalboundariesremainunexploredintermsoftheory.\n",
      "Inanutshell,theinformationtheoreticboundaryreferstotheoptimalstatisti-\n",
      "calaccuracyachievablebyanyalgorithms,whilethecomputationalboundary\n",
      "referstotheoptimalstatisticalaccuracyachievablebythealgorithmsundera\n",
      "computationalbudgetthathasapolynomialdependenceontheproblemscale\n",
      "(d,n).Moreover,itremainsunclearhowthesetwoboundariesvaryalongwith\n",
      "?.Oneinterestingquestiontoaskis29thConferenceonNeuralInformation\n",
      "ProcessingSystems(NIPS2016),Barcelona,Spain.\n",
      "howthedegreeofsupervisionthefundamentalstatisticalandcompu-\n",
      "tationaldif?cultiesofthisproblem,especiallyinthehighdimensionalregime.\n",
      "Inthispaper,wesharplycharacterizeboththeinformation-theoreticandcom-\n",
      "putationalboundariesoftheweaklysupervisedbinaryclassi?cationproblems\n",
      "undertheminimaxframework.Speci?cally,weconsidertheGaussiangenerative\n",
      "modelwhereX|Z=z?N(?z,?)andz?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "isthetruelabel.Sup-\n",
      "pose\n",
      "f\n",
      "(xi,zi)\n",
      "g\n",
      "ni=1arenindependentsamplesof(X,Z).Weassumethat\n",
      "f\n",
      "yi\n",
      "g\n",
      "ni=1aregeneratedfrom\n",
      "f\n",
      "zi\n",
      "g\n",
      "ni=1intheaforementionedmanner.Wefocus\n",
      "onthehighdimensionalregime,whered?nand?1??0iss-sparse,i.e.,?1\n",
      "??0hassnonzeroentires.Weareinterestedinestimating?1??0fromthe\n",
      "observedsamples\n",
      "f\n",
      "(xi,yi)\n",
      "g\n",
      "ni=1.Byastandardreductionargument[24],the\n",
      "fundamentallimitsofthisestimationtaskarecapturedbyahypothesistesting\n",
      "problem,namely,H0:?1??0=0versusH1:?1??0iss-sparseand(?1??0\n",
      ")???1(?1??0):=?n>0,\n",
      "(1.1)\n",
      "where?ndenotesthesignalstrengththatscaleswithn.Consequently,we\n",
      "focusonstudyingthefundamentallimitsof?nforsolvingthishypothesistesting\n",
      "problem.?n??\n",
      "E?cient\n",
      "?s2slogd?n=o?2,n?n???slogdslogd?n=??2n?n\n",
      "?n=?\n",
      "??\n",
      "s2slogd?2n?n\n",
      "?\n",
      "IntractableImpossible0\n",
      "?\n",
      "?n=o\n",
      "2\n",
      "\n",
      "??\n",
      "slogdslogd?2n?n\n",
      "?\n",
      "1\n",
      "Figure1:Computational-statisticalphasetransitionsforweaklysupervised\n",
      "binaryclassi?cation.Here?denotesthedegreeofsupervision,i.e.,thelabelis\n",
      "corruptedtobeuniformlyrandomwithprobability1??,and?nisthesignal\n",
      "strength,whichisde?nedin(1.1).Herea?bdenotesmin\n",
      "f\n",
      "a,b\n",
      "g\n",
      ".\n",
      "OurmainresultsareillustratedinFigure1.Speci?cally,weidentifythe\n",
      "impossible,intractable,andef?cientregimesforthestatistical-computational\n",
      "phasetransitionsundercertainregularityconditions.?(i)For?n=o[slog\n",
      "d/n?(1/?2?slogd/n)],anyalgorithmisasymptoticallypowerlessinsolving\n",
      "thehypothesis?testingproblem.?(ii)For?n=?[slogd/n?(1/?2?slog\n",
      "d/n)]and?n=o[s2/n?(1/?2?slogd/n)],anytractablealgorithmthat\n",
      "hasapolynomialoraclecomplexityunderanextensionofthestatisticalquery\n",
      "model[18]isasymptoticallypowerless.Wewillrigorouslyde?nethecomputa-\n",
      "tionalmodelin?2.?(iii)For?n=?[s2/n?(1/?2?slogd/n)],thereisan\n",
      "ef?cientalgorithmwithapolynomialoraclecomplexitythatisasymptotically\n",
      "powerfulinsolvingthetestingproblem.??Hereslogd/n?(1/?2?slogd/n)\n",
      "givestheinformation-theoreticboundary,whiles2/n?(1/?2?slogd/n)gives\n",
      "thecomputationalboundary.Moreover,byareductionfromtheestimation\n",
      "problemtothetestingproblem,theseboundariesfortestingimplytheonesfor\n",
      "estimating?2??1aswell.Consequently,thereexistsasigni?cantgapbetween\n",
      "thecomputationalandinformation-theoreticboundariesforsmall?.Inother\n",
      "word,toachievetheinformation-theoreticboundary,onehastopaytheprice\n",
      "ofintractablecomputation.As?tendstoone,thisgapbetweencomputational\n",
      "andinformation-theoreticboundariesnarrowsandeventuallyvanishes.Thisin-\n",
      "dicatesthat,havingmoresupervisionnotonlyimprovesthestatisticalaccuracy,\n",
      "asshownbythedecayofinformation-theoreticboundaryinFigure1,butmore\n",
      "importantly,enhancesthecomputationalef?ciencybyreducingthecomputa-\n",
      "tionalpriceforattaininginformation-theoreticoptimality.Thisphenomenon?\n",
      "?moresupervision,lesscomputation??isobservedforthe?rsttimeinthis\n",
      "paper.1.1\n",
      "MoreRelatedWork,OurContribution,andNotation\n",
      "Besidestheaforementionedliteratureonweaklysupervisedlearningand\n",
      "labelcorruption,ourworkisalsoconnectedtoarecentlineofworkonstatistical-\n",
      "computational[2?5,8,13,15,19,26?28].Incomparison,wequantify\n",
      "thestatistical-computationalforweaklysupervisedlearningforthe\n",
      "?rsttime.Furthermore,ourresultsarebuiltonanoraclecomputationalmodel\n",
      "2\n",
      "in[8]thatslightlyextendsthestatisticalquerymodel[18],andhencedonot\n",
      "hingeonunprovenconjecturesoncomputationalhardnesslikeplantedclique.\n",
      "Comparedwithourwork,[8]focusesonthecomputationalhardnessoflearning\n",
      "heterogeneousmodels,whereasweconsidertheinterplaybetweensupervision\n",
      "andstatistical-computationalAsimilarcomputationalmodelisused\n",
      "in[27]tostudystructuralnormalmeanmodelandprincipalcomponentanalysis,\n",
      "3\n",
      "\n",
      "whichexhibittstatistical-computationalphasetransitions.Inaddition,\n",
      "ourworkisrelatedtosparselineardiscriminantanalysisandtwo-sampletesting\n",
      "ofsparsemeans,whichcorrespondtoourspecialcasesof?=1and?=0,re-\n",
      "spectively.See,e.g.,[7,23]fordetails.Incontrastwiththeirresults,ourresults\n",
      "capturetheeof?onstatisticalandcomputationalInsummary,\n",
      "thecontributionofourworkistwo-fold:(i)Wecharacterizethecomputational\n",
      "andstatisticalboundariesoftheweaklysupervisedbinaryclassi?cationproblem\n",
      "forthe?rsttime.Comparedwithexistingresultsforothermodels,ourresults\n",
      "donotrelyonunprovenconjectures.(ii)Basedonourtheoreticalcharacteriza-\n",
      "tion,weproposethe?moresupervision,lesscomputation?phenomenon,which\n",
      "isobservedforthe?rsttime.Notation.Wedenotethe?2-divergencebetween\n",
      "twodistributionsP,QbyD?2(P,Q).Fortwononnegativesequencesan,bn\n",
      "indexedbyn,weusean=o(bn)asashorthandforlimn??an/bn=0.Wesay\n",
      "an=?(bn)ifan/bn?cforsomeabsoluteconstantc>0whennissuf?ciently\n",
      "large.Weusea?banda?btodenotemax\n",
      "f\n",
      "a,b\n",
      "g\n",
      "andmin\n",
      "f\n",
      "a,b\n",
      "g\n",
      ",respectively.\n",
      "Foranypositiveintegerk,wedenote\n",
      "f\n",
      "1,2,...,k\n",
      "g\n",
      "by[k].Forv?Rd,we\n",
      "denoteby?v?pthe?p-normofv.Inaddition,wedenotetheoperatornormof\n",
      "amatrixAby|||A|||2.\n",
      "2\n",
      "Background\n",
      "Inthissection,weformallyde?nethestatisticalmodelforweaklysupervised\n",
      "binaryclassi?cation.Thenwefollowitwiththestatisticalquerymodelthat\n",
      "connectscomputationalcomplexityandstatisticaloptimality.2.1\n",
      "ProblemSetup\n",
      "ConsiderthefollowingGaussiangenerativemodelforbinaryclassi?cation.\n",
      "ForarandomvectorX?RdandabinaryrandomvariableZ?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",weassume\n",
      "X|Z=0?N(?0,?),\n",
      "X|Z=1?N(?1,?),\n",
      "(2.1)\n",
      "whereP(Z=0)=P(Z=1)=1/2.Underthismodel,theoptimalclassi?er\n",
      "byBayesrulecorrespondstotheFisher?slineardiscriminativeanalysis(LDA)\n",
      "classi?er.Inthispaper,wefocusonthenoisylabelsettingwheretruelabelZis\n",
      "replacedbyauniformlyrandomlabelin\n",
      "f\n",
      "0,1\n",
      "g\n",
      "withprobability1??.Hence,\n",
      "?characterizesthedegreeofsupervisioninthemodel.Inspeci?c,if?=0,\n",
      "weobservethetruelabelZ,thustheproblembelongstosupervisedlearning.\n",
      "Whereasif?=1,theobservedlabeliscompletelyrandom,whichcontainsno\n",
      "informationofthemodelin(2.1).Thissettingisthusequivalenttolearning\n",
      "aGaussianmixturemodel,whichisanunsupervisedproblem.Inthegeneral\n",
      "settingwithnoisylabels,wedenotetheobservedlabelbyY,whichislinkedto\n",
      "thetruelabelZviaP(Y=Z)=(1+?)/2,P(Y=1?Z)=(1??)/2.(2.2)\n",
      "Weconsiderthehypothesistestingproblemofdetectingwhether?0?=?1\n",
      "givenni.i.d.samples\n",
      "f\n",
      "yi,xi\n",
      "g\n",
      "ni=1of(Y,X),namelyH0:?0=?1versusH1\n",
      ":?0?=?1.\n",
      "(2.3)\n",
      "Wefocusonthehighdimensionalandsparseregime,whered?nand?0\n",
      "??1iss-sparse,i.e.,?0??1?B0(s),whereB0(s):=\n",
      "f\n",
      "??Rd:???0?\n",
      "4\n",
      "\n",
      "s\n",
      "g\n",
      ".Throughoutthispaper,usethesamplesizentodrivetheasymptotics.We\n",
      "introduceashorthandnotation?:=(?0,?1,?,?)torepresenttheparameters\n",
      "oftheaforementionedmodel.LetP?bethejointdistributionof(Y,X)under\n",
      "ourstatisticalmodelwithparameter?,andPn?betheproductdistributionof\n",
      "ni.i.d.samplesaccordingly.Wedenotetheparameterspacesofthenulland\n",
      "alternativehypothesesbyG0andG1respectively.Foranytestfunction?:\n",
      "f\n",
      "(yi,xi)\n",
      "g\n",
      "ni=1?\n",
      "f\n",
      "0,1\n",
      "g\n",
      ",theclassicaltestingriskisde?nedasthesummation\n",
      "of3\n",
      "type-Iandtype-IIerrors,namelyRn(?;G0,G1):=supPn?(?=1)+\n",
      "supPn?(?=0).??G0\n",
      "??G1\n",
      "Theminimaxriskisde?nedasthesmallesttestingriskofallpossibletest\n",
      "functions,thatis,Rn?(G0,G1):=infRn(?;G0,G1),?\n",
      "(2.4)\n",
      "wherethein?mumistakenoverallmeasurabletestfunctions.Intuitively,\n",
      "theseparationbetweentwoGaussiancomponentsunderH1andthecovariance\n",
      "matrix?togetherdeterminethehardnessofdetection.Tocharacterizesuch\n",
      "dependence,wede?nethesignalto-noiseratio(SNR)as?(?):=(?0??1)???1\n",
      "(?0??1).Foranynonnegativesequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1,letG1(?n):=\n",
      "f\n",
      "?:?(?)\n",
      "??n\n",
      "g\n",
      "beasequenceofalternativeparameterspaceswithminimumseparation\n",
      "?n.Thefollowingminimaxratecharacterizestheinformation-theoreticlimits\n",
      "ofthedetectionproblem.De?nition2.1(Minimaxrate).Wesayasequence\n",
      "f\n",
      "?n?\n",
      "g\n",
      "n?1isaminimaxrateif?Foranysequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1satisfying?n\n",
      "=o(?n?),wehavelimn??Rn?[G0,G1(?n)]=1;?Foranysequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1satisfying?n=?(?n?),wehavelimn??Rn?[G0,G1(?n)]=0.\n",
      "TheminimaxrateinDe?nition2.1characterizesthestatisticaldif?cultyofthe\n",
      "testingproblem.However,itfailstoshedlightonthecomputationalef?ciency\n",
      "ofpossibletestingalgorithms.Thereasonisthatthisconceptdoesnotmake\n",
      "anycomputationalrestrictiononthetestfunctions.Theminimaxriskin(2.4)\n",
      "mightbeattainedonlybytestfunctionsthathaveexponentialcomputational\n",
      "complexities.ThislimitationofDe?nition2.1motivatesustostudystatistical\n",
      "limitsundercomputationalconstraints.2.2\n",
      "ComputationalModel\n",
      "Statisticalquerymodels[8?11,18,27]capturecomputationalcomplexityby\n",
      "characterizingthetotalnumberofroundsanalgorithminteractswithdata.\n",
      "Inthispaper,weconsiderthefollowingstatisticalquerymodel,whichad-\n",
      "mitsboundedqueryfunctionsbutallowstheresponsesofqueryfunctionsto\n",
      "beunbounded.De?nition2.2(Statisticalquerymodel).Inthestatisticalquery\n",
      "model,analgorithmAisallowedtoqueryanoracleTrounds,butnottoaccess\n",
      "data\n",
      "f\n",
      "(yi,xi)\n",
      "g\n",
      "ni=1directly.Ateachround,Aqueriestheoraclerwitha\n",
      "queryfunctionq?QA,inwhichQA?\n",
      "f\n",
      "q:\n",
      "f\n",
      "0,1\n",
      "g\n",
      "?Rd?[?M,M]\n",
      "g\n",
      "denotes\n",
      "thequeryspaceofA.Theoracleroutputsarealizationofarandomvariable\n",
      "Zq?Rsatisfying?????P|Zq?E[q(Y,X)]|??q?1?2?,whereq?QA\n",
      "?q=[?(QA)+log(1/?)]?M/n\n",
      "???2[?(QA)+log(1/?)]?(M2?\n",
      "f\n",
      "E[q(Y,X)]\n",
      "g\n",
      "2)n.(2.5)\n",
      "Here?q>0isthetoleranceparameterand??[0,1)isthetailprobability.\n",
      "5\n",
      "\n",
      "Thequantity?(QA)?0in?qmeasuresthecapacityofQAinlogarithmicscale,\n",
      "e.g.,forcountableQA,?(QA)=log(|QA|).ThenumberTisde?nedas\n",
      "theoraclecomplexity.WedenotebyR[?,n,T,?(QA)]thesetoforacles\n",
      "satisfying(2.5),andbyA(T)thefamilyofalgorithmsthatqueriesanoracleno\n",
      "morethanTrounds.Thisversionofstatisticalquerymodelisusedin[8],and\n",
      "reducestotheVSTATmodelproposedin[9?11]bythetransformationq?(y,x)\n",
      "=q(y,x)/(2M)+1/2foranyq?QA.ThecomputationalmodelinDe?nition\n",
      "2.2enablesustohandlequeryfunctionsthatareboundedbyanunknownand\n",
      "?xednumberM.Notethatthatbyincorporatingthetailprobability?,the\n",
      "responseZqisallowedtobeunbounded.Tounderstandtheintuitionbehind\n",
      "De?nition2.2,weremarkthat(2.5)resemblestheBernstein?sinequalityfor\n",
      "boundedrandomvariables[25]????????1n?t2q(Yi,Xi)?E[q(Y,\n",
      "X)]???t?2exp.(2.6)P??n2Var[q(Y,X)]+Mti=1\n",
      "We?rstreplaceVar[q(Y,X)]byitsupperboundM2?\n",
      "f\n",
      "E[q(Y,X)]\n",
      "g\n",
      "2,\n",
      "?whichistightwhenqtakesnvaluesin\n",
      "f\n",
      "?M,M\n",
      "g\n",
      ".Theninequality(2.5)is\n",
      "obtainedbyreplacingn?1i=1q(Yi,Xi)in(2.6)byZqandthenboundingthe\n",
      "supremaoverthequeryspaceQA.Inthede?nitionof?qin(2.5),we4\n",
      "incorporatetheofuniformconcentrationoverthequeryspaceQAby\n",
      "addingthequantity?(QA),whichmeasuresthecapacityofQA.Inaddition,\n",
      "undertheDe?nition2.2,thealgorithmAdoesnotinteractdirectlywithdata.\n",
      "Suchanrestrictioncharacterizesthefactthatinstatisticalproblems,the\n",
      "tivenessofanalgorithmonlydependsontheglobalstatisticalproperties,not\n",
      "theinformationofindividualdatapoints.Forinstance,algorithmsthatonly\n",
      "relyontheconvergenceoftheempiricaldistributiontothepopulationdistribu-\n",
      "tionarecontainedinthestatisticalquerymodel;whereasalgorithmsthathinge\n",
      "onthe?rstdatapoint(y1,x1)isnotallowed.Thisrestrictioncapturesavast\n",
      "familyofalgorithmsinstatisticsandmachinelearning,includingapplyinggra-\n",
      "dientmethodtomaximizelikelihoodfunction,matrixfactorizationalgorithms,\n",
      "expectation-maximizationalgorithms,andsamplingalgorithms[9].Basedon\n",
      "thestatisticalquerymodel,westudytheminimaxriskunderoraclecomplex-\n",
      "ityconstraints.Forthetestingproblem(2.3),letA(Tn)beaclassoftesting\n",
      "algorithmsunderthestatisticalquerymodelwithquerycomplexitynomore\n",
      "thanTn,with\n",
      "f\n",
      "Tn\n",
      "g\n",
      "n?1beingasequenceofpositiveintegersdependingonthe\n",
      "samplesizen.ForanyA?A(Tn)andanyoracler?R[?,n,Tn,?(QA)]that\n",
      "respondstoA,letH(A,r)bethesetoftestfunctionsthatdeterministically\n",
      "dependonA?squeriestotheoraclerandthecorrespondingresponses.Weuse\n",
      "P?todenotethedistributionoftherandomvariablesreturnedbyoraclerwhen\n",
      "themodelparameteris?.Forageneralhypothesistestingproblem,namely,\n",
      "H0:??G0versusH1:??G1,theminimaxtestingriskwithrespecttoan\n",
      "algorithmAandastatisticaloracler?R[?,n,Tn,?(QA)]isde?nedas???\n",
      "Rn(G0,G1;A,r):=infsupP?(?=1)+supP?(?=0).(2.7)??H(A,r)\n",
      "??G0\n",
      "??G1\n",
      "Comparedwiththeclassicalminimaxriskin(2.4),thenewnotionin(2.7)in-\n",
      "corporatesthecomputationalbudgetsviaoraclecomplexity.Inspeci?c,weonly\n",
      "considerthetestfunctionsobtainedbyanalgorithmwithatmostTnqueries\n",
      "6\n",
      "\n",
      "toastatisticaloracle.IfTnisapolynomialofthedimensionalityd,(2.7)char-\n",
      "acterizesthestatisticaloptimalityofcomputationalef?cientalgorithms.This\n",
      "motivatesustode?nethecomputationallytractableminimaxrate,whichcon-\n",
      "trastswithDe?nition2.1.De?nition2.3(Computationallytractableminimax\n",
      "rate).LetG1(?n):=\n",
      "f\n",
      "?:?(?)??n\n",
      "g\n",
      "beasequenceofmodelspaceswith\n",
      "minimumseparation?n,where?(?)istheSNR.Asequence\n",
      "f\n",
      "??n\n",
      "g\n",
      "n?1is\n",
      "calledacomputationallytractableminimaxrateif?Foranysequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1\n",
      "satisfying?n=o(??n),anyconstant?>0,andanyA?A(d?),?thereexists\n",
      "anoracler?R[?,n,Tn,?(QA)]suchthatlimn??Rn[G0,G1(?n);A,r]=\n",
      "1;??Foranysequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1satisfying?n=?(?n),thereexistaconstant\n",
      "?>0andanalgorithm?A?A(d?)suchthat,foranyr?R[?,n,Tn,?(QA\n",
      ")],wehavelimn??Rn[G0,G1(?n);A,r]=0.\n",
      "3\n",
      "MainResults\n",
      "Throughoutthispaper,weassumethatthecovariancematrix?in(2.1)is\n",
      "known.Speci?cally,forsomepositivede?nite??Rd?d,theparameterspaces\n",
      "ofthenullandalternativehypothesesarede?nedasG0(?):=\n",
      "f\n",
      "?=(?,?,?,?)\n",
      ":??Rd\n",
      "g\n",
      ",\n",
      "(3.1)d\n",
      "G1(?;?n):=\n",
      "f\n",
      "?=(?0,?1,?,?):?0,?1?R,?0??1?B0(s),?(?)?\n",
      "?n\n",
      "g\n",
      ".\n",
      "Accordingly,thetestingproblemofdetectingwhether?0?=?1istodistin-\n",
      "guishH0:??G0(?)versusH1:??G1(?;?n).\n",
      "(3.2)(3.3)\n",
      "In?3.1,wepresenttheminimaxrateofthedetectionproblemfroman\n",
      "information-theoreticperspective.In?3.2,underthestatisticalquerymodelin-\n",
      "troducedin?2.2,weprovideacomputationallowerboundandanearlymatching\n",
      "upperboundthatisachievedbyanef?cienttestingalgorithm.3.1\n",
      "Information-theoreticLimits\n",
      "NowweturntocharacterizetheminimaxrategiveninDe?nition2.1.For?parameter\n",
      "spaces(3.1)and(3.2)withknown?,weshowthatinhighlysparsesettingwhere\n",
      "s=o(d),wehave??n?=slogd/n?(1/?2?slogd/n),(3.4)5\n",
      "Toprove(3.4),we?rstpresentalowerboundwhichshowsthatthehypoth-\n",
      "esistestingproblemin(3.3)isimpossibleif?n=o(?n?).Theorem3.1.For\n",
      "thehypothesistestingproblemin(3.3)withknown?,weassumethatthere\n",
      "existsasmallconstant?>0suchthats=o(d1/2??).Let?n?bede?nedin\n",
      "(3.4).Foranysequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1suchthat?n=o(?n?),anyhypothesistest\n",
      "isasymptoticallypowerless,namely,limsupRn?[G0(?),G1(?;?n)]=1.\n",
      "n??\n",
      "?\n",
      "ByTheorem3.1,weobserveaphasetransitioninthenecessarySNRfor\n",
      "powerfuldetectionwhen?decreasesfromonetozero.Startingwithrateslog\n",
      "d/ninthesupervisedsettingwhere?=1,therequiredSNRgraduallyincreases\n",
      "aslabelqualitiesdecrease.Finally,when?reaches?zero,whichcorresponds\n",
      "totheunsupervisedsetting,powerfuldetectionrequirestheSNRtobe?(slog\n",
      "d/n).Itisworthnotingthatwhen?=(slogd/n)1/4,westillhave(n3s\n",
      "7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logd)1/4uncorruptedlabels.However,ourlowerbound(alongwiththeupper\n",
      "boundshowninTheorem3.2)indicatesthattheinformationcontainedinthese\n",
      "uncorruptedlabelsareburiedinthenoise,andcannotessentiallyimprovethe\n",
      "detectionqualitycomparedwiththeunsupervisedsetting.Nextweestablish\n",
      "amatchingupperboundforthedetectionproblemin(3.3).Wedenotethe\n",
      "conditionnumberofthecovariancematrix?by?,i.e.,?:=?max(?)/?min\n",
      "(?),where?max(?)and?min(?)arethelargestandsmallesteigenvalues\n",
      "of?,repectively.NotethatmarginallyYisuniformlydistributedover\n",
      "f\n",
      "0,1\n",
      "g\n",
      ".\n",
      "Foreaseofpresentation,weassumethatthesamplesizeis2nandeachclass\n",
      "containsexactlyndatapoints.Notethatwecanalwaysdiscardsomesamples\n",
      "inthelargerclasstomakethesamplesizesofbothclassestobeequal.Due\n",
      "tothelawoflargenumbers,thistrickwillnottheanalysisofsample\n",
      "complexityinthesenseoforderwise.dGiven2ni.i.d.samples\n",
      "f\n",
      "(yi,xi)\n",
      "g\n",
      "2n\n",
      "i=1of(Y,X)?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "?R,wede?newi=??1/2(x2i?x2i?1),foralli?[n].\n",
      "(0)nInaddition,wesplitthedataset\n",
      "f\n",
      "(yi,xi)\n",
      "g\n",
      "2ni=1intotwodisjoint\n",
      "parts\n",
      "f\n",
      "(0,xi)\n",
      "g\n",
      "i=1\n",
      "andde?ne\n",
      "(1)\n",
      "ui=xi\n",
      "(0)\n",
      "?xi,foralli?[n].\n",
      "(3.5)\n",
      "(1)and\n",
      "f\n",
      "(1,xi)\n",
      "g\n",
      "ni=1,\n",
      "(3.6)\n",
      "Wenotethatcomputingsamplein(3.5)and(3.6)iscriticalfor\n",
      "ourproblembecausewefocusondetectingthebetween?0and?1,\n",
      "andcomputingcanavoidestimatingEP?(X)thatmightbedense.\n",
      "Foranyintegers?[d],wede?neB2(s):=B0(s)?Sd?1asthesetofs-sparse\n",
      "vectorsontheunitsphereinRd.With\n",
      "f\n",
      "wi\n",
      "g\n",
      "ni=1and\n",
      "f\n",
      "ui\n",
      "g\n",
      "ni=1,weintroduce\n",
      "twotestfunctions??n1?(v???1wi)2?1:=1sup?1+?,(3.7)1?\n",
      "?1vv?B2(s)ni=12v???n1??2:=1sup?v,diag(?)?1/2ui???2\n",
      ",(3.8)v?B2(1)ni=1where?1,?2>0arealgorithmicparametersthatwill\n",
      "bespeci?edlater.Toprovidesomeintuitions,weconsiderthecasewhere?=\n",
      "I.Testfunction?1seeksasparsedirectionthatexplainsthemostvarianceof\n",
      "wi.Therefore,suchatestiscloselyrelatedtothesparseprincipalcomponent\n",
      "detection?nproblem[3].Testfunction?2simplyselectsthecoordinateofn?1\n",
      "i=1uithathasthelargestmagnitudeandcomparesitwith?2.Thistestis\n",
      "closelyrelatedtodetectingsparsenormalmeaninhighdimensions[16].Based\n",
      "onthesetwoingredients,weconstructour?naltestingfunction?as?=?1\n",
      "??2,i.e.,ifanyof?1and?2istrue,then?rejectsthenull.Thefollowing\n",
      "theoremestablishesasuf?cientconditionfortestfunction?tobeasymptotically\n",
      "powerful.Theorem3.2.Considerthetestingproblem(3.3)where?isknown\n",
      "andhasconditionnumber?.Fortestfunctions?1and?2de?nedin(3.7)and\n",
      "(3.8)withparameters?1and?2givenby???1=?slog(ed/s)/n,?2=8log\n",
      "d/n.\n",
      "Wede?netheultimatetestfunctionas?=?1??2.Weassumethats?C\n",
      "8\n",
      "\n",
      "?dforsomeabsoluteconstantCsandn?64?slog(ed/s).Thenif??n?C?\n",
      "??[slog(ed/s)/n?(1/?2?slogd/n)],(3.9)6\n",
      "whereC?isanabsoluteconstant,thentestfunction?isasymptotically\n",
      "powerful.Inspeci?c,wehavesupPn?(?=1)+??G0(?)\n",
      "sup??G1(?;?n)\n",
      "Pn?(?=0)?20/d.\n",
      "(3.10)\n",
      "Theorem3.2providesanon-asymptoticguarantee.Whenn?goestoin?nity,\n",
      "(3.10)impliesthatthetestfunction?isasymptoticallypowerful.Whens=\n",
      "o(d)and?isaconstant,(3.9)yields??n=?[slogd/n?(1/?2?slogd/n)],\n",
      "whichmatchesthelowerboundgiveninTheorem3.1.Thusweconcludethat\n",
      "?n?de?nedin(3.4)istheminimaxrateoftestingproblemin(3.3).Weremark\n",
      "thatwhens=?(d),?=1,i.e.,thestandard(low-dimensional)setting?oftwo\n",
      "sampletesting,theboundprovidedin(3.9)issub-optimalas?[22]showsthat\n",
      "SNRrated/nissuf?cientforasymptoticallypowerfuldetection?whenn=?(\n",
      "d).Itisthusworthnotingthatwefocusonthehighlysparsesettings=o(\n",
      "d)andprovidedsharpminimaxratefor??thisregime.Inthede?nitionof?1\n",
      "in(3.7),wesearchoverthesetB2(s).SinceB2(s)containsdsdistinctsetsof\n",
      "supports,computing?1requiresexponentialrunningtime.3.2\n",
      "ComputationalLimits\n",
      "Inthissection,wecharacterizethecomputationallytractableminimaxrate\n",
      "??ngiveninDe?nition2.3.Moreover,wefocusonthesettingwhere?isknown\n",
      "aprioriandtheparameterspacesforthenullandalternativehypothesesare\n",
      "de?ned?in(3.1)and(3.2),respectively.Themainresultisthat,inhighly\n",
      "sparsesettingwheres=o(d),wehave???n=s2/n?(1/?2?slogd/n).\n",
      "(3.11)\n",
      "We?rstpresentthelowerboundinthenextresult.\n",
      "Theorem3.3.Forthetestingproblemin(3.3)with?knownapriori,we\n",
      "makethesameassumptionsasinTheorem3.1.Foranysequence\n",
      "f\n",
      "?n\n",
      "g\n",
      "n?1such\n",
      "that?????s2/n?(1/?2?s/n),(3.12)?n=o?n??\n",
      "where?n?isde?nedin(3.4),anycomputationallytractabletestisasymp-\n",
      "toticallypowerlessunderthestatisticalquerymodel.Thatis,foranyconstant\n",
      "?>0andanyA?A(d?),thereexistsanoracle?r?R[?,n,Tn,?(QA)]such\n",
      "thatlimn??Rn[G0(?),G1(?,?n);A,r]=1.\n",
      "Wethelowerboundin(3.12)from?n?in(3.11)byalogarithmic\n",
      "termwhen?remark2that?1/n???slogd/n.Weexpectthisgapto\n",
      "beeliminatedbymoredelicateanalysisunderthestatisticalquerymodel.Now\n",
      "puttingTheorems3.1and3.3together,wedescribethe?moresupervision,less\n",
      "computation?phenomenonasfollows.(i)When0???(log2d/n)1/4,the\n",
      "computationallowerboundimpliesthattheuncorruptedlabelsareunableto\n",
      "improvethequalityofcomputationallytractabledetectioncomparedwiththe\n",
      "unsupervisedsetting.Inaddition,inthisregion,thegapbetween?n?and\n",
      "??nremainsthesame.(ii)When(log2d/n)1/4<??(slogd/n)1/4,the\n",
      "information-theoreticlowerboundshowsthattheuncorruptedlabelscannot\n",
      "improvethequalityofdetectioncomparedwithunsupervisedsetting.However,\n",
      "moreuncorruptedlabelsimprovethestatisticalperformancesofhypothesistests\n",
      "9\n",
      "\n",
      "thatarecomputationallytractablebyshrinkingthegapbetween?n?and??n.\n",
      "(iii)When(slogd/n)1/4<??1,havingmoreuncorruptedlabelsimprovesboth\n",
      "statisticaloptimalityandthecomputationalef?ciency.Inspeci?c,inthiscase,\n",
      "thegapbetween?n?and??nvanishesandwehave?n?=??n=1/?2?slog\n",
      "d/n.Nowwederiveanearlymatchingupperboundunderthestatisticalquery\n",
      "model,whichestablishesthecomputationallytractableminimaxratetogether\n",
      "withTheorem3.3.Weconstructacomputationallyef?cienttestingprocedure\n",
      "thatcombinestwotestfunctionswhichyieldsthetwopartsin??nrespectively.\n",
      "Similarto?1de?nedin(3.7),the?rsttestfunctiondiscardstheinformationof\n",
      "labels,whichworksforthepurelyunsupervisedsettingwhere?=0.Forj?\n",
      "[d],wedenoteby?jthej-thdiagonalelementof?.Underthestatisticalquery\n",
      "model,weconsiderthe2dqueryfunctions???(3.13)qj(y,x):=xj/?j?\n",
      "1\n",
      "f\n",
      "|xj/?j|?R?logd\n",
      "g\n",
      ",??q?j(y,x):=(x2j/?j?1)?1\n",
      "f\n",
      "|xj/?j|?R\n",
      "?logd\n",
      "g\n",
      ",forallj?[d],(3.14)7\n",
      "whereR>0isanabsoluteconstant.Hereweapplytruncationtothequery\n",
      "functionstoobtainboundedqueries,whichisspeci?edbythestatisticalquery\n",
      "modelinDe?nition2.2.Wedenotebyzqjandzq?jtherealizationsofthe\n",
      "randomvariablesoutputbythestatisticaloracleforqueryfunctionsqjandq?j\n",
      ",respectively.Asforthesecondtestfunction,similarto(3.8),weconsider??\n",
      "?qv(y,x)=(2y?1)?v?diag(?)?1/2x?1|v?diag(?)?1/2x|?R?log\n",
      "d(3.15)\n",
      "forallv?B2(1).WedenotebyZqvtheoutputofthestatisticaloraclecor-\n",
      "respondingtoqueryfunctionqv.Withthese4dqueryfunctions,weintroduce\n",
      "testfunctions?????1:=1sup(zq?j?zq2j)?C?1,?2:=1supzqv?2?\n",
      "2,(3.16)j?[d]\n",
      "v?B2(1)\n",
      "where?1and?2arepositiveparametersthatwillbespeci?edlaterandC\n",
      "isanabsoluteconstant.Theorem3.4.Forthetestfunctions?1and?2de?ned\n",
      "in(3.16),wede?netheultimatetestfunctionas?=?1??2.Weset???\n",
      "?1=R2logd?log(4d/?)/n,?2=Rlogd?log(4d/?)/n,(3.17)where?=\n",
      "o(1).Forthehypothesistestingproblemin(3.3),wefurtherassumethat??0\n",
      "?????1???C0forsomeconstantC0>0.Undertheassumptionthat????\n",
      "?sup(?0,j??1,j)2/?j=?1/?2?log2d?log(d/?)/n?logd?log(d/?)/n,\n",
      "(3.18)j?[d]\n",
      "?\n",
      "theriskof?satis?esthatRn(?)=sup??G0(?)P?(?=1)+sup??G1\n",
      "(?,?n)P?(?=0)?5?.Herewedenoteby?0,jand?1,jthej-thentryof?0\n",
      "and?1,respectively.Ifwesetthetailprobabilityofthestatisticalquerymodel\n",
      "tobe?=1/d,(3.18)showsthat?isasymptoticallypowerfulifsupj?[d](?0,j\n",
      "??1,j)2/?j=?[(1/?2?log3d/n)?(log3d/n)1/2].?Whentheenergyof\n",
      "?0??1isspreadoveritssupport,??0??1??and??0??1?2/sareclose.\n",
      "Undertheassumptionthattheconditionnumber?of?isaconstant,(3.18)is\n",
      "impliedby?n?(s2log3d/n)1/2?(1/?2?slog3d/n).\n",
      "ComparedwithTheorem3.3,theabove?upperboundmatchesthecompu-\n",
      "tationallowerbounduptoalogarithmicfactorand??nisbetweens2/n?\n",
      "(1/?2?slogd/n)and(s2log3d/n)1/2?(1/?2?slog3d/n).Notethatthe\n",
      "10\n",
      "\n",
      "truncationonqueryfunctionsin(3.13)and(3.14)yieldsanadditionallogarith-\n",
      "micterm,whichcouldbereducedto(s2logd/n)1/2?(1/?2?slogd/n)using\n",
      "moredelicateanalysis.Moreover,thetestfunction?1isessentiallybasedon\n",
      "adiagonalthresholdingalgorithmperformedonthecovariancematrix?ofX.\n",
      "Theworkin[6]providesamoredelicateanalysisofthisalgorithmwhichestab-\n",
      "lishesthes2/nrate.Theiralgorithmcanalsobeformulatedintothestatistical\n",
      "querymodel;weusethesimplerversionin(3.16)?foreaseofpresentation.\n",
      "Therefore,withmoresophicatedprooftechinique,itcanbeshownthats2/n?\n",
      "(1/?2?slogd/n)isthecriticalthresholdforasymptoticallypowerfuldetection\n",
      "withcomputationalef?ciency.3.3\n",
      "ImplicationforEstimation\n",
      "Ouraforementionedphasetransitioninthedetectionproblemsdirectlyim-\n",
      "pliesthestatisticalandcomputationalintheproblemofestimation.\n",
      "Weconsidertheproblemofestimatingtheparameter??=?0??1ofthebinary\n",
      "classi?cationmodelin(2.1)and(2.2),where??iss-sparseand?isknowna\n",
      "priori.Weassumethatthesignaltonoiseratiois?(?)=?????1????n=o(?\n",
      "?n).Foranyconstant?>0andanyA?A(T)withT=O(d?),supposewe\n",
      "obtainanestimator?of??byalgorithmAunderthestatisticalquerymodel.\n",
      "If???convergesto??inthesensethat????1??(?????)?(?????)=\n",
      "o[?n2/?(?)],\n",
      "????1?????????1??|=o(?n).Thusthetestfunction?=1\n",
      "f\n",
      "????\n",
      "?????wehave|???n/2\n",
      "g\n",
      "isasymptoticallypowerful,whichcontradictsthe\n",
      "computationallowerboundinTheorem3.3.????)???1(??????)?C?n2\n",
      "/?(?)foranyTherefore,thereexistsaconstantCsuchthat(???estimator??\n",
      "constructedfrompolynomialnumberofqueries.Acknowledgments\n",
      "WewouldliketothankVitalyFeldmanforvaluablediscussions.8\n",
      "2References\n",
      "[1]Angluin,D.andLaird,P.(1988).Learningfromnoisyexamples.Machine\n",
      "Learning,2343?370.[2]Berthet,Q.andRigollet,P.(2013).Computational\n",
      "lowerboundsforsparsePCA.InConferenceonLearningTheory.[3]Berthet,\n",
      "Q.andRigollet,P.(2013).Optimaldetectionofsparseprincipalcomponentsin\n",
      "highdimension.TheAnnalsofStatistics,411780?1815.[4]Chandrasekaran,\n",
      "V.andJordan,M.I.(2013).Computationalandstatisticalviaconvex\n",
      "relaxation.ProceedingsoftheNationalAcademyofSciences,1101181?1190.\n",
      "[5]Chen,Y.andXu,J.(2014).Statistical-computationalinplanted\n",
      "problemsandsubmatrixlocalizationwithagrowingnumberofclustersand\n",
      "submatrices.arXivpreprintarXiv:1402.1267.[6]Deshpande,Y.andMon-\n",
      "tanari,A.(2014).SparsePCAviacovariancethresholding.InAdvancesin\n",
      "NeuralInformationProcessingSystems.[7]Fan,J.,Feng,Y.andTong,X.\n",
      "(2012).Aroadtoclassi?cationinhighdimensionalspace:Theregularizedop-\n",
      "timalaf?nediscriminant.JournaloftheRoyalStatisticalSociety:SeriesB,\n",
      "74745?771.[8]Fan,J.,Liu,H.,Wang,Z.andYang,Z.(2016).Curseof\n",
      "heterogeneity:Computationalbarriersinsparsemixturemodelsandphasere-\n",
      "11\n",
      "\n",
      "trieval.Manuscript.[9]Feldman,V.,Grigorescu,E.,Reyzin,L.,Vempala,S.\n",
      "andXiao,Y.(2013).Statisticalalgorithmsandalowerboundfordetecting\n",
      "plantedcliques.InACMSymposiumonTheoryofComputing.[10]Feld-\n",
      "man,V.,Guzman,C.andVempala,S.(2015).Statisticalqueryalgorithms\n",
      "forstochasticconvexoptimization.arXivpreprintarXiv:1512.09170.[11]Feld-\n",
      "man,V.,Perkins,W.andVempala,S.(2015).Onthecomplexityofrandom\n",
      "satis?abilityproblemswithplantedsolutions.InACMSymposiumonTheory\n",
      "ofComputing.[12]Fr?nay,B.andVerleysen,M.(2014).Classi?cationinthe\n",
      "presenceoflabelnoise:Asurvey.IEEETransactionsonNeuralNetworksand\n",
      "LearningSystems,25845?869.[13]Gao,C.,Ma,Z.andZhou,H.H.(2014).\n",
      "SparseCCA:Adaptiveestimationandcomputationalbarriers.arXivpreprint\n",
      "arXiv:1409.8565.[14]Garc?a-Garc?a,D.andWilliamson,R.C.(2011).Degrees\n",
      "ofsupervision.InAdvancesinNeuralInformationProcessingSystems.[15]Ha-\n",
      "jek,B.,Wu,Y.andXu,J.(2014).Computationallowerboundsforcommunity\n",
      "detectiononrandomgraphs.arXivpreprintarXiv:1406.6625.[16]Johnstone,\n",
      "I.M.(1994).Onminimaxestimationofasparsenormalmeanvector.The\n",
      "AnnalsofStatistics,22271?289.[17]Joulin,A.andBach,F.R.(2012).A\n",
      "convexrelaxationforweaklysupervisedclassi?ers.InInternationalConference\n",
      "onMachineLearning.[18]Kearns,M.(1993).Ef?cientnoise-tolerantlearn-\n",
      "ingfromstatisticalqueries.InACMSymposiumonTheoryofComputing.\n",
      "[19]Ma,Z.andWu,Y.(2014).Computationalbarriersinminimaxsubma-\n",
      "trixdetection.TheAnnalsofStatistics,431089?1116.[20]Nettleton,D.F.,\n",
      "Orriols-Puig,A.andFornells,A.(2010).Astudyofthetofttypes\n",
      "ofnoiseontheprecisionofsupervisedlearningtechniques.Arti?cialIntelli-\n",
      "genceReview,33275?306.[21]Patrini,G.,Nielsen,F.,Nock,R.andCarioni,\n",
      "M.(2016).Lossfactorization,weaklysupervisedlearningandlabelnoisero-\n",
      "bustness.arXivpreprintarXiv:1602.02450.[22]Ramdas,A.,Singh,A.and\n",
      "Wasserman,L.(2016).Classi?cationaccuracyasaproxyfortwosampletest-\n",
      "ing.arXivpreprintarXiv:1602.02210.[23]TonyCai,T.,Liu,W.andXia,Y.\n",
      "(2014).Two-sampletestofhighdimensionalmeansunderdependence.Journal\n",
      "oftheRoyalStatisticalSociety:SeriesB,76349?372.[24]Tsybakov,A.B.\n",
      "(2008).Introductiontononparametricestimation.Springer.[25]Vershynin,\n",
      "R.(2010).Introductiontothenon-asymptoticanalysisofrandommatrices.\n",
      "arXivpreprintarXiv:1011.3027.[26]Wang,T.,Berthet,Q.andSamworth,\n",
      "R.J.(2014).Statisticalandcomputationalinestimationofsparse\n",
      "principalcomponents.arXivpreprintarXiv:1408.5369.[27]Wang,Z.,Gu,Q.\n",
      "andLiu,H.(2015).Sharpcomputational-statisticalphasetransitionsviaor-\n",
      "aclecomputationalmodel.arXivpreprintarXiv:1512.08861.[28]Zhang,Y.,\n",
      "Wainwright,M.J.andJordan,M.I.(2014).Lowerboundsontheperformance\n",
      "ofpolynomialtimealgorithmsforsparselinearregression.InConferenceon\n",
      "LearningTheory.\n",
      "9\n",
      "12\n",
      "\n",
      "PP3851.pdf\n",
      "PP3851.pdf 13\n",
      "Non-ParametricBayesianDictionaryLearningfor\n",
      "SparseImageRepresentations\n",
      "Authoredby:\n",
      "LawrenceCarin\n",
      "GuillermoSapiro\n",
      "LuRen\n",
      "MingyuanZhou\n",
      "HaojunChen\n",
      "JohnW.Paisley\n",
      "Abstract\n",
      "Non-parametricBayesiantechniquesareconsideredforlearningdic-\n",
      "tionariesforsparseimagerepresentations,withapplicationsindenoising,\n",
      "inpaintingandcompressivesensing(CS).Thebetaprocessisemployed\n",
      "asapriorforlearningthedictionary,andthisnon-parametricmethod\n",
      "naturallyinfersanappropriatedictionarysize.TheDirichletprocessand\n",
      "aprobitstick-breakingprocessarealsoconsideredtoexploitstructure\n",
      "withinanimage.Theproposedmethodcanlearnasparsedictionary\n",
      "insitu;trainingimagesmaybeexploitedifavailable,buttheyarenot\n",
      "required.Further,thenoisevarianceneednotbeknown,andcanbe\n",
      "non-stationary.Anothervirtueoftheproposedmethodisthatsequen-\n",
      "tialinferencecanbereadilyemployed,therebyallowingscalingtolarge\n",
      "images.Severalexampleresultsarepresented,usingbothGibbsand\n",
      "variationalBayesianinference,withcomparisonstootherstate-of-the-art\n",
      "approaches.\n",
      "1PaperBody\n",
      "Therehasbeentrecentinterestinsparsesignalexpansionsinseveral\n",
      "settings.Forexample,suchalgorithmsasthesupportvectormachine(SVM)[1],\n",
      "therelevancevectormachine(RVM)[2],Lasso[3]andmanyothershavebeen\n",
      "developedforsparseregression(andAsparserepresentationhas\n",
      "severaladvantages,includingthefactthatitencouragesasimplemodel,and\n",
      "thereforeover-trainingisoftenavoided.Theinferredsparsecotsalso\n",
      "oftenhavebiological/physicalmeaning,ofinterestformodelinterpretation[4].\n",
      "Ofrelevanceforthecurrentpaper,therehasrecentlybeentinterest\n",
      "insparserepresentationsinthecontextofdenoising,inpainting[5?10],com-\n",
      "1\n",
      "\n",
      "pressivesensing(CS)[11,12],and[13].Alloftheseapplications\n",
      "exploitthefactthatmostimagesmaybesparselyrepresentedinanappro-\n",
      "priatedictionary.MostoftheCSliteratureassumes?wavelet\n",
      "andDCTbases/dictionaries[14],butrecentdenoisingandinpaintingresearch\n",
      "hasdemonstratedthetadvantagesoflearninganoftenover-complete\n",
      "dictionarymatchedtothesignalsofinterest(e.g.,images)[5?10,12,15].The\n",
      "purposeofthispaperistoperformdictionarylearningusingnewnon-parametric\n",
      "Bayesiantechnology[16,17],thatersseveraladvantagesnotfoundinearlier\n",
      "approaches,whichhavegenerallysoughtpointestimates.Thispapermakes\n",
      "fourmaincontributions:?Thedictionaryislearnedusingabetaprocesscon-\n",
      "struction[16,17],andthereforethenumberofdictionaryelementsandtheir\n",
      "relativeimportancemaybeinferrednon-parametrically.?Forthedenoising\n",
      "andinpaintingapplications,wedonothavetoassumeaprioriknowledgeofthe\n",
      "noisevariance(itisinferredwithintheinversion).Thenoisevariancecanalso\n",
      "benon-stationary.?Thespatialinter-relationshipsbetweentcompo-\n",
      "nentsinimagesareexploitedbyuseoftheDirichletprocess[18]andaprobit\n",
      "stick-breakingprocess[19].1\n",
      "?Usinglearneddictionaries,inferredorinsitu,theproposedap-\n",
      "proachyieldsCSperformancethatismarkedlybetterthanexistingstandard\n",
      "CSmethodsasappliedtoimagery.\n",
      "2\n",
      "DictionaryLearningwithaBetaProcess\n",
      "Intraditionalsparsecodingtasks,oneconsidersasignalx?<nanda\n",
      "dictionaryD=(d1,d2,...,dM)whereeachdm?<n.Wewishtoimpose\n",
      "thatanyx?<nmayberepresented?=D?,where??<Missparse,andour\n",
      "objectiveistoalsominimizethe`2approximatelyasxerrork?x?xk2.With\n",
      "aproperdictionary,asparse?oftenmanifestsrobustnesstonoise(themodel\n",
      "doesn?tnoisewell),andthemodelalsoyieldseinferenceof?even\n",
      "whenxispartiallyorindirectlyobservedviaasmallnumberofmeasurements\n",
      "(ofinterestforinpainting,interpolationandcompressivesensing[5,7]).Tothe\n",
      "authors?knowledge,allpreviousworkinthisdirectionhasbeenperformedin\n",
      "thefollowingmanner:(i)ifDisgiven,thesparsevector?isestimatedviaa\n",
      "pointestimate(withoutaposteriordistribution),typicallybasedonorthogonal\n",
      "matchingpursuits(OMP),basispursuitsorrelatedmethods,forwhichthe\n",
      "stoppingcriteriaisbyassumingknowledge(orestimation)of\n",
      "thenoisevarianceorthesparsitylevelof?;and(ii)whenthedictionaryDis\n",
      "tobelearned,thedictionarysizeMmustbesetapriori,andapointestimate\n",
      "isachievedforD(inpracticeonemayinferMviacross-validation,withthis\n",
      "stepavoidedintheproposedmethod).Inmanyapplicationsonemaynotknow\n",
      "thenoisevarianceoranappropriatesparsitylevelof?;further,onemaybe\n",
      "interestedintheconoftheestimate(e.g.,?errorbars?ontheestimate\n",
      "of?).Toaddressthesegoals,weproposedevelopmentofanon-parametric\n",
      "Bayesianformulationtothisproblem,intermsofthebetaprocess,thisallowing\n",
      "onetoinfertheappropriatevaluesofMandk?k0(sparsitylevel)jointly,also\n",
      "manifestingafullposteriordensityfunctiononthelearnedDandtheinferred\n",
      "?(foraparticularx),yieldingameasureofintheinversion.As\n",
      "2\n",
      "\n",
      "discussedfurtherbelow,thenon-parametricBayesianformulationalsoallows\n",
      "onetorelaxotherassumptionsthathavebeenmadeintheoflearningD\n",
      "and?fordenoising,inpaintingandcompressivesensing.Further,theadditionof\n",
      "othergoalsarereadilyaddressedwithinthenon-parametricBayesianparadigm,\n",
      "e.g.designingDforjointcompressionandc2.1\n",
      "Betaprocessformulation\n",
      "Wedesirethemodelx=D?+,wherex?<nandD?<n?M,andwewishto\n",
      "learnDandinsodoinginferM.Towardthisend,weconsideradictionaryD?\n",
      "<n?K,withK??;byinferringthenumberofcolumnsofDthatarerequiredfor\n",
      "accuraterepresentationofx,theappropriatevalueofMisimplicitlyinferred\n",
      "(workhasbeenconsideredin[20,21]fortherelatedbutdistinctapplicationof\n",
      "factoranalysis).Wewishtoalsoimposethat??<Kissparse,andtherefore\n",
      "onlyasmallfractionofthecolumnsofDareusedforrepresentationofagiven\n",
      "x.Sp,assumethatwehaveatrainingsetD=\n",
      "f\n",
      "xi,yi\n",
      "g\n",
      "i=1,N,where\n",
      "xi?<nandyi?\n",
      "f\n",
      "1,2,...,Nc\n",
      "g\n",
      ",whereNc?2representsthenumberof\n",
      "classesfromwhichthedataarise;whenlearningthedictionaryweignorethe\n",
      "classlabelsyi,andlaterdiscusshowtheymaybeconsideredinthelearning\n",
      "process.Thetwo-parameterbetaprocess(BP)wasdevelopedin[17],towhich\n",
      "thereaderisreferredforfurtherdetails;wehereonlyprovidethosedetailsof\n",
      "relevanceforthecurrentapplication.TheBPwithparametersa>0andb>0,\n",
      "andbasemeasureH0,isrepresentedasBP(a,b,H0),andadrawH?BP(a,\n",
      "b,H0)mayberepresentedasH(?)=\n",
      "KX\n",
      "?k??k(?)\n",
      "?k?Beta(a/K,b(K?1)/K)\n",
      "?k?H0\n",
      "(1)\n",
      "k=1\n",
      "withthisavalidmeasureasK??.Theexpression??k(?)equalsone\n",
      "if?=?kandiszerootherwise.Therefore,H(?)representsavectorofK\n",
      "probabilities,witheachassociatedwitharespectiveatom?k.Inthelimit\n",
      "K??,H(?)correspondstoanvectorofprobabilities,and\n",
      "eachprobabilityhasanassociatedatom?kdrawni.i.d.fromH0.UsingH(?),\n",
      "wemaynowdrawNbinaryvectors,theithofwhichisdenotedzi?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "K\n",
      ",andthekthcomponentofziisdrawnzik?Bernoulli(?k).TheseNbinary\n",
      "columnvectorsareusedtoconstituteamatrixZ?\n",
      "f\n",
      "0,1\n",
      "g\n",
      "K?N,withithcolumn\n",
      "correspondingtozi;thekthrowofZisassociatedwithatom?k,drawn\n",
      "asdiscussedabove.Forourproblemtheatoms?k?<nwillcorrespondto\n",
      "candidatemembersofourdictionaryD,andthebinaryvectorziwhich\n",
      "membersofthedictionaryareusedtorepresentsamplexi?D.2\n",
      "Let?=(?1,?2,...,?K),andwemayconsiderthelimitK??.\n",
      "Anaiveformofourmodel,forrepresentationofsamplexi?D,isxi=?zi+\n",
      "i.However,thisishighlyrestrictive,asitimposesthatthecoetsofthe\n",
      "dictionaryexpansionmustbebinary.Toaddressthis,wedraw?1weightswi?N\n",
      "(0,?wIK),where?wistheprecisionorinversevariance;thedictionaryweights\n",
      "arenow?i=zi?wi,andxi=??i+i,where?representstheHadamard\n",
      "3\n",
      "\n",
      "(element-wise)multiplicationoftwovectors.Notethat,byconstruction,?is\n",
      "sparse;thisimpositionofsparsenessisdistinctfromthewidelyusedLaplace\n",
      "shrinkageprior[3],whichimposesthatmanycotsaresmallbutnot\n",
      "necessarilyexactlyzero.Forsimplicityweassumethatthedictionaryelements,\n",
      "bytheatoms?k,aredrawnfromamultivariateGaussianbaseH0\n",
      ",andthecomponentsoftheerrorvectorsiaredrawni.i.d.fromazero-mean\n",
      "Gaussian.Thehierarchicalformofthemodelmaynowbeexpressedasxi=\n",
      "??i+i,?i=zi?wi?=(?1,?2,...,?K),?k?N(0,n?1In)wi\n",
      "?\n",
      "zi\n",
      "?\n",
      "?1N(0,?wIK),KY\n",
      "i?N(0,??1In)?k?Beta(a/K,b(K?1)/K)\n",
      "Bernoulli(?k),\n",
      "(2)\n",
      "k=1\n",
      "Non-informativegammahyper-priorsaretypicallyplacedon?wand?.\n",
      "Consecutiveelementsintheabovehierarchicalmodelareintheconjugateex-\n",
      "ponentialfamily,andthereforeinferencemaybeimplementedviaavariational\n",
      "Bayesian[22]orGibbs-samplinganalysis,withanalyticupdateequations(allin-\n",
      "ferenceupdateequations,andthesoftware,canbefoundathttp://people.ee.duke.edu/?lihan/cs/\n",
      ").Afterperformingsuchinference,weretainthosecolumnsof?thatareused\n",
      "intherepresentationofthedatainD,therebyinferringDandhenceM.To\n",
      "imposeourdesirethatthevectorofdictionaryweights?issparse,onemay\n",
      "adjusttheparametersaandb.Particularly,asdiscussedin[17],inthelimitK\n",
      "??,thenumberofelementsofzithatarenon-zeroisarandomvariabledrawn\n",
      "fromPoisson(a/b).InSection3.1wediscussthefactthattheseparametersare\n",
      "ingeneralnon-informativeandthesparsityisintrinsictothedata.2.2\n",
      "Accountingforatask\n",
      "ThereareproblemsforwhichitisdesiredthatxissparselyrenderedinD,\n",
      "andtheassociatedweightvector?maybeemployedforotherpurposesbeyond\n",
      "representation.Forexample,onemayperformataskbasedon\n",
      "?.Ifoneisinterestedinjointcompressionandbothgoalsshould\n",
      "beaccountedforwhendesigningD.Forsimplicity,weassumethatthenumber\n",
      "ofclassesisNC=2(binarywiththisreadilyextended[23]to\n",
      "NC>2.Following[9],wemayalinearorbilinearbasedonthe\n",
      "sparseweights?andtheassociateddatax(inthebilinearcase),withthishere\n",
      "implementedintheformofaprobitWefocusonthelinearmodel,\n",
      "asitissimpler(hasfewerparameters),andtheresultsin[9]demonstrated\n",
      "thatitwasoftenasgoodorbetterthanthebilinearToaccountfor\n",
      "themodelin(2)remainsunchanged,andthefollowingmaybe\n",
      "addedtothetopofthehierarchy:?+?>0,yi=2if?T??+?<0,??\n",
      "N(0,???1IK+1),and??N(0,?0?1),whereyi=1if?T?K+1K??<?\n",
      "isthesameas??<withanappendedone,toaccountforthebias.\n",
      "Again,onetypicallyplaces(non-informative)gammahyper-priorson??and?0\n",
      ".Withtheaddedlayersforthetheconjugate-exponentialcharacterof\n",
      "4\n",
      "\n",
      "themodelisretained,sustainingtheabilitytoperformVBorMCMCinference\n",
      "withanalyticupdateequations.Notethatthemodelin(2)maybeemployed\n",
      "forunlabeleddata,andtheextensionabovemaybeemployedfortheavailable\n",
      "labeleddata;consequently,alldata(labeledandunlabeled)maybeprocessed\n",
      "jointlytoinferD.2.3\n",
      "Sequentialdictionarylearningforlargetrainingsets\n",
      "Intheabovediscussion,weimplicitlyassumedalldataD=\n",
      "f\n",
      "xi,yi\n",
      "g\n",
      "i=1,N\n",
      "areusedtogethertoinferthedictionaryD.However,insomeapplicationsN\n",
      "maybelarge,andthereforesucha?batch?approachisundesirable.Toaddress\n",
      "thisissueonemaypartitionthedataasD=D1?D2?...DJ?1?DJ,\n",
      "withthedataprocessedsequentially.Thisissuehasbeenconsideredforpoint\n",
      "estimatesofD[8],inwhichconsiderationsarerequiredtoassurealgorithm\n",
      "convergence.Itisofinteresttonotethatsequentialinferenceishandled\n",
      "naturallyviatheproposedBayesiananalysis.3\n",
      "Sp,letp(D|D,?)representtheposterioronthedesireddictionary,\n",
      "withallothermodelparametersmarginalizedout(e.g.,thesample-dependent\n",
      "cots?);thevector?representsthemodelhyper-parameters.Ina\n",
      "Bayesiananalysis,ratherthanevaluatingp(D|D,?)directly,onemayem-\n",
      "ploythesamemodel(prior)toinferp(D|D1,?).Thisposteriormaythen\n",
      "serveasapriorforDwhenconsideringnextD2,inferringp(D|D1?D2,\n",
      "?).WhendoingvariationalBayesian(VB)inferencewehaveananalyticap-\n",
      "proximaterepresentationforposteriorssuchasp(D|D1,?),whileforGibbs\n",
      "samplingwemayusetheinferredsamples.WhenpresentingresultsinSection\n",
      "5,wediscussadditionalmeansofsequentiallyacceleratingaGibbssampler.\n",
      "33.1\n",
      "Denoising,InpaintingandCompressiveSensingImageDenoisingandIn-\n",
      "painting\n",
      "AssumewearegivenanimageI?<Ny?Nxwithadditivenoiseandmissing\n",
      "pixels;wehereassumeamonochromeimageforsimplicity,butcolorimages\n",
      "arealsoreadilyhandled,asdemonstratedwhenpresentingresults.Asisdone\n",
      "typically[6,7],wepartitiontheimageintoNB=(Ny?2B+1)?(Nx?\n",
      "B+1)overlappingblocks\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NB,foreachofwhichxi?<B(B=8is\n",
      "typicallyused).Ifthereisonlyadditivenoisebutnomissingpixels,thenthe\n",
      "modelin(2)canbereadilyappliedforsimultaneousdictionarylearningand\n",
      "imagedenoising.Iftherearebothnoiseandmissingpixels,insteadofdirectly\n",
      "observingxi,weobserveasubsetofthepixelsineachxi.Notethathere?\n",
      "and\n",
      "f\n",
      "?i\n",
      "g\n",
      "i=1,NB,whichareusedtorecovertheoriginalnoise-freeandcomplete\n",
      "image,aredirectlyinferredfromthedataundertest;onemayalsoemployan\n",
      "appropriatetrainingsetDwithwhichtolearnadictionaryDorfor\n",
      "initializationofinsitulearning.Indenoisingandinpaintingstudiesofthistype\n",
      "(seeforexample[6,7]andreferencestherein),itisoftenassumedthateitherthe\n",
      "varianceisknownandusedasa?stopping?criteria,orthatthesparsitylevelis\n",
      "pre-determinedandforalli?\n",
      "f\n",
      "1,NB\n",
      "g\n",
      ".Whilethesemaybepracticalin\n",
      "someapplications,wefeelitismoredesirabletonotmaketheseassumptions.\n",
      "In(2)thenoiseprecision(inversevariance),?,isassumeddrawnfromanon-\n",
      "informativegammadistribution,andafullposteriordensityfunctionisinferred\n",
      "5\n",
      "\n",
      "for?(andallothermodelparameters).Inaddition,theproblemsofaddressing\n",
      "spatiallynonuniformnoiseaswellasnonuniformnoiseacrosscolorchannelsare\n",
      "ofinterest[7];theyarereadilyhandledintheproposedmodelbydrawinga\n",
      "separateprecision?foreachcolorchannelineachB?Bblock,eachofwhich\n",
      "isdrawnfromasharedgammaprior.Thesparsityleveloftherepresentation\n",
      "inourmodel,i.e.,\n",
      "f\n",
      "k?ik0\n",
      "g\n",
      "i=1,N,isbytheparametersaandbin\n",
      "thebetapriorin(2).Examiningtheposteriorp(?k|?)?Beta(a/K+PN\n",
      "PNi=1zik,b(K?1)/K+N?i=1zik),conditionedonallotherparameters,\n",
      "wethatmostsettingsofaandbtendtobenon-informative,especially\n",
      "inthecaseofsequentiallearning(discussedfurtherinSection5).Therefore,\n",
      "theaveragesparsityleveloftherepresentationisinferredbythedataitselfand\n",
      "eachsamplexihasitsownuniquesparserepresentationbasedontheposterior,\n",
      "whichrendersmuchmoreythanenforcingthesamesparsitylevelfor\n",
      "eachsample.3.2\n",
      "Compressivesensing\n",
      "WeconsiderCSinthemanneremployedin[12].Assumeourobjectiveisto\n",
      "measureanimageI?<Ny?Nx,withthisimageconstitutingthe8?8blocks\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NB.Ratherthanmeasuringthexidirectly,pixel-by-pixel,inCSwe\n",
      "performtheprojectionmeasurementvi=?xi,wherevi?<Np,withNp\n",
      "representingthenumberofprojections,and??<Np?64(assumingthatxiis\n",
      "representedbya64-dimensionalvector).Therearemany(typicallyrandom)\n",
      "waysinwhich?maybeconstructed,withthereaderreferredto[24].Ourgoal\n",
      "istohaveNp64,therebyyieldingcompressivemeasurements.BasedontheCS\n",
      "measurements\n",
      "f\n",
      "vi\n",
      "g\n",
      "i=1,NB,ourobjectiveistorecover\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NB.Consider\n",
      "apotentialdictionary?,asdiscussedinSection2.Itisassumedthatforeach\n",
      "ofthe\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NBfromtheimageundertestxi=??i+i,forsparse?iand\n",
      "relativelysmallerrorkik2.ThenumberofrequiredprojectionsNpneededfor\n",
      "accurateestimationof?iisproportionaltok?ik0[11],withthisunderscoring\n",
      "thedesirabilityoflearningadictionaryinwhichverysparserepresentationsare\n",
      "manifested(ascomparedtousingan?waveletsorDCTbasis).\n",
      "ForCSinversion,themodelin(2)isemployed,andthereforetheappropriate\n",
      "dictionaryDislearnedjointlywhileperformingCSinversion,insituonthe\n",
      "imageundertest.WhenperformingCSanaly4\n",
      "sis,in(2),ratherthanobservingxi,weobservevi=?D?i+i,fori=1,...\n",
      ",NB(thelikelihoodfunctionisthereforemoslightly).Asdiscussedwhen\n",
      "presentingresults,onemayalsolearntheCSdictionaryinadvance,\n",
      "withappropriatetrainingimages(usingthemodelin(2)).However,theunique\n",
      "opportunityforjointCSinversionandlearningofanappropriateparsimonious\n",
      "dictionaryisdeemedtobeatadvantage,asitdoesnotpresupposethat\n",
      "onewouldknowanappropriatetrainingsetinadvance.Theinpaintingproblem\n",
      "maybeviewedasaspecialcaseofCS,inwhicheachrowof?correspondstoa\n",
      "deltafunction,locatingauniquepixelontheimageatwhichuseful(unobscured)\n",
      "dataareobserved.Thosepixelsthatareunobserved,orthatarecontaminated\n",
      "(e.g.,bysuperposedtext[7])arenotconsideredwheninferringthe?iandD.A\n",
      "CScameradesignedaroundaninpaintingconstructionhasseveraladvantages,\n",
      "fromthestandpointofsimplicity.AsobservedfromtheresultsinSection5,an\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inpainting-basedCScamerawouldsimplyobserveasubsetoftheusualpixels,\n",
      "selectedatrandom.\n",
      "4\n",
      "ExploitingSpatialStructure\n",
      "Fortheapplicationsdiscussedabove,the\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NBcomefromthesingle\n",
      "imageundertest,andconsequentlythereisunderlying(spatial)structurethat\n",
      "shouldideallybeexploited.Ratherthanre-writingtheentiremodelin(2),we\n",
      "focusonthefollowingequationsinthehierarchy:zi?QKQKk=1Bernoulli(?k\n",
      "),and??k=1Beta(a/K,b(K?1)/K).Insteadofhavingasinglevector?=\n",
      "f\n",
      "?1,...,?K\n",
      "g\n",
      "thatissharedforall\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NB,itisexpectedthatthere\n",
      "maybeamixtureof?vectors,correspondingtotsegmentsintheimage.\n",
      "Sincethenumberofmixturecomponentsisnotknownapriori,thismixture\n",
      "modelismodeledviaaDirichletprocess[18].Wemaythereforeemploy,fori\n",
      "=1,...,NB,zi?\n",
      "KY\n",
      "Bernoulli(?ik)\n",
      "?i?G\n",
      "G?DP(?,\n",
      "k=1\n",
      "KY\n",
      "Beta(a/K,b(K?1)/K))\n",
      "(3)\n",
      "k=1\n",
      "QKAlternatively,wemayclusterthezidirectly,yieldingzi?G,G?\n",
      "DP(?,k=1Bernoulli(?k)),QK??k=1Beta(a/K,b(K?1)/K),wherethez\n",
      "iaredrawni.i.d.fromG.InpracticeweimplementsuchDPconstructionsvia\n",
      "atruncatedstick-breakingrepresentation[25],againretainingtheconjugate-\n",
      "exponentialstructureofinterestforanalyticVBorGibbsinference.Insuch\n",
      "ananalysisweplaceanon-informativegammapriorontheprecision?.The\n",
      "constructionin(3)clusterstheblocks,andthereforeitimposesstructurenot\n",
      "constitutedinthesimplermodelin(2).However,theDPstillassumesthat\n",
      "themembersof\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NBareexchangeable.Spacelimitationsprecludedis-\n",
      "cussingthismatterindetailhere,butwehavealsoconsideredreplacementofthe\n",
      "DPframeworkabovewithaprobitstick-breakingprocess(PSBP)[19],which\n",
      "explicitlyimposesthatitismorelikelyforproximateblockstobeinthesame\n",
      "cluster,relativetodistantblocks.Whenpresentingresults,weshowexamples\n",
      "inwhichPSBPhasbeenused,withitsrelativeenesscomparedtothe\n",
      "simplerDPconstruction.ThePSBPagainretainsfullconjugate-exponential\n",
      "characterwithinthehierarchy,ofinterestfortinference,asdiscussed\n",
      "above.\n",
      "5\n",
      "ExampleResults\n",
      "Forthedenoisingandinpaintingresults,weobservedthattheGibbssampler\n",
      "providedbetterperformancethanassociatedvariationalBayesianinference.For\n",
      "denoisingandinpaintingwemayexploitshiftedversionsofthedata,which\n",
      "acceleratesconvergencesubstantially(discussedindetailbelow).Therefore,\n",
      "7\n",
      "\n",
      "alldenoisingandinpaintingresultsarebasedonntGibbssampling.For\n",
      "CSwecannotexploitshiftedimages,andthereforetoachievefastinversion\n",
      "variationalBayesian(VB)inference[22]isemployed;forthisapplicationVB\n",
      "hasproventobequitee,asdiscussedbelow.Thesamesetofmodel\n",
      "hyper-parametersareusedacrossallourdenoising,inpaintingandCSexamples\n",
      "(notuningwasperformed):allgammapriorsaresetasGamma(10?6,10?6),\n",
      "alongthelinessuggestedin[2],andthebetadistributionparametersareset\n",
      "witha=Kandb=N/8(manyothersettingsofaandbyieldsimilarresults).\n",
      "5\n",
      "5.1\n",
      "Denoising\n",
      "Weconsiderdenoisinga256?256image,withcomparisonoftheproposed\n",
      "approachtoK-SVD[6](forwhichthenoisevarianceisassumedknownand\n",
      "thetruenoisestandarddeviationissetat15,25and50intheexamples\n",
      "below.Weshowresultsforthreealgorithms:(i)mismatchedK-SVD(withnoise\n",
      "standarddeviationof30),(ii)K-SVDwhenthestandarddeviationisproperly\n",
      "matched,and(iii)theproposedBPapproach.For(iii)anon-informativeprior\n",
      "isplacedonthenoiseprecision,andthesameBPmodelisrunforallthreenoise\n",
      "levels(withtheunderlyingnoiselevelsinferred).TheBPandK-SVDemployed\n",
      "noaprioritrainingdata.InFigure1areshownthenoisyimagesatthethree\n",
      "tnoiselevels,aswellasthereconstructionsviaBPandKSVD.Apreset\n",
      "largedictionarysizeK=256isusedforbothalgorithms,andfortheBPresults\n",
      "weinferredthatapproximatelyM=196,128,and34dictionaryelementswere\n",
      "importantfornoisestandarddeviations15,25,and50,respectively;theremain-\n",
      "ingelementsofthedictionarywereusedlessthan0.1%ofthetime.Asseen\n",
      "withinthebottomportionoftherightpartofFigure1,theunuseddictionary\n",
      "elementsappearasrandomdrawsfromtheprior,sincetheyarenotusedand\n",
      "hencebythedata.NotethatK-SVDworkswellwhenthesetnoise\n",
      "varianceisatorneartruth,butthemethodisunderminedbymismatch.The\n",
      "proposedBPapproachisrobusttochangingnoiselevels.Quantitativeperfor-\n",
      "manceissummarizedinTable1.TheBPdenoiserestimatesafullposterior\n",
      "densityfunctiononthenoisestandarddeviation;fortheexamplesconsidered\n",
      "here,themodesoftheinferredstandard-deviationposteriorswere15.57,25.35,\n",
      "and48.12,fortruestandarddeviations15,25,and50,respectively.Toachieve\n",
      "theseBPresults,weemployasequentialimplementationoftheGibbssampler\n",
      "(abatchimplementationconvergestothesameresultsbutwithhighercomputa-\n",
      "tionalcost);thisisdiscussedinfurtherdetailbelow,whenpresentinginpainting\n",
      "results.\n",
      "Figure1:Left:Representativedenoisingresults,withthetopthroughbot-\n",
      "tomrowscorrespondingtonoisestandarddeviationsof15,25and50,respec-\n",
      "tively.ThesecondandthirdcolumnsrepresentK-SVD[6]resultswithassumed\n",
      "standarddeviationequalto30andthegroundtruth,respectively.Thefourth\n",
      "columnrepresentstheproposedBPreconstructions.Thenoisyimagesarein\n",
      "thecolumn.Right:InferredBPdictionaryelementsfornoisestandard\n",
      "deviation25,inorderofimportance(probabilitytobeused)fromthetop-left.\n",
      "Table1:Peaksignal-to-reconstructedimagemeasure(PSNR)forthedata\n",
      "8\n",
      "\n",
      "inFigure1,forK-SVD[6]andtheproposedBPmethod.Thetruestandard\n",
      "deviationwas15,25and50,respectively,fromthetoptothebottomrow.\n",
      "ForthemismatchedK-SVDresults,thenoisestanddeviationwasat30.\n",
      "OriginalNoisyImage(dB)24.5820.1914.56\n",
      "K-SVDDenoisingmismatchedvariance(dB)30.6731.5219.60\n",
      "K-SVDDenoisingmatchedvariance(dB)34.3232.1527.95\n",
      "BetaProcessDenoising(dB)34.4432.1728.08\n",
      "5.2InpaintingOurinpaintinganddenoisingresultswereachievedbyusing\n",
      "thefollowingsequentialprocedure.Consideranypixel[p,j],wherep,j?[1,B],\n",
      "andletthispixelconstitutetheleft-bottompixelinanewB?Bblock.Further,\n",
      "considerallB?Bblockswithleft-bottompixelsat\n",
      "f\n",
      "p+`B,j+6\n",
      "30\n",
      "25\n",
      "PSNR\n",
      "20\n",
      "15\n",
      "10\n",
      "5\n",
      "0\n",
      "8\n",
      "16\n",
      "24\n",
      "32Learninground\n",
      "40\n",
      "48\n",
      "56\n",
      "64\n",
      "Figure2:Inpaintingresults.ThecurveshowsthePSNRasafunctionof\n",
      "theB2=64Gibbslearningrounds.Theleftisthetestimage,with80%\n",
      "oftheRGBpixelsmissing,themiddleistheresultafter64afterGibbs\n",
      "roundsresult),andtherightistheoriginaluncontaminatedimage.\n",
      "mB\n",
      "g\n",
      "??(p?1)\n",
      "f\n",
      "Ny?B+1,j+mB\n",
      "g\n",
      "??(j?1)\n",
      "f\n",
      "p+`B,Nx?B+1\n",
      "g\n",
      "for`andmthatsatisfyp+`B?Ny?B+1andj+mB?Nx?B+1.\n",
      "ThissetofblocksisdenoteddatasetDpj,andconsidering1?p?Band1\n",
      "?j?B,thereareatotalofB2suchshifteddatasets.Intheiterationof\n",
      "learning?,weemploytheblocksinD11,andforthisroundweinitialize\n",
      "?and?ibasedonasingularvaluedecomposition(SVD)oftheblocksinD11\n",
      "(weachievedsimilarresultswhen?wasinitializedrandomly).Wedoseveral\n",
      "GibbsiterationswithD11andthenstoptheGibbsalgorithm,retainingthe\n",
      "lastsampleof?and?ifromthepreviousstep.These?and?iarethenused\n",
      "toinitializetheGibbssamplerinthesecondround,nowappliedtotheB?B\n",
      "blocksinD11?D21(forD21theneighboring?iisusedforinitialization).The\n",
      "Gibbssamplerisnowrunonthisexpandeddataforseveraliterations,thelast\n",
      "sampleisretained,andthedatasetisaugmentedagain.ThisisdoneB2=\n",
      "64timesuntilattheendallshiftedblocksareprocessedsimultaneously.This\n",
      "sequentialprocessmaybeviewedasasequentialGibbsburnin,afterwhich\n",
      "9\n",
      "\n",
      "alloftheshiftedblocksareprocessed.Theoretically,onewouldexpecttoneed\n",
      "thousandsofGibbsiterationstoachieveconvergence.However,ourexperience\n",
      "isthatevenasingleiterationineachoftheaboveB2roundsyieldsgoodresults.\n",
      "InFigure2weshowthePSNRasafunctionofeachoftheB2=64rounds\n",
      "discussedabove.ForGibbsrounds16,32and64thecorrespondingPSNR\n",
      "valueswere26.78dB,28.46dBand29.31dB.ForthisexampleweusedK=\n",
      "256.Thisexamplewasconsideredin[7](weobtainedsimilarresultsforthe\n",
      "?NewOrleans?image,alsoconsideredin[7]);thebestresultsreportedthere\n",
      "wereaPSNRof29.65dB.However,toachievethoseresultsatrainingdataset\n",
      "wasemployedforinitialization[7];theBPresultsareachievedwithnoapriori\n",
      "trainingdata.Concerningcomputationalcosts,theinpaintinganddenoising\n",
      "algorithmsscalelinearlyasafunctionoftheblocksize,thedictionarysize,the\n",
      "sparsitylevel,andthenumberoftrainingsamples;allresultsreportedherewere\n",
      "runtlyinMatlabonPCs,withcomparablecostsasK-SVD.5.3\n",
      "Compressivesensing\n",
      "WeconsideraCSexample,inwhichtheimageisdividedinto8?8patches,\n",
      "withtheseconstitutingtheunderlyingdata\n",
      "f\n",
      "xi\n",
      "g\n",
      "i=1,NBtobeinferred.For\n",
      "eachoftheNBblocks,avectorofCSmeasurementsvi=?xiismeasured,\n",
      "wherethenumberofprojectionsperpatchisNp,andthetotalnumberof\n",
      "CSprojectionsisNpNB.Inthisexampletheelementsof?wereconstructed\n",
      "randomlyasdrawsfromN(0,1),butmanyotherprojectionclassesmaybe\n",
      "considered[11,24].Eachxiisassumedrepresentedintermsofadictionaryxi\n",
      "=D?i+i,andthreeconstructionsforDwereconsidered:(i)aDCTexpansion;\n",
      "(ii)learningofDusingthebetaprocessconstruction,usingtrainingimages;(iii)\n",
      "usingthebetaprocesstoperformjointCSinversionandlearningofD.For(ii),\n",
      "thetrainingdataconsistedof40008?8patcheschosenatrandomfrom100\n",
      "imagesselectedfromtheMicrosoftdatabase(http://research.microsoft.com/en-\n",
      "us/projects/objectclassrecognition).ThedictionarywassettoK=256,andthe\n",
      "betaprocessinferredadictionaryofsizeM=237.RepresentativeCS\n",
      "reconstructionresultsareshowninFigure3,foragray-scaleversionofthe\n",
      "?castle?image.Theinversionresultsatleftarebasedonalearneddictionary;\n",
      "exceptforthe?onlineBP?results,alloftheseresultsemploythesamedictionary\n",
      "Dlearnedasabove,andthealgorithmsaredistinguishedbyt\n",
      "waysofestimating\n",
      "f\n",
      "?i\n",
      "g\n",
      "i=1,NB.ArangeofCS-inversion7\n",
      "algorithmsareconsideredfromtheliterature,andseveralBP-basedcon-\n",
      "structionsareconsideredaswellforCSinversion.TheonlineBPresultsare\n",
      "quitecompetitivewiththoseinferredOnealsonotesthattheresults\n",
      "basedonalearneddictionary(leftinFigure3)aremarkedlybetterthanthose\n",
      "basedontheDCT(rightinFigure3);similarresultswereachievedwhenthe\n",
      "DCTwasreplacedbyawaveletrepresentation.FortheDCT-basedresults,note\n",
      "thattheDP-andPSBP-basedBPCSinversionresultsaretlybetter\n",
      "thanthoseofallotherCSinversionalgorithms.Theresultsreportedhereare\n",
      "consistentwithtestsweperformedusingover100imagesfromtheaforemen-\n",
      "tionedMicrosoftdatabase,notreportedhereindetailforbrevity.Notethat\n",
      "CSinversionusingtheDP-basedBPalgorithm(asdiscussedinSection4)yield\n",
      "thebestresults,tlybetterthanBPresultsnotbasedontheDP,and\n",
      "10\n",
      "\n",
      "betterthanallcompetingCSinversionalgorithms(forbothlearneddictionaries\n",
      "andtheDCT).TheDP-basedresultsareverysimilartothosegeneratedbythe\n",
      "probitstick-breakingprocess(PSBP)[19],whichenforcesspatialinformation\n",
      "moreexplicitly;thissuggeststhatthesimplerDP-basedresultsareadequate,\n",
      "atleastforthewideclassofexamplesconsidered.Notethatwealsoconsidered\n",
      "theDPandPSBPforthedenoisingandinpaitingexamplesabove(thoseresults\n",
      "wereomitted,forbrevity).TheDPandPSBPdenoisingandinpaintingresults\n",
      "weresimilartoBPresultswithoutDP/PSBP(thosepresentedabove);thisis\n",
      "attributedtothefactthatwhenperformingdenoising/inpaintingwemaycon-\n",
      "sidermanyshiftedversionsofthesameimage(asdiscussedwhenpresentingthe\n",
      "inpaintingresults).Concerningcomputationalcosts,allCSinversionswererun\n",
      "tlyonPCs,withthespcomputationaltimesdictatedbythede-\n",
      "tailedMatlabimplementationandthemachinerunon.Aroughrankingofthe\n",
      "computationalspeeds,fromfastesttoslowest,isasfollows:StOMP-CFAR,Fast\n",
      "BCS,OMP,BP,LARS/Lasso,OnlineBP,DPBP,PSBPBP,VBBCS,Basis\n",
      "Pursuit;inthislist,algorithmsBPthroughBasisPursuitshaveapproximately\n",
      "thesamecomputationalcosts.TheDP-basedBPCSinversionalgorithmscales\n",
      "asO(NB?Np?B2).PSBPBPDPBPOnlineBPBPBCSFastBCSBasis\n",
      "PursuitLARS/LassoOMPSTOMP-CFAR\n",
      "0.25\n",
      "0.2\n",
      "0.45\n",
      "0.15\n",
      "0.1\n",
      "0.05\n",
      "0\n",
      "3\n",
      "3.5\n",
      "4\n",
      "4.5\n",
      "5\n",
      "5.5\n",
      "6\n",
      "6.5\n",
      "7\n",
      "MeasurementsNumberNumberofCSofMeasurements(x104)\n",
      "PSBPBPDPBPBPBCSFastBCSBasisPursuitLARS/LassoOMP\n",
      "STOMP-CFAR\n",
      "0.5\n",
      "RelativeReconstructionErrorRelativeReconstructionError\n",
      "RelativeReconstructionErrorRelativeReconstructionError\n",
      "0.3\n",
      "7.5\n",
      "0.40.350.30.250.2\n",
      "3\n",
      "3.5\n",
      "11\n",
      "\n",
      "4\n",
      "4.5\n",
      "5\n",
      "5.5\n",
      "6\n",
      "6.5\n",
      "7\n",
      "MeasurementsNumberNumberofCSofMeasurements(x104)\n",
      "4\n",
      "x10\n",
      "7.54\n",
      "x10\n",
      "Figure3:CSperformance(fractionof`2error)basedonlearneddictionaries\n",
      "(left)andbasedontheDCT(right).Fortheleftresults,the?OnlineBP?results\n",
      "simultaneouslylearnedthedictionaryanddidCSinversion;theremainderofthe\n",
      "leftresultsarebasedonadictionarylearnedonatrainingset.ADCT\n",
      "dictionaryisusedfortheresultsontheright.Theunderlyingimageunder\n",
      "testisshownatright.MatlabcodeforBasisPursuit,LARS/Lasso,OMP,\n",
      "STOMPareavailableathttp://sparselab.stanford.edu/,andcodeforBCSand\n",
      "FastBCSareavailableathttp://people.ee.duke.edu/?lihan/cs/.Thehorizontal\n",
      "axisrepresentsthetotalnumberofCSprojections,NpNB.Thetotalnumber\n",
      "ofpixelsintheimageis480?320=153,600.99.9%ofthesignalenergyis\n",
      "containedin33,500DCTcots.\n",
      "6\n",
      "Conclusions\n",
      "Thenon-parametricbetaprocesshasbeenpresentedfordictionarylearning\n",
      "withthegoalofimagedenoising,inpaintingandcompressivesensing,withvery\n",
      "encouragingresultsrelativetothestateoftheart.Theframeworkmayalsobe\n",
      "appliedtojointtasks.Inthecontextofnoisyunder-\n",
      "lyingdata,thenoisevarianceneednotbeknowninadvance,anditneednotbe\n",
      "spatiallyuniform.Theproposedformulationalsoallowsuniqueopportunitiesto\n",
      "leverageknownstructureinthedata,suchasrelativespatiallocationswithin\n",
      "animage;thisframeworkwasusedtoachievemarkedimprovementsinCS-\n",
      "inversionquality.AcknowledgementTheresearchreportedherewassupported\n",
      "inpartbyARO,AFOSR,DOE,NGAandONR.8\n",
      "2References\n",
      "[1]N.CristianiniandJ.Shawe-Taylor.AnIntroductiontoSupportVectorMa-\n",
      "chines.CambridgeUniversityPress,2000.[2]M.Tipping.SparseBayesian\n",
      "learningandtherelevancevectormachine.JournalofMachineLearningRe-\n",
      "search,1,2001.[3]R.Tibshirani.Regressionshrinkageandselectionviathe\n",
      "lasso.JournaloftheRoyalStatisticalSociety,SeriesB,58,1994.[4]B.A.\n",
      "OlshausenandD.J.Field.Sparsecodingwithanovercompletebasisset:A\n",
      "strategyemployedbyV1?VisionResearch,37,1998.[5]M.Aharon,M.Elad,\n",
      "12\n",
      "\n",
      "andA.M.Bruckstein.K-SVD:Analgorithmfordesigningovercompletedic-\n",
      "tionariesforsparserepresentation.IEEETrans.SignalProcessing,54,2006.\n",
      "[6]M.EladandM.Aharon.Imagedenoisingviasparseandredundantrepre-\n",
      "sentationsoverlearneddictionaries.IEEETrans.ImageProcessing,15,2006.\n",
      "[7]J.Mairal,M.Elad,andG.Sapiro.Sparserepresentationforcolorimage\n",
      "restoration.IEEETrans.ImageProcessing,17,2008.[8]J.Mairal,F.Bach,\n",
      "J.Ponce,andG.Sapiro.Onlinedictionarylearningforsparsecoding.InProc.\n",
      "InternationalConferenceonMachineLearning,2009.[9]J.Mairal,F.Bach,J.\n",
      "Ponce,G.Sapiro,andA.Zisserman.Superviseddictionarylearning.InProc.\n",
      "NeuralInformationProcessingSystems,2008.[10]M.Ranzato,C.Poultney,\n",
      "S.Chopra,andY.Lecun.tlearningofsparserepresentationswithan\n",
      "energy-basedmodel.InProc.NeuralInformationProcessingSystems,2006.\n",
      "[11]E.Cand`esandT.Tao.Near-optimalsignalrecoveryfromrandompro-\n",
      "jections:universalencodingstrategies?IEEETrans.InformationTheory,52,\n",
      "2006.[12]J.M.Duarte-CarvajalinoandG.Sapiro.Learningtosensesparse\n",
      "signals:Simultaneoussensingmatrixandsparsifyingdictionaryoptimization.\n",
      "IMAPreprintSeries2211,2008.[13]J.Wright,A.Y.Yang,A.Ganesh,S.S.\n",
      "Sastry,andY.Ma.Robustfacerecognitionviasparserepresentation.IEEE\n",
      "Trans.PatternAnalysisMachineIntelligence,31,2009.[14]S.Ji,Y.Xue,\n",
      "andL.Carin.Bayesiancompressivesensing.IEEETrans.SignalProcessing,\n",
      "56,2008.[15]R.Raina,A.Battle,H.Lee,B.Packer,andA.Y.Ng.Self-\n",
      "taughtlearning:transferlearningfromunlabeleddata.InProc.International\n",
      "ConferenceonMachineLearning,2007.[16]R.ThibauxandM.I.Jordan.Hi-\n",
      "erarchicalbetaprocessesandtheindianprocess.InProc.International\n",
      "ConferenceonIntelligenceandStatistics,2007.[17]J.PaisleyandL.\n",
      "Carin.Nonparametricfactoranalysiswithbetaprocesspriors.InProc.Inter-\n",
      "nationalConferenceonMachineLearning,2009.[18]T.Ferguson.ABayesian\n",
      "analysisofsomenonparametricproblems.AnnalsofStatistics,1,1973.[19]A.\n",
      "RodriguezandD.B.Dunson.Nonparametricbayesianmodelsthroughprobit\n",
      "stickbreakingprocesses.Univ.CaliforniaSantaCruzTechnicalReport,2009.\n",
      "[20]D.KnowlesandZ.Ghahramani.sparsefactoranalysisand\n",
      "independentcomponentsanalysis.InProc.InternationalConferenceonInde-\n",
      "pendentComponentAnalysisandSignalSeparation,2007.[21]P.RaiandH.\n",
      "Daum?eIII.Thehierarchicalfactorregressionmodel.InProc.Neural\n",
      "InformationProcessingSystems,2008.[22]M.J.Beal.VariationalAlgorithms\n",
      "forApproximateBayesianInference.PhDthesis,GatsbyComputationalNeuro-\n",
      "scienceUnit,UniversityCollegeLondon,2003.[23]M.GirolamiandS.Rogers.\n",
      "VariationalBayesianmultinomialprobitregressionwithGaussianprocesspri-\n",
      "ors.NeuralComputation,18,2006.[24]R.G.Baraniuk.Compressivesensing.\n",
      "IEEESignalProcessingMagazine,24,2007.[25]J.Sethuraman.Aconstructive\n",
      "ofDirichletpriors.StatisticaSinica,4,1994.\n",
      "9\n",
      "13\n",
      "\n",
      "PP3529.pdf\n",
      "PP3529.pdf 11\n",
      "ModelinghumanfunctionlearningwithGaussian\n",
      "processes\n",
      "Authoredby:\n",
      "ThomasL.hs\n",
      "ChrisLucas\n",
      "JosephWilliams\n",
      "MichaelL.Kalish\n",
      "Abstract\n",
      "Accountsofhowpeoplelearnfunctionalrelationshipsbetweencontin-\n",
      "uousvariableshavetendedtofocusontwopossibilities:thatpeopleare\n",
      "estimatingexplicitfunctions,orthattheyaresimplyperformingassocia-\n",
      "tivelearningsupportedbysimilarity.Weprovidearationalanalysisof\n",
      "functionlearning,drawingonworkonregressioninmachinelearningand\n",
      "statistics.UsingtheequivalenceofBayesianlinearregressionandGaus-\n",
      "sianprocesses,weshowthatlearningexplicitrulesandusingsimilarity\n",
      "canbeseenastwoviewsofonesolutiontothisproblem.Weusethis\n",
      "insighttoaGaussianprocessmodelofhumanfunctionlearning\n",
      "thatcombinesthestrengthsofbothapproaches.\n",
      "1PaperBody\n",
      "Muchresearchonhowpeopleacquireknowledgefocusesondiscretestructures,\n",
      "suchasthenatureofcategoriesortheexistenceofcausalrelationships.How-\n",
      "ever,ourknowledgeoftheworldalsoincludesrelationshipsbetweencontinuous\n",
      "variables,suchasthebetweenlinearandexponentialgrowth,orthe\n",
      "formofcausalrelationships,suchashowpressingtheacceleratorofacarin-\n",
      "itsvelocity.Researchonhowpeoplelearnrelationshipsbetweentwo\n",
      "continuousvariables?knowninthepsychologicalliteratureasfunctionlearning\n",
      "?hastendedtoemphasizetwotwaysinwhichpeoplecouldbesolving\n",
      "thisproblem.Oneclassoftheories(e.g.,[1,2,3])suggeststhatpeoplearelearn-\n",
      "inganexplicitfunctionfromagivenclass,suchasthepolynomialsofdegreek.\n",
      "Thisapproachattributesrichrepresentationstohumanlearners,buthastra-\n",
      "ditionallygivenlimitedtreatmenttothequestionofhowsuchrepresentations\n",
      "couldbeacquired.Asecondapproach(e.g.,[4,5])emphasizesthepossibility\n",
      "thatpeoplelearnbyformingassociationsbetweenobservedvaluesofinputand\n",
      "outputvariables,andgeneralizebasedonthesimilarityofnewinputstoold.\n",
      "1\n",
      "\n",
      "Thisapproachhasaclearaccountoftheunderlyinglearningmechanisms,but\n",
      "faceschallengesinexplaininghowpeoplegeneralizesobroadlybeyondtheir\n",
      "experience,makingpredictionsaboutvariablevaluesthataretlyre-\n",
      "movedfromtheirpreviousobservations.Mostrecently,hybridsofthesetwo\n",
      "approacheshavebeenproposed(e.g.,[6,7]),withexplicitfunctionsbeingrep-\n",
      "resented,butassociativelearning.Previousmodelsofhumanfunctionlearning\n",
      "havebeenorientedtowardsunderstandingthepsychologicalprocessesbywhich\n",
      "peoplesolvethisproblem.Inthispaper,wetakeatapproach,1\n",
      "presentingarationalanalysisoffunctionlearning,inthespiritof[8].This\n",
      "rationalanalysisprovidesawaytounderstandtherelationshipbetweenthetwo\n",
      "approachesthathavedominatedpreviouswork?rulesandsimilarity?andsug-\n",
      "gestshowtheymightbecombined.Thebasicstrategywepursueistoconsider\n",
      "theabstractcomputationalprobleminvolvedinfunctionlearning,andthento\n",
      "exploreoptimalsolutionstothatproblemwiththegoalofsheddinglighton\n",
      "humanbehavior.Inparticular,theproblemoflearningafunctionalrelation-\n",
      "shipbetweentwocontinuousvariablesisaninstanceofregression,andhasbeen\n",
      "extensivelystudiedinmachinelearningandstatistics.Thereareavarietyof\n",
      "solutiontoregressionproblems,butwefocusonmethodsrelatedtoBayesian\n",
      "linearregression(e.g.,[9]),whichallowustomaketheexpectationsoflearners\n",
      "abouttheformoffunctionsexplicitthroughapriordistribution.Bayesianlinear\n",
      "regressionisalsodirectlyrelatedtoanonparametricapproachknownasGaus-\n",
      "sianprocessprediction(e.g.,[10]),inwhichpredictionsaboutthevaluesofan\n",
      "outputvariablearebasedonthesimilaritybetweenvaluesofaninputvariable.\n",
      "Weusethisrelationshiptoconnectthetwotraditionalapproachestomodeling\n",
      "functionlearning,asitshowsthatlearningrulesthatdescribefunctionsand\n",
      "specifyingthesimilaritybetweenstimuliforuseinassociativelearningarenot\n",
      "mutuallyexclusivealternatives,butrathertwoviewsofthesamesolutionto\n",
      "thisproblem.Weexploitthisfacttoarationalmodelofhumanfunction\n",
      "learningthatincorporatesthestrengthsofbothapproaches.\n",
      "2\n",
      "Modelsofhumanfunctionlearning\n",
      "Inthissectionwereviewthetwotraditionalapproachestomodelinghu-\n",
      "manfunctionlearning?rulesandsimilarity?andsomemorerecenthybrid\n",
      "approachesthatcombinethetwo.2.1\n",
      "Representingfunctionswithrules\n",
      "Theideathatpeoplemightrepresentfunctionsexplicitlyappearsinoneof\n",
      "thepapersonhumanfunctionlearning[1].Thispaperproposedthatpeo-\n",
      "pleassumeaparticularclassoffunctions(suchaspolynomialsofdegreek)and\n",
      "usetheavailableobservationstoestimatetheparametersofthosefunctions,\n",
      "formingarepresentationthatgoesbeyondtheobservedvaluesofthevariables\n",
      "involved.Consistentwiththishypothesis,peoplelearnedlinearandquadratic\n",
      "functionsbetterthanrandompairingsofvaluesfortwovariables,andextrap-\n",
      "olatedappropriately.Similarassumptionsguidedsubsequentworkexploring\n",
      "theeasewithwhichpeoplelearnfunctionsfromtclasses(e.g.,[2],and\n",
      "papershavetestedstatisticalregressionschemesaspotentialmodelsoflearn-\n",
      "ing,examininghowwellhumanresponsesweredescribedbytformsof\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinearregression(e.g.,[3]).2.2\n",
      "Similarityandassociativelearning\n",
      "Associativelearningmodelsproposethatpeopledonotlearnrelationships\n",
      "betweencontinuousvariablesbyexplicitlylearningrules,butbyforgingassocia-\n",
      "tionsbetweenobservedvariablepairsandgeneralizingbasedonthesimilarityof\n",
      "newvariablevaluestoold.Themodeltoimplementthisapproachwasthe\n",
      "Associative-LearningModel(ALM;[4,5]),inwhichinputandoutputarraysare\n",
      "usedtorepresentarangeofvaluesforthetwovariablesbetweenwhichthefunc-\n",
      "tionalrelationshipholds.Presentationofaninputactivatesinputnodesclose\n",
      "tothatvalue,withactivationfallingasaGaussianfunctionofdistance,ex-\n",
      "plicitlyimplementingatheoryofsimilarityintheinputspace.Learnedweights\n",
      "determinetheactivationoftheoutputnodes,beingaweightedlinearfunction\n",
      "oftheactivationoftheinputnodes.Associativelearningfortheweightsis\n",
      "performedbyapplyinggradientdescentonthesquarederrorbetweencurrent\n",
      "outputactivationandthecorrectvalue.Inpractice,thisapproachperforms\n",
      "wellwheninterpolatingbetweenobservedvalues,butpoorlywhenextrapolat-\n",
      "ingbeyondthosevalues.Asaconsequence,thesameauthorsintroducedthe\n",
      "Extrapolation-AssociationModel(EXAM),whichconstructsalinearapproxi-\n",
      "mationtotheoutputoftheALMwhenselectingresponses,producingabias\n",
      "towardslinearitythatbettermatcheshumanjudgments.2.3\n",
      "Hybridapproaches\n",
      "Severalpapershaveexploredmethodsforcombiningrule-likerepresentations\n",
      "offunctionswithassociativelearning.Oneexampleofsuchanapproachisthe\n",
      "setofrule-basedmodelsexploredin[6].Thesemodelsusedthesamekindof\n",
      "inputrepresentationasALMandEXAM,withactivation2\n",
      "ofasetofnodessimilartotheinputvalue.However,themodelsalsofeature\n",
      "asetofhiddenunits,whereeachhiddenunitcorrespondstoatparam-\n",
      "eterizationofarulefromagivenclass(polynomial,Fourier,orlogistic).The\n",
      "valuesofthehiddennodes?correspondingtothevaluesoftherulestheyin-\n",
      "stantiate?arecombinedlinearlytoobtainoutputpredictions,withtheweight\n",
      "ofeachhiddennodebeinglearnedthroughgradientdescent(withapenaltyfor\n",
      "thecurvatureofthefunctionsinvolved).Amorecomplexinstanceofthiskind\n",
      "ofapproachisthePopulationofLinearExperts(POLE)model[7],inwhichhid-\n",
      "denunitseachrepresenttlinearfunctions,buttheweightsfrominputto\n",
      "hiddennodesindicatewhichlinearfunctionshouldbeusedtomakepredictions\n",
      "forparticularinputvalues.Asaconsequence,themodelcanlearnnon-linear\n",
      "functionsbyidentifyingaseriesoflocallinearapproximations,andcaneven\n",
      "modelsituationsinwhichpeopleseemtolearntfunctionsint\n",
      "partsoftheinputspace.\n",
      "3\n",
      "Rationalsolutionstoregressionproblems\n",
      "Themodelsoutlinedintheprevioussectionallaimtodescribethepsy-\n",
      "chologicalprocessesinvolvedinhumanfunctionlearning.Inthissection,we\n",
      "considertheabstractcomputationalproblemunderlyingthistask,usingopti-\n",
      "malsolutionstothisproblemtoshedlightonbothpreviousmodelsandhuman\n",
      "learning.Viewedabstractly,thecomputationalproblembehindfunctionlearn-\n",
      "3\n",
      "\n",
      "ingistolearnafunctionfmappingfromxtoyfromasetofreal-valuedobser-\n",
      "vationsxn=(x1,...,xn)andtn=(t1,...,tn),wheretiisassumedtobe\n",
      "thetruevalueyi=f(xi)obscuredbyadditivenoise.1Inmachinelearningand\n",
      "statistics,thisisreferredtoasaregressionproblem.Inthissection,wediscuss\n",
      "howthisproblemcanbesolvedusingBayesianstatistics,andhowtheresultof\n",
      "thisapproachisrelatedtoGaussianprocesses.Ourpresentationfollowsthatin\n",
      "[10].3.1\n",
      "Bayesianlinearregression\n",
      "Ideally,wewouldseektosolveourregressionproblembycombiningsome\n",
      "priorbeliefsabouttheprobabilityofencounteringtkindsoffunctionsin\n",
      "theworldwiththeinformationprovidedbyxandt.Wecandothisbyapplying\n",
      "Bayes?rule,withp(f|xn,tn)=R\n",
      "p(tn|f,xn)p(f),p(tn|f,xn)p(f)dfF\n",
      "(1)\n",
      "wherep(f)isthepriordistributionoverfunctionsinthehypothesisspaceF,\n",
      "p(tn|f,xn)istheprobabilityofobservingthevaluesoftniffwerethetrue\n",
      "function,knownasthelikelihood,andp(f|xn,tn)istheposteriordistribution\n",
      "overfunctionsgiventheobservationsxnandtn.Inmanycases,thelikelihood\n",
      "isbyassumingthatthevaluesoftiareindependentgivenfandxi,\n",
      "beingGaussianwithmeanyi=f(xi)andvariance?t2.Predictionsaboutthe\n",
      "valueofthefunctionfforanewinputxn+1canbemadebyintegratingover\n",
      "theposteriordistribution,Zp(yn+1|xn+1,tn,xn)=p(yn+1|f,xn+1\n",
      ")p(f|xn,tn)df,(2)f\n",
      "wherep(yn+1|f,xn+1)isadeltafunctionplacingallofitsmassonyn+1\n",
      "=f(xn+1).Performingthecalculationsoutlinedinthepreviousparagraph\n",
      "forageneralhypothesisspaceFischallenging,butbecomesstraightforwardif\n",
      "welimitthehypothesisspacetocertainspclassesoffunctions.Ifwetake\n",
      "Ftobealllinearfunctionsoftheformy=b0+xb1,thenourproblemtakes\n",
      "thefamiliarformoflinearregression.ToperformBayesianlinearregression,\n",
      "weneedtoeapriorp(f)overalllinearfunctions.Sincethesefunctions\n",
      "areidenbytheparametersb0andb1,itisttoaprior\n",
      "overb=(b0,b1),whichwecandobyassumingthatbfollowsamultivariate\n",
      "Gaussiandistributionwithmeanzeroandcovariance?b.ApplyingEquation1\n",
      "thenresultsinamultivariateGaussianposteriordistributiononb(see[9])with\n",
      "?1TTE[b|xn,tn]=?t2??1Xntn(3)b+XnXn?1\n",
      "1T(4)cov[b|xn,yn]=??1b+2XnXn?t1Followingmuchoftheliter-\n",
      "atureonhumanfunctionlearning,weconsideronlyone-dimensionalfunctions,\n",
      "butthisapproachgeneralizesnaturallytothemulti-dimensionalcase.\n",
      "3\n",
      "whereXn=[1nxn](ie.amatrixwithavectorofoneshorizontallycon-\n",
      "catenatedwithxn+1)Sinceyn+1issimplyalinearfunctionofb,applying\n",
      "Equation2yieldsaGaussianpredictivedistribution,withyn+1havingmean\n",
      "[1xn+1]E[b|xn,tn]andvariance[1xn+1]cov[b|xn,tn][1xn+1]T.\n",
      "Thepredictivedistributionfortn+1issimilar,butwiththeadditionof?t2\n",
      "tothevariance.Whileconsideringonlylinearfunctionsmightseemoverlyre-\n",
      "strictive,linearregressionactuallygivesusthebasictoolsweneedtosolvethis\n",
      "4\n",
      "\n",
      "problemformoregeneralclassesoffunctions.Manyclassesoffunctionscanbe\n",
      "describedaslinearcombinationsofasmallsetofbasisfunctions.Forexample,\n",
      "allkthdegreepolynomialsarelinearcombinationsoffunctionsoftheform1\n",
      "(theconstantfunction),x,x2,...,xk.Letting?(1),...,?(k)denotea\n",
      "setoffunctions,wecanapriorontheclassoffunctionsthatarelinear\n",
      "combinationsofthisbasisbyexpressingsuchfunctionsintheformf(x)=b0\n",
      "+?(1)(x)b1+...+?(k)(x)bkandaprioronthevectorofweights\n",
      "b.IfwetakethepriortobeGaussian,wereachthesamesolutionasoutlined\n",
      "inthepreviousparagraph,substituting?=[1n?(1)(xn)...?(k)(xn)]for\n",
      "Xand[1?(1)(xn+1)...?(k)(xn+1)]for[1xn+1],where?(xn)=[?(x1)\n",
      "...?(xn)]T.3.2\n",
      "Gaussianprocesses\n",
      "Ifourgoalweremerelytopredictyn+1fromxn+1,yn,andxn,wemight\n",
      "consideratapproach,simplyajointdistributiononyn+1given\n",
      "xn+1andconditioningonyn.Forexample,wemighttaketheyn+1tobe\n",
      "jointlyGaussian,withcovariancematrix\n",
      "Knkn,n+1(5)Kn+1=kTn,n+1kn+1whereKndependsonthevaluesof\n",
      "xn,kn,n+1dependsonxnandxn+1,andkn+1dependsonlyonxn+1.If\n",
      "weconditiononyn,thedistributionofyn+1isGaussianwithmeankTn,n+1\n",
      "K?1nyT?1andvariancekn+1?kn,n+1Knkn,n+1.Thisapproachto\n",
      "predictionusesaGaussianprocess,astochasticprocessthatinducesaGaussian\n",
      "distributiononybasedonthevaluesofx.Thisapproachcanalsobeextended\n",
      "toallowustopredictyn+1fromxn+1,tn,andxnbyadding?t2IntoKn\n",
      ",whereInisthen?nidentitymatrix,totakeintoaccounttheadditional\n",
      "varianceassociatedwithtn.ThecovariancematrixKn+1isspusinga\n",
      "two-placefunctioninxknownasakernel,withKij=K(xi,xj).Anykernel\n",
      "thatresultsinanappropriate(symmetric,positivcovariancematrix\n",
      "forallxcanbeused.Commonkindsofkernelsincluderadialbasisfunctions,\n",
      "e.g.,1K(xi,xj)=?12exp(?2(xi?xj)2)(6)?2withvaluesofyfor\n",
      "whichvaluesofxareclosebeingcorrelated,andperiodicfunctions,e.g.,2?\n",
      "K(xi,xj)=?32exp(?42(cos([xi?xj])))(7)?5indicatingthatvaluesofy\n",
      "forwhichvaluesofxarecloserelativetotheperiod?3arelikelytobehighly\n",
      "correlated.Gaussianprocessesthusprovideaapproachtoprediction,\n",
      "withthekernelwhichvaluesofxarelikelytohavesimilarvaluesofy.\n",
      "3.3\n",
      "Twoviewsofregression\n",
      "BayesianlinearregressionandGaussianprocessesappeartobequite\n",
      "entapproaches.InBayesianlinearregression,ahypothesisspaceoffunctionsis\n",
      "idenaprioronthatspaceisandpredictionsareformedaveraging\n",
      "overtheposterior,whileGaussianprocessessimplyusethesimilaritybetween\n",
      "tvaluesofx,asexpressedthroughakernel,topredictcorrelationsin\n",
      "valuesofy.Itmightthuscomeasasurprisethattheseapproachesareequiva-\n",
      "lent.ShowingthatBayesianlinearregressioncorrespondstoGaussianprocess\n",
      "predictionisstraightforward.Theassumptionoflinearitymeansthatthevector\n",
      "yn+1isequaltoXn+1b.Itfollowsthatp(yn+1|xn+1)isamultivariate\n",
      "GaussiandistributionwithmeanzeroandcovariancematrixXn+1?bXTn+1\n",
      "5\n",
      "\n",
      ".BayesianlinearregressionthuscorrespondstopredictionusingGaussianpro-\n",
      "cesses,withthiscovariancematrixplayingtheroleofKn+1above(ie.using\n",
      "thekernelfunctionK(xi,xj)=[1xi][1xj]T).Usingarichersetofbasis\n",
      "functionscorrespondstotakingKn+1=?n+1?b?Tn+1(ie.K(xi,xj)=[1\n",
      "?(1)(xi)...?(k)(xi)][1?(1)(xi)...?(k)(xi)]T).4\n",
      "ItisalsopossibletoshowthatGaussianprocesspredictioncanalwaysbe\n",
      "interpretedasBayesianlinearregression,albeitwithpotentiallymany\n",
      "basisfunctions.Justaswecanexpressacovariancematrixintermsofits\n",
      "eigenvectorsandeigenvalues,wecanexpressagivenkernelK(xi,xj)interms\n",
      "ofitseigenfunctions?andeigenvalues?,withK(xi,xj)=\n",
      "?X\n",
      "?k?(k)(xi)?(k)(xj)\n",
      "(8)\n",
      "k=1\n",
      "foranyxiandxj.Usingtheresultsfromthepreviousparagraph,any\n",
      "kernelcanbeviewedastheresultofperformingBayesianlinearregressionwith\n",
      "asetofbasisfunctionscorrespondingtoitseigenfunctions,andapriorwith\n",
      "covariancematrix?b=diag(?).Theseresultsestablishanimportantduality\n",
      "betweenBayesianlinearregressionandGaussianprocesses:foreveryprioron\n",
      "functions,thereexistsacorrespondingkernel,andforeverykernel,thereexistsa\n",
      "correspondingprioronfunctions.Bayesianlinearregressionandpredictionwith\n",
      "Gaussianprocessesarethusjusttwoviewsofthesamesolutiontoregression\n",
      "problems.\n",
      "4\n",
      "CombiningrulesandsimilaritythroughGaussianprocesses\n",
      "Theresultsoutlinedintheprevioussectionsuggestthatlearningrulesand\n",
      "generalizingbasedonsimilarityshouldnotbeviewedasaccounts\n",
      "ofhumanfunctionlearning.Inthissection,wehighlighthowprevious\n",
      "accountsoffunctionlearningconnecttostatisticalmodels,andthenusethis\n",
      "insighttoamodelthatcombinesthestrengthsofbothapproaches.4.1\n",
      "Reinterpretingpreviousaccountsofhumanfunctionlearning\n",
      "Themodelspresentedabovewerechosenbecausethecontrastbetweenrules\n",
      "andsimilarityinfunctionlearningisanalogoustothebetweenBayesian\n",
      "linearregressionandGaussianprocesses.Theideathathumanfunctionlearning\n",
      "canbeviewedasakindofstatisticalregression[1,3]clearlyconnectsdirectlyto\n",
      "Bayesianlinearregression.Whilethereisnodirectformalcorrespondence,the\n",
      "basicideasbehindGaussianprocessregressionwitharadialbasiskerneland\n",
      "similarity-basedmodelssuchasALMarecloselyrelated.Inparticular,ALM\n",
      "hasmanycommonalitieswithradial-basisfunctionneuralnetworks,whichare\n",
      "directlyrelatedtoGaussianprocesses[11].Gaussianprocesseswithradial-basis\n",
      "kernelscanthusbeviewedasimplementingasimplekindofsimilarity-based\n",
      "generalization,predictingsimilaryvaluesforstimuliwithsimilarxvalues.Fi-\n",
      "nally,thehybridapproachtorulelearningtakenin[6]isalsocloselyrelated\n",
      "toBayesianlinearregression.Therulesrepresentedbythehiddenunitsserve\n",
      "asabasissetthatspecifyaclassoffunctions,andapplyingpenalizedgradi-\n",
      "entdescentontheweightsassignedtothosebasiselementsservesasanonline\n",
      "6\n",
      "\n",
      "algorithmfordingthefunctionwithhighestposteriorprobability[12].4.2\n",
      "MixingfunctionsinaGaussianprocessmodel\n",
      "TherelationshipbetweenGaussianprocessesandBayesianlinearregression\n",
      "suggeststhatwecanasinglemodelthatexploitsbothsimilarityand\n",
      "rulesinformingpredictions.Inparticular,wecandothisbytakingapriorthat\n",
      "coversabroadclassoffunctions?includingthoseconsistentwitharadialbasis\n",
      "kernel?or,equivalently,modelingyasbeingproducedbyaGaussianprocess\n",
      "withakernelcorrespondingtooneofasmallnumberoftypes.Sp,\n",
      "weassumethatobservationsaregeneratedbychoosingatypeoffunctionfrom\n",
      "theset\n",
      "f\n",
      "PositiveLinear,NegativeLinear,Quadratic,Nonlinear\n",
      "g\n",
      ",wherethe\n",
      "probabilitiesofthesealternativesarebythevector?,andthensampling\n",
      "yfromaGaussianprocesswithakernelcorrespondingtotheappropriateclass\n",
      "offunctions.Therelevantkernelsareintroducedintheprevioussections(taking\n",
      "?Nonlinear?tocorrespondtotheradialbasiskernel),withthe?PositiveLinear?\n",
      "and?NegativeLinear?kernelsbeingderivedinasimilarwaytothestandard\n",
      "linearkernelbutwiththemeanoftheprioronbbeing[01]and[1?1]rather\n",
      "thansimplyzero.UsingthisGaussianprocessmodelallowsalearnertomake\n",
      "aninferenceaboutthetypeoffunctionfromwhichtheirobservationsaredrawn,\n",
      "aswellasthepropertiesofthefunctionofthattype.Inpractice,weperform\n",
      "probabilisticinferenceusingaMarkovchainMonteCarlo(MCMC)algorithm\n",
      "(see[13]foranintroduction).ThisalgorithmdenesaMarkovchainforwhich\n",
      "thestationary5\n",
      "distributionisthedistributionfromwhichwewishtosample.Inourcase,\n",
      "thisistheposteriordistributionovertypesandthehyperparametersforthe\n",
      "kernels?giventheobservationsxandt.Thehyperparametersinclude?1\n",
      "and?2aboveandthenoiseintheobservations?t2.OurMCMC\n",
      "algorithmrepeatstwosteps.Thestepissamplingthetypeoffunction\n",
      "conditionedonx,t,andthecurrentvalueof?,withtheprobabilityofeachtype\n",
      "beingproportionaltotheproductofp(tn|xn)forthecorrespondingGaussian\n",
      "processandthepriorprobabilityofthattypeasgivenby?.Thesecondstep\n",
      "issamplingthevalueof?givenxn,tn,andthecurrenttype,whichisdone\n",
      "usingaMetropolis-Hastingsprocedure(see[13]),proposingavaluefor?from\n",
      "aGaussiandistributioncenteredonthecurrentvalueanddecidingwhetherto\n",
      "acceptthatvaluebasedontheproductoftheprobabilityitassignstotngiven\n",
      "xnandthepriorp(?).Weuseanuninformativeprioron?.\n",
      "5\n",
      "TestingtheGaussianprocessmodel\n",
      "Followingarecentreviewofcomputationalmodelsoffunctionlearning[6],\n",
      "welookattwoquantitativetestsofGaussianprocessesasanaccountofhuman\n",
      "functionlearning:reproducingtheorderofyoflearningfunctionsof\n",
      "ttypes,andextrapolationperformance.Asindicatedearlier,thereisa\n",
      "largeliteratureconsistingofbothmodelsanddataconcerninghumanfunction\n",
      "learning,andthesesimulationsareintendedtodemonstratethepotentialof\n",
      "theGaussianprocessmodelratherthantoprovideanexhaustivetestofits\n",
      "performance.5.1\n",
      "yoflearning\n",
      "7\n",
      "\n",
      "Anecessarycriterionforatheoryofhumanfunctionlearningisaccounting\n",
      "forwhichfunctionspeoplelearnreadilyandwhichthey?the\n",
      "relativeyoflearningvariousfunctions.Table1isanaugmentedversion\n",
      "ofresultspresentedin[6]whichcomparedseveralmodelstotheempirically\n",
      "observedyoflearningarangeoffunctions.Eachentryinthetableisthe\n",
      "meanabsolutedeviation(MAD)ofhumanormodelresponsesfromtheactual\n",
      "valueofthefunction,evaluatedoverthestimulipresentedintraining.TheMAD\n",
      "providesameasureofhowitisforpeopleoragivenmodeltolearna\n",
      "function.Thedatareportedforeachsetofstudiesareorderedbyincreasing\n",
      "MAD(correspondingtoincreasingy).Inadditiontoreproducingthe\n",
      "MADforthemodelsin[6],thetableincludesresultsforsevenGaussianprocess\n",
      "(GP)models.ThesevenGPmodelsincorporatedntkernelfunctionsby\n",
      "adjustingtheirpriorprobability.Drawingonthe\n",
      "f\n",
      "PositiveLinear,Negative\n",
      "Linear,Quadratic,Nonlinear\n",
      "g\n",
      "setofkernelfunctions,themostcomprehensive\n",
      "modeltook?=(0.5,0.4,0.09,0.01).2SixotherGPmodelswereexamined\n",
      "byassigningcertainkernelfunctionszeropriorprobabilityandre-normalizing\n",
      "themovalueof?sothatthepriorprobabilitiessummedtoone.The\n",
      "sevendistinctGPmodelsarepresentedinTable1andlabeledbythekernel\n",
      "functionswithnon-zeropriorprobability:Linear(PositiveLinearandNegative\n",
      "Linear),Quadratic,Nonlinear(RadialBasisFunction),LinearandQuadratic,\n",
      "LinearandNonlinear,QuadraticandNonlinear,andLinear,Quadratic,and\n",
      "Nonlinear.ThelasttworowsofTable1givethecorrelationsbetweenhuman\n",
      "andmodelperformanceacrossfunctions,expressingquantitativelyhowwell\n",
      "eachmodelcapturedthepatternofhumanfunctionlearningbehavior.TheGP\n",
      "modelsperformwellaccordingtothismetric,providingaclosermatchtothe\n",
      "humandatathananyofthemodelsconsideredin[6],withthequadratickernel\n",
      "andthemodelswithamixtureofkernelstendingtoprovideaclosermatchto\n",
      "humanbehavior.5.2\n",
      "Extrapolationperformance\n",
      "Predictingandexplainingpeople?scapacityforgeneralization?fromstimulus-\n",
      "responsepairstojudgmentsaboutafunctionalrelationshipbetweenvariables\n",
      "?isthesecondkeycomponentofouraccount.Thiscapacityisassessedinthe\n",
      "wayinwhichpeopleextrapolate,makingjudgmentsaboutstimulitheyhave\n",
      "notencounteredbefore.Figure1showsmeanhumanpredictionsforalinear,\n",
      "exponential,andquadraticfunction(from[4]),togetherwiththepredictionsof\n",
      "themostcomprehensiveGPmodel(withLinear,QuadraticandNonlinearker-\n",
      "nelfunctions).Theregionstotheleftandrightoftheverticallinesrepresent\n",
      "extrapolationregions,beinginputvaluesforwhichneitherpeoplenor2The\n",
      "selectionofthesevalueswasguidedbyresultsindicatingtheorderofy\n",
      "oflearningfunctionsofthesettypesforhumanlearners,butwedidnot\n",
      "optimize?withrespecttothecriteriareportedhere.\n",
      "6\n",
      "HybridmodelsFunctionHumanALMPolyFourierLogisticByun(1995,\n",
      "Expt1B)Linear.20.04.04.05.16Squareroot.35.05.06.06.19Byun(1995,\n",
      "Expt1A)Linear.15.10.33.33.17Power,pos.acc..20.12.37.37.24Power,\n",
      "neg.acc..23.12.36.36.19Logarithmic.30.14.41.41.19Logistic.39.18\n",
      "8\n",
      "\n",
      ".51.52.33Byun(1995,Expt2)Linear.18.01.18.19.12Quadratic.28.03\n",
      ".31.31.24Cyclic.68.32.41.40.68Delosh,Busemeyer,&McDaniel(1997)\n",
      "Linear.10.04.11.11.04Exponential.15.05.17.17.02Quadratic.24.07.27\n",
      ".27.11CorrelationofhumanandmodelperformanceLinear1.0.83.45.45.93\n",
      "Rank-order1.0.55.51.51.77\n",
      "GaussianprocessmodelsLinearQuadRBFLQLRQR\n",
      "LQR\n",
      ".0002.06\n",
      ".004.02\n",
      ".06.05\n",
      ".0002.0002.02.03\n",
      ".0001.02\n",
      ".0003.11.06.10.20\n",
      ".004.004.02.04.20\n",
      ".04.08.05.07.22\n",
      ".0002.0002.0009.0001.004.05.003.003.02.03.02.02.04.05.03.03.20\n",
      ".18.18.18\n",
      ".0003.20.50\n",
      ".005.09.50\n",
      ".05.14.50\n",
      ".0003.0002.09.12.50.49\n",
      ".001.04.49\n",
      ".0002.04.49\n",
      ".0005.03.1\n",
      ".005.01.06\n",
      ".03.02.07\n",
      ".0005.0003.01.02.06.06\n",
      ".002.009.04\n",
      ".0004.01.04\n",
      ".93.76\n",
      ".92.80\n",
      ".92.75\n",
      ".92.82\n",
      ".92.83\n",
      ".93.83\n",
      ".93.83\n",
      ".001.02\n",
      "Linear\n",
      "Exponential\n",
      "Quadratic\n",
      "(c)\n",
      "Exponential.997.989.997.997.997.997.994.995\n",
      "(a)\n",
      "Quadratic.961.470.901.882.886.892.878.877\n",
      "Table1:cultyoflearningresults.Rowscorrespondtofunctionslearned\n",
      "inexperimentsreviewedin[6].Columnsgivethemeanabsolutedeviation\n",
      "9\n",
      "\n",
      "(MAD)fromthetruefunctionsforhumanlearnersandtmodels(Gaus-\n",
      "sianprocessmodelswithmultiplekernelsaredenotedbytheinitialsoftheir\n",
      "kernels,e.g.,LQR=Linear,Quadratic,andRadialBasisFunction).Human\n",
      "MADvaluesrepresentsamplemeans(forasinglesubjectovertrials,thenover\n",
      "subjects),andbothestimationandproductionerrors,beinghigherthan\n",
      "modelMADvalueswhicharecomputedusingdeterministicmodelpredictions\n",
      "andthustonlyestimationerror.Thelasttworowsgivethelinearand\n",
      "rank-ordercorrelationsofthehumanandmodelMADvalues,providinganin-\n",
      "dicationofhowwellthemodelmatchestheypeoplehaveinlearning\n",
      "tfunctions.\n",
      "FunctionHuman/Model\n",
      "ModelEXAMLinearQuadRBFLQLRRQLRQ\n",
      "Linear.999.999.997.999.999.999.998.999\n",
      "(b)\n",
      "Figure1:Extrapolationperformance.(a)-(b)Meanpredictionsonlinear,\n",
      "exponential,andquadraticfunctionsfor(a)humanparticipants(from[4])and\n",
      "(b)aGaussianprocessmodelwithLinear,Quadratic,andNonlinearkernels.\n",
      "Trainingdatawerepresentedintheregionbetweentheverticallines,andex-\n",
      "trapolationperformancewasevaluatedoutsidethisregion.(c)Correlations\n",
      "betweenhumanandmodelextrapolation.Gaussianprocessmodelsaredenoted\n",
      "asinTable1.\n",
      "7\n",
      "themodelweretrained.Bothpeopleandthemodelextrapolatenearopti-\n",
      "mallyonthelinearfunction,andreasonablyaccurateextrapolationalsooccurs\n",
      "fortheexponentialandquadraticfunction.However,thereisabiastowardsa\n",
      "linearslopeintheextrapolationoftheexponentialandquadraticfunctions,with\n",
      "extremevaluesofthequadraticandexponentialfunctionbeingoverestimated.\n",
      "QuantitativemeasuresofextrapolationperformanceareshowninFigure1(c),\n",
      "whichgivesthecorrelationbetweenhumanandmodelpredictionsforEXAM\n",
      "[4,5]andthesevenGPmodels.WhilenoneoftheGPmodelsproducequiteas\n",
      "highacorrelationasEXAMonallthreefunctions,allofthemodelsexceptthat\n",
      "withjustthelinearkernelproducerespectablecorrelations.Itisparticularly\n",
      "notablethatthisperformanceisachievedwithouttheoptimizationofanyfree\n",
      "parameters,whilethepredictionsofEXAMweretheresultofoptimizingtwo\n",
      "parametersforeachofthethreefunctions.\n",
      "6\n",
      "Conclusions\n",
      "Wehavepresentedarationalaccountofhumanfunctionlearning,drawing\n",
      "onideasfrommachinelearningandstatisticstoshowthatthetwoapproaches\n",
      "thathavedominatedpreviouswork?rulesandsimilarity?canbeinterpreted\n",
      "astwoviewsofthesamekindofoptimalsolutiontothisproblem.OurGaussian\n",
      "processmodelcombinesthestrengthsofbothapproaches,usingamixtureof\n",
      "kernelstoallowsystematicextrapolationaswellassensitivenon-linearinterpo-\n",
      "lation.Testsoftheperformanceofthismodelonbenchmarkdatasetsshowthat\n",
      "itcancapturesomeofthebasicphenomenaofhumanfunctionlearning,and\n",
      "iscompetitivewithexistingprocessmodels.Infuturework,weaimtoextend\n",
      "10\n",
      "\n",
      "thisGaussianprocessmodeltoallowittoproducesomeofthemorecomplex\n",
      "phenomenaofhumanfunctionlearning,suchasnon-monotonicextrapolation\n",
      "(viaperiodickernels)andlearningtfunctionsintpartsofthein-\n",
      "putspace(viamixturemodeling).Acknowledgments.Thisworkwassupported\n",
      "bygrantFA9550-07-1-0351fromtheAirForceofScienResearchand\n",
      "grants0704034and0544705fromtheNationalScienceFoundation.\n",
      "2References\n",
      "[1]J.D.Carroll.Functionallearning:Thelearningofcontinuousfunctional\n",
      "mappingsrelatingstimulusandresponsecontinua.EducationTestingService,\n",
      "Princeton,NJ,1963.[2]B.Brehmer.Hypothesesaboutrelationsbetween\n",
      "scaledvariablesinthelearningofprobabilisticinferencetasks.Organizational\n",
      "BehaviorandHumanDecisionProcesses,11:1?27,1974.[3]K.KohandD.\n",
      "E.Meyer.Functionlearning:Inductionofcontinuousstimulus-responserela-\n",
      "tions.JournalofExperimentalPsychology:Learning,Memory,andCognition,\n",
      "17:811?836,1991.[4]E.L.DeLosh,J.R.Busemeyer,andM.A.McDaniel.\n",
      "Extrapolation:Thesinequanonofabstractioninfunctionlearning.Journalof\n",
      "ExperimentalPsychology:Learning,Memory,andCognition,23:968?986,1997.\n",
      "[5]J.R.Busemeyer,E.Byun,E.L.DeLosh,andM.A.McDaniel.Learning\n",
      "functionalrelationsbasedonexperiencewithinput-outputpairsbyhumansand\n",
      "neuralnetworks.InK.LambertsandD.Shanks,editors,Conceptsand\n",
      "Categories,pages405?437.MITPress,Cambridge,1997.[6]M.A.McDaniel\n",
      "andJ.R.Busemeyer.Theconceptualbasisoffunctionlearningandextrapo-\n",
      "lation:Comparisonofrule-basedandassociative-basedmodels.Psychonomic\n",
      "BulletinandReview,12:24?42,2005.[7]M.Kalish,S.Lewandowsky,andJ.\n",
      "Kruschke.Populationoflinearexperts:Knowledgepartitioningandfunction\n",
      "learning.PsychologicalReview,111:1072?1099,2004.[8]J.R.Anderson.The\n",
      "adaptivecharacterofthought.Erlbaum,Hillsdale,NJ,1990.[9]J.M.Bernardo\n",
      "andA.F.M.Smith.Bayesiantheory.Wiley,NewYork,1994.[10]C.K.I.\n",
      "Williams.PredictionwithGaussianprocesses:Fromlinearregressiontolinear\n",
      "predictionandbeyond.InM.I.Jordan,editor,LearninginGraphicalModels,\n",
      "pages599?621.MITPress,Cambridge,MA,1998.[11]R.M.Neal.Priorsfor\n",
      "networks.TechnicalReportCRG-TR-94-1,DepartmentofComputer\n",
      "Science,UniversityofToronto,1994.[12]D.J.C.MacKay.Probablenetworks\n",
      "andplausiblepredictions-areviewofpracticalbayesianmethodsforsupervised\n",
      "neuralnetworks.Network:ComputationinNeuralSystems,6:469?505,1995.\n",
      "[13]W.R.Gilks,S.Richardson,andD.J.Spiegelhalter,editors.MarkovChain\n",
      "MonteCarloinPractice.ChapmanandHall,UK,1996.\n",
      "8\n",
      "11\n",
      "\n",
      "PP3887.pdf\n",
      "PP3887.pdf 12\n",
      "Maximinylearningofimagesegmentation\n",
      "Authoredby:\n",
      "SebastianSeung\n",
      "KevinBriggman\n",
      "WinfriedDenk\n",
      "MoritzN.Helmstaedter\n",
      "SrinivasC.Turaga\n",
      "Abstract\n",
      "Imagescanbesegmentedbyusingatopredictan\n",
      "itygraphthatrethedegreetowhichimagepixelsmustbegrouped\n",
      "togetherandthenpartitioningthegraphtoyieldasegmentation.Ma-\n",
      "chinelearninghasbeenappliedtotheytoproducey\n",
      "graphsthataregoodinthesenseofminimizingedge\n",
      "rates.However,thiserrormeasureisonlyindirectlyrelatedtothequality\n",
      "ofsegmentationsproducedbyultimatelypartitioningtheygraph.\n",
      "Wepresentthemachinelearningalgorithmfortrainingato\n",
      "produceygraphsthataregoodinthesenseofproducingsegmenta-\n",
      "tionsthatdirectlyminimizetheRandindex,awellknownsegmentation\n",
      "performancemeasure.TheRandindexmeasuressegmentationperfor-\n",
      "mancebyquantifyingtheoftheconnectivityofimagepixel\n",
      "pairsaftersegmentation.Byusingthesimplegraphpartitioningalgo-\n",
      "rithmoftheconnectedcomponentsofthethresholdedy\n",
      "graph,weareabletotrainanytodirectlyminimizethe\n",
      "Randindexofsegmentationsresultingfromthegraphpartitioning.Our\n",
      "learningalgorithmcorrespondstothelearningofmaximinbe-\n",
      "tweenimagepixelpairs,whicharepredictiveofthepixel-pairconnectivity.\n",
      "1PaperBody\n",
      "Supervisedlearninghasemergedasaseriouscontenderintheofimage\n",
      "segmentation,eversincethecreationoftrainingsetsofimageswith?ground\n",
      "truth?segmentationsprovidedbyhumans,suchastheBerkeleySegmentation\n",
      "Dataset[15].Supervisedlearningrequires1)aparametrizedalgorithmthat\n",
      "mapimagestosegmentations,2)anobjectivefunctionthatquantheper-\n",
      "formanceofasegmentationalgorithmrelativetogroundtruth,and3)ameans\n",
      "ofsearchingtheparameterspaceofthesegmentationalgorithmforanoptimum\n",
      "oftheobjectivefunction.Inthesupervisedlearningmethodpresentedhere,\n",
      "1\n",
      "\n",
      "thesegmentationalgorithmconsistsofaparametrizedthatpredicts\n",
      "theweightsofanearestneighbornitygraphoverimagepixels,followedby\n",
      "agraphpartitionerthatthresholdstheygraphanditsconnected\n",
      "components.OurobjectivefunctionistheRandindex[18],whichhasrecently\n",
      "beenproposedasaquantitativemeasureofsegmentationperformance[23].We\n",
      "?soften?thethresholdingoftheoutputandadjusttheparametersof\n",
      "thebygradientlearningbasedontheRandindex.?sturaga@mit.edu\n",
      "1\n",
      "hypotheticalthresholdedygraphs\n",
      "segmentationalgorithm\n",
      "missing\n",
      "merge!\n",
      "yprediction\n",
      "image\n",
      "threshold,connectedcomponents\n",
      "weightedygraph\n",
      "segmentation\n",
      "ygraph#1\n",
      "ygraph#2\n",
      "Figure1:(left)Oursegmentationalgorithm.Wegenerateanear-\n",
      "estneighborweightedygraphrepresentingthedegreetowhichnearest\n",
      "neighborpixelsshouldbegroupedtogether.Thesegmentationisgenerated\n",
      "bytheconnectedcomponentsofthethresholdedygraph.(right)\n",
      "ymisclassiationratesareapoormeasureofsegmentationperformance.\n",
      "ygraph#1makesonly1error(dashededge)butresultsinpoorsegmen-\n",
      "tations,whilegraph#2generatesaperfectsegmentationdespitemakingmany\n",
      "y(dashededges).\n",
      "Becausemaximinedgesoftheygraphplayakeyroleinourlearning\n",
      "method,wecallitmaximinylearningofimagesegmentation,orMALIS.\n",
      "Theminimaxpathandedgearestandardconceptsingraphtheory,andmax-\n",
      "iministheopposite-signsiblingofminimax.Henceourworkcanbeviewedas\n",
      "amachinelearningapplicationofthesegraphtheoreticconcepts.MALISfo-\n",
      "cusesonimprovingoutputatmaximinedges,becauseclassifyingthese\n",
      "edgesincorrectlyleadstogenuinesegmentationerrors,thesplittingormerg-\n",
      "ingofsegments.Tothebestofourknowledge,MALISisthestsupervised\n",
      "learningmethodthatisbasedonoptimizingagenuinemeasureofsegmenta-\n",
      "tionperformance.Theideaoftrainingatopredicttheweightsofan\n",
      "ygraphisnotnovel.ywerepreviouslytrainedtomin-\n",
      "imizethenumberofmisclassedtyedges[9,16].Thisisnotthesame\n",
      "asoptimizingsegmentationsproducedbypartitioningtheygraph.There\n",
      "havebeenattemptstotrainytoproducegoodsegmentations\n",
      "whenpartitionedbynormalizedcuts[17,2].Buttheseapproachesdonotopti-\n",
      "mizeagenuinemeasureofsegmentationperformancesuchastheRandindex.\n",
      "TheworkofBachandJordan[2]istheclosesttoourwork.However,theyonly\n",
      "minimizeanupperboundtoarenormalizedversionoftheRandindex.Bothap-\n",
      "proachesrequiremanyapproximationstomakethelearningtractable.Inother\n",
      "2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatedwork,havebeentrainedtooptimizeperformanceatdetecting\n",
      "imagepixelsthatbelongtoobjectboundaries[16,6,14].Ourcan\n",
      "alsobeviewedasaboundarydetector,sinceanearestneighborygraph\n",
      "isessentiallythesameasaboundarymap,uptoasigninversion.However,we\n",
      "combineourwithagraphpartitionertoproducesegmentations.The\n",
      "parametersarenottrainedtooptimizeperformanceatboundaryde-\n",
      "tection,buttooptimizeperformanceatsegmentationasmeasuredbytheRand\n",
      "index.Therearealsomethodsforsupervisedlearningofimagelabelingusing\n",
      "Markovorconditionalrandom[10].Butimagelabelingismoresimilar\n",
      "tomulti-classpixelratherthanimagesegmentation,asthelatter\n",
      "taskmayrequiredistinguishingbetweenmultipleobjectsinasingleimagethat\n",
      "allhavethesamelabel.Inthecaseswhereprobabilisticrandommodels\n",
      "havebeenusedforimageparsingandsegmentation,themodelshaveeither\n",
      "beensimplisticfortractabilityreasons[12]orhavebeentrainedpiecemeal.For\n",
      "instance,Tuetal.[22]separatelytrainlow-leveldiscriminativemodulesbased\n",
      "onaboostingandtrainhigh-levelmodulesoftheiralgorithmtomodel\n",
      "thejointdistributionoftheimageandthelabeling.Thesemodelshavenever\n",
      "beentrainedtominimizetheRandindex.\n",
      "2\n",
      "Partitioningathresholdedygraphbyconnectedcomponents\n",
      "Ourclassofsegmentationalgorithmsisconstructedbycombiningac\n",
      "andagraphpartitioner(seeFigure1).Theisusedtogeneratethe\n",
      "weightsofanygraph.Thenodesofthegraphareimagepixels,andthe\n",
      "edgesarebetweennearestneighborpairsofpixels.Theweightsoftheedgesare\n",
      "calledAhighymeansthatthetwopixelstendtobelongtothe\n",
      "same2\n",
      "segment.Theclassicomputestheyofeachedgebasedonanimage\n",
      "patchsurroundingtheedge.Thegraphpartitionerthresholdsthey\n",
      "graphbyremovingalledgeswithweightslessthansomethresholdvalue?.The\n",
      "connectedcomponentsofthisthresholdedygrapharethesegmentsof\n",
      "theimage.Forthisclassofsegmentationalgorithms,it?sobviousthatasin-\n",
      "gleedgeoftheygraphcandramaticallyaltertheresulting\n",
      "segmentationbysplittingormergingtwosegments(seeFig.1).Thisiswhy\n",
      "itisimportanttolearnbyoptimizingameasureofsegmentationperformance\n",
      "ratherthanyprediction.Wearewellawarethatconnectedcomponents\n",
      "isanexceedinglysimplemethodofgraphpartitioning.Moresophisticatedalgo-\n",
      "rithms,suchasspectralclustering[20]orgraphcuts[3],mightbemorerobust\n",
      "tomiscofoneorafewedgesoftheygraph.Whynotuse\n",
      "theminstead?Wehavetworepliestothisquestion.First,becauseofthesim-\n",
      "plicityofourgraphpartitioning,wecanderiveasimpleanddirectmethod\n",
      "ofsupervisedlearningthatoptimizesatruemeasureofimagesegmentation\n",
      "performance.Sofarlearningbasedonmoresophisticatedgraphpartitioning\n",
      "methodshasfallenshortofthisgoal[17,2].Second,evenifitwerepossible\n",
      "toproperlylearntheusedbymoresophisticatedgraphpartitioning\n",
      "methods,wewouldstillpreferoursimpleconnectedcomponents.The\n",
      "inoursegmentationalgorithmcanalsocarryoutsophisticatedcomputations,if\n",
      "3\n",
      "\n",
      "itsrepresentationalpoweristlygreat.Puttingthesophisticationinthe\n",
      "hastheadvantageofmakingitlearnable,ratherthanhand-designed.\n",
      "Thesophisticatedpartitioningmethodscleanuptheygraphbyusing\n",
      "priorassumptionsaboutthepropertiesofimagesegmentations.Buttheseprior\n",
      "assumptionscouldbeincorrect.Thespiritofthemachinelearningapproach\n",
      "istousealargeamountoftrainingdataandminimizetheuseofprioras-\n",
      "sumptions.Ifthesophisticatedpartitioningmethodsareindeedthebestway\n",
      "ofachievinggoodsegmentationperformance,wesuspectthatourwill\n",
      "learnthemfromthetrainingdata.Iftheyarenotthebestway,wehopethat\n",
      "ourwilldoevenbetter.\n",
      "3\n",
      "TheRandindexquansegmentationperformance\n",
      "Imagesegmentationcanbeviewedasaspecialcaseofthegeneralproblem\n",
      "ofclustering,asimagesegmentsareclustersofimagepixels.Longago,Rand\n",
      "proposedanindexofsimilaritybetweentwoclusterings[18].Recentlyithas\n",
      "beenproposedthattheRandindexbeappliedtoimagesegmentations[23].\n",
      "asegmentationSasanassignmentofasegmentlabelsitoeachpixel\n",
      "i.Theindicatorfunction?(si,sj)is1ifpixelsiandjbelongtothesame\n",
      "segment(si=sj)and0otherwise.GiventwosegmentationsSandS?ofan\n",
      "imagewithNpixels,thefunction?S)=1?RI(S,\n",
      "?1\n",
      "N?(si,sj)??(s?i,s?j)?2i<j\n",
      "(1)\n",
      "whichisthefractionofimagepixelpairsonwhichthetwosegmentations\n",
      "disagree.Wewillreferto?S)astheRandindex,althoughstrictlyspeakingthe\n",
      "RandindexisRI(S,?S),thefunction1?RI(S,thefractionofimagepixel\n",
      "pairsonwhichthetwosegmentationsagree.Inotherwords,theRandindex\n",
      "isameasureofsimilarity,butwewilloftenapplythattermtoameasureof\n",
      "dissimilarity.Inthispaper,theRandindexisappliedtocomparetheoutputS?\n",
      "ofasegmentationalgorithmwithagroundtruthsegmentationS,andwillserve\n",
      "asanobjectivefunctionforlearning.Figure1illustrateswhytheRandindexis\n",
      "asensiblemeasureofsegmentationperformance.Thesegmentationofy\n",
      "graph#1incursahugeRandindexpenaltyrelativetothegroundtruth.A\n",
      "singlewronglyedgeoftheygraphleadstoanincorrectmergerof\n",
      "twosegments,causingmanypairsofimagepixelstobewronglyassignedtothe\n",
      "samesegment.Ontheotherhand,thesegmentationcorrespondingtoy\n",
      "graph#2hasaperfectRandindex,eventhoughtherearein\n",
      "theygraph.Inshort,theRandindexmakessensebecauseitstrongly\n",
      "penalizeserrorsintheygraphthatleadtosplitandmergererrors.3\n",
      "1\n",
      "merger\n",
      "11?\n",
      "1?\n",
      "2\n",
      "23\n",
      "3?2?2\n",
      "4\n",
      "\n",
      "2?\n",
      "3?\n",
      "3?\n",
      "4\n",
      "4?\n",
      "groundtruth\n",
      "test\n",
      "split\n",
      "4\n",
      "4?\n",
      "randindex\n",
      "Figure2:TheRandindexquanessegmentationperformancebycompar-\n",
      "ingtheinpixelpairconnectivitybetweenthegroundtruthandtest\n",
      "segmentations.Pixelpairconnectivitiescanbevisualizedassymmetricbinary\n",
      "block-diagonalmatrices(si,sj).Eachdiagonalblockcorrespondstocon-\n",
      "nectedpixelpairsbelongingtooneoftheimagesegments.TheRandindex\n",
      "incurspenaltieswhenpixelspairsthatmustnotbeconnectedareconnectedor\n",
      "viceversa.Thiscorrespondstolocationswherethetwomatricesdisagree.An\n",
      "erroneousmergeroftwogroundtruthsegmentsincursapenaltyproportionalto\n",
      "theproductofthesizesofthetwosegments.Spliterrorsaresimilarlypenalized.\n",
      "4\n",
      "Connectivityandmaximiny\n",
      "Recallthatoursegmentationalgorithmworksbyconnectedcompo-\n",
      "nentsofthethresholdedygraph.LetS?bethesegmentationproduced\n",
      "inthisway.ToapplytheRandindextotrainourweneedasimple\n",
      "wayofrelatingtheindicatorfunction(s?i,s?j)intheRandindexto\n",
      "output.Inotherwords,wewouldlikeawayofcharacterizingwhethertwopix-\n",
      "elsareconnectedinthethresholdedygraph.Todothis,weintroducethe\n",
      "conceptofmaximiny,whichisforanypairofpixelsinany\n",
      "graph(theisgenerallyapplicabletoanyweightedgraph).LetAkl\n",
      "betheyofpixelskandl.LetPijbethesetofallpathsinthegraph\n",
      "thatconnectpixelsiandj.ForeverypathPinPij,thereisanedge(oredges)\n",
      "withminimaly.Thisiswrittenasmink,lPAkl,wherek,lPmeansthat\n",
      "theedgebetweenpixelskandlareinthepathP.AmaximinpathPijisapath\n",
      "betweenpixelsiandjthatmaximizestheminimaly,Pij=\n",
      "argmaxminAklPPijk,lP\n",
      "(2)\n",
      "Themaximinyofpixelsiandjistheyofthemaximinedge,or\n",
      "theminimalyofthemaximinpath,Aij=\n",
      "maxminAkl\n",
      "PPijk,lP\n",
      "(3)\n",
      "Wearenowreadyforatrivialbutimportanttheorem.Theorem1.A\n",
      "pairofpixelsisconnectedinthethresholdedygraphifandonlyiftheir\n",
      "maximinnityexceedsthethresholdvalue.Proof.Byapixelpair\n",
      "isconnectedinthethresholdedygraphifandonlyifthereexistsapath\n",
      "5\n",
      "\n",
      "betweenthem.Suchapathisequivalenttoapathintheunthresholdedy\n",
      "graphforwhichtheminimalyisabovethethresholdvalue.Thispath\n",
      "inturnexistsifandonlyifthemaximinyisabovethethresholdvalue.\n",
      "Asaconsequenceofthistheorem,pixelpairscanbeasconnectedor\n",
      "disconnectedbythresholdingmaximinLetS?bethesegmentation\n",
      "producedbythresholdingtheygraphAijandthenconnected\n",
      "components.Thentheconnectivityindicatorfunctionis\n",
      "(s?i,s?j)=H(Aij)\n",
      "(4)\n",
      "whereHistheHeavisidestepfunction.Maximincanbecomputed\n",
      "tlyusingminimumspanningtreealgorithms[8].Amaximumspanning\n",
      "treeisequivalenttoaminimumspanningtree,uptoasignchangeoftheweights.\n",
      "4\n",
      "Anypathinamaximumspanningtreeisamaximinpath.Forournearest\n",
      "neighborygraphs,themaximinyofapixelpaircanbecomputedin\n",
      "O(|E|??(|V|))where|E|isthenumberofgraphedgesand|V|\n",
      "isthenumberofpixelsand?(?)istheinverseAckermanfunctionwhichgrows\n",
      "sub-logarithmically.ThefullmatrixAij?canbecomputedintimeO(|V|2)\n",
      "sincethecomputationcanbeshared.Notethatmaximinarerequired\n",
      "fortraining,butnottesting.Forsegmentingtheimageattesttime,onlya\n",
      "connectedcomponentscomputationneedbeperformed,whichtakestimelinear\n",
      "inthenumberofedges|E|.\n",
      "5\n",
      "OptimizingtheRandindexbylearningmaximin\n",
      "SincetheandmaximinarebothfunctionsoftheimageI\n",
      "andtheparametersW,wewillwritethemasAij(I;W)andAij?(\n",
      "I;W),respectively.ByEq.(4)oftheprevioussection,theRandindexofEq.\n",
      "(1)takestheform?1\n",
      "N\n",
      "1?RI(S,I;W)=?(si,sj)?H(Aij?(I;W)??)?2i<jSincethisisa\n",
      "discontinuousfunctionofthemaximinwemaketheusualrelaxation\n",
      "byreplacing|?(si,sj)?H(Aij?(I;W)??)|withacontinuousloss\n",
      "functionl(?(si,sj),Aij?(I;W)).Anystandardlosssuchasthesuchasthe\n",
      "squareloss,21(x?x?)2,orthehingelosscanbeusedforl(x,x?).Thus\n",
      "weobtainacostfunctionsuitableforgradientlearning,\n",
      "E(S,I;W)\n",
      "==\n",
      "?1N?l(?(si,sj),Aij?(I;W))2i<j?1NminAkl(I;W))?l(?(si,s\n",
      "j),Pmax2?Pijhk,li?Pi<j\n",
      "(5)\n",
      "Themaxandminoperationsarecontinuousandtiable(thoughnot\n",
      "continuouslytiable).Ifthelossfunctionlissmooth,andthey\n",
      "Akl(I;W)isasmoothfunction,thenthegradientofthecostfunctioniswell-\n",
      "andgradientdescentcanbeusedasanoptimizationmethod.\n",
      "(k,l)=mm(i,j)tobethemaximinedgeforthepixelpair(i,j).Ifthereis\n",
      "atie,choosebetweenthemaximinedgesatrandom.Thenthecostfunction\n",
      "6\n",
      "\n",
      "takestheform?1NE(S,I;W)=?l(?(si,sj),Amm(i,j)(I;W))2i<jIt?s\n",
      "instructivetocomparethiswiththecostfunctionforstandardylearning\n",
      "Estandard(S,I;W)=\n",
      "2cN\n",
      "?l(?(si,sj),Aij(I;W))\n",
      "hi,ji\n",
      "wherethesumisoverallnearestneighborpixelpairshi,jiandcisthe\n",
      "numberofnearestneighbors[9].Incontrast,thesumintheMALIScostfunction\n",
      "isoverallpairsofpixels,whetherornottheyareadjacentintheygraph.\n",
      "Notethatasingleedgecanbethemaximinedgeformultiplepairsofpixels,\n",
      "soitsycanappearmultipletimesintheMALIScostfunction.Roughly\n",
      "speaking,theMALIScostfunctionissimilartothestandardcostfunction,\n",
      "exceptthateachedgeintheygraphisweightedbythenumberofpixel\n",
      "pairsthatitcausestobeincorrectly\n",
      "6\n",
      "Onlinestochasticgradientdescent\n",
      "Computingthecostfunctionoritsgradientrequiresthemaximin\n",
      "edgesforallpixelpairs.Suchabatchcomputationcouldbeusedforgradient\n",
      "learning.However,onlinestochasticgradient5\n",
      "learningisoftenmoretthanbatchlearning[13].Onlinelearning\n",
      "makesagradientupdateoftheparametersaftereachpairofpixels,andisim-\n",
      "plementedasdescribedinthebox.MaximinylearningStandardnity\n",
      "learning1.Pickarandompairof(notnecessarilynearest1.Pickarandompair\n",
      "ofnearestneighborpixelsineighbor)pixelsiandjfromarandomlydrawnand\n",
      "jfromarandomlydrawntrainingimageItrainingimageI.2.Findamaximin\n",
      "edgemm(i,j)3.Makethegradientupdate:dl(?(si,sj),Amm(i,j)(I;W))\n",
      "W?W+?dW\n",
      "2.Makethegradientupdate:dl(?(si,sj),Aij(I;W))W?W+?dW\n",
      "Forcomparison,wealsoshowthestandardylearning[9].Foreachiter-\n",
      "ation,bothlearningmethodspickarandompairofpixelsfromarandomimage.\n",
      "Bothcomputethegradientoftheweightofasingleedgeintheygraph.\n",
      "However,thestandardmethodpicksanearestneighborpixelpairandtrainsthe\n",
      "yoftheedgebetweenthem.Themaximinmethodpicksapixelpairof\n",
      "arbitraryseparationandtrainstheminimalyonamaximinpathbetween\n",
      "them.ely,ourconnectedcomponentsperformsspatialintegrationover\n",
      "thenearestneighborygraphtomakeconnectivitydecisionsaboutpixel\n",
      "pairsatlargedistances.MALIStrainstheseglobaldecisions,whilestandard\n",
      "ylearningtrainsonlylocaldecisions.MALISissuperiorbecauseittruly\n",
      "learnssegmentation,butthissuperioritycomesataprice.Themaximincom-\n",
      "putationrequiresthatoneachiterationtheygraphbecomputedforthe\n",
      "wholeimage.Thereforeitisslowerthanthestandardlearningmethod,which\n",
      "requiresonlyalocalypredictionfortheedgebeingtrained.Thusthere\n",
      "isacomputationalpricetobepaidfortheoptimizationofatruesegmentation\n",
      "error.\n",
      "77.1\n",
      "7\n",
      "\n",
      "ApplicationtoelectronmicroscopicimagesofneuronsElectronmicroscopic\n",
      "imagesofneuraltissue\n",
      "By3dimagingofbraintissueatntlyhighresolution,aswellasidenti-\n",
      "fyingsynapsesandtracingallaxonsanddendritesintheseimages,itispossible\n",
      "inprincipletoreconstructconnectomes,complete?wiringdiagrams?forabrain\n",
      "orpieceofbrain[19,4,21].Axonscanbenarrowerthan100nmindiameter,\n",
      "necessitatingtheuseofelectronmicroscopy(EM)[19].Atsuchhighspatial\n",
      "resolution,justonecubicmillimeterofbraintissueyieldsteravoxelscaleimage\n",
      "sizes.Recentadvancesinautomationaremakingitpossibletocollectsuch\n",
      "images[19,4,21],butimageanalysisremainsachallenge.Tracingaxonsand\n",
      "dendritesisaverylarge-scaleimagesegmentationproblemrequiringhighac-\n",
      "curacy.Theimagesusedforthisstudywerefromtheinnerplexiformlayerof\n",
      "therabbitretina,andweretakenusingSerialBlock-FaceScanningElectron\n",
      "Microscopy[5].Twolargeimagevolumesof1003voxelswerehandsegmented\n",
      "andreservedfortrainingandtestingpurposes.7.2\n",
      "Trainingconvolutionalnetworksfory\n",
      "Anythatisasmoothfunctionofitsparameterscanbeusedfor\n",
      "maximinylearning.Wehaveusedconvolutionalnetworks(CN),butour\n",
      "methodisnotrestrictedtothischoice.Convolutionalnetworkshavepreviously\n",
      "beenshowntobeeforsimilarEMimagesofbraintissue[11].We\n",
      "trainedtwoidenticalfour-layerCNs,onewithstandardylearningand\n",
      "thesecondwithMALIS.TheCNscontained5featuremapsineachlayerwith\n",
      "sigmoidnonlinearities.AllintheCNwere5?5?5insize.Thisled\n",
      "toanythatusesa17?17?17cubicimagepatchtoclassify\n",
      "ayedge.Weusedthesquare-squarelossfunctionl(x,x?)=x?\n",
      "max(0,1?x??m)2+(1?x)?max(0,x??m)2,withamarginm\n",
      "=0.3.Asnotedearlier,maximinylearningcanbetlyslower\n",
      "thanstandardylearning,duetotheneedforcomputingtheentirey\n",
      "graphoneachiteration,whilestandardytrainingneedonlypredictthe\n",
      "weightofasingleedgeinthegraph.Forthisreason,weconstructedaproxy\n",
      "trainingimagedatasetbypickingallpossible21?21?21sizedoverlapping\n",
      "sub-images6\n",
      "fromtheoriginaltrainingset.Sinceeach21?21?21sub-imageissmaller\n",
      "thantheoriginalimage,thesizeoftheygraphneededtobepredictedfor\n",
      "thesub-imageiscantlysmaller,leadingtofastertraining.Aconsequence\n",
      "ofthisapproximationisthatthemaximumseparationbetweenimagepixelpairs\n",
      "chosenfortrainingislessthanabout20pixels.Asecondmeansofspeedingup\n",
      "themaximinprocedureisbypretrainingthemaximinCNfor500,000iterations\n",
      "usingthefaststandardycostfunction.Attheend,bothCNs\n",
      "weretrainedforatotalof1,000,000iterationsbywhichpointthetrainingerror\n",
      "plateaued.Maximinlearningleadstodramaticimprovementinsegmentation\n",
      "performance\n",
      "0.990.980.970.960.950.940.930.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "8\n",
      "\n",
      "Threshold\n",
      "0.9\n",
      "B.ROCcurve\n",
      "1\n",
      "C.Precision?Recallcurve\n",
      "0.80.60.40.20\n",
      "1\n",
      "1\n",
      "0.8\n",
      "0.8\n",
      "Mergers/object\n",
      "A.Clusteringaccuracy\n",
      "Precision\n",
      "Fractioncorrect\n",
      "1\n",
      "Truepositiverate\n",
      "7.3\n",
      "0.60.40.2\n",
      "0\n",
      "0.5\n",
      "Falsepositiverate\n",
      "1\n",
      "0\n",
      "0\n",
      "0.5\n",
      "Recall\n",
      "1\n",
      "D.Splitsvs.MergersStandard(Train)Standard(Test)Minimax(Train)\n",
      "Minimax(Test)\n",
      "0.60.40.20\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Splits/object\n",
      "4\n",
      "5\n",
      "Figure3:Quanofsegmentationperformanceon3delectronmicro-\n",
      "scopicimagesofneuraltissue.A)Clusteringaccuracymeasuringthenumber\n",
      "ofcorrectlypixelpairs.B)andC)ROCcurveandprecision-recall\n",
      "quanofpixel-pairconnectivityclashowsnearperfectperfor-\n",
      "mance.D)Segmentationerrorasmeasuredbythenumberofsplitsandmergers.\n",
      "Webenchmarkedtheperformanceofthestandardandmaximinyclas-\n",
      "bymeasuringthethepixel-pairconnectivityperformance\n",
      "usingtheRandindex.AftertrainingthestandardandMALISyclassi-\n",
      "wegeneratedygraphsforthetrainingandtestimages.Inprinciple,\n",
      "9\n",
      "\n",
      "thetrainingalgorithmsuggestsasinglethresholdforthegraphpartitioning.In\n",
      "practice,onecangenerateafullspectrumofsegmentationsleadingfromover-\n",
      "segmentationstounder-segmentationsbyvaryingthethresholdparameter.In\n",
      "Fig.3,weplottheRandindexforsegmentationsresultingfromarangeof\n",
      "thresholdvalues.Inimageswithlargenumbersofsegments,mostpixelpairs\n",
      "willbedisconnectedfromoneanotherleadingtoalargeimbalancingthenum-\n",
      "berofconnectedanddisconnectedpixelpairs.Thisisinthefactthat\n",
      "theRandindexisover95%forbothsegmentationalgorithms.Whilethisim-\n",
      "balancebetweenpositiveandnegativeexamplesisnotatproblem\n",
      "fortrainingtheyitcanmakecomparisonsbetween\n",
      "tointerpret.Instead,wecanusetheROCandprecision-recallmethod-\n",
      "ologies,whichprovideforaccuratequanoftheaccuracyof\n",
      "eveninthepresenceoflargeclassimbalance.Fromthesecurves,weobserve\n",
      "thatourmaximinydramaticallyoutperformsthestandard\n",
      "ityOurpositiveresultshaveanintriguinginterpretation.Thepoor\n",
      "performanceoftheconnectedcomponentswhenappliedtoastandardlearned\n",
      "ycouldbeinterpretedtoimplythat1)alocalclaslacksthe\n",
      "contextimportantforgoodyprediction;2)connectedcomponentsisa\n",
      "poorstrategyforimagesegmentationsincemistakesintheypredictionof\n",
      "justafewedgescanmergeorsplitsegments.Onthecontrary,ourexperiments\n",
      "suggestthatwhentrainedproperly,thresholdedyfollowed\n",
      "byconnectedcomponentscanbeanextremelycompetitivemethodofimage\n",
      "segmentations.\n",
      "8\n",
      "Discussion\n",
      "Inthispaper,wehavetrainedanytoproduceygraphs\n",
      "thatresultinexcellentsegmentationswhenpartitionedbythesimplegraph\n",
      "partitioningalgorithmofthresholdingfollowedbyconnectedcomponents.The\n",
      "keytogoodperformanceisthetrainingofasegmentation-basedcostfunction,\n",
      "andtheuseofapowerfultrainabletopredictygraphs.Once\n",
      "trained,oursegmentationalgorithmisfast.Incontrasttoclassicgraph-based\n",
      "segmentationalgorithmswhere7\n",
      "mergers\n",
      "image\n",
      "groundtruth\n",
      "maximintraining\n",
      "standardtraining\n",
      "Figure4:A2dcross-sectionthrougha3dsegmentationofthetestimage.\n",
      "Themaximinsegmentationcorrectlysegmentsseveralobjectswhicharemerged\n",
      "inthestandardsegmentation,andevencorrectlysegmentsobjectswhichare\n",
      "missinginthegroundtruthsegmentation.Notallsegmentsmergedinthestan-\n",
      "dardsegmentationaremergedatlocationsvisibleinthiscrosssection.Pixels\n",
      "coloredblackinthemachinesegmentationscorrespondtopixelscompletelydis-\n",
      "connectedfromtheirneighborsandrepresentboundaryregions.thepartitioning\n",
      "phasedominates,ourpartitioningalgorithmissimpleandcanpartitiongraphs\n",
      "intimelinearlyproportionaltothenumberofedgesinthegraph.Wealso\n",
      "10\n",
      "\n",
      "donotrequireanypriorknowledgeofthenumberofimagesegmentsorimage\n",
      "segmentsizesattesttime,incontrasttoothergraphpartitioningalgorithms[7,\n",
      "20].Theformalismofmaximinusedtoderiveourlearningalgorithm\n",
      "hasconnectionstosinglelinkagehierarchicalclustering,minimumspanningtrees\n",
      "andultrametricdistances.FelzenszwalbandHuttenlocher[7]describeagraph\n",
      "partitioningalgorithmbasedonaminimumspanningtreecomputationwhich\n",
      "resemblesoursegmentationalgorithm,inpart.TheUltrametricContourMap\n",
      "algorithm[1]generateshierarchicalsegmentationsnearlyidenticalthosegener-\n",
      "atedbyvaryingthethresholdofourgraphpartitioningalgorithm.Neitherof\n",
      "thesemethodsincorporatesameansforlearningfromlabeleddata,butourwork\n",
      "showshowtheperformanceofthesealgorithmscanbeimprovedbyuseofour\n",
      "maximinylearning.AcknowledgementsSCTandHSSweresupported\n",
      "inpartbytheHowardHughesMedicalInstituteandtheGatsbyCharitable\n",
      "Foundation.\n",
      "2References\n",
      "[1]P.Arbelaez.Boundaryextractioninnaturalimagesusingultrametriccon-\n",
      "tourmaps.Proc.POCV,2006.[2]F.BachandM.Jordan.Learningspec-\n",
      "tralclustering,withapplicationtospeechseparation.TheJournalofMachine\n",
      "LearningResearch,7:1963?2001,2006.[3]Y.Boykov,O.Veksler,andR.Zabih.\n",
      "Fastapproximateenergyminimizationviagraphcuts.PatternAnalysisand\n",
      "MachineIntelligence,IEEETransactionson,23(11):1222?1239,2001.[4]K.L.\n",
      "BriggmanandW.Denk.Towardsneuralcircuitreconstructionwithvolume\n",
      "electronmicroscopytechniques.CurrOpinNeurobiol,16(5):562?70,2006.[5]\n",
      "W.DenkandH.Horstmann.Serialblock-facescanningelectronmicroscopy\n",
      "toreconstructthree-dimensionaltissuenanostructure.PLoSBiol,2(11):e329,\n",
      "2004.[6]P.Doll?r,Z.Tu,andS.Belongie.Supervisedlearningofedgesandob-\n",
      "jectboundaries.InCVPR,June2006.[7]P.FelzenszwalbandD.Huttenlocher.\n",
      "tGraph-BasedImageSegmentation.InternationalJournalofComputer\n",
      "Vision,59(2):167?181,2004.[8]B.Fischer,V.Roth,andJ.Buhmann.Cluster-\n",
      "ingwiththeconnectivitykernel.InAdvancesinNeuralInformationProcessing\n",
      "Systems16:Proceedingsofthe2003Conference.BradfordBook,2004.[9]C.\n",
      "Fowlkes,D.Martin,andJ.Malik.Learningyfunctionsforimageseg-\n",
      "mentation:combiningpatch-basedandgradient-basedapproaches.Computer\n",
      "VisionandPatternRecognition,2003.Proceedings.2003IEEEComputerSo-\n",
      "cietyConferenceon,2,2003.8\n",
      "[10]X.He,R.Zemel,andM.Carreira-Perpinan.Multiscaleconditional\n",
      "randomforimagelabeling.InIEEEComputerSocietyConferenceon\n",
      "ComputerVisionandPatternRecognition,volume2.IEEEComputerSoci-\n",
      "ety;1999,2004.[11]V.Jain,J.Murray,F.Roth,S.Turaga,V.Zhigulin,K.\n",
      "Briggman,M.Helmstaedter,W.Denk,andH.Seung.Supervisedlearningof\n",
      "imagerestorationwithconvolutionalnetworks.ICCV2007,2007.[12]S.Ku-\n",
      "marandM.Hebert.Discriminativerandomadiscriminativeframework\n",
      "forcontextualinteractioninComputerVision,2003.Proceed-\n",
      "11\n",
      "\n",
      "ings.NinthIEEEInternationalConferenceon,pages1150?1157,2003.[13]\n",
      "Y.LeCun,L.Bottou,G.Orr,andK.M?ller.tbackprop.Lecture\n",
      "notesincomputerscience,pages9?50,1998.[14]M.Maire,P.Arbelaez,C.\n",
      "Fowlkes,andJ.Malik.Usingcontourstodetectandlocalizejunctionsinnatu-\n",
      "ralimages.InIEEEConferenceonComputerVisionandPatternRecognition,\n",
      "2008.CVPR2008,pages1?8,2008.[15]D.Martin,C.Fowlkes,D.Tal,and\n",
      "J.Malik.Adatabaseofhumansegmentednaturalimagesanditsapplication\n",
      "toevaluatingsegmentationalgorithmsandmeasuringecologicalstatistics.In\n",
      "Proc.EighthInt?lConf.ComputerVision,volume2,pages416?423,2001.[16]\n",
      "D.R.Martin,C.C.Fowlkes,andJ.Malik.Learningtodetectnaturalimage\n",
      "boundariesusinglocalbrightness,color,andtexturecues.IEEETransPattern\n",
      "AnalMachIntell,26(5):530?549,May2004.[17]M.MeilaandJ.Shi.Learning\n",
      "segmentationbyrandomwalks.ADVANCESINNEURALINFORMATION\n",
      "PROCESSINGSYSTEMS,pages873?879,2001.[18]W.Rand.Objective\n",
      "criteriafortheevaluationofclusteringmethods.JournaloftheAmericanSta-\n",
      "tisticalassociation,pages846?850,1971.[19]H.Seung.ReadingtheBookof\n",
      "Memory:SparseSamplingversusDenseMappingofConnectomes.Neuron,\n",
      "62(1):17?29,2009.[20]J.ShiandJ.Malik.Normalizedcutsandimageseg-\n",
      "mentation.IEEETransactionsonPatternAnalysisandMachineIntelligence,\n",
      "22(8):888?905,2000.[21]S.J.Smith.Circuitreconstructiontoolstoday.Curr\n",
      "OpinNeurobiol,17(5):601?608,Oct2007.[22]Z.Tu,X.Chen,A.Yuille,and\n",
      "S.Zhu.Imageparsing:Unifyingsegmentation,detection,andrecognition.In-\n",
      "ternationalJournalofComputerVision,63(2):113?140,2005.[23]R.Unnikr-\n",
      "ishnan,C.Pantofaru,andM.Hebert.Towardobjectiveevaluationofimage\n",
      "segmentationalgorithms.IEEETRANSACTIONSONPATTERNANALYSIS\n",
      "ANDMACHINEINTELLIGENCE,pages929?944,2007.\n",
      "9\n",
      "12\n",
      "\n",
      "PP3475.pdf\n",
      "PP3475.pdf 11\n",
      "OnlinePredictiononLargeDiameterGraphs\n",
      "Authoredby:\n",
      "MarkHerbster\n",
      "MassimilianoPontil\n",
      "GuyLever\n",
      "Abstract\n",
      "Currenton-linelearningalgorithmsforpredictingthelabellingofa\n",
      "graphhaveanimportantlimitationinthecaseoflargediametergraphs;\n",
      "thenumberofmistakesmadebysuchalgorithmsmaybeproportional\n",
      "tothesquarerootofthenumberofvertices,evenwhentacklingsimple\n",
      "problems.Weovercomethisproblemwithantalgorithmwhich\n",
      "achievesalogarithmicmistakebound.Furthermore,currentalgorithms\n",
      "areoptimisedfordatawhichexhibitscluster-structure;wegiveanad-\n",
      "ditionalalgorithmwhichperformswelllocallyinthepresenceofcluster\n",
      "structureandonlargediametergraphs.\n",
      "1PaperBody\n",
      "Wecontinueourstudyofonlinepredictionofthelabellingofagraph.We\n",
      "showafundamentallimitationofLaplacian-basedalgorithms:ifthegraphhas\n",
      "alargediameterthenthenumberofmistakesmadebysuchalgorithmsmaybe\n",
      "proportionaltothesquarerootofthenumberofvertices,evenwhentackling\n",
      "simpleproblems.Weovercomethisdrawbackbymeansofantalgorithm\n",
      "whichachievesalogarithmicmistakebound.Itisbasedonthenotionofa\n",
      "spine,apathgraphwhichprovidesalinearembeddingoftheoriginalgraph.In\n",
      "practice,graphsmayexhibitclusterstructure;thusinthelastpart,wepresent\n",
      "amoalgorithmwhichachievesthe?bestofbothworlds?:itperforms\n",
      "welllocallyinthepresenceofclusterstructure,andgloballyonlargediameter\n",
      "graphs.\n",
      "1\n",
      "Introduction\n",
      "Westudytheproblemofpredictingthelabellingofagraphintheonline\n",
      "learningframework.Considerthefollowinggameforpredictingthelabelling\n",
      "ofagraph:Naturepresentsagraph;naturequeriesavertexvi1;thelearner\n",
      "predictsy?1?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      ",thelabelofthevertex;naturepresentsalabely1;nature\n",
      "queriesavertexvi2;thelearnerpredictsy?2;andsoforth.Thelearner?sgoalis\n",
      "tominimisethetotalnumberofmistakesM=|\n",
      "f\n",
      "t:y?t6=yt\n",
      "g\n",
      "|.Ifnatureis\n",
      "1\n",
      "\n",
      "adversarial,thelearnerwillalwaysmispredict,butifnatureisregularorsimple,\n",
      "thereishopethatalearnermaymakeonlyafewmispredictions.Thus,acentral\n",
      "goalofonlinelearningistodesignalgorithmswhosetotalmispredictionscan\n",
      "beboundedrelativetothecomplexityofnature?slabelling.In[9,8,7],thecut\n",
      "size(thenumberofedgesbetweendisagreeinglabels)wasusedasameasureof\n",
      "thecomplexityofagraph?slabelling,andmistakeboundsrelativetothisand\n",
      "thegraphdiameterwerederived.Thestrengthofthemethodsin[8,7]isinthe\n",
      "casewhenthegraphexhibits?clusterstructure?.Theapparentof\n",
      "thesemethodsisthattheyhavepoorboundswhenthegraphdiameterislarge\n",
      "relativetothenumberofvertices.Weobservethatthisweaknessisnotdueto\n",
      "tlytightbounds,butisaproblemintheirperformance.Inparticular,\n",
      "wediscussanexampleofan-vertexlabelledgraphwithasingleedgebetween\n",
      "disagreeinglabelsets.Onthisgraph,sequentialpredictionusingthecommon\n",
      "methodbaseduponminimisingtheLaplaciansemi-normofalabelling,subject\n",
      "to?constraints,incurs?(n)mistakes(seeTheorem3).Theexpectationisthat\n",
      "thenumberofmistakesincurredbyanoptimalonlinealgorithmisboundedby\n",
      "O(lnn).Wesolvethisproblembyobservingthatthereexistsanapproximate\n",
      "structure-preservingembeddingofanygraphintoapathgraph.Inparticular\n",
      "thecut-sizeofanylabellingisincreasedbynomorethanafactoroftwo.Wecall\n",
      "thisembeddingaspineofthegraph.Thespineisthefoundationonwhichwe\n",
      "buildtwoalgorithms.Firstlywepredictdirectlyonthespinewiththe1-nearest-\n",
      "neighboralgorithm.WedemonstratethatthisequivalenttotheBayes-optimal\n",
      "foraparticularMarkovrandomAlogarithmicmistakeboundfor\n",
      "learningonapathgraphfollowsbytheHalvingalgorithmanalysis.Secondly,\n",
      "weusethespineofthegraphasafoundationtoaddabinarysupporttreeto\n",
      "theoriginalgraph.Thisenablesustoproveaboundwhichisthe?bestofboth\n",
      "worlds??ifthepredictedsetofverticeshascluster-structurewewillobtain\n",
      "aboundappropriateforthatcase,butifinstead,thepredictedsetexhibitsa\n",
      "largediameterwewillobtainapolylogarithmicbound.\n",
      "Previouswork.Theseminalapproachtosemi-supervisedlearningover\n",
      "graphsin[3]istopredictwithalabellingwhichisconsistentwithamini-\n",
      "mumlabel-separatingcut.Morerecently,thegraphLaplacianhasemergedas\n",
      "akeyobjectinsemi-supervisedlearning,forexamplethesemi-norminducedby\n",
      "theLaplacianiscommonlyeitherdirectlyminimisedsubjecttoconstraints,or\n",
      "usedasaregulariser[14,2].In[8,7]theonlinegraphlabellingproblemwas\n",
      "studied.Anaimofthosepaperswastoprovideanaturalinterpretationofthe\n",
      "boundonthecumulativemistakesofthekernelperceptronwhenthekernelis\n",
      "thepseudoinverseofthegraphLaplacian?boundsinthiscasebeingrelative\n",
      "tothecutand(resistance)diameterofthegraph.Inthispaperwenecessarily\n",
      "builddirectlyontheveryrecentresultsin[7]asthoseresultsdependonthe\n",
      "resistancediameterofthepredictedvertexsetasopposedtothewholegraph\n",
      "[8].Theonlinegraphlabellingproblemisalsostudiedin[13],andherethe\n",
      "graphstructureisnotgiveninitially.Aslightlyweakerlogarithmicboundfor\n",
      "theonlinegraphlabellingproblemhasalsobeenindependentlyderivedviaa\n",
      "connectiontoanonlineroutingproblemintheveryrecent[5].\n",
      "2\n",
      "2\n",
      "\n",
      "Preliminaries\n",
      "Westudytheprocessofpredictingalabellingontheverticesofa\n",
      "graph.Followingtheclassicalonlinelearningframework,asequenceoflabelled\n",
      "vertices\n",
      "f\n",
      "(vi1,y1),(vi2,y2),...\n",
      "g\n",
      ",thetrialsequence,ispresentedto\n",
      "alearningalgorithmsuchthat,onsightofeachvertexvit,thelearnermakes\n",
      "apredictiony?tforthelabelvalue,afterwhichthecorrectlabelisrevealed.\n",
      "Thisfeedbackinformationisthenusedbythelearningalgorithmtoimprove\n",
      "itsperformanceonfurtherexamples.Weanalysetheperformanceofalearn-\n",
      "ingalgorithminthemistakeboundframework[12]?theaimistominimise\n",
      "themaximumpossiblecumulativenumberofmistakesmadeonthetraining\n",
      "sequence.AgraphG=(V,E)isacollectionofverticesV=\n",
      "f\n",
      "v1,...,\n",
      "vn\n",
      "g\n",
      "joinedbyconnecting(possiblyweighted)edges.Denotei?jwhenevervi\n",
      "andvjareconnectedsothatE=\n",
      "f\n",
      "(i,j):i?j\n",
      "g\n",
      "isthesetofunorderedpairs\n",
      "ofconnectedvertexindices.Associatedwitheachedge(i,j)?Eisaweight\n",
      "Aij,sothatAisthen?nsymmetricadjacencymatrix.WesaythatGis\n",
      "unweightedifAij=1forevery(i,j)?Eandis0otherwise.Inthispaper,we\n",
      "consideronlyconnectedgraphs?thatis,graphssuchthatthereexistsapath\n",
      "betweenanytwovertices.TheLaplacianGofagraphPGisthen?nmatrix\n",
      "G=D?A,whereDisthediagonaldegreematrixsuchthatDii=jAij.The\n",
      "quadraticformassociatedwiththeLaplacianrelatestothecutsizeofgraph\n",
      "labellings.1.Givenalabellingu?IRnofG=(V,E)wethe\n",
      "cutsizeofuby1T1X?G(u)=uGu=Aij(ui?uj)2.(1)44(i,j)?E\n",
      "n\n",
      "Inparticular,ifu?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "wesaythatacutoccursonedge(i,j)ifui6=\n",
      "ujand?G(u)measuresthenumberofcuts.Weevaluatetheperformanceof\n",
      "predictionalgorithmsintermsofthecutsizeandtheresistancediameterofthe\n",
      "graph.Thereisanestablishednaturalconnectionbetweengraphsandresistive\n",
      "networkswhereeachedge(i,j)?Eisviewedasaresistorwithresistance1/Aij\n",
      "[4].ThustheeresistancerG(vi,vj)betweenvertexviandvjisthe\n",
      "potentialdrenceneededtoinduceaunitcurrentwbetweenviandvj.\n",
      "Theeresistancemaybecomputedbytheformula[11]rG(vi,vj)=(ei\n",
      "?ej)TG+(ei?ej),(2)+nwhere??denotesthepseudoinverseande1,..\n",
      ".,enarethecanonicalbasisvectorsofIR.Theresistancediameterofagraph\n",
      "RG:=maxvi,vj?VrG(vi,vj)isthemaximumtiveresistancebetween\n",
      "anypairofverticesonthegraph.\n",
      "3\n",
      "Limitationsofonlineminimumsemi-norminterpolation\n",
      "Aswewillshow,itispossibletodeveloponlinealgorithmsforpredictingthe\n",
      "labellingofagraphwhichhaveamistakeboundthatisalogarithmicfunctionof\n",
      "thenumberofvertices.Conversely,wehighlightainastandard\n",
      "Laplacianbasedmethodforpredictingagraphlabelling.Givenapartially\n",
      "labelledgraphG=(V,E)with|V|=n?thatis,suchthatforsome`?n,\n",
      "y`?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "`isalabellingonthe`verticesV`=\n",
      "f\n",
      "vi1,vi2,...,vi`\n",
      "g\n",
      "?theminimumsemi-norminterpolantisbyy?=argmin\n",
      "f\n",
      "uTGu:u?\n",
      "IRn,uik=yk,k=1,...,`\n",
      "g\n",
      ".\n",
      "Wethenpredictusingy?i=sgn(?yi),fori=1,...,n.Thecommon\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behindtheabovelearningparadigm[14,2]isthatminimizingthe\n",
      "cut(1)encouragesneighbouringverticestobesimilarlylabelled.However,we\n",
      "nowdemonstratethatintheonlinesettingsucharegimewillperformpoorly\n",
      "on?certaingraphconstructions?thereexistsatrialsequenceonwhichthe\n",
      "methodwillmakeatleast?(n)mistakes.2.Anoctopusgraphof\n",
      "sizedistobedpathgraphs(thetentacles)oflengthd(thatis,with\n",
      "d+1vertices)alladjoinedatacommonendvertex,towhichafurthersingle\n",
      "headvertexisattached,sothatn=|V|=d2+2.Thiscorrespondsto\n",
      "thegraphO1,d,ddiscussedin[8].Theorem3.LetG=(V,E)beanoctopus\n",
      "graphofsizedandy=(y1,...,y|V|)thelabellingsuchthatyi=1\n",
      "ifviistheheadvertexandyi=?1otherwise.Thereexistsatrialsequencefor\n",
      "pwhichonlineminimumsemi-norminterpolationmakes?(|V|)mistakes.\n",
      "Proof.Letthequeryvertexbetheheadvertex,andlettheendvertexofa\n",
      "tentaclebequeriedateachsubsequenttrial.Weshowthatthisstrategyforces\n",
      "atleastdmistakes.Thesolutiontotheminimumsemi-norminterpolationwith\n",
      "boundaryPnvaluesproblemispreciselytheharmonicsolution[4]y?(that\n",
      "is,foreveryunlabeledvertexvj,i=1Aij(?yi?y?j)=0).Ifthegraph\n",
      "isconnectedy?isuniqueandthegraphlabellingproblemisidenticaltothat\n",
      "ofidentifyingthepotentialateachvertexofaresistivenetworkonthe\n",
      "graphwhereeachedgecorrespondstoaresistorof1unit;theharmonicprinciple\n",
      "correspondstoKirc?scurrentlawinthiscase.Usingthisanalogy,suppose\n",
      "thattheendpointsofk<dtentaclesarelabelledandthattheendvertexvqof\n",
      "anunlabelledtentacleisqueried.Supposeacurrentofk?wsfromthehead\n",
      "tothebodyofthegraph.ByKirc?slaw,acurrentof?wsalongeach\n",
      "labelledtentacle(inordertoobeytheharmonicprincipleat2everyvertexit\n",
      "isclearthatnocurrentwsalongtheunlabelledtentacles).ByOhm?slaw?\n",
      "=d+k.Minimumsemi-norminterpolationthereforeresultsinthesolution2k\n",
      "y?q=1??0k?d.d+kHencetheminimumsemi-normsolutionpredicts\n",
      "incorrectlywheneverk<dandthealgorithmmakesatleastdmistakes.The\n",
      "abovedemonstratesalimitationinthemethodofonlineLaplacianminimum\n",
      "semi-norminterpolationforpredictingagraphlabelling?themistakebound\n",
      "canbeproportionaltothesquarerootofthenumberofdatapoints.Wesolve\n",
      "theseproblemsinthefollowingsection.\n",
      "4\n",
      "Alineargraphembedding\n",
      "Wedemonstrateamethodofembeddingdatarepresentedasaconnected\n",
      "graphGintoapathgraph,wecallitaspineofG,whichpartiallypreserves\n",
      "thestructureofG.LetPnbethesetofpathgraphswithnvertices.Wewould\n",
      "liketoapathgraphwiththesamevertexsetasG,whichsolves?P(u).\n",
      "minmaxP?Pnu?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "n?G(u)IfaHamiltonianpathHofG(apathonG\n",
      "whichvisitseachvertexpreciselyonce)exists,then(u)theapproximationratio\n",
      "is??H?1.TheproblemofdingaHamiltonianpathisNP-completeG(u)\n",
      "however,andsuchapathisnotguaranteedtoexist.Asweshallsee,aspineS\n",
      "ofGmaybefoundS(u)tlyand??G(u)?2.Wenowdetail\n",
      "theconstructionofaspineofagraphG=(V,E),with|V|=n.Starting\n",
      "fromanynode,Gistraversedinthemannerofasearch(thatis,each\n",
      "4\n",
      "\n",
      "vertexisfullyexploredbeforebacktrackingtothelastunexploredvertex),and\n",
      "anorderedlistVL=\n",
      "f\n",
      "vl1,vl2,...,vl2m+1\n",
      "g\n",
      "ofthevertices(m?|E|)in\n",
      "theorderthattheyarevisitedisformed,allowingrepetitionswhenavertexis\n",
      "visitedmorethanonce.NotethateachedgeinEGistraversednomorethan\n",
      "twicewhenformingVL.anedgemultisetEL=\n",
      "f\n",
      "(l1,l2),(l2,l3),..\n",
      ".,(l2m,l2m+1)\n",
      "g\n",
      "?thesetofpairsofconsecutiveverticesinVL.Letube\n",
      "anParbitrarylabellingofGanddenote,asusual,P?G(u)=41(i,j)?EG(ui\n",
      "?uj)2and?L(u)=14(i,j)?EL(ui?uj)2.SincethemultisetELcontains\n",
      "everyelementofEGnomorethantwice,?L(u)?2?G(u).Wethentakeany\n",
      "subsequenceVL0ofVLcontainingeveryvertexinVexactlyonce.AspineS\n",
      "=(V,ES)isagraphformedbyconnectingeachvertexinVtoitsimmediate\n",
      "neighboursin\n",
      "thesubsequenceVL0withanedge.Sinceacutoccursbetweenconnected\n",
      "verticesviandvjinSonlyifacutoccursonsomeedgeinELlocatedbetween\n",
      "thecorrespondingverticesinthelistVLwehave?S(u)??L(u)?2?G(u).\n",
      "(3)\n",
      "Thuswehavereducedtheproblemoflearningthecutonagenericgraphto\n",
      "thatoflearningthecutonapathgraph.Inthefollowingweseethat1-nearest\n",
      "neighbour(1-NN)algorithmisaBayesoptimalalgorithmforthisproblem.\n",
      "Notethatthe1-NNalgorithmdoesnotperformwell?ongeneralgraphs;on\n",
      "theoctopusgraphdiscussedabove,forexample,itcanmakeatleast?(n)\n",
      "mistakes,andeven?(n)mistakesonarelatedgraphconstruction[8].\n",
      "5\n",
      "Predictingwithaspine\n",
      "Weconsiderimplementingthe1-NNalgorithmonapathgraphanddemon-\n",
      "stratethatitachievesamistakeboundwhichislogarithmicinthelengthofthe\n",
      "line.LetG=(V,E)beapathgraph,whereV=\n",
      "f\n",
      "v1,v2,...,vn\n",
      "g\n",
      "isthe\n",
      "setofverticesandE=\n",
      "f\n",
      "(1,2),(2,3),...,(n?1,n)\n",
      "g\n",
      ".Thenearestneighbour\n",
      "algorithm,inthestandardonlinelearningframeworkdescribedabove,attempts\n",
      "topredictagraphlabellingbyproducing,foreachqueryvertexvit,thepre-\n",
      "dictiony?twhichisconsistentwiththelabeloftheclosestlabelledvertex(and\n",
      "predictsrandomlyinthecaseofatie).Theorem4.Giventhetaskofpredicting\n",
      "thelabellingofanyunweighted,n-vertexpathgraphPintheonlineframework,\n",
      "thenumberofmistakes,M,incurredbythe1-NNalgorithm\n",
      "n?1?P(u)M??P(u)log2++1,(4)?P(u)ln2whereu?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "n\n",
      "isanylabellingconsistentwiththetrialsequence.Proof.Weshallprovethe\n",
      "resultbynotingthattheHalvingalgorithm[1](undercertainconditionsonthe\n",
      "probabilitiesassignedtoeachhypothesis)implementsthenearestneighbour\n",
      "algorithmonapathgraph.GivenanyinputspaceXandbinaryconcept\n",
      "classC?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "|X|,theHalvingalgorithmlearnsanytargetconceptc??\n",
      "Casfollows.Eachhypothesisc?Cisgivenanassociatedprobabilityp(c).A\n",
      "sequenceoflabelledexamples\n",
      "f\n",
      "(x1,y1),...,(xt?1,yt?1)\n",
      "g\n",
      "?X?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      ",\n",
      "isrevealedinaccordancewiththeusualonlineframework.LetFtbethesetof\n",
      "feasiblehypothesesattrialt;Ft=\n",
      "f\n",
      "c:c(xs)=ys?s<t\n",
      "g\n",
      ".Givenanunlabelled\n",
      "examplextP?Xattrialtthepredictedlabely?tisthatwhichagreeswiththe\n",
      "majorityvote?thatis,suchthatitpredictsrandomlyifthisisequaltomost\n",
      "5\n",
      "\n",
      "MHmistakeswith\n",
      "12).\n",
      "c?Ft,c(xt)=y?t\n",
      "P\n",
      "c?Ft\n",
      "p(c)\n",
      "p(c)\n",
      ">\n",
      "12\n",
      "(and\n",
      "Itiswellknown[1]thattheHalvingalgorithmmakesat\n",
      "MH?log2\n",
      "1p(c?)\n",
      ".\n",
      "(5)\n",
      "Wenowaprobabilitydistributionoverthespaceofalllabellings\n",
      "u?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "nofPsuchthattheHalvingalgorithmwiththeseprobabilities\n",
      "implementsthenearestneighbouralgorithm.Letacutoccuronanygivenedge\n",
      "withprobability?,independentlyofallothercuts;Prob(ui+16=ui)=??i\n",
      "<n.Thepositionofallcutsthelabellinguptoeverylabel,and\n",
      "eachofthesetworesultingpossiblearrangementsareequallylikely.Thisrecipe\n",
      "associateswitheachpossiblelabellingu?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "naprobabilityp(u)whichis\n",
      "afunctionofthelabelling?scutsize1?P(u)?(1??)n?1??P(u).(6)2This\n",
      "inducesafulljointprobabilitydistributiononthespaceofvertexlabels.In\n",
      "fact(6)isaGibbsmeasureandassuchaMarkovrandomoverthe\n",
      "spaceofvertexlabels[10].ThemassfunctionpthereforetheMarkov\n",
      "propertyp(u)=\n",
      "p(ui=?|uj=?j?j6=i)=p(ui=?|uj=?j?j?Ni),\n",
      "(7)\n",
      "wherehereNiisthesetofverticesneighbouringvi?thoseconnectedtovi\n",
      "byanedge.WewillgiveanequivalentMarkovpropertywhichallowsamore\n",
      "generalconditioningtoreducetothatoverboundaryvertices.\n",
      "5.GivenapathgraphP=(V,E),asetofverticesV0?Vand\n",
      "avertexvi?V,wetheboundaryverticesv`,vr(eitherofwhichmaybe\n",
      "vacuous)tobethetwoverticesinV0thatareclosesttoviineachdirectionalong\n",
      "thepath;itsnearestneighboursineachdirection.Thedistributioninducedby\n",
      "(6)thefollowingMarkovproperty;givenapartiallabellingofP\n",
      "onasubsetV0?V,thelabelofanyvertexviisindependentofalllabelson\n",
      "V0exceptthoseontheverticesv`,vr(eitherofwhichcouldbevacuous)p(ui\n",
      "=?|uj=?j,?j:vj?V0)\n",
      "=p(ui=?|u`=>,ur=?r).\n",
      "(8)\n",
      "Giventheconstructionoftheprobabilitydistributionformedbyindependent\n",
      "cutsongraphedges,wecanevaluateconditionalprobabilities.Forexample,p(uj\n",
      "=?|uk=?)istheprobabilityofanevennumberofcutsbetweenvertexvj\n",
      "andvertexvk.Sincecutsoccurwithprobability?andthere\n",
      "6\n",
      "\n",
      "are|k?j|possiblearrangementsofscutswehaves\n",
      "p(uj=?|uk=?)=\n",
      "X|k?j|1?s(1??)|k?j|?s=(1+(1?2?)|k?j|).s2seven\n",
      "(9)\n",
      "X|k?j|1?s(1??)|k?j|?s=(1?(1?2?)|k?j|).s2\n",
      "(10)\n",
      "Likewisewehavethatp(uj6=?|uk=?)=\n",
      "sodd\n",
      "Notealsothatforanysinglevertexwehavep(ui=?)=12for??\n",
      "f\n",
      "?1,1\n",
      "g\n",
      ".\n",
      "Lemma6.Giventhetaskofpredictingthelabellingofann-vertexpathgraph\n",
      "online,theHalvingalgorithm,withaprobabilitydistributionoverthelabellings\n",
      "asin(6)andsuchthat0<?<12,implementsthenearestneighbour\n",
      "algorithm.Proof.Supposethatt?1trialshavebeenperformedsothatwe\n",
      "haveapartiallabellingofasubsetV0?V,\n",
      "f\n",
      "(vi1,y1),(vi2,y2),...,\n",
      "(vit?1,yt?1)\n",
      "g\n",
      ".SupposethelabelofvertexvitisqueriedsothattheHalving\n",
      "algorithmmakesthefollowingpredictiony?tforvertexvit:y?t=yifp(uit=\n",
      "y|uij=yj?1?j<t)>21,y?t=?yifp(uit=y|uij=yj?1?j<t)<\n",
      "21(andpredictsrandomlyifthisprobabilityisequalto12).Weconsider\n",
      "thecasewheretheconditionallabellingincludesverticesonbothsidesofvit.\n",
      "Wehave,by(8),thatp(uit=y|uij=yj?1?j<t)\n",
      "=p(uit=y|u`=y?(`),ur=y?(r))=\n",
      "p(u`=y?(`)|ur=y?(r),uit=y)p(ur=y?(r),uit=y)p(u`=y?(`)\n",
      ",ur=y?(r))\n",
      "=\n",
      "p(u`=y?(`)|uit=y)p(ur=y?(r)|uit=y)p(u`=y?(`)|ur=y?\n",
      "(r))\n",
      "(11)\n",
      "wherev`andvraretheboundaryverticesand?(`)and?(r)aretrialsat\n",
      "whichverticesv`andvrarequeried,respectively.Wecanevaluatetheright\n",
      "handsideofthisexpressionusing(9,10).Toshowequivalencewiththenearest\n",
      "neighbourmethodwhenever?<12,wehavefrom(9,10,11)p(uit=y|u`=\n",
      "y,ur6=y)\n",
      "=\n",
      "(1+(1?2?)|`?it|)(1?(1?2?)|r?it|)2(1?(1?2?)|`?r|)\n",
      "whichisgreaterthan12if|`?it|<|r?it|andlessthan21if|`?\n",
      "it|>|r?it|.Hence,thisproducespredictionsexactlyinaccordancewith\n",
      "thenearestneighbourscheme.Wealsohavemoresimplythatforallit,`and\n",
      "rand?<12p(uit=y|u`=y,ur=y)>\n",
      "11,andp(uit=y|u`=y)>.22\n",
      "Thisprovesthelemmaforallcases.AdirectapplicationoftheHalving\n",
      "algorithmmistakebound(5)nowgives\n",
      "12M?log2=log2p(u)??P(u)(1??)n?1??P(u)\n",
      "P(u)1whereuisanylabellingconsistentwiththetrialsequence.Wechoose\n",
      "?=min(?n?1,2)(noteP(u)thattheboundisvacuouswhen?n?1>12since\n",
      "Misnecessarilyupperboundedbyn)giving\n",
      "7\n",
      "\n",
      "?P(u)n?1+(n?1??P(u))log21++1M??P(u)log2?P(u)n?1?\n",
      "?P(u)\n",
      "n?1?P(u)??P(u)log2++1.?P(u)ln2\n",
      "Thisprovesthetheorem.Thenearestneighbouralgorithmcanpredictthe\n",
      "labellingofanygraphG=(V,E),bytransferringthedatarepresentation\n",
      "tothatofaspineSofG,aspresentedinSection4.Wenowapplytheabove\n",
      "argumenttothismethodandimmediatelydeduceourmainresult.Theo-\n",
      "rem7.Giventhetaskofpredictingthelabellingofanyunweighted,connected,\n",
      "n-vertexgraphG=(V,E)intheonlineframework,thenumberofmistakes,\n",
      "M,incurredbythenearestneighbouralgorithmoperatingonaspineSofG\n",
      "\n",
      "n?12?G(u)M?2?G(u)max0,log2+1,(12)+2?G(u)ln2whereu?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "nisanylabellingconsistentwiththetrialsequence.Proof.Theorem4\n",
      "givesbound(4)forpredictingonanypath,henceM??S(u)log2?S(u)ln2\n",
      "+1.Sincethisisanincreasingfunctionof?S(u)for?S(u)?n?S(u)?n?1\n",
      "(Misnecessarilyupperboundedbyn)weupperbound\n",
      "n?1?S(u)\n",
      "+\n",
      "?1andisvacuousatsubstituting?S(u)?\n",
      "2?G(u)(equation(3)).Weobservethatpredictingwiththespineisa\n",
      "minimaximprovementoverLaplacianminimalseminorminterpolation.Recall\n",
      "Theorem3,thereweshowed?thatthereexistsatrialsequencesuchthat\n",
      "Laplacianpminimalsemi-norminterpolationincurs?(n)mistakes.Infact\n",
      "thistriviallygeneralizesto?(?G(u)n)mistakesbycreatingacolonyof?G(u)\n",
      "octopithenidentifyingeachpreviouslyseparateheadvertexasasinglecentral\n",
      "vertex.Theupperbound(12)issmallerthanthepriorlowerbound.The\n",
      "computationalcomplexityforthisalgorithmisO(|E|+|V|ln|V|)\n",
      "time.WecomputethespineinO(|E|)timebysimplylistingverticesinthe\n",
      "orderinwhichtheyarevisitedduringasearchtraversalofG.\n",
      "Usingonline1-NNrequiresO(|V|ln|V|)timetopredictanarbitrary\n",
      "vertexsequenceusingaself-balancingbinarysearchtree(e.g.,ared-blacktree)\n",
      "astheinsertionofeachvertexintothetreeanddeterminationofthenearest\n",
      "leftandrightneighbourisO(ln|V|).\n",
      "6\n",
      "Predictionwithabinarysupporttree\n",
      "ThePounceonlinelabelpredictionalgorithm[7]isdesignedtoexploitcluster\n",
      "structureofagraphG=(V,E)andachievesthefollowingmistakeboundM?\n",
      "N(X,?,rG)+4?G(u)?+1,\n",
      "(13)\n",
      "forany?>0.Here,u?IRnisanylabellingconsistentwiththetrial\n",
      "sequence,X=\n",
      "f\n",
      "vi1,vi2,...\n",
      "g\n",
      "?VisthesetofinputsandN(X,?,rG)\n",
      "isacoveringnumber?theminimumnumberofballsofresistancediameter?\n",
      "(seeSection2)requiredtocoverX.Themistakebound(13)canbepreferable\n",
      "to(12)whenevertheinputsarentlyclusteredandsohasacoverofsmall\n",
      "diametersets.Forexample,considertwo(m+1)-cliques,onelabeled?+1?,\n",
      "one??1?withcmarbitraryinterconnectingedges(c?1)herethebound(12)\n",
      "8\n",
      "\n",
      "isvacuouswhile(13)isM?8c+32(with?=m,N(X,?,rG)=2,and\n",
      "?G(u)=cm).AninputspaceVmayhavebothlocalclusterstructureyet\n",
      "havealargediameter.Imaginea?universe?suchthatpointsaredistributed\n",
      "intomanydenseclusterssuchthatsomesetsofclustersaretightlypackedbut\n",
      "overallthedistributionisquiteAgiven?problem?X?Vmaythenbe\n",
      "centeredonafewclustersoralternativelyencompasstheentirespace.Thus,\n",
      "forpracticalpurposes,wewouldlikeapredictionalgorithm\n",
      "whichachievesthe?bestofbothworlds?,thatisamistakeboundwhichis\n",
      "nogreater,inorderofmagnitude,thanthemaximumof(12)and(13).The\n",
      "restofthispaperisdirectedtowardthisgoal.Wenowintroducethenotionof\n",
      "binarysupporttree,formalisethePouncemethodinthesupporttreesetting\n",
      "andthenprovethedesiredresult.8.GivenagraphG=(V,E),\n",
      "with|V|=n,andspineS,weabinarysupporttreeofGtobeany\n",
      "binarytreeT=(VT,ET)ofleastpossibledepth,D,whoseleavesarethe\n",
      "verticesofS,inorder.NotethatD<log2(n)+1.Weshowthatthereisa\n",
      "weightingofthesupporttreewhichensuresthattheresistancediameterofthe\n",
      "supporttreeissmall,butalsosuchthatanylabellingoftheleafverticescanbe\n",
      "extendedtothesupporttreesuchthatitscutsizeremainssmall.Thisenables\n",
      "elearningviathesupporttree.Arelatedconstructionhasbeenusedto\n",
      "buildpreconditionersforsolvinglinearsystems[6].Lemma9.Givenanyspine\n",
      "graphS=(V,E)with|V|=n,andlabellingu?\n",
      "f\n",
      "?1,1\n",
      "g\n",
      "n,with??[?1,\n",
      "1]|VT|supporttreeT=(VT,ET),thereexistsaweightingAofT,and\n",
      "alabellingu?anduareidenticalonV,?T(u)?<?S(u)andRT?(log2n\n",
      "+1)(log2n+ofTsuchthatu4)(log2(log2n+2))2.Proof.Letvrbethe\n",
      "rootvertexofT.Supposeeachedge(i,j)?EThasaweightAij,whichisa\n",
      "functionoftheedge?sdepthd=max\n",
      "f\n",
      "dT(vi,vr),dT(vj,vr)\n",
      "g\n",
      ",Aij=W\n",
      "(d)wheredT(v,v0)?suchisthenumberofedgesintheshortestpathfrom\n",
      "vtov0.Considertheuniquelabellinguthat,for1?i?nwehaveu?i=ui\n",
      "andsuchthatforeveryothervertexvp?VT,withchildu?+?uverticesvc1\n",
      ",vc2,wehaveu?p=c12c2,oru?p=u?cinthecasewherevphasonly\n",
      "onechild,vc.Supposetheedges(p,c1),(p,c2)?ETareatsomedepthd\n",
      "inT,andletV0?VcorrespondtotheleafverticesofTdescendedfromvp.\n",
      "?S(uV0)tobethecutofurestrictedtoverticesinV0.Ifu?c1=\n",
      "u?c2then(?up?u?c1)2+(?up?u?c2)2=0?2?S(uV0),andifu?c1\n",
      "6=u?c2then22(?up?u?c1)+(?up?u?c2)?2?2?S(uV0).Hence\n",
      "W(d)(?up?u?c1)2+(?up?u?c2)2?2W(d)?S(uV0)(14)(a\n",
      "similarinequalityistrivialinthecasethatvphasonlyonechild).Sincethesets\n",
      "ofleafdescendantsofallverticesatdepthdformapartitionofV,summing\n",
      "(14)overallparentnodesatagivendepthandthenoverallintegersd?\n",
      "[1,D]gives??24?T(u)\n",
      "DX\n",
      "W(d)?S(u).\n",
      "d=1\n",
      "(15)Wethenchoose1(d+1)(log2(d+1))2R??21+ln222xln12x\n",
      "dx=\n",
      "W(d)=andnotethat\n",
      "9\n",
      "\n",
      "P?\n",
      "1d=1(d+1)(log2(d+1))2\n",
      "(16)12\n",
      "+ln2<2.\n",
      "PDFurther,RT=2d=1(d+1)(log2(d+1))2?D(D+3)(log2(D+\n",
      "1))2andsoD?log2n+1givestheresistancebound.10.Given\n",
      "thetaskofpredictingthelabellingofanunweightedgraphG=(V,E)the?is\n",
      "formedaugmentedPouncealgorithmproceedsasfollows:Anaugmentedgraph\n",
      "G?=(V?,E)byattachingabinarysupporttreeofG,withweightsas\n",
      "in(16),toG;formallyletT=(VT,ET)besuchabinarysupporttreeofG,\n",
      "thenG?=(VT,E?ET).ThePouncealgorithmis?thenusedtopredictthe\n",
      "(partial)labellingonG.Theorem11.Giventhetaskofpredictingthe\n",
      "labellingofanyunweighted,connected,n-vertexgraphG=(V,E)intheonline\n",
      "framework,thenumberofmistakes,M,incurredbytheaugmentedPounce\n",
      "algorithmM?min\n",
      "f\n",
      "N(X,?,rG)+12?G(u)?\n",
      "g\n",
      "+1,(17)?>0\n",
      "whereN(X,?,rG)isthecoveringnumberoftheinputsetX=\n",
      "f\n",
      "vi1,vi2\n",
      ",...\n",
      "g\n",
      "?VrelativetotheresistancedistancerGofGandu?IRnisany\n",
      "labellingconsistentwiththetrialsequence.Furthermore,M?12?G(u)(log2n\n",
      "+1)(log2n+4)(log2(log2n+2))2+2.(18)\n",
      "Proof.Letubesomelabellingconsistentwiththetrialsequence.By(3)we\n",
      "havethat?S(u)?2?G(u)foranyspineSofG.Moreover,bythearguments\n",
      "inLemma9thereexistssomelabelling?oftheweightedsupporttreeTofG,\n",
      "consistentwithuonV,suchthat?T(u)?<?S(u).Wethenuhave?=?T\n",
      "(u)?+?G(u)<3?G(u).?G?(u)\n",
      "(19)\n",
      "ByRayleigh?smonotonicitylawtheadditionofthesupporttreedoesnot\n",
      "increasetheresistancebetweenanyverticesonG,henceN(X,?,rG?)?N(X,\n",
      "?,rG).\n",
      "(20)\n",
      "?yields?onG,Combininginequalities(19)and(20)withthepounce\n",
      "bound(13)forpredictingu?+1?N(X,?,rG)+12?G(u)?+1.M?\n",
      "N(X,?,rG?)+4?G?(u)??G?+2?whichproves(17).Weprove(18)by\n",
      "coveringG?withsingleballsothatM?4?G?(u)R12?G(u)RT+2andthe\n",
      "resultfollowsfromtheboundonRTinLemma9.\n",
      "7\n",
      "Conclusion\n",
      "Wehaveexploredawithexistingonlinetechniquesforpredicting\n",
      "thelabellingofagraph.Asasolution,wehavepresentedanapproximate\n",
      "cut-preservingembeddingofanygraphG=(V,E)intoasimplepathgraph,\n",
      "whichwecallaspine,suchthatanimplementationofthe1nearest-neighbours\n",
      "algorithmisantrealisationofaBayesoptimalThistherefore\n",
      "achievesamistakeboundwhichislogarithmicinthesizeofthevertexset\n",
      "foranygraph,andthecomplexityofouralgorithmisofO(|E|+|V|\n",
      "ln|V|).Wefurtherappliedtheinsightsgainedtoasecondalgorithm?\n",
      "anaugmentationofthePouncealgorithm,whichachievesapolylogarithmic\n",
      "10\n",
      "\n",
      "performanceguarantee,butcanfurthertakeadvantageofclustereddata,in\n",
      "whichcaseitsboundisrelativetoanycoverofthegraph.\n",
      "2References\n",
      "[1]J.M.BarzdinandR.V.Frievald.Onthepredictionofgeneralrecursive\n",
      "functions.SovietMath.Doklady,13:1224?1228,1972.[2]M.BelkinandP.\n",
      "Niyogi.Semi-supervisedlearningonriemannianmanifolds.MachineLearning,\n",
      "56:209?239,2004.[3]A.BlumandS.Chawla.Learningfromlabeledand\n",
      "unlabeleddatausinggraphmincuts.InProc.18thInternationalConf.on\n",
      "MachineLearning,pages19?26.MorganKaufmann,SanFrancisco,CA,2001.\n",
      "[4]P.DoyleandJ.Snell.Randomwalksandelectricnetworks.Mathematical\n",
      "AssociationofAmerica,1984.[5]J.FakcharoenpholandB.Kijsirikul.Low\n",
      "congestiononlineroutingandanimprovedmistakeboundforonlineprediction\n",
      "ofgraphlabeling.CoRR,abs/0809.2075,2008.[6]K.Gremban,G.Miller,and\n",
      "M.Zagha.Performanceevaluationofanewparallelpreconditioner.Parallel\n",
      "ProcessingSymposium,International,0:65,1995.[7]M.Herbster.Exploiting\n",
      "cluster-structuretopredictthelabelingofagraph.InThe19thInternational\n",
      "ConferenceonAlgorithmicLearningTheory,pages54?69,2008.[8]M.Herb-\n",
      "sterandM.Pontil.Predictiononagraphwithaperceptron.InB.Sch?olkopf,\n",
      "J.Platt,andT.editors,AdvancesinNeuralInformationProcessing\n",
      "Systems19,pages577?584.MITPress,Cambridge,MA,2007.[9]M.Herb-\n",
      "ster,M.Pontil,andL.Wainer.Onlinelearningovergraphs.InICML?05:\n",
      "Proceedingsofthe22ndinternationalconferenceonMachinelearning,pages\n",
      "305?312,NewYork,NY,USA,2005.ACM.[10]R.KindermanandJ.L.Snell.\n",
      "MarkovRandomFieldsandTheirApplications.Amer.Math.Soc.,Provi-\n",
      "dence,RI,1980.[11]D.KleinandM.Randi?c.Resistancedistance.Journal\n",
      "ofMathematicalChemistry,12(1):81?95,1993.[12]N.Littlestone.Learning\n",
      "whenirrelevantattributesabound:Anewlinear-thresholdalgorithm.Machine\n",
      "Learning,2:285?318,1988.[13]K.PelckmansandJ.A.Suykens.Anonline\n",
      "algorithmforlearningalabelingofagraph.InInProceedingsofthe6thIn-\n",
      "ternationalWorkshoponMiningandLearningwithGraphs,2008.[14]X.Zhu,\n",
      "Z.Ghahramani,andJ.y.Semi-supervisedlearningusinggaussian\n",
      "andharmonicfunctions.In20-thInternationalConferenceonMachineLearning\n",
      "(ICML-2003),pages912?919,2003.\n",
      "11\n",
      "\n",
      "PP4318.pdf\n",
      "PP4318.pdf 10\n",
      "WhyTheBrainSeparatesFaceRecognitionFrom\n",
      "ObjectRecognition\n",
      "Authoredby:\n",
      "TomasoPoggio\n",
      "JoelZ.Leibo\n",
      "JimMutch\n",
      "Abstract\n",
      "Manystudieshaveuncoveredevidencethatvisualcortexcontainsspe-\n",
      "cializedregionsinvolvedinprocessingfacesbutnototherobjectclasses.\n",
      "Recentelectrophysiologystudiesofcellsinseveralofthesespecialized\n",
      "regionsrevealedthatatleastsomeoftheseregionsareorganizedinahi-\n",
      "erarchicalmannerwithviewpoint-spccellsprojectingtodownstream\n",
      "viewpoint-invariantidentity-spcells(FreiwaldandTsao2010).A\n",
      "separatecomputationallineofreasoningleadstotheclaimthatsome\n",
      "transformationsofvisualinputsthatpreserveviewedobjectidentityare\n",
      "class-spInparticular,the2Dimagesevokedbyafaceundergoinga\n",
      "3Drotationarenotproducedbythesameimagetransformation(2D)that\n",
      "wouldproducetheimagesevokedbyanobjectofanotherclassundergoing\n",
      "thesame3Drotation.However,withintheclassoffaces,knowledgeofthe\n",
      "imagetransformationevokedby3Drotationcanbereliablytransferred\n",
      "frompreviouslyviewedfacestohelpidentifyanovelfaceatanewview-\n",
      "point.Weshow,throughcomputationalsimulations,thatanarchitecture\n",
      "whichappliesthismethodofgaininginvariancetoclass-sptransfor-\n",
      "mationsisewhenrestrictedtofacesandfailsspectacularlywhen\n",
      "appliedacrossobjectclasses.Weargueherethatinordertoaccomplish\n",
      "viewpoint-invariantfaceidenfromasingleexampleview,visual\n",
      "cortexmustseparatethecircuitryinvolvedindiscounting3Drotationsof\n",
      "facesfromthegenericcircuitryinvolvedinprocessingotherobjects.The\n",
      "resultingmodeloftheventralstreamofvisualcortexisconsistentwith\n",
      "therecentphysiologyresultsshowingthehierarchicalorganizationofthe\n",
      "faceprocessingnetwork.\n",
      "1PaperBody\n",
      "Thereisincreasingevidencethatvisualcortexcontainsdiscretepatchesin-\n",
      "volvedinprocessingfacesbutnototherobjects[2,3,4,5,6,7].Though\n",
      "progresshasbeenmaderecentlyincharacterizingthepropertiesofthesebrain\n",
      "1\n",
      "\n",
      "areas,thecomputational-levelreasonthebrainadoptsthismodulararchitecture\n",
      "hasremainedunknown.Inthispaper,weproposeanewcomputational-level\n",
      "explanationforwhyvisualcortexseparatesfaceprocessingfromobjectprocess-\n",
      "ing.Ourargumentdoesnotrequireustoclaimthatfacesareautomatically\n",
      "processedinwaysthatareinapplicabletoobjects(e.g.gazedetection,gender\n",
      "detection)orthatcorticalspecializationforfacesarisesduetoperceptualex-\n",
      "pertise[8],thoughtheperspectivethatemergesfromourmodelisconsistent\n",
      "withbothoftheseclaims.Weshowthatthetaskofidentifyingindividualfaces\n",
      "inanoptimallyviewpointinvariantwayfromsingletrainingexamplesrequires\n",
      "aseparateneuralcircuitryspecializedforfaces.Thecruxofthisiden\n",
      "probleminvolvesdiscountingtransformationsofthetargetindividual?sappear-\n",
      "ance.Generictransformationse.g,translation,scalingand2Din-planerotation\n",
      "canbelearnedfromany1\n",
      "Figure1:Layoutofface-selectiveregionsinmacaquevisualcortex,adapted\n",
      "from[1]withpermission.\n",
      "objectclassandusefullyappliedtoanyotherclass[9].Othertransformations\n",
      "whichareclassspincludechangesinviewpointandillumination.Theyde-\n",
      "pendontheobject?s3Dstructureandmaterialpropertiesbothofwhichvary\n",
      "between?butnotwithin?certainobjectclasses.Facesaretheprotoypical\n",
      "exampleofsuchaclasswheretheindividualobjectsaresimilartoeachother.In\n",
      "thispaper,wedescribeamethodbywhichinvariancetoclass-sptransfor-\n",
      "mationscanbeencodedandusedforwithin-classidenTheresulting\n",
      "modelofvisualcortexmustseparatetherepresentationsoftclassesin\n",
      "ordertoachievegoodperformance.Thisanalysisismainlycomputationalbut\n",
      "hasimplicationsforneuroscienceandpsychology.Section2ofthispaperde-\n",
      "scribestherecentlydiscoveredhierarchicalorganizationofthemacaqueface\n",
      "processingnetwork[1].Sections3and4describeanextensiontoanexisting\n",
      "hierarchicalmodelofobjectrecognitiontoincludeinvariancesforclass-sp\n",
      "transformations.Thesectionexplainswhythebrainshouldhaveseparate\n",
      "modulesandrelatestheproposedcomputationalmodeltophysiologyandneu-\n",
      "roimagingevidencethatthebraindoesindeedseparatefacerecognitionfrom\n",
      "objectrecognition.\n",
      "2\n",
      "Themacaquefacerecognitionhierarchy\n",
      "Inmacaques,thereare6discreteface-selectiveregionsintheventralvisual\n",
      "pathway,oneposteriorlateralfacepatch(PL),twomiddlefacepatches(lateral-\n",
      "MLandfundus-MF),andthreeanteriorfacepatches,theanteriorfundus(AF),\n",
      "anteriorlateral(AL),andanteriormedial(AM)patches[5,4].Atleastsome\n",
      "ofthesepatchesareorganizedintoafeedforwardhierarchy.Visualstimulation\n",
      "evokesachangeinthelocalpotential?20msearlierinML/MFthanin\n",
      "patchAM[1].Consistentwithahierarchicalorganizationinvolvinginformation\n",
      "passingfromML/MFtoAMviaAL,electricalstimulationofMLeliciteda\n",
      "responseinALandstimulationinALelicitedaresponseinAM[10].The\n",
      "ratesofcellsinML/MFaremoststronglymodulatedbyfaceviewpoint.Further\n",
      "alongthehierarchy,inpatchAM,cellsarehighlyselectiveforindividualfaces\n",
      "buttoleratesubstantialchangesinviewpoint[1].Thecomputationalroleof\n",
      "2\n",
      "\n",
      "thisrecentlydiscoveredhierarchicalorganizationisnotyetestablished.Inthis\n",
      "paper,wearguethatsuchasystem?withview-tunedcellsupstreamfromview-\n",
      "invariantidentity-selectivecells?isideallysuitedtosupportfaceiden\n",
      "Inthesubsequentsections,wepresentamodeloftheventralstreamthatis\n",
      "consistentwithalargebodyofexperimentalresults1andadditionallypredicts\n",
      "theexistenceofdiscreteface-selectivepatchesorganizedinthismanner.1\n",
      "See[11]forareview.\n",
      "2\n",
      "3\n",
      "Hubel-Wieselinspiredhierarchicalmodelsofobjectrecognition\n",
      "Attheendoftheventralvisualpathway,cellsinthemostanteriorpartsof\n",
      "visualcortexrespondselectivelytohighlycomplexstimuliandalsoinvariantly\n",
      "overseveraldegreesofvisualangle.HierarchicalmodelsinspiredbyHubeland\n",
      "Wiesel?swork,H-Wmodels,seektoachievesimilarselectivityandinvariance\n",
      "propertiesbysubjectingvisualinputstosuccessivetuningandpoolingopera-\n",
      "tions[12,13,14,15].AmajoralgorithmicclaimmadebytheseH-Wmodels\n",
      "isthatrepeatedapplicationofthisAND-liketuningoperationisthesource\n",
      "oftheselectiveresponsesofcellsattheendoftheventralstream.Likewise,\n",
      "repeatedapplicationofOR-likepoolingoperationsyieldinvariantresponses.\n",
      "HubelandWieseldescribedcomplexcellsaspoolingtheoutputsofsimplecells\n",
      "withthesameoptimalstimulibutreceptiveintlocations[16].\n",
      "Thispooling-over-positionarrangementyieldscomplexcellswithlargerrecep-\n",
      "tiveThatis,theoperationtransformsapositionsensitiveinputtoa\n",
      "(somewhat)translationinvariantoutput.Similarpoolingoperationscanalso\n",
      "beemployedtogaintolerancetootherimagetransformations,includingthose\n",
      "inducedbychangesinviewpointorillumination.BeyondV1,neuronscanim-\n",
      "plementpoolingjustastheydowithinV1.Complexcellscouldpooloverany\n",
      "transformatione.g.,viewpoint,simplybyconnectingto(simple-like)cellsthat\n",
      "areselectivefortheappearanceofthesamefeatureattviewpoints.The\n",
      "spH-Wmodelwhichweextendedinthispaperiscommonlyknownas\n",
      "HMAX[14,17];analogousextensionscouldbedoneformanyrelatedmodels.\n",
      "Inthismodel,simple(S)cellscomputeameasureoftheirinput?ssimilarityto\n",
      "astoredoptimalfeatureviaagaussianradialbasisfunctionoranormalizeddot\n",
      "product.Complex(C)cellspooloverScellsbycomputingthemaxresponse\n",
      "ofalltheScellswithwhichtheyareconnected.Theseoperationsaretypically\n",
      "repeatedinahierarchicalmanner,withtheoutputofoneClayerfeedinginto\n",
      "thenextSlayerandsoon.Themax-poolingoperationweemploycanbeviewed\n",
      "asanidealizedmathematicaldescriptionoftheoperationobtainedbyasystem\n",
      "thathasaccuratelyassociatedtemplateimagesacrosstransformations.These\n",
      "associationscouldbeacquiredbyalearningrulethatconnectsinputpatterns\n",
      "thatoccurnearbyintimetothesameCunit.Numerousalgorithmshavebeen\n",
      "proposedtosolvethisinvariance-learningproblemthroughtemporalassociation\n",
      "[18,19,20,21,22].Thereisalsopsychophysicalandphysiologicalevidencethat\n",
      "visualcortexemploysatemporalassociationstrategy2[23,24,25,26,27].\n",
      "4\n",
      "Invariancetoclass-sptransformations\n",
      "3\n",
      "\n",
      "H-Wmodelscangaininvariancetosometransformationsinagenericway.\n",
      "Whentheappearanceofaninputimageunderthetransformationdepends\n",
      "onlyoninformationavailableinasingleexamplee.g.,translation,scaling,and\n",
      "in-planerotation,thenthemodel?sresponsetoanyimageundergoingthetrans-\n",
      "formationwillremainconstantnomatterwhattemplateswereassociatedwith\n",
      "oneanothertobuildthemodel.Forexample,afacecanbeencodedinvari-\n",
      "antlytotranslationasavectorofsimilaritiestopreviouslyviewedtemplate\n",
      "imagesofanyotherobjects.Thesimilarity?values?neednotbehighaslong\n",
      "astheyremainconsistentacrosspositions[9].Werefertotransformationswith\n",
      "thispropertyasgeneric,andnotethattheyarethemostcommon.Other\n",
      "transformationsareclassspthatis,theydependoninformationaboutthe\n",
      "depictedobjectthatisnotavailableinasingleimage.Forexample,the2D\n",
      "imageevokedbyanobjectundergoingachangeinviewpointdependsonits3D\n",
      "structure.Likewise,theimagesevokedbychangesinilluminationdependon\n",
      "theobject?smaterialproperties.Theseclass-sppropertiescanbelearned\n",
      "fromoneormoreexemplarsoftheclassandappliedtootherobjectsinthe\n",
      "class(seealso[28,29]).Forthistowork,theobjectclassneedstoconsistof\n",
      "objectswithsimilar3Dshapeandmaterialproperties.Faces,asaclass,are\n",
      "consistentenoughinboth3Dstructureandmaterialpropertiesforthistowork.\n",
      "Other,morediverseclasses,suchas?automobiles?arenot.2Thesetemporal\n",
      "associationalgorithmsandtheevidencefortheiremploymentbyvisualcortex\n",
      "areinterestingintheirownright.Inthispaperwesidesteptheissueofhow\n",
      "visualcortexassociatessimilarfeaturesunderttransformationsinor-\n",
      "dertofocusontheimplicationsofhavingtherepresentationthatresultsfrom\n",
      "applyingtheselearningrules.\n",
      "3\n",
      "C3\n",
      "S3\n",
      "C2\n",
      "S2\n",
      "C1\n",
      "S1\n",
      "TuningPoolingInput\n",
      "Figure2:IllustrationofanextensiontotheHMAXmodeltoincorporate\n",
      "class-spinvariancetofaceviewpointchanges.Inourimplementationof\n",
      "theHMAXmodel,theresponseofaCcell?associatingtemplateswateach\n",
      "positiont?isgivenby:????nX1(1)(wt,j?xj)2??rw(x)=max\n",
      "?exp??t2?j=1Thesametemplatewtisreplicatedatallpositions,sothis\n",
      "Cresponsemodelstheoutcomeofatemporalassociationlearningprocessthat\n",
      "associatedthepatternsevokedbyatemplateateachposition.ThisCresponse\n",
      "isinvarianttotranslation.Ananalogousmethodcanachieveviewpointtolerant\n",
      "responses.rw(x)isinvarianttoviewpointchangesoftheinputfacex,aslong\n",
      "asthe3Dstructureofthefacedepictedinthetemplateimageswtmatchesthe\n",
      "3Dstructureofthefacedepictedinx.Sinceallhumanfaceshavearelatively\n",
      "similar3Dstructure,rw(x)willtoleratesubstantialviewpointchangeswithin\n",
      "thedomainoffaces.Itfollowsthattemplatesderivedfromaclassofobjectswith\n",
      "4\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thewrong3DstructuregiverisetoCcellsthatdonotrespondinvariantlyto3D\n",
      "rotations.Figures3and4showtheperformanceoftheextendedHMAXmodel\n",
      "onviewpoint-invariantandillumination-invariantwithin-category\n",
      "identasks.Bothoftheseareone-shotlearningtasks.Thatis,asingle\n",
      "viewofatargetobjectisencodedandasimple(nearestneighbors)\n",
      "mustranktestimagesdepictingthesameobjectasbeingmoresimilartothe\n",
      "encodedtargetthantoimagesofanyotherobjects.Bothtargetsanddistractors\n",
      "werepresentedundervaryingviewpointsandilluminations.Thistaskmodels\n",
      "thecommonsituationofencounteringanewfaceorobjectatoneviewpoint\n",
      "andthenbeingaskedtorecognizeitagainlaterfromatviewpoint.The\n",
      "originalHMAXmodel[14],representedherebytheredcurves(C2),showsa\n",
      "rapiddeclineinperformanceduetochangesinviewpointandillumination.In\n",
      "contrast,theC3featuresoftheextendedHMAXmodelperformtly\n",
      "betterthanC2.Additionally,theperformanceoftheC3featuresisnotstrongly\n",
      "byviewpointandilluminationchanges(seetheplotsalongthediagonal\n",
      "in3Iand4I).4\n",
      "I\n",
      "II\n",
      "Figure3:Viewpointinvariance.Bottompanel(II):Exampleimagesfrom\n",
      "threeclassesofstimuli.ClassAconsistsoffacesproducedusingFaceGen(Sin-\n",
      "gularInversions).ClassBisasetofsyntheticobjectsproducedusingBlender\n",
      "(StichtingBlenderFoundation).Eachobjectinthisclasshasacentralspike\n",
      "protrudingfromasphereandtwobumpsalwaysinthesamelocationontopof\n",
      "thesphere.Individualobjectsfromoneanotherbythedirectioninwhich\n",
      "anotherprotusioncomesofthecentralspikeandthelocation/directionof\n",
      "anadditionalprotrusion.ClassCisanothersetofsyntheticobjectsproduced\n",
      "usingBlender.Eachobjectinthisclasshasacentralpyramidonaplane\n",
      "andtwowallsoneitherside.Individualobjectsinthelocationandslant\n",
      "ofthreeadditionalbumps.Forbothfacesandthesyntheticclasses,thereis\n",
      "verylittleinformationtodisambiguateindividualsfromviewsofthebacksof\n",
      "theobjects.Toppanel(I):Eachcolumnshowstheresultsoftestingthemodel?s\n",
      "viewpoint-invariantrecognitionperformanceonatclassofstimuli(A,B\n",
      "orC).TheS3/C3templateswereobtainedfromobjectsinclassAinthetop\n",
      "row,classBinthemiddlerowandclassCinthebottomrow.Theabscissa\n",
      "ofeachplotshowsthemaximuminvariancerange(maximumdeviationfrom\n",
      "thefrontalviewineitherdirection)overwhichtargetsanddistractorswere\n",
      "presented.TheordinateshowstheAUCobtainedforthetaskofrecognizing\n",
      "anindividualnovelobjectdespitechangesinviewpoint.Themodelwasnever\n",
      "testedusingthesameimagesthatwereusedtoproduceS3/C3templates.A\n",
      "simplecorrelation-basednearest-neighbormustrankallimagesofthe\n",
      "sameobjectattviewpointsasbeingmoresimilartothefrontalview\n",
      "thanotherobjects.TheredcurvesshowtheresultingAUCwhentheinputto\n",
      "theconsistsofC2responsesandthebluecurvesshowtheAUCob-\n",
      "tainedwhentheinputistheC3responsesonly.Simulationdetails:\n",
      "Thesesimulationsused2000translationandscalinginvariantC2unitstuned\n",
      "topatchesofnaturalimages.ThechoiceofnaturalimagepatchesforS2/C2\n",
      "5\n",
      "\n",
      "templateshadverylittleontheresults.Errorbars(+/onestandard\n",
      "deviation)showtheresultsofcrossvalidationbyrandomlychoosingasetof\n",
      "exampleimagestouseforproducingS3/C3templatesandtestingontherest\n",
      "oftheimages.Theabovesimulationsused710S3units(10exemplarobjects\n",
      "and71views)and10C3units.5\n",
      "I\n",
      "II\n",
      "Figure4:Illuminationinvariance.Sameorganizationasin3.Bottom\n",
      "panel(II):Exampleimagesfromthreeclassesofstimuli.Eachclassconsists\n",
      "offaceswithtlightproperties,modelingtmaterials.\n",
      "ClassAwasopaqueandelikewood.ClassBwasopaquebuthighly\n",
      "elikeashinymetal.ClassCwastranslucentlikeglass.Eachimage\n",
      "showsaface?sappearancecorrespondingtoatlocationofthesource\n",
      "ofillumination(thelamp).ThefacemodelswereproducedusingFaceGen\n",
      "andmodifedwithBlender.Toppanel(I):Columnsshowtheresultsoftesting\n",
      "illumination-invariantrecognitionperformanceonclassA(left),B(middle)and\n",
      "C(right).S3/C3templateswereobtainedfromobjectsinclassA(toprow),B\n",
      "(middlerow),andC(bottomrow).Themodelwasnevertestedusingthesame\n",
      "imagesthatwereusedtoproduceS3/C3templates.Asin3,theabscissa\n",
      "ofeachplotshowsthemaximuminvariancerange(maximumdistancethelight\n",
      "couldmoveineitherdirectionawayfromaneutralpositionwherethelamp\n",
      "isevenwiththemiddleofthehead)overwhichtargetsanddistractorswere\n",
      "presented.TheordinateshowstheAUCobtainedforthetaskofrecognizing\n",
      "anindividualnovelobjectdespitechangesinillumination.Acorrelation-based\n",
      "nearest-neighbormustrankallimagesofthesameobjectunder\n",
      "eachilluminationconditionasbeingmoresimilartotheneutralviewthanother\n",
      "objects.TheredcurvesshowtheresultingAUCwhentheinputtothe\n",
      "consistsofC2responsesandthebluecurvesshowtheAUCobtainedwhenthe\n",
      "inputistheC3responsesonly.Simulationdetails:Thesesimulations\n",
      "used80translationandscalinginvariantC2unitstunedtopatchesofnatural\n",
      "images.ThechoiceofnaturalimagepatchesforS2/C2templateshadvery\n",
      "littleonthealresults.Errorbars(+/-onestandarddeviation)show\n",
      "theresultsofcrossvalidationbyrandomlychoosingasetofexampleimagesto\n",
      "useforproducingS3/C3templatesandtestingontherestoftheimages.The\n",
      "abovesimulationsused1200S3units(80exemplarfacesand15illumination\n",
      "conditions)and80C3units.\n",
      "6\n",
      "TheC3featuresareclass-spGoodperformanceonwithin-category\n",
      "idenisobtainedusingtemplatesderivedfromthesamecategory(plots\n",
      "alongthediagonalin3Iand4I).WhenC3featuresfromthewrongcat-\n",
      "egoryareusedinthisway,performanceplots).Inallthese\n",
      "cases,theC2featureswhichencodenothingspeccallyusefulfortakinginto\n",
      "accounttherelevanttransformationperformaswellasorbetterthanC3fea-\n",
      "turesderivedfromobjectsofthewrongclass.Itfollowsthatifthebrainisusing\n",
      "analgorithmofthissort(anH-Warchitecture)toaccomplishwithin-category\n",
      "identhenitmustseparatethecircuitrythatproducesinvariancefor\n",
      "6\n",
      "\n",
      "thetransformationsthatobjectsofoneclassundergofromthecircuitrypro-\n",
      "ducinginvariancetothetransformationsthatotherclassesundergo.\n",
      "5\n",
      "Conclusion\n",
      "Everydayvisualtasksrequirereasonablygoodinvariancetonon-generic\n",
      "transformationslikechangesinviewpointandillumination3.Weshowedthata\n",
      "broadclassofventralstreammodelsthatiswell-supportedbyphysiologydata\n",
      "(H-Wmodels)requireclass-spmodulesinordertoaccomplishthesetasks.\n",
      "Therecently-discoveredmacaqueface-processinghierarchybearsastrongre-\n",
      "semblancetothearchitectureofourextendedHMAXmodel.Theresponsesof\n",
      "cellsinanearlypartofthehierarchy(patchesMLandMF)arestronglydepen-\n",
      "dentonviewpoint,whilethecellsinadownstreamarea(patchAM)tolerate\n",
      "largechangesinviewpoint.IdentifyingtheS3layerofourextendedHMAX\n",
      "modelwiththeML/MFcellsandtheC3layerwiththeAMcellsisanintruig-\n",
      "ingpossibility.Anothermappingfromthemodeltothephysiologycouldbeto\n",
      "identifytheoutputsofsimpleoperatingonC2,S3orC3layerswith\n",
      "theresponsesofcellsinML/MFandAM.Fundamentally,the3Drotationofan\n",
      "objectclasswithone3Dstructuree.g.,faces,isnotthesameasthe3Drotation\n",
      "ofanotherclassofobjectswithat3Dstructure.Genericcircuitrycan-\n",
      "nottakeintoaccountbothtransformationsatonce.Thesameargumentapplies\n",
      "toallothernon-generictransformationsaswell.Sincethebrainmusttakethese\n",
      "transformationsintoaccountininterpretingthevisualworld,itfollowsthatvi-\n",
      "sualcortexmusthaveamodulararchitecture.Objectclassesthatareimportant\n",
      "enoughtorequireinvariancetothesetransformationsofnovelexemplarsmust\n",
      "beencodedbydedicatedcircuitry.Facesareclearlyatlyimportantcat-\n",
      "egoryofobjectstowarrantthisdedicationofresources.Analogousarguments\n",
      "applytoafewothercategories;humanbodiesallhaveasimilar3Dstructure\n",
      "andalsoneedtobeseenandrecognizedunderavarietyofviewpointandillu-\n",
      "minationconditions,likewise,readingisanimportantenoughactivitythatit\n",
      "makessensetoencodethevisualtransformationsthatwordsandlettersundergo\n",
      "withdedicatedcircuitry(changesinfont,viewingangle,etc).Wedonotthink\n",
      "itiscoincidentalthat,justasforfaces,brainareaswhicharethoughttobe\n",
      "specializedforvisualprocessingofthehumanbody(theextrastriatebodyarea\n",
      "[32])andreading(thevisualwordformarea[33,34])areconsistentlyfoundin\n",
      "humanfMRIexperiments.Wehavearguedinfavorofvisualcorteximplenting\n",
      "amodularityofcontentratherthanprocess.Thecomputationsperformedin\n",
      "eachdedicatedprocessingregioncanremainquitesimilartothecomputations\n",
      "performedinotherregions.Indeed,theconnectivitywithineachregioncanbe\n",
      "wiredupinthesameway,throughtemporalassociation.Theonly\n",
      "acrossareasistheobjectclass(andthetransformations)beingencoded.Inthis\n",
      "view,visualcortexmustbemodularinordertosucceedinthetaskswithwhich\n",
      "itisfaced.AcknowledgmentsThisreportdescribesresearchdoneattheCenter\n",
      "forBiological&ComputationalLearning,whichisintheMcGovernInstitute\n",
      "forBrainResearchatMIT,aswellasintheDept.ofBrain&Cognitive3\n",
      "Itissometimesclaimedthathumanvisionisnotviewpointinvariant[30].It\n",
      "iscertainlytruethatperformanceonpsychophysicaltasksrequiringviewpoint\n",
      "7\n",
      "\n",
      "invarianceisworsethanontasksrequiringtranslationinvariance.Thisisfully\n",
      "consistentwithourmodel.The3Dstructureoffacesdoesnotvarywildlywithin\n",
      "theclass,butthereiscertainlystillsometvariation.Itisthisvariabil-\n",
      "ityin3Dstructurewithintheclassthatisthesourceofthemodel?simperfect\n",
      "performance.Manypsychophysicalexperimentsonviewpointinvariancewere\n",
      "performedwithsynthetic?paperclip?objectsentirelybytheir3Dstruc-\n",
      "ture.Ourmodelpredictsparticularlyweakperformanceonviewpoint-tolerance\n",
      "taskswiththesestimuliandthatispreciselywhatisobserved[31].\n",
      "7\n",
      "Sciences,andwhichiswiththeComputerSciences&\n",
      "IntelligenceLaboratory(CSAIL).Thisresearchwassponsoredbygrantsfrom\n",
      "DARPA(IPTOandDSO),NationalScienceFoundation(NSF-0640097,NSF-\n",
      "0827427),AFSOR-THRL(FA8650-05-C-7262).Additionalsupportwaspro-\n",
      "videdby:Adobe,HondaResearchInstituteUSA,KingAbdullahUniversity\n",
      "ScienceandTechnologygranttoB.DeVore,NEC,Sonyandespeciallybythe\n",
      "EugeneMcDermottFoundation.\n",
      "2References\n",
      "[1]W.FreiwaldandD.Tsao,?FunctionalCompartmentalizationandView-\n",
      "pointGeneralizationWithintheMacaqueFace-ProcessingSystem,?Science,\n",
      "vol.330,no.6005,p.845,2010.[2]N.Kanwisher,J.McDermott,andM.\n",
      "Chun,?Thefusiformfacearea:amoduleinhumanextrastriatecortexspecial-\n",
      "izedforfaceperception,?TheJournalofNeuroscience,vol.17,no.11,p.4302,\n",
      "1997.[3]K.Grill-Spector,N.Knouf,andN.Kanwisher,?Thefusiformfacearea\n",
      "subservesfaceperception,notgenericwithin-categoryidenNature\n",
      "Neuroscience,vol.7,no.5,pp.555?562,2004.[4]D.Tsao,W.Freiwald,R.\n",
      "Tootell,andM.Livingstone,?Acorticalregionconsistingentirelyoffaceselec-\n",
      "tivecells,?Science,vol.311,no.5761,p.670,2006.[5]D.Tsao,W.Freiwald,\n",
      "T.Knutsen,J.Mandeville,andR.Tootell,?Facesandobjectsinmacaquecere-\n",
      "bralcortex,?NatureNeuroscience,vol.6,no.9,pp.989?995,2003.[6]R.\n",
      "Rajimehr,J.Young,andR.Tootell,?Ananteriortemporalfacepatchinhuman\n",
      "cortex,predictedbymacaquemaps,?ProceedingsoftheNationalAcademyof\n",
      "Sciences,vol.106,no.6,p.1995,2009.[7]S.Ku,A.Tolias,N.Logothetis,\n",
      "andJ.Goense,?fMRIoftheFace-ProcessingNetworkintheVentralTempo-\n",
      "ralLobeofAwakeandAnesthetizedMacaques,?Neuron,vol.70,no.2,pp.\n",
      "352?362,2011.[8]M.TarrandI.Gauthier,?FFA:afusiformareafor\n",
      "subordinate-levelvisualprocessingautomatizedbyexpertise,?NatureNeuro-\n",
      "science,vol.3,pp.764?770,2000.[9]J.Z.Leibo,J.Mutch,L.Rosasco,S.\n",
      "Ullman,andT.Poggio,?LearningGenericInvariancesinObjectRecognition:\n",
      "TranslationandScale,?MIT-CSAIL-TR-2010-061,CBCL-294,2010.[10]S.\n",
      "Moeller,W.Freiwald,andD.Tsao,?Patcheswithlinks:asystemfor\n",
      "processingfacesinthemacaquetemporallobe,?Science,vol.320,no.5881,\n",
      "p.1355,2008.[11]T.Serre,M.Kouh,C.Cadieu,U.Knoblich,G.Kreiman,\n",
      "andT.Poggio,?Atheoryofobjectrecognition:computationsandcircuitsin\n",
      "8\n",
      "\n",
      "thefeedforwardpathoftheventralstreaminprimatevisualcortex,?CBCL\n",
      "Paper#259/AIMemo#2005-036,2005.[12]K.Fukushima,?Neocognitron:\n",
      "Aself-organizingneuralnetworkmodelforamechanismofpatternrecognition\n",
      "byshiftinposition,?BiologicalCybernetics,vol.36,pp.193?202,\n",
      "Apr.1980.[13]M.RiesenhuberandT.Poggio,?Hierarchicalmodelsofobject\n",
      "recognitionincortex,?NatureNeuroscience,vol.2,pp.1019?1025,Nov.1999.\n",
      "[14]T.Serre,L.Wolf,S.Bileschi,M.Riesenhuber,andT.Poggio,?Robust\n",
      "ObjectRecognitionwithCortexLikeMechanisms,?IEEETrans.PatternAnal.\n",
      "Mach.Intell.,vol.29,no.3,pp.411?426,2007.[15]B.W.Mel,?SEEMORE:\n",
      "CombiningColor,Shape,andTextureHistogramminginaNeurallyInspired\n",
      "ApproachtoVisualObjectRecognition,?NeuralComputation,vol.9,pp.\n",
      "777?804,May1997.[16]D.HubelandT.Wiesel,?Receptivebinocular\n",
      "interactionandfunctionalarchitectureinthecat?svisualcortex,?TheJournal\n",
      "ofPhysiology,vol.160,no.1,p.106,1962.[17]J.MutchandD.Lowe,?Object\n",
      "classrecognitionandlocalizationusingsparsefeatureswithlimitedreceptive\n",
      "InternationalJournalofComputerVision,vol.80,no.1,pp.45?57,\n",
      "2008.[18]P.F?oldi?ak,?Learninginvariancefromtransformationsequences,?\n",
      "NeuralComputation,vol.3,no.2,pp.194?200,1991.[19]S.Stringerand\n",
      "E.Rolls,?Invariantobjectrecognitioninthevisualsystemwithnovelviewsof\n",
      "3Dobjects,?NeuralComputation,vol.14,no.11,pp.2585?2596,2002.[20]\n",
      "L.WiskottandT.Sejnowski,?Slowfeatureanalysis:Unsupervisedlearningof\n",
      "invariances,?Neuralcomputation,vol.14,no.4,pp.715?770,2002.[21]T.\n",
      "Masquelier,T.Serre,S.Thorpe,andT.Poggio,?Learningcomplexcellinvari-\n",
      "ancefromnaturalvideos:Aplausibilityproof,?AITechnicalReport#2007-060\n",
      "CBCLPaper#269,2007.[22]M.Spratling,?Learningviewpointinvariantper-\n",
      "ceptualrepresentationsfromclutteredimages,?IEEETransactionsonPattern\n",
      "AnalysisandMachineIntelligence,vol.27,no.5,pp.753?761,2005.\n",
      "8\n",
      "[23]D.Cox,P.Meier,N.Oertelt,andJ.J.DiCarlo,??Breaking?position-\n",
      "invariantobjectrecognition,?NatureNeuroscience,vol.8,no.9,pp.1145?1147,\n",
      "2005.[24]N.LiandJ.J.DiCarlo,?Unsupervisednaturalexperiencerapidly\n",
      "altersinvariantobjectrepresentationinvisualcortex.,?Science,vol.321,pp.\n",
      "1502?7,Sept.2008.[25]N.LiandJ.J.DiCarlo,?UnsupervisedNaturalVisual\n",
      "ExperienceRapidlyReshapesSize-InvariantObjectRepresentationinInferior\n",
      "TemporalCortex,?Neuron,vol.67,no.6,pp.1062?1075,2010.[26]G.Wallis\n",
      "andH.H.oftemporalassociationonrecognitionmemory.,?\n",
      "ProceedingsoftheNationalAcademyofSciencesoftheUnitedStatesofAmer-\n",
      "ica,vol.98,pp.4800?4,Apr.2001.[27]G.Wallis,B.Backus,M.Langer,\n",
      "G.Huebner,andH.?Learningillumination-andorientationinvariant\n",
      "representationsofobjectsthroughtemporalassociation,?Journalofvision,vol.\n",
      "9,no.7,2009.[28]T.Vetter,A.Hurlbert,andT.Poggio,?View-basedmodels\n",
      "of3Dobjectrecognition:invariancetoimagingtransformations,?CerebralCor-\n",
      "tex,vol.5,no.3,p.261,1995.[29]E.BartandS.Ullman,?Class-basedfeature\n",
      "matchingacrossunrestrictedtransformations,?PatternAnalysisandMachine\n",
      "Intelligence,IEEETransactionson,vol.30,no.9,pp.1618?1631,2008.[30]\n",
      "H.andS.Edelman,?Psychophysicalsupportforatwo-dimensional\n",
      "9\n",
      "\n",
      "viewinterpolationtheoryofobjectrecognition,?ProceedingsoftheNational\n",
      "AcademyofSciences,vol.89,no.1,p.60,1992.[31]N.Logothetis,J.Pauls,\n",
      "H.andT.Poggio,?View-dependentobjectrecognitionbymonkeys,?\n",
      "CurrentBiology,vol.4,no.5,pp.401?414,1994.[32]P.DowningandY.Jiang,\n",
      "?Acorticalareaselectiveforvisualprocessingofthehumanbody,?Science,vol.\n",
      "293,no.5539,p.2470,2001.[33]L.Cohen,S.Dehaene,andL.Naccache,?The\n",
      "visualwordformarea,?Brain,vol.123,no.2,p.291,2000.[34]C.Baker,J.\n",
      "Liu,L.Wald,K.Kwong,T.Benner,andN.Kanwisher,?Visualwordprocessing\n",
      "andexperientialoriginsoffunctionalselectivityinhumanextrastriatecortex,?\n",
      "ProceedingsoftheNationalAcademyofSciences,vol.104,no.21,p.9087,\n",
      "2007.\n",
      "9\n",
      "10\n",
      "\n",
      "PP6686.pdf\n",
      "PP6686.pdf 14\n",
      "Unsupervisedlearningofobjectframesbydense\n",
      "equivariantimagelabelling\n",
      "Authoredby:\n",
      "AndreaVedaldi\n",
      "HakanBilen\n",
      "JamesThewlis\n",
      "Abstract\n",
      "Oneofthekeychallengesofvisualperceptionistoextractabstract\n",
      "modelsof3Dobjectsandobjectcategoriesfromvisualmeasurements,\n",
      "whicharebycomplexnuisancefactorssuchasviewpoint,occlu-\n",
      "sion,motion,anddeformations.Startingfromtherecentideaofview-\n",
      "pointfactorization,weproposeanewapproachthat,givenalargenum-\n",
      "berofimagesofanobjectandnoothersupervision,canextractadense\n",
      "object-centriccoordinateframe.Thiscoordinateframeisinvarianttode-\n",
      "formationsoftheimagesandcomeswithadenseequivariantlabelling\n",
      "neuralnetworkthatcanmapimagepixelstotheircorrespondingobject\n",
      "coordinates.Wedemonstratetheapplicabilityofthismethodtosimple\n",
      "articulatedobjectsanddeformableobjectssuchashumanfaces,learn-\n",
      "ingembeddingsfromrandomsynthetictransformationsoropticalw\n",
      "correspondences,allwithoutanymanualsupervision.\n",
      "1PaperBody\n",
      "Humanscaneasilyconstructmentalmodelsofcomplex3Dobjectsandobject\n",
      "categoriesfromvisualobservations.Thisisremarkablebecausethedependency\n",
      "betweenanobject?sappearanceanditsstructureistangledinacomplexmanner\n",
      "withextrinsicnuisancefactorssuchasviewpoint,illumination,andarticulation.\n",
      "Therefore,learningtheintrinsicstructureofanobjectfromimagesrequiresre-\n",
      "movingtheseunwantedfactorsofvariationfromthedata.Therecentworkof\n",
      "[37]hasproposedanunsupervisedapproachtodoso,basedonontheconcept\n",
      "ofviewpointfactorization.TheideaistolearnadeepConvolutionalNeural\n",
      "Network(CNN)thatcan,givenanimageoftheobject,detectadiscretesetof\n",
      "objectlandmarks.tlyfromtraditionalapproachestolandmarkdetec-\n",
      "tion,however,landmarksareneithernorsupervisedmanually.Instead,\n",
      "thedetectorsarelearnedusingonlytherequirementthatthedetectedpoints\n",
      "mustbeequivariant(consistent)withdeformationsoftheinputimages.The\n",
      "1\n",
      "\n",
      "authorsof[37]showthatthisconstraintisttolearnlandmarksthat\n",
      "are?intrinsic?totheobjectsandhencecapturetheirstructure;remarkably,\n",
      "duetothegeneralizationabilityofCNNs,thelandmarkpointsaredetected\n",
      "consistentlynotonlyacrossdeformationsofagivenobjectinstance,whichare\n",
      "observedduringtraining,butalsoacrosstinstances.Thisbehaviour\n",
      "emergesautomaticallyfromtrainingonthousandsofsingle-instancecorrespon-\n",
      "dences.Inthispaper,wetakethisideafurther,movingbeyondasparsesetof\n",
      "landmarkstoadensemodeloftheobjectstructure(section3).Ourmethod\n",
      "relateseachpointonanobjecttoapointinalowdimensionalvectorspace\n",
      "inawaythatisconsistentacrossvariationinmotionandininstanceidentity.\n",
      "Thisgivesrisetoanobject-centriccoordinatesystem,whichallowspointson\n",
      "thesurfaceofanobjecttobeindexedsemantically1).Asanillustrative\n",
      "example,taketheobjectcategoryofafaceandthevectorspaceR3.Ourgoal\n",
      "istosemanticallymapouttheobjectsuchthatanypointonaface,suchas\n",
      "thelefteye,livesatacanonicalpositioninthis?labelspace?.WetrainaCNN\n",
      "tolearnthefunctionthatprojectsanyfaceimageintothisspace,essentially\n",
      "?coloring?eachpixelwithits31stConferenceonNeuralInformationProcessing\n",
      "Systems(NIPS2017),LongBeach,CA,USA.\n",
      "Figure1:Denseequivariantimagelabelling.Left:Givenanimagexofan\n",
      "objectorobjectcategoryandnoothersupervision,ourgoalistoacom-\n",
      "monlatentspaceZ,homeomorphictoasphere,whichattachesasemantically-\n",
      "consistentcoordinateframetotheobjectpoints.Thisisdonebylearninga\n",
      "denselabellingfunctionthatmapsimagepixelstotheircorrespondingcoordi-\n",
      "nateintheZspace.Thismappingfunctionisequivariant(compatible)with\n",
      "imagewarpsorobjectinstancevariations.Right:Anequivariantdensemap-\n",
      "pinglearnedinanunsupervisedmannerfromalargedatasetoffaces.(Results\n",
      "ofSIMPLEnetwork,Ldist,?=0.5)correspondinglabel.Asaresultofour\n",
      "learningformulation,thelabelspacehasthepropertyofbeinglocallysmooth:\n",
      "pointsnearbyintheimagearenearbyinthelabelspace.Inanidealcase,we\n",
      "couldimaginethesurfaceofanobjecttobemappedtoasphere.Inorderto\n",
      "achievetheseresults,wecontributeseveraltechnicalinnovations(section3.2).\n",
      "First,weshowthat,inordertolearnanon-trivialobjectcoordinateframe,the\n",
      "conceptofequivariancemustbecomplementedwiththeoneofdistinctiveness\n",
      "oftheembedding.Then,weproposeaCNNimplementationofthisconcept\n",
      "thatcanexplicitlyexpressuncertaintyinthelabellingoftheobjectpoints.The\n",
      "formulationisusedincombinationwithaprobabilisticloss,whichisaugmented\n",
      "witharobustgeometricdistancetoencouragebetteralignmentoftheobject\n",
      "features.Weshowthatthisframeworkcanbeusedtolearnmeaningfulobject\n",
      "coordinateframesinapurelyunsupervisedmanner,byanalyzingthousandsof\n",
      "deformationsofvisualobjects.While[37]proposedtouseThinPlateSpline\n",
      "imagewarpsfortraining,herewealsoconsidersimplesyntheticarticulatedob-\n",
      "jectshavingframesrelatedbyknownopticalw(section4).Weconcludethe\n",
      "paperwithasummaryofourg(section5).\n",
      "2\n",
      "RelatedWork\n",
      "Learningthestructureofvisualobjects.Modelingthestructureofvisual\n",
      "2\n",
      "\n",
      "objectsisawidelystudied(e.g.[6,7,11,39,12])computervisionproblemwith\n",
      "importantapplicationssuchasfaciallandmarkdetectionandhumanbodypose\n",
      "estimation.Muchofthisworkissupervisedandaimedatlearningdetectors\n",
      "ofobjectsortheirparts,oftenusingdeeplearning.Afewapproachessuchas\n",
      "spatialtransformernetworks[20]canlearngeometrictransformationswithout\n",
      "explicitgeometricsupervision,butdonotbuildexplicitgeometricmodelsof\n",
      "visualobjects.Morerelatedtoourwork,WarpNet[21]andgeometricmatching\n",
      "networks[34]learnaneuralnetworkthatpredictsThinPlateSpline[3]transfor-\n",
      "mationsbetweenpairsofimagesofanobject,includingsyntheticwarps.Deep\n",
      "DeformationNetwork[42]improvesWarpNetbyusingaPointTransformer\n",
      "Networktoreethecomputedlandmarks,butitrequiresmanualsupervision.\n",
      "Noneoftheseworkslookattheproblemoflearninganinvariantgeometricem-\n",
      "beddingfortheobject.Ourworkbuildsontheideaofviewpointfactorization\n",
      "(section3.1),recentlyintroducedin[37,31].However,weextend[37]inseveral\n",
      "tways.First,weconstructadenseratherthandiscreteembedding,\n",
      "whereallpixelsofanobjectaremappedtoaninvariantobject-centriccoordi-\n",
      "nateinsteadofjustasmallsetofselectedlandmarks.Second,weshowthatthe\n",
      "equivarianceconstraintproposedin[37]isnotquiteenoughtolearnsuchan\n",
      "embedding;itmustbecomplementedwiththeconceptofadistinctiveembed-\n",
      "ding(section3.1).Third,weintroduceanewneuralnetworkarchitectureand\n",
      "correspondingtrainingobjectivethatallowsuchanembeddingtobelearned\n",
      "inpractice(section3.2).Optical/semanticw.Acommontechniqueto\n",
      "correspondencesbetweentemporallyrelatedvideoframesisopticalw[18].\n",
      "Thestate-of-the-artmethods[14,38,19]typicallyemployconvolu2\n",
      "tionalneuralnetworkstolearnpairwisedensecorrespondencesbetweenthe\n",
      "sameobjectinstancesatsubsequentframes.TheSIFTFlowmethod[25]\n",
      "extendsthebetween-instancecorrespondencestocross-instancemappingsby\n",
      "matchingSIFTfeatures[27]betweensemanticallysimilarobjectinstances.Learned-\n",
      "Miller[24]extendsthepairwisecorrespondencestomultipleimagesbyposing\n",
      "aproblemofalignmentamongtheimagesofaset.CollectionFlow[22]and\n",
      "Mobahietal.[29]projectobjectsontoalow-rankspacethatallowforjoint\n",
      "alignment.FlowWeb[50],andZhouetal.[49]constructfullyconnectedgraphs\n",
      "tomaximisecycleconsistencybetweeneachimagepairandsynthethicdata\n",
      "asanintermediarybytrainingaCNN.Inourexperiments(section4)wis\n",
      "knownfromsyntheticwarpsormotion,butourworkcouldbuildonanyun-\n",
      "supervisedopticalwmethod.Unsupervisedlearning.Classicalunsupervised\n",
      "learningmethodssuchasautoencoders[4,2,17]anddenoisingautoencoders\n",
      "aimtolearnusefulfeaturerepresentationsfromaninputbysimplyreconstruct-\n",
      "ingitafterabottleneck.Generativeadversarialnetworks[16]targetproducing\n",
      "samplesofrealisticimagesbytraininggenerativemodels.Thesemodelswhen\n",
      "trainedjointwithimageencodersarealsoshowntolearngoodfeaturerepre-\n",
      "sentations[9,10].Morerecentlyseveralstudieshaveemergedthattrainneural\n",
      "networksbylearningauxiliaryorpseudotasks.Thesemethodsexploittypically\n",
      "someexistinginformationininputas?self-supervision?withoutanymanualla-\n",
      "belingbyremovingorperturbingsomeinformationfromaninputandrequiring\n",
      "anetworktoreconstructit.Forinstance,Doerschetal.[8],andNorooziand\n",
      "3\n",
      "\n",
      "Favaro[30]trainanetworktopredicttherelativelocationsofshuedimage\n",
      "patches.Otherself-supervisedtasksincludecolorizingimages[44],inpainting\n",
      "[33],rankingframesofavideointemporallycorrectorder[28,13].Morerelated\n",
      "toourapproach,Agrawaletal.[1]useegomotionassupervisorysignaltolearn\n",
      "featurerepresentationsinaSiamesenetworkbypredictingcameratransforma-\n",
      "tionsfromimagepairs,[32]learntogrouppixelsthatmovetogetherinavideo.\n",
      "[48,15]useawarping-basedlosstolearndepthfromvideo.\n",
      "3\n",
      "Method\n",
      "Thissectiondiscussesourmethodindetail,rstintroducingthegeneral\n",
      "ideaofdenseequivariantlabelling(section3.1),andthenpresentingaconcrete\n",
      "implementationofthelatterusinganoveldeepCNNarchitecture(section3.2).\n",
      "3.1\n",
      "Denseequivariantlabelling\n",
      "Considera3DobjectS?R3oraclassofsuchobjectsSthataretopologically\n",
      "isomorphictoasphereZ?R3(i.e.theobjectsaresimpleclosedsurfaceswithout\n",
      "holes).Wecanconstructahomeomorphismp=?S(q)mappingpointsofthe\n",
      "sphereq?Ztopointsp?Softheobjects.Furthermore,iftheobjectsbelongto\n",
      "thesamesemanticcategory(e.g.faces),wecanassumethattheseisomorphisms\n",
      "aresemanticallyconsistent,inthesensethat?S0??S?1:S?S0mapspointsof\n",
      "objectStosemantically-analogouspointsinobjectS0(e.g.forhumanfacesthe\n",
      "righteyeinonefaceshouldbemappedtotherighteyeinanother[37]).While\n",
      "thisconstructionisabstract,itshowsthatwecanendowtheobject(orobject\n",
      "category)withasphericalreferencesystemZ.Theauthorsof[37]buildonthis\n",
      "constructiontoadiscretesystemofobjectlandmarksbyconsideringa\n",
      "numberofpointszk?Z.Here,wetakethegeometricembeddingidea\n",
      "moreliterallyandproposetoexplicitlylearnadensemappingfromimagesof\n",
      "theobjecttotheobject-centriccoordinatespaceZ.Formally,wewishtolearn\n",
      "alabellingfunction?:(x,u)7?zthattakesaRGBimagex:??R3,??\n",
      "R3andapixelu??totheobjectpointz?Zwhichisimagedatu1).\n",
      "Similarlyto[37],thismappingmustbecompatibleorequivariantwithimage\n",
      "deformations.Namely,letg:???beadeformationoftheimagedomain,\n",
      "eithersyntheticorduetoaviewpointchangeorothermotion.Furthermore,\n",
      "letgx=x?g?1betheactionofgontheimage(obtainedbyinversewarp).\n",
      "Barringocclusionsandboundaryconditions,pixeluinimagexmustreceivethe\n",
      "samelabelaspixelguinimagegx,whichresultsintheinvarianceconstraint:\n",
      "?x,u:\n",
      "?(x,u)=?(gx,gu).\n",
      "(1)\n",
      "Equivalently,wecanviewthenetworkasafunctionalx7??(x,?)that\n",
      "mapstheimagetoacorrespondinglabelmap.Sincethelabelmapisanimage\n",
      "too,gactsonitbyinversewarp.1Using1\n",
      "Inthesensethatg?(x,?)=?(x,?)?g?1.\n",
      "3\n",
      "this,theconstraint(1)canberewrittenastheequivariancerelationg?(x,\n",
      "?)=?(gx,?).Thiscanbevisualizedbynotingthatthelabelimagedeformsin\n",
      "4\n",
      "\n",
      "thesamewayastheinputimage,asshowforexamplein3.Forlearning,\n",
      "constraint(1)canbeincorporatedinalossfunctionasfollows:Z12L(?|?)\n",
      "=k?(x,u)??(gx,gu)kdu.|?|?However,minimizingthislosshasthe\n",
      "tdrawbackthataglobaloptimumisobtainedbysimplysetting?(x,\n",
      "u)=const.Thereasonforthisissueisthat(1)isnotquiteenoughtolearna\n",
      "usefulobjectrepresentation.Inordertodoso,wemustrequirethelabelsnot\n",
      "onlytobeequivariant,butalsodistinctive,inthesensethat?(x,u)=?(gx,v)\n",
      "?\n",
      "v=gu.\n",
      "Wecanencodethisrequirementasalossintways.Forexample,by\n",
      "usingthefactthatpoints?(x,u)areontheunitsphere,wecanusetheloss:\n",
      "Z120kgu?argmaxvh?(x,u),?(gx,v)ikdu.(2)L(?|x,g)=|?|?By\n",
      "doingso,thelabels?(x,u)mustbeabletodiscriminatebetweentobject\n",
      "points,sothataconstantlabellingwouldreceiveahighpenalty.Relationship\n",
      "withlearninginvariantvisualdescriptors.Asanalternativetoloss(2),we\n",
      "couldhaveusedapairwiseloss2toencouragethesimilarityh?(x,u),?(x0,\n",
      "gu)iofthelabelsassignedtocorrespondingpixelsuandgutobelargerthan\n",
      "thesimilarityh?(x,u),?(x0,v)iofthelabelsassignedtopixelsuandvthat\n",
      "donotcorrespond.Formally,thiswouldresultinapairwiselosssimilarto\n",
      "theonesoftenusedtolearninvariantvisualdescriptorsforimagematching.\n",
      "Thereasonwhyourmethodlearnsanobjectrepresentationinsteadofageneric\n",
      "visualdescriptoristhatthedimensionalityofthelabelspaceZisjustenough\n",
      "torepresentapointonasurface.IfwereplaceZwithalargerspacesuchas\n",
      "Rd,d2,wecanexpect?(x,u)tolearntoextractgenericvisualdescriptors\n",
      "likeSIFTinstead.Thisestablishesaninterestingrelationshipbetweenvisual\n",
      "descriptorsandobject-spcoordinatevectorsandsuggeststhatitispossible\n",
      "totransitionbetweenthetwobycontrollingtheirdimensionality.3.2\n",
      "Concretelearningformulation\n",
      "Inthissectionweintroduceaconcreteimplementationofourmethode\n",
      "2).Forthemapping?,weuseaCNNthatreceivesasinputanimagetensor\n",
      "x?RH?W?Candproducesasoutputalabeltensorz?RH?W?L.Weuse\n",
      "thenotation?u(x)toindicatetheL-dimensionallabelvectorextractedatpixel\n",
      "ufromthelabelimagecomputedbythenetwork.Thedimensionofthelabel\n",
      "vectorsissettoL=3(insteadofL=2)inordertoallowthenetworkto\n",
      "expressuncertaintyaboutthelabelassignedtoapixel.Thenetworkcando\n",
      "sobymodulatingthenormof?u(x).Infact,correspondencesareexpressed\n",
      "probabilisticallybycomputingtheinnerproductoflabelvectorsfollowedbythe\n",
      "softmaxoperator.Formally,theprobabilitythatpixelvinimagex0corresponds\n",
      "topixeluinimagexisexpressedas:0\n",
      "eh?u(x),?v(x)ip(v|u;x,x0,?)=Ph?(x),?(x0)i.uzze\n",
      "(3)\n",
      "Inthismanner,ashortervector?uresultsinamoreprobability\n",
      "distribution.Next,wewishtoalossfunctionforlearning?fromdata.\n",
      "Tothisend,weconsideratriplet?=(x,x0,g),wherex0=gxisanimage\n",
      "thatcorrespondstoxuptotransformationg(thenature2\n",
      "Formally,thisisachievedbythelossZno1L00(?|x,g)=max0,max\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?(u,v)+h?(x,u),?(gx,v)i?h?(x,u),?(gx,gu)idu,v|?|?\n",
      "where?(u,v)?0isanerror-dependentmargin.\n",
      "4\n",
      "Opticalw\n",
      "Figure2:Unsuperviseddensecorrespondencenetwork.Fromlefttoright:\n",
      "Thenetwork?extractslabelmaps?u(x)and?v(x0)fromtheimagepairx\n",
      "andx0.Anopticalowmodule(orgroundtruthforsynthetictransformation)\n",
      "computesthewarp(correspondencegsuchthatx0=gx.Thenthelabel\n",
      "ofeachpointuintheimageiscorrelatedtoeachpointvinthesecond,\n",
      "obtaininganumberofscoremaps.Thelossevaluateshowwellthescoremaps\n",
      "predictthewarpg.ofthedataisdiscussedbelow).Wethenassesstheperfor-\n",
      "manceofthenetwork?onthetriplet?usingtwolosses.Thelossisthe\n",
      "negativelog-likelihoodoftheground-truthcorrespondences:1XLlog(?|x,x0\n",
      ",g)=?logp(gu|u;x,x0,?).(4)HWuThislosshastheadvantagethatit\n",
      "explicitlylearns(3)astheprobabilityofamatch.However,itisnotsensitive\n",
      "tothesizeofacorrespondenceerrorv?gu.Inordertoaddressthisissue,we\n",
      "alsoconsidertheloss1XXLdist(?|x,x0,g)=kv?guk?2p(v|u;x,x0\n",
      ",?).(5)HWuvHere?>0isanexponentusedtocontroltherobustnessof\n",
      "thedistancemeasure,whichwesetto?=0.5,1.Neworkdetails.Wetesttwo\n",
      "architecture.Theone,denotedSIMPLE,isthesameas[47,37]andisa\n",
      "chain(5,20)+,(2,mp),?2,(5,48)+,(3,64)+,(3,80)+,(3,256)+,(1,3)\n",
      "where(h,c)isabankofcofsizeh?h,+denotesReLU,(h,mp)ish\n",
      "?hmax-pooling,?siss?downsampling.Betterperformancecanbeobtained\n",
      "byincreasingthesupportoftheinthenetwork;forthis,weconsidera\n",
      "secondnetworkDILATIONS(5,20)+,(2,mp),?2,(5,48)+,(5,64,2)+,\n",
      "(3,80,4)+,(3,256,2)+,(1,3)where(h,c,d)isawith?ddilation[41].\n",
      "3.3\n",
      "Learningfromsyntheticandtruedeformations\n",
      "Losses(4)and(5)learnfromtriplets?=(x,x0,g).Herex0canbeeither\n",
      "generatedsyntheticallybyapplyingarandomtransformationgtoanaturalim-\n",
      "agex[37,21],oritcanbeobtainedbyobservingimagepairs(x,x0)containing\n",
      "trueobjectdeformationsarisingfromaviewpointchangeoranobjectmotion\n",
      "ordeformation.Theuseofsynthetictransformationsenablestrainingevenon\n",
      "staticimagesandwasconsideredin[37],whoshowedittobettolearn\n",
      "meaningfullandmarksforanumberofreal-worldobjectsuchashumanand\n",
      "catfaces.Here,inadditiontousingsyntheticdeformations,wealsoconsider\n",
      "usinganimatedimagepairsxandx0.Inprinciple,thelearningformulationcan\n",
      "bemosothatknowledgeofgisnotrequired;instead,imagesandtheir\n",
      "warpscanbecomparedandaligneddirectlybasedonthebrightnessconstancy\n",
      "principle.Inourtoyvideoexamplesweobtaingfromtherenderingengine,but\n",
      "itcanintheorybeobtainedusinganopticalwalgorithmwhich\n",
      "wouldproduceanoisyversionofg.\n",
      "4\n",
      "Experiments\n",
      "Thissectionassessesourunsupervisedmethodfordenseobjectlabellingon\n",
      "tworepresentativetasks:twotoyproblems(sections4.1and4.2)andhuman\n",
      "6\n",
      "\n",
      "andcatfaces(section4.3).5\n",
      "Figure3:Roboarmequivariantlabelling.Top:Originalvideoframesof\n",
      "asimplearticulatedobject.Middleandbottom:learnedlabels,whichchange\n",
      "equivariantlywiththearm,learnedusingLlogandLdist,respectively.t\n",
      "colorsdenotetpointsofthesphericalobjectframe.4.1\n",
      "Roboarmexample\n",
      "Inordertoillustrateourmethodweconsideratoyproblemconsistingofa\n",
      "simplearticulatedobject,namelyananimatedroboticarm3)created\n",
      "usinga2Dphysicsengine[36].Wedosofortworeasons:toshowthatthe\n",
      "approachiscapableoflabellingcorrectlydeformable/articulatedobjectsandto\n",
      "showthatthesphericalmodelZisapplicablealsotothinobjects,thathave\n",
      "mainlya1Dstructure.Datasetdetails.Thearmisanchoredtothebottomleft\n",
      "cornerandismadeupofcoloredcapsulesconnectedwithjointshavingreason-\n",
      "ableanglelimitstopreventunrealisticcontortionandselfocclusion.Motionis\n",
      "achievedbyvaryingthegravityvector,samplingeachelementfromaGaussian\n",
      "withstandarddeviation15ms?2every100iterations.Framesxofsize90?90\n",
      "pixelsandthecorrespondingwg:x7?x0aresavedevery20iterations.\n",
      "Wealsosavethepositionsofthecapsulecenters.Thedatasethas23999\n",
      "frames.Learning.Usingthecorrespondences?=(x,x0,g)providedbythe\n",
      "wweuseourmethodtolearnanobjectcentriccoordinateframeZand\n",
      "itscorrespondinglabellingfunction?u(x).Wetestlearning?usingtheprob-\n",
      "abilisticloss(4)anddistance-basedloss(5).Inthelossweignoreareaswith\n",
      "zerow,whichautomaticallyremovesthebackground.WeusetheSIMPLE\n",
      "networkarchitecture(section3.2).Results.Figure3providessomequalitative\n",
      "results,showingbymeansofcolormapsthelabels?u(x)associatedtot\n",
      "pixelsofeachinputimage.Itiseasytoseethatthemethodattachesconsistent\n",
      "labelstothetarmelements.Thedistance-basedlossproducesamore\n",
      "uniformembedding,asmaybeexpected.Theembeddingsarefurthervisualized\n",
      "inFigure4byprojectinganumberofvideoframesbacktothelearnedcoor-\n",
      "dinatespacesZ.Itcanbenotedthatthespaceisinvariant,inthesensethat\n",
      "theresultingisapproximatelythesamedespitethefactthattheobject\n",
      "deformstlyinimagespace.Thisistrueforbothembeddings,butthe\n",
      "distance-basedonesaregeometricallymoreconsistent.2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-2\n",
      "-2-4\n",
      "7\n",
      "\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "-2-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-2\n",
      "-2-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "-2-4\n",
      "-2\n",
      "0\n",
      "2\n",
      "4\n",
      "Figure4:Invarianceoftheobject-centriccoordinatespaceforRoboarm.\n",
      "Theplotprojectsframes3,6,9of3ontheobject-centriccoordinatespace\n",
      "Z,usingtheembeddingfunctionslearnedbymeansoftheprobabilistic(top)and\n",
      "8\n",
      "\n",
      "distance(bottom)basedlosses.Thesphereisthenunfolded,plottinglatitude\n",
      "andlongitude(inradians)alongtheverticalandhorizontalaxes.\n",
      "6\n",
      "LogDist0.5Dist1Groundtruth\n",
      "Figure5:Left:Embeddingspacesoftdimension.Sphericalem-\n",
      "bedding(fromthe3Dembeddingfunction?u(x)?R3)learnedusingthe\n",
      "distancelosscomparedtoacircularembeddingwithonedimensionless.Right:\n",
      "Capsulecenterpredictionfortlosses.Predictingcapsulecenters.We\n",
      "evaluatequantitativelytheabilityofourobjectframestolocalisethecapsule\n",
      "centers.Ifourassumptioniscorrectandacoordinatesystemintrinsictothe\n",
      "objecthasbeenlearned,thenweshouldexpecttheretobeasp3-vector\n",
      "inZcorrespondingtoeachcenter,andourjobistothesevectors.Various\n",
      "strategiescouldbeused,suchasaveragingtheobject-centriccoordinatesgiven\n",
      "tothecentersoverthetrainingset,butwechoosetoincorporatetheproblem\n",
      "intothelearningframework.Thisisdoneusingthenegativelog-likelihoodin\n",
      "muchthesamewayas(4),limitingourvectorsutothecenters.Thisisdone\n",
      "asanauxiliarylayerwithnobackpropagationtotherestofthenetwork,so\n",
      "thattheembeddingremainsunsupervised.TheerrorreportedistheEuclidean\n",
      "distanceasapercentageoftheimagewidth.Resultsaregivenforthe\n",
      "entlossfunctionsusedforunsupervisedtraininginTable1andvisualizedin\n",
      "Figure5right,showingthattheobjectcenterscanbelocatedtoahighdegree\n",
      "ofaccuracy.Thenegativeloglikelihoodperformsbestwhilethetwolossesin-\n",
      "corporatingdistanceperformsimilarly.Wealsoperformexperimentsvarying\n",
      "thedimensionalityLofthelabelspaceZ(Table2).Perhapsmostinterestingly,\n",
      "giventhealmostone-dimensionalnatureofthearm,isthecaseofL=2,which\n",
      "wouldcorrespondtoanapproximatelycircularspace(sincethelengthofvec-\n",
      "torsisusedtocodeforuncertainty).AsseenintherightofFigure5left,the\n",
      "segmentsarerepresentedalmostperfectlyontheboundaryofacircle,withthe\n",
      "exceptionofthebifurcationwhichitisunabletoaccuratelyrepresent.Thisis\n",
      "manifestedbythelightbluesegmenttrying,andfailing,tobeintwoplacesat\n",
      "once.UnsupervisedLossErrorLlog0.97%Ldist,?=11.13%Ldist,?=0.5\n",
      "1.14%Table1:Predictingcapsulecenters.Erroraspercentofimagewidth.\n",
      "4.2\n",
      "Texturedsphereexample\n",
      "DescriptorDimension23520\n",
      "Error1.29%1.14%1.16%1.28%\n",
      "Table2:Descriptordimension(Ldist,?=0.5).L>3showsnoimprovement,\n",
      "suggestingL=3isthenaturalmanifoldofthearm.\n",
      "TheexperimentofFigure6teststheabilityofthemethodtounderstand\n",
      "acompleterotationofa3Dobject,asimpletexturedsphere.Despitethefact\n",
      "thatthemethodistrainedonpairsofadjacentvideoframes(andcorrespond-\n",
      "ingopticalw),itstilllearnsaglobally-consistentembedding.However,this\n",
      "requiredswitchingfromfromtheSIMPLEtotheDILATIONSarchitecture\n",
      "(section3.2).4.3\n",
      "Faces\n",
      "Aftertestingourmethodonatoyproblem,wemovetoamuchhardertask\n",
      "9\n",
      "\n",
      "andapplyourmethodtogenerateanobject-centricreferenceframeZforthe\n",
      "categoryofhumanfaces.Inordertogenerateanimagepairandcorresponding\n",
      "wfortrainingwewarpeachfacesyntheticallyusingThinPlateSpline\n",
      "warpsinamannersimilarto[37].WetrainourmodelsontheextensiveCelebA\n",
      "[26]datasetofover200kfacesasin[37],excludingMAFL[47]testoverlapfrom\n",
      "thegiventrainingsplit.Ithasannotationsoftheeyes,noseandmouthcorners.\n",
      "Notethatwedonotusethesetotrainourmodel.WealsouseAFLW[23],\n",
      "testingon2995faces[47,40,46]with5landmarks.Like[37]weuse10,122\n",
      "facesfortraining.Weadditionallyevaluatequalitativelyonadatasetofcat\n",
      "faces[45],using8609imagesfortraining.Qualitativeassessment.Wethat\n",
      "fornetworkSIMPLEthenegativelog-likelihoodloss,whileperformingbest\n",
      "forthesimpleexampleofthearm,performspoorlyonfaces.Sp,this\n",
      "model7\n",
      "Figure6:Sphereequivariantlabelling.Top:videoframesofarotating\n",
      "texturedsphere.Middle:learneddenselabels,whichchangeequivariantlywith\n",
      "thesphere.Bottom:re-projectionofthevideoframesontheobjectframe\n",
      "(alsospherical).Exceptforocclusions,thereprojectionsareapproximately\n",
      "invariant,correctlymappingtheblueandorangesidestodrentregionsof\n",
      "thelabelspacefailstodisambiguatetheleftandrighteye,asshowninFigure\n",
      "9(right).Thedistance-basedloss(5)producesamorecoherentembedding,\n",
      "asseeninFigure9(left).UsingDILATIONSthisproblemdisappears,giving\n",
      "qualitativelysmoothandunambiguouslabelsforboththedistanceloss(Figure\n",
      "7)andthelog-likelihoodloss(Figure8).Forcatsourmethodisabletolearna\n",
      "consistentobjectframedespitelargevariationsinappearance(Figure8).\n",
      "Figure7:Faces.DILATIONSnetworkwithLdist,?=0.5.Top:Input\n",
      "images,Middle:Predicteddenselabelsmappedtocolours,Bottom:Image\n",
      "pixelsmappedtolabelsphereand\n",
      "Figure8:Cats.DILATIONSnetworkwithLlog.Top:Inputimages,\n",
      "Middle:Labelsmappedtocolours,Bottom:Imagesmappedtothespherical\n",
      "objectframes.\n",
      "8\n",
      "Figure9:Annotatedlandmarkpredictionfromtheshownunsupervisedlabel\n",
      "maps(SIMPLEnetwork).Left:TrainedwithLdist,?=0.5,Right:Failure\n",
      "todisambiguateeyeswithLlog.(Prediction:green,Groundtruth:Blue)\n",
      "Regressingsemanticlandmarks.Wewouldliketoquantifytheaccuracyof\n",
      "ourmodelintermsofabilitytoconsistentlylocatemanuallyannotatedpoints,\n",
      "sptheeyes,nose,andmouthcornersgivenintheCelebAdataset.We\n",
      "usethestandardtestsplitforevaluationoftheMAFLdataset[47],containing\n",
      "1000images.WealsousetheMAFLtrainingsubsetof19kimagesforlearning\n",
      "topredictthegroundtruthlandmarks,whichgivesaquantitativemeasureof\n",
      "theconsistencyofourobjectframefordetectingfacialfeatures.Theseare\n",
      "reportedasEuclideanerrornormalizedasapercentageofinter-oculardistance.\n",
      "Inordertomaptheobjectframetothesemanticlandmarks,asinthecase\n",
      "oftherobotarmcenters,welearnthevectorszk?Zcorrespondingtothe\n",
      "positionofeachpointinourcanonicalreferencespaceandthen,foranygiven\n",
      "image,thenearestzanditscorrespondingpixellocationu.Wereport\n",
      "10\n",
      "\n",
      "thelocalizationperformanceofthismodelinTable3(?ErrorNearest?).We\n",
      "empiricallyvalidatethatwiththeSIMPLEnetworkthenegativelog-likelihood\n",
      "isnotidealforthistask(Figure9)andweobtainhigherperformanceforthe\n",
      "robustdistancewithpower0.5.However,afterswitchingtoDILATIONSto\n",
      "increasethereceptivebothmethodsperformcomparably.Themethodof\n",
      "[37]learnstoregressPgroundtruthcoordinatesbasedonM>Punsupervised\n",
      "landmarks.Byregressingfrommultiplepointsitisnotlimitedtointegerpixel\n",
      "coordinates.Whilewearenotpredictinglandmarksasnetworkoutput,wecan\n",
      "emulatethismethodbyallowingmultiplepointsinourobjectcoordinatespace\n",
      "tobepredictiveforasinglegroundtruthlandmark.Welearnoneregressorper\n",
      "groundtruthpoint,eachformulatedasalinearregressorR2M?R2ontopof\n",
      "coordinatesfromM=50learnedintermediatepoints.Thisallowstheregression\n",
      "tosaywhichpointsinZaremostusefulforpredictingeachgroundtruthpoint.\n",
      "WealsoreportresultsafterunsupervisedingofaCelebAnetworktothe\n",
      "morechallengingAFLWfollowedbyregressortrainingonAFLW.Asshownin\n",
      "Tables3and4,weoutperformotherunsupervisedmethodsonbothdatasets,\n",
      "andarecomparabletofullysupervisedmethods.Network\n",
      "Unsup.Loss\n",
      "SIMPLESIMPLESIMPLE\n",
      "LlogLdist,?=1Ldist,?=0.5LlogLdist,?=0.5\n",
      "Error\n",
      "Nearest\n",
      "Error\n",
      "Regress\n",
      "?7.94%7.18%DILATIONS5.83%DILATIONS5.87%[37]6.67%\n",
      "Table3:NearestneighbourandregressionlandmarkpredictiononMAFL\n",
      "5\n",
      "75.02%14.57%13.29%11.05%10.53%\n",
      "MethodErrorRCPR[5]11.6%CascadedCNN[35]8.97%CFAN[43]10.94\n",
      "%TCDCN[47]7.65%RAR[40]7.23%Unsup.Landmarks[37]10.53%D\n",
      "ILATIONSLdist,?=0.58.80%Table4:Comparisonwithsupervisedand\n",
      "unsupervisedmethodsonAFLW\n",
      "Conclusions\n",
      "Buildingontheideaofviewpointfactorization,wehaveintroduceanew\n",
      "methodthatcanendowanobjectorobjectcategorywithaninvariantdense\n",
      "geometricembeddingautomatically,bysimplyobservingalargedatasetofun-\n",
      "labelledimages.Ourlearningframeworkcombinesinanovelwaytheconcept\n",
      "ofequivariancewiththeoneofdistinctiveness.Wehavealsoproposedacon-\n",
      "creteimplementationusingnovellossestolearnadeepdenseimagelabeller.\n",
      "Wehaveshownempiricallythatthemethodcanlearnaconsistentgeometric\n",
      "embeddingforasimplearticulatedsyntheticroboticarmaswellasfora3D\n",
      "spheremodelandrealfaces.Theresultingembeddingsareinvarianttodefor-\n",
      "mationsand,importantly,tointra-categoryvariations.Acknowledgments:This\n",
      "workacknowledgesthesupportoftheAIMSCDT(EPSRCEP/L015897/1)and\n",
      "ERC677195-IDIU.Clipart:FreePik.\n",
      "9\n",
      "11\n",
      "\n",
      "2References\n",
      "[1]PulkitAgrawal,JoaoCarreira,andJitendraMalik.Learningtoseebymov-\n",
      "ing.InProc.ICCV,2015.[2]YoshuaBengio.Learningdeeparchitecturesfor\n",
      "AI.FoundationsandtrendsinMachineLearning,2009.[3]FredL.Bookstein.\n",
      "PrincipalWarps:Thin-PlateSplinesandtheDecompositionofDeformations.\n",
      "PAMI,1989.[4]HBourlardandYKamp.Auto-AssociationbyMultilayer\n",
      "PerceptronsandSingularValueDecomposition.BiologicalCybernetics,1988.\n",
      "[5]XavierP.Burgos-Artizzu,PietroPerona,andPiotrDoll?r.Robustface\n",
      "landmarkestimationunderocclusion-supp.mat.InProc.ICCV,2013.[6]\n",
      "TFCootes,CJTaylor,DHCooper,andJGraham.Activeshapemodels:\n",
      "theirtrainingandapplication.CVIU,1995.[7]NavneetDalalandBillTriggs.\n",
      "HistogramsofOrientedGradientsforHumanDetection.InProc.CVPR,2005.\n",
      "[8]CarlDoersch,AbhinavGupta,andAlexeiAEfros.UnsupervisedVisual\n",
      "RepresentationLearningbyContextPrediction.InProc.ICCV,2015.[9]\n",
      "Donahue,PhilippKr?henb?hl,andTrevorDarrell.Adversarialfeaturelearning.\n",
      "Proc.ICLR,2017.[10]VincentDumoulin,IshmaelBelghazi,BenPoole,Alex\n",
      "Lamb,MartinArjovsky,OlivierMastropietro,andAaronCourville.Adversar-\n",
      "iallylearnedinference.Proc.ICLR,2017.[11]PedroF.Felzenszwalb,RossB.\n",
      "Girshick,DavidMcAllester,andDevaRamanan.ObjectDetectionwithDis-\n",
      "criminativelyTrainedPartBasedModels.PAMI,2010.[12]RobFergus,Pietro\n",
      "Perona,andAndrewZisserman.Objectclassrecognitionbyunsupervisedscale-\n",
      "invariantlearning.InProc.CVPR,2003.[13]BasuraFernando,HakanBilen,\n",
      "EfstratiosGavves,andStephenGould.Self-supervisedvideorepresentation\n",
      "learningwithodd-one-outnetworks.InProc.CVPR,2017.[14]PhilippFis-\n",
      "cher,AlexeyDosovitskiy,EddyIlg,PhilipH?usser,CanerHaz?rba?s,Vladimir\n",
      "Golkov,PatrickvanderSmagt,DanielCremers,andThomasBrox.FlowNet:\n",
      "LearningOpticalFlowwithConvolutionalNetworks.InProc.ICCV,2015.\n",
      "[15]RaviGarg,GustavoCarneiro,andIanReid.Unsupervisedcnnforsin-\n",
      "gleviewdepthestimation:Geometrytotherescue.InProc.ECCV,pages\n",
      "740?756,2016.[16]IanGoodfellow,YoshuaBengio,andAaronCourville.Deep\n",
      "Learning.MITPress,2016.http://www.deeplearningbook.org.[17]GEHin-\n",
      "tonandRRSalakhutdinov.ReducingtheDimensionalityofDatawithNeu-\n",
      "ralNetworks.Science,2006.[18]BertholdK.P.HornandBrianG.Schunck.\n",
      "Determiningopticalow.Intelligence,1981.[19]EddyIlg,Niko-\n",
      "lausMayer,TonmoySaikia,MargretKeuper,AlexeyDosovitskiy,andThomas\n",
      "Brox.FlowNet2.0:EvolutionofOpticalFlowEstimationwithDeepNetworks.\n",
      "arXivpreprintarXiv:1612.01925,2016.[20]MaxJaderberg,KarenSimonyan,\n",
      "AndrewZisserman,andKorayKavukcuoglu.SpatialTransformerNetworks.\n",
      "InProc.NIPS,2015.[21]A.Kanazawa,D.W.Jacobs,andM.Chandraker.\n",
      "WarpNet:Weaklysupervisedmatchingforsingle-viewreconstruction.InProc.\n",
      "CVPR,2016.[22]IraKemelmacher-ShlizermanandStevenM.Seitz.Collection\n",
      "w.InProc.CVPR,2012.[23]MartinKoestinger,PaulWohlhart,PeterM.\n",
      "Roth,andHorstBischof.Annotatedfaciallandmarksinthewild:Alarge-scale,\n",
      "real-worlddatabaseforfaciallandmarklocalization.InFirst10\n",
      "IEEEInternationalWorkshoponBenchmarkingFacialImageAnalysisTech-\n",
      "12\n",
      "\n",
      "nologies,2011.[24]ErikGLearned-Miller.Datadrivenimagemodelsthrough\n",
      "continuousjointalignment.IEEETransactionsonPatternAnalysisandMa-\n",
      "chineIntelligence,2006.[25]CeLiu,JennyYuen,andAntonioTorralba.SIFT\n",
      "Flow:Densecorrespondenceacrossscenesanditsapplications.PAMI,2011.\n",
      "[26]ZiweiLiu,PingLuo,XiaogangWang,andXiaoouTang.Deeplearning\n",
      "faceattributesinthewild.InProc.ICCV,2015.[27]DavidGLowe.Dis-\n",
      "tinctiveimagefeaturesfromscale-invariantkeypoints.Internationaljournalof\n",
      "computervision,60(2):91?110,2004.[28]IshanMisra,CLawrenceZitnick,\n",
      "andMartialHebert.Shandlearn:unsupervisedlearningusingtemporal\n",
      "ordervInProc.ECCV,2016.[29]HosseinMobahi,CeLiu,and\n",
      "WilliamT.Freeman.ACompositionalModelforLowDimensionalImageSet\n",
      "Representation.Proc.CVPR,2014.[30]MehdiNorooziandPaoloFavaro.Un-\n",
      "supervisedlearningofvisualrepresentationsbysolvingjigsawpuzzles.InProc.\n",
      "ECCV,2016.[31]D.Novotny,D.Larlus,andA.Vedaldi.Learning3dobject\n",
      "categoriesbylookingaroundthem.InProc.ICCV,2017.[32]DeepakPathak,\n",
      "RossGirshick,PiotrDoll?r,TrevorDarrell,andBharathHariharan.Learning\n",
      "featuresbywatchingobjectsmove.InProc.CVPR,2017.[33]DeepakPathak,\n",
      "PhilippKrahenbuhl,Donahue,TrevorDarrell,andAlexeiAEfros.Context\n",
      "Encoders:FeatureLearningbyInpainting.InProc.CVPR,2016.[34]I.Rocco,\n",
      "R.Arandjelovi?c,andJ.Sivic.Convolutionalneuralnetworkarchitecturefor\n",
      "geometricmatching.InProc.CVPR,2017.[35]YiSun,XiaogangWang,and\n",
      "XiaoouTang.Deepconvolutionalnetworkcascadeforfacialpointdetection.\n",
      "InProc.CVPR,2013.[36]YuvalTassa.CapSim-theMATLABphysicsen-\n",
      "gine.https://mathworks.com/matlabcenhange/29249-capsim-the-\n",
      "matlab-physics-engine.[37]JamesThewlis,HakanBilen,andAndreaVedaldi.\n",
      "Unsupervisedlearningofobjectlandmarksbyfactorizedspatialembeddings.\n",
      "InProc.ICCV,2017.[38]JamesThewlis,ShuaiZheng,PhilipH.S.Torr,\n",
      "andAndreaVedaldi.Fully-TrainableDeepMatching.InProc.BMVC,2016.\n",
      "[39]MarkusWeber,MaxWelling,andPietroPerona.Towardsautomaticdis-\n",
      "coveryofobjectcategories.InProc.CVPR,2000.[40]ShengtaoXiao,Jiashi\n",
      "Feng,JunliangXing,HanjiangLai,ShuichengYan,andAshrafKassim.Ro-\n",
      "bustFacialLandmarkDetectionviaRecurrentAttentivntNetworks.\n",
      "InProc.ECCV,2016.[41]FisherYuandVladlenKoltun.Multi-scalecon-\n",
      "textaggregationbydilatedconvolutions.InProc.ICLR,2016.[42]Xiang\n",
      "Yu,FengZhou,andManmohanChandraker.DeepDeformationNetworkfor\n",
      "ObjectLandmarkLocalization.InProc.ECCV,Cham,2016.[43]JieZhang,\n",
      "ShiguangShan,MeinaKan,andXilinChen.auto-encodernet-\n",
      "works(CFAN)forreal-timefacealignment.InProc.ECCV,2014.[44]Richard\n",
      "Zhang,PhillipIsola,andAlexeiAEfros.ColorfulImageColorization.InProc.\n",
      "ECCV,2016.[45]WeiweiZhang,JianSun,andXiaoouTang.Catheaddetec-\n",
      "tion-Howtoelyexploitshapeandtexturefeatures.InProc.ECCV,\n",
      "2008.[46]ZhanpengZhang,PingLuo,ChenChangeLoy,andXiaoouTang.\n",
      "Faciallandmarkdetectionbydeepmulti-tasklearning.InProc.ECCV,2014.\n",
      "11\n",
      "[47]ZhanpengZhang,PingLuo,ChenChangeLoy,andXiaoouTang.Learn-\n",
      "ingDeepRepresentationforFaceAlignmentwithAuxiliaryAttributes.PAMI,\n",
      "13\n",
      "\n",
      "2016.[48]TinghuiZhou,MatthewBrown,NoahSnavely,andDavidGLowe.\n",
      "Unsupervisedlearningofdepthandego-motionfromvideo.InProc.CVPR,\n",
      "2017.[49]TinghuiZhou,PhilippKr?henb?hl,MathieuAubry,QixingHuang,\n",
      "andAlexeiA.Efros.LearningDenseCorrespondencesvia3D-guidedCycle\n",
      "Consistency.InProc.CVPR,2016.[50]TinghuiZhou,YongJaeLee,Stella\n",
      "X.Yu,andAlexeiA.Efros.FlowWeb:Jointimagesetalignmentbyweaving\n",
      "consistent,pixel-wisecorrespondences.InProc.CVPR,2015.\n",
      "12\n",
      "14\n",
      "\n",
      "PP3729.pdf\n",
      "PP3729.pdf 9\n",
      "NonparametricBayesianTextureLearningand\n",
      "Synthesis\n",
      "Authoredby:\n",
      "AntonioTorralba\n",
      "LongZhu\n",
      "BillFreeman\n",
      "YuanahaoChen\n",
      "Abstract\n",
      "WepresentanonparametricBayesianmethodfortexturelearningand\n",
      "synthesis.Atextureimageisrepresentedbya2D-HiddenMarkovModel\n",
      "(2D-HMM)wherethehiddenstatescorrespondtotheclusterlabelingof\n",
      "textonsandthetransitionmatrixencodestheirspatiallayout(thecom-\n",
      "patibilitybetweenadjacenttextons).2D-HMMiscoupledwiththeHierar-\n",
      "chicalDirichletprocess(HDP)whichallowsthenumberoftextonsandthe\n",
      "complexityoftransitionmatrixgrowastheinputtexturebecomesirreg-\n",
      "ular.TheHDPmakesuseofDirichletprocesspriorwhichfavorsregular\n",
      "texturesbypenalizingthemodelcomplexity.Thisframework(HDP-2D-\n",
      "HMM)learnsthetextonvocabularyandtheirspatiallayoutjointlyand\n",
      "automatically.TheHDP-2D-HMMresultsinacompactrepresentation\n",
      "oftextureswhichallowsfasttexturesynthesiswithcomparablerendering\n",
      "qualityoverthestate-of-the-artimage-basedrenderingmethods.Wealso\n",
      "showthatHDP-2D-HMMcanbeappliedtoperformimagesegmentation\n",
      "andsynthesis.\n",
      "1PaperBody\n",
      "WepresentanonparametricBayesianmethodfortexturelearningandsynthesis.\n",
      "Atextureimageisrepresentedbya2DHiddenMarkovModel(2DHMM)where\n",
      "thehiddenstatescorrespondtotheclusterlabelingoftextonsandthetransition\n",
      "matrixencodestheirspatiallayout(thecompatibilitybetweenadjacenttex-\n",
      "tons).The2DHMMiscoupledwiththeHierarchicalDirichletprocess(HDP)\n",
      "whichallowsthenumberoftextonsandthecomplexityoftransitionmatrix\n",
      "growastheinputtexturebecomesirregular.TheHDPmakesuseofDirichlet\n",
      "processpriorwhichfavorsregulartexturesbypenalizingthemodelcomplexity.\n",
      "Thisframework(HDP-2DHMM)learnsthetextonvocabularyandtheirspa-\n",
      "tiallayoutjointlyandautomatically.TheHDP-2DHMMresultsinacompact\n",
      "1\n",
      "\n",
      "representationoftextureswhichallowsfasttexturesynthesiswithcomparable\n",
      "renderingqualityoverthestate-of-the-artpatch-basedrenderingmethods.We\n",
      "alsoshowthattheHDP2DHMMcanbeappliedtoperformimagesegmentation\n",
      "andsynthesis.ThepreliminaryresultssuggestthatHDP-2DHMMisgenerally\n",
      "usefulforfurtherapplicationsinlow-levelvisionproblems.\n",
      "1\n",
      "Introduction\n",
      "Texturelearningandsynthesisareimportanttasksincomputervisionand\n",
      "graphics.Recentattemptscanbecategorizedintotwotstyles.The\n",
      "styleemphasizesthemodelingandunderstandingproblemsanddevelops\n",
      "statisticalmodels[1,2]whicharecapableofrepresentingtextureusingtextons\n",
      "andtheirspatiallayout.Butthelearningisrathersensitivetotheparameter\n",
      "settingsandtherenderingqualityandspeedisstillnotsatisfactory.Thesecond\n",
      "stylereliesonpatch-basedrenderingtechniques[3,4]whichfocusonrendering\n",
      "qualityandspeed,butforegothesemanticunderstandingandmodelingoftex-\n",
      "ture.Thispaperaimsattextureunderstandingandmodelingwithfastsynthesis\n",
      "andhighrenderingquality.Ourstrategyistoaugmentthepatch-basedrender-\n",
      "ingmethod[3]withnonparametricBayesianmodelingandstatisticallearning.\n",
      "Werepresentatextureimagebya2DHiddenMarkovModel(2D-HMM)(see\n",
      "(1))wherethehiddenstatescorrespondtotheclusterlabelingoftextons\n",
      "andthetransitionmatrixencodesthetextonspatiallayout(thecompatibil-\n",
      "itybetweenadjacenttextons).The2D-HMMiscoupledwiththeHierarchical\n",
      "Dirichletprocess(HDP)[5,6]whichallowsthenumberoftextons(i.e.hidden\n",
      "states)andthecomplexityofthetransitionmatrixtogrowasmoretraining\n",
      "dataisavailableortherandomnessoftheinputtexturebecomeslarge.The\n",
      "Dirichletprocesspriorpenalizesthemodelcomplexitytofavorreusingclusters\n",
      "andtransitionsandthusregulartexturewhichcanberepresentedbycompact\n",
      "models.Thisframework(HDP-2DHMM)discoversthesemanticmeaningof\n",
      "textureinanexplicitwaythatthetextonvocabularyandtheirspatiallayout\n",
      "arelearntjointlyandautomatically(thenumberoftextonsisfullydetermined\n",
      "byHDP-2DHMM).Oncethetextonvocabularyandthetransitionmatrixare\n",
      "learnt,thesynthesisprocesssamplesthelatenttextonlabelingmapaccording\n",
      "totheprobabilityencodedinthetransitionmatrix.The1\n",
      "Figure1:Thewchartoftexturelearningandsynthesis.Thecolored\n",
      "rectanglescorrespondtotheindex(labeling)oftextonswhicharerepresented\n",
      "byimagepatches.Thetextonvocabularyshowsthecorrespondencebetweenthe\n",
      "color(states)andtheexamplesofimagepatches.Thetransitionmatricesshow\n",
      "theprobability(indicatedbytheintensity)ofgeneratinganewstate(coded\n",
      "bythecolorofthetopleftcornerrectangle),giventhestatesoftheleftand\n",
      "upperneighbornodes(codedbythetopandleft-mostrectangles).Theinferred\n",
      "textonmapshowsthestateassignmentsoftheinputtexture.Thetop-right\n",
      "panelshowsthesampledtextonmapaccordingtothetransitionmatrices.The\n",
      "lastpanelshowsthesynthesizedtextureusingimagequiltingaccordingtothe\n",
      "correspondencebetweenthesampledtextonmapandthetextonvocabulary.\n",
      "imageisthengeneratedbyselectingtheimagepatchesbasedonthesampled\n",
      "textonlabelingmap.Here,imagequilting[3]isappliedtosearchandstitch\n",
      "2\n",
      "\n",
      "togetherallthepatchessothattheboundaryinconsistencyisminimized.By\n",
      "contrastto[3],ourmethodisonlyrequiredtosearchamuchsmallersetof\n",
      "candidatepatcheswithinalocaltextoncluster.Therefore,thesynthesiscost\n",
      "isdramaticallyreduced.WeshowthattheHDP-2DHMMisabletosynthesize\n",
      "textureinonesecond(25timesfasterthanimagequilting)withcomparable\n",
      "quality.Inaddition,theHDP-2DHMMislesssensitivetothepatchsizewhich\n",
      "hastobetunedovertinputimagesin[3].Wealsoshowthatthe\n",
      "HDP-2DHMMcanbeappliedtoperformimagesegmentationandsynthesis.\n",
      "ThepreliminaryresultssuggestthattheHDP-2DHMMisgenerallyusefulfor\n",
      "furtherapplicationsinlow-levelvisionproblems.\n",
      "2\n",
      "PreviousWork\n",
      "Ourprimaryinterestistextureunderstandingandmodeling.TheFRAME\n",
      "model[7]providesaprincipledwaytolearnMarkovrandommodelsaccord-\n",
      "ingtothemarginalimagestatistics.Thismodelisverysuccessfulincapturing\n",
      "stochastictextures,butmayfailformorestructuredtexturesduetolackof\n",
      "spatialmodeling.Zhuetal.[1,2]extendittoexplicitlylearnthetextonsand\n",
      "theirspatialrelationswhicharerepresentedbyextrahiddenlayers.Thisnew\n",
      "modelisparametric(thenumberoftextonclustershastobetunedbyhand\n",
      "forttextureimages)andmodelselectionwhichmightbeunstablein\n",
      "practice,isneededtoavoidovTherefore,thelearningissensitiveto\n",
      "theparametersettings.Inspiredbyrecentprogressinmachinelearning,we\n",
      "extendthenonparametricBayesianframeworkofcoupling1DHMMandHDP\n",
      "[6]todealwith2Dtextureimage.Anewmodel(HDP-2DHMM)isdeveloped\n",
      "tolearntextonvocabularyandspatiallayoutsjointlyandautomatically.Since\n",
      "theHDP-2DHMMisdesignedtogenerateappropriateimagestatistics,butnot\n",
      "pixelintensity,apatch-basedtexturesynthesistechnique,calledimagequilting\n",
      "[3],isintegratedintooursystemtosampleimagepatches.Thetexturesynthesis\n",
      "algorithmhasalsobeenappliedtoimageinpainting[8].2\n",
      "?\n",
      "?'\n",
      "?\n",
      "?\n",
      "z1\n",
      "z2x2\n",
      "x1z4\n",
      "z3?\n",
      "?z\n",
      "?\n",
      "...\n",
      "x4\n",
      "x3...\n",
      "...\n",
      "Figure2:GraphicalrepresentationoftheHDP-2DHMM.?,?0,?are\n",
      "hyperparameterssetbyhand.?arestateparameters.?and?areemission\n",
      "andtransitionparameters,respectively.iistheindexofnodesinHMM.L(i)\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andT(i)aretwonodesontheleftandtopofnodei.ziarehiddenstatesof\n",
      "nodei.xiareobservations(features)oftheimagepatchatpositioni.\n",
      "...\n",
      "Maliketal.[9,10]andVarmaandZisserman[11]studytherepresen-\n",
      "tationsoftextonswhicharerelatedtoourimplementationsofvisualfeatures.\n",
      "Buttheinteractionsbetweentextonsarenotexplicitlyconsidered.Liuetal.\n",
      "[12,13]addresstextureunderstandingbydiscoveringregularitywithoutexplicit\n",
      "statisticaltexturemodeling.Ourworkhaspartialsimilaritieswiththeepitome\n",
      "[14]andjigsaw[15]modelsfornon-textureimageswhichalsotendtomodel\n",
      "appearanceandspatiallayoutsjointly.Themajoristhattheirmod-\n",
      "els,whichareparametric,cannotgrowautomaticallyasmoredataisavailable.\n",
      "Ourmethodiscloselyrelatedto[16]whichisnotdesignedfortexturelearning.\n",
      "TheyusehierarchicalDirichletprocess,butthemodelsandtheimagefeature\n",
      "representations,includingboththeimageandthedatalikelihoodmodel,\n",
      "aret.Thestructureof2DHMMisalsodiscussedin[17].Otherwork\n",
      "usingDirichletpriorincludes[18,19].Tree-structuredvectorquantization[20]\n",
      "hasbeenusedtospeedupexistingimage-basedrenderingalgorithms.While\n",
      "thisisorthogonaltoourwork,itmayhelpusoptimizetherenderingspeed.\n",
      "Themeaningof?nonparametric?inthispaperisunderthecontextofBayesian\n",
      "frameworkwhichfromthenon-Bayesianterminologyusedin[4].\n",
      "3TextureModeling3.1ImagePatchesandFeaturesAtextureimageIis\n",
      "representedbyagridofimagepatches\n",
      "f\n",
      "xi\n",
      "g\n",
      "withsizeof24?24inthispaper\n",
      "whereidenotesthelocation.\n",
      "f\n",
      "xi\n",
      "g\n",
      "willbegroupedintottextonsby\n",
      "theHDP-2DHMM.Webeginwithamodelwherethepositionsof\n",
      "textonsrepresentedbyimagepatchesarepre-determinedbytheimagegrid,\n",
      "andnotallowedtoshift.Wewillremovethisconstraintlater.Eachpatchxiis\n",
      "characterizedbyasetofresponses\n",
      "f\n",
      "wil,h,b\n",
      "g\n",
      "whichcorrespondtovalues\n",
      "bofimageresponsehatlocationl.Moreprecisely,eachpatchisdivided\n",
      "into6by6cells(i.e.l=1..36)eachofwhichcontains4by4pixels.Foreach\n",
      "pixelincelll,wecalculate37(h=1..37)imageresponseswhichinclude\n",
      "the17usedin[21],ofGaussian(DOG,4of\n",
      "Gaussian(DOOG,12)andcolors(R,G,BandL).wil,h,bequals\n",
      "oneiftheaveragedvalueofresponsesofthe4*4pixelscoveredbycelll\n",
      "fallsintobinb(theresponsevaluesaredividedinto6bins),andzerootherwise.\n",
      "Therefore,eachpatchxiisrepresentedby7992(=37?36?6)dimensional\n",
      "featureresponses\n",
      "f\n",
      "wil,h,b\n",
      "g\n",
      "intotal.Weletq=1..7992denotetheindex\n",
      "oftheresponsesofvisualfeatures.Itisworthemphasizingthatourfeature\n",
      "representationfromstandardmethods[10,2]wherek-meansclustering\n",
      "isappliedtoformvisualvocabularyBycontrast,weskiptheclustering\n",
      "stepandleavethelearningoftextonvocabularytogetherwithspatiallayout\n",
      "learningintotheHDP2DHMMwhichtakesovertheroleofk-means.3.2HDP-\n",
      "2DHMM:CouplingHiddenMarkovModelwithHierarchicalDirichletProcess\n",
      "Atextureismodeledbya2DHiddenMarkovModel(2DHMM)wherethe\n",
      "nodescorrespondtotheimagepatchesxiandthecompatibilityisencodedby\n",
      "theedgesconnecting4neighboringnodes.Seethegraphicalrepresentationof\n",
      "2DHMMin2.Foranynodei,letL(i),T(i),R(i),D(i)denotethefour\n",
      "4\n",
      "\n",
      "neighbors,left,upper,rightandlower,respectively.Weusezitoindexthe\n",
      "states3\n",
      "???GEM(?)?Foreachstatez?\n",
      "f\n",
      "1,2,3,...\n",
      "g\n",
      "??z?Dirichlet(?)??zL\n",
      "?DP(?0,?)??zT?DP(?0,?)?Foreachpairofstates(zL,zT)??zL\n",
      ",zT?DP(?0,?)?ForeachnodeiintheHMM?ifL(i)6=?andT(i)6=\n",
      "?:zi|(zL(i),zT(i))?Multinomial(?zL,zT)?ifL(i)6=?andT(i)=?:\n",
      "zi|zL(i)?Multinomial(?zL)?ifL(i)=?andT(i)6=?:zi|zT(i)?M\n",
      "ultinomial(?zT)?xi?Multinomial(?zi)\n",
      "Figure3:HDP-2DHMMfortexturemodelingofnodeiwhichcorrespondto\n",
      "theclusterlabelingoftextons.Thelikelihoodmodelp(xi|zi)whichsp\n",
      "theprobabilityofvisualfeturesisbymultinomialdistributionparame-\n",
      "terizedby?zisptoitscorrespondinghiddenstatezi:xi?Multinomial(?zi\n",
      ")\n",
      "(1)\n",
      "where?zispecifytheweightsofvisualfeatures.Fornodeiwhichisconnected\n",
      "tothenodesaboveandontheleft(i.e.L(i)6=?andT(i)6=?),theprobability\n",
      "p(zi|zL(i),zT(i))ofitsstateziisonlydeterminedbythestates(zL(i),\n",
      "zT(i))oftheconnectednodes.Thedistributionhasaformofmultinomial\n",
      "distributionparameterizedby?zL(i),zT(i):zi?Multinomial(?zL(i),zT(i))\n",
      "(2)\n",
      "where?zL(i),zT(i)encodesthetransitionmatrixandthusthespatiallayout\n",
      "oftextons.Forthenodeswhichareonthetoprowortheleft-mostcolumn\n",
      "(i.e.L(i)=?orT(i)=?),thedistributionoftheirstatesaremodeledbyM\n",
      "ultinomial(?zL(i))orMultinomial(?zT(i))whichcanbeconsideredassimpler\n",
      "cases.Weassumethetopleftcornercanbesampledfromanystatesaccording\n",
      "tothemarginalstatisticsofstates.Withoutlossofgenerality,wewillskipthe\n",
      "detailsoftheboundarycases,butonlyfocusonthenodeswhosestatesshould\n",
      "bedeterminedbytheirtopandleftnodesjointly.Tomakeanonparametric\n",
      "Bayesianrepresentation,weneedtoallowthenumberofstateszicountably\n",
      "andputpriordistributionsovertheparameters?ziand?zL(i),zT(i)\n",
      ".Wecanachievethisbytyingthe2DHMMtogetherwiththehierarchical\n",
      "Dirichletprocess[5].Wethepriorof?zasaconjugateDirichletprior:\n",
      "?z?Dirichlet(?)\n",
      "(3)\n",
      "where?istheconcentrationhyperparameterwhichcontrolshowuniformthe\n",
      "distributionof?zis(note?zspecifyweightsofvisualfeatures):as?increases,\n",
      "itbecomesmorelikelythatthevisualfeatureshaveequalprobability.Sincethe\n",
      "likelihoodmodelp(xi|zi)isofmultinomialform,theposteriordistributionof\n",
      "?zhasaanalyticform,stillaDirichletdistribtion.Thetransitionparameters\n",
      "?zL,zTaremodeledbyahierarchicalDirichletprocess(HDP):??GEM(?)0\n",
      "?zL,zT?DP(?,?)\n",
      "(4)(5)\n",
      "wherewedrawglobalweights?accordingtothestick-breakingprior\n",
      "distributionGEM(?).Thestick-breakingweights?specifytheprobability\n",
      "ofstatewhicharegloballysharedamongallnodes.Thestick-breakingprior\n",
      "producesexponentiallydecayedweightsinexpectationsuchthatsimplemodels\n",
      "5\n",
      "\n",
      "withlessrepresentativeclusters(textons)arefavored,givenfewobservations,\n",
      "but,thereisalwaysalow-probabilitythatsmallclustersarecreatedtocapture\n",
      "detailsrevealedbylarge,complextextures.Theconcentrationhyperparameter\n",
      "?controlsthesparsenessofstates:alarger?leadstomorestates.Theprior\n",
      "ofthetransitionparameter?zL,zTismodeledbyaDirichlet4\n",
      "processDP(?0,?)whichisadistributionovertheotherdistribution?.?0is\n",
      "ahyperparameterwhichcontrolsthevariabilityof?zL,zTovertstates\n",
      "acrossallnodes:as?0increases,thestatetransitionsbecomemoreregular.\n",
      "Therefore,theHDPmakesuseofaDirichletprocesspriortoplaceasoftbias\n",
      "towardssimplermodels(intermsofthenumberofstatesandtheregularity\n",
      "ofstatetransitions)whichexplainthetexture.Thegenerativeprocessofthe\n",
      "HDP-2DHMMisdescribedin(3).Wenowhavethefullrepresentationof\n",
      "theHDP-2DHMM.Butthismodeldoesnotallowthetextons(image\n",
      "patches)tobeshifted.Weremovethisconstraintbyintroducingtwohidden\n",
      "variables(ui,vi)whichindicatethedisplacementsoftextonsassociatedwith\n",
      "nodei.Weonlyneedtoadjustthecorrespondencebetweenimagefeaturesxi\n",
      "andhiddenstateszi.xiismoedtobexui,viwhichreferstoimagefeatures\n",
      "locatedatthepositionwithdisplacementof(ui,vi)tothepositioni.Random\n",
      "variables(ui,vi)areonlyconnectedtotheobservationxi(notshownin\n",
      "2).(ui,vi)haveauniformprior,butarelimitedtothesmallneighborhoodof\n",
      "i(maximum10%shiftononeside).\n",
      "4LearningHDP-2DHMMInaBayesianframework,thetaskoflearning\n",
      "HDP-2DHMM(alsocalledBayesianinference)istocomputetheposteriordis-\n",
      "tributionp(?,?,z|x).Itistrivialtosamplethehiddenvariables(u,v)because\n",
      "oftheiruniformprior.Forsimplicity,weskipthedetailsofsamplingu,v.Here,\n",
      "wepresentaninferenceprocedurefortheHDP-2DHMMthatisbasedonGibbs\n",
      "sampling.Ourprocedurealternatesbetweentwosamplingstages:(i)sampling\n",
      "thestateassignmentsz,(ii)samplingtheglobalweights?.Givenvalues\n",
      "forz,?,theposteriorof?canbeeasilyobtainedbyaggregatingstatisticsofthe\n",
      "observationsassignedtoeachstate.Theposteriorof?isDirichlet.Formore\n",
      "detailsonDirichletprocesses,see[5].Weinstantiatearandomhiddenstate\n",
      "labelingandtheniterativelyrepeatthefollowingtwosteps.Samplingz.Inthis\n",
      "stagewesampleastateforeachnode.Theprobabilityofnodeibeingassigned\n",
      "statetisgivenby:P(zi=t|z?i,?)?ft?xi(xi)P(zi=t|zL(i),zT(i))\n",
      "?P(zR(i)|zi=t,zT(R(i)))P(zD(i)|zL(D(i)),zi=t)\n",
      "(6)\n",
      "Thetermft?xi(xi)denotestheposteriorprobabilityofobservation\n",
      "xigivenallotherobservationsassignedtostatet,andz?idenotesallstate\n",
      "assignmentsexceptzi.Letnqtbethenumberofobservationsoffeaturewq\n",
      "withstatet.ft?xi(xi)iscalculatedby:ft?xi(xi)=\n",
      "Y(Pq\n",
      "qnqt+?qP)wi00q0nqt+q0?q\n",
      "(7)\n",
      "where?qistheweightforvisualfeaturewq.ThenexttermP(zi=t|zL(i)\n",
      "=r,zT(i)=s)istheprobabilityofstateoft,giventhestatesofthenodeson\n",
      "theleftandabove,i.e.L(i)andT(i).Letnrstbethenumberofobservations\n",
      "6\n",
      "\n",
      "withstatetwhosetheleftandupperneighbornodes?statesarerforL(i)and\n",
      "sforT(i).Theprobabilityofgeneratingstatetisgivenby:nrst+?0?tP(zi\n",
      "=t|zL(i)=r,zT(i)=s)=P0t0nrst0+?\n",
      "(8)\n",
      "where?treferstotheweightofstatet.Thiscalculationfollowstheproperties\n",
      "ofDirichletdistribution[5].ThelasttwotermsP(zR(i)|zi=t,zT(R(i)))\n",
      "andP(zD(i)|zL(D(i)),zi=t)aretheprobabilityofthestatesoftherightand\n",
      "lowerneighbornodes(R(i),D(i))givenzi.Thesetwotermscanbecomputed\n",
      "inasimilarformasequation(8).Sampling?.Inthesecondstage,giventhe\n",
      "assignmentsz=\n",
      "f\n",
      "zi\n",
      "g\n",
      ",wesample?usingtheDirichletdistributionasdescribed\n",
      "in[5].5\n",
      "Figure4:Thecolorofrectanglesincolumns2and3correspondtotheindex\n",
      "(labeling)oftextonswhicharerepresentedby24*24imagepatches.Thesyn-\n",
      "thesizedimagesareall384*384(16*16textons/patches).Ourmethodcaptures\n",
      "bothstochastictextures(thelasttworows)andmorestructuredtextures(the\n",
      "threerows,seethehorizontalandgridedlayouts).Theinferredtexton\n",
      "mapsforstructuredtexturesaresimpler(lessstates/textons)andmoreregular\n",
      "(lessclutteredtextonmaps)thanstochastictextures.\n",
      "5\n",
      "TextureSynthesis\n",
      "Oncethetextonvocabularyandthetransitionmatrixarelearnt,thesyn-\n",
      "thesisprocesssamplesthelatenttextonlabelingmapaccordingtothe\n",
      "probabilityencodedinthetransitionmatrix.ButtheHDP-2DHMMisgener-\n",
      "ativeonlyforimagefeatures,butnotimageintensity.Tomakeitpracticalfor\n",
      "imagesynthesis,imagequilting[3]isintegratedwiththeHDP-2DHMM.The\n",
      "imageisthengeneratedbyselectingimagepatchesaccordingtothetexton\n",
      "labelingmap.Imagequiltingisappliedtoselectandstitchtogetherallthe\n",
      "patchesinatop-left-to-bottom-rightordersothattheboundaryinconsistency\n",
      "isminimized.Thewidthoftheoverlapedgeis8pixels.Bycontrastto[3]\n",
      "whichneedtosearchoverallimagepatchestoensurehighrenderingquality,\n",
      "ourmethodisonlyrequiredtosearchthecandidatepatcheswithinalocalclus-\n",
      "ter.TheHDP-2DHMMiscapableofproducinghighrenderingqualitybecause\n",
      "thepatcheshavebeengroupedbasedonvisualfeatures.Therefore,thesyn-\n",
      "thesiscostisdramaticallyreduced.WeshowthattheHDP-2DHMMisableto\n",
      "synthesizea6\n",
      "Figure5:Moresynthesizedtextureimages(foreachpair,leftisinputtex-\n",
      "ture,rightissynthesized).textureimagewithsizeof384*384andwithcompa-\n",
      "rablequalityinonesecond(25timesfasterthanimagequilting).\n",
      "6ExperimentalResults6.1TextureLearningandSynthesisWeusethetex-\n",
      "tureimagesin[3].Thehyperparameters\n",
      "f\n",
      "?,?0,?\n",
      "g\n",
      "aresetto10,1,and0.5,\n",
      "respectively.Theimagepatchsizeisto24*24.Alltheparametersettings\n",
      "areidenticalforallimages.Thelearningrunswith10randominitializations\n",
      "eachofwhichtakesabout30samplingiterationstoconverge.Acomputerwith\n",
      "2.4GHzCPUwasused.Foreachimage,ittakes100secondsforlearningand\n",
      "1secondforsynthesis(almost25timesfasterthan[3]).Figure(4)showsthe\n",
      "inferredtextonlabelingmaps,thesampledtextonmapsandthesynthesized\n",
      "7\n",
      "\n",
      "textureimages.Moresynthesizedimagesareshownin(5).Theren-\n",
      "deringqualityisvisuallycomparablewith[3](notshown)forbothstructured\n",
      "texturesandstochastictextures.ItisinterestingtoseethattheHMM-HDP\n",
      "capturesttypesoftexturepatterns,suchasvertical,horizontaland\n",
      "gridedlayouts.Itsuggeststhatourmethodisabletodiscoverthesemantic\n",
      "texturemeaningbylearningtextonvocabularyandtheirspatialrelations.7\n",
      "Figure6:\n",
      "Imagesegmentationandsynthesis.ThethreerowsshowtheHDP-\n",
      "2DHMMisabletosegmentimageswithmixtureoftexturesandsynthesizenew\n",
      "textures.Thelastrowshowsafailureexamplewherethetextonisnotwell\n",
      "aligned.\n",
      "6.2\n",
      "ImageSegmentationandSynthesis\n",
      "WealsoapplytheHDP-2DHMMtoperformimagesegmentationandsynthe-\n",
      "sis.Figure(6)showsseveralexamplesofnaturalimageswhichcontainmixture\n",
      "oftexturedregions.Thesegmentationresultsarerepresentedbytheinferred\n",
      "stateassignments(thetextonmap).Ingure(6),onecanseethatourmethod\n",
      "successfullydividesimagesintomeaningfulregionsandthesynthesizedimages\n",
      "lookvisuallysimilartotheinputimages.TheseresultssuggestthattheHDP-\n",
      "2DHMMframeworkisgenerallyusefulforlow-levelvisionproblems.Thelast\n",
      "rowin(6)showsafailureexamplewherethetextonisnotwellaligned.\n",
      "7\n",
      "Conclusion\n",
      "ThispaperdescribesanovelnonparametricBayesianmethodfortextrure\n",
      "learningandsynthesis.The2DHiddenMarkovModel(HMM)iscoupledwith\n",
      "thehierarchicalDirichletprocess(HDP)whichallowsthenumberoftextons\n",
      "andthecomplexityoftransitionmatrixgrowsastheinputtexturebecomes\n",
      "irregular.TheHDPmakesuseofDirichletprocesspriorwhichfavorsregular\n",
      "texturesbypenalizingthemodelcomplexity.Thisframework(HDP-2DHMM)\n",
      "learnsthetextonvocabularyandtheirspatiallayoutjointlyandautomatically.\n",
      "Wedemonstratedthattheresultingcompactrepresentationobtainedbythe\n",
      "HDP-2DHMMallowsfasttexturesynthesis(underonesecond)withcomparable\n",
      "renderingqualitytothestate-of-the-artimage-basedrenderingmethods.Our\n",
      "resultsonimagesegmentationandsynthesissuggestthattheHDP-2DHMMis\n",
      "generallyusefulforfurtherapplicationsinlow-levelvisionproblems.Acknowl-\n",
      "edgments.ThisworkwassupportedbyNGANEGI-1582-04-0004,MURIGrant\n",
      "N0001406-1-0734,ARDAVACE,andgiftsfromMicrosoftResearchandGoogle.\n",
      "Thankstotheanonymousreviewersforhelpfulfeedback.8\n",
      "2References\n",
      "[1]Y.N.Wu,S.C.Zhu,andC.-e.Guo,?Statisticalmodelingoftexturesketch,?\n",
      "inECCV?02:Proceedingsofthe7thEuropeanConferenceonComputerVision-\n",
      "PartIII,2002,pp.240?254.[2]S.-C.Zhu,C.-E.Guo,Y.Wang,andZ.Xu,\n",
      "?Whataretextons??InternationalJournalofComputerVision,vol.62,no.\n",
      "8\n",
      "\n",
      "1-2,pp.121?143,2005.[3]A.A.EfrosandW.T.Freeman,?Imagequilting\n",
      "fortexturesynthesisandtransfer,?inSiggraph,2001.[4]A.EfrosandT.\n",
      "Leung,?Texturesynthesisbynon-parametricsampling,?inInternationalCon-\n",
      "ferenceonComputerVision,1999,pp.1033?1038.[5]Y.W.Teh,M.I.Jordan,\n",
      "M.J.Beal,andD.M.Blei,?Hierarchicaldirichletprocesses,?Journalofthe\n",
      "AmericanStatisticalAssociation,2006.[6]M.J.Beal,Z.Ghahramani,andC.\n",
      "E.Rasmussen,?Thehiddenmarkovmodel,?inNIPS,2002.[7]S.C.\n",
      "Zhu,Y.Wu,andD.Mumford,?Filters,randomandmaximumentropy\n",
      "(frame):Towardsautheoryfortexturemodeling,?InternationalJournal\n",
      "ofComputerVision,vol.27,pp.1?20,1998.[8]A.Criminisi,P.Perez,and\n",
      "K.Toyama,?Regionandobjectremovalbyexemplar-basedinpainting,?\n",
      "IEEETrans.onImageProcessing,2004.[9]J.Malik,S.Belongie,J.Shi,and\n",
      "T.Leung,?Textons,contoursandregions:Cueintegrationinimagesegmenta-\n",
      "tion,?IEEEInternationalConferenceonComputerVision,vol.2,1999.[10]\n",
      "T.LeungandJ.Malik,?Representingandrecognizingthevisualappearanceof\n",
      "materialsusingthree-dimensionaltextons,?InternationalJournalofComputer\n",
      "Vision,vol.43,pp.29?44,2001.[11]M.VarmaandA.Zisserman,?Texture\n",
      "Arebanksnecessary??IEEEComputerSocietyConfer-\n",
      "enceonComputerVisionandPatternRecognition,vol.2,2003.[12]Y.Liu,\n",
      "W.-C.Lin,andJ.H.Hays,?Nearregulartextureanalysisandmanipulation,?\n",
      "ACMTransactionsonGraphics(SIGGRAPH2004),vol.23,no.1,pp.368\n",
      "?376,August2004.[13]J.Hays,M.Leordeanu,A.A.Efros,andY.Liu,\n",
      "?Discoveringtextureregularityasahigherordercorrespondenceproblem,?in\n",
      "9thEuropeanConferenceonComputerVision,May2006.[14]N.Jojic,B.\n",
      "J.Frey,andA.Kannan,?Epitomicanalysisofappearanceandshape,?inIn\n",
      "ICCV,2003,pp.34?41.[15]A.Kannan,J.Winn,andC.Rother,?Clustering\n",
      "appearanceandshapebylearningjigsaws,?inInAdvancesinNeuralInforma-\n",
      "tionProcessingSystems.MITPress,2007.[16]J.J.Kivinen,E.B.Sudderth,\n",
      "andM.I.Jordan,?Learningmultiscalerepresentationsofnaturalscenesusing\n",
      "dirichletprocesses,?IEEEInternationalConferenceonComputerVision,vol.\n",
      "0,2007.[17]J.Domke,A.Karapurkar,andY.Aloimonos,?Whokilledthe\n",
      "directedmodel??inIEEEComputerSocietyConferenceonComputerVision\n",
      "andPatternRecognition,2008.[18]L.CaoandL.Fei-Fei,?Spatiallycoherent\n",
      "latenttopicmodelforconcurrentobjectsegmentationandin\n",
      "ProceedingsofIEEEInternationalConferenceonComputerVision,2007.[19]\n",
      "X.WangandE.Grimson,?Spatiallatentdirichletallocation,?inNIPS,2007.\n",
      "[20]L.-Y.WeiandM.Levoy,?Fasttexturesynthesisusingtree-structuredvector\n",
      "quantization,?inSIGGRAPH?00:Proceedingsofthe27thannualconference\n",
      "onComputergraphicsandinteractivetechniques,2000,pp.479?488.[21]J.\n",
      "Winn,A.Criminisi,andT.Minka,?Objectcategorizationbylearneduniversal\n",
      "visualdictionary,?inProceedingsoftheTenthIEEEInternationalConference\n",
      "onComputerVision,2005.\n",
      "9\n",
      "9\n",
      "\n",
      "PP4734.pdf\n",
      "PP4734.pdf 11\n",
      "DecisionMakingforAdaptivek-Nearest\n",
      "Neighbor\n",
      "Authoredby:\n",
      "DanielD.Lee\n",
      "Yung-kyunNoh\n",
      "FrankPark\n",
      "Abstract\n",
      "Thispapershedslightonsomefundamentalconnectionsofthe\n",
      "siondecisionmakingmodelofneuroscienceandcognitivepsychologywith\n",
      "k-nearestneighborWeshowthatconventionalk-nearest\n",
      "neighborcanbeviewedasaspecialproblemofthe\n",
      "siondecisionmodelintheasymptoticsituation.Applyingtheoptimal\n",
      "strategyassociatedwiththedecisionmodel,anadaptiveruleis\n",
      "developedfordeterminingappropriatevaluesofkink-nearestneighbor\n",
      "Makinguseofthesequentialprobabilityratiotest(SPRT)\n",
      "andBayesiananalysis,weproposeentcriteriaforadaptively\n",
      "acquiringnearestneighbors.Experimentswithbothsyntheticandreal\n",
      "datasetsdemonstratetheofourcriteria.\n",
      "1PaperBody\n",
      "Therecentinterestinunderstandinghumanperceptionandbehaviorfromthe\n",
      "perspectiveofneuroscienceandcognitivepsychologyhasspurredarevivalof\n",
      "interestinmathematicaldecisiontheory.Oneofthestandardinterpretations\n",
      "ofthistheoryisthatwhenthereisacontinuousinputofnoisyinformation,a\n",
      "decisionbecomescertainonlyafteraccumulatingtinformation.Itis\n",
      "alsotypicallyunderstoodthatearlydecisionssaveresources.Amongthemany\n",
      "theoreticalexplanationsforthisphenomenon,thedecisionmodelrs\n",
      "aparticularlyappealingexplanationofhowinformationisaccumulatedandhow\n",
      "thetimeinvolvedinmakingadecisionoverallaccuracy.The\n",
      "decisionmodelconsiderstheofaccumulatedevidencetowardoneof\n",
      "thecompetingchoices,andreachesadecisionwhentheevidencemeetsapre-\n",
      "level.Thedecisionmodelsuccessfullyexplainsthe\n",
      "distributionofdecisiontimesforhumans[13,14,15].Morerecently,thismodel\n",
      "acompellingexplanationoftheneuronaldecisionmakingprocessinthe\n",
      "lateralintraparietal(LIP)areaofthebrainforperceptualdecisionmakingbased\n",
      "1\n",
      "\n",
      "onvisualevidence[2,11,16].Thefundamentalpremisebehindthismodelis\n",
      "thatthereisabetweendecisiontimesandaccuracy,andthatbothare\n",
      "controlledbythelevel.AsdescribedinBogaczetal[3],thesequential\n",
      "probabilityratiotest(SPRT)isonemathematicalmodelthatexplainsthis\n",
      "MorerecentstudiesalsodemonstratehowSPRTcanbeusedtoexplain\n",
      "theevidenceasemanatedfromPoissonprocesses[6,21].Nowshiftingour\n",
      "attentiontomachinelearning,thewell-knownk-nearestneighborclasscation\n",
      "usesasimplemajorityvotingstrategythat,atleastintheasymptoticcase,\n",
      "implicitlyinvolvesasimilarbetweentimeandaccuracy.Accordingto\n",
      "CoverandHart[4],theexpectedaccuracyofk-nearestneighbor\n",
      "alwaysincreaseswithrespecttokwhenthereistdata.Atthesame\n",
      "time,thereisanaturalpreferencetouselessresources,orequivalently,afewer\n",
      "numberofnearestneighbors.Ifoneseekstomaximizetheaccuracyforagiven\n",
      "numberoftotalnearestneigh1\n",
      "Figure1:decisionmodel.Theevidenceofdecisionmakingisaccu-\n",
      "mulated,anditovertime(totheright).Oncetheaccumulatedevidence\n",
      "reachesoneofthelevelsofeitherchoice,zor?z,themodelstops\n",
      "collectinganymoreevidenceandmakesadecision.bors,thisnaturallyleadsto\n",
      "theideaofusingtksfortdata.Atacertainlevel,thisadaptive\n",
      "ideacanbeanticipated,butmethodsdescribedintheexistingliteratureare\n",
      "almostexclusivelyheuristic-based,withoutathoroughunderstanding\n",
      "ofunderwhatsituationsheuristicsaree[1,12,19].Inthiswork,we\n",
      "presentasetofsimple,theoreticallysoundcriteriaforadaptivek-nearestneigh-\n",
      "borWeshowthattheconventionalmajorityvotingruleis\n",
      "identicaltothedecisionmodelwhenappliedtodatafromtwot\n",
      "Poissonprocesses.Dependingonhowtheaccumulatingevidenceisit\n",
      "ispossibletoconstructetcriteriabasedontstatisticaltests.\n",
      "First,wederivethreetcriteriausingtheSPRTstatisticaltest.Sec-\n",
      "ond,usingstandardBayesiananalysis,wederivetwoprobabilitiesforthecase\n",
      "whereonedensityfunctionisgreaterthantheother.Ourecriteriaarethen\n",
      "usedasevidence;oncetheevidenceexceedsacertainlevel,\n",
      "collectionofinformationcanceaseandadecisioncanbemadeimmediately.\n",
      "Despitethecomplexityofthederivationsinvolved,theresultingecriteria\n",
      "haveaparticularlysimpleandappealingform.Thisfeaturecanbetracedto\n",
      "thememorylesspropertyofPoissonprocesses.Inparticular,allcriteriacanbe\n",
      "castasafunctionoftheinformationofonlyonenearestneighborineachclass.\n",
      "Usingourderivation,weconsiderthispropertytobetheresultoftheassump-\n",
      "tionthatwehavetdata;thecriteriaarenotguaranteedtoworkinthe\n",
      "eventthatthereistdata.Wepresentexperimentalresultsinvolving\n",
      "realandsyntheticdatatoverifythisconjecture.Theremainderofthepaper\n",
      "isorganizedasfollows.InSection2,aparticularformofthedusiondecision\n",
      "modelisreviewedforPoissonprocesses,andtwosimpletestsbasedonSPRT\n",
      "arederived.Therelationshipbetweenk-nearestneighboranddif-\n",
      "fusiondecisionmakingisexplainedinSection3.InSection4,wedescribethe\n",
      "adaptivek-nearestneighborprocedureintermsofthe\n",
      "decisionmodel,andweintroduceetcriteriawithinthiscontext.Ex-\n",
      "2\n",
      "\n",
      "perimentsforsyntheticandrealdatasetsarepresentedinSection5,andthe\n",
      "mainconclusionsaresummarizedinSection6.\n",
      "2\n",
      "DecisionModelforTwoPoissonProcesses\n",
      "Thedecisionmodelisastochasticmodelfordecisionmaking.The\n",
      "modelconsiderstheofanevidenceinfavorofeitheroftwopossible\n",
      "choicesbycontinuouslyaccumulatingtheinformation.Afterinitialwavering\n",
      "betweenthetwochoices,theevidencereachesalevelofwhere\n",
      "adecisionismadeasinFig.1.Inmathematicalmodelingofthis\n",
      "process,Gaussiannoisehasbeenpredominantlyusedasamodelforzigzagging\n",
      "uponaconstantdrifttowardachoice[3,13].However,whenweconsider\n",
      "twocompetingPoissonsignals,asimplerstatisticaltestcanbeusedinsteadof\n",
      "estimatingthedirectionofthedrift.Inthestudiesofdecisionmakinginthe\n",
      "lateralintraparietal(LIP)areaofthebrain[2,11],twoPoissonprocessesare\n",
      "assumedtohaverateparametersofeither?+and??whereweknowthat?+>\n",
      "??,butexactvaluesareunknown.WhenitshouldbedeterminedwhichPoisson\n",
      "processhasthelargerrate?+,asequentialprobabilityratiotest(SPRT)can\n",
      "beusedtoexplainadecisionmodel[6,21].2\n",
      "N\n",
      ")ThePoissondistributionweusehastheform:p(N|?,T)=(?TN!\n",
      "exp(??T),andweconsidertwoPoissondistributionsforN1andN2attimeT1\n",
      "andT2,respectively:p(N1|?1,T1)andp(N2|?2,T2).Here,?1and?2\n",
      "aretherateparameters,andeitheroftheseparametershas?+wheretheother\n",
      "has??.Now,weapplythestatisticaltestofWald[18]fora?(>1):\n",
      "p(N1|?1=?+)p(N2|?2=??)>?p(N1|?1=??)p(N2|?2=?+)\n",
      "or\n",
      "<\n",
      "1?\n",
      "(1)\n",
      "forthesituationwherethereisN1numberofsignalsattimeT1forthe\n",
      "PoissonprocessandN2numberofsignalsattimeT2forthesecondprocess.\n",
      "Wecandeterminethat?1hasthe?+oncethelefttermisgreaterthan?,\n",
      "and?2hasthe?+onceitisgreaterthan?1,otherwise,wemustcollectmore\n",
      "information.AccordingtoWaldandWolfowitz[18],thistestisoptimalinthat\n",
      "thetestrequiresthefewestaverageobservationswiththesameprobabilityof\n",
      "error.Bytakingthelogonbothsides,wecanrewritethetestas\n",
      "?+log(N1?N2)?(?+???)(T1?T2)>loga??<?loga.\n",
      "or\n",
      "(2)\n",
      "Consideringtwospecialsituations,thisequationcanbereducedintotwo\n",
      "t,simpletests.First,wecanconsiderobservationofthenumbersN1\n",
      "andN2atacertaintimeT=T1=T2.ThentestinEq.(2)isreducedinto\n",
      "onetestpreviouslyproposedin[21]:|N1?N2|>zN\n",
      "(3)\n",
      "log?.AnothersimpletestcanbemadebyusingthewherezNisaconstant\n",
      "satisfyingzN=log(?+/??)observationtimesT1andT2whenwethe\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samenumberofsignalsN=N1=N2:\n",
      "|T1?T2|>zTwherezTzT=\n",
      "(4)\n",
      "log??+???.\n",
      "Here,wecanconsider?N=N1?N2and?T=T1?T2astwot\n",
      "evidencesinthedecisionmodel.Theevidencesaswecollect\n",
      "moreinformation,andwecometomakeadecisiononcetheevidencereaches\n",
      "thelevels,?zNfor?N,and?zTfor?T.Inthiswork,werefertothe\n",
      "model,usingthecriterion?N,asthe?Nruleandthesecondmodel,using\n",
      "?T,asthe?Trule.Althoughthe?Nrulehasbeenpreviouslyderivedandused\n",
      "[21],wepropsefourmoretestcriteriainthispaperincludingEq.(4).Later,\n",
      "weshowthatthedecisionmakingwiththeseecriteriaisrelatedto\n",
      "tmethodsfork-nearestneighbor\n",
      "3\n",
      "EquivalenceofDecisionModelandk-NearestNeighbor\n",
      "tion\n",
      "Aconventionalk-nearestneighbor(k-NN)takesamajorityvot-\n",
      "ingstrategyusingknumberofnearestneighbors.AccordingtoCoverandHart\n",
      "[4],inthelimitofitesampling,thissimplemajorityvotingrulecanpro-\n",
      "duceafairlylowexpectederrorandfurthermore,thiserrordecreasesevenmore\n",
      "asabiggerkisused.Thistheoreticalresultisobtainedfromtherelationship\n",
      "betweenthek-NNerrorandtheoptimalBayeserror:theexpected\n",
      "errorwithonenearestneighborisalwayslessthantwicetheBayeserror,andthe\n",
      "errordecreaseswiththenumberofkasymptoticallytotheBayeserror[4].In\n",
      "thissituation,wecanclaimthatthek-NNactuallyperformsthe\n",
      "aforementioneddecisionmakingforPoissonprocesses.Theidentity\n",
      "comesfromtwoequivalencerelationships:thelogicalequivalencebetween\n",
      "twodecisionrules;second,theequivalenceofdistributionofnearestneighbors\n",
      "tothePoissondistributioninanasymptoticsituation.3.1\n",
      "EquivalentStrategyofMajorityVoting\n",
      "Here,weshowanequivalencebetweentheconventionalk-NN\n",
      "cationandanovelcomparisonalgorithm:3\n",
      "Theorem:Fortwo-classdata,weconsidertheN-thnearestdatumofeach\n",
      "classfromthetestingpoint.Withanoddnumberk,majorityvotingrulein\n",
      "k-NNisequivalenttotheruleofpickinguptheclasstowhicha\n",
      "datumwithsmallerdistancetothetestingpointbelongs,fork=2N?1.Proof:\n",
      "Amongk-NNsofatestpoint,iftherearemorethanorequaltoNdatahaving\n",
      "labelC,forC?\n",
      "f\n",
      "1,2\n",
      "g\n",
      ",thetestpointisasclassCaccordingtothe\n",
      "majorityvotingbecauseN=(k+1)/2>k2.Ifweconsiderthreedistancesdk\n",
      "tothek-thnearestneighboramongalldata,dN,CtotheN-thnearestneighbor\n",
      "inclassC,anddN,?CtotheN-thnearestneighborinclassnonC,thenboth\n",
      "dN,C?dkanddN,?C>dkareinthiscase.Thiscompletesonedirection\n",
      "ofproofthattheselectionofclassCbymajorityvotingimpliesdN,C<dN,?C.\n",
      "Theoppositedirectioncanbeprovedsimilarly.Therefore,insteadofcounting\n",
      "thenumberofnearestneighbors,wecanclassifyatestpointusingtwoseparate\n",
      "N-thnearestneighborsoftwoclassesandcomparingthedistances.Thislogical\n",
      "4\n",
      "\n",
      "equivalenceappliesregardlessoftheunderlyingdensityfunctions.3.2\n",
      "NearestneighborsasPoissonprocesses\n",
      "Therandomgenerationofdatafromaparticularunderlyingdensityfunction\n",
      "inducesadensityfunctionofdistancetothenearestneighbors.Whenthe\n",
      "densityfunctionis?(x)forx?RDandweconsideraD-dimensionalhypersphere\n",
      "ofvolumeVwithN-thnearestneighboronitssurface,arandomvariableu=\n",
      "MV,whichisthevolumeofthesphereVmultipliedbythenumberofdataM\n",
      ",asymptoticallyconvergesindistributiontotheErlangdensityfunction[10]:\n",
      "p(u|?)=\n",
      "?Nexp(??u)uN?1?(N)\n",
      "(5)\n",
      "withalargeamountofdata.Here,thevolumeelementisafunctionof\n",
      "distancedwhichcanbe?D/2representedasV=?dDand?=?(D/2+1)\n",
      ",aproportionalityconstantforahyperspherevolume.ThisErlangfunction\n",
      "isaspecialcaseoftheGammadensityfunctionwhentheparameterNisan\n",
      "integer.WecanalsonotethatthisErlangdensityfunctionimpliesthePoisson\n",
      "distributionwithrespecttoN[20],andwecanwritethedistributionofNas\n",
      "follows:p(N|?)=\n",
      "?Nexp(??).?(N+1)\n",
      "(6)\n",
      "Thisequationshowsthattheappearanceofnearestneighborscanbeapprox-\n",
      "imatedwithPoissonprocesses.Inotherwords,withagrowinghypersphereat\n",
      "aconstantrateinvolume,theoccurrenceofnewpointswithinahypersphere\n",
      "willfollowaPoissondistribution.ThisErlangfunctioninEq.(5)comesfrom\n",
      "theasymptoticconvergenceindistributionoftherealdistribution,thebino-\n",
      "mialdistributionwithNnumberofsamples[10].Here,wenotethat,\n",
      "withaitenumberofsamples,thememorylesspropertyofthePoissondisap-\n",
      "pears.Thisresultsinthebreakdownoftheindependencyassumptionbetween\n",
      "posteriorprobabilitiesforclasseswhichCoverandHartusedimplicitlywhen\n",
      "theyderivedtheexpectederrorofk-NN[4].Ontheotherhand,\n",
      "oncewehaveenoughdata,andhencethedensityfunctionsEq.(5)andEq.\n",
      "(6)explaindatacorrectly,wecanexpecttheequivalencebetweenthedusion\n",
      "decisionmakingandk-NNInthiscase,thenearestneighbors\n",
      "arethesamplesofaPoissonprocess,havingtherateparameter?,whichisthe\n",
      "probabilitydensityatthetestpoint.Now,wecanturnbacktotheconventional\n",
      "k-NNBytheorem1andtheargumentsinthissection,thek-NN\n",
      "strategyisthesameasthestrategyofcomparingtwoPoissonpro-\n",
      "cessesusingN-thsamplesofeachclass.Thisconnectionnaturallyexploitsthe\n",
      "conventionalk-NNtotheadaptivemethodofusingtks\n",
      "usingthelevelinthedecisionmodel.4\n",
      "4\n",
      "CriteriaforAdaptivek-NNClasscation\n",
      "Usingtheequivalencesettingsofthedecisionmodelandthek-\n",
      "NNwecanextendtheconventionalmajorityvotingstrategyto\n",
      "moresophisticatedadaptivestrategies.First,theSPRTcriteriaintheprevious\n",
      "section,?Nruleand?Trulecanbeused.Forthe?NruleinEq.(3),wecan\n",
      "5\n",
      "\n",
      "usethenumbersofnearestneighborsN1andN2withinadistanced,then\n",
      "compare|?N|=|N1?N2|withalevelzN.\n",
      "Insteadofmakinganimmediatedecision,wecancollectmorenearstneighbors\n",
      "byincreasingduntilEq.(3)issatised.Thisisthe??Nrule?foradaptivek-\n",
      "NNIntermsofthe?TruleinEq.(4),usingthecorrespondence\n",
      "oftimeintheoriginalSPRTtothevolumewithinthehypersphereink-NN\n",
      "wecanmaketwotcriteriaforadaptivek-NN\n",
      "First,weconsidertwovolumeelements,V1andV2ofN-thnearestneighbors,\n",
      "andthecriterioncanberewrittenas|V1?V2|>zV.Werefertothisruleas\n",
      "the??Vrule?.Additionalcriterionforthe?Truleconsidersamoreconservative\n",
      "ruleusingthevolumeof(N+1)thnearestneighborhypersphere.Sinceaslightly\n",
      "smallerhyperspherethanthishyperspherestillcontainsNnumberofnearest\n",
      "neighbors,wecanmakethesametestmoretostopbyreplacing\n",
      "thesmallervolumeinthe?Vrulewiththevolumeof(N+1)-thnearestneighbor\n",
      "hypersphereofthatclass.Werefertothisruleasthe?Conservative?Vrule?\n",
      "becauseitismorecautiousinmakingadecisionwiththisstrategy.Inaddition\n",
      "totheSPRTmethod,withwhichwederivethreetcriteria,wecanalso\n",
      "deriveseveralstoppingcriteriausingtheBayesianapproach.Ifweconsider?\n",
      "asarandomvariableandapplyanappropriateprior,wecanobtainaposterior\n",
      "distributionof?aswellastheprobabilityofP(?1>?2)orP(?1<?2).Inthe\n",
      "followingsection,weshowhowwecanderivetheseprobabilitiesandhowthese\n",
      "probabilitiescanbeusedasevidenceinthedecisionmakingmodel.\n",
      "4.1\n",
      "BayesianCriteria\n",
      "ForbothEq.(5)andEq.(6),weconsider?asarandomvariable,andwe\n",
      "canapplyaconjugatepriorfor?:p(?)=\n",
      "baa?1?exp(??b)?(a)\n",
      "(7)\n",
      "withconstantsaandb.Theconstantaisanintegersatisfyinga?1,andb\n",
      "isarealnumber.WiththispriorEq.(7),theposteriorsfortwolikelihoodsEq.\n",
      "(5)andEq.(6)areobtainedeasily:p(?|u)\n",
      "=\n",
      "p(?|N)\n",
      "=\n",
      "(u+b)N+aN+a?1?exp(??(u+b))?(N+a)(b+1)N+aN+a?1?\n",
      "exp(??(b+1))?(N+a)\n",
      "(8)(9)\n",
      "First,wederiveP(?1>?2|u1,u2)foru1andu2obtainedusingtheN\n",
      "-thnearestneighborsinclass1andclass2.Becausetheposteriorfunctionsof\n",
      "tclassesareindependentfromeachother,thisprobabilityof?1>?2is\n",
      "simplyobtainedbythedoubleintegration:Z?Z?2P(?1>?2|u1,u2)=\n",
      "p(?2|u2)p(?1|u1)d?1d?2.(10)0\n",
      "0\n",
      "Aftersomecalculation,theintegrationresultgivesanextremelysimplean-\n",
      "alyticsolution:P(?1>?2|u1,u2)=\n",
      "6\n",
      "\n",
      "NX+a?1(u1+b)m(u2+b)2N+2a?1?m2N+2a?1m(u1+u2+\n",
      "2b)2N+2a?1m=0\n",
      "(11)\n",
      "Here,wemerelyconsiderthecasethata=1,anditisinterestingtonote\n",
      "thatthisprobabilityisequivalenttotheprobabilityofabiasedcoin\n",
      "2N+1timesandobservinglessthanorequaltoNnumberofheads.This\n",
      "probabilityfromtheBayesianapproachcanbetlycomputed5\n",
      "(a)\n",
      "(b)\n",
      "Figure2:Decisionmakingprocessforthenearestneighbor\n",
      "with(a)80%and(b)90%level.Sampledataaregeneratedfrom\n",
      "theprobabilitydensities?1=0.8and?2=0.2.ForincrementingN-thnearest\n",
      "neighborsoftclasses,thecriterionprobabilitiesP(?1>?2|u1,u2)\n",
      "andP(?1<?2|u1,u2)arecalculatedandcomparedwiththelevel.\n",
      "Unlesstheprobabilityexceedsthelevel,thenext(N+1)-thnearest\n",
      "neighborsarecollectedandthecriterionprobabilitiesarecalculatedagain.In\n",
      "thistheofthecriterionprobabilityP(?1>?2|u1,u2)is\n",
      "displayedfortrealizations,wheretheevidencestopsoncethe\n",
      "criterionpassesthethresholdwhereenoughevidencehasaccumulated.The\n",
      "barsrepresentthenumberofpointsthatarecorrectly(Red,upwardbars)and\n",
      "incorrectly(Blue,downwardbars)ateachstageofthecomputation.\n",
      "Usingalargerconresultsinlesserror,butwithaconcomitantincrease\n",
      "inthenumberofnearestneighborsused.inanincrementalfashion,andthe\n",
      "nearestneighborcomputationcanbeadaptivelystoppedwithenough\n",
      "oftheevidenceprobability.ThesecondprobabilityP(?1>?2|N1,N2)for\n",
      "thenumberofnearestneighborsN1andN2withinaparticulardistancecanbe\n",
      "similarlyderived.UsingthedoubleintegrationofEq.(9),wecanderivethe\n",
      "analyticresultagainas\n",
      "N1X+a?11N1+N2+2a?1.(12)P(?1>?2|N1,N2)=N1+N2\n",
      "+2a?1m2m=0\n",
      "BoththeprobabilitiesEq.(11)andEq.(12)canbeusedasevidencethat\n",
      "alongwithincominginformation.Stoppingcriteriaforcanbe\n",
      "derivedusingtheseprobabilities.4.2\n",
      "Adaptivek-NN\n",
      "Ofinterestinthedecisionmodelistherelationshipbetweenthe\n",
      "accuracyandtheamountofresourcesneededtoobtaintheaccuracy.Ina\n",
      "decisionsettingfork-NNwecancontroltheamountof\n",
      "resourcesusingthelevel.Forexample,inFig.2,wegenerateddata\n",
      "fromtwouniformdensityfunctions,?1=0.8and?2=0.2,fortclasses,\n",
      "andweapplieddierentencelevels,0.8and0.9inFig.2(a)and(b),\n",
      "respectively.UsingtheP(?1>?2|u1,u2)criterioninEq.(11),weapplied\n",
      "theadaptivek-NNclasscationwithanincreasingNoftwoclasses.Fig.2\n",
      "showsthedecisionresultsofthewithincrementingNfor1000\n",
      "realizations,andafewexamplesoftheevidenceprobabilityinEq.\n",
      "(11)arepresented.Accordingtothelevel,theaveragenumberof\n",
      "nearestneighborsusedForFig.2(a)whenthelevelislower\n",
      "7\n",
      "\n",
      "thanFig.2(b),theevidencereachesthelevelatanearlierstage\n",
      "thanFig.2(b),whilethedecisioninFig.2(b)tendstoselecttheclass\n",
      "moreoftenthaninFig.2(a).ConsideringthattheoptimalBayes\n",
      "choosingclass1for?1>?2,thedecisionsforclass2canbeconsideredaserrors.\n",
      "Inthissense,wecansaywiththehigherlevel,decisionsaremade\n",
      "morecorrectlywhileusingmoreresources.Therefore,the6\n",
      "0.8\n",
      "0.770.76\n",
      "PNDNPVCDVDVkNNCNNRaceminRaceMinMaxRatioJigang\n",
      "0.7\n",
      "0.65\n",
      "0\n",
      "510152025Averagenumberofnearestneighbors\n",
      "PNDNPVCDVDVkNNCNNRaceminRaceMinMaxRatioJigang\n",
      "0.75Accuracy\n",
      "Accuracy\n",
      "0.75\n",
      "0.740.730.720.710\n",
      "30\n",
      "(a)\n",
      "5101520Numberofnearestneighborsused\n",
      "25\n",
      "(b)0.74\n",
      "0.550.720.5\n",
      "0.40.350.30.250.20\n",
      "PNDNPVCDVDVkNNCNNRaceminRaceMinMaxRatioJigang\n",
      "PNDNPVCDVDVkNNCNNRaceminRaceMinMaxRatioJigang\n",
      "0.7Accuracy\n",
      "Accuracy\n",
      "0.45\n",
      "0.680.660.640.62\n",
      "5101520Averagenumberofnearestneighbors\n",
      "25\n",
      "(c)\n",
      "0.60\n",
      "5101520Averagenumberofnearestneighbors\n",
      "(d)\n",
      "Figure3:accuracy(verticalaxis)versustheaveragenumber\n",
      "ofnearestneighborsused(horizontalaxis)foradaptivek-NN(a)\n",
      "Uniformprobabilitydensitiesfor?1=0.8and?2=0.2in100-dimensional\n",
      "space,(b)CIFAR-10,(c)2?105dataperclassfor5-dimensionalGaussians,\n",
      "and(d)2?106dataperclassforthesameGaussiansin(c)areused.\n",
      "betweenstrategiescanbecomparedusingtheaccuraciesaswellastheav-\n",
      "eragenumberofnearestneighborsused.\n",
      "5\n",
      "Experiments\n",
      "8\n",
      "\n",
      "Intheexperiments,wecomparetheaccuracyofthealgorithmstothenumber\n",
      "ofnearestneighborsused,forvariousdencelevelsforcriteria.Weused\n",
      "theconventionalk-NNaswellastheproposedadaptivemethods.\n",
      "AdaptiveincludesthecomparisonruleofNthnearestneighbors\n",
      "usingthreecriteria?the?Vrule(DV),theConservative?Vrule(CDV),and\n",
      "BayesianprobabilityinEq.(11)(PV)?,aswellasthecomparisonruleofN1\n",
      "-thandN2-thatagivenvolumeusingtworules?the?Nrule(DN)andBayesian\n",
      "probabilityinEq.(12)(PN).Wepresenttheaverageaccuraciesresultingfrom\n",
      "theuseofthesek-NNclasscationandveadaptiveruleswithrespectto\n",
      "theaveragenumberofnearestneighborsused.Weshowtheresultson\n",
      "syntheticdatasets.InFig.3(a),weusedtwouniformprobabilitydensities?1=\n",
      "0.8and?2=0.2in100-dimensionalspace,andweclasatestpointbased\n",
      "onthenearestneighbors.Inthisallalgorithmsareexpectedtoapproach\n",
      "theBayesperformancebasedonCoverandHart?sapproachwhentheaverage\n",
      "numberofnearestneighborsincrease.In7\n",
      "25\n",
      "thisexperiment,wecanobservethatalleproposedadaptivealgorithms\n",
      "approachtheBayeserrorquickerthanothermethodsshowingsimilarrateswith\n",
      "eachother.Here,wealsopresenttheresultsofotheradaptivealgorithmsCNN\n",
      "[12],Race,minRace,MinMaxRatio,andJigang[19].Theyperformmajority\n",
      "votingwithincreasingk;CNNstopscollectingmorenearestneighborsoncemore\n",
      "thanacertainamountofconsecutiveneighborsarefoundwiththesamelabels;\n",
      "Racestopswhenthetotalamountofneighborsofoneclassexceedsacertain\n",
      "level;minRacestopswhenallclasseshaveatleastaamountofneigh-\n",
      "bors;MinMaxRatioconsiderstheratiobetweennumbersofnearestneighborsin\n",
      "tclasses;lastly,Jigangisaprobabilitycriterionslightlytfrom\n",
      "Eq.(12).ExceptforJigang?smethod,allalgorithmsperformpoorly,while\n",
      "ourealgorithmsperformequallywellthoughtheyusetinformation,\n",
      "probablybecausetheperformanceproducedbydecisionmakingalgo-\n",
      "rithmsisoptimal.Fig.3(b)showstheexperimentsforaCIFAR-10subsetofthe\n",
      "tinyimagesdataset[17].TheCIFAR10sethas10-class32?32colorimages.\n",
      "Eachclasshas6000images,andtheyareseparatedintoonetestingsetand\n",
      "etrainingsets.Withthis10-classdata,weperformedFisherDiscrim-\n",
      "inantAnalysistoobtaina9-dimensionalsubspace,thenalltadaptive\n",
      "algorithmsareappliedonthissubspace.Theresultistheaverageaccuracy\n",
      "forettrainingsetsandforallpossiblepairsof10classes.Because\n",
      "theunderlyingdensityisnon-uniformhere,theresultshowstheperformance\n",
      "decreasewhenalgorithmsusenon-closenearestneighbors.ExceptforDVand\n",
      "PVcriteria,allofouradaptivealgorithmsoutperformallothermethods.The\n",
      "k-NNintheoriginaldataspaceshowsthemaximalaverageper-\n",
      "formanceof0.721atk=3,whichisfarlessthantheoverallaccuraciesinthe\n",
      "becausethedistanceinformationispoorinthehighdimensionalspace.\n",
      "Fig.3(c)and(d)clearlyshowthatouralgorithmsarenotguaranteedtowork\n",
      "withtdata.WegenerateddatafromtwodrentGaussianfunctions\n",
      "andtriedtoclassifyadatumlocatedatoneofthemodestooutthelabel\n",
      "ofthisdatum.Thenumberofgenerateddatais2?105perclassfor(c),and2\n",
      "9\n",
      "\n",
      "?106perclassfor(d)in5-dimensionalspace.Wepresentedtheaverageresult\n",
      "of5000realizations,andthecomparisonoftwoshowthatouradaptive\n",
      "algorithmsworkasexpectedwhenCoverandHart?sasymptoticdatacondi-\n",
      "tionholds.ThePoissonprocessassumptionalsoholdswhenthisconditionis\n",
      "\n",
      "6\n",
      "Conclusions\n",
      "Inthiswork,weshowedthatk-NNintheasymptoticlimitis\n",
      "equivalenttothedecisionmodelfordecisionmaking.Nearestneighbor\n",
      "andthedecisionmodelarebothverywellknownmodels\n",
      "inmachinelearningandcognitivesciencerespectively,buttheintimatecon-\n",
      "nectionbetweenthemhasnotbeenstudiedbefore.UsinganalysisofPoisson\n",
      "processes,weshowedhowusingincrementallyincreasingnearest\n",
      "neighborscanbemappedtoasimplethresholdbaseddecisionmodel.Inthe\n",
      "decisionmodel,thelevelplaysakeyroleindetermining\n",
      "thebetweenspeedandaccuracy.Thenotionofcanalso\n",
      "beappliedtonearestneighbortoadaptthenumberofnearest\n",
      "neighborsusedinmakingthedecision.Wepresentedseveraldif-\n",
      "ferentcriteriaforchoosingtheappropriatenumberofnearestneighborsbased\n",
      "onthesequentialprobabilityratiotestinadditiontoBayesianinference.We\n",
      "demonstratedtheutilityofthesemethodsinmodulatingspeedversusaccuracy\n",
      "onbothsimulatedandbenchmarkdatasets.Itisstraightforwardtoextend\n",
      "thesemethodstootherdatasetsandalgorithmsthatutilizeneighborhoodinfor-\n",
      "mation.Futureworkwillinvestigatehowourresultswouldscalewithdataset\n",
      "sizeandfeaturerepresentations.Potentialbofthisworkincludeawell-\n",
      "groundedapproachtospeedingupusingparallelcomputationon\n",
      "verylargedatasets.AcknowledgmentsThisresearchissupportedinpartbythe\n",
      "USceofNavalResearch,IntelScienceandTechnologyCenter,AIMCenter,\n",
      "KIST-CIR,ROSAEC-ERC,SNU-IAMD,andtheBK21.8\n",
      "2References\n",
      "[1]A.F.Atiya.Estimatingtheposteriorprobabilitiesusingthek-nearestneigh-\n",
      "borrule.NeuralComputation,17(3):731?740,2005.[2]J.M.Beck,W.J.\n",
      "Ma,R.Kiani,T.Hanks,A.K.Churchland,J.Roitman,M.N.Shadlen,P.E.\n",
      "Latham,andA.Pouget.ProbabilisticpopulationcodesforBayesiandecision\n",
      "making.Neuron,60(6):1142?1152,2008.[3]R.Bogacz,E.Brown,J.Moehlis,\n",
      "P.Holmes,andJ.D.Cohen.Thephysicsofoptimaldecisionmaking:Afor-\n",
      "malanalysisofmodelsofperformanceintwo-alternativeforced-choicetasks.\n",
      "PsychologicalReview,113(4):700?765,2006.[4]T.CoverandP.Hart.Near-\n",
      "estneighborpatternIEEETransactionsonInformationTheory,\n",
      "13(1):21?27,1967.[5]L.Devroye,L.andG.Lugosi.Aprobabilistic\n",
      "theoryofpatternrecognition.Applicationsofmathematics.Springer,1996.\n",
      "[6]M.A.Girshick.ContributionstothetheoryofsequentialanalysisI.The\n",
      "AnnualsofMathematicalStatistics,17:123?143,1946.[7]M.Goldstein.kn\n",
      "10\n",
      "\n",
      "-NearestNeighborIEEETransactionsonInformationTheory,\n",
      "IT-18(5):627?630,1972.[8]C.C.HolmesandN.M.Adams.Aprobabilis-\n",
      "ticnearestneighbourmethodforstatisticalpatternrecognition.Journalofthe\n",
      "RoyalStatisticalSocietySeriesB,64(2):295?306,2002.[9]M.D.Lee,I.G.Fuss,\n",
      "andD.J.Navarro.ABayesianapproachtomodelsofdecisionmak-\n",
      "ingandresponsetime.InAdvancesinNeuralInformationProcessingSystems\n",
      "19,pages809?816.2007.[10]N.Leonenko,L.Pronzato,andV.Savani.A\n",
      "classofR?enyiinformationestimatorsformultidimensionaldensities.Annals\n",
      "ofStatistics,36:2153?2182,2008.[11]W.J.Ma,J.M.Beck,P.E.Latham,\n",
      "andA.Pouget.Bayesianinferencewithprobabilisticpopulationcodes.Na-\n",
      "tureNeuroscience,9(11):1432?1438,2006.[12]S.Ougiaroglou,A.Nanopoulos,\n",
      "A.N.Papadopoulos,Y.Manolopoulos,andT.WelzerDruzovec.Adaptivek-\n",
      "nearest-neighborusingadynamicnumberofnearestneighbors.In\n",
      "Proceedingsofthe11thEastEuropeanconferenceonAdvancesindatabases\n",
      "andinformationsystems,pages66?82,2007.[13]R.andG.Mckoon.\n",
      "Thedusiondecisionmodel:theoryanddatafortwo-choicedecisiontasks.\n",
      "NeuralComputation,20(4):873?922,2008.[14]R.andJ.N.Rouder.A\n",
      "modelaccountofmaskingintwo-choiceletteridenJournal\n",
      "ofExperimentalPsychologyHumanPerceptionandPerformance,26(1):127?\n",
      "140,2000.[15]M.N.Shadlen,A.K.Hanks,A.K.Churchland,R.Kiani,and\n",
      "T.Yang.Thespeedandaccuracyofasimpleperceptualdecision:amathemat-\n",
      "icalprimer.Bayesianbrain:Probabilisticapproachestoneuralcoding,2006.\n",
      "[16]M.N.ShadlenandW.T.Newsome.Thevariabledischargeofcortical\n",
      "neurons:Implicationsforconnectivity,computation,andinformationcoding.\n",
      "JournalofNeuroscience,18:3870?3896,1998.[17]A.Torralba,R.Fergus,\n",
      "andW.T.Freeman.80milliontinyimages:Alargedatasetfornonpara-\n",
      "metricobjectandscenerecognition.IEEETransactionsonPatternAnalysis\n",
      "andMachineIntelligence,30(11):1958?1970,2008.[18]A.WaldandJ.Wol-\n",
      "fowitz.Optimumcharacterofthesequentialprobabilityratiotest.Annalsof\n",
      "MathematicalStatistics,19:326?339,1948.[19]J.Wang,P.Neskovic,andL.N.\n",
      "Cooper.Neighborhoodsizeselectioninthek-nearest-neighborruleusingstatis-\n",
      "ticalPatternRecognition,39(3):417?423,2006.[20]L.Wasserman.\n",
      "AllofStatistics:AConciseCourseinStatisticalInference(SpringerTextsin\n",
      "Statistics).Springer,December2003.[21]J.ZhangandR.Bogacz.Optimal\n",
      "decisionmakingonthebasisofevidencerepresentedinspiketrains.Neural\n",
      "Computation,22(5):1113?1148,2010.\n",
      "9\n",
      "11\n",
      "\n",
      "PP5416.pdf\n",
      "PP5416.pdf 11\n",
      "DeepLearningFaceRepresentationbyJoint\n",
      "Iden\n",
      "Authoredby:\n",
      "XiaogangWang\n",
      "XiaoouTang\n",
      "YiSun\n",
      "YuhengChen\n",
      "Abstract\n",
      "Thekeychallengeoffacerecognitionistodevelopefeaturerep-\n",
      "resentationsforreducingintra-personalvariationswhileenlarginginter-\n",
      "personalInthispaper,weshowthatitcanbewellsolvedwith\n",
      "deeplearningandusingbothfaceidenandvsignals\n",
      "assupervision.TheDeepIDenfeatures(DeepID2)\n",
      "arelearnedwithcarefullydesigneddeepconvolutionalnetworks.The\n",
      "faceideniontaskincreasestheinter-personalvariationsbydrawing\n",
      "DeepID2featuresextractedfromtidentitiesapart,whiletheface\n",
      "vtaskreducestheintra-personalvariationsbypullingDeepID2\n",
      "featuresextractedfromthesameidentitytogether,bothofwhicharees-\n",
      "sentialtofacerecognition.ThelearnedDeepID2featurescanbewellgen-\n",
      "eralizedtonewidentitiesunseeninthetrainingdata.Onthechallenging\n",
      "LFWdataset,99.15%facevaccuracyisachieved.Compared\n",
      "withthebestpreviousdeeplearningresultonLFW,theerrorratehas\n",
      "beentlyreducedby67%.\n",
      "1PaperBody\n",
      "Facesofthesameidentitycouldlookmuchtwhenpresentedindif-\n",
      "ferentposes,illuminations,expressions,ages,andocclusions.Suchvariations\n",
      "withinthesameidentitycouldoverwhelmthevariationsduetoidentityder-\n",
      "encesandmakefacerecognitionchallenging,especiallyinunconstrainedcon-\n",
      "ditions.Therefore,reducingtheintra-personalvariationswhileenlargingthe\n",
      "inter-personalisacentraltopicinfacerecognition.Itcanbetraced\n",
      "backtoearlysubspacefacerecognitionmethodssuchasLDA[1],Bayesianface\n",
      "[16],andsubspace[22,23].Forexample,LDAapproximatesinter-and\n",
      "intra-personalfacevariationsbyusingtwoscattermatricesandtheprojec-\n",
      "tiondirectionstomaximizetheratiobetweenthem.Morerecentstudieshave\n",
      "1\n",
      "\n",
      "alsotargetedthesamegoal,eitherexplicitlyorimplicitly.Forexample,metric\n",
      "learning[6,9,14]mapsfacestosomefeaturerepresentationsuchthatfacesof\n",
      "thesameidentityareclosetoeachotherwhilethoseoftidentitiesstay\n",
      "apart.However,thesemodelsaremuchlimitedbytheirlinearnatureorshallow\n",
      "structures,whileinter-andintra-personalvariationsarecomplex,highlynon-\n",
      "linear,andobservedinhigh-dimensionalimagespace.Inthiswork,weshow\n",
      "thatdeeplearningprovidesmuchmorepowerfultoolstohandlethetwotypes\n",
      "ofvariations.Thankstoitsdeeparchitectureandlargelearningcapacity,\n",
      "tivefeaturesforfacerecognitioncanbelearnedthroughhierarchicalnonlinear\n",
      "mappings.Wearguethatitisessentialtolearnsuchfeaturesbyusingtwosuper-\n",
      "visorysignalssimultaneously,i.e.thefaceidenandvsignals,\n",
      "andthelearnedfeaturesarereferredtoasDeepIDenfea-\n",
      "tures(DeepID2).Idenistoclassifyaninputimageintoalargenumber\n",
      "ofidentity1\n",
      "classes,whilevistoclassifyapairofimagesasbelongingtothe\n",
      "sameidentityornot(i.e.binaryInthetrainingstage,given\n",
      "aninputfaceimagewiththeidensignal,itsDeepID2featuresareex-\n",
      "tractedinthetophiddenlayerofthelearnedhierarchicalnonlinearfeature\n",
      "representation,andthenmappedtooneofalargenumberofidentitiesthrough\n",
      "anotherfunctiong(DeepID2).Inthetestingstage,thelearnedDeepID2features\n",
      "canbegeneralizedtoothertasks(suchasfacevandnewidentities\n",
      "unseeninthetrainingdata.Theidensupervisorysignaltendstopull\n",
      "aparttheDeepID2featuresoftidentitiessincetheyhavetobeclassi\n",
      "intotclasses.Therefore,thelearnedfeatureswouldhaverichidentity-\n",
      "relatedorinter-personalvariations.However,theidensignalhasa\n",
      "relativelyweakconstraintonDeepID2featuresextractedfromthesameiden-\n",
      "tity,sincedissimilarDeepID2featurescouldbemappedtothesameidentity\n",
      "throughfunctiong(?).ThisleadstoproblemswhenDeepID2featuresaregener-\n",
      "alizedtonewtasksandnewidentitiesintestwheregisnotapplicableanymore.\n",
      "Wesolvethisbyusinganadditionalfacevsignal,whichrequiresthat\n",
      "everytwoDeepID2featurevectorsextractedfromthesameidentityareclose\n",
      "toeachotherwhilethoseextractedfromtidentitiesarekeptaway.The\n",
      "strongper-elementconstraintonDeepID2featurescanectivelyreducethe\n",
      "intra-personalvariations.Ontheotherhand,usingtheversignalalone\n",
      "(i.e.onlydistinguishingapairofDeepID2featurevectorsatatime)isnotas\n",
      "einextractingidentityrelatedfeaturesasusingtheidensignal\n",
      "(i.e.distinguishingthousandsofidentitiesatatime).Therefore,thetwosu-\n",
      "pervisorysignalsemphasizetaspectsinfeaturelearningandshouldbe\n",
      "employedtogether.Tocharacterizefacesfromtaspects,complemen-\n",
      "taryDeepID2featuresareextractedfromvariousfaceregionsandresolutions,\n",
      "andareconcatenatedtoformthefeaturerepresentationafterPCAdimen-\n",
      "sionreduction.SincethelearnedDeepID2featuresarediverseamongt\n",
      "identitieswhileconsistentwithinthesameidentity,itmakesthefollowingface\n",
      "recognitioneasier.Usingthelearnedfeaturerepresentationandarecentlypro-\n",
      "posedfacevmodel[3],weachievedthehighest99.15%facev\n",
      "accuracyonthechallengingandextensivelystudiedLFWdataset[11].Thisis\n",
      "2\n",
      "\n",
      "thetimethatamachineprovidedwithonlythefaceregionachievesan\n",
      "accuracyonparwiththe99.20%accuracyofhumantowhomtheentireLFW\n",
      "faceimageincludingthefaceregionandlargebackgroundareaarepresentedto\n",
      "verify.Inrecentyears,agreatdealofhavebeenmadeforfacerecogni-\n",
      "tionwithdeeplearning[5,10,18,26,8,21,20,27].Amongthedeeplearning\n",
      "works,[5,18,8]learnedfeaturesordeepmetricswiththevsignal,\n",
      "whileDeepFace[21]andourpreviousworkDeepID[20]learnedfeatureswith\n",
      "theidensignalandachievedaccuraciesaround97.45%onLFW.Our\n",
      "approachtlyimprovesthestate-of-the-art.Theideaofjointlysolving\n",
      "theandvtaskswasappliedtogeneralobjectrecogni-\n",
      "tion[15],withthefocusonimprovingaccuracyonobject\n",
      "classesinsteadofhiddenfeaturerepresentations.Ourworktargetsonlearn-\n",
      "ingfeatureswhichcanbewellgeneralizedtonewclasses(identities)andthe\n",
      "vtask.\n",
      "2\n",
      "Idenguideddeepfeaturelearning\n",
      "Welearnfeatureswithvariationsofdeepconvolutionalneuralnetworks\n",
      "(deepConvNets)[12].TheconvolutionandpoolingoperationsindeepCon-\n",
      "vNetsarespeciallydesignedtoextractvisualfeatureshierarchically,fromlocal\n",
      "low-levelfeaturestoglobalhigh-levelones.OurdeepConvNetstakesimilar\n",
      "structuresasin[20].Itcontainsfourconvolutionallayers,withlocalweight\n",
      "sharing[10]inthethirdandfourthconvolutionallayers.TheConvNetextracts\n",
      "a160-dimensionalDeepID2featurevectoratitslastlayer(DeepID2layer)ofthe\n",
      "featureextractioncascade.TheDeepID2layertobelearnedarefully-connected\n",
      "toboththethirdandfourthconvolutionallayers.Weuselinearunits\n",
      "(ReLU)[17]forneuronsintheconvolutionallayersandtheDeepID2layer.An\n",
      "illustrationoftheConvNetstructureusedtoextractDeepID2featuresisshown\n",
      "inFig.1givenanRGBinputofsize55?47.Whenthesizeoftheinput\n",
      "regionchanges,themapsizesinthefollowinglayerswillchangeaccordingly.\n",
      "TheDeepID2featureextractionprocessisdenotedasf=Conv(x,?c),where\n",
      "Conv(?)isthefeatureextractionfunctionbytheConvNet,xisthe\n",
      "inputfacepatch,fistheextractedDeepID2featurevector,and?cdenotes\n",
      "ConvNetparameterstobelearned.2\n",
      "Figure1:TheConvNetstructureforDeepID2featureextraction.DeepID2\n",
      "featuresarelearnedwithtwosupervisorysignals.Theisfaceiden\n",
      "signal,whicheachfaceimageintooneofn(e.g.,n=8192)t\n",
      "identities.IdentiisachievedbyfollowingtheDeepID2layerwithann-\n",
      "waysoftmaxlayer,whichoutputsaprobabilitydistributionoverthenclasses.\n",
      "Thenetworkistrainedtominimizethecross-entropyloss,whichwecallthe\n",
      "idenloss.Itisdenotedas\n",
      "Ident(f,t,?id)=?\n",
      "nX\n",
      "pilogp?i=?logp?t,\n",
      "(1)\n",
      "i=1\n",
      "wherefistheDeepID2featurevector,tisthetargetclass,and?iddenotes\n",
      "3\n",
      "\n",
      "thesoftmaxlayerparameters.piisthetargetprobabilitydistribution,wherepi\n",
      "=0foralliexceptpt=1forthetargetclasst.p?iisthepredictedprobability\n",
      "distribution.Tocorrectlyclassifyalltheclassessimultaneously,theDeepID2\n",
      "layermustformdiscriminativeidentity-relatedfeatures(i.e.featureswithlarge\n",
      "inter-personalvariations).Thesecondisfacevsignal,whichencour-\n",
      "agesDeepID2featuresextractedfromfacesofthesameidentitytobesimilar.\n",
      "ThevcationsignaldirectlyregularizeDeepID2featuresandcanely\n",
      "reducetheintra-personalvariations.Commonlyusedconstraintsincludethe\n",
      "L1/L2normandcosinesimilarity.Weadoptthefollowinglossfunctionbased\n",
      "ontheL2norm,whichwasoriginallyproposedbyHadselletal.[7]fordimen-\n",
      "sionalityreduction,(V,fj,yij,?ve)=\n",
      "1212\n",
      "2\n",
      "?fjk22max0,m??fjk2\n",
      "ifyij=1,ifyij=?1\n",
      "(2)\n",
      "whereandfjareDeepID2featurevectorsextractedfromthetwoface\n",
      "imagesincomparison.yij=1meansthatandfjarefromthesameidentity.\n",
      "Inthiscase,itminimizestheL2distancebetweenthetwoDeepID2feature\n",
      "vectors.yij=?1meanstidentities,andEq.(2)requiresthedistance\n",
      "largerthanamarginm.?ve=\n",
      "f\n",
      "m\n",
      "g\n",
      "istheparametertobelearnedinthe\n",
      "vlossfunction.LossfunctionsbasedontheL1normcouldhave\n",
      "similarformulations[15].Thecosinesimilaritywasusedin[17]asVer,fj,\n",
      "yij,?ve)=\n",
      "12(yij??(wd+b)),2\n",
      "(3)\n",
      "f?f\n",
      "whered=ki2kfjjk2isthecosinesimilaritybetweenDeepID2feature\n",
      "vectors,?ve=\n",
      "f\n",
      "w,b\n",
      "g\n",
      "arelearnablescalingandshiftingparameters,?isthe\n",
      "sigmoidfunction,andyijisthebinarytargetofwhetherthetwocomparedface\n",
      "imagesbelongtothesameidentity.Allthethreelossfunctionsareevaluated\n",
      "andcomparedinourexperiments.Ourgoalistolearntheparameters?cin\n",
      "thefeatureextractionfunctionConv(?),while?idand?veareonlyparameters\n",
      "introducedtopropagatetheidenandvsignalsduringtrain-\n",
      "ing.Inthetestingstage,only?cisusedforfeatureextraction.Theparameters\n",
      "areupdatedbystochasticgradientdescent.Theidenandv\n",
      "gradientsareweightedbyahyperparameter?.Ourlearningalgorithmissum-\n",
      "marizedinTab.1.ThemarginminEq.(2)isaspecialcase,whichcannot\n",
      "beupdatedbygradientdescentsincethiswillcollapseittozero.Instead,m\n",
      "isandupdatedeveryNtrainingpairs(N?200,000inourexperiments)\n",
      "suchthatitisthethresholdof3\n",
      "Table1:TheDeepID2featurelearningalgorithm.input:trainingset?=\n",
      "f\n",
      "(xi,li)\n",
      "g\n",
      ",initializedparameters?c,?id,and?ve,hyperparameter?,learning\n",
      "rate?(t),t?0whilenotconvergedot?t+1sampletwotrainingsamples(xi\n",
      ",li)and(xj,lj)from?=Conv(xi,?c)andfj=Conv(xj,?c)?Ident(fj\n",
      ",lj,?id),li,?id)??id=?Ident??+??idid?V,fj,yij,?ve)??ve=?\n",
      "4\n",
      "\n",
      "?,whereyij=1ifli=lj,andyij=?1otherwise.??ve?V,fj,yij,?ve\n",
      ")?Iden,li,?id)=+???Verif,fj,yij,?ve)?Ident(fj,lj,?id)\n",
      "+???fj=?fj?fj?Conv(xj,?c)?Conv(xi,?c)+?fj???c=???c??c\n",
      "update?id=?id??(t)???id,?ve=?ve??(t)???ve,and?c=?c??(t)?\n",
      "??c.endwhileoutput?c\n",
      "Figure2:Patchesselectedforfeatureextraction.TheJointBayesian[3]face\n",
      "vaccuracy(%)usingfeaturesextractedfromeachindividualpatchis\n",
      "shownbelow.\n",
      "thefeaturedistances?fjktominimizetheverrorofthe\n",
      "previousNtrainingpairs.UpdatingmisnotincludedinTab.1forsimplicity.\n",
      "3\n",
      "FaceV\n",
      "ToevaluatethefeaturelearningalgorithmdescribedinSec.2,DeepID2\n",
      "featuresareembeddedintotheconventionalfacevcationpipelineofface\n",
      "alignment,featureextraction,andfacevWeusetherecently\n",
      "proposedSDMalgorithm[24]todetect21faciallandmarks.Thenthefaceim-\n",
      "agesaregloballyalignedbysimilaritytransformationaccordingtothedetected\n",
      "landmarks.Wecropped400facepatches,whichvaryinpositions,scales,color\n",
      "channels,andhorizontalaccordingtothegloballyalignedfacesandthe\n",
      "positionofthefaciallandmarks.Accordingly,400DeepID2featurevectorsare\n",
      "extractedbyatotalof200deepConvNets,eachofwhichistrainedtoextract\n",
      "two160-dimensionalDeepID2featurevectorsononeparticularfacepatchand\n",
      "itshorizontallyedcounterpart,respectively,ofeachface.Toreducethe\n",
      "redundancyamongthelargenumberofDeepID2featuresandmakeoursystem\n",
      "practical,weusetheforward-backwardgreedyalgorithm[25]toselectasmall\n",
      "numberofeandcomplementaryDeepID2featurevectors(25inourex-\n",
      "periment),whichsavesmostofthefeatureextractiontimeduringtest.Fig.2\n",
      "showsalltheselected25patches,fromwhich25160-dimensionalDeepID2fea-\n",
      "turevectorsareextractedandareconcatenatedtoa4000-dimensionalDeepID2\n",
      "featurevector.The4000-dimensionalvectorisfurthercompressedto180di-\n",
      "mensionsbyPCAforfacevWelearnedtheJointBayesianmodel[3]\n",
      "forfacevbasedontheextractedDeepID2features.JointBayesian\n",
      "hasbeensuccessfullyusedtomodelthejointprobabilityoftwofacesbeingthe\n",
      "sameortpersons[3,4].4\n",
      "4\n",
      "Experiments\n",
      "WereportfacevresultsontheLFWdataset[11],whichisthe\n",
      "defactostandardtestsetforfacevinunconstrainedconditions.It\n",
      "contains13,233faceimagesof5749identitiescollectedfromtheInternet.For\n",
      "comparisonpurposes,algorithmstypicallyreportthemeanfacevac-\n",
      "curacyandtheROCcurveon6000givenfacepairsinLFW.Thoughbeing\n",
      "soundasatestset,itisinadequatefortraining,sincethemajorityofidentities\n",
      "inLFWhaveonlyonefaceimage.Therefore,werelyonalargeroutsidedataset\n",
      "fortraining,asdidbyallrecenthighperformancefacevalgorithms[4,\n",
      "2,21,20,13].Inparticular,weusetheCelebFaces+dataset[20]fortraining,\n",
      "whichcontains202,599faceimagesof10,177identities(celebrities)collected\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fromtheInternet.PeopleinCelebFaces+andLFWaremutuallyexclusive.\n",
      "DeepID2featuresarelearnedfromthefaceimagesof8192identitiesrandomly\n",
      "sampledfromCelebFaces+(referredtoasCelebFaces+A),whiletheremain-\n",
      "ingfaceimagesof1985identities(referredtoasCelebFaces+B)areusedfor\n",
      "thefollowingfeatureselectionandlearningthefacevmodels(Joint\n",
      "Bayesian).WhenlearningDeepID2featuresonCelebFaces+A,CelebFaces+B\n",
      "isusedasavalidationsettodecidethelearningrate,trainingepochs,andhy-\n",
      "perparameter?.Afterthat,CelebFaces+Bisseparatedintoatrainingsetof\n",
      "1485identitiesandavalidationsetof500identitiesforfeatureselection.Finally,\n",
      "wetraintheJointBayesianmodelontheentireCelebFaces+Bdataandtest\n",
      "onLFWusingtheselectedDeepID2features.Weevaluatevariousaspect\n",
      "offeaturelearningfromSec.4.1toSec.4.3byusingasingledeepConvNetto\n",
      "extractDeepID2featuresfromtheentirefaceregion.Thenthesystemis\n",
      "constructedandcomparedwithexistingbestperformingmethodsinSec.4.4.\n",
      "4.1\n",
      "Balancingtheidenandvcationsignals\n",
      "Weinvestigatestheinteractionsofidenandvsignalson\n",
      "featurelearning,byvarying?from0to+?.At?=0,thevsignal\n",
      "vanishesandonlytheidensignaltakesWhen?increases,the\n",
      "vsignalgraduallydominatesthetrainingprocess.Attheotherex-\n",
      "tremeof??+?,onlythevsignalremains.TheL2normv\n",
      "lossinEq.(2)isusedfortraining.Figure3showsthefacevaccuracy\n",
      "onthetestsetbycomparingthelearnedDeepID2featureswithL2normand\n",
      "theJointBayesianmodel,respectively.Itclearlyshowsthatneithertheidenti-\n",
      "northevsignalistheoptimalonetolearnfeatures.Instead,\n",
      "efeaturescomefromtheappropriatecombinationofthetwo.Thisphe-\n",
      "nomenoncanbeexplainedfromtheviewofinter-andintra-personalvariations,\n",
      "whichcouldbeapproximatedbyLDA.AccordingtoLDA,theinter-personal\n",
      "scattermatrixisSinter=Pc>xi?x?)(?xi?x?),wherex?iisthemean\n",
      "featureofthei-thidentity,x?isthemeanofthei=1ni?(?entiredataset,\n",
      "andniisthenumberoffaceimagesofthei-thidentity.Theintra-personal\n",
      "scatterPcP>matrixisSintra=?i)(x?x?i),whereDiisthesetoffeatures\n",
      "ofthei-thi=1x?Di(x?xidentity,x?iisthecorrespondingmean,andcis\n",
      "thenumberoftidentities.Theinter-andintra-personalvariancesare\n",
      "theeigenvaluesofthecorrespondingscattermatrices,andareshowninFig.5.\n",
      "Thecorrespondingeigenvectorsrepresenttvariationpatterns.Boththe\n",
      "magnitudeanddiversityoffeaturevariancesmatterinrecognition.Ifallthe\n",
      "featurevariancesconcentrateonasmallnumberofeigenvectors,itindicatesthe\n",
      "diversityofintra-orinter-personalvariationsislow.Thefeaturesarelearned\n",
      "with?=0,0.05,and+?,respectively.Thefeaturevariancesofeachgiven?are\n",
      "normalizedbythecorrespondingmeanfeaturevariance.Whenonlytheidenti-\n",
      "signalisused(?=0),thelearnedfeaturescontainbothdiverseinter-\n",
      "andintra-personalvariations,asshownbythelongtailsoftheredcurvesin\n",
      "bothWhilediverseinter-personalvariationshelptodistinguisht\n",
      "identities,largeanddiverseintra-personalvariationsaredisturbingfactorsand\n",
      "makefacevWhenboththeidenandv\n",
      "6\n",
      "\n",
      "signalsareusedwithappropriateweighting(?=0.05),thediversityofthe\n",
      "inter-personalvariationskeepsunchangedwhilethevariationsinafewmain\n",
      "directionsbecomeevenlarger,asshownbythegreencurveintheleftcompared\n",
      "totheredone.Atthesametime,theintra-personalvariationsdecreaseinboth\n",
      "thediversityandmagnitude,asshownbythegreencurveintheright.There-\n",
      "fore,boththeinter-andintra-personalvariationschangesinadirectionthat\n",
      "makesfaceveasier.When?furtherincreasestowardsy,both\n",
      "theinter-andintra-personalvariationscollapsetothevariationsinonlyafew\n",
      "maindirections,sincewithouttheidensignal,diversefeaturescannot\n",
      "beformed.Withlowdiversityoninter5\n",
      "Figure3:FacevaccuracybyvaryingFigure4:Facev\n",
      "accuracyofDeepID2theweightingparameter?.?isplottedinlogfeatures\n",
      "learnedbyboththethefaceidenscale.andvsignals,where\n",
      "thenumberoftrainingidentities(showninlogscale)usedforfaceiden\n",
      "varies.Theresultmaybefurtherimprovedwithmorethan8192identities.\n",
      "Figure5:Spectrumofeigenvaluesoftheinter-andintra-personalscatter\n",
      "matrices.Bestviewedincolor.personalvariations,distinguishingt\n",
      "identitiesbecomesThereforetheperformancedegradestly.\n",
      "Figure6showsthetwoPCAdimensionsoffeatureslearnedwith?=0,\n",
      "0.05,and+?,respectively.Thesefeaturescomefromthesixidentitieswiththe\n",
      "largestnumbersoffaceimagesinLFW,andaremarkedbytcolors.The\n",
      "furthervourobservations.When?=0(left),tclustersare\n",
      "mixedtogetherduetothelargeintra-personalvariations,althoughthecluster\n",
      "centersareactuallyt.When?increasesto0.05(middle),intra-personal\n",
      "variationsaretlyreducedandtheclustersbecomedistinguishable.\n",
      "When?furtherincreasestowardsy(right),althoughtheintra-personal\n",
      "variationsfurtherdecrease,theclustercentersalsobegintocollapseandsome\n",
      "clustersbecometlyoverlapped(asthered,blue,andcyanclustersin\n",
      "Fig.6right),makingithardtodistinguishagain.4.2\n",
      "Richidentityinformationimprovesfeaturelearning\n",
      "Weinvestigatehowwouldtheidentityinformationcontainedintheiden-\n",
      "supervisorysignalthelearnedfeatures.Inparticular,we\n",
      "experimentwithanexponentiallyincreasingnumberofidentitiesusedforiden-\n",
      "duringtrainingfrom32to8192,whilethevsignalisgen-\n",
      "eratedfromallthe8192trainingidentitiesallthetime.Fig.4showshowthe\n",
      "vaccuraciesofthelearnedDeepID2features(derivedfromtheL2\n",
      "normandJointBayesian)varyonthetestsetwiththenumberofidentities\n",
      "usedintheidensignal.Itshowsthat6\n",
      "Figure6:ThetwoPCAdimensionsofDeepID2featuresextractedfrom\n",
      "sixidentitiesinLFW.Table2:Comparisonoftvsignals.\n",
      "vsignal\n",
      "L2\n",
      "L2+\n",
      "L2-\n",
      "L1\n",
      "cosinenone\n",
      "7\n",
      "\n",
      "L2norm(%)JointBayesian(%)\n",
      "94.9595.12\n",
      "94.4394.87\n",
      "86.2392.98\n",
      "92.9294.13\n",
      "87.0793.38\n",
      "86.4392.73\n",
      "identifyingalargenumber(e.g.,8192)ofidentitiesiskeytolearninge\n",
      "DeepID2featurerepresentation.ThisobservationisconsistentwiththoseinSec.\n",
      "4.1.Theincreasingnumberofidentitiesprovidesricheridentityinformationand\n",
      "helpstoformDeepID2featureswithdiverseinterpersonalvariations,making\n",
      "theclasscentersoftidentitiesmoredistinguishable.4.3\n",
      "Investigatingthevsignals\n",
      "AsshowninSec.4.1,thevsignalwithmoderateintensitymainly\n",
      "takestheofreducingtheintra-personalvariations.Tofurtherverifythis,\n",
      "wecompareourL2normvsignalonallthesamplepairswiththose\n",
      "onlyconstraineitherthepositiveornegativesamplepairs,denotedasL2+\n",
      "andL2-,respectively.Thatis,theL2+onlydecreasesthedistancesbetween\n",
      "DeepID2featuresofthesameidentity,whileL2-onlyincreasesthedistances\n",
      "betweenDeepID2featuresoftidentitiesiftheyaresmallerthanthe\n",
      "margin.ThefacevaccuraciesofthelearnedDeepID2featuresonthe\n",
      "testset,measuredbytheL2normandJointBayesianrespectively,areshown\n",
      "inTable2.ItalsocompareswiththeL1normandcosinevsignals,as\n",
      "wellasnovsignal(none).Theidensignalisthesame(clas-\n",
      "sifyingthe8192identities)forallthecomparisons.DeepID2featureslearned\n",
      "withtheL2+vsignalareonlyslightlyworsethanthoselearnedwith\n",
      "L2.Incontrast,theL2-vsignalhelpslittleinfeaturelearningand\n",
      "givesalmostthesameresultasnovsignalisused.Thisisastrong\n",
      "evidencethattheofthevsignalismainlyreducingtheintra-\n",
      "personalvariations.Anotherobservationisthatthefacevaccuracy\n",
      "improvesingeneralwheneverthevsignalisaddedinadditiontothe\n",
      "idensignal.However,theL2normisbetterthantheothercompared\n",
      "vmetrics.Thismaybeduetothatalltheotherconstraintsareweaker\n",
      "thanL2andlesseinreducingtheintra-personalvariations.Forexample,\n",
      "thecosinesimilarityonlyconstrainstheangle,butnotthemagnitude.4.4\n",
      "Finalsystemandcomparisonwithothermethods\n",
      "BeforelearningJointBayesian,DeepID2featuresareprojectedto180\n",
      "dimensionsbyPCA.AfterPCA,theJointBayesianmodelistrainedonthe\n",
      "entireCelebFaces+Bdataandtestedonthe6000givenfacepairsinLFW,\n",
      "wherethelog-likelihoodratiogivenbyJointBayesianiscomparedtoathresh-\n",
      "oldoptimizedonthetrainingdataforfacevTab.3showsthe\n",
      "facevaccuracywithanincreasingnumberoffacepatchestoextract\n",
      "DeepID2features,aswellasthetimeusedtoextractthoseDeepID2features\n",
      "fromeachfacewithasingleTitanGPU.Weachieve98.97%accuracywithall\n",
      "the25selectedfacepatches.Thefeatureextractionprocessisalsotand\n",
      "takesonly35msforeachfaceimage.Thefacevaccuracyofeach\n",
      "8\n",
      "\n",
      "individualfacepatchisprovidedinFig.2.TheshortDeepID2signatureis\n",
      "extremelyientforfaceidenandfaceimagesearchwhenmatching\n",
      "aqueryimagewithalargenumberofcandidates.7\n",
      "Table3:FacevaccuracywithDeepID2featuresextractedfrom\n",
      "anincreasingnumberoffacepatches.#patches\n",
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "25\n",
      "accuracy(%)time(ms)\n",
      "95.431.7\n",
      "97.283.4\n",
      "97.756.1\n",
      "98.5511\n",
      "98.9323\n",
      "98.9735\n",
      "Table4:AccuracycomparisonwiththepreviousbestresultsonLFW.\n",
      "method\n",
      "accuracy(%)\n",
      "High-dimLBP[4]TLJointBayesian[2]DeepFace[21]DeepID[20]Gaus-\n",
      "sianFace[13]DeepID2\n",
      "95.17?1.1396.33?1.0897.35?0.2597.45?0.2698.52?0.6699.15?0.13\n",
      "Figure7:ROCcomparisonwiththepreviousbestresultsonLFW.Best\n",
      "viewedincolor.TofurtherexploittherichpoolofDeepID2featuresextracted\n",
      "fromthelargenumberofpatches,werepeatthefeatureselectionalgorithmfor\n",
      "anothersixtimes,eachtimechoosingDeepID2featuresfromthepatchesthat\n",
      "havenotbeenselectedbypreviousfeatureselectionsteps.Thenwelearnthe\n",
      "JointBayesianmodeloneachofthesevengroupsofselectedfeatures,respec-\n",
      "tively.WefusethesevenJointBayesianscoresoneachpairofcomparedfaces\n",
      "byfurtherlearninganSVM.Inthisway,weachieveanevenhigher99.15%\n",
      "facevaccuracy.TheaccuracyandROCcomparisonwithprevious\n",
      "state-of-the-artmethodsonLFWareshowninTab.4andFig.7,respectively.\n",
      "Weachievethebestresultsandimprovepreviousresultswithalargemargin.\n",
      "5\n",
      "Conclusion\n",
      "Thispaperhaveshownthattheofthefaceidenandver\n",
      "cationsupervisorysignalsondeepfeaturerepresentationcoincidewiththetwo\n",
      "aspectsofconstructingidealfeaturesforfacerecognition,i.e.,increasinginter-\n",
      "personalvariationsandreducingintra-personalvariations,andthecombination\n",
      "ofthetwosupervisorysignalsleadtotlybetterfeaturesthaneither\n",
      "oneofthem.Whenembeddingthelearnedfeaturestothetraditionalfacever-\n",
      "pipeline,weachievedanextremelyesystemwith99.15%face\n",
      "vaccuracyonLFW.ThearXivreportofthispaperwaspublishedin\n",
      "June2014[19].8\n",
      "9\n",
      "\n",
      "2References\n",
      "[1]P.N.Belhumeur,J.a.P.Hespanha,andD.J.Kriegman.Eigenfaces\n",
      "vs.Fisherfaces:Recognitionusingclasssplinearprojection.PAMI,\n",
      "19:711?720,1997.[2]X.Cao,D.Wipf,F.Wen,G.Duan,andJ.Sun.A\n",
      "practicaltransferlearningalgorithmforfacevInProc.ICCV,2013.\n",
      "[3]D.Chen,X.Cao,L.Wang,F.Wen,andJ.Sun.Bayesianfacerevisited:A\n",
      "jointformulation.InProc.ECCV,2012.[4]D.Chen,X.Cao,F.Wen,andJ.\n",
      "Sun.Blessingofdimensionality:High-dimensionalfeatureanditstcom-\n",
      "pressionforfaceverInProc.CVPR,2013.[5]S.Chopra,R.Hadsell,\n",
      "andY.LeCun.Learningasimilaritymetricdiscriminatively,withapplication\n",
      "tofacevInProc.CVPR,2005.[6]M.Guillaumin,J.Verbeek,and\n",
      "C.Schmid.Isthatyou?MetriclearningapproachesforfaceidenIn\n",
      "Proc.ICCV,2009.[7]R.Hadsell,S.Chopra,andY.LeCun.Dimensionality\n",
      "reductionbylearninganinvariantmapping.InProc.CVPR,2006.[8]J.Hu,J.\n",
      "Lu,andY.-P.Tan.Discriminativedeepmetriclearningforfacevin\n",
      "thewild.InProc.CVPR,2014.[9]C.Huang,S.Zhu,andK.Yu.Largescale\n",
      "stronglysupervisedensemblemetriclearning,withapplicationstofacev\n",
      "cationandretrieval.NECTechnicalReportTR115,2011.[10]G.B.Huang,\n",
      "H.Lee,andE.Learned-Miller.Learninghierarchicalrepresentationsforface\n",
      "vwithconvolutionaldeepbeliefnetworks.InProc.CVPR,2012.\n",
      "[11]G.B.Huang,M.Ramesh,T.Berg,andE.Learned-Miller.LabeledFaces\n",
      "intheWild:Adatabaseforstudyingfacerecognitioninunconstrainedenvi-\n",
      "ronments.TechnicalReport0749,UniversityofMassachusetts,Amherst,2007.\n",
      "[12]Y.LeCun,L.Bottou,Y.Bengio,andP.Gradient-basedlearning\n",
      "appliedtodocumentrecognition.ProceedingsoftheIEEE,1998.[13]C.Lu\n",
      "andX.Tang.Surpassinghuman-levelfacevperformanceonLFW\n",
      "withGaussianFace.Technicalreport,arXiv:1404.3840,2014.[14]A.Mignon\n",
      "andF.Jurie.PCCA:Anewapproachfordistancelearningfromsparsepairwise\n",
      "constraints.InProc.CVPR,2012.[15]H.Mobahi,R.Collobert,andJ.We-\n",
      "ston.Deeplearningfromtemporalcoherenceinvideo.InProc.ICML,2009.\n",
      "[16]B.Moghaddam,T.Jebara,andA.Pentland.Bayesianfacerecognition.\n",
      "PR,33:1771?1782,2000.[17]V.NairandG.E.Hinton.linearunits\n",
      "improverestrictedBoltzmannmachines.InProc.ICML,2010.[18]Y.Sun,X.\n",
      "Wang,andX.Tang.HybriddeeplearningforfaceveriInProc.ICCV,\n",
      "2013.[19]Y.Sun,X.Wang,andX.Tang.Deeplearningfacerepresentationby\n",
      "jointidenvTechnicalreport,arXiv:1406.4773,2014.[20]Y.\n",
      "Sun,X.Wang,andX.Tang.Deeplearningfacerepresentationfrompredicting\n",
      "10,000classes.InProc.CVPR,2014.[21]Y.Taigman,M.Yang,M.Ranzato,\n",
      "andL.Wolf.DeepFace:Closingthegaptohuman-levelperformanceinfacever-\n",
      "InProc.CVPR,2014.[22]X.WangandX.Tang.subspace\n",
      "analysisforfacerecognition.InProc.ICCV,2003.[23]X.WangandX.Tang.\n",
      "Aframeworkforsubspacefacerecognition.PAMI,26:1222?1228,2004.\n",
      "[24]X.XiongandF.DelaTorreFrade.Superviseddescentmethodandits\n",
      "applicationstofacealignment.InProc.CVPR,2013.[25]T.Zhang.Adaptive\n",
      "forward-backwardgreedyalgorithmforlearningsparserepresentations.IEEE\n",
      "10\n",
      "\n",
      "Trans.Inf.Theor.,57:4689?4708,2011.[26]Z.Zhu,P.Luo,X.Wang,andX.\n",
      "Tang.Deeplearningidentity-preservingfacespace.InProc.ICCV,2013.[27]\n",
      "Z.Zhu,P.Luo,X.Wang,andX.Tang.Deeplearninganddisentanglingface\n",
      "representationbymulti-viewperceptron.InProc.NIPS,2014.\n",
      "9\n",
      "11\n",
      "\n",
      "PP5172.pdf\n",
      "PP5172.pdf 10\n",
      "TrackingTime-varyingGraphicalStructure\n",
      "Authoredby:\n",
      "DavidDanks\n",
      "ErichKummerfeld\n",
      "Abstract\n",
      "Structurelearningalgorithmsforgraphicalmodelshavefocusedal-\n",
      "mostexclusivelyonstableenvironmentsinwhichtheunderlyinggener-\n",
      "ativeprocessdoesnotchange;thatis,theyassumethatthegenerating\n",
      "modelisgloballystationary.Inreal-worldenvironments,however,such\n",
      "changesoftenoccurwithoutwarningorsignal.Real-worlddataoften\n",
      "comefromgeneratingmodelsthatareonlylocallystationary.Inthispa-\n",
      "per,wepresentLoSST,anovel,heuristicstructurelearningalgorithmthat\n",
      "trackschangesingraphicalmodelstructureorparametersinadynamic,\n",
      "real-timemanner.Weshowbysimulationthatthealgorithmperforms\n",
      "comparablytobatch-modelearningwhenthegeneratinggraphicalstruc-\n",
      "tureisgloballystationary,andtlybetterwhenitisonlylocally\n",
      "stationary.\n",
      "1PaperBody\n",
      "Graphicalmodelsareusedinawidevarietyofdomains,bothtoprovidecompact\n",
      "representationsofprobabilitydistributionsforrapid,tinference,and\n",
      "alsotorepresentcomplexcausalstructures.Almostallstandardalgorithmsfor\n",
      "learninggraphicalmodelstructure[9,10,12,3]assumethattheunderlying\n",
      "generatingstructuredoesnotchangeoverthecourseofdatacollection,andso\n",
      "thedataarei.i.d.(orcanbetransformedintoi.i.d.data).Intherealworld,\n",
      "however,generatingstructuresoftenchangeanditcanbecriticaltoquickly\n",
      "detectthestructurechangeandthenlearnthenewone.Inmanyofthesereal-\n",
      "worldcontexts,wealsodonothavetheluxuryofcollectinglargeamountsof\n",
      "dataandthenretrospectivelydeterminingwhen(ifever)thestructurechanged.\n",
      "Thatis,wecannotlearnin?batchmode,?butmustinsteadlearnthenovel\n",
      "structureinanonlinemanner,processingthedataasitarrives.Currentonline\n",
      "learningalgorithmscandetectandhandlechangesinthelearningenvironment,\n",
      "butnonearecapableofgeneral,graphicalmodelstructurelearning.Inthis\n",
      "paper,wedevelopaheuristicalgorithmthatthisgap:itassumesonlythat\n",
      "ourdataarelocallyi.i.d.,andlearnsgraphicalmodelstructureinanonline\n",
      "fashion.Inthenextsection,wequicklysurveyrelatedmethodsandshowthat\n",
      "1\n",
      "\n",
      "theyareindividuallyntforthistask.Wethenpresentthedetailsof\n",
      "ouralgorithmandprovidesimulationevidencethatitcansuccessfullylearn\n",
      "graphicalmodelstructureinanonlinemanner.Importantly,whenthereisa\n",
      "stablegeneratingstructure,thealgorithm?sperformanceisindistinguishable\n",
      "fromastandardbatch-modestructurelearningalgorithm.Thus,usingthis\n",
      "algorithmincursnoadditionalcostsin?normal?structurelearningsituations.\n",
      "2\n",
      "Relatedwork\n",
      "Wefocushereongraphicalmodelsbasedondirectedacyclicgraphs(DAGs)\n",
      "overrandomvariableswithcorrespondingquantitativecomponents,whether\n",
      "BayesiannetworksorrecursiveStructuralEquationModels(SEMs)[3,12,10].\n",
      "Allofourobservationsinthispaper,aswellasthecore1\n",
      "algorithm,arereadilyadaptabletolearnstructureformodelsbasedonundi-\n",
      "rectedgraphs,suchasMarkovrandomorGaussiangraphicalmodels[6,9].\n",
      "Standardgraphicalmodelstructurelearningalgorithmsdivideintotworough\n",
      "types.Bayesian/scorebasedmethodsaimtothemodelMthatmaximizes\n",
      "P(M|Data),butinpractice,scorethemodelsusingadecomposablemeasure\n",
      "basedonP(Data|M)andthenumberofparametersinM[3].Constraint-\n",
      "basedstructurelearningalgorithmsleveragethefactthateverygraphicalmodel\n",
      "predictsapatternof(conditional)independenciesoverthevariables,though\n",
      "multiplemodelscanpredictthesamepattern.Thosealgorithms(e.g.,[10,12])\n",
      "thesetofgraphicalmodelsthatbestpredictthe(conditional)independen-\n",
      "ciesinthedata.Bothtypesofstructurelearningalgorithmsassumethatthe\n",
      "datacomefromasinglegeneratingstructure,andsoneitherisdirectlyusable\n",
      "forlearningwhenstructurechangeispossible.Theylearnfromthet\n",
      "statistics,butneitherhasanymechanismfordetectingchange,respondingto\n",
      "it,orlearningthenewstructure.Bayesianlearningalgorithms?orvariousap-\n",
      "proximationstothem?areoftenusedforonlinelearning,butpreciselybecause\n",
      "case-by-caseBayesianupdatingyieldsthesameoutputasbatch-modeprocess-\n",
      "ing(assumingthedataarei.i.d.).Sincewearefocusedonsituationsinwhich\n",
      "theunderlyingstructurecanchange,wedonotwantthesameoutput.One\n",
      "couldinsteadlooktoonlinelearningmethodsthattracksomeenvironmental\n",
      "feature.TheclassicTDLalgorithm,TD(0)[13],providesadynamicestimate\n",
      "Et(X)ofaunivariaterandomvariableXusingasimpleupdaterule:Et+1\n",
      "(X)?Et(X)+?(Xt?Et(X)),whereXtisthevalueofXattimet.The\n",
      "static?parameterencodesthelearningrate,andtradesconvergencerate\n",
      "androbustnesstonoise(instableenvironments).Ingeneral,TDLmethods\n",
      "aregoodattrackingslow-movingenvironmentalchanges,butperformsubopti-\n",
      "mallyduringtimesofeitherhighstabilityordramaticchange,suchaswhenthe\n",
      "generatingmodelstructureabruptlychanges.BothBayesian[1]andfrequen-\n",
      "tist[4]onlinechangepointdetection(CPD)algorithmsareeatdetecting\n",
      "abruptchanges,butdosobystoringsubstantialportionsoftheinputdata.For\n",
      "example,aBayesianCPD[1]outputstheprobabilityofachangepointhaving\n",
      "occurredrtimestepsago,andsothealgorithmmuststoremorethanrdata-\n",
      "points.Furthermore,CPDalgorithmsassumeamodeloftheenvironmentthat\n",
      "hasonlyabruptchangesseparatedbyperiodsofstability.Environmentsthat\n",
      "2\n",
      "\n",
      "evolveslowlybutcontinuouslywillhavetheirtime-seriesdiscretizedinseem-\n",
      "inglyarbitraryfashion,ornotatall.Twopreviouspapershaveaimedtolearn\n",
      "time-indexedgraphstructuresfromtime-seriesdata,thoughbothrequirefull\n",
      "datasetsasinput,socannotfunctioninreal-time[14,11].TalihandHengartner\n",
      "(2005)takeanordereddatasetanddivideitintoanumberof(possibly\n",
      "empty)dataintervals,eachwithanassociatedundirectedgraphthatby\n",
      "oneedgefromitsneighbors.Incontrastwithourwork,theyfocusonapartic-\n",
      "ulartypeofgraphstructurechange(singleedgeadditionordeletion),operate\n",
      "solelyin?batchmode,?anduseundirectedgraphsinsteadofdirectedacyclic\n",
      "graphmodels.SiracusaandFisherIII(2009)usesaBayesianapproachto\n",
      "theposterioruncertaintyoverthepossibledirectededgesattpoints\n",
      "inatime-series.Ourapproachbyusingfrequentistmethodsinsteadof\n",
      "Bayesianones(sincewewouldotherwiseneedtomaintainaprobabilitydistri-\n",
      "butionoverthesuperexponentialnumberofgraphicalmodels),andbybeing\n",
      "abletooperateinreal-timeonanincomingdatastream.\n",
      "3\n",
      "LocallyStationaryStructureTracker(LoSST)Algorithm\n",
      "GivenasetofcontinuousvariablesV,weassumethatthereis,ateachtime\n",
      "r,atrueunderlyinggenerativemodelGroverV.Grisassumedtobearecursive\n",
      "StructuralEquationModel(SEM):apairhG,Fi,whereGdenotesaDAGover\n",
      "V,andFisasetoflinearequationsoftheformVi=PVj?pa(Vi)aji?Vj\n",
      "+i,wherepa(Vi)denotesthevariablesVj?GsuchthatVj?Vi,and\n",
      "theiarenormallydistributednoise/errorterms.Incontrasttopreviouswork\n",
      "onstructurelearning,weassumeonlythatthegeneratingprocessislocally\n",
      "stationary:foreachtimer,dataaregeneratedi.i.d.fromGr,butitisnot\n",
      "necessarilythecasethatGr=Gsforr6=s.NoticethatGrcanchangeinboth\n",
      "structure(i.e.,adding,removing,orreorientingedges)andparameters(i.e.,\n",
      "changesinaji?sortheidistributions).Atahighlevel,theLocallyStationary\n",
      "StructureTracker(LoSST)algorithmtakes,ateachtimestepr,anewdatapoint\n",
      "asinputandoutputsagraphicalmodelMr.Obviously,asingledatapointis2\n",
      "ttolearngraphicalmodelstructure.TheLoSSTalgorithmin-\n",
      "steadtracksthelocallystationarytstatistics?forrecursiveSEMs,the\n",
      "means,covariances,andsamplesize?inanonlinefashion,andthendynamically\n",
      "(re)learnsthegraphicalmodelstructureasappropriate.TheLoSSTalgorithm\n",
      "processeseachdatapointonlyonce,andsoLoSSTcanalsofunctionasasin-\n",
      "glepass,graphicalmodelstructurelearnerforverylargedatasets.LetXrbethe\n",
      "r-thmultivariatedatapointandletXirbethevalueofViforthatdatapoint.To\n",
      "trackthepotentiallychanginggeneratingstructure,thedatapointsmustpoten-\n",
      "tiallybetiallyweighted.Inparticular,datapointsshouldPbeweighted\n",
      "moreheavilyafterachangeoccurs.Letar?(0,?)bertheweightonXr,and\n",
      "letbr=k=1akbethesumofthoseweightsovertime.PrakkTheweighted\n",
      "meanofViafterdatapointris?ri=k=1brXi,whichcanbecomputedinan\n",
      "onlinefashionusingtheupdateequation:?r+1=i\n",
      "brbr+1\n",
      "?ri+\n",
      "ar+1r+1Xbr+1i\n",
      "3\n",
      "\n",
      "(1)\n",
      "The(weighted)covariancebetweenViandVjafterdatapointrisprovably\n",
      "equaltoCrVi,Vj=Prakrr+1r+1rrr(Xir+1??ri).Theupdateequation\n",
      "for??ri=abr+1k=1br(Xi??i)(Xj??j).Let?i=?iCr+1canbewritten\n",
      "(aftersomealgebra)as:1Cr+1[brCrXi,Xj+br?i?j+ar+1(Xir+1??r+1\n",
      ")(Xjr+1??r+1)]ijXi,Xj=br+1\n",
      "(2)\n",
      "Ifak=cforallkandsomeconstantc>0,thentheestimatedcovariance\n",
      "matrixisidenticaltothebatch-modeestimatedcovariancematrix.Ifar=?br\n",
      ",thenthelearningisthesameasifoneusesTD(0)learningforeachcovariance\n",
      "withalearningrateof?.ThesamplesizeSrismorecomplicated,sincedata-\n",
      "pointsareweighteddierentlyandsothee?samplesizecanfrom\n",
      "theactualsamplesize(thoughitshouldalwaysbeless-than-orequal).Because\n",
      "Xr+1comesfromthecurrentgeneratingstructure,itshouldalwayscontribute\n",
      "1tomorethanXr.Ifweadjustthenaturaltheesamplesize.Inaddi-\n",
      "tion,Xr+1isweightedaar+1rsamplesizeupdateequationtosatisfythesetwo\n",
      "constraints,thentheupdateequationbecomes:arrSr+1=S+1(3)ar+1If\n",
      "ar+1?arforallr(asinthemethodweusebelow),thenSr+1?Sr+1.If\n",
      "ar+1=arforallr,thenSr=r;thatis,ifthedatapointweightsareconstant,\n",
      "thenSristhetruesamplesize.tstatisticstracking??r+1,Cr+1,and\n",
      "Sr+1?thusrequiresrememberingonlytheirpreviousvaluesandbr,assuming\n",
      "thatar+1canbetlycomputed.Thear+1weightsarebasedonthe\n",
      "betweenthecurrentestimatedcovariancematrixandtheinputdata:poort\n",
      "impliesthatachangeintheunderlyinggeneratingstructureismorelikely.For\n",
      "multivariateGaussiandata,thebetweenXr+1andthecurrentestimated\n",
      "covariancematrixCrisgivenbytheMahalanobisdistanceDr+1[8]:Dr+1=\n",
      "(Xr+1??r)(Cr)?1(Xr+1??r)T.AlargeMahalanobisdistance(i.e.,poor\n",
      "forsomedatapointcouldindicatesimplyanoutlier;inferringthattheun-\n",
      "derlyinggeneratingstructurehaschangedrequireslargeMahalanobisdistances\n",
      "overmultipledatapoints.Thelikelihoodofthe(weighted)sequenceofDr?sis\n",
      "analyticallyintractable,andsowecannotusetheDrvaluesdirectly.Wein-\n",
      "steadbasethear+1weightsonthe(weighted)pooledp-valueoftheindividual\n",
      "p-valuesfortheMahalanobisdistanceofeachdatapoint.TheMahalanobisdis-\n",
      "tanceofaV-dimensionaldatapointfromacovariancematrixestimatedfroma\n",
      "sampleofsizeNisdistributedasHotelling?sT2withparametersp=Vandm\n",
      "=N?1.Thep-valuefortheMahalanobisdistanceDr+1isthus:pr+1=T2\n",
      "(x>Dr+1|p=N,m=Sr?1)whereSristhetivesamplesize.Let?(x,\n",
      "y)bethecdfofaGaussianwithmean0andvarianceyevaluatedatx.Then\n",
      "Liptak?smethodforweightedpoolingpPoftheindividual?p-values[7]givesPr\n",
      "a2i)=?(?r+1,?r+1),wherethethefollowing?r+1=?(i=1ai\n",
      "??1(pi,1),?1updateequationsfor?and?are?r+1=?r+ar?(pr,1)and\n",
      "?r+1=?r+a2r.1?r+1cannotincludepr+1withoutbeingcircular:pr+1\n",
      "wouldhavetobeappropriatelyweightedbyar+1,butthatweightdependson\n",
      "?r+1.\n",
      "3\n",
      "Therearemanywaystoconvertthepooledp-value?r+1intoaweightar+1\n",
      "4\n",
      "\n",
      ".Weusethestrategy:if?r+1isgreaterthansomethresholdT(i.e.,thedata\n",
      "sequenceistlylikelygiventhecurrentmodel),thenkeeptheweight\n",
      "constant;if?r+1islessthatT,thenincreasear+1linearlyandinverselyto\n",
      "?r+1uptoamaximumof?arat?r+1=0.Mathematically,thistransformation\n",
      "is:\n",
      "?T???r+1+?r+1ar+1=ar?max1,(4)Ttcomputationofar+1\n",
      "thusonlyrequiresadditionallytracking?r,?r,and?r.Wecantlytrack\n",
      "therelevantientstatisticsinanonlinefashion,andsotheonlyremaining\n",
      "stepistolearnthecorrespondinggraphicalmodel.Theimplementationinthis\n",
      "paperusesthePCalgorithm[12],astandardconstraint-basedstructurelearning\n",
      "algorithm.Arangeofalternativestructurelearningalgorithmscouldbeused\n",
      "instead,dependingontheassumptionsoneisabletomake.Learninggraphical\n",
      "modelstructureiscomputationallyexpensive[2]andsooneshouldbalancethe\n",
      "accuracyofthecurrentmodelagainstthecomputationalcostofrelearning.\n",
      "Moreprecisely,graph2relearningshouldbemostfrequentafteraninferred\n",
      "underlyingchange,thoughthereshouldbeanon-zerochanceofrelearningeven\n",
      "whenthestructureappearstoberelativelystable(sincethestructurecould\n",
      "beslowlydrifting).Inpractice,theLoSSTalgorithmprobabilisticallyrelearns\n",
      "basedontheinverse3of?r:theprobabilityofrelearningattimer+1isa\n",
      "noisy-ORgatewiththeprobabilityofrelearningattimer,andaweighted(1\n",
      "??r+1).Mathematically,Pr+1(relearn)=Pr(relearn)+?(1??r+1)?\n",
      "Pr(relearn)?(1??r+1),where??[0,1]mothefrequencyofgraph\n",
      "relearning:largevaluesresultinmorefrequentrelearningandsmallvalues\n",
      "resultinfewer.Ifarelearningeventistriggeredatdatapointr,thenanew\n",
      "graphicalmodelstructureandparametersarelearned,andPr(relearn)isset\n",
      "to0.Ingeneral,?rislowerwhenchangepointsaredetected,soPr(relearn)will\n",
      "increasemorequicklyaroundchangepoints,andgraphrelearningwillbecome\n",
      "morefrequent.Duringtimesofstability,?rwillbecomparativelylarge,resulting\n",
      "inaslowerincreaseofPr(relearn)andthuslessfrequentgraphrelearning.3.1\n",
      "Convergencevs.diligenceinLoSST\n",
      "LoSSTiscapableofexhibitingtlong-runproperties,dependingonits\n",
      "parameters.Convergenceisastandarddesideratum:ifthereisastablestruc-\n",
      "tureinthelimit,thenthealgorithm?soutputshouldstabilizeonthatstructure.\n",
      "Incontextsinwhichthetruestructurecanchange,anotherdesirableproperty\n",
      "forlearningalgorithmsisdiligence:ifthegeneratingstructurehasachangeof\n",
      "givensize(thatmanifestsinthedata),thenthealgorithmshoulddetectand\n",
      "respondtothatchangewithinanumberofdatapoints(regardlessofthe\n",
      "amountofpreviousdata).Bothdiligenceandconvergencearedesirablemethod-\n",
      "ologicalvirtues,buttheyareprovablyincompatible:nolearningalgorithmcan\n",
      "bebothdiligentandconvergent[5].Intuitively,theyareincompatiblebecause\n",
      "theymustrespondtlytoimprobabledatapoints:convergentalgorithms\n",
      "musttoleratethem(sincesuchdataoccurwithprobability1inthenite\n",
      "limit),whilediligentalgorithmsmustregardthemassignalsthatthestructure\n",
      "haschanged.If?=1,thenLoSSTisaconvergentalgorithm,sinceitfollows\n",
      "thatar+1=arforallr(whichisasucientconditionforconvergence).For?\n",
      ">1,thebehaviorofLoSSTdependsonT.IfT<0,thenweagainhavear+1\n",
      "5\n",
      "\n",
      "=arforallr,andsoLoSSTisconvergent.LoSSTisalsoprovablyconvergent\n",
      "ifTistime-indexedsuchthatTr=f(Sr)forsomefwith(0,1]range,where\n",
      "P?4i=1(1?f(i))converges.2\n",
      "Recallthattheientstatisticsareupdatedaftereverydatapoint.Recall\n",
      "that?risPapooledp-value,solowvaluesindicateunlikelydata.4Proofsketch:\n",
      "?i=r(1?qi)canbeshowntobeanupperboundontheprobabilitythat\n",
      "(1??i)>qiwilloccurforsomeiPin[r,?),whereqiisthei-thelement\n",
      "ofthesequenceQoflowerthresholdvalues.?AnysequenceQs.t.i=1(1?\n",
      "qi)<1willthenguaranteethatanamountofunbiaseddatawillbe\n",
      "accumulatedinthelimit.Thisprovidesprobability1convergencefor\n",
      "LoSST,sincethestructurelearningmethodhasprobability1convergencein\n",
      "thelimit.IfQisprependedwitharbitrarystrictlypositivethresholdvalues,\n",
      "theelementofQwillstillbereachedmanytimeswithprobability\n",
      "1inthelimit,andsoLoSSTwillstillconvergewithprobability1,even\n",
      "usingtheseexpandedsequences.3\n",
      "4\n",
      "Incontrast,ifT>1and?>1,thenLoSSTisprovablydiligent.5Weconjec-\n",
      "turethattherearesequencesoftime-indexedTr<1thatwillalsoyielddiligent\n",
      "versionsofLoSST,analogouslytotheconditiongivenaboveforconvergence.\n",
      "Interestingly,if?>1and0<T<1,thenLoSSTisneitherconvergentnor\n",
      "diligent,butratherstrikesabalancebetweenthedesiderata.Inparticular,\n",
      "theseversions(a)tendtoconvergetowardsstablestructures,butprovablydo\n",
      "notactuallyconvergesincetheyremainsensitivetooutliers;and(b)respond\n",
      "quicklytochangeingeneratingstructure,butonlyexponentiallyfastinthe\n",
      "numberofpreviousdatapoints,ratherthanwithinainterval.Thefull\n",
      "behaviorofLoSSTinthisparameterregime,includingtheextentandsensitiv-\n",
      "ityofisanopenquestionforfutureresearch.Forthesimulations\n",
      "below,unsystematicinvestigationledtoT=0.05and?=3,whichseemedto\n",
      "appropriatelytradeconvergencevs.diligenceinthatcontext.\n",
      "4\n",
      "Simulationresults\n",
      "WeusedsyntheticdatatoevaluatetheperformanceofLoSSTgivenknown\n",
      "groundtruth.Allsimulationsusedscenariosinwhicheitherthegroundtruth\n",
      "parametersorgroundtruthgraph(andparameters)changedduringthecourse\n",
      "ofdatacollection.Beforethechangepoint,thereshouldbenosign\n",
      "cantrencebetweenLoSSTandastandardbatch-modelearner,sincethose\n",
      "datapointsaregloballyi.i.d.Performanceonthesedatapointsthusprovidesin-\n",
      "formationabouttheperformancecost(ifany)ofonlinelearningusingLoSST,\n",
      "relativetotraditionalalgorithms.Afterachangepoint,oneisinterestedboth\n",
      "intheabsoluteperformanceofLoSST(i.e.,canittrackthechanges?)andin\n",
      "itsperformancerelativetoastandardbatch-modealgorithm(i.e.,whatperfor-\n",
      "mancegaindoesitprovide?).WeusedthePCalgorithm[12]asourbaseline\n",
      "batch-modelearningalgorithm;weconjecturethatanyotherstandardgraphical\n",
      "modelstructurelearningalgorithmwouldperformsimilarly,giventhegraphs\n",
      "andsamplesizesinoursimulations.Inordertodirectlycomparetheperfor-\n",
      "manceofLoSSTandPC,weimposeda?graphrelearning?schedule6on\n",
      "6\n",
      "\n",
      "LoSST.Thestsetofsimulationsuseddatasetswith2000datapoints,where\n",
      "theSEMgraphandparametersbothchangedafterthe1000datapoints.\n",
      "500datasetsweregeneratedforeachofarangeofh#variables,MaxDegreei\n",
      "pairs,7whereeachdatasetusedtwot,randomlygeneratedSEMsofthe\n",
      "spsizeanddegree.Figures1(a-c)showthemeanedgeaddition,removal,\n",
      "andorientationerrors(respectively)byLoSSTasafunctionoftime,andFigures\n",
      "1(d-f)showthemeansof#errorsPC?#errorsLoSSTforeacherrortype(i.e.,\n",
      "highernumbersimplyLoSSToutperformsPC).InallFigures,eachhvariable,\n",
      "degreeipairisadistinctline.Asexpected,LoSSTwasbasicallyindistinguish-\n",
      "ablefromPCforthe1000datapoints;thelinesinFigures1(d-f)forthat\n",
      "intervalareallessentiallyzero.Aftertheunderlyinggeneratingmodelchanges,\n",
      "however,therearetdierences.ThePCalgorithmperformsquite\n",
      "poorlybecausethefulldatasetisessentiallyamixturefromtwotdistri-\n",
      "butionswhichinducesalargenumberofspuriousassociations.Incontrast,the\n",
      "LoSSTalgorithmlargeMahalanobisdistancesforthosedatapoints,which\n",
      "leadtohigherweights,whichleadittolearn(approximately)thenewunder-\n",
      "lyinggraphicalmodel.Inpractice,LoSSTtypicallystabilizedonanewmodel\n",
      "byroughly250datapointsafterthechangepoint.Thesecondsetofsimulations\n",
      "wasidenticaltothe(500runseachforvariouspairsofvariablenumber\n",
      "andedgedegree),exceptthatthegraphwasheldconstantthroughoutandonly\n",
      "theSEMparameterschangedafter1000datapoints.Figures2(a-c)and2(d-f)\n",
      "report,forthesesimulations,thesamemeasuresasFigures1(a-c)and1(d-f).\n",
      "Again,LoSSTandPCperformedbasicallyidenticallyforthe1000data-\n",
      "points.Performanceaftertheparameterchangedidnotfollowquitethesame\n",
      "patternasbefore,however.LoSSTagaindoesmuchbetteronedgeaddition\n",
      "andorientationerrors,butperformedtlyworseonedgeremovalerrors\n",
      "forthe200pointsfollowingtheProofsketch:Byequation(4),T>1&?\n",
      ">1?????1>1?ar+1?ar(????1)>arforallTT?T??+1r.Thislast\n",
      "strictinequalityimpliesthattheesamplesizehasaupperbound\n",
      "(=(??1)(Tif?1)?r=1forallr),andthemajorityoftheesample\n",
      "comesfromrecentdatapoints.Thesetwoconditionsarejointlytfor\n",
      "diligence.6LoSSTrelearnedgraphsandPCwasrerunafterdatapoints\n",
      "f\n",
      "25,50,\n",
      "100,200,300,500,750,1000,1025,1050,1100,1200,1300,1500,1750,2000\n",
      "g\n",
      ".\n",
      "7Sp,h4,3i,h8,3i,h10,3i,h10,7i,h15,4i,h15,9i,h20,5i,andh20,\n",
      "12i5\n",
      "5\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "(d)\n",
      "(e)\n",
      "(f)\n",
      "Figure1:Structure&parameterchanges:(a-c)LoSSTerrors;(d-f)LoSST\n",
      "improvementoverPC\n",
      "(a)\n",
      "(b)\n",
      "7\n",
      "\n",
      "(c)\n",
      "(d)\n",
      "(e)\n",
      "(f)\n",
      "Figure2:Parameterchanges:(a-c)LoSSTerrors;(d-f)LoSSTimprovement\n",
      "overPCchange.Whenachangeocccurs,PCintiallyrespondsbyaddingedges\n",
      "totheoutput,whileLoSSTrespondsbybeingmorecautiousinitsinferences\n",
      "(sincetheesamplesizeshrinksafterachange).Theshort-termimpact\n",
      "oneachalgorithmisthus:PC?soutputtendstobeasupersetoftheoriginal\n",
      "edges,whileLoSSToutputsfeweredges.Asaresult,PCcanoutperformLoSST\n",
      "forabrieftimeontheedgeremovalmetricinthesetypesofcasesinwhich\n",
      "thechangeinvolvesonlyparameters,notgraphstructure.Thethirdsetof\n",
      "simulationswasdesignedtoexploreindetailtheperformancewithprobabilistic\n",
      "relearning.Werandomlygeneratedasingledatasetwith10,000datapoints,\n",
      "wheretheunderlyingSEMgraphandparameterschangedafterevery1000\n",
      "datapoints.EachSEMhad10variablesandmaximumdegreeof7.Wethen\n",
      "ranLoSSTwithprobabilisticrelearning(?=.005)500timesonthisdataset.\n",
      "Figure3(a)showsthe(observed)expectednumberof?relearnings?ineach256\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "(d)\n",
      "Figure3:(a)LoSSTexpectedrelearnings;(b-d)Expectededgeadditions,\n",
      "removals,andagainstconstantrelearning\n",
      "(a)\n",
      "(b)\n",
      "(c)\n",
      "Figure4:(a)esamplesizeduringLoSSTrunonBLSdata;(b)\n",
      "Pooledp-values;(c)Mahalanobisdistancesdatapointwindow.Asexpected,\n",
      "therearesubstantialrelearningpeaksaftereachstructureshift,andtheex-\n",
      "pectednumberofrelearningspersistedatroughly0.1per25datapointsthrough-\n",
      "outthestableperiods.Figures3(b-d)provideerrorinformation:thesmooth\n",
      "greenlinesindicatethemeanedgeaddition,removal,andorientationerrors(re-\n",
      "spectively)duringlearning,andtheblockybluelinesindicatetheLoSSTerrors\n",
      "ifgraphrelearningoccurredaftereverydatapoint.Althoughtherearemany\n",
      "fewergraphrelearningswiththeprobabilisticschedule,overallerrorsdidnot\n",
      "tlyincrease.\n",
      "5\n",
      "ApplicationtoUSpriceindexvolatility\n",
      "TotesttheperformanceoftheLoSSTalgorithmonreal-worlddata,weap-\n",
      "pliedittoseasonallyadjustedpriceindexdatafromtheU.S.BureauofLabor\n",
      "Statistics.Welimitedthedatatocommodities/serviceswithdatagoingback\n",
      "toatleast1967,resultinginadatasetof6variables:Apparel,Food,Housing,\n",
      "Medical,Other,andTransportation.Thedatawerecollectedmonthlyfrom\n",
      "19672011,resultingin529datapoints.Becauseofttrendsinthe\n",
      "indicesovertime,weusedmonth-to-monthFigure4(a)showsthe\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "changeinesamplesize,wherethekeyobservationisthatchangede-\n",
      "tectionpromptstdropsintheesamplesize.Figures4(b)and\n",
      "4(c)showthepooledp-valueandMahalanobisdistanceforeachmonth,which\n",
      "arethedriversofsamplesize7\n",
      "changes.TheGreatModerationwasawell-knownmacroeconomicphe-\n",
      "nomenonbetween1980and2007inwhichtheU.S.marketunderwenta\n",
      "slowbutsteadyreductioninvolatility.LoSSTappearstodetectexactlysucha\n",
      "shiftinthevolatilityoftherelationshipsbetweenthesepriceindexes,thoughit\n",
      "detectsanothershiftshortlyafter2000.8Thisreal-worldcasestudyalsodemon-\n",
      "stratestheimportanceofusingpooledp-values,asthatiswhyLoSSTdoesnot\n",
      "respondtothesingle-monthspikeinMahalanobisdistancein1995,butdoesre-\n",
      "spondtotheextendedsequenceofslightlyaboveaverageMahalanobisdistances\n",
      "around1980.\n",
      "6\n",
      "Discussionandfutureresearch\n",
      "TheLoSSTalgorithmissuitableforlocallystationarystructures,butthere\n",
      "areobviouslylimits.Inparticular,itwillperformpoorlyifthegeneratingstruc-\n",
      "turechangesveryrapidly,orifthedatapointsarearandom-ordermixturefrom\n",
      "multiplestructures.Animportantfutureresearchdirectionistocharacterize\n",
      "andthenimproveLoSST?sperformanceonmorerapidlyvaryingstructures.\n",
      "VariousheuristicaspectsofLoSSTcouldalsopotentiallybereplacedbymore\n",
      "normativeprocedures,thoughasnotedearlier,manywillnotworkwithout\n",
      "substantialrevision(e.g.,obviousBayesianmethods).Thisalgorithmcanalso\n",
      "beextendedtohavethecurrentlearnedmodelthearweights.Sup-\n",
      "poseparticulargraphicaledgesoradjacencieshavenotchangedoveralong\n",
      "periodoftime,orhavebeenstableovermultiplerelearnings.Inthatcase,\n",
      "onemightplausiblyconcludethatthoseconnectionsarelesslikelytochange,\n",
      "andsomuchgreatererrorshouldberequiredtorelearnthoseconnections.In\n",
      "practice,thisextensionwouldrequirethearweightstovaryacrosshVi,Vj\n",
      "ipairs,whichtlycomplicatesthemathematicsandmemoryrequire-\n",
      "mentsofthetstatistictracking.Itisanopenquestionwhetherthe\n",
      "(presumably)improvedtrackingwouldcompensatefortheadditionalcompu-\n",
      "tationalandmemorycostinparticulardomains.WehavefocusedonSEMs,\n",
      "buttherearemanyothertypesofgraphicalmodels;forexample,Bayesiannet-\n",
      "workshavethesamegraph-typebutareoverdiscretevariableswith\n",
      "conditionalprobabilitytables.TrackingthetstatisticsforBayesnet\n",
      "structurelearningissubstantiallymorecostly,andwearecurrentlyinvesti-\n",
      "gatingwaystolearnthenecessaryinformationinatractable,onlinefashion.\n",
      "Similarly,ourgraphlearningreliesonconstraint-basedstructurelearningsince\n",
      "therelevantscoresinscore-basedmethods(suchas[3])donotdecomposeina\n",
      "mannerthatissuitableforonlinelearning.Wearethusinvestigatingalterna-\n",
      "tivescores,aswellasheuristicapproximationstoprincipledscore-basedsearch.\n",
      "Therearemanyreal-worldcontextsinwhichbatch-modestructurelearningis\n",
      "eitherinfeasibleorinappropriate.Inparticular,therealworldfrequentlyin-\n",
      "volvesdynamicallyvaryingstructuresthatouralgorithmsmusttrackovertime.\n",
      "Theonlinestructurelearningalgorithmpresentedherehasgreatpotentialto\n",
      "9\n",
      "\n",
      "performwellinarangeofchallengingcontexts,andatlittlecostin?traditional?\n",
      "settings.AcknowledgmentsThankstoJoeRamseyandRobTillmanforhelp\n",
      "withthesimulations,andthreeanonymousreviewersforhelpfulcomments.DD\n",
      "waspartiallysupportedbyaJamesS.McDonnellFoundationScholarAward.\n",
      "8\n",
      "ThisshiftisalmostcertainlyduetotheU.S.recessionthatoccurredin\n",
      "MarchtoNovemberofthatyear.\n",
      "8\n",
      "2References\n",
      "[1]R.P.AdamsandD.J.C.MacKay.Bayesianonlinechangepointdetection.\n",
      "Technicalreport,UniversityofCambridge,Cambridge,UK,2007.arXiv:0710.3742v1\n",
      "[stat.ML].[2]D.M.Chickering.LearningBayesiannetworksisNP-complete.\n",
      "InProceedingsofAIandStatistics,1995.[3]D.M.Chickering.Optimal\n",
      "structureidenwithgreedysearch.JournalofMachineLearningRe-\n",
      "search,3:507?554,2002.[4]F.Desobry,M.Davy,andC.Doncarli.Anon-\n",
      "linekernelchangedetectionalgorithm.IEEETransactionsonSignalProcess-\n",
      "ing,8:2961?2974,2005.[5]E.KummerfeldandD.Danks.Modelchangeand\n",
      "methodologicalvirtuesinsciencinference.Technicalreport,CarnegieMellon\n",
      "University,Pittsburgh,Pennsylvania,2013.[6]S.L.Lauritzen.Graphicalmod-\n",
      "els.ClarendonPress,1996.[7]T.Liptak.Onthecombinationofindependent\n",
      "tests.MagyarTud.Akad.Mat.KutatoInt.Kozl.,3:171?197,1958.[8]P.C.\n",
      "Mahalanobis.Onthegeneralizeddistanceinstatistics.ProceedingsoftheNa-\n",
      "tionalInstituteofSciencesofIndia,2:49?55,1936.[9]A.McCallum,D.Freitag,\n",
      "andF.C.N.Pereira.MaximumentropyMarkovmodelsofinformationextrac-\n",
      "tionandsegmentation.InProceedingsofICML-2000,pages591?598,2000.\n",
      "[10]J.Pearl.Causality:Models,Reasoning,andInference.CambridgeUni-\n",
      "versityPress,2000.[11]M.R.SiracusaandJ.W.FisherIII.Tractablebayesian\n",
      "inferenceoftime-seriesdependencestructure.InProceedingsofthe12thIn-\n",
      "ternationalConferenceonIntelligenceandStatistics,2009.[12]P.\n",
      "Spirtes,C.Glymour,andR.Scheines.Causation,Prediction,andSearch.MIT\n",
      "Press,2ndedition,2000.[13]R.Sutton.Learningtopredictbythemethods\n",
      "oftemporals.MachineLearning,3:9?44,1988.[14]M.TalihandN.\n",
      "Hengartner.Structurallearningwithtime-varyingcomponents:trackingthe\n",
      "cross-sectionofancialtimeseries.JournaloftheRoyalStatisticalSociety-\n",
      "SeriesB:StatisticalMethodology,67(3):321?341,2005.\n",
      "9\n",
      "10\n",
      "\n",
      "PP5614.pdf\n",
      "PP5614.pdf 13\n",
      "AcceleratedMini-batchRandomizedBlock\n",
      "CoordinateDescentMethod\n",
      "Authoredby:\n",
      "HanLiu\n",
      "RamanArora\n",
      "TuoZhao\n",
      "MoYu\n",
      "YimingWang\n",
      "Abstract\n",
      "Weconsiderregularizedempiricalriskminimizationproblems.Inpar-\n",
      "ticular,weminimizethesumofasmoothempiricalriskfunctionanda\n",
      "nonsmoothregularizationfunction.Whentheregularizationfunctionis\n",
      "blockseparable,wecansolvetheminimizationproblemsinarandomized\n",
      "blockcoordinatedescent(RBCD)manner.ExistingRBCDmethodsusu-\n",
      "allydecreasetheobjectivevaluebyexploitingthepartialgradientofa\n",
      "randomlyselectedblockofcoordinatesineachiteration.Thustheyneed\n",
      "alldatatobeaccessiblesothatthepartialgradientoftheblockgradient\n",
      "canbeexactlyobtained.However,sucha\\batchsettingmaybecompu-\n",
      "tationallyexpensiveinpractice.Inthispaper,weproposeamini-batch\n",
      "randomizedblockcoordinatedescent(MRBCD)method,whichestimates\n",
      "thepartialgradientoftheselectedblockbasedonamini-batchofran-\n",
      "domlysampleddataineachiteration.WefurtheracceleratetheMRBCD\n",
      "methodbyexploitingthesemi-stochasticoptimizationscheme,whichef-\n",
      "fectivelyreducesthevarianceofthepartialgradientestimators.Theoret-\n",
      "ically,weshowthatforstronglyconvexfunctions,theMRBCDmethod\n",
      "attainsloweroveralliterationcomplexitythanexistingRBCDmethods.\n",
      "Asanapplication,wefurthertrimtheMRBCDmethodtosolvethereg-\n",
      "ularizedsparselearningproblems.Ournumericalexperimentsshowsthat\n",
      "theMRBCDmethodnaturallyexploitsthesparsitystructureandachieves\n",
      "bettercomputationalperformancethanexistingmethods.\"\n",
      "1PaperBody\n",
      "Bigdataanalysischallengesbothstatisticsandcomputation.Inthepastdecade,\n",
      "researchershavedevelopedalargefamilyofsparseregularizedM-estimators,\n",
      "suchasSparseLinearRegression[17,24],GroupSparseLinearRegression[22],\n",
      "SparseLogisticRegression[9],SparseSupportVectorMachine[23,19],andetc.\n",
      "1\n",
      "\n",
      "Theseestimatorsareusuallyformulatedasregularizedempiricalriskminimiza-\n",
      "tionproblemsinagenericformasfollows[10],?b=argminP(?)=argmin\n",
      "F(?)+R(?),?\n",
      "(1.1)\n",
      "?\n",
      "where?istheparameteroftheworkingmodel.Hereweassumetheempir-\n",
      "icalriskfunctionF(?)issmooth,andtheregularizationfunctionR(?)isnon-\n",
      "tiable.Somerstorderalgorithms,mostlyvariantsofproximalgradient\n",
      "methods[11],havebeenproposedforsolving(1.1).ForstronglyconvexP(?),\n",
      "thesemethodsachievelinearratesofconvergence[1].\n",
      "Theproximalgradientmethods,thoughsimple,arenotnecessarilyt\n",
      "forlargeproblems.NotethatempiricalriskfunctionF(?)isusuallycomposed\n",
      "ofmanysmoothcomponentfunctions:n\n",
      "F(?)=?\n",
      "1X(?)ni=1\n",
      "n\n",
      "and\n",
      "rF(?)=\n",
      "Bothauthorscontributedequally.\n",
      "1\n",
      "1X(?),ni=1\n",
      "whereeachisassociatedwithafewsamplesofthewholedateset.Since\n",
      "theproximalgradientmethodsneedtocalculatethegradientofFineveryiter-\n",
      "ation,thecomputationalcomplexityscaleslinearlywiththesamplesize(orthe\n",
      "numberofcomponentsfunctions).Thustheoverallcomputationcanbeexpen-\n",
      "siveespeciallywhenthesamplesizeisverylargeinsucha?batch?setting[16].\n",
      "Toovercometheabovedrawback,recentworkhasfocusedonstochasticproxi-\n",
      "malgradientmethods(SPG),whichexploittheadditivenatureoftheempirical\n",
      "riskfunctionF(?).Inparticular,theSPGmethodsrandomlysampleonlyafew\n",
      "?stoestimatethegradientrF(?),i.e.,givenanindexsetB,alsoasknown\n",
      "asamini-batch[16],whereallelementsarePindependentlysampledfrom1\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "withreplacement,weconsideragradientestimator|B|i2B(?).\n",
      "Thuscalculatingsucha?stochastic?gradientcanbefarlessexpensivethan\n",
      "theproximalgradientmethodswithineachiteration.Existingliteraturehas\n",
      "establishedtheglobalconvergenceresultsforthestochasticproximalgradient\n",
      "methods[3,7]basedontheunbiasednessofthegradientestimator,i.e.,\"#1\n",
      "XEB(?)=rF(?)for8?2Rd.|B|i2B\n",
      "However,owingtothevarianceofthegradientestimatorintroducedbythe\n",
      "stochasticsampling,SPGmethodsonlyachievesublinearratesofconvergence\n",
      "evenwhenP(?)isstronglyconvex[3,7].\n",
      "Asecondlineofresearchhasfocusedrandomizedblockcoordinatedescent\n",
      "(RBCD)methods.Thesemethodsexploittheblockseparabilityoftheregular-\n",
      "izationfunctionR,i.e.,givenapartition\n",
      "f\n",
      "G1,...,Gk\n",
      "g\n",
      "ofdcoordinates,weuse\n",
      "vGjtodenotethesubvectorofvwithallindicesinGj,andthenwecanwrite\n",
      "R(?)=\n",
      "kXj=1\n",
      "2\n",
      "\n",
      "rj(?Gj)\n",
      "with?=(?GT1,...,?GTk)T.\n",
      "Accordingly,theydeveloptherandomizedblockcoordinatedescent(RBCD)\n",
      "methods.Inparticular,theblockcoordinatedescentmethodsrandomlyselect\n",
      "ablockofcoordinatesineachiteration,andthenonlycalculatethegradientof\n",
      "Fwithrespecttotheselectedblock[15,13].Sincethevarianceintroducedby\n",
      "theblockselectionasymptoticallygoestozero,theRBCDmethodsalsoattain\n",
      "linearratesofconvergencewhenP(?)isstronglyconvex.Forsparselearning\n",
      "problems,theRBCDmethodshaveanaturaladvantageovertheproximalgradi-\n",
      "entmethods.Becausemanyblocksofcoordinatesstayatzerovaluesthroughout\n",
      "mostofiterations,wecanintegratetheactivesetstrategyintothecomputa-\n",
      "tion.Theactivesetstrategymaintainsanonlyiteratesoverasmallsubsetofall\n",
      "blocks[2],whichgreatlybooststhecomputationalperformance.Recentwork\n",
      "hascorroboratedtheempiricaladvantageofRBCDmethodsovertheproximal\n",
      "gradientmethod[4,20,8].TheRBCDmethods,however,stillrequiresthat\n",
      "allcomponentfunctionsareaccessiblewithineveryiterationsothatthepartial\n",
      "gradientcanbeexactlyobtained.Toaddressthisissue,weproposeastochastic\n",
      "variantoftheRBCDmethods,whichsharestheadvantagewithboththeSPG\n",
      "andRBCDmethods.Moresp,werandomlyselectablockofcoordi-\n",
      "natesineachiteration,andestimatethecorrespondingpartialgradientbased\n",
      "onamini-batchof?ssampledfromallcomponentfunctions.Toaddressthe\n",
      "varianceintroducedbystochasticsampling,weexploitthesemi-stochasticop-\n",
      "timizationschemeproposedin[5,6].Thesemi-stochasticoptimizationscheme\n",
      "containstwonestedloops:Foreachiterationoftheouterloop,wecalculate\n",
      "anexactgradient.Theninthefollow-upinnerloop,weadjustallestimated\n",
      "partialgradientsbytheobtainedexactgradient.Suchamothough\n",
      "simple,hasaprofoundimpact:theamortizedcomputationalcomplexityin\n",
      "eachiterationissimilartothestochasticoptimization,buttherateofconver-\n",
      "genceisnotcompromised.Theoretically,weshowthatwhenP(?)isstrongly\n",
      "convex,theMRBCDmethodattainsbetteroveralliterationcomplexitythan\n",
      "existingRBCDmethods.WethenapplytheMRBCDmethodcombinedwith\n",
      "theactivesetstrategytosolvetheregularizedsparselearningproblems.Our\n",
      "numericalexperimentsshowsthattheMRBCDmethodachievesmuchbetter\n",
      "computationalperformancethanexistingmethods.Acloselyrelatedmethod\n",
      "isthestochasticproximalvariancereducedgradientmethodproposedin[21].\n",
      "Theirmethodisavariantofthestochasticproximalgradientmethodsusing\n",
      "thesamesemistochasticoptimizationschemeasours,buttheirmethodinherits\n",
      "thesamedrawbackastheproximalgradientmethod,anddoesnotfullyexploit\n",
      "theunderlyingsparsitystructureforlargesparselearningproblems.Wewill\n",
      "compareitscomputationalperformancewiththeMRBCDmethodinnumerical\n",
      "2\n",
      "experiments.Notethattheirmethodcanbeviewedasaspecialexampleof\n",
      "theMRBCDmethodwithonesingleblock.Whilethispaperwasunderreview,\n",
      "welearntthatasimilarmethodwasindependentlyproposedby[18].Theyalso\n",
      "applythevariancereductiontechniqueintotherandomizedblockcoordinate\n",
      "descentmethod,andobtainsimilartheoreticalresultstoours.\n",
      "3\n",
      "\n",
      "2\n",
      "NotationsandAssumptions\n",
      "PPGivenavectorv=(v1,...,vd)T2Rd,wevectornorms:\n",
      "||v||1=j|vj|,||v||2=jvj2,and||v||1=maxj|vj|.\n",
      "Let\n",
      "f\n",
      "G1,...,Gk\n",
      "g\n",
      "beapartitionofalldcoordinateswith|Gj|=pjandPk\n",
      "j=1pj=d.WeusevGjtodenotethesubvectorofvwithallindicesinGj,and\n",
      "vGjtodenotethesubvectorofvwithallindicesinGjremoved.Throughout\n",
      "therestofthepaper,ifnotspeced,wemakethefollowingassumptionson\n",
      "P(?).\n",
      "Assumption2.1.Each(?)isconvexandtiable.Giventhepartition\n",
      "f\n",
      "G1,...,Gk\n",
      "g\n",
      ",allrGj(?)=(?)]Gj?sareLipschitzcontinuous,i.e.,there\n",
      "existsapositiveconstantsLmaxsuchthatforall?,?02Rdand?Gj6=?G0\n",
      "j,wehaverGj(?0)||?Lmax||?Gj\n",
      "||rGj(?)\n",
      "?G0j||.\n",
      "Moreover,(?)isLipschitzcontinuous,i.e.,thereexistsapositiveconstant\n",
      "Tmaxforall?,?02Rdand?6=?0,wehave(?)\n",
      "(?0)||?Tmax||?\n",
      "?0||.\n",
      "Assumption2.1alsoimpliesthatrF(?)isLipschitzcontinuous,andgiven\n",
      "thetightestTmaxandLmaxinAssumption2.1,wehaveTmax?kLmax.\n",
      "Assumption2.2.F(?)isstronglyconvex,i.e.,forall?and?0,thereexistsa\n",
      "positiveconstant?suchthat?0||??||2.F(?0)F(?)+rF(?)T(?0\n",
      "?)2NotethatAssumption2.2alsoimpliesthatP(?)isstronglyconvex.\n",
      "Assumption2.3.R(?)isasimpleconvexnonsmoothfunctionsuchthat\n",
      "givensomepositiveconstant?,wecanobtainaclosedformsolutiontothe\n",
      "followingoptimizationproblem,T?j(?G0j)=argmin?Gj2R\n",
      "pj\n",
      "1||?Gj2?\n",
      "?G0j||2+rj(?).\n",
      "Assumptions2.1-2.3arebymanypopularregularizedempiricalrisk\n",
      "minimizationproblems.Wegivesomeexamplesintheexperimentssection.\n",
      "3\n",
      "Method\n",
      "TheMRBCDmethodisdoublystochastic,inthesensethatwenotonly\n",
      "randomlyselectablockofcoordinates,butalsorandomlysampleamini-batch\n",
      "ofcomponentfunctionsfromall?s.Thepartialgradientoftheselectedblock\n",
      "isestimatedbasedontheselectedcomponentfunctions,whichyieldsamuch\n",
      "lowercomputationalcomplexitythanexistingRBCDmethodsineachiteration.\n",
      "AnaiveimplementationoftheMRBCDmethodissummarizedinAlgorithm1.\n",
      "Sincethevarianceintroducedbystochasticsamplingovercomponentfunctions\n",
      "doesnotgotozeroasthenumberofiterationincreases,wehavetochoosea\n",
      "sequenceofdiminishingstepsizes(e.g.?t=?1t1)toensuretheconvergence.\n",
      "Whentislarge,weonlygainverylimiteddescentineachiteration.Thusthe\n",
      "MRBCD-Imethodcanonlyattainasublinearrateofconvergence.3\n",
      "4\n",
      "\n",
      "Algorithm1Mini-batchRandomizedBlockCoordinateDescentMethod-I:\n",
      "ANaiveImplementation.Thestochasticsamplingovercomponentfunctions\n",
      "introducesvariancetothepartialgradientestimator.Toensuretheconver-\n",
      "gence,weadoptasequenceofdiminishingstepsizes,whicheventuallyleadsto\n",
      "sublinearratesofconvergence.Parameter:Stepsize?tInitialize:?(0)Fort=\n",
      "1,2,...Randomlysampleamini-batchBfrom\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "withequalprobability\n",
      "Randomlysamplejfrom\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      "with?equalprobability?(t)(t1)(t)(t1)j\n",
      "?GjT?t?Gj?trGjfB(?(t1)),?Gj?GjEndfor3.1\n",
      "MRBCDwithVarianceReduction\n",
      "Arecentlineofworkshowshowtoreducethevarianceinthegradientestima-\n",
      "tionwithoutdeterioratingratesofconvergenceusingasemi-stochasticoptimiza-\n",
      "tionscheme[5,6].Thesemi-stochasticoptimizationcontainstwonestedloops:\n",
      "Ineachiterationoftheouterloop,wecalculateanexactgradient;Thenwithin\n",
      "thefollow-upinnerloop,weusetheobtainedexactgradienttoadjustallesti-\n",
      "matedpartialgradients.Theseadjustmentscanguaranteethatthevariancein-\n",
      "troducedbystochasticsamplingovercomponentfunctionsasymptoticallygoes\n",
      "tozero(see[5]).Algorithm2Mini-batchRandomizedBlockCoordinateDescent\n",
      "Method-II:MRBCD+VarianceReduction.Weperiodicallycalculatetheexact\n",
      "gradientatthebeginningofeachouterloop,andthenusetheobtainedexact\n",
      "gradienttoadjustallfollow-upestimatedpartialgradients.Theseadjustments\n",
      "guaranteethatthevarianceintroducedbystochasticsamplingovercomponent\n",
      "functionsasymptoticallygoestozero,andhelptheMRBCDIImethodattain\n",
      "linearratesofconvergence.Parameter:updatefrequencymandstepsize?\n",
      "Initialize:?e(0)Fors=1,2,...e?e?e(s1),?rF(?e(s1)),?(0)?e(s1)For\n",
      "t=1,2,...,mRandomlysampleamini-batchBfrom\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "withequal\n",
      "probabilityRandomlysample?jfrom\n",
      "f\n",
      "1,h...,k\n",
      "g\n",
      "withequalprobabilityi?(t)\n",
      "(t1)(t)(t1)je+?eGj,?Gj?GjT??Gj?rGjfB(?(t1))rGjfB(?)\n",
      "?GjEndforPm(l)?e(s)l=1?EndforTheMRBCDmethodwithvariance\n",
      "reductionissummarizedinAlgorithm2.Inthenextsection,wewillshowthat\n",
      "theMRBCDIImethodattainslinearratesofconvergence,andtheamortized\n",
      "computationalcomplexitywithineachiterationisalmostthesameasthatof\n",
      "theMRBCDImethod.Remark3.1.Anotheroptionforthevariancereduc-\n",
      "tionisthestochasticaveragingschemeasproposedin[14],whichstoresthe\n",
      "gradientsofmostrecentlysubsampledcomponentfunctions.ButtheMRBCD\n",
      "methoditeratesrandomlyovertblocksofcoordinates,whichmakesthe\n",
      "stochasticaveragingschemeinapplicable.3.2\n",
      "MRBCDwithVarianceReductionandActiveSetStrategy\n",
      "WhenapplyingtheMRBCDIImethodtoregularizedsparselearningprob-\n",
      "lems,wefurtherincorporatetheactivesetstrategytoboosttheempiricalper-\n",
      "formance.tfromexistingRBCDmethods,whichusuallyidentifythe\n",
      "activesetbycyclicsearch,weexploitaproximalgradientpilottoidentifythe\n",
      "activeset.Moresp,withineachiterationoftheouterloop,weconduct\n",
      "aproximalgradientdescentstep,andselectthesupportoftheresultingsolution\n",
      "astheactiveset.ThisisverynaturaltotheMRBCD-IImethod.Becauseat\n",
      "thebeginningofeachouterloop,wealwayscalculateanexactgradient,and\n",
      "deliveringaproximalgradientpilotwillnotintroducemuchaddi4\n",
      "5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tionalcomputationalcost.Oncetheactivesetisidenallrandomized\n",
      "blockcoordinatedescentstepswithinthefollow-upinnerlooponlyiteratesover\n",
      "blocksofcoordinatesintheactiveset.Algorithm3Mini-batchRandomized\n",
      "BlockCoordinateDescentMethod-III:MRBCDwithVarianceReductionand\n",
      "ActiveSet.Tofullytakeadvantageoftheobtainedexactgradient,weadopta\n",
      "proximalgradientpilot?(0)toidentifytheactivesetateachiterationofthe\n",
      "outerloop.Thenallrandomizedcoordinatedescentstepswithinthefollow-up\n",
      "innerlooponlyiterateoverblocksofcoordinatesintheactiveset.Parameter:\n",
      "updatefrequencymandstepsize?Initialize:?e(0)Fors=1,2,...e?e?e(s1)\n",
      ",?rF(?e(s1))Forj=1,2,...,k??(0)jeGj/k?GjT?/k?eGj??Endfor\n",
      "(0)A\n",
      "f\n",
      "j|?Gj6=0\n",
      "g\n",
      ",|B|=|A|Fort=1,2,...,m|A|/kRandomly\n",
      "sampleamini-batchBfrom\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      "withequalprobabilityRandomlysample\n",
      "jfrom\n",
      "f\n",
      "1,...,k\n",
      "g\n",
      "withequalprobabilityForallj2?Aehi?(t)(t1)(t)(t1)e\n",
      "+?eGj,?Gj?GjT?j?Gj?rGjfB(?(t1))rGjfB(?)?GjEndforPm(l)\n",
      "?e(s)l=1?Endfor\n",
      "TheMRBCDmethodwithvariancereductionandactivesetstrategyissum-\n",
      "marizedinAlgorithm3.Sinceweintegratetheactivesetintothecomputation,\n",
      "asuccessive|A|coordinatedecentiterationsinMRBCD-IIIwillhavesimilar\n",
      "performanceaskiterationsinMRBCD-II.Thereforewechangethemaximum\n",
      "numberofiterationswithineachinnerloopto|A|m/k.Moreover,sincethe\n",
      "supportisonly|A|blocksofcoordinates,weonlyneedtotake|B|=\n",
      "|A|toguaranteetvariancereduction.Thesemowillfur-\n",
      "therboostthecomputationalperformanceofMRBCD-III.Remark3.2.The\n",
      "exactgradientcanbealsousedtodeterminetheconvergenceoftheMRBCDIII\n",
      "method.WeterminatetheiterationwhentheapproximateKKTconditionis\n",
      "e+?||?\",where\"isapositivepresetconvergenceparameter.\n",
      "Sinceevaluatmin?2@R(?)e||?ingwhethertheapproximateKKTcondition\n",
      "holdsisbasedontheexactgradientobtainedateachiterationoftheouterloop,\n",
      "itdoesnotintroducemuchadditionalcomputationalcost,either.\n",
      "4\n",
      "Theory\n",
      "BeforeweproceedwithourmainresultsoftheMRBCD-IImethod,we\n",
      "introducetheimportantlemmaforcontrollingthevarianceintroducedby\n",
      "stochasticsampling.P1(t1))Lemma4.1.LetBbeamini-batchsampled\n",
      "from\n",
      "f\n",
      "1,...,n\n",
      "g\n",
      ".vB=|B|i2|B|(?P1(t1)(t1)e+?.e\n",
      "Conditioningon?(?),wehaveEBvB=rF(?)and|B|\n",
      "i2|B|\n",
      "EB||vB\n",
      "rF(?(t\n",
      "1)\n",
      ")||2?\n",
      "4TmaxhP(?(t|B|\n",
      "1)\n",
      ")\n",
      "b+P(?)eP(?)\n",
      "ib.P(?)\n",
      "6\n",
      "\n",
      "TheproofofLemma4.1isprovidedinAppendixA.Lemma4.1guarantees\n",
      "thatvisanunbiasedestimatorofF(?),anditsvarianceisboundedbythe\n",
      "objectivevaluegap.Thereforewedonotneedtochooseasequencediminishing\n",
      "stepsizestoreducethevariance.4.1\n",
      "StronglyConvexFunctions\n",
      "WethenpresenttheconcreteratesofconvergenceofMRBCD-IIwhenPis\n",
      "stronglyconvex.5\n",
      "Theorem4.2.SupposethatAssumptions2.1-2.3hold.Let?e(s)bearandom\n",
      "pointgeneratedbytheMRBCD-IImethodinAlgorithm2.Givenalargeenough\n",
      "batchBandasmallenoughlearningrate1?suchthat|B|Tmax/Lmax\n",
      "and?<Lmax/4,wehave??sk4?Lmax(m+1)(s)ebbEP(?)P(?)?+\n",
      "[P(?e(0))P(?)].??(14?Lmax)m(14?Lmax)m\n",
      "Hereweonlypresentasketch.ThedetailedproofisprovidedinAppendix\n",
      "B.Theexpectedsuccessivedescentoftheobjectivevalueiscomposedoftwo\n",
      "terms:Theoneisthesameastheexpectedsuccessivedescentofthe\n",
      "?batch?RBCDmethods;Thesecondoneisthevarianceintroducedbythe\n",
      "stochasticsampling.Thedescenttermcanbeboundedbytakingtheaverage\n",
      "ofthesuccessivedescentoverallblocksofcoordinates.Thevariancetermcan\n",
      "beboundedusingLemma4.1.Themini-batchsamplingandadjustmentsof??s\n",
      "guaranteesthatthevarianceasymptoticallygoestozeroataproperscale.By\n",
      "takingexpectationovertherandomnessofcomponentfunctionsandblocksof\n",
      "coordinatesthroughoutalliterations,wederiveageometricrateofconvergence.\n",
      "ThenextcorollarypresenttheconcreteiterationcomplexityoftheMRBCD-II\n",
      "method.Corollary4.3.SupposethatAssumptions2.1-2.3hold.Let|B|\n",
      "=Tmax/Lmax,m=65kLmax/?,1and?=Lmax/16.Giventhetarget\n",
      "accuracy?andsome?2(0,1),foranyswehaveP(?e(s))\n",
      "3log[P(?e(0))\n",
      "bP(?)/?]+3log(1/?),\n",
      "b??withatlastprobability1P(?)\n",
      "?.\n",
      "Corollary4.3isadirectresultofTheorem4.2andMarkovinequality.The\n",
      "detailedproofisprovidedinAppendixC.Tocharacterizetheoveralliteration\n",
      "complexity,wecountthenumberofpartialgradientsweestimate.Ineach\n",
      "iterationoftheouterloop,wecalculateanexactgradient.Thusthenumber\n",
      "ofestimatedpartialgradientsisO(nk).Withineachiterationoftheinnerloop\n",
      "(mintotal),weestimatethepartialgradientsbasedonamini-batchB.Thus\n",
      "thenumberofestimatepartialgradientsisO(m|B|).Ifwechoose?,m,\n",
      "andBasinCorollary(4.3)andconsider?asaconstant,thentheiteration\n",
      "complexityoftheMRBCD-IImethodwithrespecttothenumberofestimated\n",
      "partialgradientsisO((nk+kTmax/?)?log(1/?)),\n",
      "whichismuchlowerthanthatofexisting?batch?RBCDmethods,O(nkL-\n",
      "max/??log(1/?)).Remark4.4(ConnectiontotheMRBCD-IIImethod).\n",
      "Therestillexistsagapbetweenthetheoryandempiricalsuccessoftheactive\n",
      "setstrategyanditsinexistingliterature,evenforthe?batch?RBCDmeth-\n",
      "ods.WhenincorporatingtheactivesetstrategytotheRBCD-stylemethods,\n",
      "wehaveknownthattheempiricalperformancecanbegreatlyboosted.Howto\n",
      "7\n",
      "\n",
      "exactlycharacterizethetheoreticalspeedupisstilllargelyunknown.There-\n",
      "foreTheorem4.2and4.3canonlyserveasanimprecisecharacterizationof\n",
      "theMRBCD-IIImethod.Aroughunderstandingisthatifthesolutionhasat\n",
      "mostqnonzeroentriesthroughoutalliterations,thentheMRBCD-IIImethod\n",
      "shouldhaveanapproximateoveralliterationcomplexityO((nk+qTmax/?)\n",
      "?log(1/?)).4.2\n",
      "NonstronglyConvexFunctions\n",
      "WhenP(?)isnotstronglyconvex,wecanadoptaperturbationapproach.\n",
      "Insteadofsolving(1.1),weconsidertheminimizationproblemasfollows,?=\n",
      "argminF(?)+||?(0)?2Rd\n",
      "?||2+R(?),\n",
      "(4.1)\n",
      "ewhereissomepositiveperturbationparameter,and?(0)istheinitial\n",
      "value.IfweconsiderF(?)=(0)2eF(?)+||??||in(4.1)asthesmooth\n",
      "empiricalriskfunction,thenF(?)isastronglyconvexfunction.ThusCorollary\n",
      "4.3canbeappliedto(4.1):WhenB,m,?,and?aresuitablychosen,givens\n",
      "3log([P(?(0))\n",
      "P(?)\n",
      "||?(0)\n",
      "6\n",
      "2]/?)+3log(2/?),?||\n",
      "wehaveP(?e(s))P(?e(s))\n",
      "P(?)\n",
      "||?(0)\n",
      "2??/2withatleastprobability1?||\n",
      "?.Wethenhave\n",
      "b?P(?e(s))P(?)bb2+||?(0)?||b2P(?)||?(0)?||\n",
      "2+||?(0)?||b2??/2+||?(0)?P(?e(s))P(?)||?(0)\n",
      "?||\n",
      "b2.?||\n",
      "+||?(0)?||2?P(?)+||?(0)?||b2,wherethesecond\n",
      "inequalitycomesfromthefactthatP(?)(0)2(s)b,wehaveP(?e)P(?)b\n",
      "??.because?istheminimizerto(4.1).Ifwechoose=?/||??||Since\n",
      "dependsonthedesiredaccuracy?,thenumberofestimatedpartialgradients\n",
      "alsodependsb2asaconstant,thentheoveralliterationcomplexityoftheon\n",
      "?.Thusifweconsider||?(0)?||perturbationapproachbecomesO((nk\n",
      "+kTmax/?)?log(1/?)).\n",
      "5\n",
      "NumericalSimulations\n",
      "ThesparselearningproblemofourinterestisLasso,whichsolvesn\n",
      "1X?b=argmin(?)+||?||1?2Rdni=1\n",
      "with=\n",
      "1(yi2\n",
      "xTi?)2.\n",
      "(5.1)\n",
      "8\n",
      "\n",
      "Wesetn=2000andd=1000,andallcovariatevectorsxi?sareindepen-\n",
      "dentlysampledfroma1000-dimensionalGaussiandistributionwithmean0and\n",
      "covariancematrix?,where?jj=1and?jk=0.5forallk6=j.The50\n",
      "entriesoftheregressioncotvector?areindependentlySsamplesfrom\n",
      "auniformdistributionoversupport(2,1)(+1,+2).Theresponsesyi?sare\n",
      "generatedbythelinearmodelyi=xTi?+?i,whereall?i?sareindependently\n",
      "sampledfromastandardGaussiandistributionN(0,1).pWechoose=log\n",
      "d/n,andcomparetheproposedMRBCD-IandMRBCD-IImethodswiththe\n",
      "?batch?proximalgradient(BPG)method[11],thestochasticproximalvariance\n",
      "reducedgradientmethod(SPVRG)[21],andthe?batch?randomizedblockco-\n",
      "ordinatedescent(BRBCD)method[12].Wesetk=100.Allblocksareofthe\n",
      "samesizePn(10coordinates).ForBPG,thestepsizeis1/T,whereTisthe\n",
      "largestsingularvalueofn1i=1xixTi.ForBRBCD,thestepsizePnas1/L,\n",
      "whereListhemaximumoverthelargestsingularvaluesofn1i=1[xi]Gjof\n",
      "allblocks.ForSPVRG,wechoosem=n,andthestepsizeis1/(4T).For\n",
      "MRBCD-I,thestepsizeis1/(Ldt/8000e),wheretistheiterationindex.For\n",
      "MRBCD-II,wechoosem=n,andthestepsizeis1/(4L).Notethatthestepsize\n",
      "andnumberofiterationsmwithineachinnerloopforMRBCD-IIandSPVRG\n",
      "aretunedoverarenedgridsuchthatthebestcomputationalperformanceis\n",
      "obtained.Numberofpartialgradientsestimates\n",
      "2\n",
      "10\n",
      "0\n",
      "ObjectiveValueGap\n",
      "10\n",
      "?2\n",
      "10\n",
      "?4\n",
      "10\n",
      "?6\n",
      "10\n",
      "?8\n",
      "10\n",
      "?10\n",
      "10\n",
      "0\n",
      "MRBCD?IISPVRGBRBCDBPGMRBCD?I1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Numberofpartialgradientestimates\n",
      "8\n",
      "9\n",
      "9\n",
      "\n",
      "106x10\n",
      "9\n",
      "10\n",
      "8\n",
      "10\n",
      "7\n",
      "10\n",
      "MRBCD?IIISPVRGBRBCD\n",
      "6\n",
      "10\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "RegularizationIndex\n",
      "(a)Comparisonbetweentmethodsforasin-(b)Comparisonbetween\n",
      "tmethodsforasegleregularizationparameter.quenceofregularization\n",
      "parameters.\n",
      "binlogscale.Figure5.1:[a]Theverticalaxiscorrespondstoobjectivevalue\n",
      "gapsP(?)P(?)Thehorizontalaxiscorrespondstonumbersofpartialgradi-\n",
      "entestimates.[b]Thehorizontalaxiscorrespondstoindicesofregularization\n",
      "parameters.Theverticalaxiscorrespondstonumbersofpartialgradientesti-\n",
      "matesinlogscale.WeseethatMRBCDattainsthebestperformanceamong\n",
      "allmethodsforbothsettingsWeevaluatethecomputationalperformanceby\n",
      "thenumberofestimatedpartialgradients,andtheresultsaveragedover100\n",
      "replicationsarepresentedinFigure5.1[a].Ascanbeseen,MRBCD-IIout-\n",
      "performsSPVRG,andattainsthebestperformanceamongallmethods.The\n",
      "BRBCDandBPG7\n",
      "performworsethanMRBCD-IIandSPVRGduetohighcomputational\n",
      "complexitywithineachiteration.MRBCD-Iisactuallythefastestamongall\n",
      "methodsatthefewiterations,andthenfallsbehindSPGandSPVRGdue\n",
      "toitssublinearrateofconvergence.WethencomparetheproposedMRBCD-III\n",
      "methodwithSPVRGandBRBCDforasequenceofregularizationparameters.\n",
      "Thesequencecontains21regularizationparameters\n",
      "f\n",
      "0,...,p20\n",
      "g\n",
      ".WePset0\n",
      "=||n1iyixi||1,whichyieldsanullsolution(allentriesarezero),and\n",
      "20=logd/n.ForK=1,...,19,wesetK=?K1,where?=(20/0)1/20.\n",
      "Whensolving(5.1)withrespecttoK,weusetheoutputsolutionforK1asthe\n",
      "initialsolution.Theabovesettingisoftenreferredtothewarmstartschemein\n",
      "existingliterature,anditisverynaturaltosparselearningproblems,sincewe\n",
      "10\n",
      "\n",
      "alwaysneedtotunetheregularizationparametertosecuregoodsample\n",
      "performance.Foreachregularizationparameter,thealgorithmterminatesthe\n",
      "iterationwhentheapproximateKKTconditioniswith?=1010\n",
      ".Theresultsover50replicationsarepresentedinFigure5.1[b].Ascan\n",
      "beseen,MRBCD-IIIoutperformsSPVRGandBRBCD,andattainsthebest\n",
      "performanceamongallmethods.SinceBRBCDisalsocombinedwiththeactive\n",
      "setstrategy,itattainsbetterperformancethanSPVRG.Seemoredetailed\n",
      "resultsinTableE.1inAppendixE\n",
      "6\n",
      "RealDataExample\n",
      "Thesecondsparselearningproblemistheelastic-netregularizedlogistic\n",
      "regression,whichsolvesn\n",
      "1X?b=argmin(?)+?2Rdni=1\n",
      "1||?||1\n",
      "with=log(1+exp(yixTi?))+\n",
      "2\n",
      "2\n",
      "||?||2.\n",
      "Weadoptthercv1datasetwithn=20242andd=47236.Wesetk=\n",
      "200,andeachblockcontainsapproximately237coordinates.Wechoose2=\n",
      "104,and1=104,andcompareMRBCD-IIwithSPVRGandBRBCD.\n",
      "ForPBRBCD,thestepsizeas1/(4L),whereListhemaximumofthelargest\n",
      "singularvaluesofn1ForSPVRG,m=nandthestepsizeis1/(16T),where\n",
      "i=1[xi]GjoverallblocksforBRBCD.nPnTisthelargestsingularvalueof\n",
      "1/n1i=1xixTi.ForMRBCD-II,m=nandthestepsizeisPn1/(16T).For\n",
      "BRBCD,thestepsizeas1/(4L),whereL=n1maxji=1[xi]2jforBRBCD.\n",
      "Notethatthestepsizeandnumberofiterationsmwithineachinnerloopfor\n",
      "MRBCD-IIandSPVRGaretunedoveragridsuchthatthebestcompu-\n",
      "tationalperformanceisobtained.Theresultsaveragedover30replicationsare\n",
      "presentedinFigureF.1[a]ofAppendixF.Ascanbeseen,MRBCD-IIoutper-\n",
      "formsSPVRG,andattainsthebestperformanceamongallmethods.TheBR-\n",
      "BCDperformsworsethanMRBCD-IIandSPVRGduetohighcomputational\n",
      "complexitywithineachiteration.WethencomparetheproposedMRBCD-III\n",
      "methodwithSPVRGandBRBCDforasequenceofregularizationPparame-\n",
      "ters.Thesequencecontains11regularizationparameters\n",
      "f\n",
      "0,...,10\n",
      "g\n",
      ".Weset1\n",
      "4.For0=||i(0)||1,whichyieldsanullsolution(allentriesarezero),\n",
      "and10=1eK=1,...,9,wesetK=?K1,where?=(10/0)1/10.Foreach\n",
      "regularizationparameter,weset?=107fortheapproximateKKTcondition.\n",
      "Theresultsover30replicationsarepresentedinFigureF.1[b]ofAppendixF.\n",
      "Ascanbeseen,MRBCD-IIIoutperformsSPVRGandBRBCD,andattainsthe\n",
      "bestperformanceamongallmethods.SinceBRBCDisalsocombinedwiththe\n",
      "activesetstrategy,itattainsbetterperformancethanSPVRG.Acknowledge-\n",
      "mentsThisworkispartiallysupportedbythegrantsNSFIIS1408910,NSF\n",
      "IIS1332109,NIHR01MH102339,NIHR01GM083084,andNIHR01HG06841.\n",
      "YuissupportedbyChinaScholarshipCouncilandbyNSFC61173073.\n",
      "8\n",
      "11\n",
      "\n",
      "2References\n",
      "[1]AmirBeckandMarcTeboulle.Afastiterativeshrinkage-thresholdingalgo-\n",
      "rithmforlinearinverseproblems.SIAMJournalonImagingSciences,2(1):183?202,\n",
      "2009.[2]S.BoydandL.Vandenberghe.ConvexOptimization.Cambridge\n",
      "UniversityPress,2009.[3]JohnDuchiandYoramSinger.tonlineand\n",
      "batchlearningusingforwardbackwardsplitting.TheJournalofMachineLearn-\n",
      "ingResearch,10:2899?2934,2009.[4]JeromeFriedman,TrevorHastie,Holger\n",
      "andRobertTibshirani.Pathwisecoordinateoptimization.TheAn-\n",
      "nalsofAppliedStatistics,1(2):302?332,2007.[5]RieJohnsonandTongZhang.\n",
      "Acceleratingstochasticgradientdescentusingpredictivevariancereduction.In\n",
      "AdvancesinNeuralInformationProcessingSystems,pages315?323,2013.[6]\n",
      "JakubKone?cn`yandPeterRicht?arik.arXiv:1312.1666,2013.\n",
      "Semi-stochasticgradientdescentmethods.\n",
      "arXivpreprint\n",
      "[7]JohnLangford,LihongLi,andTongZhang.Sparseonlinelearningvia\n",
      "truncatedgradient.JournalofMachineLearningResearch,10(777-801):65,\n",
      "2009.[8]HanLiu,MarkPalatucci,andJianZhang.Blockwisecoordinatede-\n",
      "scentproceduresforthemulti-tasklasso,withapplicationstoneuralsemantic\n",
      "basisdiscovery.InProceedingsofthe26thAnnualInternationalConferenceon\n",
      "MachineLearning,pages649?656,2009.[9]L.Meier,S.VanDeGeer,andP\n",
      "B?uhlmann.Thegrouplassoforlogisticregression.JournaloftheRoyalSta-\n",
      "tisticalSociety:SeriesB,70(1):53?71,2008.[10]SahandNNegahban,Pradeep\n",
      "Ravikumar,MartinJWainwright,andBinYu.Auframeworkforhigh-\n",
      "dimensionalanalysisofm-estimatorswithdecomposableregularizers.Statistical\n",
      "Science,27(4):538?557,2012.[11]YuNesterov.Gradientmethodsformini-\n",
      "mizingcompositeobjectivefunction.Technicalreport,Universit?ecatholique\n",
      "deLouvain,CenterforOperationsResearchandEconometrics(CORE),2007.\n",
      "[12]PeterRicht?arikandMartinTak?ac?.Iterationcomplexityofrandomized\n",
      "block-coordinatedescentmethodsforminimizingacompositefunction.arXiv\n",
      "preprintarXiv:1107.2848,2011.[13]PeterRicht?arikandMartinTak?ac?.\n",
      "Iterationcomplexityofrandomizedblock-coordinatedescentmethodsformin-\n",
      "imizingacompositefunction.MathematicalProgramming,pages1?38,2012.\n",
      "[14]NicolasLRoux,MarkSchmidt,andFrancisRBach.Astochasticgradient\n",
      "methodwithanexponentialconvergenceratefortrainingsets.InAd-\n",
      "vancesinNeuralInformationProcessingSystems,pages2672?2680,2012.[15]\n",
      "ShaiShalev-ShwartzandAmbujTewari.Stochasticmethodsfor`1-regularized\n",
      "lossminimization.TheJournalofMachineLearningResearch,12:1865?1892,\n",
      "2011.[16]SuvritSra,SebastianNowozin,andStephenJWright.Optimization\n",
      "formachinelearning.MitPress,2012.[17]R.Tibshirani.Regressionshrink-\n",
      "ageandselectionviathelasso.JournaloftheRoyalStatisticalSociety,Series\n",
      "B,58(1):267?288,1996.[18]HuahuaWangandArindamBanerjee.Random-\n",
      "izedblockcoordinatedescentforonlineandstochasticoptimization.CoRR,\n",
      "abs/1407.0107,2014.[19]LiWang,JiZhu,andHuiZou.Thedoublyregular-\n",
      "izedsupportvectormachine.StatisticaSinica,16(2):589,2006.[20]TongTong\n",
      "WuandKennethLange.Coordinatedescentalgorithmsforlassopenalizedre-\n",
      "12\n",
      "\n",
      "gression.TheAnnalsofAppliedStatistics,2:224?244,2008.[21]LinXiaoand\n",
      "TongZhang.Aproximalstochasticgradientmethodwithprogressivevariance\n",
      "reduction.arXivpreprintarXiv:1403.4699,2014.[22]MingYuanandYiLin.\n",
      "Modelselectionandestimationinthegaussiangraphicalmodel.Biometrika,\n",
      "94(1):19?35,2007.[23]JiZhu,SaharonRosset,TrevorHastie,andRobertTib-\n",
      "shirani.1-normsupportvectormachines.InNIPS,volume15,pages49?56,\n",
      "2003.[24]HuiZouandTrevorHastie.Regularizationandvariableselectionvia\n",
      "theelasticnet.JournaloftheRoyalStatisticalSociety:SeriesB(Statistical\n",
      "Methodology),67(2):301?320,2005.\n",
      "9\n",
      "13\n",
      "\n",
      "PP6334.pdf\n",
      "PP6334.pdf 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlexibleModelsforMicroclusteringwith\n",
      "ApplicationtoEntityResolution\n",
      "Authoredby:\n",
      "W.Miller\n",
      "BrendaBetancourt\n",
      "GiacomoZanella\n",
      "HannaWallach\n",
      "AbbasZaidi\n",
      "RebeccaC.Steorts\n",
      "Abstract\n",
      "Mostgenerativemodelsforclusteringimplicitlyassumethatthenum-\n",
      "berofdatapointsineachclustergrowslinearlywiththetotalnumber\n",
      "ofdatapoints.Finitemixturemodels,Dirichletprocessmixturemod-\n",
      "els,andPitman{Yorprocessmixturemodelsmakethisassumption,as\n",
      "doallotherexchangeableclusteringmodels.However,forsome\n",
      "applications,thisassumptionisinappropriate.Forexample,whenper-\n",
      "formingentityresolution,thesizeofeachclustershouldbeunrelatedto\n",
      "thesizeofthedataset,andeachclustershouldcontainanegligiblefrac-\n",
      "tionofthetotalnumberofdatapoints.Theseapplicationsrequiremodels\n",
      "thatyieldclusterswhosesizesgrowsublinearlywiththesizeofthedata\n",
      "set.Weaddressthisrequirementbythemicroclusteringproperty\n",
      "andintroducinganewclassofmodelsthatcanexhibitthisproperty.We\n",
      "comparemodelswithinthisclasstotwocommonlyusedclusteringmodels\n",
      "usingfourentity-resolutiondatasets.\n",
      "1PaperBody\n",
      "Manyclusteringapplicationsrequiremodelsthatassumeclustersizesgrowlin-\n",
      "earlywiththesizeofthedataset.Theseapplicationsincludetopicmodeling,\n",
      "inferringpopulationstructure,anddiscriminatingamongcancersubtypes.In-\n",
      "exchangeableclusteringmodels,includingmixturemodels,Dirich-\n",
      "letprocessmixturemodels,andPitman?Yorprocessmixturemodels,allmake\n",
      "thislineargrowthassumption,andhaveseennumeroussuccesseswhenusedin\n",
      "thesecontexts.Forotherclusteringapplications,suchasentityresolution,this\n",
      "assumptionisinappropriate.Entityresolution(includingrecordlinkageand\n",
      "de-duplication)involvesidentifyingduplicate2recordsinnoisydatabases[1,2],\n",
      "1\n",
      "\n",
      "traditionallybydirectlylinkingrecordstooneanother.Unfortunately,this\n",
      "traditionalapproachiscomputationallyinfeasibleforlargedatasets?aserious\n",
      "limitationin?theageofbigdata?[1,3].Asa?\n",
      "GiacomoZanellaandBrendaBetancourtarejointauthors.Inthe\n",
      "entityresolutionliterature,theterm?duplicaterecords?doesnotmeanthat\n",
      "therecordsareidentical,butratherthattherecordsarecorrupted,degraded,\n",
      "orotherwisenoisyrepresentationsofthesameentity.2\n",
      "30thConferenceonNeuralInformationProcessingSystems(NIPS2016),\n",
      "Barcelona,Spain.\n",
      "result,researchersincreasinglytreatentityresolutionasaclusteringprob-\n",
      "lem,whereeachentityisimplicitlyassociatedwithoneormorerecordsandthe\n",
      "inferencegoalistorecoverthelatententities(clusters)thatcorrespondtothe\n",
      "observedrecords(datapoints)[4,5,6].Incontrasttootherclusteringapplica-\n",
      "tions,thenumberofdatapointsineachclustershouldremainsmall,evenfor\n",
      "largedatasets.Applicationslikethisrequiremodelsthatyieldclusterswhose\n",
      "sizesgrowsublinearlywiththetotalnumberofdatapoints[7].Toaddressthis\n",
      "requirement,wethemicroclusteringpropertyinsection2and,insection\n",
      "3,introduceanewclassofmodelsthatcanexhibitthisproperty.Insection\n",
      "4,wecomparetwomodelswithinthisclasstotwocommonlyused\n",
      "exchangeableclusteringmodels.\n",
      "2\n",
      "TheMicroclusteringProperty\n",
      "ToclusterNdatapointsx1,...,xNusingapartition-basedBayesian\n",
      "clusteringmodel,oneplacesaprioroverpartitionsof[N]=\n",
      "f\n",
      "1,...,N\n",
      "g\n",
      ".\n",
      "Then,givenapartitionCNof[N],onemodelsthedatapointsineachpartc\n",
      "?CNasjointlydistributedaccordingtosomechosendistribution.Finally,one\n",
      "computestheposteriordistributionoverpartitionsand,e.g.,usesittoidentify\n",
      "probablepartitionsof[N].Mixturemodelsareawell-knowntypeofpartition-\n",
      "basedBayesianclusteringmodel,inwhichCNisimplicitlyrepresentedbyaset\n",
      "ofclusterassignmentsz1,...,zN.Theseclusterassignmentscanberegarded\n",
      "astheNelementsofaninsequencez1,z2,...,drawnapriorifrom\n",
      "??H\n",
      "iid\n",
      "andz1,z2,...|???,\n",
      "(1)\n",
      "PwhereHisapriorover?and?isavectorofmixtureweightswithl?l=1\n",
      "and?l?0foralll.Commonlyusedmixturemodelsinclude(a)mixtures\n",
      "wherethedimensionalityof?isandHisusuallyaDirichletdistribution;\n",
      "(b)mixtureswherethedimensionalityof?isarandomvariable[8,9];(c)\n",
      "Dirichletprocess(DP)mixtureswherethedimensionalityof?is[10];\n",
      "and(d)Pitman?Yorprocess(PYP)mixtures,whichgeneralizeDPmixtures\n",
      "[11].Equation1implicitlyaprioroverpartitionsofN=\n",
      "f\n",
      "1,2,...\n",
      "g\n",
      ".\n",
      "AnyrandompartitionCNofNinducesasequenceofrandompartitions(CN:\n",
      "N=1,2,...),whereCNisapartitionof[N].Viathestronglawoflarge\n",
      "numbers,theclustersizesinanysuchsequenceobtainedviaequation1grow\n",
      "PNlinearlywithNbecause,withprobabilityone,foralll,N1n=1I(zn=l)\n",
      "2\n",
      "\n",
      "??lasN??,whereI(?)denotestheindicatorfunction.Unfortunately,this\n",
      "lineargrowthassumptionisnotappropriateforentityresolutionandotherap-\n",
      "plicationsthatrequireclusterswhosesizesgrowsublinearlywithN.Toaddress\n",
      "thisrequirement,wethereforethemicroclusteringproperty:Asequence\n",
      "ofrandompartitions(CN:N=1,2,...)exhibitsthemicroclusteringprop-\n",
      "ertyifMNisop(N),whereMNisthesizeofthelargestclusterinCN,or,\n",
      "equivalently,ifMN/N?0inprobabilityasN??.Aclusteringmodelexhibits\n",
      "themicroclusteringpropertyifthesequenceofrandompartitionsimpliedby\n",
      "thatmodeltheaboveNomixturemodelcanexhibitthe\n",
      "microclusteringproperty(unlessitsparametersareallowedtovarywithN).\n",
      "Infact,Kingman?spaintboxtheorem[12,13]impliesthatanyexchangeable\n",
      "partitionofN,suchasapartitionobtainedusingequation1,iseitherequalto\n",
      "thetrivialpartitioninwhicheachpartcontainsoneelementorliminfN\n",
      "??MN/N>0withpositiveprobability.ByKolmogorov?sextensiontheorem,\n",
      "asequenceofrandompartitions(CN:N=1,2,...)correspondstoanex-\n",
      "changeablerandompartitionofNwhenever(a)eachCNisexchangeable\n",
      "(i.e.,itsprobabilityisinvariantunderpermutationsof\n",
      "f\n",
      "1,...,N\n",
      "g\n",
      ")and(b)\n",
      "thesequenceisprojective(alsoknownasconsistentindistribution)?i.e.,ifN0\n",
      "<N,thedistributionoverCN0coincideswiththemarginaldistributionover\n",
      "partitionsof[N0]inducedbythedistributionoverCN.Therefore,toobtain\n",
      "anontrivialmodelthatexhibitsthemicroclusteringproperty,wemust\n",
      "either(a)or(b).Previouswork[14](a);inthispaper,weinstead\n",
      "(b).exchangeabilityandscingprojectivityhave\n",
      "veryrentconsequences.Ifapartition-basedBayesianclusteringmodelis\n",
      "notexchangeable,theninferencewilldependontheorderofthedata\n",
      "points.Formostapplications,thisconsequenceisundesirable?thereisnorea-\n",
      "sontobelievethattheorderofthedatapointsismeaningful.Incontrast,ifa\n",
      "modellacksprojectivity,thentheimpliedjointdistributionoverasubsetofthe\n",
      "datapointsinadatasetwillnotbethesameasthejointdistributionobtained\n",
      "bymodelingthesubsetdirectly.Inthecontextofentityresolution,\n",
      "projectivityisamorenaturalandlessrestrictivechoicethan\n",
      "exchangeability.2\n",
      "3\n",
      "KolchinPartitionModelsforMicroclustering\n",
      "WeintroduceanewclassofBayesianmodelsformicroclusteringbyplacing\n",
      "aprioronthenumberofclustersKand,givenK,modelingtheclustersizesN1\n",
      ",...,NKdirectly.WestartbyK??and\n",
      "iid\n",
      "N1,...,NK|K??,\n",
      "(2)\n",
      "where?=(?1,?2,...)and?=(?1,?2,...)areprobability\n",
      "distributionsoverN=\n",
      "f\n",
      "1,2,...\n",
      "g\n",
      ".PKWethenN=k=1Nkand,given\n",
      "N1,...,NK,generateasetofclusterassignmentsz1,...,zNbydrawing\n",
      "avectoruniformlyatrandomfromthesetofpermutationsof(1,...,1,2,.\n",
      "..,2,......,K,...,K).Theclusterassignmentsz1,...,zNinduce\n",
      "arandompar|\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "f\n",
      "z\n",
      "g\n",
      "N1times\n",
      "3\n",
      "\n",
      "N2times\n",
      "NKtimes\n",
      "titionCNof[N],whereNisitselfarandomvariable?i.e.,CNisarandom\n",
      "partitionofarandomnumberofelements.Werefertotheresultingclass\n",
      "ofmarginaldistributionsoverCNasKolchinpartition(KP)models[15,16]\n",
      "becausetheformofequation2iscloselyrelatedtoKolchin?srepresentation\n",
      "theoremforGibbs-typepartitions(see,e.g.,16,theorem1.2).Forappropriate\n",
      "choicesof?and?,KPmodelscanexhibitthemicroclusteringproperty(see\n",
      "appendixBforanexample).S?IfCNdenotesthesetofallpossiblepartitions\n",
      "of[N],thenN=1CNistheS?setofallpossiblepartitionsof[N]forallN?N.\n",
      "TheprobabilityofanygivenpartitionCN?N=1CNis!Y|CN|!?|CN\n",
      "|P(CN)=|c|!?|c|,(3)N!c?CN\n",
      "where|?|denotesthecardinalityofaset,|CN|isthenumberof\n",
      "clustersinCN,and|c|isthenumberofelementsinclusterc.Inpractice,\n",
      "however,NConditionedon\n",
      "Qisusuallyobserved.N,aKPmodelimpliesthatP(CN|N)?|CN\n",
      "|!?|CN||c|!?.Equation3leadstoa|c|c?CN?reseatingalgo-\n",
      "rithm??muchliketheChineserestaurantprocess(CRP)?derivedbysampling\n",
      "fromP(CN|N,CNn),whereCNnisthepartitionobtainedbyremoving\n",
      "elementnfromCN:?forn=1,...,N,reassignelementnto?an\n",
      "existingclusterc?CNnwithprobability?(|c|+1)?oranewcluster\n",
      "withprobability?(|CNn|+1)\n",
      "?(|c|+1)?|c|\n",
      "?(|CNn|+1)?|CNn|?1.\n",
      "WecanusethisreseatingalgorithmtodrawsamplesfromP(CN|N);\n",
      "however,unliketheCRP,itdoesnotproduceanexactsampleifitisused\n",
      "toincrementallyconstructapartitionfromtheemptyset.Inpractice,this\n",
      "limitationdoesnotleadtoanynegativeconsequencesbecausestandardposterior\n",
      "inferencesamplingmethodsdonotrelyonthisproperty.WhenaKPmodelis\n",
      "usedasthepriorinapartition-basedclusteringmodel?e.g.,asanalternative\n",
      "toequation1?theresultingGibbssamplingalgorithmforCNissimilartothis\n",
      "reseatingalgorithm,butaccompaniedbylikelihoodterms.Unfortunately,this\n",
      "algorithmisslowforlargedatasets.InappendixC,wethereforeproposea\n",
      "fasterGibbssamplingalgorithm?thechaperonesalgorithm?thatisparticularly\n",
      "wellsuitedtomicroclustering.Insections3.1and3.2,weintroducetworelated\n",
      "KPmodelsformicroclustering,andinsection3.4weexplainhowKPmodels\n",
      "canbeappliedinthecontextofentityresolutionwithcategoricaldata.3.1\n",
      "TheNBNBModel\n",
      "Westartwithequation3anddene?=NegBin(a,q)\n",
      "and\n",
      "?=NegBin(r,p),\n",
      "(4)\n",
      "whereNegBin(a,q)andNegBin(r,p)arenegativebinomialdistributions\n",
      "truncatedtoN=\n",
      "f\n",
      "1,2,...\n",
      "g\n",
      ".Weassumethata>0andq?(0,1)are\n",
      "hyperparameters,whilerandparedistributedasr?Gam(?r,sr)and\n",
      "4\n",
      "\n",
      "p?Beta(up,vp)forxed?r,sr,upandvp.3Werefertotheresult-\n",
      "ingmarginaldistributionoverCNasthenegativebinomial?negativebinomial\n",
      "(NBNB)model.3\n",
      "Weusetheshape-and-rateparameterizationofthegammadistribution.\n",
      "3\n",
      "7\n",
      "8\n",
      "9\n",
      "?4\n",
      "?26\n",
      "?6\n",
      "log(MN/N)\n",
      "?4?6\n",
      "log(MN/N)\n",
      "5\n",
      "5\n",
      "6\n",
      "log(N)\n",
      "7\n",
      "8\n",
      "9\n",
      "log(N)\n",
      "Figure1:TheNBNB(left)andNBD(right)modelsappeartoexhibitthe\n",
      "microclusteringproperty.Bysubstitutingequation4intoequation3,weobtain\n",
      "theprobabilityofCNconditionedN:P(CN|N,a,q,r,p)??(|CN|+\n",
      "a)?|CN|\n",
      "Y?(|c|+r),?(r)\n",
      "(5)\n",
      "c?CNr\n",
      "q(1?p)where?=1?(1?p)r.Weprovidethecompletederivationofequation\n",
      "5,alongwiththeconditionalposteriordistributionsoverrandp,inappendix\n",
      "A.2.PosteriorinferencefortheNBNBmodelinvolvesalternatingbetween(a)\n",
      "samplingCNfromP(CN|N,a,q,r,p)usingthechaperonesalgorithmand\n",
      "(b)samplingrandpfromtheirrespectiveconditionalposteriorsusing,e.g.,\n",
      "slicesampling[17].\n",
      "3.2\n",
      "TheNBDModel\n",
      "Although?=NegBin(a,q)willyieldplausiblevaluesofK,?=NegBin\n",
      "(r,p)maynotbetlytocapturerealisticpropertiesofN1,\n",
      "...,NK,especiallywhenKislarge.Forexample,inarecord-linkage\n",
      "applicationinvolvingtwootherwisenoise-freedatabasescontainingthousands\n",
      "ofrecords,KwillbelargeandeachNkwillbeatmosttwo.Anegativebinomial\n",
      "distributioncannotcapturethisproperty.WethereforeasecondKP\n",
      "model?thenegativebinomial?Dirichlet(NBD)model?bytakinganonparametric\n",
      "approachtomodelingN1,...,NKanddrawing?froman\n",
      "Dirichletdistributionoverthepositiveintegers:\n",
      "5\n",
      "\n",
      "?=NegBin(a,q)and?|?,?(0)?Dir?,?(0),(6)(0)\n",
      "(0)\n",
      "where?>0isaconcentrationparameterand?(0)=(?1,?2,???\n",
      ")isabasemeasureP?(0)(0)withm=1?m=1and?m?0forallm.\n",
      "TheprobabilityofCNconditionedonNand?isYP(CN|N,a,q,?)??\n",
      "(|CN|+a)q|CN||c|!?|c|.(7)c?CN\n",
      "PosteriorinferencefortheNBDmodelinvolvesalternatingbetween(a)sam-\n",
      "plingCNfromP(CN|N,a,q,?)usingthechaperonesalgorithmand(b)\n",
      "sampling?fromitsconditionalposterior:\n",
      "(0)(0)?|CN,?,?(0)?Dir??1+L1,??2+L2,...,(8)whereLm\n",
      "isthenumberofclustersofsizeminCN.Although?isan\n",
      "vector,onlytheNelementstP(CN|a,q,?).Therefore,itis\n",
      "ttosamplethePN(N+1)-dimensionalvector(?1,...,?N,1?\n",
      "m=1?m)fromequation8,modaccordingly,andretainonly?1,...,?N\n",
      ".Weprovidecompletederivationsofequations7and8inappendixA.3.3.3\n",
      "TheMicroclusteringPropertyfortheNBNBandNBDModels\n",
      "Figure1containsempiricalevidencesuggestingthattheNBNBandNBD\n",
      "modelsbothexhibitthemicroclusteringproperty.Foreachmodel,wegenerated\n",
      "samplesofMN/NforN=100,...,104.FortheNBNBmodel,weset\n",
      "a=1,q=0.5,r=1,andp=0.5andgeneratedthesamplesusingrejection\n",
      "sampling.FortheNBDmodel,weseta=1,q=0.5,and?=1andset?(0)\n",
      "tobeageometricdistributionoverN=\n",
      "f\n",
      "1,2,...\n",
      "g\n",
      "withaparameterof0.5.\n",
      "WegeneratedthesamplesusingMCMCmethods.Forbothmodels,MN/N\n",
      "appearstoconvergetozeroinprobabilityasN??,asdesired.InappendixB,\n",
      "wealsoprovethatavariantoftheNBNBmodelexhibitsthemicroclustering\n",
      "property.4\n",
      "3.4\n",
      "ApplicationtoEntityResolution\n",
      "KPmodelscanbeusedtoperformentityresolution.Inthiscontext,the\n",
      "datapointsx1,...,xNareobservedrecordsandtheKclustersarelatent\n",
      "entities.IfeachrecordconsistsofFcategoricalthenCN?KPmodel?f\n",
      "k|?f,?f?Dir?f,?f\n",
      "(9)\n",
      "zn??(CN,n)xfn|zn,?f1,...,?fK?Cat(?fzn)\n",
      "(10)(11)(12)\n",
      "forf=1,...,F,k=1,...,K,andn=1,...,N,where\n",
      "?(CN,n)mapsthenthrecordtoalatentclusterassignmentznaccordingto\n",
      "CN.Weassumethat?f>0isdistributedas?f?Gam(1,1),while?fis\n",
      "ViaDirichlet?multinomialconjugacy,wecanmarginalizeover?11,.\n",
      "..,?FKtoobtainaclosed-formexpressionforP(x1,...,xN|z1\n",
      ",...,zN,?f,?f).Posteriorinferenceinvolvesalternatingbetween(a)\n",
      "samplingCNfromP(CN|x1,...,xN,?f)usingthechaperonesalgorithm\n",
      "accompaniedbyappropriatelikelihoodterms,(b)samplingtheparametersof\n",
      "theKPmodelfromtheirconditionalposteriors,and(c)sampling?ffromits\n",
      "conditionalposteriorusingslicesampling.\n",
      "4\n",
      "6\n",
      "\n",
      "Experiments\n",
      "Inthissection,wecomparetwoentityresolutionmodelsbasedontheNBNB\n",
      "modelandtheNBDmodeltotwosimilarmodelsbasedontheDPmixture\n",
      "model[10]andthePYPmixturemodel[11].Allfourmodelsusethelikelihood\n",
      "inequations10and12.FortheNBNBmodelpandtheNBDmodel,weseta\n",
      "andqtoaweaklyinformativepriorbeliefthatE[K]=Var[K]=N2.For\n",
      "theNBNBmodel,weset?r=sr=1andup=vp=2.4FortheNBDmodel,we\n",
      "set?=1andset?(0)tobeageometricdistributionoverN=\n",
      "f\n",
      "1,2,...\n",
      "g\n",
      "with\n",
      "aparameterof0.5.ThisbasemeasureapriorbeliefthatE[Nk]=2.\n",
      "Finally,toensureafaircomparisonbetweenthetwotclassesofmodel,\n",
      "wesettheDPandPYPconcentrationparameterstoapriorbeliefthat\n",
      "E[K]=N2.Weassesshowwelleachmodelfourdatasetstypicalof\n",
      "thosearisinginreal-worldentityresolutionapplications.Foreachdataset,we\n",
      "considerfourstatistics:(a)thenumberofsingletonclusters,(b)themaximum\n",
      "clustersize,(c)themeanclustersize,and(d)the90thpercentileofclustersizes.\n",
      "Wecompareeachstatistic?struevaluetoitsposteriordistributionaccordingto\n",
      "eachofthemodels.Foreachmodelanddatasetcombination,wealsoconsider\n",
      "eentity-resolutionsummarystatistics:(a)theposteriorexpectednumberof\n",
      "clusters,(b)theposteriorstandarderror,(c)thefalsenegativerate,(d)the\n",
      "falsediscoveryrate,and(e)theposteriorexpectedvalueof?f=?forf=1,.\n",
      "..,F.Thefalsenegativeandfalsediscoveryratesarebothinvariantunder\n",
      "permutationsof1,...,K[5,18].4.1\n",
      "DataSets\n",
      "Weconstructedfourrealisticdatasets,eachconsistingofNrecordsasso-\n",
      "ciatedwithKentities.Italy:WederivedthisdatasetfromtheSurveyon\n",
      "HouseholdIncomeandWealth,conductedbytheBankofItalyeverytwoyears.\n",
      "Thereareninecategoricalincludingyearofbirth,employmentstatus,\n",
      "andhighestlevelofeducationattained.Groundtruthisavailableviaunique\n",
      "idenbaseduponsocialsecuritynumbers;roughly74%oftheclustersare\n",
      "singletons.Weusedthe2008and2010databasesfromtheFruiliregiontocreate\n",
      "arecord-linkagedatasetconsistingofN=789records;eachNkisatmosttwo.\n",
      "Wediscardedtherecordsthemselves,butpreservedthenumberofthe\n",
      "empiricaldistributionofcategoriesforeachthenumberofclusters,and\n",
      "theclustersizes.Wethengeneratedsyntheticrecordsusingequations10and\n",
      "12.Wecreatedthreevariantsofthisdataset,correspondingto?=0.02,0.05,\n",
      "0.1.Forallthree,weusedtheempiricaldistributionofcategoriesforfas\n",
      "?f.Bygeneratingsyntheticrecordsinthisfashion,wepreservethepertinent\n",
      "characteristicsoftheoriginaldata,whilemakingiteasytoisolatetheimpacts\n",
      "ofthetpriorsoverpartitions.NLTCS5000:Wederivedthisdataset\n",
      "fromtheNationalLongTermCareSurvey(NLTCS)5?alongitudinalsurveyof\n",
      "olderAmericans,conductedroughlyeverysixyears.Weusedfourofthe45\n",
      "Weusedp?Beta(2,2)becauseauniformpriorimpliesanunrealisticprior\n",
      "beliefthatE[Nk]=?.http://www.nltcs.aas.duke.edu/\n",
      "5\n",
      "availabledateofbirth,sex,stateofresidence,andregionalWe\n",
      "splitdateofbirthintothreeseparateday,month,andyear.Ground\n",
      "7\n",
      "\n",
      "truthisavailableviasocialsecuritynumbers;roughly68%oftheclustersare\n",
      "singletons.Weusedthe1982,1989,and1994databasesanddown-sampledthe\n",
      "records,preservingtheproportionofclustersofeachsizeandthemaximumclus-\n",
      "tersize,tocreatearecord-linkagedatasetofN=5,000records;eachNkisat\n",
      "mostthree.Wethengeneratedsyntheticrecordsusingthesameapproachthat\n",
      "weusedtocreatetheItalydataset.Syria2000andSyriaSizes:Weconstructed\n",
      "thesedatasetsfromdatacollectedbyfourhuman-rightsgroupsbetween2011\n",
      "and2014onpeoplekilledintheSyrian[19,20].Hand-matchedground\n",
      "truthisavailablefromtheHumanRightsDataAnalysisGroup.Becausethe\n",
      "recordswerehandmatched,thedataarenoisyandpotentiallybiased.Per-\n",
      "formingentityresolutionisnon-trivialbecausethereareonlythreecategorical\n",
      "gender,governorate,anddateofdeath.Wesplitdateofdeath,which\n",
      "ispresentformostrecords,intothreeseparateday,month,andyear.\n",
      "However,becausetherecordsonlyspanfouryears,theyearconveyslittle\n",
      "information.Inaddition,mostrecordsaremale,andthereareonlyfourteen\n",
      "governorates.WecreatedtheSyria2000datasetbydown-samplingtherecords,\n",
      "preservingtheproportionofclustersofeachsize,tocreateadatasetofN=\n",
      "2,000records;themaximumclustersizeise.WecreatedtheSyriaSizes\n",
      "datasetbydown-samplingtherecords,preservingsomeofthelargerclusters\n",
      "(whichnecessarilycontainwithindatabaseduplications),tocreateadatasetof\n",
      "N=6,700records;themaximumclustersizeisten.Weprovidetheempirical\n",
      "distributionoverclustersizesforeachdatasetinappendixD.Wegenerated\n",
      "syntheticrecordsforbothdatasetsusingthesameapproachthatweusedto\n",
      "createtheItalydataset.4.2\n",
      "Results\n",
      "Wereporttheresultsofourexperimentsintable1and2.TheNBNB\n",
      "andNBDmodelsoutperformedtheDPandPYPmodelsforalmostallvariants\n",
      "oftheItalyandNLTCS5000datasets.Ingeneral,theNBDmodelperformed\n",
      "thebestofthefour,andthebetweenthemodels?performancegrew\n",
      "asthevalueof?increased.FortheSyria2000andSyriaSizesdatasets,we\n",
      "seenoconsistentpatterntothemodels?abilitiestorecoverthetruevaluesof\n",
      "thedata-setstatistics.Moreover,allfourmodelshadpoorfalsenegativerates,\n",
      "andfalsediscoveryrates?mostlikelybecausethesedatasetsareextremelynoisy\n",
      "andcontainveryfewWesuspectthatnoentityresolutionmodelwould\n",
      "performwellforthesedatasets.Forthreeofthefourdatasets,theexception\n",
      "beingtheSyria2000dataset,theDPmodelandthePYPmodelbothgreatly\n",
      "overestimatedthenumberofclustersforlargervaluesof?.Takentogether,\n",
      "theseresultssuggestthattheyoftheNBNBandNBDmodelsmake\n",
      "themmoreappropriatechoicesformostentityresolutionapplications.\n",
      "5\n",
      "Summary\n",
      "exchangeableclusteringmodelsassumethatclustersizesgrowlin-\n",
      "earlywiththesizeofthedataset.Althoughthisassumptionisreasonablefor\n",
      "someapplications,itisinappropriateforothers.Forexample,whenentityres-\n",
      "olutionistreatedasaclusteringproblem,thenumberofdatapointsineach\n",
      "clustershouldremainsmall,evenforlargedatasets.Applicationslikethisre-\n",
      "8\n",
      "\n",
      "quiremodelsthatyieldclusterswhosesizesgrowsublinearlywiththesizeofthe\n",
      "dataset.Weintroducedthemicroclusteringpropertyasonewaytocharacterize\n",
      "modelsthataddressthisrequirement.Wethenintroducedahighlyclass\n",
      "ofmodels?KPmodels?thatcanexhibitthisproperty.Wepresentedtwomodels\n",
      "withinthisclass?theNBNBmodelandtheNBDmodel?andshowedthatthey\n",
      "arebettersuitedtoentityresolutionapplicationsthantwoexchange-\n",
      "ableclusteringmodels.WethereforerecommendKPmodelsforapplications\n",
      "wherethesizeofeachclustershouldbeunrelatedtothesizeofthedataset,\n",
      "andeachclustershouldcontainanegligiblefractionofthetotalnumberofdata\n",
      "points.AcknowledgmentsWethankTamaraBroderick,DavidDunson,Merlise\n",
      "Clyde,andAbelRodriguezforconversationsthathelpedformtheideasinthis\n",
      "paper.Inparticular,TamaraBroderickplayedakeyroleindevelopingthe\n",
      "ideaofmicroclustering.WealsothanktheHumanRightsDataAnalysisGroup\n",
      "forprovidinguswithdata.ThisworkwassupportedinpartbyNSFgrants\n",
      "SBE-0965436,DMS-1045153,andIIS-1320219;NIHgrant5R01ES017436-05;\n",
      "theJohnTempletonFoundation;theFoerster-BernsteinPostdoctoralFellow-\n",
      "ship;theUMassAmherstCIIR;andanEPSRCDoctoralPrizeFellowship.6\n",
      "?????????\n",
      "??\n",
      "??????????\n",
      "???????????\n",
      "??\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "??\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "???\n",
      "???\n",
      "????\n",
      "?\n",
      "???\n",
      "???\n",
      "??\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "??\n",
      "9\n",
      "\n",
      "?\n",
      "?\n",
      "1.35\n",
      "?\n",
      "??\n",
      "???\n",
      "??\n",
      "?\n",
      "??\n",
      "??\n",
      "??\n",
      "??\n",
      "??\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?????\n",
      "71.30\n",
      "???????????????\n",
      "??\n",
      "????????????????????????????????????\n",
      "????????????????????\n",
      "??????????????\n",
      "???????\n",
      "??\n",
      "????????????????????????????????????\n",
      "???????????????????????????????\n",
      "??????????\n",
      "?????\n",
      "????\n",
      "????????????????????????????????????\n",
      "??????????????????????????????????????\n",
      "????????????????\n",
      "??????????????????????????\n",
      "????????\n",
      "?????????????????\n",
      "???????????\n",
      "?\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "??????\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "2.5\n",
      "10\n",
      "\n",
      "3.0\n",
      "3.5\n",
      "4.0\n",
      "7\n",
      "1.30\n",
      "1.35\n",
      "500\n",
      "8\n",
      "1.40\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "1.5\n",
      "2.0\n",
      "2.5\n",
      "90thPercentileofClusterSizes\n",
      "?????\n",
      "2.0\n",
      "??\n",
      "??\n",
      "90thPercentileofClusterSizes\n",
      "?\n",
      "2.0\n",
      "6\n",
      "MeanClusterSize1.25\n",
      "??\n",
      "1.8\n",
      "5\n",
      "4\n",
      "????\n",
      "???\n",
      "??????\n",
      "1.6\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "3\n",
      "MaximumClusterSize\n",
      "???????????\n",
      "1.4\n",
      "1.581.601.621.641.661.681.70\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "2\n",
      "450\n",
      "?\n",
      "1.2\n",
      "9\n",
      "11\n",
      "\n",
      "?????????\n",
      "1.0\n",
      "8\n",
      "??\n",
      "????\n",
      "90thPercentileofClusterSizes\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "7\n",
      "MeanClusterSize\n",
      "?\n",
      "????????\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "???\n",
      "1.25\n",
      "?\n",
      "1.20\n",
      "?\n",
      "?\n",
      "?????\n",
      "??????\n",
      "3.0\n",
      "???\n",
      "??????\n",
      "2.8\n",
      "???\n",
      "?\n",
      "1.15\n",
      "6\n",
      "?\n",
      "??\n",
      "????\n",
      "2.6\n",
      "???\n",
      "??\n",
      "?????\n",
      "2.4\n",
      "?\n",
      "???????\n",
      "2.2\n",
      "??\n",
      "?\n",
      "????\n",
      "2.0\n",
      "??\n",
      "12\n",
      "\n",
      "?\n",
      "?\n",
      "?\n",
      "MeanClusterSize\n",
      "5\n",
      "?\n",
      "?\n",
      "?????????\n",
      "90thPercentileofClusterSizes\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "1.10\n",
      "4\n",
      "400\n",
      "SingletonClusters\n",
      "?\n",
      "?\n",
      "?\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "????????????????????????????????????\n",
      "??????????????????????????????????????\n",
      "??????????????????????????\n",
      "??\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "????????????????????????????????\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "??????\n",
      "?\n",
      "1.8\n",
      "??\n",
      "MaximumClusterSize\n",
      "?\n",
      "3\n",
      "??\n",
      "?\n",
      "?\n",
      "1.7\n",
      "????????????????????????????????????\n",
      "??\n",
      "10\n",
      "??????\n",
      "13\n",
      "\n",
      "8\n",
      "?????\n",
      "6\n",
      "????????????\n",
      "1.6\n",
      "????????????????????????????????????\n",
      "????????????\n",
      "?????\n",
      "?\n",
      "1.5\n",
      "??????????????\n",
      "??????????\n",
      "?\n",
      "MeanClusterSize\n",
      "??\n",
      "?\n",
      "4\n",
      "??????\n",
      "?\n",
      "MaximumClusterSize\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "350\n",
      "????????\n",
      "2\n",
      "1800\n",
      "?\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "??????????????\n",
      "??????????\n",
      "1.4\n",
      "18\n",
      "???????????????\n",
      "??????????\n",
      "16\n",
      "1700\n",
      "SingletonClusters\n",
      "????????????????????????\n",
      "14\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "1600\n",
      "?\n",
      "?????\n",
      "12\n",
      "14\n",
      "\n",
      "1600????\n",
      "???????\n",
      "10\n",
      "1400\n",
      "????\n",
      "8\n",
      "1200\n",
      "SingletonClusters???\n",
      "???????\n",
      "6\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "1000\n",
      "????????\n",
      "MaximumClusterSize\n",
      "3000\n",
      "????????????????\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "DP(0.02)PYP(0.02)NBNB(0.02)NDB(0.02)DP(0.05)PYP(0.05)NBNB(0.05)\n",
      "NDB(0.05)DP(0.1)PYP(0.1)NBNB(0.1)NDB(0.1)\n",
      "2500\n",
      "SingletonClusters\n",
      "2000\n",
      "????\n",
      "(a)Italy:NBDmodel>NBNBmodel>PYPmixturemodel>DPmixture\n",
      "model.\n",
      "(b)NLTCS5000:NBDmodel>NBNBmodel>PYPmixturemodel>DP\n",
      "mixturemodel.\n",
      "?\n",
      "?\n",
      "?\n",
      "??\n",
      "?\n",
      "??\n",
      "???\n",
      "?\n",
      "??\n",
      "?\n",
      "??\n",
      "??\n",
      "??\n",
      "??\n",
      "??\n",
      "(c)Syria2000:themodelsperformsimilarlybecausetherearesofew\n",
      "???\n",
      "15\n",
      "\n",
      "???\n",
      "???\n",
      "???\n",
      "???\n",
      "???\n",
      "???\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "?\n",
      "(d)SyriaSizes:themodelsperformsimilarlybecausetherearesofew\n",
      "Figure2:Boxplotsdepictingthetruevalue(dashedline)ofeachdata-set\n",
      "statisticforeachvariantofeachdataset,aswellasitsposteriordistribution\n",
      "accordingtoeachofthefourentityresolutionmodels.\n",
      "Table1:Entity-resolutionsummarystatistics?theposteriorexpectednum-\n",
      "berofclusters,theposteriorstandarderror,thefalsenegativerate(loweris\n",
      "better),thefalsediscoveryrate(lowerisbetter),andtheposteriorexpected\n",
      "valueof??foreachvariantofeachdatasetandeachofthefourmodels.Data\n",
      "Set\n",
      "TrueK\n",
      "Variant\n",
      "Model\n",
      "E[K]\n",
      "Std.Err.\n",
      "FNR\n",
      "FDR\n",
      "E[?]\n",
      "Italy\n",
      "587\n",
      "?=0.02\n",
      "DPPYPNBNBNBD\n",
      "594.00593.90591.00590.50\n",
      "4.514.524.433.64\n",
      "0.070.070.040.03\n",
      "0.030.030.030.00\n",
      "0.020.020.020.02\n",
      "?=0.05\n",
      "DPPYPNBNBNBD\n",
      "601.60601.50596.40592.60\n",
      "5.895.905.795.20\n",
      "0.130.130.110.09\n",
      "16\n",
      "\n",
      "0.030.030.040.04\n",
      "0.030.040.040.04\n",
      "?=0.1\n",
      "DPPYPNBNBNBD\n",
      "617.40617.40610.90596.60\n",
      "7.237.227.819.37\n",
      "0.270.270.240.18\n",
      "0.060.050.060.05\n",
      "0.070.070.080.10\n",
      "?=0.02\n",
      "DPPYPNBNBNBD\n",
      "3021.703018.703037.803028.20\n",
      "24.9625.6925.185.65\n",
      "0.020.030.020.01\n",
      "0.110.110.070.09\n",
      "0.030.030.020.03\n",
      "?=0.05\n",
      "DPPYPNBNBNBD\n",
      "3024.003045.803040.903039.30\n",
      "26.1523.6624.8610.17\n",
      "0.050.050.040.03\n",
      "0.130.100.060.07\n",
      "0.060.050.050.06\n",
      "?=0.1\n",
      "DPPYPNBNBNBD\n",
      "3130.503115.103067.303049.10\n",
      "21.4425.7325.3116.48\n",
      "0.120.130.110.09\n",
      "0.090.100.080.08\n",
      "0.100.100.110.12\n",
      "?=0.02\n",
      "DPPYPNBNBNBD\n",
      "1695.201719.701726.801715.20\n",
      "25.4036.1027.9651.56\n",
      "0.700.710.700.67\n",
      "0.270.260.280.28\n",
      "0.070.040.050.02\n",
      "?=0.05\n",
      "DPPYPNBNBNBD\n",
      "1701.801742.901738.301711.40\n",
      "31.1524.3325.4847.10\n",
      "0.770.750.740.69\n",
      "0.310.320.310.32\n",
      "0.070.040.040.03\n",
      "?=0.1\n",
      "DPPYPNBNBNBD\n",
      "17\n",
      "\n",
      "1678.101761.201779.401757.30\n",
      "40.5639.3829.8473.60\n",
      "0.810.810.770.74\n",
      "0.190.220.260.25\n",
      "0.180.080.040.03\n",
      "?=0.02\n",
      "DPPYPNBNBNBD\n",
      "4175.704234.304108.703979.50\n",
      "66.0468.5570.5670.85\n",
      "0.650.640.650.68\n",
      "0.170.190.190.20\n",
      "0.010.010.010.03\n",
      "?=0.05\n",
      "DPPYPNBNBNBD\n",
      "4260.004139.104047.103863.90\n",
      "77.18104.2255.1868.05\n",
      "0.710.750.730.75\n",
      "0.210.180.200.22\n",
      "0.020.040.040.07\n",
      "?=0.1\n",
      "DPPYPNBNBNBD\n",
      "4507.404540.304400.604251.90\n",
      "82.27100.53111.91203.23\n",
      "0.800.800.800.82\n",
      "0.190.200.230.25\n",
      "0.030.030.030.04\n",
      "NLTCS5000\n",
      "Syria2000\n",
      "SyriaSizes\n",
      "3,061\n",
      "1,725\n",
      "4,075\n",
      "8\n",
      "2References\n",
      "[1]P.Christen.DataMatching:ConceptsandTechniquesforRecordLinkage,\n",
      "EntityResolution,andDuplicateDetection.Springer,2012.[2]P.Christen.\n",
      "Asurveyofindexingtechniquesforscalablerecordlinkageanddeduplication.\n",
      "IEEETransactionsonKnowledgeandDataEngineering,24(9),2012.[3]W.E.\n",
      "Winkler.Overviewofrecordlinkageandcurrentresearchdirections.Technical\n",
      "report,U.S.BureauoftheCensusStatisticalResearchDivision,2006.[4]R.C.\n",
      "Steorts,R.Hall,andS.E.Fienberg.ABayesianapproachtographicalrecord\n",
      "linkageandde-duplication.JournaloftheAmericanStatisticalSociety,Inpress.\n",
      "[5]R.C.Steorts.Entityresolutionwithempiricallymotivatedpriors.Bayesian\n",
      "18\n",
      "\n",
      "Analysis,10(4):849?875,2015.[6]R.C.Steorts,R.Hall,andS.E.Fienberg.\n",
      "SMERED:ABayesianapproachtographicalrecordlinkageandde-duplication.\n",
      "JournalofMachineLearningResearch,33:922?930,2014.[7]T.Broderickand\n",
      "R.C.Steorts.Variationalbayesformergingnoisydatabases.InNIPS2014\n",
      "WorkshoponAdvancesinVariationalInference,2014.arXiv:1410.4792.[8]S.\n",
      "RichardsonandP.J.Green.OnBayesiananalysisofmixtureswithanunknown\n",
      "numberofcomponents.JournaloftheRoyalStatisticalSocietySeriesB,pages\n",
      "731?792,1997.[9]J.W.MillerandM.T.Harrison.Mixturemodelswithaprior\n",
      "onthenumberofcomponents.arXiv:1502.06241,2015.[10]J.Sethuraman.\n",
      "AconstructiveofDirichletpriors.StatisticaSinica,4:639?650,1994.\n",
      "[11]H.IshwaranandL.F.James.GeneralizedweightedChineserestaurantpro-\n",
      "cessesforspeciessamplingmixturemodels.StatisticaSinica,13(4):1211?1236,\n",
      "2003.[12]J.F..CKingman.Therepresentationofpartitionstructures.Jour-\n",
      "naloftheLondonMathematicalSociety,2(2):374?380,1978.[13]D.Aldous.\n",
      "Exchangeabilityandrelatedtopics.?coled??t?deProbabilit?sdeSaint-Flour\n",
      "XIII?1983,pages1?198,1985.[14]H.M.Wallach,S.Jensen,L.Dicker,andK.\n",
      "A.Heller.AnalternativepriorprocessfornonparametricBayesianclustering.\n",
      "InProceedingsofthe13thInternationalConferenceonIntelligence\n",
      "andStatistics,2010.[15]V.F.Kolchin.Aproblemoftheallocationofparticles\n",
      "incellsandcyclesofrandompermutations.TheoryofProbability&ItsAppli-\n",
      "cations,16(1):74?90,1971.[16]J.Pitman.Combinatorialstochasticprocesses.\n",
      "?coled??t?deProbabilit?sdeSaint-FlourXXXII?2002,2006.[17]R.M.Neal.\n",
      "Slicesampling.AnnalsofStatistics,31:705?767,2003.[18]R.C.Steorts,S.\n",
      "L.Ventura,M.Sadinle,andS.E.Fienberg.Acomparisonofblockingmeth-\n",
      "odsforrecordlinkage.InInternationalConferenceonPrivacyinStatistical\n",
      "Databases,pages253?268,2014.[19]M.Price,J.Klingner,A.Qtiesh,andP.\n",
      "Ball.UpdatedstatisticalanalysisofdocumentationofkillingsintheSyrian\n",
      "ArabRepublic,2013.UnitedNationsoftheUNHighCommissionerfor\n",
      "HumanRights.[20]M.Price,J.Klingner,A.Qtiesh,andP.Ball.Updated\n",
      "statisticalanalysisofdocumentationofkillingsintheSyrianArabRepublic.\n",
      "HumanRightsDataAnalysisGroup,Geneva,2014.\n",
      "9\n",
      "19\n",
      "\n",
      "PP5563.pdf\n",
      "PP5563.pdf 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructureRegularizationforStructured\n",
      "Prediction\n",
      "Authoredby:\n",
      "XuSun\n",
      "Abstract\n",
      "Whiletherearemanystudiesonweightregularization,thestudy\n",
      "onstructureregularizationisrare.Manyexistingsystemsonstruc-\n",
      "turedpredictionfocusonincreasingthelevelofstructuraldependencies\n",
      "withinthemodel.However,thistrendcouldhavebeenmisdirected,be-\n",
      "causeourstudysuggeststhatcomplexstructuresareactuallyharmful\n",
      "togeneralizationabilityinstructuredprediction.Tocontrolstructure-\n",
      "basedovweproposeastructureregularizationframeworkvia\n",
      "emph\n",
      "f\n",
      "structuredecomposition\n",
      "g\n",
      ",whichdecomposestrainingsamplesinto\n",
      "mini-sampleswithsimplerstructures,derivingamodelwithbettergen-\n",
      "eralizationpower.Weshowboththeoreticallyandempiricallythatstruc-\n",
      "tureregularizationcanelycontrolovriskandleadtobetter\n",
      "accuracy.Asaby-product,theproposedmethodcanalsosubstantially\n",
      "acceleratethetrainingspeed.Themethodandthetheoreticalresultscan\n",
      "applytogeneralgraphicalmodelswitharbitrarystructures.Experiments\n",
      "onwell-knowntasksdemonstratethatourmethodcaneasilybeatthe\n",
      "benchmarksystemsonthosehighly-competitivetasks,achievingrecord-\n",
      "breakingaccuraciesyetwithsubstantiallyfastertrainingspeed.\n",
      "1PaperBody\n",
      "Structuredpredictionmodelsarepopularlyusedtosolvestructuredependent\n",
      "problemsinawidevarietyofapplicationdomainsincludingnaturallanguage\n",
      "processing,bioinformatics,speechrecognition,andcomputervision.Recently,\n",
      "manyexistingsystemsonstructuredpredictionfocusonincreasingthelevelof\n",
      "structuraldependencieswithinthemodel.Wearguethatthistrendcouldhave\n",
      "beenmisdirected,becauseourstudysuggeststhatcomplexstructuresareac-\n",
      "tuallyharmfultomodelaccuracy.Whileitisobviousthatintensivestructural\n",
      "dependenciescanelyincorporatestructuralinformation,itislessobvi-\n",
      "ousthatintensivestructuraldependencieshaveadrawbackofincreasingthe\n",
      "generalizationrisk,becausemorecomplexstructuresareeasiertofrom\n",
      "overSincethistypeofoviscausedbystructurecomplexity,it\n",
      "canhardlybesolvedbyordinaryregularizationmethodssuchasL2andL1\n",
      "1\n",
      "\n",
      "regularizationschemes,whichisonlyforcontrollingweightcomplexity.Todeal\n",
      "withthisproblem,weproposeasimplestructureregularizationsolutionbased\n",
      "ontagstructuredecomposition.Theproposedmethoddecomposeseachtrain-\n",
      "ingsampleintomultipleminisampleswithsimplerstructures,derivingamodel\n",
      "withbettergeneralizationpower.Theproposedmethodiseasytoimplement,\n",
      "andithasseveralinterestingproperties:(1)Weshowboththeoreticallyand\n",
      "empiricallythattheproposedmethodcanelyreducetheovrisk\n",
      "onstructuredprediction.(2)Theproposedmethoddoesnotchangethecon-\n",
      "vexityoftheobjectivefunction,suchthataconvexfunctionpenalizedwitha\n",
      "structureregularizerisstillconvex.(3)Theproposedmethodhasno\n",
      "withtheweightregularization.Thuswecanapplystructureregularizationto-\n",
      "getherwithweightregularization.(4)Theproposedmethodcanacceleratethe\n",
      "convergencerateintraining.Thetermstructuralregularizationhasbeenused\n",
      "inpriorworkforregularizingstructuresoffeatures,includingspectralregular-\n",
      "ization[1],regularizingfeaturestructuresfor[20],andmany1\n",
      "recentstudiesonstructuredsparsityinstructuredpredictionscenarios[11,\n",
      "8],viaadoptingmixednormregularization[10],GroupLasso[22],andpos-\n",
      "teriorregularization[5].Comparedwiththosepriorwork,weemphasizethat\n",
      "ourproposalontagstructureregularizationisnovel.Thisisbecausetheterm\n",
      "structureinalloftheaforementionedworkreferstostructuresoffeaturespace,\n",
      "whichissubstantiallytcomparedwithourproposalonregularizingtag\n",
      "structures(interactionsamongtags).Also,therearesomeotherrelatedstud-\n",
      "ies.[17]describedaninterestingheuristicpiecewisetrainingmethod.[19]de-\n",
      "scribeda?lookahead\"learningmethod.Ourworkfrom[17]and[19]\n",
      "mainlybecauseourworkisbuiltonaregularizationframework,withargu-\n",
      "mentsandtheoreticalonreducinggeneralizationriskandimprov-\n",
      "ingconvergencerate.Also,ourmethodandthetheoreticalresultscangen-\n",
      "eralgraphicalmodelswitharbitrarystructures,andthedetailedalgorithmis\n",
      "veryt.Ongeneralizationriskanalysis,relatedstudiesinclude[2,12]\n",
      "onnon-structuredand[18,7]onstructuredTothe\n",
      "bestofourknowledge,thisisthetheoreticalresultonquantifyingthere-\n",
      "lationbetweenstructurecomplexityandthegeneralizationriskinstructured\n",
      "prediction,andthisisalsotheproposalonstructureregularizationvia\n",
      "regularizingtag-interactions.Thecontributionsofthiswork1aretwo-fold:?\n",
      "Onthemethodologyside,weproposeastructureregularizationframeworkfor\n",
      "structuredprediction.Weshowboththeoreticallyandempiricallythatthepro-\n",
      "posedmethodcanelyreducetheovrisk,andatthesametime\n",
      "acceleratetheconvergencerateintraining.Ourmethodandthetheoretical\n",
      "analysisdonotmakeassumptionsbasedonspstructures.Inotherwords,\n",
      "themethodandthetheoreticalresultscanapplytographicalmodelswithar-\n",
      "bitrarystructures,includinglinearchains,trees,andgeneralgraphs.?On\n",
      "theapplicationside,forseveralimportantnaturallanguageprocessingtasks,\n",
      "oursimplemethodcaneasilybeatthebenchmarksystemsonthosehighly-\n",
      "competitivetasks,achievingrecord-breakingaccuraciesaswellassubstantially\n",
      "fastertrainingspeed.\n",
      "2StructureRegularizationAgraphofobservations(evenwitharbitrary\n",
      "2\n",
      "\n",
      "structures)canbeindexedandbedenotedbyusinganindexedsequenceof\n",
      "observationsO=\n",
      "f\n",
      "o1,...,on\n",
      "g\n",
      ".WeusethetermsampletodenoteO\n",
      "=\n",
      "f\n",
      "o1,...,on\n",
      "g\n",
      ".Forexample,innaturallanguageprocessing,asample\n",
      "maycorrespondtoasentenceofnwordswithdependenciesoftreestructures\n",
      "(e.g.,insyntacticparsing).Forsimplicityinanalysis,weassumeallsamples\n",
      "havenobservations(thusntags).Inatypicalsettingofstructuredprediction,\n",
      "allthentagshaveinter-dependenciesviaconnectingeachMarkovdependency\n",
      "betweenneighboringtags.Thus,wecallnastagstructurecomplexityorsimply\n",
      "structurecomplexitybelow.x(1),...,x(n)\n",
      "g\n",
      ",wherex(k)?Asampleis\n",
      "convertedtoanindexedsequenceoffeaturevectorsx=\n",
      "f\n",
      "xXisofthedimension\n",
      "dandcorrespondstothelocalfeaturesextractedfromtheposition/indexk.x,\n",
      "y)?ZdenoteWecanuseann?dmatrixtorepresentx?Xn.LetZ\n",
      "=(Xn,Yn)andletz=(xx1,y1),...,zm=(xxm,ym)\n",
      "g\n",
      ",a\n",
      "sampleinthetrainingdata.SupposeatrainingsetisS=\n",
      "f\n",
      "zz1=(xwithsize\n",
      "m,andthesamplesaredrawni.i.d.fromadistributionDwhichisunknown.\n",
      "AlearningalgorithmisafunctionG:Zm7?FwiththefunctionspaceF?\n",
      "f\n",
      "Xn7?Yn\n",
      "g\n",
      ",i.e.,GmapsatrainingsetStoafunctionGS:Xn7?Y\n",
      "n.WesupposeGissymmetricwithrespecttoS,sothatGisindependent\n",
      "ontheorderofS.Structuraldependenciesamongtagsarethemajor\n",
      "betweenstructuredpredictionandnonstructuredclasForthelatter\n",
      "case,alocalofgbasedonapositionkcanbex(k?a),...,x(k+a)\n",
      "),wheretheterm\n",
      "f\n",
      "xx(k?a),...,x(k+a)\n",
      "g\n",
      "representsalocalwinexpressedas\n",
      "g(xdow.However,forstructuredprediction,alocalclascationonaposition\n",
      "dependsonthewholex(1),...,x(n)\n",
      "g\n",
      "ratherthanalocalwindow,dueto\n",
      "thenatureofstructuraldependenciesinputx=\n",
      "f\n",
      "xamongtags(e.g.,graphical\n",
      "modelslikeCRFs).Thus,instructuredpredictionalocalx(1),.\n",
      "..,x(n),k).Tosimplifythenotation,weonkshouldbedenotedas\n",
      "g(xx,k),g(xx(1),...,x(n),k)g(x1\n",
      "Seethecodeathttp://klcl.pku.edu.cn/member/sunxu/code.htm\n",
      "2\n",
      "yy\n",
      "(1)\n",
      "(2)\n",
      "y\n",
      "(2)\n",
      "x\n",
      "y\n",
      "(3)\n",
      "y\n",
      "(3)\n",
      "x\n",
      "(4)\n",
      "y\n",
      "(5)\n",
      "y\n",
      "x\n",
      "3\n",
      "\n",
      "(5)\n",
      "x\n",
      "y\n",
      "(1)\n",
      "yx\n",
      "x\n",
      "(1)\n",
      "x\n",
      "(1)\n",
      "x\n",
      "(4)\n",
      "(2)\n",
      "(6)\n",
      "(3)\n",
      "y\n",
      "(3)\n",
      "x\n",
      "(4)\n",
      "y\n",
      "(2)\n",
      "x\n",
      "(6)\n",
      "(5)\n",
      "y\n",
      "(5)\n",
      "x\n",
      "(6)\n",
      "(4)\n",
      "x\n",
      "(6)\n",
      "Figure1:Anillustrationofstructureregularizationinsimplelinearchain\n",
      "case,whichdecomposeatrainingsamplezwithstructurecomplexity6into\n",
      "threemini-sampleswithstructurecomplexity2.Structureregularizationcan\n",
      "applytomoregeneralgraphswitharbitrarydependencies.x,k),y(k)],which\n",
      "measuresthecostonWepoint-wisecostfunctionc:Y?Y7?R+as\n",
      "c[GS(xx,k)andthegold-standardtagy(k),andweintroducethepoint-wise\n",
      "apositionkbycomparingGS(xlossasx,k),y(k)]?(GS,z,k),c[GS(x\n",
      "Then,wesample-wisecostfunctionC:Yn?Yn7?R+,whichisthe\n",
      "costfunctionwithrespecttoawholesample,andweintroducethesample-wise\n",
      "lossasx),y]=L(GS,z),C[GS(x\n",
      "n?\n",
      "?(GS,z,k)=\n",
      "k=1\n",
      "n?\n",
      "x,k),y(k)]c[GS(x\n",
      "k=1\n",
      "4\n",
      "\n",
      "GivenGandatrainingsetS,whatwearemostinterestedinisthegeneral-\n",
      "izationriskinstructuredprediction(i.e.,expectedaverageloss)[18,7]:[L(G,\n",
      "z)]SR(GS)=EznSincethedistributionDisunknown,wehavetoestimate\n",
      "R(GS)byusingtheempiricalrisk:1??1?L(GS,zi)=?(GS,zi,k)mn\n",
      "i=1mni=1m\n",
      "Re(GS)=\n",
      "m\n",
      "n\n",
      "k=1\n",
      "Tostateourtheoreticalresults,wemustdescribeseveralquantitiesand\n",
      "assumptionsfollowingpriorwork[2,12].Weassumeasimplereal-valuedstruc-\n",
      "turedpredictionschemesuchthattheclassx,k)?D.2Also,weassumethe\n",
      "point-wisecostpredictedonpositionkofxisthesignofGS(xfunctionc?is\n",
      "convexand?-smoothsuchthat?y1,y2?D,?y??Y|c?(y1,y?)?c?\n",
      "(y2,y?)|??|y1?y2|\n",
      "(1)\n",
      "x,k)?GSi(xx,k)|whilechangingasingleAlso,weuseavalue?to\n",
      "quantifytheboundof|GS(xsample(withsizen??n)inthetrainingset\n",
      "withrespecttothestructuredinputx.This?-admissibleassumptioncanbe\n",
      "formulatedas?k,x,k)?GSi(xx,k)|??||GS?GSi||2?||x\n",
      "x||2|GS(x\n",
      "(2)\n",
      "where??R+isavaluerelatedtothedesignofalgorithmG.2.1Struc-\n",
      "tureRegularizationMostexistingregularizationtechniquesareforregularizing\n",
      "modelweights/parameters(e.g.,arepresentativeregularizeristheGaussianreg-\n",
      "ularizerorsocalledL2regularizer),andwecallsuchregularizationtechniques\n",
      "asweightregularization.1(Weightregularization)LetN?:F7?\n",
      "R+beaweightregularizationfunctiononFwithregularizationstrength?,the\n",
      "structuredbasedobjectivefunctionwithgeneralweightregular-\n",
      "izationisasfollows:R?(GS),Re(GS)+N?(GS)\n",
      "(3)\n",
      "2Inpractice,manypopularstructuredpredictionmodelshaveaconvexand\n",
      "real-valuedcostfunction(e.g.,CRFs).\n",
      "3\n",
      "Algorithm1Trainingwithstructureregularization1:Input:modelweights\n",
      "w,trainingsetS,structureregularizationstrength?2:repeat3:S???4:for\n",
      "i=1?mdo5:Randomlydecomposezi?Sintomini-samplesN?(zzi)=\n",
      "f\n",
      "zz\n",
      "(i,1),...,z(i,?)\n",
      "g\n",
      "6:S??S??N?(zzi)7:endfor8:fori=1?|S?|do\n",
      "w)9:Samplez?uniformlyatrandomfromS?,withgradient?gz?(ww)10:\n",
      "w?w???gz?(w11:endfor12:untilConvergence13:returnwWhileweight\n",
      "regularizationisnormalizingmodelweights,theproposedstructureregulariza-\n",
      "tionmethodisnormalizingthestructuralcomplexityofthetrainingsamples.\n",
      "AsillustratedinFigure1,ourproposalisbasedontagstructuredecomposition,\n",
      "whichcanbeformallyasfollows:2(Structureregularization)\n",
      "LetN?:F7?FbeastructureregularizationfunctiononFwithregularization\n",
      "strength?with1???n,thestructuredcbasedobjectivefunction\n",
      "5\n",
      "\n",
      "withstructureregularizationisasfollows3:1??1???R?(GS),Re[GN?(S)\n",
      "]=L[GS?,z(i,j)]=?[GS?,z(i,j),k]mni=1j=1mni=1j=1m\n",
      "?\n",
      "m\n",
      "?n/?\n",
      "(4)\n",
      "k=1\n",
      "whereN?(zzi)randomlysplitsziinto?mini-samples\n",
      "f\n",
      "zz(i,1),...,\n",
      "z(i,?)\n",
      "g\n",
      ",sothatthemini-sampleshaveadistributionontheirsizes(structure\n",
      "complexities)withtheexpectedvaluen?=n/?.Thus,wegetS?=\n",
      "f\n",
      "zz(1,1)\n",
      ",z(1,2),...,z(1,?),...,z(m,1),z(m,2),...,z(m,?)\n",
      "g\n",
      "(5)|\n",
      "f\n",
      "z\n",
      "g\n",
      "|\n",
      "f\n",
      "z\n",
      "g\n",
      "?\n",
      "?\n",
      "withm?mini-sampleswithexpectedstructurecomplexityn/?.Wecan\n",
      "denoteS?morecompactlyasS?=\n",
      "f\n",
      "zz?1,z?2,...,z?m?\n",
      "g\n",
      "andR?(GS\n",
      ")canbeas1?1??R?(GS),L(GS?,z?i)=?[GS?,z?i,k]\n",
      "mni=1mni=1m?n/?\n",
      "m?\n",
      "(6)\n",
      "k=1\n",
      "Whenthestructureregularizationstrength?=1,wehaveS?=Sand\n",
      "R?=Re.Thestructureregularizationalgorithm(withthestochasticgradient\n",
      "descentsetting)issummarizedinAlgorithmx(1),...,x(n)\n",
      "g\n",
      "represents\n",
      "featurevectors.Thus,itshouldbeemphasizedthat1.Recallthatx=\n",
      "f\n",
      "x\n",
      "thedecompositionofxisthedecompositionofthefeaturevectors,notthe\n",
      "originalobservations.Actuallythedecompositionofthefeaturevectorsismore\n",
      "convenientandhasnoinformationloss?decomposingobservationsneedsto\n",
      "regeneratefeaturesandmaylosesomefeatures.Thestructureregularization\n",
      "hasnowiththeweightregularization,andthestructureregularization\n",
      "canbeappliedtogetherwiththeweightregularization.3(Structure\n",
      "&weightregularization)BycombiningstructureregularizationinDenition\n",
      "2andweightregularizationin1,thestructuredbased\n",
      "objectivefunctionisasfollows:R?,?(GS),R?(GS)+N?(GS)(7)When\n",
      "?=1,wehaveR?,?=Re(GS)+N?(GS)=R?.Likeexistingweight\n",
      "regularizationmethods,currentlyourstructureregularizationisonlyforthe\n",
      "trainingstage.Currentlywedonotusestructureregularizationinthetest\n",
      "stage.3ThenotationNisoverloadedhere.Forclaritythroughout,Nwith\n",
      "subscript?referstoweightregularizationfunction,andNwithsubscript?\n",
      "referstostructureregularizationfunction.\n",
      "4\n",
      "2.2\n",
      "ReductionofGeneralizationRisk\n",
      "Incontrasttothesimplicityofthealgorithm,thetheoreticalanalysisisquite\n",
      "technical.Inthispaperweonlydescribethemajortheoreticalresult.Detailed\n",
      "analysisandproofsaregiveninthefullversionofthiswork[14].Theorem\n",
      "4(Generalizationvs.structureregularization)Letthestructuredprediction\n",
      "6\n",
      "\n",
      "objectivefunctionofGbepenalizedbystructureregularizationwithfactor?\n",
      "?[1,n]andL2weightregularizationwithfactor?,andthepenalizedfunction\n",
      "hasaminimizerf:m?(1?)?(8)f=argminR?,?(g)=argminL?(g,z?j)\n",
      "+||g||22mnj=12g?Fg?FAssumethepoint-wiseloss??isconvexand\n",
      "tiable,andisboundedby??(f,z,k)??.x,k)is?-admissible.Leta\n",
      "localfeaturevaluebeboundedbyvsuchthatx(k,q)?vforAssumef(xq?\n",
      "f\n",
      "1,...,d\n",
      "g\n",
      ".Then,forany??(0,1),withprobabilityatleast1??overthe\n",
      "randomdrawofthetrainingsetS,thegeneralizationriskR(f)isboundedby\n",
      "?)?ln??12d?2?2v2n2((4m?2)d?2?2v2n2R(f)?Re(f)++\n",
      "(9)+?m??m??22mSince?,?,andvaretypicallysmallcomparedwithother\n",
      "variables,especiallym,(9)canbeapproximatedasfollowsbyignoringsmall\n",
      "terms:(dn2?ln??1)?(10)R(f)?Re(f)+O??1.5m)(2?ln???1in(10)\n",
      "Theproofisgiveninthefullversionofthiswork[14].WecallthetermOdn1.5\n",
      "??mas?ov-bound\",andreducingtheoveroundiscrucialforreducing\n",
      "thegeneralizationriskbound.First,(10)suggeststhatstructurecomplexityn\n",
      "canincreasetheovoundonamagnitudeofO(n2),andapplyingweight\n",
      "regularizationcanreducetheovoundbyO(?).Importantly,applying\n",
      "structureregularizationfurther(overweightregularization)canadditionally\n",
      "reducetheovoundbyamagnitudeofO(?1.5).Sincemanyapplications\n",
      "inpracticearebasedonsparsefeatures,usingasparsefeatureassumptioncan\n",
      "furtherimprovethegeneralizationbound.Theimprovedgeneralizationbounds\n",
      "aregiveninthefullversionofthiswork[14].2.3\n",
      "AcceleratingConvergenceRatesinTraining\n",
      "Wealsoanalyzetheimpactontheconvergencerateofonlinelearningby\n",
      "applyingstructureregularization.Followingpriorwork[9],ouranalysisisbased\n",
      "onthestochasticgradientdescent(SGD)w)bethestructuredpredictionob-\n",
      "jectivefunctionandw?Wisthewithlearningrate.Letg(wweight\n",
      "vector.RecallthattheSGDupdatewithlearningrate?hasaformlike\n",
      "this:wt)wt+1?wt???gzt(w\n",
      "(11)\n",
      "wt)isthestochasticestimationoftheobjectivefunctionbasedonzwhich\n",
      "israndomlywheregz(wdrawnfromS.Tostateourconvergencerateanalysis\n",
      "results,weneedseveralassumptionsfollowingw,w??W,(Nemirovskietal.\n",
      "2009).Weassumegisstronglyconvexwithmodulusc,thatis,?wc?w?)?\n",
      "g(ww)+(ww??w)T?g(ww)+||ww?w||2g(w(12)2Wheng\n",
      "isstronglyconvex,thereisaglobaloptimum/minimizerw?.Wealsoassume\n",
      "Lipschitzw,w??W,continuoustiabilityofgwiththeconstantq,\n",
      "thatis,?ww?)??g(ww)||?q||ww??w||||?g(w\n",
      "(13)\n",
      "w)hasalmostsurelypositivecorrelationwithItisalsoreasonabletoassume\n",
      "thatthenormof?gz(wthestructurecomplexityofz,4whichcanbequan\n",
      "byabound??R+:w)||2??|zz|almostsurelyfor?ww?W||?gz\n",
      "(w\n",
      "(14)\n",
      "4Manystructuredpredictionsystems(e.g.,CRFs)satisfythisassumption\n",
      "thatthegradientbasedonalargersample(i.e.,nislarge)isexpectedtohave\n",
      "7\n",
      "\n",
      "alargernorm.\n",
      "5\n",
      "where|zz|denotesthestructurecomplexityofz.Moreover,itisrea-\n",
      "sonabletoassume?c<1\n",
      "(15)\n",
      "becauseeventheordinarygradientdescentmethodswilldivergeif?c>1.\n",
      "Then,weshowthatstructureregularizationcanquadraticallyacceleratethe\n",
      "SGDratesofconvergence:Proposition5(Convergenceratesvs.structurereg-\n",
      "ularization)Withtheaforementionedasc???2sumptions,lettheSGDtraining\n",
      "havealearningratedenedas?=q?2n2,where?>0isaconvergence\n",
      "tolerancevalueand??(0,1].Lettbeaintegersatisfyingt?\n",
      "q?2n2log(qa0/?)??c2?2\n",
      "(16)\n",
      "wherenand??[1,n]islikebefore,anda0istheinitialdistancewhich\n",
      "dependsontheinitializationw0?w?||2.Then,aftertupdatesofwitof\n",
      "theweightsw0andtheminimizerw?,i.e.,a0=||wwt)?g(ww?)]?\n",
      "?.convergestoE[g(wTheproofisgiveninthefullversionofthiswork[14].As\n",
      "wecansee,usingstructureregularizationwiththestrength?canquadratically\n",
      "acceleratetheconvergenceratewithafactorof?2.\n",
      "3\n",
      "Experiments\n",
      "DivTasks.Thenaturallanguageprocessingtasksinclude(1)part-of-\n",
      "speechtagging,(2)biomedicalnamedentityrecognition,and(3)Chineseword\n",
      "segmentation.Thesignalprocessingtaskis(4)sensor-basedhumanactivity\n",
      "recognition.Thetasks(1)to(3)usebooleanfeaturesandthetask(4)adopts\n",
      "real-valuedfeatures.Fromtasks(1)to(4),theaveragedstructurecomplexity\n",
      "(numberofobservations)nisveryt,withn=23.9,26.5,46.6,67.9,\n",
      "respectively.Thedimensionoftags|Y|isalsodivamongtasks,with\n",
      "|Y|rangingfrom5to45.Part-of-SpeechTagging(POS-Tagging).Part-of-\n",
      "Speech(POS)taggingisanimportantandhighlycompetitivetask.Weusethe\n",
      "standardbenchmarkdatasetinpriorwork[3],with38,219trainingsamplesand\n",
      "5,462testsamples.Followingpriorwork[19],weusefeaturesbasedonwords\n",
      "andlexicalpatterns,with393,741rawfeatures5.Theevaluationmetricisper-\n",
      "wordaccuracy.BiomedicalNamedEntityRecognition(Bio-NER).Thistask\n",
      "isfromtheBioNLP-2004sharedtask[19].Thereare17,484trainingsamples\n",
      "and3,856testsamples.Followingpriorwork[19],weusewordpatternfeatures\n",
      "andPOSfeatures,with403,192rawfeaturesintotal.Theevaluationmetric\n",
      "isbalancedF-score.WordSegmentation(Word-Seg).WeusetheMSRdata\n",
      "providedbySIGHAN-2004contest[4].Thereare86,918trainingsamplesand\n",
      "3,985testsamples.Thefeaturesaresimilarto[16],with1,985,720rawfea-\n",
      "turesintotal.TheevaluationmetricisbalancedF-score.Sensor-basedHuman\n",
      "ActivityRecognition(Act-Recog).Thisisataskbasedonreal-valuedsensor\n",
      "signals,withthedataextractedfromtheBao04activityrecognitiondataset\n",
      "[15].Thefeaturesaresimilarto[15],with1,228rawfeaturesintotal.There\n",
      "are16,000trainingsamplesand4,000testsamples.Theevaluationmetricis\n",
      "accuracy.WechoosetheCRFs[6]andstructuredperceptrons(Perc)[3],which\n",
      "8\n",
      "\n",
      "arearguablythemostpopularprobabilisticandnon-probabilisticstructured\n",
      "predictionmodels,respectively.TheCRFsaretrainedusingtheSGDalgo-\n",
      "rithm,6andthebaselinemethodisthetraditionalweightregularizationscheme\n",
      "(WeightReg),whichadoptsthemostrepresentativeL2weightregularization,\n",
      "i.e.,aGaussianprior.7Forthestructuredperceptrons,thebaselineWeightAvg\n",
      "isthepopularimplicitregularizationtechniquebasedonparameteraveraging,\n",
      "i.e.,averagedperceptron[3].5\n",
      "Rawfeaturesarethoseobservationfeaturesbasedonlyonx,i.e.,nocom-\n",
      "binationwithtaginformation.Intheoreticalanalysis,followingpriorworkwe\n",
      "adopttheSGDwithlearningrate,asdescribedinSection2.3.However,\n",
      "sincetheSGDwithdecayinglearningrateismorecommonlyusedinprac-\n",
      "tice,inexperimentsweusetheSGDwithdecayinglearningrate.7Wealso\n",
      "testedonsparsityemphasizedregularizationmethods,includingL1regulariza-\n",
      "tionandGroupLassoregularization[8].However,wethatinmostcases\n",
      "thosesparsityemphasizedregularizationmethodshaveloweraccuracythanthe\n",
      "L2regularization.6\n",
      "6\n",
      "Bio?NER:CRF\n",
      "POS?Tagging:CRF\n",
      "Word?Seg:CRF\n",
      "Act?Recog:CRF\n",
      "97.4\n",
      "72.4\n",
      "97.2\n",
      "72.2\n",
      "72StructRegWeightReg\n",
      "97.155\n",
      "10\n",
      "15\n",
      "71.80\n",
      "20\n",
      "5\n",
      "5\n",
      "10\n",
      "97.3\n",
      "71.8\n",
      "97.2\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Mini?SampleSize(n/?)\n",
      "20\n",
      "0\n",
      "5\n",
      "10\n",
      "9\n",
      "\n",
      "15\n",
      "20\n",
      "Mini?SampleSize(n/?)Act?Recog:Perc\n",
      "93.5\n",
      "97.1\n",
      "93\n",
      "97StructRegWeightAvg\n",
      "71.20\n",
      "15\n",
      "Word?Seg:Perc\n",
      "72\n",
      "71.6\n",
      "StructRegWeightReg\n",
      "93\n",
      "Mini?SampleSize(n/?)\n",
      "71.4\n",
      "97.10\n",
      "93.2\n",
      "92.697.40\n",
      "20\n",
      "F?score(%)\n",
      "97.15\n",
      "F?score(%)\n",
      "StructRegWeightAvg\n",
      "93.4\n",
      "92.8\n",
      "97.42\n",
      "Bio?NER:Perc\n",
      "POS?Tagging:Perc\n",
      "Accuracy(%)\n",
      "15\n",
      "97.44\n",
      "Mini?SampleSize(n/?)\n",
      "Mini?SampleSize(n/?)\n",
      "97.2\n",
      "10\n",
      "97.46\n",
      "Accuracy(%)\n",
      "97.10\n",
      "StructRegWeightReg\n",
      "97.48\n",
      "Accuracy(%)\n",
      "97.25\n",
      "93.6\n",
      "97.5F?score(%)\n",
      "StructRegWeightReg\n",
      "10\n",
      "\n",
      "97.3\n",
      "F?score(%)\n",
      "Accuracy(%)\n",
      "97.35\n",
      "5\n",
      "10\n",
      "15\n",
      "StructRegWeightAvg96.90\n",
      "20\n",
      "Mini?SampleSize(n/?)\n",
      "5\n",
      "10\n",
      "15\n",
      "Mini?SampleSize(n/?)\n",
      "20\n",
      "StructRegWeightAvg92.50\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Mini?SampleSize(n/?)\n",
      "Figure2:Onthefourtasks,comparingthestructureregularizationmethod\n",
      "(StructReg)withexistingregularizationmethodsintermsofaccuracy/F-score.\n",
      "Row-1showstheresultsonCRFsandRow-2showstheresultsonstructured\n",
      "perceptrons.Table1:Comparingourresultswiththebenchmarksystemson\n",
      "correspondingtasks.POS-Tagging(Acc%)Bio-NER(F1%)Word-Seg(F1%)\n",
      "Benchmarksystem97.33(see[13])72.28(see[19])97.19(see[4])Ourresults\n",
      "97.3672.4397.50Therichedgefeatures[16]areemployedforallmethods.All\n",
      "methodsarebasedonthe1st-orderMarkovdependency.ForWeightReg,the\n",
      "L2regularizationstrengths(i.e.,?/2inEq.(8))aretunedamongvalues0.1,0.5,\n",
      "1,2,5,andaredeterminedonthedevelopmentdata(POS-Tagging)orsimply\n",
      "via4-foldcrossvalidationonthetrainingset(Bio-NER,Word-Seg,andAct-\n",
      "Recog).WiththisautomatictuningforWeightReg,weset2,5,1and5for\n",
      "POS-Tagging,Bio-NER,Word-Seg,andAct-Recogtasks,respectively.3.1\n",
      "ExperimentalResults\n",
      "Theexperimentalresultsintermsofaccuracy/F-scoreareshowninFigure\n",
      "2.FortheCRFmodel,thetrainingisconvergent,andtheresultsonthecon-\n",
      "vergencestate(decidedbyrelativeobjectivechangewiththethresholdvalueof\n",
      "0.0001)areshown.Forthestructuredperceptronmodel,thetrainingistyp-\n",
      "icallynotconvergent,andtheresultsonthe10?thiterationareshown.For\n",
      "stabilityofthecurves,theresultsofthestructuredperceptronsareaveraged\n",
      "over10repeatedruns.Sincetsampleshavetsizeninpractice,\n",
      "weset?beingafunctionofn,sothatthegeneratedmini-samplesarewith\n",
      "sizen?withn?=n/?.Actually,n?isaprobabilisticdistributionbecause\n",
      "weadoptrandomizeddecomposition.Forexample,ifn?=5.5,itmeansthe\n",
      "minisamplesareamixtureoftheoneswiththesize5andtheoneswiththe\n",
      "11\n",
      "\n",
      "size6,andthemeanofthesizedistributionis5.5.Inthethecurves\n",
      "arebasedonn?=1.5,2.5,3.5,5.5,10.5,15.5,20.5.Aswecansee,there-\n",
      "sultsarequiteconsistent.Itdemonstratesthatstructureregularizationleadsto\n",
      "higheraccuracies/F-scorescomparedwiththeexistingbaselines.Wealsocon-\n",
      "ducttestsbasedont-test.Sincethet-testforF-scorebasedtasks\n",
      "(Bio-NERandWord-Seg)maybeunreliable8,weonlyperformt-testforthe\n",
      "accuracy-basedtasks,i.e.,POS-TaggingandAct-Recog.ForPOS-Tagging,the\n",
      "testsuggeststhatthesuperiorityofStructRegoverWeightRegis\n",
      "verystatisticallycant,withp<0.01.ForAct-Recog,thetests\n",
      "suggestthatboththeStructRegvs.WeightRegandtheStructReg\n",
      "vs.WeightAvgareextremelystatis8IndeedwecanconvertF-scores\n",
      "toaccuracyscoresfort-test,butinmanycasesthisconversionisunreliable.\n",
      "Forexample,verytF-scoresmaycorrespondtosimilaraccuracyscores.\n",
      "7\n",
      "4\n",
      "2.5\n",
      "x10\n",
      "POS?Tagging:CRF\n",
      "Bio?NER:CRF\n",
      "Word?Seg:CRF\n",
      "5000\n",
      "Act?Recog:CRF\n",
      "5000\n",
      "5000\n",
      "StructRegWeightReg1\n",
      "3000StructRegWeightReg2000\n",
      "40003500StructRegWeightReg\n",
      "3000\n",
      "Train?time(sec)\n",
      "1.5\n",
      "4000\n",
      "Train?time(sec)\n",
      "Train?time(sec)\n",
      "Train?time(sec)\n",
      "45002\n",
      "4000\n",
      "3000StructRegWeightReg2000\n",
      "25000.50\n",
      "5\n",
      "10\n",
      "15\n",
      "10000\n",
      "20\n",
      "5\n",
      "10\n",
      "15\n",
      "12\n",
      "\n",
      "20000\n",
      "20\n",
      "Mini?SampleSize(n/?)\n",
      "Mini?SampleSize(n/?)\n",
      "5\n",
      "Bio?NER:Perc\n",
      "POS?Tagging:Perc\n",
      "15\n",
      "10000\n",
      "20\n",
      "600\n",
      "350300250\n",
      "StructRegWeightAvg\n",
      "200\n",
      "400\n",
      "StructRegWeightAvg\n",
      "1504000\n",
      "5\n",
      "10\n",
      "15\n",
      "Mini?SampleSize(n/?)\n",
      "20\n",
      "1000\n",
      "20\n",
      "350\n",
      "Train?time(sec)\n",
      "StructRegWeightAvg\n",
      "15\n",
      "300Train?time(sec)\n",
      "Train?time(sec)\n",
      "Train?time(sec)\n",
      "800\n",
      "10\n",
      "Act?Recog:Perc\n",
      "450\n",
      "4001000\n",
      "5\n",
      "Mini?SampleSize(n/?)\n",
      "Word?Seg:Perc\n",
      "450\n",
      "1200\n",
      "10\n",
      "Mini?SampleSize(n/?)\n",
      "5\n",
      "10\n",
      "15\n",
      "13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3500\n",
      "20\n",
      "Mini?SampleSize(n/?)\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "250StructRegWeightAvg\n",
      "2001501000\n",
      "Mini?SampleSize(n/?)\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "Mini?SampleSize(n/?)\n",
      "Figure3:Onthefourtasks,comparingthestructureregularizationmethod\n",
      "(StructReg)withexistingregularizationmethodsintermsofwall-clocktraining\n",
      "time.ticallyt,withp<0.0001inbothcases.Theexperimentalre-\n",
      "sultssupportourtheoreticalanalysisthatstructureregularizationcanfurther\n",
      "reducethegeneralizationriskoverexistingweightregularizationtechniques.\n",
      "Ourmethodoutperformsthebenchmarksystemsonthethreeimportantnat-\n",
      "urallanguageprocessingtasks.ThePOS-Taggingtaskisahighlycompetitive\n",
      "task,withmanymethodsproposed,andthebestreport(withoutusingex-\n",
      "traresources)untilnowisachievedbyusingabidirectionallearningmodelin\n",
      "[13],9withtheaccuracy97.33%.Oursimplemethodachievesbetteraccuracy\n",
      "comparedwithallofthosestate-of-the-artsystems.Furthermore,ourmethod\n",
      "achievesasgoodscoresasthebenchmarksystemsontheBio-NERandWord-\n",
      "Segtasks.OntheBio-NERtask,[19]achieves72.28%basedonlookahead\n",
      "learningand[21]achieves72.65%basedonreranking.OntheWord-Segtask,\n",
      "[4]achieves97.19%basedonmaximumentropyandourrecent\n",
      "work[16]achieves97.5%basedonfeature-frequency-adaptiveonlinelearning.\n",
      "ThecomparisonsaresummarizedinTable1.Figure3showsexperimental\n",
      "comparisonsintermsofwall-clocktrainingtime.Aswecansee,theproposed\n",
      "methodcansubstantiallyimprovethetrainingspeed.Thespeedupisnotonly\n",
      "fromthefasterconvergencerates,butalsofromthefasterprocessingtimeon\n",
      "thestructures,becauseitismorettoprocessthedecomposedsamples\n",
      "withsimplestructures.\n",
      "4\n",
      "Conclusions\n",
      "Weproposedastructureregularizationframework,whichdecomposestrain-\n",
      "ingsamplesintominisampleswithsimplerstructures,derivingatrainedmodel\n",
      "withregularizedstructuralcomplexity.Ourtheoreticalanalysisshowedthat\n",
      "thismethodcanelyreducethegeneralizationrisk,andcanalsoacceler-\n",
      "atetheconvergencespeedintraining.Theproposedmethoddoesnotchange\n",
      "theconvexityoftheobjectivefunction,andcanbeusedtogetherwithany\n",
      "existingweightregularizationmethods.Notethat,theproposedmethodand\n",
      "14\n",
      "\n",
      "thetheoreticalresultscangeneralstructuresincludinglinearchains,trees,\n",
      "andgraphs.Experimentalresultsdemonstratedthatourmethodachievedbet-\n",
      "terresultsthanstate-of-the-artsystemsonseveralhighly-competitivetasks,\n",
      "andatthesametimewithsubstantiallyfastertrainingspeed.Acknowledg-\n",
      "ments.ThisworkwassupportedinpartbyNSFC(No.61300063).9Seea\n",
      "collectionofthesystemsathttp://aclweb.org/aclwiki/index.php?title=POS\n",
      "Tagging\n",
      "(State\n",
      "of\n",
      "the\n",
      "art)\n",
      "8\n",
      "2References\n",
      "[1]A.Argyriou,C.A.Micchelli,M.Pontil,andY.Ying.Aspectralregulariza-\n",
      "tionframeworkformulti-taskstructurelearning.InProceedingsofNIPS?07.\n",
      "MITPress,2007.[2]O.BousquetandA.Stabilityandgeneraliza-\n",
      "tion.JournalofMachineLearningResearch,2:499?526,2002.[3]M.Collins.\n",
      "Discriminativetrainingmethodsforhiddenmarkovmodels:Theoryandexper-\n",
      "imentswithperceptronalgorithms.InProceedingsofEMNLP?02,pages1?8,\n",
      "2002.[4]J.Gao,G.Andrew,M.Johnson,andK.Toutanova.Acomparative\n",
      "studyofparameterestimationmethodsforstatisticalnaturallanguageprocess-\n",
      "ing.InProceedingsofACL?07,pages824?831,2007.[5]J.Gra?a,K.Ganchev,\n",
      "B.Taskar,andF.Pereira.Posteriorvsparametersparsityinlatentvariable\n",
      "models.InProceedingsofNIPS?09,pages664?672,2009.[6]J.y,A.\n",
      "McCallum,andF.Pereira.ConditionalrandomProbabilisticmodels\n",
      "forsegmentingandlabelingsequencedata.InICML?01,pages282?289,2001.\n",
      "[7]B.London,B.Huang,B.Taskar,andL.Getoor.Pac-bayesgeneralization\n",
      "boundsforrandomizedstructuredprediction.InNIPSWorkshoponPertur-\n",
      "bation,OptimizationandStatistics,2007.[8]A.F.T.Martins,N.A.Smith,\n",
      "M.A.T.Figueiredo,andP.M.Q.Aguiar.Structuredsparsityinstructured\n",
      "prediction.InProceedingsofEMNLP?11,pages1500?1511,2011.[9]F.Niu,\n",
      "B.Recht,C.Re,andS.J.Wright.Hogwild:Alock-freeapproachtoparal-\n",
      "lelizingstochasticgradientdescent.InNIPS?11,pages693?701,2011.[10]A.\n",
      "Quattoni,X.Carreras,M.Collins,andT.Darrell.Antprojectionfor\n",
      "yregularization.InProceedingsofICML?09,page108,2009.[11]M.\n",
      "W.SchmidtandK.P.Murphy.Convexstructurelearninginlog-linearmodels:\n",
      "Beyondpairwisepotentials.InProceedingsofAISTATS?10,volume9ofJMLR\n",
      "Proceedings,pages709?716,2010.[12]S.Shalev-Shwartz,O.Shamir,N.Srebro,\n",
      "andK.Sridharan.Learnabilityandstabilityinthegenerallearningsetting.In\n",
      "ProceedingsofCOLT?09,2009.[13]L.Shen,G.Satta,andA.K.Joshi.Guided\n",
      "learningforbidirectionalsequenceInProceedingsofACL?07,\n",
      "2007.[14]X.Sun.Structureregularizationforstructuredprediction:Theories\n",
      "andexperiments.InTechnicalreport,arXiv,2014.[15]X.Sun,H.Kashima,\n",
      "andN.Ueda.Large-scalepersonalizedhumanactivityrecognitionusingon-\n",
      "linemultitasklearning.IEEETrans.Knowl.DataEng.,25(11):2551?2563,\n",
      "2013.[16]X.Sun,W.Li,H.Wang,andQ.Lu.Feature-frequency-adaptive\n",
      "on-linetrainingforfastandaccuratenaturallanguageprocessing.Computa-\n",
      "15\n",
      "\n",
      "tionalLinguistics,40(3):563?586,2014.[17]C.A.SuttonandA.McCallum.\n",
      "PiecewisepseudolikelihoodforttrainingofconditionalrandomIn\n",
      "ICML?07,pages863?870.ACM,2007.[18]B.Taskar,C.Guestrin,andD.\n",
      "Koller.Max-marginmarkovnetworks.InNIPS?03,2003.[19]Y.Tsuruoka,\n",
      "Y.Miyao,andJ.Kazama.Learningwithlookahead:Canhistory-basedmod-\n",
      "elsrivalgloballyoptimizedmodels?InConferenceonComputationalNatural\n",
      "LanguageLearning,2011.[20]H.Xue,S.Chen,andQ.Yang.Structural\n",
      "regularizedsupportvectormachine:Aframeworkforstructurallargemargin\n",
      "IEEETransactionsonNeuralNetworks,22(4):573?587,2011.[21]K.\n",
      "YoshidaandJ.Tsujii.Rerankingforbiomedicalnamed-entityrecognition.In\n",
      "ACLWorkshoponBioNLP,page209?lC216,2007.[22]M.YuanandY.Lin.\n",
      "Modelselectionandestimationinregressionwithgroupedvariables.Journalof\n",
      "theRoyalStatisticalSociety,SeriesB,68:49?67,2006.\n",
      "9\n",
      "16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import PyPDF2\n",
    "pdfs = glob.glob(r'PP*.pdf')\n",
    "pdf_f = (re.split(r',',str(pdfs)))\n",
    "#print(pdf_f)\n",
    "for i in range (0,len(pdf_f),1):\n",
    "    target = pdf_f[i:(i+1)]\n",
    "    #print(target)\n",
    "    target_f = (re.findall('PP\\d{4}.pdf',str(target)))\n",
    "    target_f1 = str(target_f).strip('')[2:-2]\n",
    "    print(target_f1)\n",
    "    \n",
    "    pdfFileObj = open(target_f1, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    numpage = pdfReader.numPages\n",
    "    print(target_f1,numpage)\n",
    "    content = []\n",
    "    for page in range(0,numpage): \n",
    "        pageObj = pdfReader.getPage(page)\n",
    "        content = pageObj.extractText()\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP5563.pdf\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
