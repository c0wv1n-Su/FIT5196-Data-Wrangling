{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1\n",
    "<a id=\"FIT5196\"></a>\n",
    "\n",
    "#### Student Name: Jiawei Su\n",
    "#### Student ID: 29590183\n",
    "\n",
    "\n",
    "#### Student Name: Weiwei Jin\n",
    "#### Student ID: 28106946\n",
    "\n",
    "Date: 25/08/2019\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.7.1 and Jupyter notebook\n",
    "\n",
    "Libraries used: \n",
    "* pandas (for dataframe, included in Anaconda Python 3.7.1) \n",
    "* re (for regular expression, included in Anaconda Python 3.7.1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [Student Information](#FIT5196)\n",
    "* [1. Introduction](#Introduction)\n",
    "* [2. Import libraries](#Lib)\n",
    "* [3. Regular Expressions Design](#Reg)\n",
    "   * [3.1. Approach](#app)\n",
    "   * [3.2. Patterns](#pat)\n",
    "   * [3.2. Explanation of Patterns](#Expat)\n",
    "* [4. Functions](#Functions)\n",
    "* [5. Processing the file](#Processing)\n",
    "   * [5.1. Read file](#read)\n",
    "   * [5.2. Process data and generate CSV file](#csv)\n",
    "   * [5.3. Process data and generate JSON file](#json)\n",
    "* [6. Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Introduction\n",
    "<a id=\"Introduction\"></a>\n",
    "\n",
    "In this task, a text file `Group067.txt` will be provided, all the data in the text file should be processed. Follow the assignment 1 requirement, the data in the text should be parsed and certain elements of data should be extracted. After the data is wrangled, it will be converted to `Group067.csv` file and `Group067.json` in the provided format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries\n",
    "<a id=\"Lib\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries used in this assessment\n",
    "\n",
    "# Pandas library provides high-performance, easy-to-use data structures \n",
    "# and data analysis tools\n",
    "import pandas as pd\n",
    "\n",
    "# Re library provides regex related functions\n",
    "import re\n",
    "\n",
    "# CSV library is used to process CSV file\n",
    "import csv\n",
    "\n",
    "# JSON library is used to process JSON file\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Regular Expressions Design\n",
    "<a id=\"Reg\"></a>\n",
    "\n",
    "In this section, we have defined the Regular expression patterns we used to extract data from text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Approach\n",
    "<a id=\"app\"></a>\n",
    "The approach we designed to extract data elements from the provided `.txt` file is stated as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "1. Read `.txt` file, separate the file into blocks of patents by using the line `<?xml version=\"1.0\" encoding=\"UTF-8\"?>` we have identified.\n",
    "\n",
    "\n",
    "2. For `150` blocks of data, we identify patterns and use them to extract different elements which will be explained in `section 3.2`.\n",
    "\n",
    "\n",
    "3. There are math formulas in the text. We have decided to remove them (both `regular math formula` and `in-line math formula`) as they cannot be shown correctly in `.csv` file or `.json` file. We will keep the variables in text.\n",
    "\n",
    "\n",
    "4. We put the lists of different element result together using either `Pandas` or `Zip` based on assessment requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Patterns\n",
    "<a id=\"pat\"></a>\n",
    "The regular expression patterns and other useful constants we use in this assignment is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'Group067.txt'\n",
    "\n",
    "# Define the output path for csv document\n",
    "CSV_OUTPUT_PATH = 'Group067.csv'      \n",
    "\n",
    "# Define the output path for json document\n",
    "JSON_OUTPUT_PATH = 'Group067.json'    \n",
    "\n",
    "# Using regular expression patterns to extract trageted data\n",
    "ID_PATTERN = re.compile('(<document-id>.+?</document-id>)')      \n",
    "ID_CONTENT_PATTERN = re.compile('<publication-reference>(.*?)</publication-reference>')\n",
    "\n",
    "KIND_CONTENT_PATTERN = re.compile('appl-type\\s*=\\s*\"(.+?)\"')\n",
    "\n",
    "TITLE_CONTENT_PATTERN = re.compile('<invention-title id=\".*\">(.*?)</invention-title>')\n",
    "\n",
    "CLAIM_CONTENT_PATTERN = re.compile('<number-of-claims>(.*?)</number-of-claims>')\n",
    "\n",
    "EXAM_CITE_CONTENT_PATTERN = re.compile('<category>cited by examiner</category>')\n",
    "\n",
    "APP_CITE_CONTENT_PATTERN = re.compile('<category>cited by applicant</category>')\n",
    "\n",
    "INVENTORS_GROUP_PATTERN = re.compile('<inventors>(.*?)</inventors>')\n",
    "INVENTORS_CONTENT_PATTERN = re.compile('<inventor sequence=\"[^\"]*\" designation=\"[^\"]*\">(.*?)</inventor>')\n",
    "FIRST_NAME_CONTENT_PATTERN = re.compile('<first-name>(.*?)</first-name>')\n",
    "LAST_NAME_CONTENT_PATTERN = re.compile('<last-name>(.*?)</last-name>')\n",
    "\n",
    "CLAIMS_CONTENT_PATTERN = re.compile('<claim id=\"[^\"]*\" num=\"[^\"]*\">(.*?)</claim>')\n",
    "TAG_REMOVE_PATTERN = re.compile('</?(.+?)>')\n",
    "MATH_REMOVE_PATTERN = re.compile('<maths id=\"[^\"]*\" num=\"[^\"]*\">(.*?)</maths>')\n",
    "FORMULA_REMOVE_PATTERN = re.compile('<[?]in-line-formulae description=\"In-line Formulae\" end=\"lead\"[?]>(.*?)<[?]in-line-formulae description=\"In-line Formulae\" end=\"tail\"[?]>')\n",
    "\n",
    "ABSTRACT_CONTENT_PATTERN = re.compile('<abstract id=\"abstract\">(.*?)</abstract>')\n",
    "\n",
    "# A list consists of the name of required data elements\n",
    "NAME_ROW = [\"grant_id\", \"patent_title\", \"kind\", \"number_of_claims\", \"inventors\", \n",
    "            \"citations_applicant_count\", \"citations_examiner_count\", \"claims_text\", \"abstract\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Explanation of Patterns\n",
    "<a id=\"Expat\"></a>\n",
    "Explanation of our designed regular expression and the approach we design them is below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "1. **`ID_PATTERN`** and **`ID_CONTENT_PATTERN`** is used to extract: country code(which sits between `<country>` and `</country>`) and id number(which sits between `<doc-number>` and `</doc-number>`) and concatenate them to get ID. Full approach in function **grant_id**.\n",
    "\n",
    "\n",
    "2. **`KIND_CONTENT_PATTERN`** is used to extract: patent kind(which sits in `<application-reference >` as the value of the attribute `appl-type`). Full approach in function **kind**.\n",
    "\n",
    "\n",
    "3. **`TITLE_CONTENT_PATTERN`** is used to extract: patent title(which sits between `<invention-title>` and `</invention-title>`). Full approach in function **patent_title**.\n",
    "\n",
    "\n",
    "4. **`CLAIM_CONTENT_PATTERN`** is used to extract: the number of claims(which sits between `<number-of-claims>` and `</number-of-claims>`). Full approach in function **number_of_claims**.\n",
    "\n",
    "\n",
    "5. **`EXAM_CITE_CONTENT_PATTERN`** is used to extract: the number of examiner citations(where the text between `<category>` and `</category>` in each block is `cited by examiner`), we count the number of this text we scanned frm the text. Full approach in function **citations_examiner_count**.\n",
    "\n",
    "\n",
    "6. **`APP_CITE_CONTENT_PATTERN`** is used to extract: the number of applicant citations(where the text between `<category>` and `</category>` in each block is `cited by applicant`), we count the number of this text we scanned frm the text. Full approach in function **citations_applicant_count**.\n",
    "\n",
    "\n",
    "7. **`INVENTORS_GROUP_PATTERN`** and **`INVENTORS_CONTENT_PATTERN`** is used to extract: all the authors(which sits between `<inventors>` and `</inventors>`) for each block and from which we can separate each author's detail(which sits between `<inventor >` and `</inventor>`). Then we use **`FIRST_NAME_CONTENT_PATTERN`** and **`LAST_NAME_CONTENT_PATTERN`** to  extract: First Name(which sits between `<first-name>` and `</first-name>`) and Last Name(which sits between `<last-name>` and `</last-name>`) and concatenate them to get the full name. Full approach in function **inventors**.\n",
    "\n",
    "\n",
    "8. **`CLAIMS_CONTENT_PATTERN`** is used to extract: claim content(which sits between `<claim >` and `</claim>`). Then we first need to remove Math formula using **`MATH_REMOVE_PATTERN`** and **`FORMULA_REMOVE_PATTERN`** ,then we need to remove all tags using **`TAG_REMOVE_PATTERN`**. Lastly we concatenate all the claims. Full approach in function **claims_text**.\n",
    "\n",
    "\n",
    "9. **`ABSTRACT_CONTENT_PATTERN`** is used to extract: abstract(which sits between `<abstract >` and `</abstract>`). Then we first need to remove Math formula using **`MATH_REMOVE_PATTERN`** and **`FORMULA_REMOVE_PATTERN`** ,then we need to remove all tags using **`TAG_REMOVE_PATTERN`**. Full approach in function **abstract**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "1. **`TAG_REMOVE_PATTERN`**: Remove useless tags and text between `<` and `>`.\n",
    "\n",
    "\n",
    "2. **`MATH_REMOVE_PATTERN`**: Used to clean maths equations between `<maths >` and `</maths>` which we don't need to handle in this assignment.\n",
    "\n",
    "\n",
    "3. **`FORMULA_REMOVE_PATTERN`**: Used to clean in line math formulas between `<?in-line-formulae description=\"In-line Formulae\" end=\"lead\"?>` and `<?in-line-formulae description=\"In-line Formulae\" end=\"tail\"?>` which we don't need to handle in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Functions\n",
    "<a id=\"Functions\"></a>\n",
    "\n",
    "In this secition, we define a couple of functions prior to processing the file. The goal is to make it simpler when we use the them to extract the data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the a text file, preprocess it, add the content of the text file to a list and return the list.\n",
    "def read_file(path):        \n",
    "    content = []                                         \n",
    "    try:\n",
    "        with open(path, 'r', encoding = 'utf-8') as fp: \n",
    "            for line in fp:\n",
    "                if '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' in line:\n",
    "                    content.append('')\n",
    "                content[-1] += line.strip('\\n')\n",
    "    finally:\n",
    "        fp.close()\n",
    "    return content\n",
    "\n",
    "# Function to find the required data(patent id) and return the results in a list\n",
    "def grant_id(content):                                   \n",
    "    result = []\n",
    "\n",
    "    # Use ID_CONTENT_PATTERN to findout the country and document number and put them together as the id\n",
    "    for entry in content:    \n",
    "        block = ID_CONTENT_PATTERN.findall(entry)       \n",
    "        result.append(re.findall(r'(<country>(.*?)</country>)', block[0])[0][1] \n",
    "                      + re.findall(r'(<doc-number>(.*?)</doc-number>)', block[0])[0][1])\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(patent id), pre-process it and return the result in a list\n",
    "def kind(content):\n",
    "    result = []\n",
    "    for entry in content:\n",
    "        raw_opt = KIND_CONTENT_PATTERN.findall(entry)\n",
    "        if \"utility\" in raw_opt:\n",
    "            result.append(\"Utility Patent Grant (with a published application) issued on or after January 2, 2001.\")\n",
    "        else:\n",
    "            result.append(raw_opt[0].capitalize() + \" Patent\")\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(patent title) and return the result in a list\n",
    "def patent_title(content):  \n",
    "    result = []\n",
    "    for entry in content:\n",
    "        result.append(re.findall(TITLE_CONTENT_PATTERN, entry)[0])\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(number of claims) and return the result in a list\n",
    "def number_of_claims(content): \n",
    "    result = []\n",
    "    for entry in content:\n",
    "        result.append(re.findall(CLAIM_CONTENT_PATTERN, entry)[0])\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(ciatations examiner count) and return the result in a list\n",
    "def citations_examiner_count(content):\n",
    "    result = []\n",
    "    for entry in content:\n",
    "        result.append(len(re.findall(EXAM_CITE_CONTENT_PATTERN, entry)))\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(application citation content) and return the result in a list\n",
    "def citations_applicant_count(content): \n",
    "    result = []\n",
    "    for entry in content:\n",
    "        result.append(len(re.findall(APP_CITE_CONTENT_PATTERN, entry)))\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(inventors' name) and return the result in a list\n",
    "def inventors(content):     \n",
    "    result = []\n",
    "    for entry in content:\n",
    "        stri = \"[\"\n",
    "        author = []\n",
    "        inv_block = re.findall(INVENTORS_GROUP_PATTERN, entry)[0]  \n",
    "        for inv in re.findall(INVENTORS_CONTENT_PATTERN, inv_block):\n",
    "            author.append(re.findall(FIRST_NAME_CONTENT_PATTERN, inv)[0] \n",
    "                          + \" \" + re.findall(LAST_NAME_CONTENT_PATTERN, inv)[0])\n",
    "        # If the list is not empty, add the list of authors in the result list or if it is empty, add \"NA\"\n",
    "        if author:                      \n",
    "            for loc, au in enumerate(author):\n",
    "                stri += au\n",
    "                if loc < len(author) - 1:\n",
    "                    stri += \",\"\n",
    "                if loc == len(author) - 1:\n",
    "                    stri += \"]\"\n",
    "            result.append(stri)\n",
    "        else:\n",
    "            result.append(\"NA\")\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(claims text) and return the result in a list \n",
    "def claims_text(content):           \n",
    "    result = []\n",
    "    for entry in content:           \n",
    "        block = re.findall(CLAIMS_CONTENT_PATTERN, entry)\n",
    "        this_claim = []\n",
    "        stri = \"[\"\n",
    "         \n",
    "        # Add the result into the result list\n",
    "        for claim in block:\n",
    "            # Clean Math formulas\n",
    "            new_claim = re.sub(MATH_REMOVE_PATTERN, '', claim)\n",
    "            \n",
    "            # Clean in-line math formulas\n",
    "            a_new_claim = re.sub(FORMULA_REMOVE_PATTERN, '', new_claim)\n",
    "            \n",
    "            # Replece all the tags(and contents between \"</>\") in the claims_content_pattern with ''\n",
    "            this_claim.append(re.sub(TAG_REMOVE_PATTERN, '', a_new_claim))\n",
    "        # If the required data is found, add to the result list, if not just append \"NA\"\n",
    "        if this_claim:            \n",
    "            for loc, cl in enumerate(this_claim):\n",
    "                stri += cl\n",
    "                if loc < len(this_claim) - 1:\n",
    "                    stri += \",\"\n",
    "                if loc == len(this_claim) - 1:\n",
    "                    stri += \"]\"\n",
    "            result.append(stri)\n",
    "        else:\n",
    "            result.append(\"NA\")\n",
    "    return result\n",
    "\n",
    "# Function to find the required data(abstract) and return the result in a list \n",
    "def abstract(content):\n",
    "    result = []\n",
    "    # Add the data to the result list\n",
    "    for entry in content:         \n",
    "        result.append(re.findall(ABSTRACT_CONTENT_PATTERN, entry))\n",
    "    for count in range(len(result)):\n",
    "        # If not data can be found, append \"NA\"\n",
    "        if not result[count]:\n",
    "            result[count] = 'NA'\n",
    "        # If there are matched result, replace the tag(and the contents between \"</>\") with ''.\n",
    "        else:                         \n",
    "            result[count] = re.sub(TAG_REMOVE_PATTERN, '', result[count][0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Processing the file\n",
    "<a id=\"Processing\"></a>\n",
    "\n",
    "In this section, we process the file using the defined function, and then generate output files in the format of CSV using pandas and JSON using traditional method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Read file\n",
    "<a id=\"read\"></a>\n",
    "Read the file defined in the file path into a list called `src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file defined in the file path into a list\n",
    "src = read_file(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Process data and generate CSV file\n",
    "<a id=\"csv\"></a>\n",
    "Process the data and then output into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of functions which will be applied to the list of data\n",
    "parsing_alrogithms = [grant_id, patent_title, kind, number_of_claims, inventors,    \n",
    "                      citations_applicant_count, citations_examiner_count, claims_text, abstract]\n",
    "\n",
    "# Define an empty dictionay\n",
    "dic = {}\n",
    "\n",
    "# Apply functions in list to data list and then add the result to the dictionary under the key of its function name\n",
    "for funct in parsing_alrogithms:        \n",
    "    dic[funct.__name__] = funct(src)\n",
    "\n",
    "# Using pandas's dataframe to store the dictionary with using the defined table's column name \n",
    "df = pd.DataFrame(dic, columns = NAME_ROW)\n",
    "\n",
    "# Output the dataframe to a CSV file\n",
    "df.to_csv(CSV_OUTPUT_PATH, index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Process data and generate JSON file\n",
    "<a id=\"json\"></a>\n",
    "Process the data and then output into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to extract data and store into separate lists\n",
    "list_id = grant_id(src)\n",
    "list_kind = kind(src)\n",
    "list_title = patent_title(src)\n",
    "list_no_claims = number_of_claims(src)\n",
    "list_exam_cite = citations_examiner_count(src)\n",
    "list_app_cite = citations_applicant_count(src)\n",
    "list_inv = inventors(src)\n",
    "list_claim = claims_text(src)\n",
    "list_abst = abstract(src)\n",
    "\n",
    "# Zip the lists together(without the list of IDs)\n",
    "zipped = zip(list_kind, list_title, list_no_claims, list_exam_cite,  \n",
    "            list_app_cite, list_inv, list_claim, list_abst)\n",
    "\n",
    "info = []\n",
    "for el in zipped:\n",
    "    # Process each entry of the zipped result and add data into the new dictionary\n",
    "    dict_temp = {}\n",
    "    dict_temp[\"patent_title\"] = el[1]\n",
    "    dict_temp[\"kind\"] = el[0]\n",
    "    dict_temp[\"number_of_claims\"] = int(el[2])\n",
    "    dict_temp[\"inventors\"] = el[5]\n",
    "    dict_temp[\"citations_applicant_count\"] = el[4]\n",
    "    dict_temp[\"citations_examiner_count\"] = el[3]\n",
    "    dict_temp[\"claims_text\"] = el[6]\n",
    "    dict_temp[\"abstract\"] = el[7]\n",
    "    \n",
    "    # Add the dictionary of contents into a list\n",
    "    info.append(dict_temp)\n",
    "\n",
    "# Zip the ids with its information and then add them into a new dictionary\n",
    "j_dict = {}              \n",
    "for each in zip(list_id, info):\n",
    "    j_dict[each[0]] = each[1]\n",
    "\n",
    "# Dump the dictionary into a string\n",
    "json_str = json.dumps(j_dict)  \n",
    "with open(JSON_OUTPUT_PATH, 'w') as json_file:\n",
    "    # Write the json string to a new json file\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "<a id=\"Summary\"></a>\n",
    "\n",
    "In this assignment, we are required to parse a text document and output into a JSON file and CSV document. Firstly, we use the regular expression to scan all the required elements and save them into result lists. Secondly, we use a pandas DatatFrame structure to output the contents into a CSV file. Lastly, we use use the traditional method to zip the results of different elements and then output the result into a JSON file. Takeaways of this assessmnet is:\n",
    "\n",
    "- **Applying Regular Expression** : We explore differnet techniques of regular expression to help us extract useful data element from text. Useful functions in `re` library are `findall()` and `sub()`.\n",
    "\n",
    "\n",
    "- **Pandas Dataframe** : We use Pandasdataframe to store data, this is an easier and simpler format. `to_csv()` function can be used to generate an `.csv` outout of a Dataframe .\n",
    "\n",
    "\n",
    "- **Combining Lists** : The `zip()` function returns a zip object, which is an iterator of tuples where the first item in each passed iterator is paired together, and then the second item in each passed iterator are paired together, etc. \n",
    "\n",
    "\n",
    "- **List Traversal** : The `enumerate()` function helps us an easier way to traverse a list. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
